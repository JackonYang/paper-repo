{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40190254"
                        ],
                        "name": "I. Fujita",
                        "slug": "I.-Fujita",
                        "structuredName": {
                            "firstName": "Ichiro",
                            "lastName": "Fujita",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Fujita"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2048860"
                        ],
                        "name": "Keiji Tanaka",
                        "slug": "Keiji-Tanaka",
                        "structuredName": {
                            "firstName": "Keiji",
                            "lastName": "Tanaka",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Keiji Tanaka"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108813944"
                        ],
                        "name": "Minami Ito",
                        "slug": "Minami-Ito",
                        "structuredName": {
                            "firstName": "Minami",
                            "lastName": "Ito",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Minami Ito"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40622591"
                        ],
                        "name": "K. Cheng",
                        "slug": "K.-Cheng",
                        "structuredName": {
                            "firstName": "Kang",
                            "lastName": "Cheng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Cheng"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 38714031,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "083630744dbf60994867cbd776bfe601b4d0dbe6",
            "isKey": false,
            "numCitedBy": 684,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "AT early stages of the mammalian visual cortex, neurons with similar stimulus selectivities are vertically arrayed through the thickness of the cortical sheet and clustered in patches or bands across the surface. This organization, referred to as a 'column', has been found with respect to one-dimensional stimulus parameters such as orientation of stimulus contours1, eye dominance of visual inputs1, and direction of stimulus motion2. It is unclear, however, whether information with extremely high dimensions, such as visual shape, is organized in a similar columnar fashion or in a different manner in the brain. Here we report that the anterior inferotemporal area of the monkey cortex, the final station of the visual cortical stream crucial for object recognition3\u20138, consists of columns, each containing cells responsive to similar visual features of objects."
            },
            "slug": "Columns-for-visual-features-of-objects-in-monkey-Fujita-Tanaka",
            "title": {
                "fragments": [],
                "text": "Columns for visual features of objects in monkey inferotemporal cortex"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The anterior inferotemporal area of the monkey cortex, the final station of the visual cortical stream crucial for object recognition, consists of columns, each containing cells responsive to similar visual features of objects."
            },
            "venue": {
                "fragments": [],
                "text": "Nature"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31772450"
                        ],
                        "name": "N. Logothetis",
                        "slug": "N.-Logothetis",
                        "structuredName": {
                            "firstName": "Nikos",
                            "lastName": "Logothetis",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Logothetis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144320332"
                        ],
                        "name": "J. Pauls",
                        "slug": "J.-Pauls",
                        "structuredName": {
                            "firstName": "Jon",
                            "lastName": "Pauls",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Pauls"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685292"
                        ],
                        "name": "T. Poggio",
                        "slug": "T.-Poggio",
                        "structuredName": {
                            "firstName": "Tomaso",
                            "lastName": "Poggio",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Poggio"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15325604,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "7d7721e2c556e02f35654428953ed83cfa8adff8",
            "isKey": false,
            "numCitedBy": 988,
            "numCiting": 41,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Shape-representation-in-the-inferior-temporal-of-Logothetis-Pauls",
            "title": {
                "fragments": [],
                "text": "Shape representation in the inferior temporal cortex of monkeys"
            },
            "venue": {
                "fragments": [],
                "text": "Current Biology"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1996960"
                        ],
                        "name": "M. Riesenhuber",
                        "slug": "M.-Riesenhuber",
                        "structuredName": {
                            "firstName": "Maximilian",
                            "lastName": "Riesenhuber",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Riesenhuber"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685292"
                        ],
                        "name": "T. Poggio",
                        "slug": "T.-Poggio",
                        "structuredName": {
                            "firstName": "Tomaso",
                            "lastName": "Poggio",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Poggio"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "We used a scheme similar to a biological model incorporating the maximum operatio"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 8920227,
            "fieldsOfStudy": [
                "Biology",
                "Psychology"
            ],
            "id": "85abadb689897997f1e37baa7b5fc6f7d497518b",
            "isKey": false,
            "numCitedBy": 3317,
            "numCiting": 51,
            "paperAbstract": {
                "fragments": [],
                "text": "Visual processing in cortex is classically modeled as a hierarchy of increasingly sophisticated representations, naturally extending the model of simple to complex cells of Hubel and Wiesel. Surprisingly, little quantitative modeling has been done to explore the biological feasibility of this class of models to explain aspects of higher-level visual processing such as object recognition. We describe a new hierarchical model consistent with physiological data from inferotemporal cortex that accounts for this complex visual task and makes testable predictions. The model is based on a MAX-like operation applied to inputs to certain cortical neurons that may have a general role in cortical function."
            },
            "slug": "Hierarchical-models-of-object-recognition-in-cortex-Riesenhuber-Poggio",
            "title": {
                "fragments": [],
                "text": "Hierarchical models of object recognition in cortex"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "A new hierarchical model consistent with physiological data from inferotemporal cortex that accounts for this complex visual task and makes testable predictions is described."
            },
            "venue": {
                "fragments": [],
                "text": "Nature Neuroscience"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1743045"
                        ],
                        "name": "S. Ullman",
                        "slug": "S.-Ullman",
                        "structuredName": {
                            "firstName": "Shimon",
                            "lastName": "Ullman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Ullman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143715947"
                        ],
                        "name": "S. Soloviev",
                        "slug": "S.-Soloviev",
                        "structuredName": {
                            "firstName": "Sergei",
                            "lastName": "Soloviev",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Soloviev"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 11002128,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "444ed0d2de5b0a56e70c93089b6205659707f522",
            "isKey": false,
            "numCitedBy": 63,
            "numCiting": 62,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Computation-of-pattern-invariance-in-brain-like-Ullman-Soloviev",
            "title": {
                "fragments": [],
                "text": "Computation of pattern invariance in brain-like structures"
            },
            "venue": {
                "fragments": [],
                "text": "Neural Networks"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2093644"
                        ],
                        "name": "Bartlett W. Mel",
                        "slug": "Bartlett-W.-Mel",
                        "structuredName": {
                            "firstName": "Bartlett",
                            "lastName": "Mel",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bartlett W. Mel"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7632903,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "33b98b5dc150680fc02a14c0cf629168dd0af08b",
            "isKey": false,
            "numCitedBy": 408,
            "numCiting": 55,
            "paperAbstract": {
                "fragments": [],
                "text": "Severe architectural and timing constraints within the primate visual system support the conjecture that the early phase of object recognition in the brain is based on a feedforward feature-extraction hierarchy. To assess the plausibility of this conjecture in an engineering context, a difficult three-dimensional object recognition domain was developed to challenge a pure feedforward, receptive-field based recognition model called SEEMORE. SEEMORE is based on 102 viewpoint-invariant nonlinear filters that as a group are sensitive to contour, texture, and color cues. The visual domain consists of 100 real objects of many different types, including rigid (shovel), nonrigid (telephone cord), and statistical (maple leaf cluster) objects and photographs of complex scenes. Objects were in dividually presented in color video images under normal room lighting conditions. Based on 12 to 36 training views, SEEMORE was required to recognize unnormalized test views of objects that could vary in position, orientation in the image plane and in depth, and scale (factor of 2); for non rigid objects, recognition was also tested under gross shape deformations. Correct classification performance on a test set consisting of 600 novel object views was 97 percent (chance was 1 percent) and was comparable for the subset of 15 nonrigid objects. Performance was also measured under a variety of image degradation conditions, including partial occlusion, limited clutter, color shift, and additive noise. Generalization behavior and classification errors illustrate the emergence of several striking natural shape categories that are not explicitly encoded in the dimensions of the feature space. It is concluded that in the light of the vast hardware resources available in the ventral stream of the primate visual system relative to those exercised here, the appealingly simple feature-space conjecture remains worthy of serious consideration as a neurobiological model."
            },
            "slug": "SEEMORE:-Combining-Color,-Shape,-and-Texture-in-a-Mel",
            "title": {
                "fragments": [],
                "text": "SEEMORE: Combining Color, Shape, and Texture Histogramming in a Neurally Inspired Approach to Visual Object Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "It is concluded that in the light of the vast hardware resources available in the ventral stream of the primate visual system relative to those exercised here, the appealingly simple feature-space conjecture remains worthy of serious consideration as a neurobiological model."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144187218"
                        ],
                        "name": "A. J. Bell",
                        "slug": "A.-J.-Bell",
                        "structuredName": {
                            "firstName": "Anthony",
                            "lastName": "Bell",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. J. Bell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1714528"
                        ],
                        "name": "T. Sejnowski",
                        "slug": "T.-Sejnowski",
                        "structuredName": {
                            "firstName": "Terrence",
                            "lastName": "Sejnowski",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Sejnowski"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 83,
                                "start": 80
                            }
                        ],
                        "text": "Detected fragments were combined within a 40-pixel search window using equation (3)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 6219133,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ca1d23be869380ac9e900578c601c2d1febcc0c9",
            "isKey": false,
            "numCitedBy": 2373,
            "numCiting": 90,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "The-\u201cindependent-components\u201d-of-natural-scenes-are-Bell-Sejnowski",
            "title": {
                "fragments": [],
                "text": "The \u201cindependent components\u201d of natural scenes are edge filters"
            },
            "venue": {
                "fragments": [],
                "text": "Vision Research"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49649079"
                        ],
                        "name": "D. Field",
                        "slug": "D.-Field",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Field",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Field"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 153,
                                "start": 150
                            }
                        ],
                        "text": "We also I(C, F) = \u2013P(C)Log(P(C)) \u2013P(C)Log(P(C) + P(F)((P(C\uf8e6 F) Log(P(C\uf8e6 F)) + P(C\uf8e6 F)Log P(C\uf8e6 F)))+ P(F)((P(C\uf8e6 F) Log(P(C\uf8e6 F)) + P(C\uf8e6 F)Log(P(C\uf8e6 F))) (4) 1."
                    },
                    "intents": []
                }
            ],
            "corpusId": 1650980,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ff1152582155acaa0e9d0ccbc900a4641504256d",
            "isKey": false,
            "numCitedBy": 1344,
            "numCiting": 85,
            "paperAbstract": {
                "fragments": [],
                "text": "A number of recent attempts have been made to describe early sensory coding in terms of a general information processing strategy. In this paper, two strategies are contrasted. Both strategies take advantage of the redundancy in the environment to produce more effective representations. The first is described as a compact coding scheme. A compact code performs a transform that allows the input to be represented with a reduced number of vectors (cells) with minimal RMS error. This approach has recently become popular in the neural network literature and is related to a process called Principal Components Analysis (PCA). A number of recent papers have suggested that the optimal compact code for representing natural scenes will have units with receptive field profiles much like those found in the retina and primary visual cortex. However, in this paper, it is proposed that compact coding schemes are insufficient to account for the receptive field properties of cells in the mammalian visual pathway. In contrast, it is proposed that the visual system is near to optimal in representing natural scenes only if optimality is defined in terms of sparse distributed coding. In a sparse distributed code, all cells in the code have an equal response probability across the class of images but have a low response probability for any single image. In such a code, the dimensionality is not reduced. Rather, the redundancy of the input is transformed into the redundancy of the firing pattern of cells. It is proposed that the signature for a sparse code is found in the fourth moment of the response distribution (i.e., the kurtosis). In measurements with 55 calibrated natural scenes, the kurtosis was found to peak when the bandwidths of the visual code matched those of cells in the mammalian visual cortex. Codes resembling wavelet transforms are proposed to be effective because the response histograms of such codes are sparse (i.e., show high kurtosis) when presented with natural scenes. It is proposed that the structure of the image that allows sparse coding is found in the phase spectrum of the image. It is suggested that natural scenes, to a first approximation, can be considered as a sum of self-similar local functions (the inverse of a wavelet). Possible reasons for why sensory systems would evolve toward sparse coding are presented."
            },
            "slug": "What-Is-the-Goal-of-Sensory-Coding-Field",
            "title": {
                "fragments": [],
                "text": "What Is the Goal of Sensory Coding?"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "It is proposed that compact coding schemes are insufficient to account for the receptive field properties of cells in the mammalian visual pathway and suggested that natural scenes, to a first approximation, can be considered as a sum of self-similar local functions (the inverse of a wavelet)."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1403305613"
                        ],
                        "name": "K. Grill-Spector",
                        "slug": "K.-Grill-Spector",
                        "structuredName": {
                            "firstName": "Kalanit",
                            "lastName": "Grill-Spector",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Grill-Spector"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39370159"
                        ],
                        "name": "T. Kushnir",
                        "slug": "T.-Kushnir",
                        "structuredName": {
                            "firstName": "Tammar",
                            "lastName": "Kushnir",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kushnir"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1705259"
                        ],
                        "name": "T. Hendler",
                        "slug": "T.-Hendler",
                        "structuredName": {
                            "firstName": "Talma",
                            "lastName": "Hendler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Hendler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2331213"
                        ],
                        "name": "S. Edelman",
                        "slug": "S.-Edelman",
                        "structuredName": {
                            "firstName": "Shimon",
                            "lastName": "Edelman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Edelman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2162208921"
                        ],
                        "name": "Yacov Itzchak",
                        "slug": "Yacov-Itzchak",
                        "structuredName": {
                            "firstName": "Yacov",
                            "lastName": "Itzchak",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yacov Itzchak"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1993227"
                        ],
                        "name": "R. Malach",
                        "slug": "R.-Malach",
                        "structuredName": {
                            "firstName": "Rafael",
                            "lastName": "Malach",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Malach"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": ", as well as in human visual cortex (mapped by functional magnetic resonance imaging"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1565604,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "1525a40e0947889dcd5083d277109f61452c09dc",
            "isKey": false,
            "numCitedBy": 474,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "Functional magnetic resonance imaging was used in combined functional selectivity and retinotopic mapping tests to reveal object\u2010related visual areas in the human occpital lobe. Subjects were tested with right, left, up, or down hemivisual field stimuli which were composed of images of natural objects (faces, animals, man\u2010made objects) or highly scrambled (1,024 elements) versions of the same images. In a similar fashion, the horizontal and vertical meridians were mapped to define the borders of these areas. Concurrently, the same cortical sites were tested for their sensitivity to image\u2010scrambling by varying the number of scrambled picture fragments (from 16\u20131,024) while controlling for the Fourier power spectrum of the pictures and their order of presentation. Our results reveal a stagewise decrease in retinotopy and an increase in sensitivity to image\u2010scrambling. Three main distinct foci were found in the human visual object recognition pathway (Ungerleider and Haxby [1994]: Curr Opin Neurobiol 4:157\u2013165): 1) Retinotopic primary areas V1\u20133 did not exhibit significant reduction in activation to scrambled images. 2) Areas V4v (Sereno et al., [1995]: Science 268:889\u2013893) and V3A (DeYoe et al., [1996]: Proc Natl Acad Sci USA 93:2382\u20132386; Tootell et al., [1997]: J Neurosci 71:7060\u20137078) manifested both retinotopy and decreased activation to highly scrambled images. 3) The essentially nonretinotopic lateral occipital complex (LO) (Malach et al., [1995]: Proc Natl Acad Sci USA 92:8135\u20138139; Tootell et al., [1996]: Trends Neurosci 19:481\u2013489) exhibited the highest sensitivity to image scrambling, and appears to be homologous to macaque the infero\u2010temporal (IT) cortex (Tanaka [1996]: Curr Opin Neurobiol 523\u2013529). Breaking the images into 64, 256, or 1,024 randomly scrambled blocks reduced activation in LO voxels. However, many LO voxels remained significantly activated by mildly scrambled images (16 blocks). These results suggest the existence of object\u2010fragment representation in LO. Hum. Brain Mapping 6:316\u2013328, 1998. \u00a9 1998 Wiley\u2010Liss, Inc."
            },
            "slug": "A-sequence-of-object\u2010processing-stages-revealed-by-Grill-Spector-Kushnir",
            "title": {
                "fragments": [],
                "text": "A sequence of object\u2010processing stages revealed by fMRI in the human occipital lobe"
            },
            "tldr": {
                "abstractSimilarityScore": 83,
                "text": "Functional magnetic resonance imaging was used in combined functional selectivity and retinotopic mapping tests to reveal object\u2010related visual areas in the human occpital lobe and suggest the existence of object\u2010fragment representation in LO."
            },
            "venue": {
                "fragments": [],
                "text": "Human brain mapping"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2157875742"
                        ],
                        "name": "K. Tanaka",
                        "slug": "K.-Tanaka",
                        "structuredName": {
                            "firstName": "K.",
                            "lastName": "Tanaka",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Tanaka"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 41793357,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "ae16712906bdb66907950fbb8c5436e54b281812",
            "isKey": false,
            "numCitedBy": 524,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "Recognition of objects from their visual images is a key function of the primate brain. This recognition is not a template matching between the input image and stored images like the vision in lower animals but is a flexible process in which considerable change in images, resulting from different illumination, viewing angle, and articulation of the object, can be tolerated. Recent experimental findings about the representation of object images in the inferotemporal cortex, a brain structure that is thought to be essential for object vision, are summarized and discussed in relation to the computational frames proposed for object recognition."
            },
            "slug": "Neuronal-mechanisms-of-object-recognition.-Tanaka",
            "title": {
                "fragments": [],
                "text": "Neuronal mechanisms of object recognition."
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "Recent experimental findings about the representation of object images in the inferotemporal cortex, a brain structure that is thought to be essential for object vision, are summarized and discussed in relation to the computational frames proposed for object recognition."
            },
            "venue": {
                "fragments": [],
                "text": "Science"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1708655"
                        ],
                        "name": "B. Olshausen",
                        "slug": "B.-Olshausen",
                        "structuredName": {
                            "firstName": "Bruno",
                            "lastName": "Olshausen",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Olshausen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49649079"
                        ],
                        "name": "D. Field",
                        "slug": "D.-Field",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Field",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Field"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "or from faithful reconstruction of the input using sparse encodin"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 4358477,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8012c4a1e2ca663f1a04e80cbb19631a00cbab27",
            "isKey": false,
            "numCitedBy": 5639,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "THE receptive fields of simple cells in mammalian primary visual cortex can be characterized as being spatially localized, oriented1\u20134 and bandpass (selective to structure at different spatial scales), comparable to the basis functions of wavelet transforms5,6. One approach to understanding such response properties of visual neurons has been to consider their relationship to the statistical structure of natural images in terms of efficient coding7\u201312. Along these lines, a number of studies have attempted to train unsupervised learning algorithms on natural images in the hope of developing receptive fields with similar properties13\u201318, but none has succeeded in producing a full set that spans the image space and contains all three of the above properties. Here we investigate the proposal8,12 that a coding strategy that maximizes sparseness is sufficient to account for these properties. We show that a learning algorithm that attempts to find sparse linear codes for natural scenes will develop a complete family of localized, oriented, bandpass receptive fields, similar to those found in the primary visual cortex. The resulting sparse image code provides a more efficient representation for later stages of processing because it possesses a higher degree of statistical independence among its outputs."
            },
            "slug": "Emergence-of-simple-cell-receptive-field-properties-Olshausen-Field",
            "title": {
                "fragments": [],
                "text": "Emergence of simple-cell receptive field properties by learning a sparse code for natural images"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "It is shown that a learning algorithm that attempts to find sparse linear codes for natural scenes will develop a complete family of localized, oriented, bandpass receptive fields, similar to those found in the primary visual cortex."
            },
            "venue": {
                "fragments": [],
                "text": "Nature"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2361681"
                        ],
                        "name": "W. Vinje",
                        "slug": "W.-Vinje",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Vinje",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Vinje"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40373111"
                        ],
                        "name": "J. Gallant",
                        "slug": "J.-Gallant",
                        "structuredName": {
                            "firstName": "Jack",
                            "lastName": "Gallant",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Gallant"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "or from faithful reconstruction of the input using sparse encodin"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 13307465,
            "fieldsOfStudy": [
                "Biology",
                "Psychology"
            ],
            "id": "409243d8e00d82754933020346c59eae72cf6371",
            "isKey": false,
            "numCitedBy": 1210,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": "Theoretical studies suggest that primary visual cortex (area V1) uses a sparse code to efficiently represent natural scenes. This issue was investigated by recording from V1 neurons in awake behaving macaques during both free viewing of natural scenes and conditions simulating natural vision. Stimulation of the nonclassical receptive field increases the selectivity and sparseness of individual V1 neurons, increases the sparseness of the population response distribution, and strongly decorrelates the responses of neuron pairs. These effects are due to both excitatory and suppressive modulation of the classical receptive field by the nonclassical receptive field and do not depend critically on the spatiotemporal structure of the stimuli. During natural vision, the classical and nonclassical receptive fields function together to form a sparse representation of the visual world. This sparse code may be computationally efficient for both early vision and higher visual processing."
            },
            "slug": "Sparse-coding-and-decorrelation-in-primary-visual-Vinje-Gallant",
            "title": {
                "fragments": [],
                "text": "Sparse coding and decorrelation in primary visual cortex during natural vision."
            },
            "tldr": {
                "abstractSimilarityScore": 99,
                "text": "Theoretical studies suggest that primary visual cortex (area V1) uses a sparse code to efficiently represent natural scenes, but this issue was investigated by recording from V1 neurons in awake behaving macaques during both free viewing of natural scenes and conditions simulating natural vision."
            },
            "venue": {
                "fragments": [],
                "text": "Science"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2281877"
                        ],
                        "name": "J. Atick",
                        "slug": "J.-Atick",
                        "structuredName": {
                            "firstName": "Joseph",
                            "lastName": "Atick",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Atick"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144513847"
                        ],
                        "name": "A. Redlich",
                        "slug": "A.-Redlich",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Redlich",
                            "middleNames": [
                                "Norman"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Redlich"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "This encoding can arise from the computational principles of decorrelation and redundancy reductio"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 17515861,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "841cd4a6cac86fa0cfb0e8542eac5ed164f23f50",
            "isKey": false,
            "numCitedBy": 711,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "By examining the experimental data on the statistical properties of natural scenes together with (retinal) contrast sensitivity data, we arrive at a first principle, theoretical hypothesis for the purpose of retinal processing and its relationship to an animal's environment. We argue that the retinal goal is to transform the visual input as much as possible into a statistically independent basis as the first step in creating a redundancy reduced representation in the cortex, as suggested by Barlow. The extent of this whitening of the input is limited, however, by the need to suppress input noise. Our explicit theoretical solutions for the retinal filters also show a simple dependence on mean stimulus luminance: they predict an approximate Weber law at low spatial frequencies and a De Vries-Rose law at high frequencies. Assuming that the dominant source of noise is quantum, we generate a family of contrast sensitivity curves as a function of mean luminance. This family is compared to psychophysical data."
            },
            "slug": "What-Does-the-Retina-Know-about-Natural-Scenes-Atick-Redlich",
            "title": {
                "fragments": [],
                "text": "What Does the Retina Know about Natural Scenes?"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "It is argued that the retinal goal is to transform the visual input as much as possible into a statistically independent basis as the first step in creating a redundancy reduced representation in the cortex, as suggested by Barlow."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "5737624"
                        ],
                        "name": "E. Rosch",
                        "slug": "E.-Rosch",
                        "structuredName": {
                            "firstName": "Eleanor",
                            "lastName": "Rosch",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Rosch"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3050353"
                        ],
                        "name": "C. Mervis",
                        "slug": "C.-Mervis",
                        "structuredName": {
                            "firstName": "Carolyn",
                            "lastName": "Mervis",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Mervis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2926253"
                        ],
                        "name": "Wayne D. Gray",
                        "slug": "Wayne-D.-Gray",
                        "structuredName": {
                            "firstName": "Wayne",
                            "lastName": "Gray",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wayne D. Gray"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50156221"
                        ],
                        "name": "D. M. Johnson",
                        "slug": "D.-M.-Johnson",
                        "structuredName": {
                            "firstName": "D",
                            "lastName": "Johnson",
                            "middleNames": [
                                "M"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. M. Johnson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1405696055"
                        ],
                        "name": "P. Boyes-Braem",
                        "slug": "P.-Boyes-Braem",
                        "structuredName": {
                            "firstName": "Penny",
                            "lastName": "Boyes-Braem",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Boyes-Braem"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "The main difficulty in classification arises from the variability in shape within a natural class of object"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5612467,
            "fieldsOfStudy": [
                "Philosophy"
            ],
            "id": "2c05d131576d01668ef01156ac73e52c3152384a",
            "isKey": false,
            "numCitedBy": 4978,
            "numCiting": 58,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Basic-objects-in-natural-categories-Rosch-Mervis",
            "title": {
                "fragments": [],
                "text": "Basic objects in natural categories"
            },
            "venue": {
                "fragments": [],
                "text": "Cognitive Psychology"
            },
            "year": 1976
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39409429"
                        ],
                        "name": "R. L. Valois",
                        "slug": "R.-L.-Valois",
                        "structuredName": {
                            "firstName": "Russell",
                            "lastName": "Valois",
                            "middleNames": [
                                "L.",
                                "de"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. L. Valois"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2129244"
                        ],
                        "name": "D. G. Albrecht",
                        "slug": "D.-G.-Albrecht",
                        "structuredName": {
                            "firstName": "Duane",
                            "lastName": "Albrecht",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. G. Albrecht"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40471674"
                        ],
                        "name": "Lisa G. Thorell",
                        "slug": "Lisa-G.-Thorell",
                        "structuredName": {
                            "firstName": "Lisa",
                            "lastName": "Thorell",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lisa G. Thorell"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": ", and it has been suggested that the mammalian visual system also performs multi-resolution processing using multiple receptive field size"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 16496844,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "e2f74bec30cc4e471919de4dfd27c45dbc7b4b9d",
            "isKey": false,
            "numCitedBy": 1118,
            "numCiting": 53,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Spatial-frequency-selectivity-of-cells-in-macaque-Valois-Albrecht",
            "title": {
                "fragments": [],
                "text": "Spatial frequency selectivity of cells in macaque visual cortex"
            },
            "venue": {
                "fragments": [],
                "text": "Vision Research"
            },
            "year": 1982
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40373111"
                        ],
                        "name": "J. Gallant",
                        "slug": "J.-Gallant",
                        "structuredName": {
                            "firstName": "Jack",
                            "lastName": "Gallant",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Gallant"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49965880"
                        ],
                        "name": "J. Braun",
                        "slug": "J.-Braun",
                        "structuredName": {
                            "firstName": "Jochen",
                            "lastName": "Braun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Braun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7549580"
                        ],
                        "name": "D. V. Van Essen",
                        "slug": "D.-V.-Van-Essen",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Van Essen",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. V. Van Essen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8304057,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "b9de10eae4dc0054e76abf46e5c3c482db38174b",
            "isKey": false,
            "numCitedBy": 559,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": "The neural basis of pattern recognition is a central problem in visual neuroscience. Responses of single cells were recorded in area V4 of macaque monkey to three classes of periodic stimuli that are based on spatial derivative operators: polar (concentric and radial), hyperbolic, and conventional sinusoidal (Cartesian) gratings. Of 118 cells tested, 16 percent responded significantly more to polar or hyperbolic (non-Cartesian) gratings than to Cartesian gratings and only 8 percent showed a significant preference for Cartesian gratings. Among cells selective for non-Cartesian gratings, those that preferred concentric gratings were most common. Cells selective for non-Cartesian gratings may constitute an important intermediate stage in pattern recognition and the representation of surface shape."
            },
            "slug": "Selectivity-for-polar,-hyperbolic,-and-Cartesian-in-Gallant-Braun",
            "title": {
                "fragments": [],
                "text": "Selectivity for polar, hyperbolic, and Cartesian gratings in macaque visual cortex."
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "Cell selective for non-Cartesian gratings may constitute an important intermediate stage in pattern recognition and the representation of surface shape in macaque monkey pattern recognition."
            },
            "venue": {
                "fragments": [],
                "text": "Science"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144097660"
                        ],
                        "name": "M. Turk",
                        "slug": "M.-Turk",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Turk",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Turk"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144994682"
                        ],
                        "name": "A. Pentland",
                        "slug": "A.-Pentland",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Pentland",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Pentland"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "The optimal fragments we found are considerably more complex than V1-like receptive fields, but still correspond to local image structures rather than to the global shape templates that are used in some current visual recognition model"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 26127529,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a6f1dfcc44277d4cfd8507284d994c9283dc3a2f",
            "isKey": false,
            "numCitedBy": 14954,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "We have developed a near-real-time computer system that can locate and track a subject's head, and then recognize the person by comparing characteristics of the face to those of known individuals. The computational approach taken in this system is motivated by both physiology and information theory, as well as by the practical requirements of near-real-time performance and accuracy. Our approach treats the face recognition problem as an intrinsically two-dimensional (2-D) recognition problem rather than requiring recovery of three-dimensional geometry, taking advantage of the fact that faces are normally upright and thus may be described by a small set of 2-D characteristic views. The system functions by projecting face images onto a feature space that spans the significant variations among known face images. The significant features are known as \"eigenfaces,\" because they are the eigenvectors (principal components) of the set of faces; they do not necessarily correspond to features such as eyes, ears, and noses. The projection operation characterizes an individual face by a weighted sum of the eigenface features, and so to recognize a particular face it is necessary only to compare these weights to those of known individuals. Some particular advantages of our approach are that it provides for the ability to learn and later recognize new faces in an unsupervised manner, and that it is easy to implement using a neural network architecture."
            },
            "slug": "Eigenfaces-for-Recognition-Turk-Pentland",
            "title": {
                "fragments": [],
                "text": "Eigenfaces for Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 82,
                "text": "A near-real-time computer system that can locate and track a subject's head, and then recognize the person by comparing characteristics of the face to those of known individuals, and that is easy to implement using a neural network architecture."
            },
            "venue": {
                "fragments": [],
                "text": "Journal of Cognitive Neuroscience"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3082093"
                        ],
                        "name": "M. Tarr",
                        "slug": "M.-Tarr",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Tarr",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Tarr"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2423436"
                        ],
                        "name": "Q. Vuong",
                        "slug": "Q.-Vuong",
                        "structuredName": {
                            "firstName": "Quoc",
                            "lastName": "Vuong",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Q. Vuong"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5427717,
            "fieldsOfStudy": [
                "Art"
            ],
            "id": "f8b8b4204a87c263e71e571e411894b0f17e296e",
            "isKey": false,
            "numCitedBy": 693,
            "numCiting": 85,
            "paperAbstract": {
                "fragments": [],
                "text": "Object recognition concerns itself with two questions: What is the form of object representation? and How do observers match object percepts to object representations? Many objects look similar and most contain no single feature that uniquely identifies them. Furthermore, objects are rarely seen under identical viewing conditions: Objects change their size, position, orientation, and relations between parts, viewers move about, and sources of illumination turn on and off or move. Successful object recognition requires generalizing across such changes. Two different approaches to these issues have been adopted. Viewpoint-invariant theories assume that there are specific invariant cues to object identity that may be recovered under almost all viewing conditions. Viewpoint-dependent theories suggest that no such general invariants exist and that object features are represented much as they appeared when originally viewed, thereby preserving shape information and surface appearance. Despite many differences, theories of object recognition include some common principles. These include the decomposition of an image into component features, the coding of the spatial relations between such features, multiple views to represent feature sets arising from different object viewpoints, generalization mechanisms to normalize over changes in viewing conditions, and the flexibility to support recognition tasks ranging from item-specific individuation to basic-level categorization. \n \n \nKeywords: \n \nframes of reference; \nimage normalization; \nimage-based models; \nstructural description models; \nviewpoint-dependent recognition; \nviewpoint-invariant recognition"
            },
            "slug": "Visual-object-recognition-Tarr-Vuong",
            "title": {
                "fragments": [],
                "text": "Visual Object Recognition"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3136431"
                        ],
                        "name": "D. Bhat",
                        "slug": "D.-Bhat",
                        "structuredName": {
                            "firstName": "Dinkar",
                            "lastName": "Bhat",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Bhat"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1750470"
                        ],
                        "name": "S. Nayar",
                        "slug": "S.-Nayar",
                        "structuredName": {
                            "firstName": "Shree",
                            "lastName": "Nayar",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Nayar"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "We also tested normalized cross-correlation and the ordinal measure (in ref"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1930147,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "a4312c7886c88cfae3bb8af9d75c2f91d700e466",
            "isKey": false,
            "numCitedBy": 387,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "We present ordinal measures of association for image correspondence in the context of stereo. Linear correspondence measures like correlation and the sum of squared difference between intensity distributions are known to be fragile. Ordinal measures which are based on relative ordering of intensity values in windows-rank permutations-have demonstrable robustness. By using distance metrics between two rank permutations, ordinal measures are defined. These measures are independent of absolute intensity scale and invariant to monotone transformations of intensity values like gamma variation between images. We have developed simple algorithms for their efficient implementation. Experiments suggest the superiority of ordinal measures over existing techniques under nonideal conditions. These measures serve as a general tool for image matching that are applicable to other vision problems such as motion estimation and texture-based image retrieval."
            },
            "slug": "Ordinal-Measures-for-Image-Correspondence-Bhat-Nayar",
            "title": {
                "fragments": [],
                "text": "Ordinal Measures for Image Correspondence"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "These measures serve as a general tool for image matching that are applicable to other vision problems such as motion estimation and texture-based image retrieval and suggest the superiority of ordinal measures over existing techniques under nonideal conditions."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38690369"
                        ],
                        "name": "R. Vogels",
                        "slug": "R.-Vogels",
                        "structuredName": {
                            "firstName": "Rufin",
                            "lastName": "Vogels",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Vogels"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 41369186,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "f2452a7800d8b702a90e1d7d00f50bfcf2059fa6",
            "isKey": false,
            "numCitedBy": 40,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "Imaging studies compared activations elicited by images of objects and scrambled versions of these same images in order to localize human brain regions involved in object recognition. Given these studies and the known role of macaque temporal cortex in object recognition, I determined the effect of image scrambling on the responses of macaque inferior temporal neurons. Images of natural objects were scrambled to different degrees. The response of most neurons decreased with increasing degrees of scrambling. In 26% of the neurons, response was reduced by 50% when the image was scrambled using only four parts, but most neurons tolerated higher degrees of scrambling, suggesting that these neurons code object parts instead of entire objects. These results are related to human functional imaging studies."
            },
            "slug": "Effect-of-image-scrambling-on-inferior-temporal-Vogels",
            "title": {
                "fragments": [],
                "text": "Effect of image scrambling on inferior temporal cortical responses."
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The effect of image scrambling on the responses of macaque inferior temporal neurons was determined, suggesting that these neurons code object parts instead of entire objects."
            },
            "venue": {
                "fragments": [],
                "text": "Neuroreport"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1715634"
                        ],
                        "name": "Ming-Hsuan Yang",
                        "slug": "Ming-Hsuan-Yang",
                        "structuredName": {
                            "firstName": "Ming-Hsuan",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ming-Hsuan Yang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1765887"
                        ],
                        "name": "D. Kriegman",
                        "slug": "D.-Kriegman",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Kriegman",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Kriegman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145237406"
                        ],
                        "name": "N. Ahuja",
                        "slug": "N.-Ahuja",
                        "structuredName": {
                            "firstName": "Narendra",
                            "lastName": "Ahuja",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Ahuja"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "1% false detection, showing that a biologically plausible combination of informative features is competitive with current classification system"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 9045232,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ebb34b75982f628f9ce5995821fff81fd967dc2d",
            "isKey": false,
            "numCitedBy": 3968,
            "numCiting": 251,
            "paperAbstract": {
                "fragments": [],
                "text": "Images containing faces are essential to intelligent vision-based human-computer interaction, and research efforts in face processing include face recognition, face tracking, pose estimation and expression recognition. However, many reported methods assume that the faces in an image or an image sequence have been identified and localized. To build fully automated systems that analyze the information contained in face images, robust and efficient face detection algorithms are required. Given a single image, the goal of face detection is to identify all image regions which contain a face, regardless of its 3D position, orientation and lighting conditions. Such a problem is challenging because faces are non-rigid and have a high degree of variability in size, shape, color and texture. Numerous techniques have been developed to detect faces in a single image, and the purpose of this paper is to categorize and evaluate these algorithms. We also discuss relevant issues such as data collection, evaluation metrics and benchmarking. After analyzing these algorithms and identifying their limitations, we conclude with several promising directions for future research."
            },
            "slug": "Detecting-Faces-in-Images:-A-Survey-Yang-Kriegman",
            "title": {
                "fragments": [],
                "text": "Detecting Faces in Images: A Survey"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2115651440"
                        ],
                        "name": "Daniel D. Lee",
                        "slug": "Daniel-D.-Lee",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Lee",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Daniel D. Lee"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144924970"
                        ],
                        "name": "H. Seung",
                        "slug": "H.-Seung",
                        "structuredName": {
                            "firstName": "H.",
                            "lastName": "Seung",
                            "middleNames": [
                                "Sebastian"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Seung"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "The features were selected by this procedure to support generalization and classification rather than economic reconstruction of the imag"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 4428232,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "29bae9472203546847ec1352a604566d0f602728",
            "isKey": false,
            "numCitedBy": 11308,
            "numCiting": 47,
            "paperAbstract": {
                "fragments": [],
                "text": "Is perception of the whole based on perception of its parts? There is psychological and physiological evidence for parts-based representations in the brain, and certain computational theories of object recognition rely on such representations. But little is known about how brains or computers might learn the parts of objects. Here we demonstrate an algorithm for non-negative matrix factorization that is able to learn parts of faces and semantic features of text. This is in contrast to other methods, such as principal components analysis and vector quantization, that learn holistic, not parts-based, representations. Non-negative matrix factorization is distinguished from the other methods by its use of non-negativity constraints. These constraints lead to a parts-based representation because they allow only additive, not subtractive, combinations. When non-negative matrix factorization is implemented as a neural network, parts-based representations emerge by virtue of two properties: the firing rates of neurons are never negative and synaptic strengths do not change sign."
            },
            "slug": "Learning-the-parts-of-objects-by-non-negative-Lee-Seung",
            "title": {
                "fragments": [],
                "text": "Learning the parts of objects by non-negative matrix factorization"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "An algorithm for non-negative matrix factorization is demonstrated that is able to learn parts of faces and semantic features of text and is in contrast to other methods that learn holistic, not parts-based, representations."
            },
            "venue": {
                "fragments": [],
                "text": "Nature"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1767767"
                        ],
                        "name": "P. Belhumeur",
                        "slug": "P.-Belhumeur",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Belhumeur",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Belhumeur"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685300"
                        ],
                        "name": "J. Hespanha",
                        "slug": "J.-Hespanha",
                        "structuredName": {
                            "firstName": "Jo\u00e3o",
                            "lastName": "Hespanha",
                            "middleNames": [
                                "Pedro"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Hespanha"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1765887"
                        ],
                        "name": "D. Kriegman",
                        "slug": "D.-Kriegman",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Kriegman",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Kriegman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 30582,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "be86da00efdd8c2a7fdeb2334605796c24b370f0",
            "isKey": false,
            "numCitedBy": 11721,
            "numCiting": 46,
            "paperAbstract": {
                "fragments": [],
                "text": "We develop a face recognition algorithm which is insensitive to large variation in lighting direction and facial expression. Taking a pattern classification approach, we consider each pixel in an image as a coordinate in a high-dimensional space. We take advantage of the observation that the images of a particular face, under varying illumination but fixed pose, lie in a 3D linear subspace of the high dimensional image space-if the face is a Lambertian surface without shadowing. However, since faces are not truly Lambertian surfaces and do indeed produce self-shadowing, images will deviate from this linear subspace. Rather than explicitly modeling this deviation, we linearly project the image into a subspace in a manner which discounts those regions of the face with large deviation. Our projection method is based on Fisher's linear discriminant and produces well separated classes in a low-dimensional subspace, even under severe variation in lighting and facial expressions. The eigenface technique, another method based on linearly projecting the image space to a low dimensional subspace, has similar computational requirements. Yet, extensive experimental results demonstrate that the proposed \"Fisherface\" method has error rates that are lower than those of the eigenface technique for tests on the Harvard and Yale face databases."
            },
            "slug": "Eigenfaces-vs.-Fisherfaces:-Recognition-Using-Class-Belhumeur-Hespanha",
            "title": {
                "fragments": [],
                "text": "Eigenfaces vs. Fisherfaces: Recognition Using Class Specific Linear Projection"
            },
            "tldr": {
                "abstractSimilarityScore": 65,
                "text": "A face recognition algorithm which is insensitive to large variation in lighting direction and facial expression is developed, based on Fisher's linear discriminant and produces well separated classes in a low-dimensional subspace, even under severe variations in lighting and facial expressions."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47246616"
                        ],
                        "name": "R. Brunelli",
                        "slug": "R.-Brunelli",
                        "structuredName": {
                            "firstName": "Roberto",
                            "lastName": "Brunelli",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Brunelli"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685292"
                        ],
                        "name": "T. Poggio",
                        "slug": "T.-Poggio",
                        "structuredName": {
                            "firstName": "Tomaso",
                            "lastName": "Poggio",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Poggio"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "This could explain why intermediate resolution face templates are computationally useful for face detectio"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 16859093,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "239beb3861ceceb4c7c7f229234d97198d5c7697",
            "isKey": false,
            "numCitedBy": 2828,
            "numCiting": 49,
            "paperAbstract": {
                "fragments": [],
                "text": "Two new algorithms for computer recognition of human faces, one based on the computation of a set of geometrical features, such as nose width and length, mouth position, and chin shape, and the second based on almost-gray-level template matching, are presented. The results obtained for the testing sets show about 90% correct recognition using geometrical features and perfect recognition using template matching. >"
            },
            "slug": "Face-Recognition:-Features-Versus-Templates-Brunelli-Poggio",
            "title": {
                "fragments": [],
                "text": "Face Recognition: Features Versus Templates"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "Two new algorithms for computer recognition of human faces, one based on the computation of a set of geometrical features, such as nose width and length, mouth position, and chin shape, and the second based on almost-gray-level template matching are presented."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1736245"
                        ],
                        "name": "Laurenz Wiskott",
                        "slug": "Laurenz-Wiskott",
                        "structuredName": {
                            "firstName": "Laurenz",
                            "lastName": "Wiskott",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Laurenz Wiskott"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145893752"
                        ],
                        "name": "J. Fellous",
                        "slug": "J.-Fellous",
                        "structuredName": {
                            "firstName": "Jean-Marc",
                            "lastName": "Fellous",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Fellous"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1721722"
                        ],
                        "name": "N. Kr\u00fcger",
                        "slug": "N.-Kr\u00fcger",
                        "structuredName": {
                            "firstName": "Norbert",
                            "lastName": "Kr\u00fcger",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Kr\u00fcger"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1704573"
                        ],
                        "name": "C. Malsburg",
                        "slug": "C.-Malsburg",
                        "structuredName": {
                            "firstName": "Christoph",
                            "lastName": "Malsburg",
                            "middleNames": [
                                "von",
                                "der"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Malsburg"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 10223132,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5c27487c3e0894b65e976a287e6f8c9aa40f089c",
            "isKey": false,
            "numCitedBy": 2132,
            "numCiting": 89,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a system for recognizing human faces from single images out of a large database containing one image per person. Faces are represented by labeled graphs, based on a Gabor wavelet transform. Image graphs of new faces are extracted by an elastic graph matching process and can be compared by a simple similarity function. The system differs from Lades et al. (1993) in three respects. Phase information is used for accurate node positioning. Object-adapted graphs are used to handle large rotations in depth. Image graph extraction is based on a novel data structure, the bunch graph, which is constructed from a small set of sample image graphs."
            },
            "slug": "Face-recognition-by-elastic-bunch-graph-matching-Wiskott-Fellous",
            "title": {
                "fragments": [],
                "text": "Face recognition by elastic bunch graph matching"
            },
            "tldr": {
                "abstractSimilarityScore": 74,
                "text": "A system for recognizing human faces from single images out of a large database containing one image per person, based on a Gabor wavelet transform, which differs from Lades et al. (1993) in three respects."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of International Conference on Image Processing"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143766793"
                        ],
                        "name": "A. Rosenfeld",
                        "slug": "A.-Rosenfeld",
                        "structuredName": {
                            "firstName": "Azriel",
                            "lastName": "Rosenfeld",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Rosenfeld"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 441278,
            "fieldsOfStudy": [
                "Computer Science",
                "Art"
            ],
            "id": "b441dd8fb25eddbaf92bc9938afda69627a281ab",
            "isKey": false,
            "numCitedBy": 3876,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Computer-Vision-Rosenfeld",
            "title": {
                "fragments": [],
                "text": "Computer Vision"
            },
            "venue": {
                "fragments": [],
                "text": "Adv. Comput."
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144663088"
                        ],
                        "name": "E. Rolls",
                        "slug": "E.-Rolls",
                        "structuredName": {
                            "firstName": "Edmund",
                            "lastName": "Rolls",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Rolls"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 44977576,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "d2d33a806f1982fc522566f8b2bf1f06c66b73e1",
            "isKey": false,
            "numCitedBy": 121,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Neural-organization-of-higher-visual-functions-Rolls",
            "title": {
                "fragments": [],
                "text": "Neural organization of higher visual functions"
            },
            "venue": {
                "fragments": [],
                "text": "Current Opinion in Neurobiology"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50785579"
                        ],
                        "name": "N. Friedman",
                        "slug": "N.-Friedman",
                        "structuredName": {
                            "firstName": "Nir",
                            "lastName": "Friedman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Friedman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144527211"
                        ],
                        "name": "D. Geiger",
                        "slug": "D.-Geiger",
                        "structuredName": {
                            "firstName": "Dan",
                            "lastName": "Geiger",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Geiger"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1770007"
                        ],
                        "name": "M. Goldszmidt",
                        "slug": "M.-Goldszmidt",
                        "structuredName": {
                            "firstName": "Mois\u00e9s",
                            "lastName": "Goldszmidt",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Goldszmidt"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "This combination rule assumes conditional independence between fragments given the class variable, and often gives good result"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 930676,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c76ac0a39577760d4aaf6fce98327543ec64a560",
            "isKey": false,
            "numCitedBy": 4537,
            "numCiting": 61,
            "paperAbstract": {
                "fragments": [],
                "text": "Recent work in supervised learning has shown that a surprisingly simple Bayesian classifier with strong assumptions of independence among features, called naive Bayes, is competitive with state-of-the-art classifiers such as C4.5. This fact raises the question of whether a classifier with less restrictive assumptions can perform even better. In this paper we evaluate approaches for inducing classifiers from data, based on the theory of learning Bayesian networks. These networks are factored representations of probability distributions that generalize the naive Bayesian classifier and explicitly represent statements about independence. Among these approaches we single out a method we call Tree Augmented Naive Bayes (TAN), which outperforms naive Bayes, yet at the same time maintains the computational simplicity (no search involved) and robustness that characterize naive Bayes. We experimentally tested these approaches, using problems from the University of California at Irvine repository, and compared them to C4.5, naive Bayes, and wrapper methods for feature selection."
            },
            "slug": "Bayesian-Network-Classifiers-Friedman-Geiger",
            "title": {
                "fragments": [],
                "text": "Bayesian Network Classifiers"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "Tree Augmented Naive Bayes (TAN) is single out, which outperforms naive Bayes, yet at the same time maintains the computational simplicity and robustness that characterize naive Baye."
            },
            "venue": {
                "fragments": [],
                "text": "Machine Learning"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144187514"
                        ],
                        "name": "R. Durbin",
                        "slug": "R.-Durbin",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Durbin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Durbin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7912930"
                        ],
                        "name": "C. Miall",
                        "slug": "C.-Miall",
                        "structuredName": {
                            "firstName": "Chris",
                            "lastName": "Miall",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Miall"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145666307"
                        ],
                        "name": "G. Mitchison",
                        "slug": "G.-Mitchison",
                        "structuredName": {
                            "firstName": "Graeme",
                            "lastName": "Mitchison",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Mitchison"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 61649254,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c6e32b4f82c2a1833ef7ae32967ce2f3685fa1c5",
            "isKey": false,
            "numCitedBy": 289,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "The-computing-neuron-Durbin-Miall",
            "title": {
                "fragments": [],
                "text": "The computing neuron"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2102692030"
                        ],
                        "name": "RussLL L. Ds Vnlos",
                        "slug": "RussLL-L.-Ds-Vnlos",
                        "structuredName": {
                            "firstName": "RussLL",
                            "lastName": "Vnlos",
                            "middleNames": [
                                "L.",
                                "Ds"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "RussLL L. Ds Vnlos"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2081557442"
                        ],
                        "name": "Duaxs G. ALSREcHT",
                        "slug": "Duaxs-G.-ALSREcHT",
                        "structuredName": {
                            "firstName": "Duaxs",
                            "lastName": "ALSREcHT",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Duaxs G. ALSREcHT"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2103028334"
                        ],
                        "name": "Lrse G. Tsonrll",
                        "slug": "Lrse-G.-Tsonrll",
                        "structuredName": {
                            "firstName": "Lrse",
                            "lastName": "Tsonrll",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lrse G. Tsonrll"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 9306470,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "d54f243c31a5797b059c945fec65502e47d5e879",
            "isKey": false,
            "numCitedBy": 701,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "SPATIAL-FREQUENCY-SELECTIVITY-OF-CELLS-IN-MACAQUE-Vnlos-ALSREcHT",
            "title": {
                "fragments": [],
                "text": "SPATIAL FREQUENCY SELECTIVITY OF CELLS IN MACAQUE VISUAL CORTEX"
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "N  at  u  re  P  u  b  lis  h  in  g  G  ro  u  p  h  tt  p  :"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1997
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 7,
            "methodology": 7
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 30,
        "totalPages": 3
    },
    "page_url": "https://www.semanticscholar.org/paper/Visual-features-of-intermediate-complexity-and-use-Ullman-Vidal-Naquet/d52be22dc0033293d335b6dc5cf3e3588c1fc0bc?sort=total-citations"
}