{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1784196"
                        ],
                        "name": "Datong Chen",
                        "slug": "Datong-Chen",
                        "structuredName": {
                            "firstName": "Datong",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Datong Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1719610"
                        ],
                        "name": "J. Odobez",
                        "slug": "J.-Odobez",
                        "structuredName": {
                            "firstName": "Jean-Marc",
                            "lastName": "Odobez",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Odobez"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733733"
                        ],
                        "name": "H. Bourlard",
                        "slug": "H.-Bourlard",
                        "structuredName": {
                            "firstName": "Herv\u00e9",
                            "lastName": "Bourlard",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Bourlard"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 46,
                                "start": 42
                            }
                        ],
                        "text": "Text classification, or text verification [14], is often cast as a texture classification problem, and several texture descriptors have been considered in the literature."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 11796155,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "42a8ff86566538103c6116f9047a4c3128e1542c",
            "isKey": false,
            "numCitedBy": 303,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Text-detection,-recognition-in-images-and-video-Chen-Odobez",
            "title": {
                "fragments": [],
                "text": "Text detection, recognition in images and video frames"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit."
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46772671"
                        ],
                        "name": "Xiangrong Chen",
                        "slug": "Xiangrong-Chen",
                        "structuredName": {
                            "firstName": "Xiangrong",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xiangrong Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145081362"
                        ],
                        "name": "A. Yuille",
                        "slug": "A.-Yuille",
                        "structuredName": {
                            "firstName": "Alan",
                            "lastName": "Yuille",
                            "middleNames": [
                                "Loddon"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Yuille"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 28,
                                "start": 25
                            }
                        ],
                        "text": "In 2004, Chen and Yuille [7] proposed a descriptor that combin es several features, including 2D histograms of image intensity and gradient, computed separ ately for the top, middle, and bottom of the text region, as well as for more complex subdivisions o f the image\u201489 features in total."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 84,
                                "start": 69
                            }
                        ],
                        "text": "They partition the candidate\nsub-image into 14 cells, as proposed by Chen and Yuille, but compute for each cell a 4-bin HOG complemented by a2\u00d7 3 array of LBP features."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 28,
                                "start": 25
                            }
                        ],
                        "text": "In 2004, Chen and Yuille [7] observed that different parts of t he ext regions have distinctive distributions of edge directions."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 24,
                                "start": 9
                            }
                        ],
                        "text": "In 2004, Chen and Yuille [7] observed that different parts of the ext regions have distinctive\ndistributions of edge directions."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 24,
                                "start": 9
                            }
                        ],
                        "text": "In 2004, Chen and Yuille [7] proposed a descriptor that combines several features, including 2D\nhistograms of image intensity and gradient, computed separately for the top, middle, and bottom of the text region, as well as for more complex subdivisions of the image\u201489 features in total."
                    },
                    "intents": []
                }
            ],
            "corpusId": 61234963,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "37ba7b9a823e8a400046bd149b7756adf5d698da",
            "isKey": true,
            "numCitedBy": 512,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper gives an algorithm for detecting and reading text in natural images. The algorithm is intended for use by blind and visually impaired subjects walking through city scenes. We first obtain a dataset of city images taken by blind and normally sighted subjects. From this dataset, we manually label and extract the text regions. Next we perform statistical analysis of the text regions to determine which image features are reliable indicators of text and have low entropy (i.e. feature response is similar for all text images). We obtain weak classifiers by using joint probabilities for feature responses on and off text. These weak classifiers are used as input to an AdaBoost machine learning algorithm to train a strong classifier. In practice, we trained a cascade with 4 strong classifiers containing 79 features. An adaptive binarization and extension algorithm is applied to those regions selected by the cascade classifier. Commercial OCR software is used to read the text or reject it as a non-text region. The overall algorithm has a success rate of over 90% (evaluated by complete detection and reading of the text) on the test set and the unread text is typically small and distant from the viewer."
            },
            "slug": "Detecting-and-reading-text-in-natural-scenes-Chen-Yuille",
            "title": {
                "fragments": [],
                "text": "Detecting and reading text in natural scenes"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "The overall algorithm has a success rate of over 90% (evaluated by complete detection and reading of the text) on the test set and the unread text is typically small and distant from the viewer."
            },
            "venue": {
                "fragments": [],
                "text": "CVPR 2004"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694936"
                        ],
                        "name": "Qixiang Ye",
                        "slug": "Qixiang-Ye",
                        "structuredName": {
                            "firstName": "Qixiang",
                            "lastName": "Ye",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Qixiang Ye"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1689702"
                        ],
                        "name": "Qingming Huang",
                        "slug": "Qingming-Huang",
                        "structuredName": {
                            "firstName": "Qingming",
                            "lastName": "Huang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Qingming Huang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2153706048"
                        ],
                        "name": "W. Gao",
                        "slug": "W.-Gao",
                        "structuredName": {
                            "firstName": "Wen",
                            "lastName": "Gao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Gao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1725937"
                        ],
                        "name": "Debin Zhao",
                        "slug": "Debin-Zhao",
                        "structuredName": {
                            "firstName": "Debin",
                            "lastName": "Zhao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Debin Zhao"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[18] described a similar text recognizer with multiscale wavelet decomposition but they used more el aborate features including moments, energy, entropy, etc."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 17956059,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bcb8cd892adbfded8373716a53787f55da89180a",
            "isKey": false,
            "numCitedBy": 363,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Fast-and-robust-text-detection-in-images-and-video-Ye-Huang",
            "title": {
                "fragments": [],
                "text": "Fast and robust text detection in images and video frames"
            },
            "venue": {
                "fragments": [],
                "text": "Image Vis. Comput."
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40263913"
                        ],
                        "name": "Chucai Yi",
                        "slug": "Chucai-Yi",
                        "structuredName": {
                            "firstName": "Chucai",
                            "lastName": "Yi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chucai Yi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35484757"
                        ],
                        "name": "Yingli Tian",
                        "slug": "Yingli-Tian",
                        "structuredName": {
                            "firstName": "Yingli",
                            "lastName": "Tian",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yingli Tian"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "[31] and Epshtein et al."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "66 Yi and Tian [31] 0."
                    },
                    "intents": []
                }
            ],
            "corpusId": 206724376,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9cb107a5b3b6539a9b9a758d91871f8b2519c79d",
            "isKey": false,
            "numCitedBy": 380,
            "numCiting": 40,
            "paperAbstract": {
                "fragments": [],
                "text": "Text information in natural scene images serves as important clues for many image-based applications such as scene understanding, content-based image retrieval, assistive navigation, and automatic geocoding. However, locating text from a complex background with multiple colors is a challenging task. In this paper, we explore a new framework to detect text strings with arbitrary orientations in complex natural scene images. Our proposed framework of text string detection consists of two steps: 1) image partition to find text character candidates based on local gradient features and color uniformity of character components and 2) character candidate grouping to detect text strings based on joint structural features of text characters in each text string such as character size differences, distances between neighboring characters, and character alignment. By assuming that a text string has at least three characters, we propose two algorithms of text string detection: 1) adjacent character grouping method and 2) text line grouping method. The adjacent character grouping method calculates the sibling groups of each character candidate as string segments and then merges the intersecting sibling groups into text string. The text line grouping method performs Hough transform to fit text line among the centroids of text candidates. Each fitted text line describes the orientation of a potential text string. The detected text string is presented by a rectangle region covering all characters whose centroids are cascaded in its text line. To improve efficiency and accuracy, our algorithms are carried out in multi-scales. The proposed methods outperform the state-of-the-art results on the public Robust Reading Dataset, which contains text only in horizontal orientation. Furthermore, the effectiveness of our methods to detect text strings with arbitrary orientations is evaluated on the Oriented Scene Text Dataset collected by ourselves containing text strings in nonhorizontal orientations."
            },
            "slug": "Text-String-Detection-From-Natural-Scenes-by-and-Yi-Tian",
            "title": {
                "fragments": [],
                "text": "Text String Detection From Natural Scenes by Structure-Based Partition and Grouping"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A new framework to detect text strings with arbitrary orientations in complex natural scene images with outperform the state-of-the-art results on the public Robust Reading Dataset, which contains text only in horizontal orientation."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Image Processing"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1704629"
                        ],
                        "name": "M. Anthimopoulos",
                        "slug": "M.-Anthimopoulos",
                        "structuredName": {
                            "firstName": "Marios",
                            "lastName": "Anthimopoulos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Anthimopoulos"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7232446"
                        ],
                        "name": "B. Gatos",
                        "slug": "B.-Gatos",
                        "structuredName": {
                            "firstName": "Basilios",
                            "lastName": "Gatos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Gatos"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1748249"
                        ],
                        "name": "I. Pratikakis",
                        "slug": "I.-Pratikakis",
                        "structuredName": {
                            "firstName": "Ioannis",
                            "lastName": "Pratikakis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Pratikakis"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 18523324,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "980087708326d4c4411ca2b76a9f2afb3f68238b",
            "isKey": false,
            "numCitedBy": 88,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-two-stage-scheme-for-text-detection-in-video-Anthimopoulos-Gatos",
            "title": {
                "fragments": [],
                "text": "A two-stage scheme for text detection in video images"
            },
            "venue": {
                "fragments": [],
                "text": "Image Vis. Comput."
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145572873"
                        ],
                        "name": "K. C. Kim",
                        "slug": "K.-C.-Kim",
                        "structuredName": {
                            "firstName": "K.",
                            "lastName": "Kim",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. C. Kim"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144036125"
                        ],
                        "name": "H. Byun",
                        "slug": "H.-Byun",
                        "structuredName": {
                            "firstName": "Hyeran",
                            "lastName": "Byun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Byun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2111340535"
                        ],
                        "name": "Y. Song",
                        "slug": "Y.-Song",
                        "structuredName": {
                            "firstName": "Y.",
                            "lastName": "Song",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Song"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2167591743"
                        ],
                        "name": "Young-Woo Choi",
                        "slug": "Young-Woo-Choi",
                        "structuredName": {
                            "firstName": "Young-Woo",
                            "lastName": "Choi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Young-Woo Choi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2066686052"
                        ],
                        "name": "S. Chi",
                        "slug": "S.-Chi",
                        "structuredName": {
                            "firstName": "S.",
                            "lastName": "Chi",
                            "middleNames": [
                                "Y."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Chi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2144368895"
                        ],
                        "name": "K. Kim",
                        "slug": "K.-Kim",
                        "structuredName": {
                            "firstName": "Kye",
                            "lastName": "Kim",
                            "middleNames": [
                                "Kyung"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Kim"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2133127067"
                        ],
                        "name": "Y. Chung",
                        "slug": "Y.-Chung",
                        "structuredName": {
                            "firstName": "YunKoo",
                            "lastName": "Chung",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Chung"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[15] described a text recognizer that decomposes the candidate sub-image into a multiscale 16 16 cell grid and computes wavelet moments for each block."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 45144473,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5b9cc09a70e4ea58efc232ed5f04ff401dfd880d",
            "isKey": false,
            "numCitedBy": 62,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a method that extracts text regions in natural scene images using low-level image features and that verifies the extracted regions through a high-level text stroke feature. Then the two level features are combined hierarchically. The low-level features are color continuity, gray-level variation and color variance. The color continuity is used since most of the characters in a text region have the same color, and the gray-level variation is used since the text strokes are distinctive to the background in their gray-level values. Also, the color variance is used since the text strokes are distinctive in their colors to the background, and this value is more sensitive than the gray-level variations. As a high level feature, text stroke is examined using multi-resolution wavelet transforms on local image areas and the feature vector is input to a SVM (support vector machine) for verification. We tested the proposed method with various kinds of the natural scene images and confirmed that extraction rates are high even in complex images."
            },
            "slug": "Scene-text-extraction-in-natural-scene-images-using-Kim-Byun",
            "title": {
                "fragments": [],
                "text": "Scene text extraction in natural scene images using hierarchical feature combining and verification"
            },
            "tldr": {
                "abstractSimilarityScore": 82,
                "text": "The proposed method that extracts text regions in natural scene images using low-level image features and that verifies the extracted regions through a high-level text stroke feature confirmed that extraction rates are high even in complex images."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 17th International Conference on Pattern Recognition, 2004. ICPR 2004."
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38340927"
                        ],
                        "name": "Yi-Feng Pan",
                        "slug": "Yi-Feng-Pan",
                        "structuredName": {
                            "firstName": "Yi-Feng",
                            "lastName": "Pan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yi-Feng Pan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1761961"
                        ],
                        "name": "Xinwen Hou",
                        "slug": "Xinwen-Hou",
                        "structuredName": {
                            "firstName": "Xinwen",
                            "lastName": "Hou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xinwen Hou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1689269"
                        ],
                        "name": "Cheng-Lin Liu",
                        "slug": "Cheng-Lin-Liu",
                        "structuredName": {
                            "firstName": "Cheng-Lin",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Cheng-Lin Liu"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 120,
                                "start": 110
                            }
                        ],
                        "text": "This property was exploi ted by other researchers who used the R-HOG descriptors to characterize text regions [8, 9, 10]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 10018912,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "751266eaeeacfe73d9cf879e905b17387bae6037",
            "isKey": false,
            "numCitedBy": 93,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we present a robust system to accurately detect and localize texts in natural scene images. For text detection, a region-based method utilizing multiple features and cascade AdaBoost classifier is adopted. For text localization, a window grouping method integrating text line competition analysis is used to generate text lines. Then within each text line, local binarization is used to extract candidate connected components (CCs) and non-text CCs are filtered out by Markov Random Fields (MRF) model, through which text line can be localized accurately. Experiments on the public benchmark ICDAR 2003 Robust Reading and Text Locating Dataset show that our system is comparable to the best existing methods both in accuracy and speed."
            },
            "slug": "A-Robust-System-to-Detect-and-Localize-Texts-in-Pan-Hou",
            "title": {
                "fragments": [],
                "text": "A Robust System to Detect and Localize Texts in Natural Scene Images"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A region-based method utilizing multiple features and cascade AdaBoost classifier is adopted for text detection and a window grouping method integrating text line competition analysis is used to generate text lines."
            },
            "venue": {
                "fragments": [],
                "text": "2008 The Eighth IAPR International Workshop on Document Analysis Systems"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2152526333"
                        ],
                        "name": "Ming Zhao",
                        "slug": "Ming-Zhao",
                        "structuredName": {
                            "firstName": "Ming",
                            "lastName": "Zhao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ming Zhao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2116066317"
                        ],
                        "name": "Shutao Li",
                        "slug": "Shutao-Li",
                        "structuredName": {
                            "firstName": "Shutao",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shutao Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145193332"
                        ],
                        "name": "J. Kwok",
                        "slug": "J.-Kwok",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Kwok",
                            "middleNames": [
                                "Tin-Yau"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Kwok"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[19] used an edge detector based on the wav elet transform, and sparse representation with discriminative dictionaries to distingu ish between text-like and background-like edge patterns."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 18340818,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5f5f802bf01c8632dda4586b05bc86fc4878326f",
            "isKey": false,
            "numCitedBy": 103,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Text-detection-in-images-using-sparse-with-Zhao-Li",
            "title": {
                "fragments": [],
                "text": "Text detection in images using sparse representation with discriminative dictionaries"
            },
            "venue": {
                "fragments": [],
                "text": "Image Vis. Comput."
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48950628"
                        ],
                        "name": "N. Dalal",
                        "slug": "N.-Dalal",
                        "structuredName": {
                            "firstName": "Navneet",
                            "lastName": "Dalal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Dalal"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1756114"
                        ],
                        "name": "B. Triggs",
                        "slug": "B.-Triggs",
                        "structuredName": {
                            "firstName": "Bill",
                            "lastName": "Triggs",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Triggs"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 82,
                                "start": 76
                            }
                        ],
                        "text": "We compare classifiers by plotting the decision error trade-off (DET) curve [4,24], which is the set of pairs \u00f0tb,bb\u00de for bA 1\u20442 1, ."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 119,
                                "start": 116
                            }
                        ],
                        "text": "The use of gradient orientation histograms (HOGs) as texture descriptors was introduced by Dalal and Triggs in 2005 [4] for human recognition."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 179,
                                "start": 176
                            }
                        ],
                        "text": "All the HOG-based text recognizers above use vertical cuts as well as horizontal ones when partitioning the candidate region, apparently inspired by the Dalal and Triggs paper [4] on pedestrian recognition."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 156,
                                "start": 153
                            }
                        ],
                        "text": "Dalal and Triggs found that the recognition of some classes of objects (such as humans) was improved when opposite directions were considered equivalent [4], in which case the range of y\u00f0rI\u00de is 1\u204420,p radians."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 86,
                                "start": 83
                            }
                        ],
                        "text": "The T-HOG descriptor is based on the general histogram of oriented gradients (HOG) [4] method for shape recognition, introduced by Dalal and Triggs for the detection of pedestrians in photographs [4] and later used for other solid objects [5]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 206590483,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cec734d7097ab6b1e60d95228ffd64248eb89d66",
            "isKey": true,
            "numCitedBy": 29259,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "We study the question of feature sets for robust visual object recognition; adopting linear SVM based human detection as a test case. After reviewing existing edge and gradient based descriptors, we show experimentally that grids of histograms of oriented gradient (HOG) descriptors significantly outperform existing feature sets for human detection. We study the influence of each stage of the computation on performance, concluding that fine-scale gradients, fine orientation binning, relatively coarse spatial binning, and high-quality local contrast normalization in overlapping descriptor blocks are all important for good results. The new approach gives near-perfect separation on the original MIT pedestrian database, so we introduce a more challenging dataset containing over 1800 annotated human images with a large range of pose variations and backgrounds."
            },
            "slug": "Histograms-of-oriented-gradients-for-human-Dalal-Triggs",
            "title": {
                "fragments": [],
                "text": "Histograms of oriented gradients for human detection"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "It is shown experimentally that grids of histograms of oriented gradient (HOG) descriptors significantly outperform existing feature sets for human detection, and the influence of each stage of the computation on performance is studied."
            },
            "venue": {
                "fragments": [],
                "text": "2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05)"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2118417872"
                        ],
                        "name": "Xiufei Wang",
                        "slug": "Xiufei-Wang",
                        "structuredName": {
                            "firstName": "Xiufei",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xiufei Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2109137618"
                        ],
                        "name": "Lei Huang",
                        "slug": "Lei-Huang",
                        "structuredName": {
                            "firstName": "Lei",
                            "lastName": "Huang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lei Huang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1800844"
                        ],
                        "name": "Chang-ping Liu",
                        "slug": "Chang-ping-Liu",
                        "structuredName": {
                            "firstName": "Chang-ping",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chang-ping Liu"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 120,
                                "start": 110
                            }
                        ],
                        "text": "This property was exploi ted by other researchers who used the R-HOG descriptors to characterize text regions [8, 9, 10]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[10] for isolated Chinese and Roman characters as well as single-line text."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 26821280,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8de5f6b5fe19609b3592583b2f92f1ee3f146330",
            "isKey": false,
            "numCitedBy": 14,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, a new feature for text verification is proposed. The difficulties for the selection of features for text verification (FTV) are first discussed, followed by two principles for the FTV: the FTV should minimize the influence of backgrounds, and it should also be expressive enough for all the texts varied in structures prominently. In this paper, we exploit different block partition methods and introduce two widely used features: the gray scale contrast (GSC) feature to eliminate the background difference, and the edge orient histogram (EOH) feature to distinguish the structure of texts from that of non-texts. A texture classifier can be got by SVM training of pre-labeled data. The candidate text lines can be verified by this classifier. Experimental results show that our feature performs well."
            },
            "slug": "A-New-Block-Partitioned-Text-Feature-for-Text-Wang-Huang",
            "title": {
                "fragments": [],
                "text": "A New Block Partitioned Text Feature for Text Verification"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This paper exploits different block partition methods and introduces two widely used features: the gray scale contrast (GSC) feature to eliminate the background difference, and the edge orient histogram (EOH) featureto distinguish the structure of texts from that of non-texts."
            },
            "venue": {
                "fragments": [],
                "text": "2009 10th International Conference on Document Analysis and Recognition"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1746772"
                        ],
                        "name": "G. Louloudis",
                        "slug": "G.-Louloudis",
                        "structuredName": {
                            "firstName": "Georgios",
                            "lastName": "Louloudis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Louloudis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7232446"
                        ],
                        "name": "B. Gatos",
                        "slug": "B.-Gatos",
                        "structuredName": {
                            "firstName": "Basilios",
                            "lastName": "Gatos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Gatos"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1748249"
                        ],
                        "name": "I. Pratikakis",
                        "slug": "I.-Pratikakis",
                        "structuredName": {
                            "firstName": "Ioannis",
                            "lastName": "Pratikakis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Pratikakis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1759370"
                        ],
                        "name": "C. Halatsis",
                        "slug": "C.-Halatsis",
                        "structuredName": {
                            "firstName": "Constantin",
                            "lastName": "Halatsis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Halatsis"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 154,
                                "start": 150
                            }
                        ],
                        "text": "There is an extensive literature on text detection, but most of it are dedicated to specific contexts such as text detection in handwritten documents [11], text r cognition in medieval manuscript images [12], and license plate recognition [13, 14]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 43027422,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8804b7e906a3678daa0d2b99d342f4df1c0ea374",
            "isKey": false,
            "numCitedBy": 81,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Text-line-detection-in-handwritten-documents-Louloudis-Gatos",
            "title": {
                "fragments": [],
                "text": "Text line detection in handwritten documents"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit."
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1744575"
                        ],
                        "name": "P. Shivakumara",
                        "slug": "P.-Shivakumara",
                        "structuredName": {
                            "firstName": "Palaiahnakote",
                            "lastName": "Shivakumara",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Shivakumara"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3186240"
                        ],
                        "name": "Weihua Huang",
                        "slug": "Weihua-Huang",
                        "structuredName": {
                            "firstName": "Weihua",
                            "lastName": "Huang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Weihua Huang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1715066"
                        ],
                        "name": "T. Phan",
                        "slug": "T.-Phan",
                        "structuredName": {
                            "firstName": "Trung",
                            "lastName": "Phan",
                            "middleNames": [
                                "Quy"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Phan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1679749"
                        ],
                        "name": "C. Tan",
                        "slug": "C.-Tan",
                        "structuredName": {
                            "firstName": "Chew",
                            "lastName": "Tan",
                            "middleNames": [
                                "Lim"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Tan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[20] u sed 6 different gradient edge features (mean, standard deviation, energy, entropy, inertia and lo cal homogeneity) over image blocks, to capture the texture property of the candidate text region."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 13084689,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "578bfdbc4a5c1a228dedbe8b6b1e95cae56259ec",
            "isKey": false,
            "numCitedBy": 83,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Accurate-video-text-detection-through-of-low-and-Shivakumara-Huang",
            "title": {
                "fragments": [],
                "text": "Accurate video text detection through classification of low and high contrast images"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit."
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3331461"
                        ],
                        "name": "S. Hanif",
                        "slug": "S.-Hanif",
                        "structuredName": {
                            "firstName": "Shehzad",
                            "lastName": "Hanif",
                            "middleNames": [
                                "Muhammad"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Hanif"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2554802"
                        ],
                        "name": "L. Prevost",
                        "slug": "L.-Prevost",
                        "structuredName": {
                            "firstName": "Lionel",
                            "lastName": "Prevost",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Prevost"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 79,
                                "start": 62
                            }
                        ],
                        "text": "Other HOG-based text recognizers have been proposed in 2009by Hanif and Prevost [8] for\nsingle-line text, and by Wang et al. [10] for isolated Chineseand Roman characters as well as single-line text."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 84,
                                "start": 81
                            }
                        ],
                        "text": "Other HOG-based text recognizers have been proposed in 2009 by Hanif and Prevost [8] for single-line text, and by Wang et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 17,
                                "start": 0
                            }
                        ],
                        "text": "Hanif and Prevost\u2019s descriptor has 151 features (16 cells each with an 8-bin HOG, supplemented by 7 mean difference and 16 standard deviationfeatures)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 120,
                                "start": 110
                            }
                        ],
                        "text": "This property was exploi ted by other researchers who used the R-HOG descriptors to characterize text regions [8, 9, 10]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 17474464,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5233651e7c6436ce63d24b8d74a03a34925d09b6",
            "isKey": true,
            "numCitedBy": 113,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "We have proposed a complete system for text detection and localization in gray scale scene images. A boosting framework integrating feature and weak classifier selection based on computational complexity is proposed to construct efficient text detectors. The proposed scheme uses a small set of heterogeneous features which are spatially combined to build a large set of features. A neural network based localizer learns necessary rules for localization. The evaluation is done on the challenging ICDAR 2003 robust reading and text locating database. The results are encouraging and our system can localize text of various font sizes and styles in complex background."
            },
            "slug": "Text-Detection-and-Localization-in-Complex-Scene-Hanif-Prevost",
            "title": {
                "fragments": [],
                "text": "Text Detection and Localization in Complex Scene Images using Constrained AdaBoost Algorithm"
            },
            "tldr": {
                "abstractSimilarityScore": 62,
                "text": "A boosting framework integrating feature and weak classifier selection based on computational complexity is proposed to construct efficient text detectors and a neural network based localizer learns necessary rules for localization in gray scale scene images."
            },
            "venue": {
                "fragments": [],
                "text": "2009 10th International Conference on Document Analysis and Recognition"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1796455"
                        ],
                        "name": "R. Minetto",
                        "slug": "R.-Minetto",
                        "structuredName": {
                            "firstName": "Rodrigo",
                            "lastName": "Minetto",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Minetto"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1728523"
                        ],
                        "name": "Nicolas Thome",
                        "slug": "Nicolas-Thome",
                        "structuredName": {
                            "firstName": "Nicolas",
                            "lastName": "Thome",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nicolas Thome"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "51021910"
                        ],
                        "name": "M. Cord",
                        "slug": "M.-Cord",
                        "structuredName": {
                            "firstName": "Matthieu",
                            "lastName": "Cord",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Cord"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1715861"
                        ],
                        "name": "Jonathan Fabrizio",
                        "slug": "Jonathan-Fabrizio",
                        "structuredName": {
                            "firstName": "Jonathan",
                            "lastName": "Fabrizio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jonathan Fabrizio"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1740693"
                        ],
                        "name": "B. Marcotegui",
                        "slug": "B.-Marcotegui",
                        "structuredName": {
                            "firstName": "Beatriz",
                            "lastName": "Marcotegui",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Marcotegui"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 85,
                                "start": 74
                            }
                        ],
                        "text": "Through visual inspection, we separated the candidate regions returned by SnooperText into a set of text regionsXi, and a set of non-text (\u2018background\u2019) regionsBi, for i = 1, 2, 3."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 149,
                                "start": 138
                            }
                        ],
                        "text": "Therefore, we extracted from these image collections six sets of candidate sub-images as follows: We processed each image collection with SnooperText [3], a state-of-the-art text detector algorithm, tuned for high recall and moderate precision."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 3,
                                "start": 0
                            }
                        ],
                        "text": "[3], which was developed within the iTowns urb an documentation and navigation project [26]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 154,
                                "start": 151
                            }
                        ],
                        "text": "Therefore, we extracted from these image collections six se ts of candidate sub-images as follows: We processed each image collection with SnooperText [3], a s tate-of-the-art text detector algorithm, tuned for high recall and moderate precision."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 80,
                                "start": 77
                            }
                        ],
                        "text": "In particular, we sh ow that the combination of a \u201cpermissive\u201d text detector [3] with a T-HOG based post-filter outperforms state-of-the-art text detectors described in the literature [4]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14339518,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6372065966fce1efcba0abafc50c1abc25152d85",
            "isKey": false,
            "numCitedBy": 44,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "Text detection in natural images remains a very challenging task. For instance, in an urban context, the detection is very difficult due to large variations in terms of shape, size, color, orientation, and the image may be blurred or have irregular illumination, etc. In this paper, we describe a robust and accurate multiresolution approach to detect and classify text regions in such scenarios. Based on generation/validation paradigm, we first segment images to detect character regions with a multiresolution algorithm able to manage large character size variations. The segmented regions are then filtered out using shapebased classification, and neighboring characters are merged to generate text hypotheses. A validation step computes a region signature based on texture analysis to reject false positives. We evaluate our algorithm in two challenging databases, achieving very good results."
            },
            "slug": "Snoopertext:-A-multiresolution-system-for-text-in-Minetto-Thome",
            "title": {
                "fragments": [],
                "text": "Snoopertext: A multiresolution system for text detection in complex visual scenes"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This paper describes a robust and accurate multiresolution approach to detect and classify text regions in such scenarios in an urban context with very good results."
            },
            "venue": {
                "fragments": [],
                "text": "2010 IEEE International Conference on Image Processing"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3126798"
                        ],
                        "name": "B. Epshtein",
                        "slug": "B.-Epshtein",
                        "structuredName": {
                            "firstName": "Boris",
                            "lastName": "Epshtein",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Epshtein"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "20592981"
                        ],
                        "name": "E. Ofek",
                        "slug": "E.-Ofek",
                        "structuredName": {
                            "firstName": "Eyal",
                            "lastName": "Ofek",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Ofek"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1743988"
                        ],
                        "name": "Y. Wexler",
                        "slug": "Y.-Wexler",
                        "structuredName": {
                            "firstName": "Yonatan",
                            "lastName": "Wexler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Wexler"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 92,
                                "start": 89
                            }
                        ],
                        "text": "published methods on the ICDAR dataset, and outperforms the Stroke Width Transform (SWT) [3] results of Epshtein et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 185,
                                "start": 182
                            }
                        ],
                        "text": "In particular, we show that the combination of a \u2018permissive\u2019 text detector [2] with a T-HOG based post-filter outperforms state-ofthe-art text detectors described in the literature [3]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 3,
                                "start": 0
                            }
                        ],
                        "text": "[3], which had the highest f-scores reported in the literature (as of 2011)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 13,
                                "start": 10
                            }
                        ],
                        "text": "benchmark [3], with 307 color images of urban scenes, ranging from 1024 1360 to 1024 768 pixels, taken with hand-held cameras."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 8890220,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "39c4ae83b5c92e0fa55de1ec7e5cf12589c408db",
            "isKey": true,
            "numCitedBy": 1470,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a novel image operator that seeks to find the value of stroke width for each image pixel, and demonstrate its use on the task of text detection in natural images. The suggested operator is local and data dependent, which makes it fast and robust enough to eliminate the need for multi-scale computation or scanning windows. Extensive testing shows that the suggested scheme outperforms the latest published algorithms. Its simplicity allows the algorithm to detect texts in many fonts and languages."
            },
            "slug": "Detecting-text-in-natural-scenes-with-stroke-width-Epshtein-Ofek",
            "title": {
                "fragments": [],
                "text": "Detecting text in natural scenes with stroke width transform"
            },
            "tldr": {
                "abstractSimilarityScore": 84,
                "text": "A novel image operator is presented that seeks to find the value of stroke width for each image pixel, and its use on the task of text detection in natural images is demonstrated."
            },
            "venue": {
                "fragments": [],
                "text": "2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2257498"
                        ],
                        "name": "N. Sharma",
                        "slug": "N.-Sharma",
                        "structuredName": {
                            "firstName": "Nabin",
                            "lastName": "Sharma",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Sharma"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144167309"
                        ],
                        "name": "U. Pal",
                        "slug": "U.-Pal",
                        "structuredName": {
                            "firstName": "Umapada",
                            "lastName": "Pal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "U. Pal"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1801266"
                        ],
                        "name": "M. Blumenstein",
                        "slug": "M.-Blumenstein",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Blumenstein",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Blumenstein"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[15], that covers some advances in this area."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6423795,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6a13631b70b7ace95d3906e99ece1aa97c685eb0",
            "isKey": false,
            "numCitedBy": 43,
            "numCiting": 72,
            "paperAbstract": {
                "fragments": [],
                "text": "Extraction and recognition of text present in video has become a very popular research area in the last decade. Generally, text present in video frames is of different size, orientation, style, etc. with complex backgrounds, noise, low resolution and contrast. These factors make the automatic text extraction and recognition in video frames a challenging task. A large number of techniques have been proposed by various researchers in the recent past to address the problem. This paper presents a review of various state-of-the-art techniques proposed towards different stages (e.g. detection, localization, extraction, etc.) of text information processing in video frames. Looking at the growing popularity and the recent developments in the processing of text in video frames, this review imparts details of current trends and potential directions for further research activities to assist researchers."
            },
            "slug": "Recent-Advances-in-Video-Based-Document-Processing:-Sharma-Pal",
            "title": {
                "fragments": [],
                "text": "Recent Advances in Video Based Document Processing: A Review"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This paper presents a review of various state-of-the-art techniques proposed towards different stages (e.g. detection, localization, extraction, etc.) of text information processing in video frames."
            },
            "venue": {
                "fragments": [],
                "text": "2012 10th IAPR International Workshop on Document Analysis Systems"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144522420"
                        ],
                        "name": "T. Ojala",
                        "slug": "T.-Ojala",
                        "structuredName": {
                            "firstName": "Timo",
                            "lastName": "Ojala",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Ojala"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145962204"
                        ],
                        "name": "M. Pietik\u00e4inen",
                        "slug": "M.-Pietik\u00e4inen",
                        "structuredName": {
                            "firstName": "Matti",
                            "lastName": "Pietik\u00e4inen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Pietik\u00e4inen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "26883091"
                        ],
                        "name": "Topi M\u00e4enp\u00e4\u00e4",
                        "slug": "Topi-M\u00e4enp\u00e4\u00e4",
                        "structuredName": {
                            "firstName": "Topi",
                            "lastName": "M\u00e4enp\u00e4\u00e4",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Topi M\u00e4enp\u00e4\u00e4"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "[22]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 14540685,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f11a7136b6b7854bd0998ef463ffa8e907c411a2",
            "isKey": false,
            "numCitedBy": 13063,
            "numCiting": 95,
            "paperAbstract": {
                "fragments": [],
                "text": "Presents a theoretically very simple, yet efficient, multiresolution approach to gray-scale and rotation invariant texture classification based on local binary patterns and nonparametric discrimination of sample and prototype distributions. The method is based on recognizing that certain local binary patterns, termed \"uniform,\" are fundamental properties of local image texture and their occurrence histogram is proven to be a very powerful texture feature. We derive a generalized gray-scale and rotation invariant operator presentation that allows for detecting the \"uniform\" patterns for any quantization of the angular space and for any spatial resolution and presents a method for combining multiple operators for multiresolution analysis. The proposed approach is very robust in terms of gray-scale variations since the operator is, by definition, invariant against any monotonic transformation of the gray scale. Another advantage is computational simplicity as the operator can be realized with a few operations in a small neighborhood and a lookup table. Experimental results demonstrate that good discrimination can be achieved with the occurrence statistics of simple rotation invariant local binary patterns."
            },
            "slug": "Multiresolution-Gray-Scale-and-Rotation-Invariant-Ojala-Pietik\u00e4inen",
            "title": {
                "fragments": [],
                "text": "Multiresolution Gray-Scale and Rotation Invariant Texture Classification with Local Binary Patterns"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "A generalized gray-scale and rotation invariant operator presentation that allows for detecting the \"uniform\" patterns for any quantization of the angular space and for any spatial resolution and presents a method for combining multiple operators for multiresolution analysis."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145897899"
                        ],
                        "name": "David Picard",
                        "slug": "David-Picard",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Picard",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David Picard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1728523"
                        ],
                        "name": "Nicolas Thome",
                        "slug": "Nicolas-Thome",
                        "structuredName": {
                            "firstName": "Nicolas",
                            "lastName": "Thome",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nicolas Thome"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "51021910"
                        ],
                        "name": "M. Cord",
                        "slug": "M.-Cord",
                        "structuredName": {
                            "firstName": "Matthieu",
                            "lastName": "Cord",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Cord"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "The SVM is defined as f(z) = \u2211M i=1 \u03b1iK(zi, z)\u2212b where K is the kernel [24], a function from R \u00d7RN to R; the zi are the M fixed support vectors; the \u03b1i are real weights; and b is the bias or decision threshold."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 11942721,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7c3063cd382a8231e58380e3360325c1240a4d7b",
            "isKey": false,
            "numCitedBy": 25,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "Recently, increasing interest has been brought to improve image categorization performances by combining multiple descriptors. However, very few approaches have been proposed for combining features based on complementary aspects, and evaluating the performances in realistic databases. In this paper, we tackle the problem of combining different feature types (edge and color), and evaluate the performance gain in the very challenging VOC 2009 benchmark. Our contribution is three-fold. First, we propose new local color descriptors, unifying edge and color feature extraction into the \u201cBag Of Word\u201d model. Second, we improve the Spatial Pyramid Matching (SPM) scheme for better incorporating spatial information into the similarity measurement. Last but not least, we propose a new combination strategy based on \u21131 Multiple Kernel Learning (MKL) that simultaneously learns individual kernel parameters and the kernel combination. Experiments prove the relevance of the proposed approach, which outperforms baseline combination methods while being computationally effective."
            },
            "slug": "An-efficient-system-for-combining-complementary-in-Picard-Thome",
            "title": {
                "fragments": [],
                "text": "An efficient system for combining complementary kernels in complex visual categorization tasks"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This paper proposes new local color descriptors, unifying edge and color feature extraction into the \u201cBag Of Word\u201d model, and proposes a new combination strategy based on \u21131 Multiple Kernel Learning (MKL) that simultaneously learns individual kernel parameters and the kernel combination."
            },
            "venue": {
                "fragments": [],
                "text": "2010 IEEE International Conference on Image Processing"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [],
                        "name": "Wei Zhang",
                        "slug": "Wei-Zhang",
                        "structuredName": {
                            "firstName": "Wei",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wei Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1696991"
                        ],
                        "name": "G. Zelinsky",
                        "slug": "G.-Zelinsky",
                        "structuredName": {
                            "firstName": "Gregory",
                            "lastName": "Zelinsky",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Zelinsky"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145654220"
                        ],
                        "name": "D. Samaras",
                        "slug": "D.-Samaras",
                        "structuredName": {
                            "firstName": "Dimitris",
                            "lastName": "Samaras",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Samaras"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8356979,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "340ad17611fddb1f59a8b50114839544878229b7",
            "isKey": false,
            "numCitedBy": 134,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a multi-resolution framework inspired by human visual search for general object detection. Different resolutions are represented using a coarse-to-fine feature hierarchy. During detection, the lower resolution features are initially used to reject the majority of negative windows at relatively low cost, leaving a relatively small number of windows to be processed in higher resolutions. This enables the use of computationally more expensive higher resolution features to achieve high detection accuracy. We applied this framework on Histograms of Oriented Gradient (HOG) features for object detection. Our multi-resolution detector produced better performance for pedestrian detection than state-of-the-art methods (Dalal and Triggs, 2005), and was faster during both training and testing. Testing our method on motorbikes and cars from the VOC database revealed similar improvements in both speed and accuracy, suggesting that our approach is suitable for realtime general object detection applications."
            },
            "slug": "Real-time-Accurate-Object-Detection-using-Multiple-Zhang-Zelinsky",
            "title": {
                "fragments": [],
                "text": "Real-time Accurate Object Detection using Multiple Resolutions"
            },
            "tldr": {
                "abstractSimilarityScore": 65,
                "text": "This work proposes a multi-resolution framework inspired by human visual search for general object detection that produced better performance for pedestrian detection than state-of-the-art methods, and was faster during both training and testing."
            },
            "venue": {
                "fragments": [],
                "text": "2007 IEEE 11th International Conference on Computer Vision"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1728523"
                        ],
                        "name": "Nicolas Thome",
                        "slug": "Nicolas-Thome",
                        "structuredName": {
                            "firstName": "Nicolas",
                            "lastName": "Thome",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nicolas Thome"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1736075"
                        ],
                        "name": "A. Vacavant",
                        "slug": "A.-Vacavant",
                        "structuredName": {
                            "firstName": "Antoine",
                            "lastName": "Vacavant",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Vacavant"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2324681"
                        ],
                        "name": "Lionel Robinault",
                        "slug": "Lionel-Robinault",
                        "structuredName": {
                            "firstName": "Lionel",
                            "lastName": "Robinault",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lionel Robinault"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1774594"
                        ],
                        "name": "S. Miguet",
                        "slug": "S.-Miguet",
                        "structuredName": {
                            "firstName": "Serge",
                            "lastName": "Miguet",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Miguet"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 246,
                                "start": 239
                            }
                        ],
                        "text": "There is an extensive literature on text detection, but most of it are dedicated to specific contexts such as text detection in handwritten documents [10], text recognition in medieval manuscript images [11], and license plate recognition [12,28]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 4893218,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "76d67faaa2b0b1bc871cfe1969ebf7b18257528a",
            "isKey": false,
            "numCitedBy": 59,
            "numCiting": 50,
            "paperAbstract": {
                "fragments": [],
                "text": "License Plate Recognition (LPR) is mainly regarded as a solved problem. However, robust solutions able to face real-world scenarios still need to be proposed. Country-specific systems are mostly, designed, which can (artificially) reach high-level recognition rates. This option, however, strictly limits their applicability. In this paper, we propose an approach that can deal with various national plates. There are three main areas of novelty. First, the Optical Character Recognition (OCR) is managed by a hybrid strategy, combining statistical and structural algorithms. Secondly, an efficient probabilistic edit distance is proposed for providing an explicit video-based LPR. Last but not least, cognitive loops are introduced at critical stages of the algorithm. These feedback steps take advantage of the context modeling to increase the overall system performances, and overcome the inextricable parameter settings of the low-level processing. The system performances have been tested in more than 1200 static images with difficult illumination conditions and complex backgrounds, as well as in six different videos containing 525 moving vehicles. The evaluations prove our system to be very competitive among the non-country specific approaches."
            },
            "slug": "A-cognitive-and-video-based-approach-for-License-Thome-Vacavant",
            "title": {
                "fragments": [],
                "text": "A cognitive and video-based approach for multinational License Plate Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "An efficient probabilistic edit distance is proposed for providing an explicit video-based LPR, and cognitive loops are introduced at critical stages of the algorithm to take advantage of the context modeling to increase the overall system performances."
            },
            "venue": {
                "fragments": [],
                "text": "Machine Vision and Applications"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2502166"
                        ],
                        "name": "I. Giannoukos",
                        "slug": "I.-Giannoukos",
                        "structuredName": {
                            "firstName": "Ioannis",
                            "lastName": "Giannoukos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Giannoukos"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1696199"
                        ],
                        "name": "C. Anagnostopoulos",
                        "slug": "C.-Anagnostopoulos",
                        "structuredName": {
                            "firstName": "Christos-Nikolaos",
                            "lastName": "Anagnostopoulos",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Anagnostopoulos"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2692971"
                        ],
                        "name": "V. Loumos",
                        "slug": "V.-Loumos",
                        "structuredName": {
                            "firstName": "Vassilis",
                            "lastName": "Loumos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Loumos"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3231139"
                        ],
                        "name": "E. Kayafas",
                        "slug": "E.-Kayafas",
                        "structuredName": {
                            "firstName": "Eleftherios",
                            "lastName": "Kayafas",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Kayafas"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 35416844,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "74db72f7ca90338d837dc7ab3996580265a7aec0",
            "isKey": false,
            "numCitedBy": 65,
            "numCiting": 51,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Operator-context-scanning-to-support-high-rates-for-Giannoukos-Anagnostopoulos",
            "title": {
                "fragments": [],
                "text": "Operator context scanning to support high segmentation rates for real time license plate recognition"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit."
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145815031"
                        ],
                        "name": "S. Lucas",
                        "slug": "S.-Lucas",
                        "structuredName": {
                            "firstName": "Simon",
                            "lastName": "Lucas",
                            "middleNames": [
                                "M.",
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Lucas"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 1842569,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bbf50fe5622253f401e892ed943a18033e18b7b9",
            "isKey": false,
            "numCitedBy": 318,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes the results of the ICDAR 2005 competition for locating text in camera captured scenes. For this we used the same data as the ICDAR 2003 competition, which has been kept private until now. This allows a direct comparison with the 2003 entries. The main result is that the leading 2005 entry has improved significantly on the leading 2003 entry, with an increase in average f-score from 0.5 to 0.62, where the f-score is the same adapted information retrieval measure used for the 2003 competition. The paper also discusses the Web-based deployment and evaluation of text locating systems, and one of the leading entries has now been deployed in this way. This mode of usage could lead to more complete and more immediate knowledge of the strengths and weaknesses of each newly developed system."
            },
            "slug": "ICDAR-2005-text-locating-competition-results-Lucas",
            "title": {
                "fragments": [],
                "text": "ICDAR 2005 text locating competition results"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The main result is that the leading 2005 entry has improved significantly on the leading 2003 entry, with an increase in average f- score from 0.5 to 0.62, where the f-score is the same adapted information retrieval measure used for the 2003 competition."
            },
            "venue": {
                "fragments": [],
                "text": "Eighth International Conference on Document Analysis and Recognition (ICDAR'05)"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1796455"
                        ],
                        "name": "R. Minetto",
                        "slug": "R.-Minetto",
                        "structuredName": {
                            "firstName": "Rodrigo",
                            "lastName": "Minetto",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Minetto"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1728523"
                        ],
                        "name": "Nicolas Thome",
                        "slug": "Nicolas-Thome",
                        "structuredName": {
                            "firstName": "Nicolas",
                            "lastName": "Thome",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nicolas Thome"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "51021910"
                        ],
                        "name": "M. Cord",
                        "slug": "M.-Cord",
                        "structuredName": {
                            "firstName": "Matthieu",
                            "lastName": "Cord",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Cord"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1756125"
                        ],
                        "name": "N. J. Leite",
                        "slug": "N.-J.-Leite",
                        "structuredName": {
                            "firstName": "Neucimar",
                            "lastName": "Leite",
                            "middleNames": [
                                "Jer\u00f4nimo"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. J. Leite"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1719901"
                        ],
                        "name": "J. Stolfi",
                        "slug": "J.-Stolfi",
                        "structuredName": {
                            "firstName": "Jorge",
                            "lastName": "Stolfi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Stolfi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 17419543,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b9eb30d9450f09963f3a2a07c4692657e98c77f5",
            "isKey": false,
            "numCitedBy": 49,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "In this work we introduced SnooperTrack, an algorithm for the automatic detection and tracking of text objects \u2014 such as store names, traffic signs, license plates, and advertisements \u2014 in videos of outdoor scenes. The purpose is to improve the performances of text detection process in still images by taking advantage of the temporal coherence in videos. We first propose an efficient tracking algorithm using particle filtering framework with original region descriptors. The second contribution is our strategy to merge tracked regions and new detections. We also propose an improved version of our previously published text detection algorithm in still images. Tests indicate that SnooperTrack is fast, robust, enable false positive suppression, and achieved great performances in complex videos of outdoor scenes."
            },
            "slug": "Snoopertrack:-Text-detection-and-tracking-for-Minetto-Thome",
            "title": {
                "fragments": [],
                "text": "Snoopertrack: Text detection and tracking for outdoor videos"
            },
            "tldr": {
                "abstractSimilarityScore": 52,
                "text": "An efficient tracking algorithm using particle filtering framework with original region descriptors and a strategy to merge tracked regions and new detections to improve the performances of text detection process in still images by taking advantage of the temporal coherence in videos."
            },
            "venue": {
                "fragments": [],
                "text": "2011 18th IEEE International Conference on Image Processing"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145115014"
                        ],
                        "name": "Corinna Cortes",
                        "slug": "Corinna-Cortes",
                        "structuredName": {
                            "firstName": "Corinna",
                            "lastName": "Cortes",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Corinna Cortes"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50560492"
                        ],
                        "name": "V. Vapnik",
                        "slug": "V.-Vapnik",
                        "structuredName": {
                            "firstName": "Vladimir",
                            "lastName": "Vapnik",
                            "middleNames": [
                                "Naumovich"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Vapnik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 51,
                                "start": 48
                            }
                        ],
                        "text": "Like Dalal and Triggs, we use an SVM classifier [1] to turn the descriptor zAR into a real-valued score f(z), such that positive scores indicate \u2018probably text\u2019 and negative scores indicate \u2018probably non-text\u2019."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 58,
                                "start": 55
                            }
                        ],
                        "text": "We show that a support vector machine (SVM) classifier [1] using T-HOG descriptors can effectively solve the text/non-text classification problem."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 52874011,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "52b7bf3ba59b31f362aa07f957f1543a29a4279e",
            "isKey": false,
            "numCitedBy": 33421,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "The support-vector network is a new learning machine for two-group classification problems. The machine conceptually implements the following idea: input vectors are non-linearly mapped to a very high-dimension feature space. In this feature space a linear decision surface is constructed. Special properties of the decision surface ensures high generalization ability of the learning machine. The idea behind the support-vector network was previously implemented for the restricted case where the training data can be separated without errors. We here extend this result to non-separable training data.High generalization ability of support-vector networks utilizing polynomial input transformations is demonstrated. We also compare the performance of the support-vector network to various classical learning algorithms that all took part in a benchmark study of Optical Character Recognition."
            },
            "slug": "Support-Vector-Networks-Cortes-Vapnik",
            "title": {
                "fragments": [],
                "text": "Support-Vector Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "High generalization ability of support-vector networks utilizing polynomial input transformations is demonstrated and the performance of the support- vector network is compared to various classical learning algorithms that all took part in a benchmark study of Optical Character Recognition."
            },
            "venue": {
                "fragments": [],
                "text": "Machine Learning"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3100171"
                        ],
                        "name": "Yann Leydier",
                        "slug": "Yann-Leydier",
                        "structuredName": {
                            "firstName": "Yann",
                            "lastName": "Leydier",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yann Leydier"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145573734"
                        ],
                        "name": "F. Lebourgeois",
                        "slug": "F.-Lebourgeois",
                        "structuredName": {
                            "firstName": "Frank",
                            "lastName": "Lebourgeois",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Lebourgeois"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1739381"
                        ],
                        "name": "H. Emptoz",
                        "slug": "H.-Emptoz",
                        "structuredName": {
                            "firstName": "Hubert",
                            "lastName": "Emptoz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Emptoz"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 207,
                                "start": 203
                            }
                        ],
                        "text": "There is an extensive literature on text detection, but most of it are dedicated to specific contexts such as text detection in handwritten documents [10], text recognition in medieval manuscript images [11], and license plate recognition [12,28]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 31207133,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3bd42d5b7a0cce96e1cdd84eaa2fd9f2d17e260f",
            "isKey": false,
            "numCitedBy": 131,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Text-search-for-medieval-manuscript-images-Leydier-Lebourgeois",
            "title": {
                "fragments": [],
                "text": "Text search for medieval manuscript images"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit."
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2374536"
                        ],
                        "name": "Alvin F. Martin",
                        "slug": "Alvin-F.-Martin",
                        "structuredName": {
                            "firstName": "Alvin",
                            "lastName": "Martin",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alvin F. Martin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2862682"
                        ],
                        "name": "G. Doddington",
                        "slug": "G.-Doddington",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Doddington",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Doddington"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2258795"
                        ],
                        "name": "T. Kamm",
                        "slug": "T.-Kamm",
                        "structuredName": {
                            "firstName": "Teresa",
                            "lastName": "Kamm",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kamm"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2731353"
                        ],
                        "name": "M. Ordowski",
                        "slug": "M.-Ordowski",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Ordowski",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Ordowski"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2282719"
                        ],
                        "name": "Mark A. Przybocki",
                        "slug": "Mark-A.-Przybocki",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Przybocki",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mark A. Przybocki"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 107,
                                "start": 100
                            }
                        ],
                        "text": "DET curve and area metric We compare classifiers by plotting the d cision error trade-off(DET) curve[5, 27], which is the set of pairs(\u03c4b, \u03b2b) for b \u2208 [\u2212\u221e, ."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 9497630,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f127eda80dfe4e4cda63357c5c051b409c242b24",
            "isKey": false,
            "numCitedBy": 1570,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract : We introduce the DET Curve as a means of representing performance on detection tasks that involve a tradeoff of error types. We discuss why we prefer it to the traditional ROC Curve and offer several examples of its use in speaker recognition and language recognition. We explain why it is likely to produce approximately linear curves. We also note special points that may be included on these curves, how they are used with multiple targets, and possible further applications."
            },
            "slug": "The-DET-curve-in-assessment-of-detection-task-Martin-Doddington",
            "title": {
                "fragments": [],
                "text": "The DET curve in assessment of detection task performance"
            },
            "tldr": {
                "abstractSimilarityScore": 73,
                "text": "The DET Curve is introduced as a means of representing performance on detection tasks that involve a tradeoff of error types and why it is likely to produce approximately linear curves."
            },
            "venue": {
                "fragments": [],
                "text": "EUROSPEECH"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1796455"
                        ],
                        "name": "R. Minetto",
                        "slug": "R.-Minetto",
                        "structuredName": {
                            "firstName": "Rodrigo",
                            "lastName": "Minetto",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Minetto"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1728523"
                        ],
                        "name": "Nicolas Thome",
                        "slug": "Nicolas-Thome",
                        "structuredName": {
                            "firstName": "Nicolas",
                            "lastName": "Thome",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nicolas Thome"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "51021910"
                        ],
                        "name": "M. Cord",
                        "slug": "M.-Cord",
                        "structuredName": {
                            "firstName": "Matthieu",
                            "lastName": "Cord",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Cord"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1719901"
                        ],
                        "name": "J. Stolfi",
                        "slug": "J.-Stolfi",
                        "structuredName": {
                            "firstName": "Jorge",
                            "lastName": "Stolfi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Stolfi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1699175"
                        ],
                        "name": "F. Precioso",
                        "slug": "F.-Precioso",
                        "structuredName": {
                            "firstName": "Fr\u00e9d\u00e9ric",
                            "lastName": "Precioso",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Precioso"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2030869"
                        ],
                        "name": "Jonathan Guyomard",
                        "slug": "Jonathan-Guyomard",
                        "structuredName": {
                            "firstName": "Jonathan",
                            "lastName": "Guyomard",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jonathan Guyomard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1756125"
                        ],
                        "name": "N. J. Leite",
                        "slug": "N.-J.-Leite",
                        "structuredName": {
                            "firstName": "Neucimar",
                            "lastName": "Leite",
                            "middleNames": [
                                "Jer\u00f4nimo"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. J. Leite"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2257115,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "19525c3d68f509b0e39eba044b47dab60093e4d5",
            "isKey": false,
            "numCitedBy": 36,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "Text detection and recognition in real images taken in unconstrained environments, such as street view images, remain surprisingly challenging in Computer Vision."
            },
            "slug": "Text-detection-and-recognition-in-urban-scenes-Minetto-Thome",
            "title": {
                "fragments": [],
                "text": "Text detection and recognition in urban scenes"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "Text detection and recognition in real images taken in unconstrained environments, such as street view images, remain surprisingly challenging in Computer Vision."
            },
            "venue": {
                "fragments": [],
                "text": "2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops)"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2860056"
                        ],
                        "name": "M. Nezamabadi",
                        "slug": "M.-Nezamabadi",
                        "structuredName": {
                            "firstName": "Mahdi",
                            "lastName": "Nezamabadi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Nezamabadi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 162,
                                "start": 158
                            }
                        ],
                        "text": "In this step we also convert the image from color to gray scale, since the human visual system uses only the brightness channel to recognize character shapes [21]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 8208827,
            "fieldsOfStudy": [
                "Art"
            ],
            "id": "ef65035d6d88d8aa5d3851b1563868d847a093ce",
            "isKey": false,
            "numCitedBy": 525,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Color science is a multidisciplinary field with broad applications in industries such as digital imaging, coatings and textiles, food, lighting, archiving, art, and fashion. Accurate definition and measurement of color appearance is a challenging task that directly affects color reproduction in such applications. Color Appearance Models addresses those challenges and offers insight into the preferred solutions. Extensive research on the human visual system (HVS) and color vision has been performed in the last century, and this book contains a good overview of the most important and relevant literature regarding color appearance models."
            },
            "slug": "Color-Appearance-Models-Nezamabadi",
            "title": {
                "fragments": [],
                "text": "Color Appearance Models"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "This book is a good overview of the most important and relevant literature regarding color appearance models and offers insight into the preferred solutions."
            },
            "venue": {
                "fragments": [],
                "text": "J. Electronic Imaging"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2084353304"
                        ],
                        "name": "G. Louloudisa",
                        "slug": "G.-Louloudisa",
                        "structuredName": {
                            "firstName": "G.",
                            "lastName": "Louloudisa",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Louloudisa"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2080207726"
                        ],
                        "name": "B. Gatosb",
                        "slug": "B.-Gatosb",
                        "structuredName": {
                            "firstName": "B.",
                            "lastName": "Gatosb",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Gatosb"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2085864307"
                        ],
                        "name": "I. Pratikakisb",
                        "slug": "I.-Pratikakisb",
                        "structuredName": {
                            "firstName": "I.",
                            "lastName": "Pratikakisb",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Pratikakisb"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2080987605"
                        ],
                        "name": "C. Halatsisa",
                        "slug": "C.-Halatsisa",
                        "structuredName": {
                            "firstName": "C.",
                            "lastName": "Halatsisa",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Halatsisa"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 154,
                                "start": 150
                            }
                        ],
                        "text": "There is an extensive literature on text detection, but most of it are dedicated to specific contexts such as text detection in handwritten documents [10], text recognition in medieval manuscript images [11], and license plate recognition [12,28]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 16167028,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "812c82942fe61b1d63439c0ae8bbf9e92da2e68f",
            "isKey": false,
            "numCitedBy": 56,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "Article history: Received 13 April 2007 Received in revised form 26 March 2008"
            },
            "slug": "Text-line-detection-in-handwritten-documents-Louloudisa-Gatosb",
            "title": {
                "fragments": [],
                "text": "Text line detection in handwritten documents"
            },
            "tldr": {
                "abstractSimilarityScore": 37,
                "text": "This article is intended to provide a history of the project and its aims and aims, as well as some of the issues that led to its development."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "70524822"
                        ],
                        "name": "Ken Turkowski",
                        "slug": "Ken-Turkowski",
                        "structuredName": {
                            "firstName": "Ken",
                            "lastName": "Turkowski",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ken Turkowski"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 129,
                                "start": 125
                            }
                        ],
                        "text": "In both the R-HOG and T-HOG algorithms, the sub-images were rescaled during extraction with the Lanczos interpolation filter [25] to the chosen height H."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 117128712,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6bde94dd86c8e5551f03d2787121c11eb617738d",
            "isKey": false,
            "numCitedBy": 279,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Filters-for-common-resampling-tasks-Turkowski",
            "title": {
                "fragments": [],
                "text": "Filters for common resampling tasks"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1861837498"
                        ],
                        "name": "G. G. Stokes",
                        "slug": "G.-G.-Stokes",
                        "structuredName": {
                            "firstName": "G.",
                            "lastName": "Stokes",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. G. Stokes"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 188,
                                "start": 180
                            }
                        ],
                        "text": "T-HOG as a post-filter to text detection The motivating application for text classifiers such as T-HO G and R-HOG is the detection of text in photos and videos of arbitrary scenes [29, 30]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 221060727,
            "fieldsOfStudy": [
                "Philosophy"
            ],
            "id": "90006064cafcb0a9ad8a30cffeb56efe7e14129b",
            "isKey": false,
            "numCitedBy": 673049,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "however (for it was the literal soul of the life of the Redeemer, John xv. io), is the peculiar token of fellowship with the Redeemer. That love to God (what is meant here is not God\u2019s love to men) is described in such a case as a perfect love (love that has been perfected), involves no difficulty, for the simple reason that the proposition is purely hypothetical. We must, of course, also take the &dquo;keeping&dquo; in all its stringency. John knows right well that the case supposed here ncver becomes full reality. &dquo; Hereb)\u2019,&dquo; i.e. from the actual realization of love to God. &dquo; TIli7i 7e)e are ill Hinz &dquo;"
            },
            "slug": "\"J.\"-Stokes",
            "title": {
                "fragments": [],
                "text": "\"J.\""
            },
            "venue": {
                "fragments": [],
                "text": "The New Yale Book of Quotations"
            },
            "year": 2021
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2972851"
                        ],
                        "name": "M. Brill",
                        "slug": "M.-Brill",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Brill",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Brill"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 221615103,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "93993b08b5e8bbfe3f749dea72d57c458309b33a",
            "isKey": false,
            "numCitedBy": 1040,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Color-appearance-models-Brill",
            "title": {
                "fragments": [],
                "text": "Color appearance models"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "84120004"
                        ],
                        "name": "\uc131\uae30\uc775",
                        "slug": "\uc131\uae30\uc775",
                        "structuredName": {
                            "firstName": "",
                            "lastName": "\uc131\uae30\uc775",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "\uc131\uae30\uc775"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "52064104"
                        ],
                        "name": "\uc774\uc601\ud0c1",
                        "slug": "\uc774\uc601\ud0c1",
                        "structuredName": {
                            "firstName": "",
                            "lastName": "\uc774\uc601\ud0c1",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "\uc774\uc601\ud0c1"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "66797895"
                        ],
                        "name": "\ubc15\uacc4\ud604",
                        "slug": "\ubc15\uacc4\ud604",
                        "structuredName": {
                            "firstName": "",
                            "lastName": "\ubc15\uacc4\ud604",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "\ubc15\uacc4\ud604"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "66930011"
                        ],
                        "name": "\uc804\ud0dc\uad6d",
                        "slug": "\uc804\ud0dc\uad6d",
                        "structuredName": {
                            "firstName": "",
                            "lastName": "\uc804\ud0dc\uad6d",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "\uc804\ud0dc\uad6d"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "65818414"
                        ],
                        "name": "\ubc15\ud45c\uc6d0",
                        "slug": "\ubc15\ud45c\uc6d0",
                        "structuredName": {
                            "firstName": "",
                            "lastName": "\ubc15\ud45c\uc6d0",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "\ubc15\ud45c\uc6d0"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "66373723"
                        ],
                        "name": "\ud55c\uc77c\uc6a9",
                        "slug": "\ud55c\uc77c\uc6a9",
                        "structuredName": {
                            "firstName": "",
                            "lastName": "\ud55c\uc77c\uc6a9",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "\ud55c\uc77c\uc6a9"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "79743017"
                        ],
                        "name": "\uc7a5\uc724\ud76c",
                        "slug": "\uc7a5\uc724\ud76c",
                        "structuredName": {
                            "firstName": "",
                            "lastName": "\uc7a5\uc724\ud76c",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "\uc7a5\uc724\ud76c"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[17] described a text recognizer that decomposes the c andidate sub-image into a multiscale 16 \u00d7 16 cell grid and computes wavelet moments for each block."
                    },
                    "intents": []
                }
            ],
            "corpusId": 73741649,
            "fieldsOfStudy": [
                "Medicine"
            ],
            "id": "07b056a23b225fa4fc54cda80a8e6c2c74760541",
            "isKey": false,
            "numCitedBy": 46244,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Y.-\uc131\uae30\uc775-\uc774\uc601\ud0c1",
            "title": {
                "fragments": [],
                "text": "Y."
            },
            "venue": {
                "fragments": [],
                "text": "Industrial and Labor Relations Terms"
            },
            "year": 2019
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Text detection and recognition in images and video frames, Pattern Recognition"
            },
            "venue": {
                "fragments": [],
                "text": "Elsevier"
            },
            "year": 2004
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Filters for common resampling tasks Graphics Gems"
            },
            "venue": {
                "fragments": [],
                "text": "Filters for common resampling tasks Graphics Gems"
            },
            "year": 1990
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 72,
                                "start": 69
                            }
                        ],
                        "text": "Towards this goal, we describe here the T-HOG, publicly available at [1], a novel gradient-based descriptor that efficiently and accurately characterizes i mages of single-line texts."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Text-HOG (T-HOG)., http://www.dainf.ct.utfpr.edu.br/ \u0303 rminetto/projects/thog.html"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2012
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 72,
                                "start": 69
                            }
                        ],
                        "text": "Towards this goal, we describe here the T-HOG, publicly available at [1], a novel gradient-based descriptor that efficiently and accurately characterizes i mages of single-line texts."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Text-HOG (T-HOG)., http://www.dainf.ct.utfpr.edu.br"
            },
            "venue": {
                "fragments": [],
                "text": "rminetto/projects/thog.html"
            },
            "year": 2012
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 247,
                                "start": 239
                            }
                        ],
                        "text": "There is an extensive literature on text detection, but most of it are dedicated to specific contexts such as text detection in handwritten documents [11], text r cognition in medieval manuscript images [12], and license plate recognition [13, 14]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A cogniti ve and video-based approach for multinational license plate recognition"
            },
            "venue": {
                "fragments": [],
                "text": "Machine Vision a nd Applications 22 (2) "
            },
            "year": 2011
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 207,
                                "start": 203
                            }
                        ],
                        "text": "There is an extensive literature on text detection, but most of it are dedicated to specific contexts such as text detection in handwritten documents [11], text r cognition in medieval manuscript images [12], and license plate recognition [13, 14]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Text search for m edieval manuscript images"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognition, Elsevier 40 (12) "
            },
            "year": 2007
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 46,
                                "start": 42
                            }
                        ],
                        "text": "Text classification, or text verification [16], is often cast s a texture classification problem, and several texture descriptors have been considered in the literature."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Text detection and rec ognition in images and video frames"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognition, Elsevier 37 (3) "
            },
            "year": 2004
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The iTowns project"
            },
            "venue": {
                "fragments": [],
                "text": "The iTowns project"
            },
            "year": 2009
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Multiresolution grayscale and rotation invariant texture classification with local binary patterns"
            },
            "venue": {
                "fragments": [],
                "text": "Image and Vision Computing , Elsevier"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 91,
                                "start": 87
                            }
                        ],
                        "text": "[3], which was developed within the iTowns urb an documentation and navigation project [26]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 46,
                                "start": 42
                            }
                        ],
                        "text": "A subset of the iTowns Project collection [26], consistin g of 100 color images of Parisian fa\u00e7ades taken by a camera-equipped vehicle (similar to Goo gle\u2019s Street View)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Recherche, The iTowns project,  h tp://www.itowns.fr"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2009
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 18,
            "methodology": 13
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 43,
        "totalPages": 5
    },
    "page_url": "https://www.semanticscholar.org/paper/T-HOG:-An-effective-gradient-based-descriptor-for-Minetto-Thome/adf3a79db1b6169bd57ec6a10bedba8ea809e37c?sort=total-citations"
}