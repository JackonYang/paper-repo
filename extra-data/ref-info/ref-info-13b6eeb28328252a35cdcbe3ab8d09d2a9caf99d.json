{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2390150"
                        ],
                        "name": "Dekai Wu",
                        "slug": "Dekai-Wu",
                        "structuredName": {
                            "firstName": "Dekai",
                            "lastName": "Wu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dekai Wu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8762213,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "79f20fb39a6e78352ebbb65b1737970837a420b5",
            "isKey": false,
            "numCitedBy": 82,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a grammarless method for simultaneously bracketing both halves of a parallel text and giving word alignments, assuming only a translation lexicon for the language pair. We introduce inversion-invariant transduction grammars which serve as generative models for parallel bilingual sentences with weak order constraints. Focusing on transduction grammars for bracketing, we formulate a normal form, and a stochastic version amenable to a maximum-likelihood bracketing algorithm. Several extensions and experiments are discussed."
            },
            "slug": "An-Algorithm-for-Simultaneously-Bracketing-Parallel-Wu",
            "title": {
                "fragments": [],
                "text": "An Algorithm for Simultaneously Bracketing Parallel Texts by Aligning Words"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "Focusing on transduction grammars for bracketing, this work forms a normal form, and a stochastic version amenable to a maximum-likelihood bracketing algorithm."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34938639"
                        ],
                        "name": "W. Gale",
                        "slug": "W.-Gale",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Gale",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Gale"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2244184"
                        ],
                        "name": "Kenneth Ward Church",
                        "slug": "Kenneth-Ward-Church",
                        "structuredName": {
                            "firstName": "Kenneth",
                            "lastName": "Church",
                            "middleNames": [
                                "Ward"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kenneth Ward Church"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 189,
                                "start": 169
                            }
                        ],
                        "text": "\u2026be assumed that a parallel bilingual corpus may be aligned to the sentence level with reasonable accuracy (Kay and Ri3cheisen 1988; Catizone, Russel, and Warwick 1989; Gale and Church 1991; Brown, Lai, and Mercer 1991; Chen 1993), even for languages as disparate as Chinese and English (Wu 1994)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 148,
                                "start": 128
                            }
                        ],
                        "text": "Parallel bilingual corpora have been shown to provide a rich source of constraints for statistical analysis (Brown et al. 1990; Gale and Church 1991; Gale, Church, and Yarowsky 1992; Church 1993; Brown et al. 1993; Dagan, Church, and Gale 1993; Fung and Church 1994; Wu and Xia 1994; Fung and\u2026"
                    },
                    "intents": []
                }
            ],
            "corpusId": 519954,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "4fe2a45babab10c1bfae05d2464363f4e52bbaf9",
            "isKey": false,
            "numCitedBy": 1322,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "Researchers in both machine translation (e.g., Brown et al. 1990) and bilingual lexicography (e.g., Klavans and Tzoukermann 1990) have recently become interested in studying bilingual corpora, bodies of text such as the Canadian Hansards (parliamentary proceedings), which are available in multiple languages (such as French and English). One useful step is to align the sentences, that is, to identify correspondences between sentences in one language and sentences in the other language.This paper will describe a method and a program (align) for aligning sentences based on a simple statistical model of character lengths. The program uses the fact that longer sentences in one language tend to be translated into longer sentences in the other language, and that shorter sentences tend to be translated into shorter sentences. A probabilistic score is assigned to each proposed correspondence of sentences, based on the scaled difference of lengths of the two sentences (in characters) and the variance of this difference. This probabilistic score is used in a dynamic programming framework to find the maximum likelihood alignment of sentences.It is remarkable that such a simple approach works as well as it does. An evaluation was performed based on a trilingual corpus of economic reports issued by the Union Bank of Switzerland (UBS) in English, French, and German. The method correctly aligned all but 4% of the sentences. Moreover, it is possible to extract a large subcorpus that has a much smaller error rate. By selecting the best-scoring 80% of the alignments, the error rate is reduced from 4% to 0.7%. There were more errors on the English-French subcorpus than on the English-German subcorpus, showing that error rates will depend on the corpus considered; however, both were small enough to hope that the method will be useful for many language pairs.To further research on bilingual corpora, a much larger sample of Canadian Hansards (approximately 90 million words, half in English and and half in French) has been aligned with the align program and will be available through the Data Collection Initiative of the Association for Computational Linguistics (ACL/DCI). In addition, in order to facilitate replication of the align program, an appendix is provided with detailed c-code of the more difficult core of the align program."
            },
            "slug": "A-Program-for-Aligning-Sentences-in-Bilingual-Gale-Church",
            "title": {
                "fragments": [],
                "text": "A Program for Aligning Sentences in Bilingual Corpora"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "This paper will describe a method and a program for aligning sentences based on a simple statistical model of character lengths, which uses the fact that longer sentences in one language tend to be translated into longer sentence in the other language, and that shorter sentences tend to been translated into shorter sentences."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145366908"
                        ],
                        "name": "Fernando C Pereira",
                        "slug": "Fernando-C-Pereira",
                        "structuredName": {
                            "firstName": "Fernando",
                            "lastName": "Pereira",
                            "middleNames": [
                                "C"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Fernando C Pereira"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1701402"
                        ],
                        "name": "Rebecca N. Wright",
                        "slug": "Rebecca-N.-Wright",
                        "structuredName": {
                            "firstName": "Rebecca",
                            "lastName": "Wright",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Rebecca N. Wright"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 88,
                                "start": 76
                            }
                        ],
                        "text": "FSTs may also be used to parse restricted classes of context-free grammars (Pereira 1991; Roche 1994; Laporte 1996)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5094703,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "189b516bcb97aac7645bb57d21ebb83a60b4bc0d",
            "isKey": false,
            "numCitedBy": 99,
            "numCiting": 45,
            "paperAbstract": {
                "fragments": [],
                "text": "Phrase-structure grammars are an effective representation for important syntactic and semantic aspects of natural languages, but are computationally too demanding for use as language models in real-time speech recognition. An algorithm is described that computes finite-state approximations for context-free grammars and equivalent augmented phrase-structure grammar formalisms. The approximation is exact for certain context-free grammars generating regular languages, including all left-linear and right-linear context-free grammars. The algorithm has been used to construct finite-state language models for limited-domain speech recognition tasks."
            },
            "slug": "Finite-State-Approximation-of-Phrase-Structure-Pereira-Wright",
            "title": {
                "fragments": [],
                "text": "Finite-State Approximation of Phrase Structure Grammars"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "An algorithm is described that computes finite-state approximations for context-free grammars and equivalent augmented phrase-structure grammar formalisms, and the approximation is exact for certain context- Free Grammars generating regular languages, including all left-linear and right-linear context- free grammARS."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34938639"
                        ],
                        "name": "W. Gale",
                        "slug": "W.-Gale",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Gale",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Gale"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2244184"
                        ],
                        "name": "Kenneth Ward Church",
                        "slug": "Kenneth-Ward-Church",
                        "structuredName": {
                            "firstName": "Kenneth",
                            "lastName": "Church",
                            "middleNames": [
                                "Ward"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kenneth Ward Church"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1693517"
                        ],
                        "name": "David Yarowsky",
                        "slug": "David-Yarowsky",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Yarowsky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David Yarowsky"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1848011,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "809d6ee2b1a1dfa1623360ee94cd4efacbd7edf1",
            "isKey": false,
            "numCitedBy": 131,
            "numCiting": 76,
            "paperAbstract": {
                "fragments": [],
                "text": "Word sense disambiguation has been recognized as a major problem in natural language processing research for over forty years. Much of this work has been stymied by difficulties in acquiring appropriate lexical resources, such as semantic networks and annotated corpora. Following the suggestion in Brown et al. (1991a) and Dagan et al. (1991), we have achieved considerable progress recently by taking advantage of a new source of testing and training materials. Rather than depending on small amounts of hand-labeled text, we have been making use of relatively large amounts of parallel text, text such as the Canadian Hansards (parliamentary debates), which are available in two (or more) languages. The translation can often be used in lieu of hand-labeling. For example, consider the polysemous word sentence, which has two major senses: (1) a judicial sentence, and (2), a syntactic sentence. We can collect a number of sense (1) examples by extracting instances that are translated as peine, and we can collect a number of sense (2) examples by extracting instances that are translated as phrase. In this way, we have been able to acquire a considerable amount of testing and training material for developing and testing our disambiguation algorithms. The availability of this testing and training material has enabled us to develop quantitative disambiguation methods that achieve 90% accuracy in discriminating between two very distinct senses of a noun such as sentence. In the training phase, we collect a number of instances of each sense of the polysemous noun. Then in the testing phase, we are given a new instance of the noun, and are asked to assign the instance to one of the senses. We attempt to answer this question by comparing the context of the unknown instance with contexts of known instances using a Bayesian argument that has been applied successfully in related applications such as author identification and information retrieval. The final section of the paper will describe a number of methodological studies which show that the training set need not be large and that it need not be free from errors. Perhaps most surprisingly, we find that the context should extend \u00b150 words, an order of magnitude larger than one typically finds in the literature. 1. Word-Sense Disambiguation Consider, for example, the word duty which has at least two quite distinct senses: (1) a tax and (2) an obligation. Three examples of each sense are given in Table 1 below. The classic disambiguation problem is to construct a means for discriminating between two or more sets of examples such as those shown in Table 1. This paper will focus on the methodology required to address the classic problem, and will have less to say about the details required for practical application of this methodology. Consequently, me reader should exercise some caution in interpreting the 90% figure reported here; this figure could easily be swamped out in a practical system by any number of factors that go beyond the scope of this paper. In particular, the Canadian Hansards, one of just the few currently available sources of parallel text, is extremely unbalanced, and is therefore severely limited as a basis for a practical disambiguation system."
            },
            "slug": "Using-bilingual-materials-to-develop-word-sense-Gale-Church",
            "title": {
                "fragments": [],
                "text": "Using bilingual materials to develop word sense disambiguation methods"
            },
            "tldr": {
                "abstractSimilarityScore": 37,
                "text": "The methodology required to address the classic problem of word sense disambiguation is focused on, and there will be less to say about the details required for practical application of this methodology."
            },
            "venue": {
                "fragments": [],
                "text": "TMI"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1788050"
                        ],
                        "name": "R. Grishman",
                        "slug": "R.-Grishman",
                        "structuredName": {
                            "firstName": "Ralph",
                            "lastName": "Grishman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Grishman"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 60563644,
            "fieldsOfStudy": [
                "Linguistics",
                "Computer Science"
            ],
            "id": "fb65e4f188f1e079db3f87959b2a03799b625b97",
            "isKey": false,
            "numCitedBy": 34,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "Alignment of parallel bilingual corpora at the level of syntactic structure holds the promise of being able to discover detailed bilingual structural correspondences automatically. This paper describes a procedure for the alignment of regularized syntactic structures, proceeding bottom-up through the trees. It makes use of information about possible lexical correspondences, from a bilingual dictionary, to generate initial candidate alignments. We consider in particular how much dictionary coverage is needed for the alignment process, and how the alignment can be iteratively improved by having an initial alignment generate additional lexical correspondences for the dictionary, and then using this augmented dictionary for subsequent alignment passes1."
            },
            "slug": "Iterative-Alignment-of-Syntactic-Structures-for-a-Grishman",
            "title": {
                "fragments": [],
                "text": "Iterative Alignment of Syntactic Structures for a Bilingual Corpus"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This paper considers in particular how much dictionary coverage is needed for the alignment process, and how the alignment can be iteratively improved by having an initial alignment generate additional lexical correspondences for the dictionary, and then using this augmented dictionary for subsequent alignment passes."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46278220"
                        ],
                        "name": "Emmanuel Roche",
                        "slug": "Emmanuel-Roche",
                        "structuredName": {
                            "firstName": "Emmanuel",
                            "lastName": "Roche",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Emmanuel Roche"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 100,
                                "start": 90
                            }
                        ],
                        "text": "FSTs may also be used to parse restricted classes of context-free grammars (Pereira 1991; Roche 1994; Laporte 1996)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 8692748,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f017664e424af7a07227e8789c4cc3370e1c34c9",
            "isKey": false,
            "numCitedBy": 22,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a new approach, illustrated by two algorithms, for parsing not only Finite State Grammars but also Context Free Grammars and their extension, by means of finite state machines. The basis is the computation of a fixed point of a finite-state function, i.e. a finite-state transducer. Using these techniques, we have built a program that parses French sentences with a grammar of more than 200,000 lexical rules with a typical response time of less than a second. The first algorithm computes a fixed point of a non-deterministic finite-state transducer and the second computes a fixed point of a deterministic bidirectional device called a bimachine. These two algorithms point out a new connection between the theory of parsing and the theory of representation of rational transductions."
            },
            "slug": "Two-Parsing-Algorithms-by-Means-of-Finite-State-Roche",
            "title": {
                "fragments": [],
                "text": "Two Parsing Algorithms by Means of Finite State Transducers"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This work builds a program that parses French sentences with a grammar of more than 200,000 lexical rules with a typical response time of less than a second and points out a new connection between the theory of parsing and the Theory of representation of rational transductions."
            },
            "venue": {
                "fragments": [],
                "text": "COLING"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1818123"
                        ],
                        "name": "E. Black",
                        "slug": "E.-Black",
                        "structuredName": {
                            "firstName": "Ezra",
                            "lastName": "Black",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Black"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153733790"
                        ],
                        "name": "R. Garside",
                        "slug": "R.-Garside",
                        "structuredName": {
                            "firstName": "Roger",
                            "lastName": "Garside",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Garside"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143998726"
                        ],
                        "name": "G. Leech",
                        "slug": "G.-Leech",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Leech",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Leech"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "112868461"
                        ],
                        "name": "E. Eyes",
                        "slug": "E.-Eyes",
                        "structuredName": {
                            "firstName": "Elizabeth",
                            "lastName": "Eyes",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Eyes"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 17387777,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "32889f93ab4f08e6b8d9e8bf4719fef18ec986d3",
            "isKey": false,
            "numCitedBy": 121,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "This book is about building computer programs that parse (analyze, or diagram) sentences of a real-world English. The English we are concerned with might be a corpus of everyday, naturally-occurring prose, such as the entire text of this morning's newspaper. Most programs that now exist for this purpose are not very successful at finding the correct analysis for everyday sentences. In contrast, the programs described here make use of a more successful statistically-driven approach. Our book is, first, a record of a five-year research collaboration between IBM and Lancaster University. Large numbers of real-world sentences were fed into the memory of a program for grammatical analysis (including a detailed grammar of English) and processed by statistical methods. The idea is to single out the correct parse, among all those offered by the grammar, on the basis of probabilities. Second, this is a how-to book, showing how to build and implement a statistically-driven broad-coverage grammar of English. We even supply our own grammar, with the necessary statistical algorithms, and with the knowledge needed to prepare a very large set (or corpus) of sentences so that it can be used to guide the statistical processing of the grammar's rules."
            },
            "slug": "Statistically-driven-computer-grammars-of-English-:-Black-Garside",
            "title": {
                "fragments": [],
                "text": "Statistically-driven computer grammars of English : the IBM/LANCASTER approach"
            },
            "tldr": {
                "abstractSimilarityScore": 87,
                "text": "This book is about building computer programs that parse (analyze, or diagram) sentences of a real-world English, which might be a corpus of everyday, naturally-occurring prose, such as the entire text of this morning's newspaper."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2110909951"
                        ],
                        "name": "Stanley F. Chen",
                        "slug": "Stanley-F.-Chen",
                        "structuredName": {
                            "firstName": "Stanley",
                            "lastName": "Chen",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Stanley F. Chen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15369413,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1f55d2bca810edbf9870934a41d956d06ae2d9cf",
            "isKey": false,
            "numCitedBy": 286,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we describe a fast algorithm for aligning sentences with their translations in a bilingual corpus. Existing efficient algorithms ignore word identities and only consider sentence length (Brown et al., 1991b; Gale and Church, 1991). Our algorithm constructs a simple statistical word-to-word translation model on the fly during alignment. We find the alignment that maximizes the probability of generating the corpus with this translation model. We have achieved an error rate of approximately 0.4% on Canadian Hansard data, which is a significant improvement over previous results. The algorithm is language independent."
            },
            "slug": "Aligning-Sentences-in-Bilingual-Corpora-using-Chen",
            "title": {
                "fragments": [],
                "text": "Aligning Sentences in Bilingual Corpora using Lexical Information"
            },
            "tldr": {
                "abstractSimilarityScore": 56,
                "text": "A fast algorithm for aligning sentences with their translations in a bilingual corpus that constructs a simple statistical word-to-word translation model on the fly during alignment and finds the alignment that maximizes the probability of generating the corpus with this translation model."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2580777"
                        ],
                        "name": "David M. Magerman",
                        "slug": "David-M.-Magerman",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Magerman",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David M. Magerman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1734174"
                        ],
                        "name": "M. Marcus",
                        "slug": "M.-Marcus",
                        "structuredName": {
                            "firstName": "Mitchell",
                            "lastName": "Marcus",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Marcus"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14390678,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8cf9b7c08655dadad0cad00771f3c9670181004e",
            "isKey": false,
            "numCitedBy": 167,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "The purpose of this paper is to characterize a constituent boundary parsing algorithm, using an information-theoretic measure called generalized mutual information, which serves as an alternative to traditional grammar-based parsing methods. This method is based on the hypothesis that constituent boundaries can be extracted from a given sentence (or word sequence) by analyzing the mutual information values of the part of speech n-grams within the sentence. This hypothesis is supported by the performance of an implementation of this parsing algorithm which determines a recursive unlabeled bracketing of unrestricted English text with a relatively low error rate. This paper derives the generalized mutual information statistic, describes the parsing algorithm, and presents results and sample output from the parser."
            },
            "slug": "Parsing-a-Natural-Language-Using-Mutual-Information-Magerman-Marcus",
            "title": {
                "fragments": [],
                "text": "Parsing a Natural Language Using Mutual Information Statistics"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "The generalized mutual information statistic is derived, the parsing algorithm is described, and results and sample output from the parser are presented."
            },
            "venue": {
                "fragments": [],
                "text": "AAAI"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153574717"
                        ],
                        "name": "H. Kaji",
                        "slug": "H.-Kaji",
                        "structuredName": {
                            "firstName": "Hiroyuki",
                            "lastName": "Kaji",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Kaji"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2923399"
                        ],
                        "name": "Yuuko Kida",
                        "slug": "Yuuko-Kida",
                        "structuredName": {
                            "firstName": "Yuuko",
                            "lastName": "Kida",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yuuko Kida"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2054477577"
                        ],
                        "name": "Yasutsugu Morimoto",
                        "slug": "Yasutsugu-Morimoto",
                        "structuredName": {
                            "firstName": "Yasutsugu",
                            "lastName": "Morimoto",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yasutsugu Morimoto"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 17552985,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "44254390973b3d3e6a98f53f1da961addb4d352b",
            "isKey": false,
            "numCitedBy": 198,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper proposes a two-phase example-based machine translation methodology which develops translation templates from examples and then translates using template matching. This method improves translation quality and facilitates customization of machine translation systems. This paper focuses on the automatic learning of translation templates. A translation template is a bilingual pair of sentences in which corresponding units (words and pharases) are coupled and replaced with variables. Correspondence between units is determined by suing a bilingual dictionary and by analyzing the syntactic structure of the sentences. Syntactic ambiguity and ambiguity in correspondence between units are simultaneously resolved. All of the translation templates generated from a bilingual corpus are grouped by their source language part, and then further refined to resolved conflicts among templates whose source language parts are the same but whose target language parts are different. By using the proposed method, not only transfer rules but also knowledge for lexical selection is effectively extracted from a bilingual corpus."
            },
            "slug": "Learning-Translation-Templates-From-Bilingual-Text-Kaji-Kida",
            "title": {
                "fragments": [],
                "text": "Learning Translation Templates From Bilingual Text"
            },
            "tldr": {
                "abstractSimilarityScore": 97,
                "text": "This paper proposes a two-phase example-based machine translation methodology which develops translation templates from examples and then translates using template matching, which improves translation quality and facilitates customization of machine translation systems."
            },
            "venue": {
                "fragments": [],
                "text": "COLING"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145002066"
                        ],
                        "name": "D. Younger",
                        "slug": "D.-Younger",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Younger",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Younger"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 133,
                                "start": 121
                            }
                        ],
                        "text": "Our algorithm is similar in spirit to the recognition algorithm for HMMs (Viterbi 1967) and to CYK parsing (Kasami 1965; Younger 1967)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 40504606,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "30da8ecce8b3ebc3e9344a79e5c2f8dc4c423bd2",
            "isKey": false,
            "numCitedBy": 1035,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Recognition-and-Parsing-of-Context-Free-Languages-Younger",
            "title": {
                "fragments": [],
                "text": "Recognition and Parsing of Context-Free Languages in Time n^3"
            },
            "venue": {
                "fragments": [],
                "text": "Inf. Control."
            },
            "year": 1967
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145366908"
                        ],
                        "name": "Fernando C Pereira",
                        "slug": "Fernando-C-Pereira",
                        "structuredName": {
                            "firstName": "Fernando",
                            "lastName": "Pereira",
                            "middleNames": [
                                "C"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Fernando C Pereira"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1725500"
                        ],
                        "name": "Yves Schabes",
                        "slug": "Yves-Schabes",
                        "structuredName": {
                            "firstName": "Yves",
                            "lastName": "Schabes",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yves Schabes"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 218,
                                "start": 194
                            }
                        ],
                        "text": "Aside from purely linguistic interest, bracket structure has been empirically shown to be highly effective at constraining subsequent training of, for example, stochastic context-free grammars (Pereira and Schabes 1992; Black, Garside, and Leech 1993)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 696805,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0c0eab87d4855c42ae6395bf2e27eefe55003b4a",
            "isKey": false,
            "numCitedBy": 345,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "The inside-outside algorithm for inferring the parameters of a stochastic context-free grammar is extended to take advantage of constituent information in a partially parsed corpus. Experiments on formal and natural language parsed corpora show that the new algorithm can achieve faster convergence and better modelling of hierarchical structure than the original one. In particular, over 90% of the constituents in the most likely analyses of a test set are compatible with test set constituents for a grammar trained on a corpus of 700 hand-parsed part-of-speech strings for ATIS sentences."
            },
            "slug": "Inside-Outside-Reestimation-From-Partially-Corpora-Pereira-Schabes",
            "title": {
                "fragments": [],
                "text": "Inside-Outside Reestimation From Partially Bracketed Corpora"
            },
            "tldr": {
                "abstractSimilarityScore": 78,
                "text": "The inside-outside algorithm for inferring the parameters of a stochastic context-free grammar is extended to take advantage of constituent information in a partially parsed corpus to achieve faster convergence and better modelling of hierarchical structure than the original one."
            },
            "venue": {
                "fragments": [],
                "text": "HLT"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144954740"
                        ],
                        "name": "J. Earley",
                        "slug": "J.-Earley",
                        "structuredName": {
                            "firstName": "Jay",
                            "lastName": "Earley",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Earley"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 35664,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "62ea2ef8b7d98cf3a3b912a62a7a42ee82650e6b",
            "isKey": false,
            "numCitedBy": 1339,
            "numCiting": 44,
            "paperAbstract": {
                "fragments": [],
                "text": "A parsing algorithm which seems to be the most efficient general context-free algorithm known is described. It is similar to both Knuth's LR(<italic>k</italic>) algorithm and the familiar top-down algorithm. It has a time bound proportional to <italic>n</italic><supscrpt>3</supscrpt> (where <italic>n</italic> is the length of the string being parsed) in general; it has an <italic>n</italic><supscrpt>2</supscrpt> bound for unambiguous grammars; and it runs in linear time on a large class of grammars, which seems to include most practical context-free programming language grammars. In an empirical comparison it appears to be superior to the top-down and bottom-up algorithms studied by Griffiths and Petrick."
            },
            "slug": "An-efficient-context-free-parsing-algorithm-Earley",
            "title": {
                "fragments": [],
                "text": "An efficient context-free parsing algorithm"
            },
            "tldr": {
                "abstractSimilarityScore": 72,
                "text": "A parsing algorithm which seems to be the most efficient general context-free algorithm known is described and appears to be superior to the top-down and bottom-up algorithms studied by Griffiths and Petrick."
            },
            "venue": {
                "fragments": [],
                "text": "CACM"
            },
            "year": 1983
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2390150"
                        ],
                        "name": "Dekai Wu",
                        "slug": "Dekai-Wu",
                        "structuredName": {
                            "firstName": "Dekai",
                            "lastName": "Wu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dekai Wu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3181713"
                        ],
                        "name": "Xuanyin Xia",
                        "slug": "Xuanyin-Xia",
                        "structuredName": {
                            "firstName": "Xuanyin",
                            "lastName": "Xia",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xuanyin Xia"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 13934422,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "13a5c0e48580415e825ecba20d6db50b93949c1b",
            "isKey": false,
            "numCitedBy": 119,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "We report experiments on automatic learning of an English-Chinese translation lexicon, through statistical training on a large parallel corpus. The learned vocabulary size is nontrivial at 6,517 English words averaging 2.33 Chinese translations per entry, with a manuallyfiltered precision of 95.1% and a single-most-probable precision of 91.2%. We then introduce a significance filtering method that is fully automatic, yet still yields a weighted precision of 86.0%. Learning of translations is adaptive to the domain. To our knowledge, these are the first empirical results of the kind between an Indo-European and non-Indo-European language for any significant corpus size with a non-toy vocabulary."
            },
            "slug": "Learning-an-English-Chinese-Lexicon-from-a-Parallel-Wu-Xia",
            "title": {
                "fragments": [],
                "text": "Learning an English-Chinese Lexicon from a Parallel Corpus"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "To the authors' knowledge, these are the first empirical results of the kind between an Indo-European and non-Indo-European language for any significant corpus size with a non-toy vocabulary."
            },
            "venue": {
                "fragments": [],
                "text": "AMTA"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32538203"
                        ],
                        "name": "P. Brown",
                        "slug": "P.-Brown",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Brown",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Brown"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2714577"
                        ],
                        "name": "S. D. Pietra",
                        "slug": "S.-D.-Pietra",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Pietra",
                            "middleNames": [
                                "Della"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. D. Pietra"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39944066"
                        ],
                        "name": "V. D. Pietra",
                        "slug": "V.-D.-Pietra",
                        "structuredName": {
                            "firstName": "Vincent",
                            "lastName": "Pietra",
                            "middleNames": [
                                "J.",
                                "Della"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. D. Pietra"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2474650"
                        ],
                        "name": "R. Mercer",
                        "slug": "R.-Mercer",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Mercer",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Mercer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 13259913,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ab7b5917515c460b90451e67852171a531671ab8",
            "isKey": false,
            "numCitedBy": 4745,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a series of five statistical models of the translation process and give algorithms for estimating the parameters of these models given a set of pairs of sentences that are translations of one another. We define a concept of word-by-word alignment between such pairs of sentences. For any given pair of such sentences each of our models assigns a probability to each of the possible word-by-word alignments. We give an algorithm for seeking the most probable of these alignments. Although the algorithm is suboptimal, the alignment thus obtained accounts well for the word-by-word relationships in the pair of sentences. We have a great deal of data in French and English from the proceedings of the Canadian Parliament. Accordingly, we have restricted our work to these two languages; but we feel that because our algorithms have minimal linguistic content they would work well on other pairs of languages. We also feel, again because of the minimal linguistic content of our algorithms, that it is reasonable to argue that word-by-word alignments are inherent in any sufficiently large bilingual corpus."
            },
            "slug": "The-Mathematics-of-Statistical-Machine-Translation:-Brown-Pietra",
            "title": {
                "fragments": [],
                "text": "The Mathematics of Statistical Machine Translation: Parameter Estimation"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "It is reasonable to argue that word-by-word alignments are inherent in any sufficiently large bilingual corpus, given a set of pairs of sentences that are translations of one another."
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Linguistics"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1715952"
                        ],
                        "name": "A. Aho",
                        "slug": "A.-Aho",
                        "structuredName": {
                            "firstName": "Alfred",
                            "lastName": "Aho",
                            "middleNames": [
                                "V."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Aho"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1742391"
                        ],
                        "name": "J. Ullman",
                        "slug": "J.-Ullman",
                        "structuredName": {
                            "firstName": "Jeffrey",
                            "lastName": "Ullman",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Ullman"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 176,
                                "start": 143
                            }
                        ],
                        "text": "\u2026(as well as inversion transduction grammars) are restricted cases of the general class of context-free syntax-directed transduction grammars (Aho and Ullman 1969a, 1969b, 1972); however, we will avoid the term syntax-directed here, so as to de-emphasize the input-output connotation as\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 60775129,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "40dbb25a15b63af3faccb81c8e64a3f5d659e07e",
            "isKey": false,
            "numCitedBy": 1856,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "From volume 1 Preface (See Front Matter for full Preface) \n \nThis book is intended for a one or two semester course in compiling theory at the senior or graduate level. It is a theoretically oriented treatment of a practical subject. Our motivation for making it so is threefold. \n \n(1) In an area as rapidly changing as Computer Science, sound pedagogy demands that courses emphasize ideas, rather than implementation details. It is our hope that the algorithms and concepts presented in this book will survive the next generation of computers and programming languages, and that at least some of them will be applicable to fields other than compiler writing. \n \n(2) Compiler writing has progressed to the point where many portions of a compiler can be isolated and subjected to design optimization. It is important that appropriate mathematical tools be available to the person attempting this optimization. \n \n(3) Some of the most useful and most efficient compiler algorithms, e.g. LR(k) parsing, require a good deal of mathematical background for full understanding. We expect, therefore, that a good theoretical background will become essential for the compiler designer. \n \nWhile we have not omitted difficult theorems that are relevant to compiling, we have tried to make the book as readable as possible. Numerous examples are given, each based on a small grammar, rather than on the large grammars encountered in practice. It is hoped that these examples are sufficient to illustrate the basic ideas, even in cases where the theoretical developments are difficult to follow in isolation. \n \nFrom volume 2 Preface (See Front Matter for full Preface) \n \nCompiler design is one of the first major areas of systems programming for which a strong theoretical foundation is becoming available. Volume I of The Theory of Parsing, Translation, and Compiling developed the relevant parts of mathematics and language theory for this foundation and developed the principal methods of fast syntactic analysis. Volume II is a continuation of Volume I, but except for Chapters 7 and 8 it is oriented towards the nonsyntactic aspects of compiler design. \n \nThe treatment of the material in Volume II is much the same as in Volume I, although proofs have become a little more sketchy. We have tried to make the discussion as readable as possible by providing numerous examples, each illustrating one or two concepts. \n \nSince the text emphasizes concepts rather than language or machine details, a programming laboratory should accompany a course based on this book, so that a student can develop some facility in applying the concepts discussed to practical problems. The programming exercises appearing at the ends of sections can be used as recommended projects in such a laboratory. Part of the laboratory course should discuss the code to be generated for such programming language constructs as recursion, parameter passing, subroutine linkages, array references, loops, and so forth."
            },
            "slug": "The-Theory-of-Parsing,-Translation,-and-Compiling-Aho-Ullman",
            "title": {
                "fragments": [],
                "text": "The Theory of Parsing, Translation, and Compiling"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "It is the hope that the algorithms and concepts presented in this book will survive the next generation of computers and programming languages, and that at least some of them will be applicable to fields other than compiler writing."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1972
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2466657"
                        ],
                        "name": "K. Koskenniemi",
                        "slug": "K.-Koskenniemi",
                        "structuredName": {
                            "firstName": "Kimmo",
                            "lastName": "Koskenniemi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Koskenniemi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 144,
                                "start": 128
                            }
                        ],
                        "text": "Finite-state transducers , or FSTs, are well known to be useful for specific tasks such as analysis of inflectional morphology (Koskenniemi 1983), text-to-speech conversion (Kaplan and Kay 1994), and nominal, number, and temporal phrase normalization (Gazdar and Mellish 1989)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 12819449,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e11ce10eff56df1729626bda3ef6109566f779c9",
            "isKey": false,
            "numCitedBy": 579,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "A language independent model for recognition and production of word forms is presented. This \"two-level model\" is based on a new way of describing morphological alternations. All rules describing the morphophonological variations are parallel and relatively independent of each other. Individual rules are implemented as finite state automata, as in an earlier model due to Martin Kay and Ron Kaplan. The two-level model has been implemented as an operational computer programs in several places. A number of operational two-level descriptions have been written or are in progress (Finnish, English, Japanese, Rumanian, French, Swedish, Old Church Slavonic, Greek, Lappish, Arabic, Icelandic). The model is bidirectional and it is capable of both analyzing and synthesizing word-forms."
            },
            "slug": "A-General-Computational-Model-for-Word-Form-and-Koskenniemi",
            "title": {
                "fragments": [],
                "text": "A General Computational Model for Word-Form Recognition and Production"
            },
            "tldr": {
                "abstractSimilarityScore": 78,
                "text": "A language independent model for recognition and production of word forms is presented, based on a new way of describing morphological alternations that is capable of both analyzing and synthesizing word-forms."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 1984
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "147812033"
                        ],
                        "name": "P. M. Lewis",
                        "slug": "P.-M.-Lewis",
                        "structuredName": {
                            "firstName": "Philip",
                            "lastName": "Lewis",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. M. Lewis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2520473"
                        ],
                        "name": "R. Stearns",
                        "slug": "R.-Stearns",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Stearns",
                            "middleNames": [
                                "Edwin"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Stearns"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 16512120,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2a9d6137c95cc7c106bf84f18fb13449eded7826",
            "isKey": false,
            "numCitedBy": 377,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "A transduction is a mapping from one set of sequences to another. A syntax-directed transduction is a particular type of transduction which is defined on the grammar of a context-free language and which is meant to be a model of part of the translation process used in many compilers. The transduction is considered from an automata theory viewpoint as specifying the input-output relation of a machine. Special consideration is given to machines called translators which both transduce and recognize. In particular, some special conditions are investigated under which syntax-directed translations can be performed on (deterministic) pushdown machines. In addition, some time bounds for translations on Turing machines are derived."
            },
            "slug": "Syntax-Directed-Transduction-Lewis-Stearns",
            "title": {
                "fragments": [],
                "text": "Syntax-Directed Transduction"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "Some special conditions are investigated under which syntax-directed translations can be performed on (deterministic) pushdown machines and some time bounds for translations on Turing machines are derived."
            },
            "venue": {
                "fragments": [],
                "text": "JACM"
            },
            "year": 1968
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32538203"
                        ],
                        "name": "P. Brown",
                        "slug": "P.-Brown",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Brown",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Brown"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3853032"
                        ],
                        "name": "J. Lai",
                        "slug": "J.-Lai",
                        "structuredName": {
                            "firstName": "Jennifer",
                            "lastName": "Lai",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Lai"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2474650"
                        ],
                        "name": "R. Mercer",
                        "slug": "R.-Mercer",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Mercer",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Mercer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 813825,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a76563076016fb1cb813deba45db2409772a51da",
            "isKey": false,
            "numCitedBy": 587,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we describe a statistical technique for aligning sentences with their translations in two parallel corpora. In addition to certain anchor points that are available in our data, the only information about the sentences that we use for calculating alignments is the number of tokens that they contain. Because we make no use of the lexical details of the sentence, the alignment computation is fast and therefore practical for application to very large collections of text. We have used this technique to align several million sentences in the English-French Hansard corpora and have achieved an accuracy in excess of 99% in a random selected set of 1000 sentence pairs that we checked by hand. We show that even without the benefit of anchor points the correlation between the lengths of aligned sentences is strong enough that we should expect to achieve an accuracy of between 96% and 97%. Thus, the technique may be applicable to a wider variety of texts than we have yet tried."
            },
            "slug": "Aligning-Sentences-in-Parallel-Corpora-Brown-Lai",
            "title": {
                "fragments": [],
                "text": "Aligning Sentences in Parallel Corpora"
            },
            "tldr": {
                "abstractSimilarityScore": 65,
                "text": "This paper describes a statistical technique for aligning sentences with their translations in two parallel corpora and shows that even without the benefit of anchor points the correlation between the lengths of aligned sentences is strong enough that it should be expected to achieve an accuracy of between 96% and 97%."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1715952"
                        ],
                        "name": "A. Aho",
                        "slug": "A.-Aho",
                        "structuredName": {
                            "firstName": "Alfred",
                            "lastName": "Aho",
                            "middleNames": [
                                "V."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Aho"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1742391"
                        ],
                        "name": "J. Ullman",
                        "slug": "J.-Ullman",
                        "structuredName": {
                            "firstName": "Jeffrey",
                            "lastName": "Ullman",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Ullman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 177,
                                "start": 157
                            }
                        ],
                        "text": "Parsing form is a noteworthy characteristic of ITGs; no such normal form is available for unrestricted context-free (syntax-directed) transduction grammars (Aho and Ullman 1969b)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 176,
                                "start": 143
                            }
                        ],
                        "text": "\u2026(as well as inversion transduction grammars) are restricted cases of the general class of context-free syntax-directed transduction grammars (Aho and Ullman 1969a, 1969b, 1972); however, we will avoid the term syntax-directed here, so as to de-emphasize the input-output connotation as\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7729404,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9ce84ac66b20d2a56bf972ccd0cab657de44c086",
            "isKey": false,
            "numCitedBy": 79,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Properties-of-Syntax-Directed-Translations-Aho-Ullman",
            "title": {
                "fragments": [],
                "text": "Properties of Syntax Directed Translations"
            },
            "venue": {
                "fragments": [],
                "text": "J. Comput. Syst. Sci."
            },
            "year": 1969
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7465342"
                        ],
                        "name": "Ido Dagan",
                        "slug": "Ido-Dagan",
                        "structuredName": {
                            "firstName": "Ido",
                            "lastName": "Dagan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ido Dagan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2244184"
                        ],
                        "name": "Kenneth Ward Church",
                        "slug": "Kenneth-Ward-Church",
                        "structuredName": {
                            "firstName": "Kenneth",
                            "lastName": "Church",
                            "middleNames": [
                                "Ward"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kenneth Ward Church"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2005310920"
                        ],
                        "name": "W. Gale",
                        "slug": "W.-Gale",
                        "structuredName": {
                            "firstName": "Willian",
                            "lastName": "Gale",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Gale"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 908361,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "23e1993ad65ef984bd11d58463d59f1e3cec1341",
            "isKey": false,
            "numCitedBy": 186,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "We have developed a new program called word_align for aligning parallel text, text such as the Canadian Hansards that are available in two or more languages. The program takes the output of char_align (Church, 1993), a robust alternative to sentence-based alignment programs, and applies word-level constraints using a version of Brown et al.\u2019s Model 2 (Brown et al., 1993), modified and extended to deal with robustness issues. Word_align was tested on a subset of Canadian Hansards supplied by Simard (Simard et al., 1992). The combination of word_align plus char_align reduces the variance (average square error) by a factor of 5 over char_align alone. More importantly, because word_align and char_align were designed to work robustly on texts that are smaller and more noisy than the Hansards, it has been possible to successfully deploy the programs at AT&T Language Line Services, a commercial translation service, to help them with difficult terminology."
            },
            "slug": "Robust-Bilingual-Word-Alignment-for-Machine-Aided-Dagan-Church",
            "title": {
                "fragments": [],
                "text": "Robust Bilingual Word Alignment for Machine Aided Translation"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "Because word_align and char_align were designed to work robustly on texts that are smaller and more noisy than the Hansards, it has been possible to successfully deploy the programs at AT&T Language Line Services, a commercial translation service, to help them with difficult terminology."
            },
            "venue": {
                "fragments": [],
                "text": "VLC@ACL"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145421878"
                        ],
                        "name": "R. Sproat",
                        "slug": "R.-Sproat",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Sproat",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Sproat"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145115135"
                        ],
                        "name": "C. Shih",
                        "slug": "C.-Shih",
                        "structuredName": {
                            "firstName": "Chilin",
                            "lastName": "Shih",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Shih"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34938639"
                        ],
                        "name": "W. Gale",
                        "slug": "W.-Gale",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Gale",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Gale"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145375772"
                        ],
                        "name": "Nancy Chang",
                        "slug": "Nancy-Chang",
                        "structuredName": {
                            "firstName": "Nancy",
                            "lastName": "Chang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nancy Chang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 158,
                                "start": 140
                            }
                        ],
                        "text": "\u2026input text through a word segmentation module (Chiang et al. 1992; Lin, Chiang, and Su 1992, 1993; Chang and Chen 1993; Wu and Tseng 1993; Sproat et al. 1994; Wu and Fung 1994), but, clearly, bilingual parsing will be hampered by any errors arising from segmentation ambiguities that\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5651543,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6945192dcb9de0ff618b13510a1593e90c3242cb",
            "isKey": false,
            "numCitedBy": 314,
            "numCiting": 75,
            "paperAbstract": {
                "fragments": [],
                "text": "The initial stage of text analysis for any NLP task usually involves the tokenization of the input into words. For languages like English one can assume, to a first approximation, that word boundaries are given by whitespace or punctuation. In various Asian languages, including Chinese, on the other hand, whitespace is never used to delimit words, so one must resort to lexical information to \"reconstruct\" the word-boundary information. In this paper we present a stochastic finite-state model wherein the basic workhorse is the weighted finite-state transducer. The model segments Chinese text into dictionary entries and words derived by various productive lexical processes, and---since the primary intended application of this model is to text-to-speech synthesis---provides pronunciations for these words. We evaluate the system's performance by comparing its segmentation \"judgments\" with the judgements of a pool of human segmenters, and the system is shown to perform quite well."
            },
            "slug": "A-Stochastic-Finite-State-Word-Segmentation-for-Sproat-Shih",
            "title": {
                "fragments": [],
                "text": "A Stochastic Finite-State Word-Segmentation Algorithm for Chinese"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This paper presents a stochastic finite-state model wherein the basic workhorse is the weighted finite- state transducer and the model segments Chinese text into dictionary entries and words derived by various productive lexical processes, and provides pronunciations for these words."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32326549"
                        ],
                        "name": "J. Kupiec",
                        "slug": "J.-Kupiec",
                        "structuredName": {
                            "firstName": "Julian",
                            "lastName": "Kupiec",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Kupiec"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 261,
                                "start": 250
                            }
                        ],
                        "text": "Algorithms for subsentential alignment have been developed as well as granularities of the character (Church 1993), word (Dagan, Church, and Gale 1993; Fung and Church 1994; Fung and McKeown 1994), collocation (Smadja 1992), and specially segmented (Kupiec 1993) levels."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 3031527,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "b1bf3d314ad996c394949f88c4091a4832ce0c9b",
            "isKey": false,
            "numCitedBy": 261,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "The paper describes an algorithm that employs English and French text taggers to associate noun phrases in an aligned bilingual corpus. The taggers provide part-of-speech categories which are used by finite-state recognizers to extract simple noun phrases for both languages. Noun phrases are then mapped to each other using an iterative re-estimation algorithm that bears similarities to the Baum-Welch algorithm which is used for training the taggers. The algorithm provides an alternative to other approaches for finding word correspondences, with the advantage that linguistic structure is incorporated. Improvements to the basic algorithm are described, which enable context to be accounted for when constructing the noun phrase mappings."
            },
            "slug": "An-Algorithm-for-finding-Noun-Phrase-in-Bilingual-Kupiec",
            "title": {
                "fragments": [],
                "text": "An Algorithm for finding Noun Phrase Correspondences in Bilingual Corpora"
            },
            "tldr": {
                "abstractSimilarityScore": 69,
                "text": "The paper describes an algorithm that employs English and French text taggers to associate noun phrases in an aligned bilingual corpus and provides an alternative to other approaches for finding word correspondences, with the advantage that linguistic structure is incorporated."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2390150"
                        ],
                        "name": "Dekai Wu",
                        "slug": "Dekai-Wu",
                        "structuredName": {
                            "firstName": "Dekai",
                            "lastName": "Wu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dekai Wu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2144821,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "b83dbea361cd583f9fdfb134bb55c48f0335d297",
            "isKey": false,
            "numCitedBy": 220,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe our experience with automatic alignment of sentences in parallel English-Chinese texts. Our report concerns three related topics: (1) progress on the HKUST English-Chinese Parallel Bilingual Corpus; (2) experiments addressing the applicability of Gale & Church's (1991) length-based statistical method to the task of alignment involving a non-Indo-European language; and (3) an improved statistical method that also incorporates domain-specific lexical cues."
            },
            "slug": "Aligning-a-Parallel-English-Chinese-Corpus-With-Wu",
            "title": {
                "fragments": [],
                "text": "Aligning a Parallel English-Chinese Corpus Statistically With Lexical Criteria"
            },
            "tldr": {
                "abstractSimilarityScore": 70,
                "text": "This report concerns three related topics: progress on the HKUST English-Chinese Parallel Bilingual Corpus; experiments addressing the applicability of Gale & Church's length-based statistical method to the task of alignment involving a non-Indo-European language; and an improved statistical method that also incorporates domain-specific lexical cues."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1803660"
                        ],
                        "name": "R. Kaplan",
                        "slug": "R.-Kaplan",
                        "structuredName": {
                            "firstName": "Ronald",
                            "lastName": "Kaplan",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Kaplan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145493610"
                        ],
                        "name": "M. Kay",
                        "slug": "M.-Kay",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "Kay",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Kay"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 193,
                                "start": 174
                            }
                        ],
                        "text": "Finite-state transducers , or FSTs, are well known to be useful for specific tasks such as analysis of inflectional morphology (Koskenniemi 1983), text-to-speech conversion (Kaplan and Kay 1994), and nominal, number, and temporal phrase normalization (Gazdar and Mellish 1989)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15971472,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6c3f94fc15407398c8f9d4bec893b02ed0dbe452",
            "isKey": false,
            "numCitedBy": 828,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a set of mathematical and computational tools for manipulating and reasoning about regular languages and regular relations and argues that they provide a solid basis for computational phonology. It shows in detail how this framework applies to ordered sets of context-sensitive rewriting rules and also to grammars in Koskenniemi's two-level formalism. This analysis provides a common representation of phonological constraints that supports efficient generation and recognition by a single simple interpreter."
            },
            "slug": "Regular-Models-of-Phonological-Rule-Systems-Kaplan-Kay",
            "title": {
                "fragments": [],
                "text": "Regular Models of Phonological Rule Systems"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This paper shows in detail how this framework applies to ordered sets of context-sensitive rewriting rules and also to grammars in Koskenniemi's two-level formalism."
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Linguistics"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1801071"
                        ],
                        "name": "Frank Smadja",
                        "slug": "Frank-Smadja",
                        "structuredName": {
                            "firstName": "Frank",
                            "lastName": "Smadja",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Frank Smadja"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7177359,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "f98d4d1fb37c5d203185c7b7012363d12db81d56",
            "isKey": false,
            "numCitedBy": 37,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "These sentences are extracted from a corpus of the proccedings of the Canadian Parliament, also called the Hansards corpus. As required by law, the Hansards corpus have both the English and the French for each sentence.The corpus consists of a number of pairs of files, one written in English and the other one in French. We used a version of the Hansards in which the sentences have been aligned with their translations as described in [Church91] 2. Sentence (If) is thus the translation in French of Sentence (le). 3"
            },
            "slug": "How-to-Compile-a-Bilingual-Collocational-Lexicon-.-Smadja",
            "title": {
                "fragments": [],
                "text": "How to Compile a Bilingual Collocational Lexicon . Automatically"
            },
            "tldr": {
                "abstractSimilarityScore": 79,
                "text": "These sentences are extracted from a corpus of the proccedings of the Canadian Parliament, also called the Hansards corpus, andSentence (If) is thus the translation in French of Sentence (le)."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2244184"
                        ],
                        "name": "Kenneth Ward Church",
                        "slug": "Kenneth-Ward-Church",
                        "structuredName": {
                            "firstName": "Kenneth",
                            "lastName": "Church",
                            "middleNames": [
                                "Ward"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kenneth Ward Church"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5703760,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1cf01798f07e1f13cd44daad6119f4978721c61d",
            "isKey": false,
            "numCitedBy": 247,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "There have been a number of recent papers on aligning parallel texts at the sentence level, e.g., Brown et al (1991), Gale and Church (to appear), Isabelle (1992), Kay and Rosenschein (to appear), Simard et al (1992), Warwick-Armstrong and Russell (1990). On clean inputs, such as the Canadian Hansards, these methods have been very successful (at least 96% correct by sentence). Unfortunately, if the input is noisy (due to OCR and/or unknown markup conventions), then these methods tend to break down because the noise can make it difficult to find paragraph boundaries, let alone sentences. This paper describes a new program, char_align, that aligns texts at the character level rather than at the sentence/paragraph level, based on the cognate approach proposed by Simard et al."
            },
            "slug": "Char_align:-A-Program-for-Aligning-Parallel-Texts-Church",
            "title": {
                "fragments": [],
                "text": "Char_align: A Program for Aligning Parallel Texts at the Character Level"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "This paper describes a new program, char_align, that aligns texts at the character level rather than at the sentence/paragraph level, based on the cognate approach proposed by Simard et al."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "37039859"
                        ],
                        "name": "J. Boons",
                        "slug": "J.-Boons",
                        "structuredName": {
                            "firstName": "Jean-Paul",
                            "lastName": "Boons",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Boons"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2078768737"
                        ],
                        "name": "Alain Guillet",
                        "slug": "Alain-Guillet",
                        "structuredName": {
                            "firstName": "Alain",
                            "lastName": "Guillet",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alain Guillet"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 114,
                                "start": 102
                            }
                        ],
                        "text": "FSTs may also be used to parse restricted classes of context-free grammars (Pereira 1991; Roche 1994; Laporte 1996)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15279871,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "43a8c33248cffb0dfed95e2c9b5c3f496faf28ba",
            "isKey": false,
            "numCitedBy": 3,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Analyse syntaxique du frann cais. Grammaire en cha^ ne. Number 2 in Etudes en linguistique frann caise et g en erale. Benjamins, Am-sterdam, 1979. Tom86] Masaru Tomita. EEcient Parsing for Natural Language. A fast algorithm for practical systems. Kluwer, Boston/Dordrecht/Lancaster, 1986. 201 p."
            },
            "slug": "Context-Free-Parsing-With-Finite-State-Transducers-Boons-Guillet",
            "title": {
                "fragments": [],
                "text": "Context-Free Parsing With Finite-State Transducers"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2612754"
                        ],
                        "name": "T. Kasami",
                        "slug": "T.-Kasami",
                        "structuredName": {
                            "firstName": "Tadao",
                            "lastName": "Kasami",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kasami"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 119,
                                "start": 108
                            }
                        ],
                        "text": "Our algorithm is similar in spirit to the recognition algorithm for HMMs (Viterbi 1967) and to CYK parsing (Kasami 1965; Younger 1967)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 61491815,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "af66165c454a0e94afbab36271fe3deaae0b421a",
            "isKey": false,
            "numCitedBy": 608,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract : An efficient algorithm of recognition and syntaxanalysis for the full class of context-free languages without the difficulty of exponential growth of computing time with the length n of input sequence is presented. This algorithm makes use of the essential property of a context-free language as a multi-parenthesis system. It is shown in this paper that a context-free language is n cubed-recognizable in the sense of Hartmanis and Stearns ('Computational complexity of recursive sequences'. Proc. Fifth Annual Symposium of Switching Circuit Theory and Logical Design (Oct. 1964) p.82-90) by a double-tape or double-head single-tape Turing machine and it is n to the 4th power-recognizable by a single-head single-tape Turing machine. If we use a random-access memory whose size is proportional to n cubed, the computing time required for syntaxanalysis is upperbounded by C(1)n cubed + C(2)n squared N, where N denotes the number of nonequivalent valid derivation sequences for a given input sequence and C(i)'s are constants independent of input sequences. If we use a tape of length C(3)n cubed and one of length C(4)n squared as working memories, the computing time for syntax-analysis is upperbounded by C(5)n cubed (1 + N). The size of required memory can be reduced to the order of n squared, but the computing time rises to the order of n to the 4th power. (Author)"
            },
            "slug": "An-Efficient-Recognition-and-Syntax-Analysis-for-Kasami",
            "title": {
                "fragments": [],
                "text": "An Efficient Recognition and Syntax-Analysis Algorithm for Context-Free Languages"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "It is shown in this paper that a context-free language is n cubed-recognizable in the sense of Hartmanis and Stearns and it is n to the 4th power- Recognizable by a single-head single-tape Turing machine."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1965
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1681502"
                        ],
                        "name": "Yuji Matsumoto",
                        "slug": "Yuji-Matsumoto",
                        "structuredName": {
                            "firstName": "Yuji",
                            "lastName": "Matsumoto",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yuji Matsumoto"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2060002072"
                        ],
                        "name": "Hiroyuki Ishimoto",
                        "slug": "Hiroyuki-Ishimoto",
                        "structuredName": {
                            "firstName": "Hiroyuki",
                            "lastName": "Ishimoto",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hiroyuki Ishimoto"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1732417"
                        ],
                        "name": "T. Utsuro",
                        "slug": "T.-Utsuro",
                        "structuredName": {
                            "firstName": "Takehito",
                            "lastName": "Utsuro",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Utsuro"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 155,
                                "start": 119
                            }
                        ],
                        "text": "A number of recent proposals can be cast in this framework (Sadler and Vendelmans 1990; Kaji, Kida, and Morimoto 1992; Matsumoto, Ishimoto, and Utsuro 1993; Cranias, Papageorgiou, and Peperidis 1994; Grishman 1994)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 277,
                                "start": 241
                            }
                        ],
                        "text": "Crossing constraints are implicit in many phrasal matching approaches, both constituency-oriented (Kaji, Kida, and Morimoto 1992; Cranias, Papageorgiou, and Peperidis 1994; Grishman 1994) and dependency-oriented (Sadler and Vendelmans 1990; Matsumoto, Ishimoto, and Utsuro 1993)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 13287721,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "0d8436f85424a450b15015610caf4d5fd4e4321b",
            "isKey": false,
            "numCitedBy": 122,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes a method for finding structural matching between parallel sentences of two languages, (such as Japanese and English). Parallel sentences are analyzed based on unification grammars, and structural matching is performed by making use of a similarity measure of word pairs in the two languages. Syntactic ambiguities are resolved simultaneously in the matching process. The results serve as a useful source for extracting linguistic and lexical knowledge."
            },
            "slug": "Sructural-Matching-of-Parallel-Texts-Matsumoto-Ishimoto",
            "title": {
                "fragments": [],
                "text": "Sructural Matching of Parallel Texts"
            },
            "tldr": {
                "abstractSimilarityScore": 74,
                "text": "This paper describes a method for finding structural matching between parallel sentences of two languages, (such as Japanese and English), and structural matching is performed by making use of a similarity measure of word pairs in the two languages."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2162080"
                        ],
                        "name": "M. Nagao",
                        "slug": "M.-Nagao",
                        "structuredName": {
                            "firstName": "Makoto",
                            "lastName": "Nagao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Nagao"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 111,
                                "start": 101
                            }
                        ],
                        "text": "This requirement is becoming increasingly direct for the example-based machine translation paradigm (Nagao 1984), whose translation flexibility is strongly restricted if the examples are only at the sentential level."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 18366233,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bc43f6bccb18a5a4892daa8e66756e0a684e7f5c",
            "isKey": false,
            "numCitedBy": 678,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Problems inherent in current machine translation systems have been reviewed and have been shown to be inherently inconsistent. The present paper defines a model based on a series of human language processing and in particular the use of analogical thinking. Machine translation systems developed so far have a kind of inherent contradiction in themselves. The more detailed a system has become by the additional improvements, the clearer the limitation and the boundary will be for the translation ability. To break through this difficulty we have to think about the mechanism of human translation, and have to build a model based on the fundamental function of language processing in the human brain. The following is an attempt to do this based on the ability of analogy finding in human beings."
            },
            "slug": "A-framework-of-a-mechanical-translation-between-and-Nagao",
            "title": {
                "fragments": [],
                "text": "A framework of a mechanical translation between Japanese and English by analogy principle"
            },
            "tldr": {
                "abstractSimilarityScore": 36,
                "text": "A model based on a series of human language processing and in particular the use of analogical thinking is defined, based on the ability of analogy finding in human beings."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1981
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "21490655"
                        ],
                        "name": "Victor Sadler",
                        "slug": "Victor-Sadler",
                        "structuredName": {
                            "firstName": "Victor",
                            "lastName": "Sadler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Victor Sadler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3230483"
                        ],
                        "name": "Ronald Vendelmans",
                        "slug": "Ronald-Vendelmans",
                        "structuredName": {
                            "firstName": "Ronald",
                            "lastName": "Vendelmans",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ronald Vendelmans"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 86,
                                "start": 60
                            }
                        ],
                        "text": "A number of recent proposals can be cast in this framework (Sadler and Vendelmans 1990; Kaji, Kida, and Morimoto 1992; Matsumoto, Ishimoto, and Utsuro 1993; Cranias, Papageorgiou, and Peperidis 1994; Grishman 1994)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 239,
                                "start": 213
                            }
                        ],
                        "text": "Crossing constraints are implicit in many phrasal matching approaches, both constituency-oriented (Kaji, Kida, and Morimoto 1992; Cranias, Papageorgiou, and Peperidis 1994; Grishman 1994) and dependency-oriented (Sadler and Vendelmans 1990; Matsumoto, Ishimoto, and Utsuro 1993)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2749381,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "fbdebca0f1cd0b3e0ffcca5d40ad474b1b7ee622",
            "isKey": false,
            "numCitedBy": 58,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "A Bilingual Knowledge Bank is a syntactically and referentially structured pair of corpora, one being a translation of the other, in which translation units are cross-coded between the corpora. A pilot implementation is described for a corpus of some 20,000 words each in English, French and Esperanto which has been cross-coded between English and Esperanto and between Esperanto and French. The aim is to develop a corpus-based general-purpose knowledge source for applications in machine translation and computer-aided translation."
            },
            "slug": "Pilot-Implementation-of-a-Bilingual-Knowledge-Bank-Sadler-Vendelmans",
            "title": {
                "fragments": [],
                "text": "Pilot Implementation of a Bilingual Knowledge Bank"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "A Bilingual Knowledge Bank is a syntactically and referentially structured pair of corpora, one being a translation of the other, in which translation units are cross-coded between the corpora."
            },
            "venue": {
                "fragments": [],
                "text": "COLING"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2390150"
                        ],
                        "name": "Dekai Wu",
                        "slug": "Dekai-Wu",
                        "structuredName": {
                            "firstName": "Dekai",
                            "lastName": "Wu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dekai Wu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1683412"
                        ],
                        "name": "Pascale Fung",
                        "slug": "Pascale-Fung",
                        "structuredName": {
                            "firstName": "Pascale",
                            "lastName": "Fung",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Pascale Fung"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1713067,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8f3e1bbbdc1190ae6320c0520f539337a5ca5927",
            "isKey": false,
            "numCitedBy": 73,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "The first step in Chinese NLP is to tokenize or segment character sequences into words, since the text contains no word delimiters. Recent heavy activity in this area has shown the biggest stumbling block to be words that are absent from the lexicon, since successful tokenizers to date have been based on dictionary lookup (e.g., Chang & Chen 1993; Chiang et al. 1992; Lin et al. 1993; Wu & Tseng 1993; Sproat et al. 1994).We present empirical evidence for four points concerning tokenization of Chinese text: (1) More rigorous \"blind\" evaluation methodology is needed to avoid inflated accuracy measurements; we introduce the nk-blind method. (2) The extent of the unknown-word problem is far more serious than generally thought, when tokenizing unrestricted texts in realistic domains. (3) Statistical lexical acquisition is a practical means to greatly improve tokenization accuracy with unknown words, reducing error rates as much as 32.0%. (4) When augmenting the lexicon, linguistic constraints can provide simple inexpensive filters yielding significantly better precision, reducing error rates as much as 49.4%."
            },
            "slug": "Improving-Chinese-Tokenization-With-Linguistic-On-Wu-Fung",
            "title": {
                "fragments": [],
                "text": "Improving Chinese Tokenization With Linguistic Filters On Statistical Lexical Acquisition"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "Empirical evidence is presented for four points concerning tokenization of Chinese text: more rigorous \"blind\" evaluation methodology is needed to avoid inflated accuracy measurements, the extent of the unknown-word problem is far more serious than generally thought, and the nk-blind method is introduced."
            },
            "venue": {
                "fragments": [],
                "text": "ANLP"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7465342"
                        ],
                        "name": "Ido Dagan",
                        "slug": "Ido-Dagan",
                        "structuredName": {
                            "firstName": "Ido",
                            "lastName": "Dagan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ido Dagan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2244184"
                        ],
                        "name": "Kenneth Ward Church",
                        "slug": "Kenneth-Ward-Church",
                        "structuredName": {
                            "firstName": "Kenneth",
                            "lastName": "Church",
                            "middleNames": [
                                "Ward"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kenneth Ward Church"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 257,
                                "start": 246
                            }
                        ],
                        "text": "\u2026bilingual corpora have been shown to provide a rich source of constraints for statistical analysis (Brown et al. 1990; Gale and Church 1991; Gale, Church, and Yarowsky 1992; Church 1993; Brown et al. 1993; Dagan, Church, and Gale 1993; Fung and Church 1994; Wu and Xia 1994; Fung and McKeown 1994)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 172,
                                "start": 161
                            }
                        ],
                        "text": "Algorithms for subsentential alignment have been developed as well as granularities of the character (Church 1993), word (Dagan, Church, and Gale 1993; Fung and Church 1994; Fung and McKeown 1994), collocation (Smadja 1992), and specially segmented (Kupiec 1993) levels."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2132578,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0ceab4bab5462584b0c6124ba1d95636d50904d0",
            "isKey": false,
            "numCitedBy": 297,
            "numCiting": 41,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a semi-automatic tool, termight, that helps professional translators and terminologists identify technical terms and their translations. The tool makes use of part-of-speech tagging and word-alignment programs to extract candidate terms and their translations. Although the extraction programs are far from perfect, it isn't too hard for the user to filter out the wheat from the chaff. The extraction algorithms emphasize completeness. Alternative proposals are likely to miss important but infrequent terms/translations. To reduce the burden on the user during the filtering phase, candidates are presented in a convenient order, along with some useful concordance evidence, in an interface that is designed to minimize keystrokes. Termight is currently being used by the translators at AT&T Business Translation Services (formerly AT&T Language Line Services)."
            },
            "slug": "Termight:-Identifying-and-Translating-Technical-Dagan-Church",
            "title": {
                "fragments": [],
                "text": "Termight: Identifying and Translating Technical Terminology"
            },
            "tldr": {
                "abstractSimilarityScore": 80,
                "text": "A semi-automatic tool that helps professional translators and terminologists identify technical terms and their translations using part-of-speech tagging and word-alignment programs in an interface designed to minimize keystrokes is proposed."
            },
            "venue": {
                "fragments": [],
                "text": "ANLP"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1683412"
                        ],
                        "name": "Pascale Fung",
                        "slug": "Pascale-Fung",
                        "structuredName": {
                            "firstName": "Pascale",
                            "lastName": "Fung",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Pascale Fung"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2244184"
                        ],
                        "name": "Kenneth Ward Church",
                        "slug": "Kenneth-Ward-Church",
                        "structuredName": {
                            "firstName": "Kenneth",
                            "lastName": "Church",
                            "middleNames": [
                                "Ward"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kenneth Ward Church"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 257,
                                "start": 237
                            }
                        ],
                        "text": "\u2026bilingual corpora have been shown to provide a rich source of constraints for statistical analysis (Brown et al. 1990; Gale and Church 1991; Gale, Church, and Yarowsky 1992; Church 1993; Brown et al. 1993; Dagan, Church, and Gale 1993; Fung and Church 1994; Wu and Xia 1994; Fung and McKeown 1994)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 172,
                                "start": 152
                            }
                        ],
                        "text": "Algorithms for subsentential alignment have been developed as well as granularities of the character (Church 1993), word (Dagan, Church, and Gale 1993; Fung and Church 1994; Fung and McKeown 1994), collocation (Smadja 1992), and specially segmented (Kupiec 1993) levels."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 541539,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "3491aa4a9a66ba3d1603230a70d82c7479666a7d",
            "isKey": false,
            "numCitedBy": 183,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "Various methods have been proposed for aligning texts in two or more languages such as the Canadian Parliamentary Debates (Hansards). Some of these methods generate a bilingual lexicon as a by-product. We present an alternative alignment strategy which we call K-vec, that starts by estimating the lexicon. For example, it discovers that the English word fisheries is similar to the French peches by noting that the distribution of fisheries in the English text is similar to the distribution of p\u00ea'ches in the French. K-vec does not depend on sentence boundaries."
            },
            "slug": "K-vec:-A-New-Approach-for-Aligning-Parallel-Texts-Fung-Church",
            "title": {
                "fragments": [],
                "text": "K-vec: A New Approach for Aligning Parallel Texts"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "An alternative alignment strategy which is presented, which is called K-vec, that starts by estimating the lexicon, that discovers that the English word fisheries is similar to the French peches by noting that the distribution of fisheries in the English text isSimilar to the Distribution of p\u00ea'ches in the French."
            },
            "venue": {
                "fragments": [],
                "text": "COLING"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145493610"
                        ],
                        "name": "M. Kay",
                        "slug": "M.-Kay",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "Kay",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Kay"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2573037"
                        ],
                        "name": "Martin R\u00f6scheisen",
                        "slug": "Martin-R\u00f6scheisen",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "R\u00f6scheisen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Martin R\u00f6scheisen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14531125,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a0b61625e60a419bd5ea1d892047a65a73d9f0c4",
            "isKey": false,
            "numCitedBy": 410,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "We present an algorithm for aligning texts with their translations that is based only on internal evidence. The relaxation process rests on a notion of which word in one text corresponds to which word in the other text that is essentially based on the similarity of their distributions. It exploits a partial alignment of the word level to induce a maximum likelihood alignment of the sentence level, which is in turn used, in the next iteration, to refine the word level estimate. The algorithm appears to converge to the correct sentence alignment in only a few iterations."
            },
            "slug": "Text-Translation-Alignment-Kay-R\u00f6scheisen",
            "title": {
                "fragments": [],
                "text": "Text-Translation Alignment"
            },
            "tldr": {
                "abstractSimilarityScore": 70,
                "text": "An algorithm for aligning texts with their translations that is based only on internal evidence and appears to converge to the correct sentence alignment in only a few iterations is presented."
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Linguistics"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "37022977"
                        ],
                        "name": "Chao-Huang Chang",
                        "slug": "Chao-Huang-Chang",
                        "structuredName": {
                            "firstName": "Chao-Huang",
                            "lastName": "Chang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chao-Huang Chang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35469435"
                        ],
                        "name": "Cheng-Der Chen",
                        "slug": "Cheng-Der-Chen",
                        "structuredName": {
                            "firstName": "Cheng-Der",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Cheng-Der Chen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1555319,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f52b2abd79a3025ee1a2f4d2d7c0769e4f7b2277",
            "isKey": false,
            "numCitedBy": 41,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "Chinese part-of-speech tagging is more difficult than its English counterpart because it needs to be solved together wgh the problem of word identification. In this paper, we present our work on Chinese part-ofspeech tagging based on a first-order, fully-connected hsdden Markov model. Part of the 1991 United Daily corpus of approzimately 10 million Chinese characters zs used for training and testing. A news article is first segmented into clauses, then into words by a Viterbi-based word identification system. The (untagged} segmented corpus is then used to train the HMM for tagging using the Bantu. Welch reestimation procedure. We also adopt Kupiec's concept of word equivalence classes in the tagger. Modeling higher or. der local constraints, a pattern.driven tag corrector is designed to postprocess the tag output of the Vgerbi decoder based on ~rained HMM parameters. Experimental results for various testing conditions are re. ported: The system is able to correctly tag approzimately 96~ of all words in the testing data."
            },
            "slug": "HMM-Based-Part-of-Speech-Tagging-for-Chinese-Chang-Chen",
            "title": {
                "fragments": [],
                "text": "HMM-Based Part-of-Speech Tagging for Chinese Corpora"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This work presents work on Chinese part-of-speech tagging based on a first-order, fully-connected hsdden Markov model that adopts Kupiec's concept of word equivalence classes in the tagger and is able to correctly tag approzimately 96~ of all words in the testing data."
            },
            "venue": {
                "fragments": [],
                "text": "VLC@ACL"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1715952"
                        ],
                        "name": "A. Aho",
                        "slug": "A.-Aho",
                        "structuredName": {
                            "firstName": "Alfred",
                            "lastName": "Aho",
                            "middleNames": [
                                "V."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Aho"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1742391"
                        ],
                        "name": "J. Ullman",
                        "slug": "J.-Ullman",
                        "structuredName": {
                            "firstName": "Jeffrey",
                            "lastName": "Ullman",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Ullman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 177,
                                "start": 157
                            }
                        ],
                        "text": "Parsing form is a noteworthy characteristic of ITGs; no such normal form is available for unrestricted context-free (syntax-directed) transduction grammars (Aho and Ullman 1969b)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 176,
                                "start": 143
                            }
                        ],
                        "text": "\u2026(as well as inversion transduction grammars) are restricted cases of the general class of context-free syntax-directed transduction grammars (Aho and Ullman 1969a, 1969b, 1972); however, we will avoid the term syntax-directed here, so as to de-emphasize the input-output connotation as\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 205894705,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fa5b410d52c1c292cd1a0c984f88b6a0ac9eb448",
            "isKey": false,
            "numCitedBy": 192,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Syntax-Directed-Translations-and-the-Pushdown-Aho-Ullman",
            "title": {
                "fragments": [],
                "text": "Syntax Directed Translations and the Pushdown Assembler"
            },
            "venue": {
                "fragments": [],
                "text": "J. Comput. Syst. Sci."
            },
            "year": 1969
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2047212835"
                        ],
                        "name": "Ziming Wu",
                        "slug": "Ziming-Wu",
                        "structuredName": {
                            "firstName": "Ziming",
                            "lastName": "Wu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ziming Wu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2406147"
                        ],
                        "name": "G. Tseng",
                        "slug": "G.-Tseng",
                        "structuredName": {
                            "firstName": "Gwyneth",
                            "lastName": "Tseng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Tseng"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 6509531,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6067d14c7d684ea68507218eb8bf071f833b867f",
            "isKey": false,
            "numCitedBy": 86,
            "numCiting": 51,
            "paperAbstract": {
                "fragments": [],
                "text": "Present text retrieval systems are generally built on the reductionist basis that words in texts (keywords) are used as indexing terms to represent the texts. A necessary precursor to these systems is word extraction which, for English texts, can be achieved automatically by using spaces and punctuations as word delimiters. This cannot be readily applied to Chinese texts because they do not have obvious word boundaries. A Chinese text consists of a linear sequence of nonspaced or equally spaced ideographic characters, which are similar to morphemes in English. Researchers of Chinese text retrieval have been seeking methods of text segmentation to divide Chinese texts automatically into words. First, a review of these methods is provided in which the various different approaches to Chinese text segmentation have been classified in order to provide a general picture of the research activity in this area. Some of the most important work is described. There follows a discussion of the problems of Chinese text segmentation with examples to illustrate. These problems include morphological complexities, segmentation ambiguity, and parsing problems, and demonstrate that text segmentation remains one of the most challenging and interesting areas for Chinese text retrieval. \u00a9 1993 John Wiley & Sons, Inc."
            },
            "slug": "Chinese-Text-Segmentation-for-Text-Retrieval:-and-Wu-Tseng",
            "title": {
                "fragments": [],
                "text": "Chinese Text Segmentation for Text Retrieval: Achievements and Problems"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "A review of the various different approaches to Chinese text segmentation has been classified in order to provide a general picture of the research activity in this area and demonstrate thatText segmentation remains one of the most challenging and interesting areas for Chinese text retrieval."
            },
            "venue": {
                "fragments": [],
                "text": "J. Am. Soc. Inf. Sci."
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1701400"
                        ],
                        "name": "G. Gazdar",
                        "slug": "G.-Gazdar",
                        "structuredName": {
                            "firstName": "Gerald",
                            "lastName": "Gazdar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Gazdar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145801917"
                        ],
                        "name": "C. Mellish",
                        "slug": "C.-Mellish",
                        "structuredName": {
                            "firstName": "Chris",
                            "lastName": "Mellish",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Mellish"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 275,
                                "start": 252
                            }
                        ],
                        "text": "Finite-state transducers , or FSTs, are well known to be useful for specific tasks such as analysis of inflectional morphology (Koskenniemi 1983), text-to-speech conversion (Kaplan and Kay 1994), and nominal, number, and temporal phrase normalization (Gazdar and Mellish 1989)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7164699,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "00c2b7f24c18f5cc22771fd7551baa69bb6990fb",
            "isKey": false,
            "numCitedBy": 32,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Many people are trying to be smarter every day. How's about you? There are many ways to evoke this case you can find knowledge and lesson everywhere you want. However, it will involve you to get what call as the preferred thing. When you need this kind of sources, the following book can be a great choice. natural language processing in lisp an introduction to computational linguistics is the PDF of the book."
            },
            "slug": "Natural-Language-Processing-in-LISP-an-introduction-Gazdar-Mellish",
            "title": {
                "fragments": [],
                "text": "Natural Language Processing in LISP - an introduction to computational linguistics"
            },
            "tldr": {
                "abstractSimilarityScore": 36,
                "text": "The following book can be a great choice when you need this kind of sources, natural language processing in lisp an introduction to computational linguistics."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1794826"
                        ],
                        "name": "Tung-Hui Chiang",
                        "slug": "Tung-Hui-Chiang",
                        "structuredName": {
                            "firstName": "Tung-Hui",
                            "lastName": "Chiang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tung-Hui Chiang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7972578"
                        ],
                        "name": "Jing-Shin Chang",
                        "slug": "Jing-Shin-Chang",
                        "structuredName": {
                            "firstName": "Jing-Shin",
                            "lastName": "Chang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jing-Shin Chang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2115913603"
                        ],
                        "name": "Ming-Yu Lin",
                        "slug": "Ming-Yu-Lin",
                        "structuredName": {
                            "firstName": "Ming-Yu",
                            "lastName": "Lin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ming-Yu Lin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145718668"
                        ],
                        "name": "Keh-Yih Su",
                        "slug": "Keh-Yih-Su",
                        "structuredName": {
                            "firstName": "Keh-Yih",
                            "lastName": "Su",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Keh-Yih Su"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 119,
                                "start": 101
                            }
                        ],
                        "text": "The usual Chinese NLP architecture first preprocesses input text through a word segmentation module (Chiang et al. 1992; Lin, Chiang, and Su 1992, 1993; Chang and Chen 1993; Wu and Tseng 1993; Sproat et al. 1994; Wu and Fung 1994), but, clearly, bilingual parsing will be hampered by any errors\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 232,
                                "start": 102
                            }
                        ],
                        "text": ") The usual Chinese NLP architecture first preprocesses input text through a word segmentation module (Chiang et al. 1992; Lin, Chiang, and Su 1992, 1993; Chang and Chen 1993; Wu and Tseng 1993; Sproat et al. 1994; Wu and Fung 1994), but, clearly, bilingual parsing will be hampered by any errors arising from segmentation ambiguities that could not be resolved in the isolated monolingual context because even if the Chinese segmentation is acceptable monolingually, it may not agree with the words present in the English sentence."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15163276,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8229ec71d7edb244d548218850cd97aa28b6274e",
            "isKey": false,
            "numCitedBy": 68,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "In a Chinesesentence,thereare no word delimiters, like blanks,betweenthe \u201cwords\u201d. Therefore,it is important to identify the word boundariesbefore processingChinesetext. Traditional approachestend to usedictionary lookup, morphologicalrules and heuristicsto identify the word boundaries.Suchapproachesmay not be appliedto a large systemdueto the complicated linguistic phenomenainvolved in Chinesemorphologyand syntax. In this paper,the variousavailable featuresin a sentenceareusedto constructa generalized word segmentationmodel;thevariousprobabilisticmodelsfor word segmentationarethenderived basedon the generali zed model. In general,the likelihood measureadoptedin a probabilisticmodel doesnot provide a scoringmechanismthatdirectly indicates therealranksof thevariouscandidatesegmentation patterns.To enhancethe baselinemodels,a robustadaptivelearningalgorithm is proposed to adjust the parameter s of the baselinemodelsso as to increasethe discriminationpower and robustnessof the models. The simulation showsthat cost-efective word segmentationcould be achieved under various contextswith the proposedmodels. It is possibleto achieve accuracy in word recognitionrateof 99.39%andsentencerecognitionrateof 97.65%in the testingcorpusby incorporatingword length information to a context-independent word modelandapplyinga robustadaptivelearning algorithm in the segmentationprocess. Sincenot all lexical itemscouldbefoundin thesystemdictionaryin realapplications,the performanceof mostword segmentati on methodsin the literaturemaydegradedsignificantly whenunknownwordsareencountere d. Suchan \u201cunknown word problem\u201d is alsoexamined in this paper. An error recoverymechanismbasedon the segmentationmodel is proposed."
            },
            "slug": "Statistical-Models-for-Word-Segmentation-And-Word-Chiang-Chang",
            "title": {
                "fragments": [],
                "text": "Statistical Models for Word Segmentation And Unknown Word Resolution"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The various available features in a sentence are used to construct a generalized word segmentationmodel and an error recoverymechanism based on the segmentation model is proposed and an robustadaptivelearning algorithm is proposed to adjust the parameter s of the baselinemodels so as to increasethe discriminationpower and robustness of the models."
            },
            "venue": {
                "fragments": [],
                "text": "ROCLING/IJCLCLP"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1683412"
                        ],
                        "name": "Pascale Fung",
                        "slug": "Pascale-Fung",
                        "structuredName": {
                            "firstName": "Pascale",
                            "lastName": "Fung",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Pascale Fung"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145590324"
                        ],
                        "name": "K. McKeown",
                        "slug": "K.-McKeown",
                        "structuredName": {
                            "firstName": "Kathleen",
                            "lastName": "McKeown",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. McKeown"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2135678,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "19cc8befd39c2f8c555918e5be15c33ef5d1c651",
            "isKey": false,
            "numCitedBy": 90,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a new algorithm called DK-vec for aligning pairs of Asian/Indo-European noisy parallel texts without sentence boundaries. DK-vec improves on previous alignment algorithms in that it handles better the non-linear nature of noisy corpora. The algorithm uses frequency, position and recency information as features for pattern matching. Dynamic Time Warping is used as the matching technique between word pairs. This algorithm produces a small bilingual lexicon which provides anchor points for alignment."
            },
            "slug": "Aligning-Noisy-Parallel-Corpora-Across-Language-by-Fung-McKeown",
            "title": {
                "fragments": [],
                "text": "Aligning Noisy Parallel Corpora Across Language Groups: Word Pair Feature Matching by Dynamic Time Warping"
            },
            "tldr": {
                "abstractSimilarityScore": 73,
                "text": "A new algorithm called DK-vec is proposed for aligning pairs of Asian/Indo-European noisy parallel texts without sentence boundaries that handles better the non-linear nature of noisy corpora."
            },
            "venue": {
                "fragments": [],
                "text": "AMTA"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1683412"
                        ],
                        "name": "Pascale Fung",
                        "slug": "Pascale-Fung",
                        "structuredName": {
                            "firstName": "Pascale",
                            "lastName": "Fung",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Pascale Fung"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2390150"
                        ],
                        "name": "Dekai Wu",
                        "slug": "Dekai-Wu",
                        "structuredName": {
                            "firstName": "Dekai",
                            "lastName": "Wu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dekai Wu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 207,
                                "start": 191
                            }
                        ],
                        "text": "\u2026that was automatically learned from the HKUST English-Chinese Parallel Bilingual Corpus via statistical sentence alignment (Wu 1994) and statistical Chinese word and collocation extraction (Fung and Wu 1994; Wu and Fung 1994), followed by an EM word-translation-learning procedure (Wu and Xia 1994)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 12756087,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7a7383b777a6b5b0c8b9b38eb5cb930df5ed243c",
            "isKey": false,
            "numCitedBy": 67,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a method of using statistically-collected Chinese character groups from a corpus to augment a Chinese dictionary. The method is particularly useful for extracting domain-specific and regional words not readily available in machine-readable dictionaries. Output was evaluated both using human evaluators and against a previously available dictionary. We also evaluated performance improvement in automatic Chinese tokenization. Results show that our method outputs legitimate words, acronymic constructions, idioms, names and titles, as well as technical compounds, many of which were lacking from the original dictionary."
            },
            "slug": "Statistical-Augmentation-of-a-Chinese-Dictionary-Fung-Wu",
            "title": {
                "fragments": [],
                "text": "Statistical Augmentation of a Chinese Machine-Readable Dictionary"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "Results show that the method outputs legitimate words, acronymic constructions, idioms, names and titles, as well as technical compounds, many of which were lacking from the original dictionary."
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3195176"
                        ],
                        "name": "L. Cranias",
                        "slug": "L.-Cranias",
                        "structuredName": {
                            "firstName": "Lambros",
                            "lastName": "Cranias",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Cranias"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "36050276"
                        ],
                        "name": "Haris Papageorgiou",
                        "slug": "Haris-Papageorgiou",
                        "structuredName": {
                            "firstName": "Haris",
                            "lastName": "Papageorgiou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Haris Papageorgiou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2954279"
                        ],
                        "name": "S. Piperidis",
                        "slug": "S.-Piperidis",
                        "structuredName": {
                            "firstName": "Stelios",
                            "lastName": "Piperidis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Piperidis"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 58124,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6cfd00fc5a110002595d90ed4714905a71e64a7f",
            "isKey": false,
            "numCitedBy": 62,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper addresses an important problem in Example-Based Machine Translation (EMBT), namely how to measure similarity between a sentence fragment and a set of stored examples. A new method is proposed that measures similarity according to both surface structure and content. A second contribution is the use of clustering to make retrieval of the best matching example from the database more efficient. Results on a large number of test cases from the CELEX database are presented."
            },
            "slug": "A-Matching-Technique-in-Example-Based-Machine-Cranias-Papageorgiou",
            "title": {
                "fragments": [],
                "text": "A Matching Technique in Example-Based Machine Translation"
            },
            "tldr": {
                "abstractSimilarityScore": 95,
                "text": "This paper addresses an important problem in Example-Based Machine Translation (EMBT), namely how to measure similarity between a sentence fragment and a set of stored examples by proposing a new method that measures similarity according to both surface structure and content."
            },
            "venue": {
                "fragments": [],
                "text": "COLING"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32538203"
                        ],
                        "name": "P. Brown",
                        "slug": "P.-Brown",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Brown",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Brown"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144716964"
                        ],
                        "name": "J. Cocke",
                        "slug": "J.-Cocke",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Cocke",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Cocke"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2714577"
                        ],
                        "name": "S. D. Pietra",
                        "slug": "S.-D.-Pietra",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Pietra",
                            "middleNames": [
                                "Della"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. D. Pietra"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39944066"
                        ],
                        "name": "V. D. Pietra",
                        "slug": "V.-D.-Pietra",
                        "structuredName": {
                            "firstName": "Vincent",
                            "lastName": "Pietra",
                            "middleNames": [
                                "J.",
                                "Della"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. D. Pietra"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2472759"
                        ],
                        "name": "F. Jelinek",
                        "slug": "F.-Jelinek",
                        "structuredName": {
                            "firstName": "Frederick",
                            "lastName": "Jelinek",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Jelinek"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1739581"
                        ],
                        "name": "J. Lafferty",
                        "slug": "J.-Lafferty",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Lafferty",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Lafferty"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2474650"
                        ],
                        "name": "R. Mercer",
                        "slug": "R.-Mercer",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Mercer",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Mercer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3069902"
                        ],
                        "name": "P. Roossin",
                        "slug": "P.-Roossin",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Roossin",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Roossin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14386564,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a1066659ec1afee9dce586f6f49b7d44527827e1",
            "isKey": false,
            "numCitedBy": 1940,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we present a statistical approach to machine translation. We describe the application of our approach to translation from French to English and give preliminary results."
            },
            "slug": "A-Statistical-Approach-to-Machine-Translation-Brown-Cocke",
            "title": {
                "fragments": [],
                "text": "A Statistical Approach to Machine Translation"
            },
            "tldr": {
                "abstractSimilarityScore": 51,
                "text": "The application of the statistical approach to translation from French to English and preliminary results are described and the results are given."
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Linguistics"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "52052145"
                        ],
                        "name": "Van Nostrand",
                        "slug": "Van-Nostrand",
                        "structuredName": {
                            "firstName": "Van",
                            "lastName": "Nostrand",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Van Nostrand"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 124355301,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9b5c1d0844714588cf59629cbbc8e5f2e01f4a15",
            "isKey": false,
            "numCitedBy": 1882,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Error-Bounds-for-Convolutional-Codes-and-an-Optimum-Nostrand",
            "title": {
                "fragments": [],
                "text": "Error Bounds for Convolutional Codes and an Asymptotically Optimum Decoding Algorithm"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1967
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2085225921"
                        ],
                        "name": "H. Markov",
                        "slug": "H.-Markov",
                        "structuredName": {
                            "firstName": "H.",
                            "lastName": "Markov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Markov"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "70080674"
                        ],
                        "name": "T. Valtchev",
                        "slug": "T.-Valtchev",
                        "structuredName": {
                            "firstName": "T.",
                            "lastName": "Valtchev",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Valtchev"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "102748049"
                        ],
                        "name": "J. Borissova",
                        "slug": "J.-Borissova",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Borissova",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Borissova"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "101197516"
                        ],
                        "name": "V. Golev",
                        "slug": "V.-Golev",
                        "structuredName": {
                            "firstName": "Valery",
                            "lastName": "Golev",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Golev"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 115379557,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "3ee7bd39e81eee73024f4ec1a22eff0537769ed6",
            "isKey": false,
            "numCitedBy": 131,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "An-algorithm-to-Markov-Valtchev",
            "title": {
                "fragments": [],
                "text": "An algorithm to"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1391514108"
                        ],
                        "name": "G. Gazdar",
                        "slug": "G.-Gazdar",
                        "structuredName": {
                            "firstName": "Gerard",
                            "lastName": "Gazdar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Gazdar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145801917"
                        ],
                        "name": "C. Mellish",
                        "slug": "C.-Mellish",
                        "structuredName": {
                            "firstName": "Chris",
                            "lastName": "Mellish",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Mellish"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 275,
                                "start": 252
                            }
                        ],
                        "text": "Finite-state transducers , or FSTs, are well known to be useful for specific tasks such as analysis of inflectional morphology (Koskenniemi 1983), text-to-speech conversion (Kaplan and Kay 1994), and nominal, number, and temporal phrase normalization (Gazdar and Mellish 1989)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 202791076,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "e66cad9a00fe4a6c3f5c4137dc1a534d87132e67",
            "isKey": false,
            "numCitedBy": 176,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Natural-Language-Processing-in-Pop-11:-An-to-Gazdar-Mellish",
            "title": {
                "fragments": [],
                "text": "Natural Language Processing in Pop-11: An Introduction to Computational Linguistics"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2859514"
                        ],
                        "name": "W. Savitch",
                        "slug": "W.-Savitch",
                        "structuredName": {
                            "firstName": "Walter",
                            "lastName": "Savitch",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Savitch"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 57784602,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4c6dd9f5297c0e4603222a58560877cd031279ba",
            "isKey": false,
            "numCitedBy": 12,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Abstract-machines-and-grammars-Savitch",
            "title": {
                "fragments": [],
                "text": "Abstract machines and grammars"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1982
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2115913603"
                        ],
                        "name": "Ming-Yu Lin",
                        "slug": "Ming-Yu-Lin",
                        "structuredName": {
                            "firstName": "Ming-Yu",
                            "lastName": "Lin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ming-Yu Lin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1794826"
                        ],
                        "name": "Tung-Hui Chiang",
                        "slug": "Tung-Hui-Chiang",
                        "structuredName": {
                            "firstName": "Tung-Hui",
                            "lastName": "Chiang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tung-Hui Chiang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145718668"
                        ],
                        "name": "Keh-Yih Su",
                        "slug": "Keh-Yih-Su",
                        "structuredName": {
                            "firstName": "Keh-Yih",
                            "lastName": "Su",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Keh-Yih Su"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 37590617,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0cba04776c816df09004399c672371fdfb480f65",
            "isKey": false,
            "numCitedBy": 50,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-Preliminary-Study-On-Unknown-Word-Problem-In-Word-Lin-Chiang",
            "title": {
                "fragments": [],
                "text": "A Preliminary Study On Unknown Word Problem In Chinese Word Segmentation"
            },
            "venue": {
                "fragments": [],
                "text": "ROCLING/IJCLCLP"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1946387"
                        ],
                        "name": "Yi-Chung Lin",
                        "slug": "Yi-Chung-Lin",
                        "structuredName": {
                            "firstName": "Yi-Chung",
                            "lastName": "Lin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yi-Chung Lin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1794826"
                        ],
                        "name": "Tung-Hui Chiang",
                        "slug": "Tung-Hui-Chiang",
                        "structuredName": {
                            "firstName": "Tung-Hui",
                            "lastName": "Chiang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tung-Hui Chiang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145718668"
                        ],
                        "name": "Keh-Yih Su",
                        "slug": "Keh-Yih-Su",
                        "structuredName": {
                            "firstName": "Keh-Yih",
                            "lastName": "Su",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Keh-Yih Su"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1022121,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d18b72f441e2ce1c89b94b243e6f39567fb9348e",
            "isKey": false,
            "numCitedBy": 24,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Discrimination-Oriented-Probabilistic-Tagging-Lin-Chiang",
            "title": {
                "fragments": [],
                "text": "Discrimination Oriented Probabilistic Tagging"
            },
            "venue": {
                "fragments": [],
                "text": "ROCLING/IJCLCLP"
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Deriving translation data from bilingual texts"
            },
            "venue": {
                "fragments": [],
                "text": "In"
            },
            "year": 1989
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Deriving translation data from bilingual texts"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the First Lexical Acquisition Workshop"
            },
            "year": 1989
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 119,
                                "start": 108
                            }
                        ],
                        "text": "Our algorithm is similar in spirit to the recognition algorithm for HMMs (Viterbi 1967) and to CYK parsing (Kasami 1965; Younger 1967)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 136,
                                "start": 109
                            }
                        ],
                        "text": "Our algori thm is similar in spirit to the recognition algori thm for HMMs (Viterbi 1967) and to CYK parsing (Kasami 1965; Younger 1967)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "An efficient recognition"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1965
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 218,
                                "start": 207
                            }
                        ],
                        "text": "\u2026be assumed that a parallel bilingual corpus may be aligned to the sentence level with reasonable accuracy (Kay and Ri3cheisen 1988; Catizone, Russel, and Warwick 1989; Gale and Church 1991; Brown, Lai, and Mercer 1991; Chen 1993), even for languages as disparate as Chinese and English (Wu 1994)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Aligning sentences"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1991
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 134,
                                "start": 121
                            }
                        ],
                        "text": "Moreover, if the resources for a good monolingual part-of-speech or grammar-based bracketer such as that of Magerman and Marcus (1990) are available, its output can readily be incorporated in complementary fashion as discussed in Section 9."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 231,
                                "start": 220
                            }
                        ],
                        "text": "Previous algorithms for automatic bracketing operate on monolingual texts and hence require more grammatical constraints; for example , tactics employing mutual information have been applied to tagged text (Magerman and Marcus 1990)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Parsing a natural"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1990
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Iterative alignment"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Context-free parsing"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 297,
                                "start": 276
                            }
                        ],
                        "text": "\u2026bilingual corpora have been shown to provide a rich source of constraints for statistical analysis (Brown et al. 1990; Gale and Church 1991; Gale, Church, and Yarowsky 1992; Church 1993; Brown et al. 1993; Dagan, Church, and Gale 1993; Fung and Church 1994; Wu and Xia 1994; Fung and McKeown 1994)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 195,
                                "start": 174
                            }
                        ],
                        "text": "Algorithms for subsentential alignment have been developed as well as granularities of the character (Church 1993), word (Dagan, Church, and Gale 1993; Fung and Church 1994; Fung and McKeown 1994), collocation (Smadja 1992), and specially segmented (Kupiec 1993) levels."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Aligning noisy parallel corpora Computational Linguistics Number 3 across language groups: Word pair feature matching by dynamic time warping"
            },
            "venue": {
                "fragments": [],
                "text": "AMTA-94, Association for Machine Translation in the Americas"
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 232,
                                "start": 102
                            }
                        ],
                        "text": ") The usual Chinese NLP architecture first preprocesses input text through a word segmentation module (Chiang et al. 1992; Lin, Chiang, and Su 1992, 1993; Chang and Chen 1993; Wu and Tseng 1993; Sproat et al. 1994; Wu and Fung 1994), but, clearly, bilingual parsing will be hampered by any errors arising from segmentation ambiguities that could not be resolved in the isolated monolingual context because even if the Chinese segmentation is acceptable monolingually, it may not agree with the words present in the English sentence."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 158,
                                "start": 140
                            }
                        ],
                        "text": "\u2026input text through a word segmentation module (Chiang et al. 1992; Lin, Chiang, and Su 1992, 1993; Chang and Chen 1993; Wu and Tseng 1993; Sproat et al. 1994; Wu and Fung 1994), but, clearly, bilingual parsing will be hampered by any errors arising from segmentation ambiguities that\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A stochastic word segmentation algorithm for a Mandarin text-to-speech system"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 32nd Annual Meeting,"
            },
            "year": 1994
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 24,
            "methodology": 5
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 60,
        "totalPages": 6
    },
    "page_url": "https://www.semanticscholar.org/paper/Stochastic-Inversion-Transduction-Grammars-and-of-Wu/13b6eeb28328252a35cdcbe3ab8d09d2a9caf99d?sort=total-citations"
}