{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8551365"
                        ],
                        "name": "N. Kushmerick",
                        "slug": "N.-Kushmerick",
                        "structuredName": {
                            "firstName": "Nicholas",
                            "lastName": "Kushmerick",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Kushmerick"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1780531"
                        ],
                        "name": "Daniel S. Weld",
                        "slug": "Daniel-S.-Weld",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Weld",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Daniel S. Weld"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2913159"
                        ],
                        "name": "Robert B. Doorenbos",
                        "slug": "Robert-B.-Doorenbos",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Doorenbos",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Robert B. Doorenbos"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 90,
                                "start": 86
                            }
                        ],
                        "text": "Summarizing our results, we find that most of our wrapper classes are reasonably useful (70% of surveyed sites can be handled in total), yet can rapidly learned (learning usually requires just a handful of examples and a fraction of a CPU second per example)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5119155,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f9e7402ad740b73cc0bb64178f86df3478c3aaf5",
            "isKey": false,
            "numCitedBy": 1283,
            "numCiting": 83,
            "paperAbstract": {
                "fragments": [],
                "text": "Many Internet information resources present relational data|telephone directories, product catalogs, etc. Because these sites are formatted for people, mechanically extracting their content is di cult. Systems using such resources typically use hand-coded wrappers, procedures to extract data from information resources. We introduce wrapper induction, a method for automatically constructing wrappers, and identify hlrt, a wrapper class that is e ciently learnable, yet expressive enough to handle 48% of a recently surveyed sample of Internet resources. We use PAC analysis to bound the problem's sample complexity, and show that the system degrades gracefully with imperfect labeling knowledge."
            },
            "slug": "Wrapper-Induction-for-Information-Extraction-Kushmerick-Weld",
            "title": {
                "fragments": [],
                "text": "Wrapper Induction for Information Extraction"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This work introduces wrapper induction, a method for automatically constructing wrappers, and identifies hlrt, a wrapper class that is e ciently learnable, yet expressive enough to handle 48% of a recently surveyed sample of Internet resources."
            },
            "venue": {
                "fragments": [],
                "text": "IJCAI"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3276863"
                        ],
                        "name": "Ion Muslea",
                        "slug": "Ion-Muslea",
                        "structuredName": {
                            "firstName": "Ion",
                            "lastName": "Muslea",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ion Muslea"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145293454"
                        ],
                        "name": "Steven Minton",
                        "slug": "Steven-Minton",
                        "structuredName": {
                            "firstName": "Steven",
                            "lastName": "Minton",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Steven Minton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1745117"
                        ],
                        "name": "Craig A. Knoblock",
                        "slug": "Craig-A.-Knoblock",
                        "structuredName": {
                            "firstName": "Craig",
                            "lastName": "Knoblock",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Craig A. Knoblock"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 172,
                                "start": 168
                            }
                        ],
                        "text": "report that STALKER is 4-fold slowerlearnHLRT for one domain, 12-fold faster in a second, and our six classes are not expressive enough to handle several other domains [60]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 177,
                                "start": 161
                            }
                        ],
                        "text": "community has focused on free text [16,43,62,72], while the information integration and software agent communities have focused on structured Internet documents [9,11,41,52, 60]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[60] describeSTALKER, an algorithm for learning a wrapper language that, like SOFTMEALY, allows disjunction and reordered or missing attributes."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 3514097,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1cc263c84b85027164bd39db169f5d5959ef6822",
            "isKey": false,
            "numCitedBy": 464,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "With the tremendous amount of information that becomes available on the Web on a daily basis, the ability to quickly develop information agents has become a crucial problem. A vital component of any Web-based information agent is a set of wrappers that can extract the relevant data from semistructured information sources. Our novel approach to wrapper induction is based on the idea of hierarchical information extraction, which turns the hard problem of extracting data from an arbitrarily complex document into a series of easier extraction tasks. We introduce an inductive algorithm, STALKER, that generates high accuracy extraction rules based on user-labeled training examples. Labeling the training data represents the major bottleneck in using wrapper induction techniques, and our experimental results show that STALKER does significantly better then other approaches; on one hand, STALKER requires up to two orders of magnitude fewer examples than other algorithms, while on the other hand it can handle information sources that could not be wrapped by existing techniques."
            },
            "slug": "A-hierarchical-approach-to-wrapper-induction-Muslea-Minton",
            "title": {
                "fragments": [],
                "text": "A hierarchical approach to wrapper induction"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This work introduces an inductive algorithm, STALKER, that generates high accuracy extraction rules based on user-labeled training examples that can handle information sources that could not be wrapped by existing techniques."
            },
            "venue": {
                "fragments": [],
                "text": "AGENTS '99"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34607455"
                        ],
                        "name": "Chun-Nan Hsu",
                        "slug": "Chun-Nan-Hsu",
                        "structuredName": {
                            "firstName": "Chun-Nan",
                            "lastName": "Hsu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chun-Nan Hsu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2094164369"
                        ],
                        "name": "Ming-Tzung Dung",
                        "slug": "Ming-Tzung-Dung",
                        "structuredName": {
                            "firstName": "Ming-Tzung",
                            "lastName": "Dung",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ming-Tzung Dung"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "community has focused on free text [16,43,62,72], while the information integration and software agent communities have focused on structured Internet documents [9,11,41,52, 60]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "1 that our six classes can not handle [41]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Hsu and Dung [41] present SOFTMEALY."
                    },
                    "intents": []
                }
            ],
            "corpusId": 17895561,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f9478265afd280486299a5b8f1dbaaf6769422de",
            "isKey": false,
            "numCitedBy": 507,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Generating-Finite-State-Transducers-for-Data-from-Hsu-Dung",
            "title": {
                "fragments": [],
                "text": "Generating Finite-State Transducers for Semi-Structured Data Extraction from the Web"
            },
            "venue": {
                "fragments": [],
                "text": "Inf. Syst."
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2178614"
                        ],
                        "name": "N. Ashish",
                        "slug": "N.-Ashish",
                        "structuredName": {
                            "firstName": "Naveen",
                            "lastName": "Ashish",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Ashish"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1745117"
                        ],
                        "name": "Craig A. Knoblock",
                        "slug": "Craig-A.-Knoblock",
                        "structuredName": {
                            "firstName": "Craig",
                            "lastName": "Knoblock",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Craig A. Knoblock"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 177,
                                "start": 161
                            }
                        ],
                        "text": "community has focused on free text [16,43,62,72], while the information integration and software agent communities have focused on structured Internet documents [9,11,41,52, 60]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 38,
                                "start": 33
                            }
                        ],
                        "text": ", using the regular expression \u2018 [1-9][0-9]+ \u2019 to identify country codes."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 23,
                                "start": 20
                            }
                        ],
                        "text": "Ashish and Knoblock [9] describe a semi-automatic technique for wrapper induction that uses HTML-specific heuristics to generate plausible segmentations of a document, and plausible items for extraction within a segment."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 8200914,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "15b3cd323910de0551c680e8dae27d7413494a46",
            "isKey": false,
            "numCitedBy": 210,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "To simplify the task of obtaining information from the vast number of information sources that are available on the World Wide Web (WWW), the authors are building information mediators for extracting and integrating data from multiple Web sources. In a mediator based approach, wrappers are built around individual information sources to translate between the mediator query language and the individual sources. They present an approach for semi-automatically generating wrappers for structured Internet sources. The key idea is to exploit formatting information in Web pages to hypothesize the underlying structure of a page. From this structure the system generates a wrapper that facilitates querying of a source and possibly integrating it with other sources. They demonstrate the ease with which they are able to build wrappers for a number of Web sources using their implemented wrapper generation toolkit."
            },
            "slug": "Semi-automatic-wrapper-generation-for-Internet-Ashish-Knoblock",
            "title": {
                "fragments": [],
                "text": "Semi-automatic wrapper generation for Internet information sources"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "The key idea is to exploit formatting information in Web pages to hypothesize the underlying structure of a page and generate a wrapper that facilitates querying of a source and possibly integrating it with other sources."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of CoopIS 97: 2nd IFCIS Conference on Cooperative Information Systems"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2955985"
                        ],
                        "name": "J. Gruser",
                        "slug": "J.-Gruser",
                        "structuredName": {
                            "firstName": "Jean-Robert",
                            "lastName": "Gruser",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Gruser"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733877"
                        ],
                        "name": "L. Raschid",
                        "slug": "L.-Raschid",
                        "structuredName": {
                            "firstName": "Louiqa",
                            "lastName": "Raschid",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Raschid"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143858195"
                        ],
                        "name": "Maria-Esther Vidal",
                        "slug": "Maria-Esther-Vidal",
                        "structuredName": {
                            "firstName": "Maria-Esther",
                            "lastName": "Vidal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Maria-Esther Vidal"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144363438"
                        ],
                        "name": "Laura Bright",
                        "slug": "Laura-Bright",
                        "structuredName": {
                            "firstName": "Laura",
                            "lastName": "Bright",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Laura Bright"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 169,
                                "start": 147
                            }
                        ],
                        "text": "There has been substantial research on specialized programming languages and graphical user interfaces to assist in manually writing such wrappers [3,25,37,39,42,63, 69]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 334566,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "827c3ad17c48d6f0b0cb0c26610f1624fa973536",
            "isKey": false,
            "numCitedBy": 103,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "There is an increase in the number of data sources that can be queried across the WWW. Such sources typically support HTML forms-based interfaces and search engines query collections of suitably indexed data. The data is displayed via a browser: One drawback to these sources is that there is no standard programming interface suitable for applications to submit queries. Second, the output (answer to a query) is not well structured. Structured objects have to be extracted from the HTML documents which contain irrelevant data and which may be volatile. Third, domain knowledge about the data source is also embedded in HTML documents and must be extracted. To solve these problems, we present technology to define and (automatically) generate wrappers for Web accessible sources. Our contributions are as follows: (1) Defining a wrapper interface to specify the capability of Web accessible data sources. (2) Developing a wrapper generation toolkit of graphical interfaces and specification languages to specify the capability of sources and the functionality of the wrapper (3) Developing the technology to automatically generate a wrapper appropriate to the Web accessible source, from the specifications."
            },
            "slug": "Wrapper-generation-for-Web-accessible-data-sources-Gruser-Raschid",
            "title": {
                "fragments": [],
                "text": "Wrapper generation for Web accessible data sources"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This work presents technology to define and (automatically) generate wrappers for Web accessible sources and develops a wrapper generation toolkit of graphical interfaces and specification languages to specify the capability of sources and the functionality of the wrapper."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings. 3rd IFCIS International Conference on Cooperative Information Systems (Cat. No.98EX122)"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1758106"
                        ],
                        "name": "Dayne Freitag",
                        "slug": "Dayne-Freitag",
                        "structuredName": {
                            "firstName": "Dayne",
                            "lastName": "Freitag",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dayne Freitag"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 17,
                                "start": 10
                            }
                        ],
                        "text": "\u2022 Freitag [33,34] describes theSRV system."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 138,
                                "start": 128
                            }
                        ],
                        "text": "This distinction has started to blur, as researchers have started to evaluate their systems on both structured and natural text [33,70,71]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 8125917,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "dd7cee21074ea6b346011d7463f7387ad9bfcc2a",
            "isKey": false,
            "numCitedBy": 313,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "Because the World Wide Web consists primarily of text, information extraction is central to any effort that would use the Web as a resource for knowledge discovery. We show how information extraction can be cast as a standard machine learning problem, and argue for the suitability of relational learning in solving it. The implementation of a general-purpose relational learner for information extraction, SRV, is described. In contrast with earlier learning systems for information extraction, SRV makes no assumptions about document structure and the kinds of information available for use in learning extraction patterns. Instead, structural and other information is supplied as input in the form of an extensible token-oriented feature set. We demonstrate the effectiveness of this approach by adapting SRV for use in learning extraction rules for a domain consisting of university course and research project pages sampled from the Web. Making SRV Web-ready only involves adding several simple HTML-specific features to its basic feature set."
            },
            "slug": "Information-Extraction-from-HTML:-Application-of-a-Freitag",
            "title": {
                "fragments": [],
                "text": "Information Extraction from HTML: Application of a General Machine Learning Approach"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This work shows how information extraction can be cast as a standard machine learning problem, and argues for the suitability of relational learning in solving it, and the implementation of a general-purpose relational learner for information extraction, SRV."
            },
            "venue": {
                "fragments": [],
                "text": "AAAI/IAAI"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2441542"
                        ],
                        "name": "G. Huck",
                        "slug": "G.-Huck",
                        "structuredName": {
                            "firstName": "Gerald",
                            "lastName": "Huck",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Huck"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144137629"
                        ],
                        "name": "P. Fankhauser",
                        "slug": "P.-Fankhauser",
                        "structuredName": {
                            "firstName": "P\u00e9ter",
                            "lastName": "Fankhauser",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Fankhauser"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751802"
                        ],
                        "name": "K. Aberer",
                        "slug": "K.-Aberer",
                        "structuredName": {
                            "firstName": "Karl",
                            "lastName": "Aberer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Aberer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1720826"
                        ],
                        "name": "E. Neuhold",
                        "slug": "E.-Neuhold",
                        "structuredName": {
                            "firstName": "Erich",
                            "lastName": "Neuhold",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Neuhold"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 169,
                                "start": 147
                            }
                        ],
                        "text": "There has been substantial research on specialized programming languages and graphical user interfaces to assist in manually writing such wrappers [3,25,37,39,42,63, 69]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2538164,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "62c9b4c353afad20f9a1f1d59060066d5aceb708",
            "isKey": false,
            "numCitedBy": 164,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "Jedi (Java based Extraction and Dissemination of Information) is a lightweight tool for the creation of wrappers and mediators to extract, combine, and reconcile information from several independent information sources. For wrappers it uses attributed grammars, which are evaluated with a fault-tolerant parsing strategy to cope with ambiguous grammars and irregular sources. For mediation it uses a simple generic object-model that can be extended with Java-libraries for specific models such as HTML, XML or the relational model. This paper describes the architecture of Jedi, and then focuses on Jedi's wrapper generator."
            },
            "slug": "Jedi:-extracting-and-synthesizing-information-from-Huck-Fankhauser",
            "title": {
                "fragments": [],
                "text": "Jedi: extracting and synthesizing information from the Web"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "The architecture of Jedi is described, and then the focus is on Jedi's wrapper generator."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings. 3rd IFCIS International Conference on Cooperative Information Systems (Cat. No.98EX122)"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8551365"
                        ],
                        "name": "N. Kushmerick",
                        "slug": "N.-Kushmerick",
                        "structuredName": {
                            "firstName": "Nicholas",
                            "lastName": "Kushmerick",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Kushmerick"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 132,
                                "start": 128
                            }
                        ],
                        "text": "We then turn toefficiency: we measure the number of examples and time required to learn wrappers in each class, and we compare these results to PAC models of our task and asymptotic complexity analyses of our algorithms."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                }
            ],
            "corpusId": 5876617,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d060dec4bf295ba459b197288e05807bbd5c51a5",
            "isKey": false,
            "numCitedBy": 96,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "Recent work on Internet information integration assumes a library of wrappers, specialized information extraction procedures. Maintaining wrappers is difficult, because the formatting regularities on which they rely often change. The wrapper verification problem is to determine whether a wrapper is correct. Standard regression testing approaches are inappropriate, because both the formatting regularities and a site's underlying content may change. Wei ntroduce RAPTURE, a fully-implemented, domain-independenvt erification algorithm. RAPTURE uses well-motivated heuristics to compute the similarity between a wrapper's expected and observed output. Experiments with 27 actual Internet sites show a substantial performance improvement over standard regression testing."
            },
            "slug": "Regression-testing-for-wrapper-maintenance-Kushmerick",
            "title": {
                "fragments": [],
                "text": "Regression testing for wrapper maintenance"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "RAPTURE is a fully-implemented, domain-independenvt erification algorithm that uses well-motivated heuristics to compute the similarity between a wrapper's expected and observed output."
            },
            "venue": {
                "fragments": [],
                "text": "AAAI/IAAI"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1802339"
                        ],
                        "name": "M. Pazienza",
                        "slug": "M.-Pazienza",
                        "structuredName": {
                            "firstName": "Maria",
                            "lastName": "Pazienza",
                            "middleNames": [
                                "Teresa"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Pazienza"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 133,
                                "start": 126
                            }
                        ],
                        "text": "Information extraction (IE) is the task of identifying fragments in a document that constitute its core semantic content; see [22,40] for surveys."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1102517,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "06894f06b6411af67a0ffde61d27efd86a5d31c7",
            "isKey": false,
            "numCitedBy": 916,
            "numCiting": 55,
            "paperAbstract": {
                "fragments": [],
                "text": "It seems widely agreed that IE (Information Extraction) is now a tested language technology that has reached precision+recall values that put it in about the same position as Information Retrieval and Machine Translation, both of which are widely used commercially. There is also a clear range of practical applications that would be eased by the sort of template-style data that IE provides. The problem for wider deployment of the technology is adaptability: the ability to customize IE rapidly to new domains. In this paper we discuss some methods that have been tried to ease this problem, and to create something more rapid than the bench-mark one-month figure, which was roughly what ARPA teams in IE needed to adapt an existing system by hand to a new domain of corpora and templates. An important distinction in discussing the issue is the degree to which a user can be assumed to know what is wanted, to have preexisting templates ready to hand, as opposed to a user who has a vague idea of what is needed from a corpus. We shall discuss attempts to derive templates directly from corpora; to derive knowledge structures and lexicons directly from corpora, including discussion of the recent LE project ECRAN which attempted to tune existing lexicons to new corpora. An important issue is how far established methods in Information Retrieval of tuning to a user\u2019s needs with feedback at an interface can be transferred to IE."
            },
            "slug": "Information-Extraction-Pazienza",
            "title": {
                "fragments": [],
                "text": "Information Extraction"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "This paper discusses attempts to derive templates directly from corpora; to derive knowledge structures and lexicons directly from Corpora, including discussion of the recent LE project ECRAN which attempted to tune existing lexicons to new corpora."
            },
            "venue": {
                "fragments": [],
                "text": "Lecture Notes in Computer Science"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1758106"
                        ],
                        "name": "Dayne Freitag",
                        "slug": "Dayne-Freitag",
                        "structuredName": {
                            "firstName": "Dayne",
                            "lastName": "Freitag",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dayne Freitag"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 86,
                                "start": 82
                            }
                        ],
                        "text": "is combined with other learning algorithms in a \u201cmultistrategy learning\u201d approach [35]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 16677640,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "29c99d263b5e05aae6bb96f004f025dcc9b5caae",
            "isKey": false,
            "numCitedBy": 126,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "Information extraction IE is the problem of lling out pre de ned structured sum maries from text documents We are in terested in performing IE in non traditional domains where much of the text is often ungrammatical such as electronic bulletin board posts and Web pages We suggest that the best approach is one that takes into ac count many di erent kinds of information and argue for the suitability of a multistrat egy approach We describe learners for IE drawn from three separate machine learning paradigms rote memorization term space text classi cation and relational rule induc tion By building regression models mapping from learner con dence to probability of cor rectness and combining probabilities appro priately it is possible to improve extraction accuracy over that achieved by any individ ual learner We describe three di erent mul tistrategy approaches Experiments on two IE domains a collection of electronic seminar announcements from a university computer science department and a set of newswire ar ticles describing corporate acquisitions from the Reuters collection demonstrate the e ec tiveness of all three approaches"
            },
            "slug": "Multistrategy-Learning-for-Information-Extraction-Freitag",
            "title": {
                "fragments": [],
                "text": "Multistrategy Learning for Information Extraction"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "It is possible to improve extraction accuracy over that achieved by any individ ual learner by building regression models mapping from learner con dence to probability of cor rectness and combining probabilities."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2105119697"
                        ],
                        "name": "Jonathan Shakes",
                        "slug": "Jonathan-Shakes",
                        "structuredName": {
                            "firstName": "Jonathan",
                            "lastName": "Shakes",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jonathan Shakes"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47085377"
                        ],
                        "name": "Marc Langheinrich",
                        "slug": "Marc-Langheinrich",
                        "structuredName": {
                            "firstName": "Marc",
                            "lastName": "Langheinrich",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Marc Langheinrich"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1741101"
                        ],
                        "name": "Oren Etzioni",
                        "slug": "Oren-Etzioni",
                        "structuredName": {
                            "firstName": "Oren",
                            "lastName": "Etzioni",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Oren Etzioni"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 94,
                                "start": 78
                            }
                        ],
                        "text": "We were strongly influenced by the University of Washington \u201cSoftbot\u201d project [23,26,30,66,67]; related projects include ARIADNE [46], CARNOT [21], DISCO [32], GARLIC [18], HERMES [2], the Information Manifold [55],TSIMMIS [19], FUSION [68], BargainFinder [49], and the Knowledge Broker [4]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 40413824,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "32c4fd87ccccf21880ff70f46875788942a66311",
            "isKey": false,
            "numCitedBy": 114,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Dynamic-Reference-Sifting:-A-Case-Study-in-the-Shakes-Langheinrich",
            "title": {
                "fragments": [],
                "text": "Dynamic Reference Sifting: A Case Study in the Homepage Domain"
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Networks"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694279"
                        ],
                        "name": "D. Embley",
                        "slug": "D.-Embley",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Embley",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Embley"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145887845"
                        ],
                        "name": "D. M. Campbell",
                        "slug": "D.-M.-Campbell",
                        "structuredName": {
                            "firstName": "Douglas",
                            "lastName": "Campbell",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. M. Campbell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2158090475"
                        ],
                        "name": "Y. S. Jiang",
                        "slug": "Y.-S.-Jiang",
                        "structuredName": {
                            "firstName": "Y.",
                            "lastName": "Jiang",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. S. Jiang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1742211"
                        ],
                        "name": "Stephen W. Liddle",
                        "slug": "Stephen-W.-Liddle",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Liddle",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Stephen W. Liddle"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143743807"
                        ],
                        "name": "Yiu-Kai Ng",
                        "slug": "Yiu-Kai-Ng",
                        "structuredName": {
                            "firstName": "Yiu-Kai",
                            "lastName": "Ng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yiu-Kai Ng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144259075"
                        ],
                        "name": "D. Quass",
                        "slug": "D.-Quass",
                        "structuredName": {
                            "firstName": "Dallan",
                            "lastName": "Quass",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Quass"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108985589"
                        ],
                        "name": "Randy D. Smith",
                        "slug": "Randy-D.-Smith",
                        "structuredName": {
                            "firstName": "Randy",
                            "lastName": "Smith",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Randy D. Smith"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 169,
                                "start": 147
                            }
                        ],
                        "text": "There has been substantial research on specialized programming languages and graphical user interfaces to assist in manually writing such wrappers [3,25,37,39,42,63, 69]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1589294,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f3ea8d41b57e74cf5c4815fbd20982719dea768f",
            "isKey": false,
            "numCitedBy": 84,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "Electronically available data on the Web is exploding at an ever increasing pace. Much of this data is unstructured, which makes searching hard and traditional database querying impossible. Many Web documents, however, contain an abundance of recognizable constants that together describe the essence of a document\u2019s content. For these kinds of data-rich documents (e.g., advertisements, movie reviews, weather reports, travel information, sports summaries, financial statements, obituaries, and many others) we can apply a conceptual-modeling approach to extract and structure data. The approach is based on an ontology \u2013 a conceptual model instance \u2013 that describes the data of interest, including relationships, lexical appearance, and context keywords. By parsing the ontology, we can automatically produce a database scheme and recognizers for constants and keywords, and then invoke routines to recognize and extract data from unstructured documents and structure it according to the generated database scheme. Experiments show that it is possible to achieve good recall and precision ratios for documents that are rich in recognizable constants and narrow in ontological breadth."
            },
            "slug": "A-Conceptual-Modeling-Approach-to-Extracting-Data-Embley-Campbell",
            "title": {
                "fragments": [],
                "text": "A Conceptual-Modeling Approach to Extracting Data from the Web"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "Experiments show that it is possible to achieve good recall and precision ratios for documents that are rich in recognizable constants and narrow in ontological breadth."
            },
            "venue": {
                "fragments": [],
                "text": "ER"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1741101"
                        ],
                        "name": "Oren Etzioni",
                        "slug": "Oren-Etzioni",
                        "structuredName": {
                            "firstName": "Oren",
                            "lastName": "Etzioni",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Oren Etzioni"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "The learning algorithms described in Sections 3 and 4 are steps toward our goal of automatic wrapper construction, but the labeling problem [27] remains: our learning algorithms require not just the example pages (e."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 3353849,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5f9b342307b1149615a49486ff7d2abf783314ff",
            "isKey": false,
            "numCitedBy": 706,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "Skeptics believe the Web is too unstructured for Web mining to succeed. Indeed, data mining has been applied traditionally to databases, yet much of the information on the Web lies buried in documents designed for human consumption such as home pages or product catalogs. Furthermore, much of the information on the Web is presented in natural-language text with no machine-readable semantics; HTML annotations structure the display of Web pages, but provide little insight into their content. Some have advocated transforming the Web into a massive layered database to facilitate data mining [12], but the Web is too dynamic and chaotic to be tamed in this manner. Others have attempted to hand code site-specific \u201cwrappers\u201d that facilitate the extraction of information from individual Web resources (e.g., [8]). Hand coding is convenient but cannot keep up with the explosive growth of the Web. As an alternative, this article argues for the structured Web hypothesis: Information on the Web is sufficiently structured to facilitate effective Web mining. Examples of Web structure include linguistic and typographic conventions, HTML annotations (e.g., <title>), classes of semi-structured documents (e.g., product catalogs), Web indices and directories, and much more. To support the structured Web hypothesis, this article will survey preliminary Web mining successes and suggest directions for future work. Web mining may be organized into the following subtasks:"
            },
            "slug": "The-World-Wide-Web:-quagmire-or-gold-mine-Etzioni",
            "title": {
                "fragments": [],
                "text": "The World-Wide Web: quagmire or gold mine?"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "Information on the Web is sufficiently structured to facilitate effective Web mining, according to the structured Web hypothesis, and preliminary Web mining successes are surveyed and directions for future work are suggested."
            },
            "venue": {
                "fragments": [],
                "text": "CACM"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2832139"
                        ],
                        "name": "B. Adelberg",
                        "slug": "B.-Adelberg",
                        "structuredName": {
                            "firstName": "Brad",
                            "lastName": "Adelberg",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Adelberg"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 169,
                                "start": 147
                            }
                        ],
                        "text": "There has been substantial research on specialized programming languages and graphical user interfaces to assist in manually writing such wrappers [3,25,37,39,42,63, 69]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 38,
                                "start": 33
                            }
                        ],
                        "text": ", using the regular expression \u2018 [1-9][0-9]+ \u2019 to identify country codes."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 15329383,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "30cad07f9c314777641b9d1bfa60eb0c7bf58fac",
            "isKey": false,
            "numCitedBy": 344,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "Often interesting structured or semistructured data is not in database systems but in HTML pages, text files, or on paper. The data in these formats is not usable by standard query processing engines and hence users need a way of extracting data from these sources into a DBMS or of writing wrappers around the sources. This paper describes NoDoSE, the Northwestern Document Structure Extractor, which is an interactive tool for semi-automatically determining the structure of such documents and then extracting their data. Using a GUI, the user hierarchically decomposes the file, outlining its interesting regions and then describing their semantics. This task is expedited by a mining component that attempts to infer the grammar of the file from the information the user has input so far. Once the format of a document has been determined, its data can be extracted into a number of useful forms. This paper describes both the NoDoSE architecture, which can be used as a test bed for structure mining algorithms in general, and the mining algorithms that have been developed by the author. The prototype, which is written in Java, is described and experiences parsing a variety of documents are reported."
            },
            "slug": "NoDoSE\u2014a-tool-for-semi-automatically-extracting-and-Adelberg",
            "title": {
                "fragments": [],
                "text": "NoDoSE\u2014a tool for semi-automatically extracting structured and semistructured data from text documents"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "NoDoSE, the Northwestern Document Structure Extractor, is described, which is an interactive tool for semi-automatically determining the structure of such documents and then extracting their data."
            },
            "venue": {
                "fragments": [],
                "text": "SIGMOD '98"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1967815"
                        ],
                        "name": "M. E. Califf",
                        "slug": "M.-E.-Califf",
                        "structuredName": {
                            "firstName": "Mary",
                            "lastName": "Califf",
                            "middleNames": [
                                "Elaine"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. E. Califf"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1797655"
                        ],
                        "name": "R. Mooney",
                        "slug": "R.-Mooney",
                        "structuredName": {
                            "firstName": "Raymond",
                            "lastName": "Mooney",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Mooney"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 27,
                                "start": 20
                            }
                        ],
                        "text": "\u2022 Califf and Mooney [16,17] describe RAPIER."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 48,
                                "start": 35
                            }
                        ],
                        "text": "community has focused on free text [16,43,62,72], while the information integration and software agent communities have focused on structured Internet documents [9,11,41,52, 60]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 489775,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "16bd1fbe3694173eda4ad4338a85f8288d19bf02",
            "isKey": false,
            "numCitedBy": 700,
            "numCiting": 77,
            "paperAbstract": {
                "fragments": [],
                "text": "Information extraction is a form of shallow text processing that locates a specified set of relevant items in a natural-language document. Systems for this task require significant domain-specific knowledge and are time-consuming and difficult to build by hand, making them a good application for machine learning. We present a system, RAPIER, that uses pairs of sample documents and filled templates to induce pattern-match rules that directly extract fillers for the slots in the template. RAPIER employs a bottom-up learning algorithm which incorporates techniques from several inductive logic programming systems and acquires unbounded patterns that include constraints on the words, part-of-speech tags, and semantic classes present in the filler and the surrounding text. We present encouraging experimental results on two domains."
            },
            "slug": "Relational-Learning-of-Pattern-Match-Rules-for-Califf-Mooney",
            "title": {
                "fragments": [],
                "text": "Relational Learning of Pattern-Match Rules for Information Extraction"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "RAPIER employs a bottom-up learning algorithm which incorporates techniques from several inductive logic programming systems and acquires unbounded patterns that include constraints on the words, part-of-speech tags, and semantic classes present in the filler and the surrounding text."
            },
            "venue": {
                "fragments": [],
                "text": "CoNLL"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2913159"
                        ],
                        "name": "Robert B. Doorenbos",
                        "slug": "Robert-B.-Doorenbos",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Doorenbos",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Robert B. Doorenbos"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1741101"
                        ],
                        "name": "Oren Etzioni",
                        "slug": "Oren-Etzioni",
                        "structuredName": {
                            "firstName": "Oren",
                            "lastName": "Etzioni",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Oren Etzioni"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1780531"
                        ],
                        "name": "Daniel S. Weld",
                        "slug": "Daniel-S.-Weld",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Weld",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Daniel S. Weld"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 189,
                                "start": 185
                            }
                        ],
                        "text": "These challenges have lead to work on resource discovery [13], Web query languages [48,57], semi-structured data models [1,15], query planning [24,36,55], reasoning about local completeness [28,53] and ontological [31,56] knowledge, and handling heterogeneous identifiers [20,59]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 3531043,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7b3b14828a71c3bd4e56fda87a8c89a72d358c4e",
            "isKey": false,
            "numCitedBy": 608,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": "The WorldWideWeb is less agent-friendly than we might hope. Most information on the Web is presented in loosely structured natural language text with no agent-readable semantics. HTML annotations structure the display of Web pages, but provide virtually no insight into their content. Thus, the designers of intelligent Web agents need to address the following questions: (1) To what extent can an agent understand information published at Web sites? (2) Is the agent's understanding sufficient to provide genuinely useful assistance to users? (3) Is site-specific hand-coding necessary, or can the agent automatically extract information from unfamiliar Web sites? (4) What aspects of the Web facilitate this competence? In this paper we investigate these issues with a case study using ShopBot, a fully-implemented, domainindependent comparison-shopping agent. Given the home pages of several online stores, ShopBot autonomously learns how to shop at those vendors. After learning, it is able to speedily visit over a dozen software and CD vendors, extract product information, and summarize the results for the user. Preliminary studies show that ShopBot enables users to both find superior prices and substantially reduce Web shopping time. Remarkably, ShopBot achieves this performance without sophisticated natural language processing, and requires only minimal knowledge about different product domains. Instead, ShopBot relies on a combination of heuristic search, pattern matching, and inductive learning techniques. PERMISSION TO COPY WITHOUT FEE ALL OR OR PART OF THIS MATERIAL IS GRANTED PROVIDED THAT THE COPIES ARE NOT MADE OR DISTRIBUTED FOR DIRECT COMMERCIAL ADVANTAGE, THE ACM copyRIGHT NOTICE AND THE TITLE OF THE PUBLICATION AND ITS DATE APPEAR, AND NOTICE IS GIVEN THAT COPYING IS BY PERMISSION OF ACM. To COPY OTHERWISE, OR TO REPUBLISH, REQUIRES A FEE AND/OR SPECIFIC PERMISSION. AGENTS '97 CONFERENCE PROCEEDINGS, COPYRIGHT 1997 ACM."
            },
            "slug": "A-scalable-comparison-shopping-agent-for-the-Web-Doorenbos-Etzioni",
            "title": {
                "fragments": [],
                "text": "A scalable comparison-shopping agent for the World-Wide Web"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "ShopBot, a fully-implemented, domainindependent comparison-shopping agent that relies on a combination of heuristic search, pattern matching, and inductive learning techniques, enables users to both find superior prices and substantially reduce Web shopping time."
            },
            "venue": {
                "fragments": [],
                "text": "AGENTS '97"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50056360"
                        ],
                        "name": "William W. Cohen",
                        "slug": "William-W.-Cohen",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Cohen",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "William W. Cohen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 279,
                                "start": 272
                            }
                        ],
                        "text": "These challenges have lead to work on resource discovery [13], Web query languages [48,57], semi-structured data models [1,15], query planning [24,36,55], reasoning about local completeness [28,53] and ontological [31,56] knowledge, and handling heterogeneous identifiers [20,59]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 10180842,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0ba3e29dac0857100935b6eb22bce9cee4afcf17",
            "isKey": false,
            "numCitedBy": 465,
            "numCiting": 72,
            "paperAbstract": {
                "fragments": [],
                "text": "Most databases contain \u201cname constants\u201d like course numbers, personal names, and place names that correspond to entities in the real world. Previous work in integration of heterogeneous databases has assumed that local name constants can be mapped into an appropriate global domain by normalization. However, in many cases, this assumption does not hold; determining if two name constants should be considered identical can require detailed knowledge of the world, the purpose of the user's query, or both. In this paper, we reject the assumption that global domains can be easily constructed, and assume instead that the names are given in natural language text. We then propose a logic called WHIRL which reasons explicitly about the similarity of local names, as measured using the vector-space model commonly adopted in statistical information retrieval. We describe an efficient implementation of WHIRL and evaluate it experimentally on data extracted from the World Wide Web. We show that WHIRL is much faster than naive inference methods, even for short queries. We also show that inferences made by WHIRL are surprisingly accurate, equaling the accuracy of hand-coded normalization routines on one benchmark problem, and outperforming exact matching with a plausible global domain on a second."
            },
            "slug": "Integration-of-heterogeneous-databases-without-on-Cohen",
            "title": {
                "fragments": [],
                "text": "Integration of heterogeneous databases without common domains using queries based on textual similarity"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This paper rejects the assumption that global domains can be easily constructed, and assumes instead that the names are given in natural language text, and proposes a logic called WHIRL which reasons explicitly about the similarity of local names, as measured using the vector-space model commonly adopted in statistical information retrieval."
            },
            "venue": {
                "fragments": [],
                "text": "SIGMOD '98"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1745117"
                        ],
                        "name": "Craig A. Knoblock",
                        "slug": "Craig-A.-Knoblock",
                        "structuredName": {
                            "firstName": "Craig",
                            "lastName": "Knoblock",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Craig A. Knoblock"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145293454"
                        ],
                        "name": "Steven Minton",
                        "slug": "Steven-Minton",
                        "structuredName": {
                            "firstName": "Steven",
                            "lastName": "Minton",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Steven Minton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2887330"
                        ],
                        "name": "J. Ambite",
                        "slug": "J.-Ambite",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Ambite",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Ambite"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2178614"
                        ],
                        "name": "N. Ashish",
                        "slug": "N.-Ashish",
                        "structuredName": {
                            "firstName": "Naveen",
                            "lastName": "Ashish",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Ashish"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2463523"
                        ],
                        "name": "P. J. Modi",
                        "slug": "P.-J.-Modi",
                        "structuredName": {
                            "firstName": "Pragnesh",
                            "lastName": "Modi",
                            "middleNames": [
                                "Jay"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. J. Modi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3276863"
                        ],
                        "name": "Ion Muslea",
                        "slug": "Ion-Muslea",
                        "structuredName": {
                            "firstName": "Ion",
                            "lastName": "Muslea",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ion Muslea"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2135707"
                        ],
                        "name": "A. Philpot",
                        "slug": "A.-Philpot",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Philpot",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Philpot"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145565197"
                        ],
                        "name": "S. Tejada",
                        "slug": "S.-Tejada",
                        "structuredName": {
                            "firstName": "Sheila",
                            "lastName": "Tejada",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Tejada"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 133,
                                "start": 129
                            }
                        ],
                        "text": "We were strongly influenced by the University of Washington \u201cSoftbot\u201d project [23,26,30,66,67]; related projects include ARIADNE [46], CARNOT [21], DISCO [32], GARLIC [18], HERMES [2], the Information Manifold [55],TSIMMIS [19], FUSION [68], BargainFinder [49], and the Knowledge Broker [4]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 9829974,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6b04707bf7810f6030539638f93fef712b684d7a",
            "isKey": false,
            "numCitedBy": 239,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "The Web is based on a browsing paradigm that makes it difficult to retrieve and integrate data from multiple sites. Today, the only way to do this is to build specialized applications, which are time-consuming to develop and difficult to maintain. We are addressing this problem by creating the technology and tools for rapidly constructing information agents that extract, query, and integrate data from web sources. Our approach is based on a simple, uniform representation that makes it efficient to integrate multiple sources. Instead of building specialized algorithms for handling web sources, we have developed methods for mapping web sources into this uniform representation. This approach builds on work from knowledge representation, machine learning and automated planning. The resulting system, called Ariadne, makes it fast and cheap to build new information agents that access existing web sources. Ariadne also makes it easy to maintain these agents and incorporate new sources as they become available."
            },
            "slug": "Modeling-Web-Sources-for-Information-Integration-Knoblock-Minton",
            "title": {
                "fragments": [],
                "text": "Modeling Web Sources for Information Integration"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "This work has developed methods for mapping web sources into a simple, uniform representation that makes it efficient to integrate multiple sources and makes it easy to maintain these agents and incorporate new sources as they become available."
            },
            "venue": {
                "fragments": [],
                "text": "AAAI/IAAI"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3017541"
                        ],
                        "name": "M. Perkowitz",
                        "slug": "M.-Perkowitz",
                        "structuredName": {
                            "firstName": "Mike",
                            "lastName": "Perkowitz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Perkowitz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1741101"
                        ],
                        "name": "Oren Etzioni",
                        "slug": "Oren-Etzioni",
                        "structuredName": {
                            "firstName": "Oren",
                            "lastName": "Etzioni",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Oren Etzioni"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 8,
                                "start": 4
                            }
                        ],
                        "text": "ILA [61] learns an information source\u2019s schema in terms of its background knowledge."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5903740,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7dabaac2a302bf2c99cd21341802fbe885398408",
            "isKey": false,
            "numCitedBy": 124,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper investigates the problem of automatically learning declarative models of information sources available on the Internet. We report on ILA, a domain-independent program that learns the meaning of external information by explaining it in terms of internal categories. In our experiments, ILA starts with knowledge of local faculty members, and is able to learn models of the Internet service whois and of the personnel directories available at Berkeley, Brown, Caltech, Cornell, Rice, Rutgers, and UCI, averaging fewer than 40 queries per information source. ILA\u2019s hypothesis language is first-order conjunctions, and its bias is compactly encoded as a determination. We analyze ILA\u2019s sample complexity within the Valiant model, and using a probabilistic model specifically tailored to ILA."
            },
            "slug": "Category-Translation:-Learning-to-Understand-on-the-Perkowitz-Etzioni",
            "title": {
                "fragments": [],
                "text": "Category Translation: Learning to Understand Information on the Internet"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "IA is a domain-independent program that learns the meaning of external information by explaining it in terms of internal categories, and its bias is compactly encoded as a determination."
            },
            "venue": {
                "fragments": [],
                "text": "IJCAI"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2158668062"
                        ],
                        "name": "M. L\u00f3pez",
                        "slug": "M.-L\u00f3pez",
                        "structuredName": {
                            "firstName": "M.",
                            "lastName": "L\u00f3pez",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. L\u00f3pez"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108915870"
                        ],
                        "name": "Dan J. Smith",
                        "slug": "Dan-J.-Smith",
                        "structuredName": {
                            "firstName": "Dan",
                            "lastName": "Smith",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dan J. Smith"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "There has been substantial research on specialized programming languages and graphical user interfaces to assist in manually writing such wrappers [3,25,37,39,42,63, 69]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15509673,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1a0ef2286995c3a381f4e73336fecc0eb82ee2f9",
            "isKey": false,
            "numCitedBy": 60,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "The number of unstructured or semi-structured documents produced in all types of organizations continues to increase rapidly. Cost-effective ways of finding the relevant ones and extracting useful information from them are increasingly important to a large number of enterprises for operational and decision-support applications. The approach discussed in this paper constitutes a suitable basis for building an effective solution to extracting information from semi-structured documents for two principal reasons. First, it provides an extensible architecture basis for: extracting structured information from semistructured documents; providing fast and accurate selective access to this information; performing selective dissemination of relevant documents depending on filtering criteria. Second, it is simple in terms of: the complexity of the algorithms used for structure recognition and document filtering; the number and size of data structures required to perform the three functions mentioned above; the amount and complexity of the metadata required to handle a given collection of documents. The work described here is part of the Dyade M\u00e9diation project, which aims to provide integrated software components for accessing heterogeneous data sources in Internet/Intranet environments."
            },
            "slug": "Information-extraction-for-semi-structured-L\u00f3pez-Smith",
            "title": {
                "fragments": [],
                "text": "Information extraction for semi-structured documents"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "The approach discussed in this paper constitutes a suitable basis for building an effective solution to extracting information from semi-structured documents for two principal reasons: an extensible architecture basis for extracting structured information from semistructured documents and selective dissemination of relevant documents depending on filtering criteria."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144295318"
                        ],
                        "name": "S. Soderland",
                        "slug": "S.-Soderland",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Soderland",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Soderland"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "This distinction has started to blur, as researchers have started to evaluate their systems on both structured and natural text [33, 70 ,71]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Soderland later developed WEB-FOOT [ 70 ], an extension to CRYSTAL for structured HTML documents."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 10566644,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "130cbc5e907cccbd0fcd4f9138bc9886dc3217d7",
            "isKey": false,
            "numCitedBy": 262,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "There is a wealth of information to be mined from narrative text on the World Wide Web. Unfortunately, standard natural language processing (NLP) extraction techniques expect full, grammatical sentences, and perform poorly on the choppy sentence fragments that are often found on web pages. \n \nThis paper1 introduces Webfoot, a preprocessor that parses web pages into logically coherent segments based on page layout cues. Output from Webfoot is then passed on to CRYSTAL, an NLP system that learns text extraction rules from example. Webfoot and CRYSTAL transform the text into a formal representation that is equivalent to relational database entries. This is a necessary first step for knowledge discovery and other automated analysis of free text."
            },
            "slug": "Learning-to-Extract-Text-Based-Information-from-the-Soderland",
            "title": {
                "fragments": [],
                "text": "Learning to Extract Text-Based Information from the World Wide Web"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "Webfoot, a preprocessor that parses web pages into logically coherent segments based on page layout cues, is introduced and passed on to CRYSTAL, an NLP system that learns text extraction rules from example."
            },
            "venue": {
                "fragments": [],
                "text": "KDD"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1691993"
                        ],
                        "name": "E. Riloff",
                        "slug": "E.-Riloff",
                        "structuredName": {
                            "firstName": "Ellen",
                            "lastName": "Riloff",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Riloff"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 48,
                                "start": 35
                            }
                        ],
                        "text": "community has focused on free text [16,43,62,72], while the information integration and software agent communities have focused on structured Internet documents [9,11,41,52, 60]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2257053,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bdc08721414c972ab451f8ef3ef39d63c741b324",
            "isKey": false,
            "numCitedBy": 555,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "Knowledge-based natural language processing systems have achieved good success with certain tasks but they are often criticized because they depend on a domain-specific dictionary that requires a great deal of manual knowledge engineering. This knowledge engineering bottleneck makes knowledge-based NLP systems impractical for real-world applications because they cannot be easily scaled up or ported to new domains. In response to this problem, we developed a system called AutoSlog that automatically builds a domain-specific dictionary of concepts for extracting information from text. Using AutoSlog, we constructed a dictionary for the domain of terrorist event descriptions in only 5 person-hours. We then compared the AutoSlog dictionary with a hand-crafted dictionary that was built by two highly skilled graduate students and required approximately 1500 person-hours of effort. We evaluated the two dictionaries using two blind test sets of 100 texts each. Overall, the AutoSlog dictionary achieved 98% of the performance of the hand-crafted dictionary. On the first test set, the AutoSlog dictionary obtained 96.3% of the performance of the hand-crafted dictionary. On the second test set, the overall scores were virtually indistinguishable with the AutoSlog dictionary achieving 99.7% of the performance of the handcrafted dictionary."
            },
            "slug": "Automatically-Constructing-a-Dictionary-for-Tasks-Riloff",
            "title": {
                "fragments": [],
                "text": "Automatically Constructing a Dictionary for Information Extraction Tasks"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "Using AutoSlog, a system that automatically builds a domain-specific dictionary of concepts for extracting information from text, a dictionary for the domain of terrorist event descriptions was constructed in only 5 person-hours and the overall scores were virtually indistinguishable."
            },
            "venue": {
                "fragments": [],
                "text": "AAAI"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2198460"
                        ],
                        "name": "Oliver M. Duschka",
                        "slug": "Oliver-M.-Duschka",
                        "structuredName": {
                            "firstName": "Oliver",
                            "lastName": "Duschka",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Oliver M. Duschka"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1770962"
                        ],
                        "name": "A. Halevy",
                        "slug": "A.-Halevy",
                        "structuredName": {
                            "firstName": "Alon",
                            "lastName": "Halevy",
                            "middleNames": [
                                "Y."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Halevy"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 153,
                                "start": 143
                            }
                        ],
                        "text": "These challenges have lead to work on resource discovery [13], Web query languages [48,57], semi-structured data models [1,15], query planning [24,36,55], reasoning about local completeness [28,53] and ontological [31,56] knowledge, and handling heterogeneous identifiers [20,59]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7295834,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "33c42fb781564e0902888bbe2d20114faf205645",
            "isKey": false,
            "numCitedBy": 139,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "Generating query-answering plans for information gathering agents requires to translate a user query, formulated in terms of a set of virtual relations, to a query that uses relations that are actually stored in information sources. Previous solutions to the translation problem produced sets of conjunctive plans, and were therefore limited in their ability to handle information sources with binding-pattern limitations, and to exploit functional dependencies in the domainmodel. As a result, these plans were incomplete w.r.t. sources encountered in practice (i.e., produced only a subset of the possible answers). We describe the novel class of recursive information gathering plans, which enables us to settle two open problems. First, we describe an algorithm for nding a query plan that produces the maximal set of answers from the sources in the presence of functional dependencies. Second, we describe an analogous algorithm in the presence of binding-pattern restrictions in the sources, which was not possible without recursive plans."
            },
            "slug": "Recursive-Plans-for-Information-Gathering-Duschka-Halevy",
            "title": {
                "fragments": [],
                "text": "Recursive Plans for Information Gathering"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "The novel class of recursive information gathering plans is described, which enables us to settle two open problems and describes an algorithm fording a query plan that produces the maximal set of answers from the sources in the presence of functional dependencies."
            },
            "venue": {
                "fragments": [],
                "text": "IJCAI"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144477659"
                        ],
                        "name": "J. Hammer",
                        "slug": "J.-Hammer",
                        "structuredName": {
                            "firstName": "Joachim",
                            "lastName": "Hammer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Hammer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1398574232"
                        ],
                        "name": "H. Garcia-Molina",
                        "slug": "H.-Garcia-Molina",
                        "structuredName": {
                            "firstName": "Hector",
                            "lastName": "Garcia-Molina",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Garcia-Molina"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "4658767"
                        ],
                        "name": "Junghoo Cho",
                        "slug": "Junghoo-Cho",
                        "structuredName": {
                            "firstName": "Junghoo",
                            "lastName": "Cho",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Junghoo Cho"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3308846"
                        ],
                        "name": "R. Aranha",
                        "slug": "R.-Aranha",
                        "structuredName": {
                            "firstName": "Rohan",
                            "lastName": "Aranha",
                            "middleNames": [
                                "F.",
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Aranha"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143965506"
                        ],
                        "name": "Arturo Crespo",
                        "slug": "Arturo-Crespo",
                        "structuredName": {
                            "firstName": "Arturo",
                            "lastName": "Crespo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Arturo Crespo"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 169,
                                "start": 147
                            }
                        ],
                        "text": "There has been substantial research on specialized programming languages and graphical user interfaces to assist in manually writing such wrappers [3,25,37,39,42,63, 69]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1733803,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "aac5b7d3127605318708de9496617a79e10dd21b",
            "isKey": false,
            "numCitedBy": 381,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a configurable tool for extracting semistructured data from a set of HTML pages andfor converting the extracted information into database objects. The input to the extractor is adeclarative specification that states where the data of interest is located on the HTML pages, andhow the data should be packaged into objects. We have implemented the Web extractor usingthe Python programming language stressing efficiency and ease-of-use. We also describe variousways of improving the functionality of our current prototype. The prototype is installed andrunning in the TSIMMIS testbed as part of a DARPA I3 (Intelligent Integration of Information)technology demonstration where it is used for extracting weather data form various WWW sites."
            },
            "slug": "Extracting-Semistructured-Information-from-the-Web.-Hammer-Garcia-Molina",
            "title": {
                "fragments": [],
                "text": "Extracting Semistructured Information from the Web."
            },
            "tldr": {
                "abstractSimilarityScore": 75,
                "text": "A configurable tool for extracting semistructured data from a set of HTML pages and for converting the extracted information into database objects and various ways of improving the functionality of the current prototype are described."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1680223"
                        ],
                        "name": "A. Smeaton",
                        "slug": "A.-Smeaton",
                        "structuredName": {
                            "firstName": "Alan",
                            "lastName": "Smeaton",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Smeaton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2060202"
                        ],
                        "name": "F. Crimmins",
                        "slug": "F.-Crimmins",
                        "structuredName": {
                            "firstName": "Francis",
                            "lastName": "Crimmins",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Crimmins"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 240,
                                "start": 236
                            }
                        ],
                        "text": "We were strongly influenced by the University of Washington \u201cSoftbot\u201d project [23,26,30,66,67]; related projects include ARIADNE [46], CARNOT [21], DISCO [32], GARLIC [18], HERMES [2], the Information Manifold [55],TSIMMIS [19], FUSION [68], BargainFinder [49], and the Knowledge Broker [4]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 10529293,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e448016b37b03635f39967514d6bd3b03e005d3a",
            "isKey": false,
            "numCitedBy": 28,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "A fully operational large scale digital library is likely to be based on a distributed architecture and because of this it is likely that a number of independent search engines may be used to index different overlapping portions of the entire contents of the library. In any case, different media, text, audio, image, etc., will be indexed for retrieval by different search engines so techniques which provide a coherent and unified search over a suite of underlying independent search engines are thus likely to be an important part of navigating in a digital library. In this paper we present an architecture and a system for searching the world's largest DL, the world wide web. What makes our system novel is that we use a suite of underlying web search engines to do the bulk of the work while our system orchestrates them in a parallel fashion to provide a higher level of information retrieval functionality. Thus it is our meta search engine and not the underlying direct search engines that provide the relevance feedback and query expansion options for the user. The paper presents the design and architecture of the system which has been implemented, describes an initial version which has been operational for almost a year, and outlines the operation of the advanced version."
            },
            "slug": "Relevance-Feedback-and-Query-Expansion-for-the-Web:-Smeaton-Crimmins",
            "title": {
                "fragments": [],
                "text": "Relevance Feedback and Query Expansion for Searching the Web: A Model for Searching a Digital Library"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This paper presents an architecture and a system for searching the world's largest DL, the world wide web, which uses a suite of underlying web search engines to do the bulk of the work while the system orchestrates them in a parallel fashion to provide a higher level of information retrieval functionality."
            },
            "venue": {
                "fragments": [],
                "text": "ECDL"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46987823"
                        ],
                        "name": "Chung T. Kwok",
                        "slug": "Chung-T.-Kwok",
                        "structuredName": {
                            "firstName": "Chung",
                            "lastName": "Kwok",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chung T. Kwok"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1780531"
                        ],
                        "name": "Daniel S. Weld",
                        "slug": "Daniel-S.-Weld",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Weld",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Daniel S. Weld"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 62232918,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "248b6e3f56e8d70b9fa4af38e4147dd6ebea9e86",
            "isKey": false,
            "numCitedBy": 132,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe Occam, a query planning algorithm that determines the best way to integrate data from different sources. As input, Occam takes a library of site descriptions and a user query. As output, Occam automatically generates one or more plans that encode alternative ways to gather the requested information. \n \nOccam has several important features: (1) it integrates both legacy systems and full relational databases with an efficient, domain-independent, query-planning algorithm, (2) it reasons about the capabilities of different information sources, (3) it handles partial goal satisfaction i.e., gathers as much data as possible when it can't gather exactly all that the user requested, (4) it is both sound and complete, (5) it is efficient. We present empirical results demonstrating Occam's performance on a variety of information gathering tasks."
            },
            "slug": "Planning-to-gather-inforrnation-Kwok-Weld",
            "title": {
                "fragments": [],
                "text": "Planning to gather inforrnation"
            },
            "tldr": {
                "abstractSimilarityScore": 65,
                "text": "Occam, a query planning algorithm that determines the best way to integrate data from different sources, is described and empirical results demonstrating Occam's performance on a variety of information gathering tasks are presented."
            },
            "venue": {
                "fragments": [],
                "text": "AAAI 1996"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2071034516"
                        ],
                        "name": "Alvaro E. Monge",
                        "slug": "Alvaro-E.-Monge",
                        "structuredName": {
                            "firstName": "Alvaro",
                            "lastName": "Monge",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alvaro E. Monge"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1722831"
                        ],
                        "name": "C. Elkan",
                        "slug": "C.-Elkan",
                        "structuredName": {
                            "firstName": "Charles",
                            "lastName": "Elkan",
                            "middleNames": [
                                "Peter"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Elkan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 279,
                                "start": 272
                            }
                        ],
                        "text": "These challenges have lead to work on resource discovery [13], Web query languages [48,57], semi-structured data models [1,15], query planning [24,36,55], reasoning about local completeness [28,53] and ontological [31,56] knowledge, and handling heterogeneous identifiers [20,59]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 16071510,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2fc7b36564eff791d5997178f7aa649ee57cd72b",
            "isKey": false,
            "numCitedBy": 564,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "To combine information from heterogeneous sources, equivalent data in the multiple sources must be identified. This task is the field matching problem. Specifically, the task is to determine whether or not two syntactic values are alternative designations of the same semantic entity. For example the addresses Dept. of Comput. Sci. and Eng., University of California, San Diego, 9500 Gilman Dr. Dept. 0114, La Jolla. CA 92093 and UCSD, Computer Science and Engineering Department, CA 92093-0114 do designate the same department. This paper describes three field matching algorithms, and evaluates their performance on real-world datasets. One proposed method is the well-known Smith-Waterman algorithm for comparing DNA and protein sequences. Several applications of field matching in knowledge discovery are described briefly, including WEBFIND, which is a new software tool that discovers scientific papers published on the worldwide web. WEBFIND uses external information sources to guide its search for authors and papers. Like many other worldwide web tools, WEBFIND needs to solve the field matching problem in order to navigate between information sources."
            },
            "slug": "The-Field-Matching-Problem:-Algorithms-and-Monge-Elkan",
            "title": {
                "fragments": [],
                "text": "The Field Matching Problem: Algorithms and Applications"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "Three field matching algorithms are described, one of which is the well-known Smith-Waterman algorithm for comparing DNA and protein sequences, and their performance on real-world datasets is evaluated."
            },
            "venue": {
                "fragments": [],
                "text": "KDD"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2077174403"
                        ],
                        "name": "M. I. Mauldin",
                        "slug": "M.-I.-Mauldin",
                        "structuredName": {
                            "firstName": "M.",
                            "lastName": "Mauldin",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. I. Mauldin"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 60521362,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6d23684e422688703aa347bb7d21abea2563895f",
            "isKey": false,
            "numCitedBy": 57,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "One of the enabling technologies of the World Wide Web, along with browsers, domain name servers, and hypertext markup language, is the search engine. Although the Web contains over 100 million pages of information, those millions of pages are useless if you cannot find the pages you need. All major Web search engines operate the same way: a gathering program explores the hyperlinked documents of the Web, foraging for Web pages to index. These pages are stockpiled by storing them in some kind of database or repository. Finally, a retrieval program takes a user query and creates a list of links to Web documents matching the words, phrases, or concepts in the query. Although the retrieval program itself is correctly called a search engine, by popular usage the term now means a database combined with a retrieval program. For example, the Lycos search engine comprises the Lycos Catalog of the Internet and the Pursuit retrieval program. This paper describes the Lycos system for collecting, storing, and retrieving information about pages on the Web. After outlining the history and precursors of the Lycos system, the paper discusses some of the design choices made in building this Web indexer and touches briefly on the economic issues involved in working with very large retrieval systems."
            },
            "slug": "Lycos:-design-choices-in-an-Internet-search-service-Mauldin",
            "title": {
                "fragments": [],
                "text": "Lycos: design choices in an Internet search service"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "The history and precursors of the Lycos system for collecting, storing, and retrieving information about pages on the Web are outlined and some of the design choices made in building this Web indexer are discussed."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2913226"
                        ],
                        "name": "Eric Lambrecht",
                        "slug": "Eric-Lambrecht",
                        "structuredName": {
                            "firstName": "Eric",
                            "lastName": "Lambrecht",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Eric Lambrecht"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1740315"
                        ],
                        "name": "S. Kambhampati",
                        "slug": "S.-Kambhampati",
                        "structuredName": {
                            "firstName": "S.",
                            "lastName": "Kambhampati",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Kambhampati"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 88,
                                "start": 75
                            }
                        ],
                        "text": "Recently, there has been much interest in systems (such as software agents [30,36,49,66] or information-integration systems [8,18,19,45,55]) that automatically access such resources, manipulating their content on a user\u2019s behalf."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 153,
                                "start": 143
                            }
                        ],
                        "text": "These challenges have lead to work on resource discovery [13], Web query languages [48,57], semi-structured data models [1,15], query planning [24,36,55], reasoning about local completeness [28,53] and ontological [31,56] knowledge, and handling heterogeneous identifiers [20,59]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2328510,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "006f91111aa7d1da2e18f9df330c47856dc08a7d",
            "isKey": false,
            "numCitedBy": 26,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "The most costly aspect of gathering information over the Internet is that of transferring data over the network to answer the user\u2019s query. We make two contributions in this paper that alleviate this problem. First, we present an algorithm for reducing the number of information sources in an information gathering (IG) plan by reasoning with localized closed world (LCW) statements. In contrast to previous work on this problem, our algorithm can handle recursive information gathering plans that arise commonly in practice. Second, we present a method for reducing the amount of network traffic generated while executing an information gathering plan by reordering the sequence in which queries are sent to remote information sources. We will explain why a direct application of traditional distributed database methods to this problem does not work, and present a novel and cheap way of adorning source descriptions to assist in ordering the queries."
            },
            "slug": "Efficiently-Executing-Information-Gathering-Plans-Lambrecht-Kambhampati",
            "title": {
                "fragments": [],
                "text": "Efficiently Executing Information Gathering Plans"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "An algorithm for reducing the number of information sources in an information gathering (IG) plan by reasoning with localized closed world (LCW) statements is presented and can handle recursive information gathering plans that arise commonly in practice."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1770962"
                        ],
                        "name": "A. Halevy",
                        "slug": "A.-Halevy",
                        "structuredName": {
                            "firstName": "Alon",
                            "lastName": "Halevy",
                            "middleNames": [
                                "Y."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Halevy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "69484854"
                        ],
                        "name": "A. Rajaraman",
                        "slug": "A.-Rajaraman",
                        "structuredName": {
                            "firstName": "Anand",
                            "lastName": "Rajaraman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Rajaraman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2193834"
                        ],
                        "name": "J. Ordille",
                        "slug": "J.-Ordille",
                        "structuredName": {
                            "firstName": "Joann",
                            "lastName": "Ordille",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Ordille"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 139,
                                "start": 124
                            }
                        ],
                        "text": "Recently, there has been much interest in systems (such as software agents [30,36,49,66] or information-integration systems [8,18,19,45,55]) that automatically access such resources, manipulating their content on a user\u2019s behalf."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 214,
                                "start": 210
                            }
                        ],
                        "text": "We were strongly influenced by the University of Washington \u201cSoftbot\u201d project [23,26,30,66,67]; related projects include ARIADNE [46], CARNOT [21], DISCO [32], GARLIC [18], HERMES [2], the Information Manifold [55],TSIMMIS [19], FUSION [68], BargainFinder [49], and the Knowledge Broker [4]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 153,
                                "start": 143
                            }
                        ],
                        "text": "These challenges have lead to work on resource discovery [13], Web query languages [48,57], semi-structured data models [1,15], query planning [24,36,55], reasoning about local completeness [28,53] and ontological [31,56] knowledge, and handling heterogeneous identifiers [20,59]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14649913,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0e93b228ffa2c27e96ba7d0158cc6ba5b1cdcb5d",
            "isKey": false,
            "numCitedBy": 271,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe the architecture and query-answering algorithms used in the Information Manifold, an implemented information gathering system that provides uniform access to structured information sources on the World-Wide Web. Our architecture provides an expressive language for describing information sources, which makes it easy to add new sources and to model the fine-grained distinctions between their contents. The query-answering algorithm guarantees that the descriptions of the sources are exploited to access only sources that are relevant to a given query. Accessing only relevant sources is crucial to scale up such a system to large numbers of sources. In addition, our algorithm can exploit run-time information to further prune information sources and to reduce the cost of query planning."
            },
            "slug": "Query-Answering-Algorithms-for-Information-Agents-Halevy-Rajaraman",
            "title": {
                "fragments": [],
                "text": "Query-Answering Algorithms for Information Agents"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "The architecture provides an expressive language for describing information sources, which makes it easy to add new sources and to model the fine-grained distinctions between their contents, and the query-answering algorithm guarantees that the descriptions of the sources are exploited to access only sources that are relevant to a given query."
            },
            "venue": {
                "fragments": [],
                "text": "AAAI/IAAI, Vol. 1"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "69026873"
                        ],
                        "name": "S. Abiteboul",
                        "slug": "S.-Abiteboul",
                        "structuredName": {
                            "firstName": "Serge",
                            "lastName": "Abiteboul",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Abiteboul"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 38,
                                "start": 33
                            }
                        ],
                        "text": ", using the regular expression \u2018 [1-9][0-9]+ \u2019 to identify country codes."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 126,
                                "start": 120
                            }
                        ],
                        "text": "These challenges have lead to work on resource discovery [13], Web query languages [48,57], semi-structured data models [1,15], query planning [24,36,55], reasoning about local completeness [28,53] and ontological [31,56] knowledge, and handling heterogeneous identifiers [20,59]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 17100824,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "da5abbdfe36b667d3e1459471289af7c02631d54",
            "isKey": false,
            "numCitedBy": 928,
            "numCiting": 73,
            "paperAbstract": {
                "fragments": [],
                "text": "Querying Semi-Structured Data Serge Abiteboul ? INRIA-Rocquencourt Serge.Abiteboul@inria.fr 1 Introduction The amount of data of all kinds available electronically has increased dramatically in recent years. The data resides in different forms, ranging from unstructured data in file systems to highly structured in relational database systems. Data is accessible through a variety of interfaces including Web browsers, database query languages, application-specific interfaces, or data exchange formats. Some of this data is raw data, e.g., images or sound. Some of it has structure even if the structure is often implicit, and not as rigid or regular as that found in standard database systems. Sometimes the structure exists but has to be extracted from the data. Sometimes also it exists but we prefer to ignore it for certain purposes such as browsing. We call here semi-structured data this data that is (from a particular viewpoint) neither raw data nor strictly typed, i.e., not table-oriented as in a relational model or sorted-graph as in object databases. As will seen later when the notion of semi-structured data is more precisely defined, the need for semi-structured data arises naturally in the context of data integration, even when the data sources are themselves well-structured. Although data integration is an old topic, the need to integrate a wider variety of dataformats (e.g., SGML or ASN.1 data) and data found on the Web has brought the topic of semi-structured data to the forefront of research. The main purpose of the paper is to isolate the essential aspects of semistructured data. We also survey some proposals of models and query languages for semi-structured data. In particular, we consider recent works at Stanford U. and U. Penn on semi-structured data. In both cases, the motivation is found in the integration of heterogeneous data. The \"lightweight\" data models they use (based on labelled graphs) are very similar. As we shall see, the topic of semi-structur"
            },
            "slug": "Querying-Semi-Structured-Data-Abiteboul",
            "title": {
                "fragments": [],
                "text": "Querying Semi-Structured Data"
            },
            "tldr": {
                "abstractSimilarityScore": 37,
                "text": "The main purpose of the paper is to isolate the essential aspects of semistructured data, and survey some proposals of models and query languages for semi-structured data."
            },
            "venue": {
                "fragments": [],
                "text": "ICDT"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1682406"
                        ],
                        "name": "A. Mendelzon",
                        "slug": "A.-Mendelzon",
                        "structuredName": {
                            "firstName": "Alberto",
                            "lastName": "Mendelzon",
                            "middleNames": [
                                "O."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Mendelzon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1678202"
                        ],
                        "name": "G. Mihaila",
                        "slug": "G.-Mihaila",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Mihaila",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Mihaila"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1702212"
                        ],
                        "name": "T. Milo",
                        "slug": "T.-Milo",
                        "structuredName": {
                            "firstName": "Tova",
                            "lastName": "Milo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Milo"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 90,
                                "start": 83
                            }
                        ],
                        "text": "These challenges have lead to work on resource discovery [13], Web query languages [48,57], semi-structured data models [1,15], query planning [24,36,55], reasoning about local completeness [28,53] and ontological [31,56] knowledge, and handling heterogeneous identifiers [20,59]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7284440,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "190c9f196e7dd9757e1bfcde2d53ec80a6c646dd",
            "isKey": false,
            "numCitedBy": 414,
            "numCiting": 42,
            "paperAbstract": {
                "fragments": [],
                "text": "The World Wide Web is a large, heterogeneous, distributed collection of documents connected by hypertext links. The most common technology currently used for searching the Web depends on sending information retrieval requests to \"index servers\". One problem with this is that these queries cannot exploit the structure and topology of the document network. The authors propose a query language, WebSQL, that takes advantage of multiple index servers without requiring users to know about them, and that integrates textual retrieval with structure and topology-based queries. They give a formal semantics for WebSQL using a calculus based on a novel \"virtual graph\" model of a document network. They propose a new theory of query cost based on the idea of \"query locality,\" that is, how much of the network must be visited to answer a particular query. Finally, they describe a prototype implementation of WebSQL written in Java."
            },
            "slug": "Querying-the-World-Wide-Web-Mendelzon-Mihaila",
            "title": {
                "fragments": [],
                "text": "Querying the World Wide Web"
            },
            "tldr": {
                "abstractSimilarityScore": 37,
                "text": "The authors propose a query language, WebSQL, that takes advantage of multiple index servers without requiring users to know about them, and that integrates textual retrieval with structure and topology-based queries."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal on Digital Libraries"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144295318"
                        ],
                        "name": "S. Soderland",
                        "slug": "S.-Soderland",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Soderland",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Soderland"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145262164"
                        ],
                        "name": "David Fisher",
                        "slug": "David-Fisher",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Fisher",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David Fisher"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "51080653"
                        ],
                        "name": "J. Aseltine",
                        "slug": "J.-Aseltine",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Aseltine",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Aseltine"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1925215"
                        ],
                        "name": "W. Lehnert",
                        "slug": "W.-Lehnert",
                        "structuredName": {
                            "firstName": "Wendy",
                            "lastName": "Lehnert",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Lehnert"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 48,
                                "start": 35
                            }
                        ],
                        "text": "community has focused on free text [16,43,62,72], while the information integration and software agent communities have focused on structured Internet documents [9,11,41,52, 60]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 16,
                                "start": 12
                            }
                        ],
                        "text": "\u2022 Soderland [72] describes CRYSTAL, which learns information extraction rules triggered by part-of-speech and lexical information."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 9168228,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8245f6099f547008522ebbe6fb813d8132085746",
            "isKey": false,
            "numCitedBy": 409,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "One of the central knowledge sources of an information extraction (IE) system IS a dictionary of linguistic patterns that can be used to identify references to relevant information in a text Automatic creation of conceptual dictionaries is important for portability and scalability of an IE system This paper describes CRYSTAL, a system which automatically induces a dictionary of \"concept-node definitions\" sufficient to identify relevant information from a training corpus Each of these concept-node definitions is generalized as far as possible without producing errors, so that a minimum number of dictionary entries cover the positive training instances Because it tests the accuracy of each proposed definition, CRYSTAL can often surpass human intuitions in creating reliable extraction rules."
            },
            "slug": "CRYSTAL:-Inducing-a-Conceptual-Dictionary-Soderland-Fisher",
            "title": {
                "fragments": [],
                "text": "CRYSTAL: Inducing a Conceptual Dictionary"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "CRYSTAL is described, a system which automatically induces a dictionary of \"concept-node definitions\" sufficient to identify relevant information from a training corpus that can often surpass human intuitions in creating reliable extraction rules."
            },
            "venue": {
                "fragments": [],
                "text": "IJCAI"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2605572"
                        ],
                        "name": "S. Huffman",
                        "slug": "S.-Huffman",
                        "structuredName": {
                            "firstName": "Scott",
                            "lastName": "Huffman",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Huffman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 48,
                                "start": 35
                            }
                        ],
                        "text": "community has focused on free text [16,43,62,72], while the information integration and software agent communities have focused on structured Internet documents [9,11,41,52, 60]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14690792,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8dadbf2dfebe794ad4fc5022f8bb65195c8f0d5a",
            "isKey": false,
            "numCitedBy": 193,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "A growing population of users want to extract a growing variety of information from on-line texts. Unfortunately, current information extraction systems typically require experts to hand-build dictionaries of extraction patterns for each new type of information to be extracted. This paper presents a system that can learn dictionaries of extraction patterns directly from user-provided examples of texts and events to be extracted from them. The system, called LIEP, learns patterns that recognize relationships between key constituents based on local syntax. Sets of patterns learned by LIEP for a sample extraction task perform nearly at the level of a hand-built dictionary of patterns."
            },
            "slug": "Learning-information-extraction-patterns-from-Huffman",
            "title": {
                "fragments": [],
                "text": "Learning information extraction patterns from examples"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A system that can learn dictionaries of extraction patterns directly from user-provided examples of texts and events to be extracted from them, and learns patterns that recognize relationships between key constituents based on local syntax."
            },
            "venue": {
                "fragments": [],
                "text": "Learning for Natural Language Processing"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9086294"
                        ],
                        "name": "S. Chawathe",
                        "slug": "S.-Chawathe",
                        "structuredName": {
                            "firstName": "Sudarshan",
                            "lastName": "Chawathe",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Chawathe"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1398574232"
                        ],
                        "name": "H. Garcia-Molina",
                        "slug": "H.-Garcia-Molina",
                        "structuredName": {
                            "firstName": "Hector",
                            "lastName": "Garcia-Molina",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Garcia-Molina"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144477659"
                        ],
                        "name": "J. Hammer",
                        "slug": "J.-Hammer",
                        "structuredName": {
                            "firstName": "Joachim",
                            "lastName": "Hammer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Hammer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144185412"
                        ],
                        "name": "K. Ireland",
                        "slug": "K.-Ireland",
                        "structuredName": {
                            "firstName": "Kelly",
                            "lastName": "Ireland",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Ireland"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1786049"
                        ],
                        "name": "Y. Papakonstantinou",
                        "slug": "Y.-Papakonstantinou",
                        "structuredName": {
                            "firstName": "Yannis",
                            "lastName": "Papakonstantinou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Papakonstantinou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1742391"
                        ],
                        "name": "J. Ullman",
                        "slug": "J.-Ullman",
                        "structuredName": {
                            "firstName": "Jeffrey",
                            "lastName": "Ullman",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Ullman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1737896"
                        ],
                        "name": "J. Widom",
                        "slug": "J.-Widom",
                        "structuredName": {
                            "firstName": "Jennifer",
                            "lastName": "Widom",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Widom"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 139,
                                "start": 124
                            }
                        ],
                        "text": "Recently, there has been much interest in systems (such as software agents [30,36,49,66] or information-integration systems [8,18,19,45,55]) that automatically access such resources, manipulating their content on a user\u2019s behalf."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 227,
                                "start": 223
                            }
                        ],
                        "text": "We were strongly influenced by the University of Washington \u201cSoftbot\u201d project [23,26,30,66,67]; related projects include ARIADNE [46], CARNOT [21], DISCO [32], GARLIC [18], HERMES [2], the Information Manifold [55],TSIMMIS [19], FUSION [68], BargainFinder [49], and the Knowledge Broker [4]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2113876,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "14348170a14b4e2edca01521184cb2cd60b83200",
            "isKey": false,
            "numCitedBy": 1264,
            "numCiting": 44,
            "paperAbstract": {
                "fragments": [],
                "text": "The goal of the Tsimmis Project is to develop tools that facilitate the rapid integration of heterogeneous information sources that may include both structured and unstructured data. This paper gives an overview of the project, describing components that extract properties from unstructured objects, that translate information into a common object model, that combine information from several sources, that allow browsing of information, and that manage constraints across heterogeneous sites. Tsimmis is a joint project between Stanford and the IBM Almaden Research Center. 1 Overview A common problem facing many organizations today is that of multiple, disparate information sources and repositories, including databases, object stores, knowledge bases, file systems, digital libraries, information retrieval systems, and electronic mail systems. Decision makers often need information from multiple sources, but are unable to get and fuse the required information in a timely fashion due to the diffculties of accessing the different systems, and due to the fact that the information obtained can be inconsistent and contradictory. Research sponsored by the Wright Laboratory, Aeronautical Systems Center, Air Force Material Command, USAF, under Grant Number F33615-93-1-1339. The US Government is authorized to reproduce and distribute reprints for Government purposes notwithstanding any copyright notation thereon. The views and conclusions contained in this document are those of the authors and should not be interpreted as necessarily representing the offcial policies or endorsements, either express or implied, of Wright Laboratory or the US Government. This work was also supported by the Reid and Polly Anderson Faculty Scholar Fund, the Center for Integrated Systems at Stanford University, and by Equipment Grants from Digital Equipment Corporation and IBM Corporation. The goal of the TSIMMIS 1 project is to provide tools for accessing, in an integrated fashion, multiple informati"
            },
            "slug": "The-TSIMMIS-Project:-Integration-of-Heterogeneous-Chawathe-Garcia-Molina",
            "title": {
                "fragments": [],
                "text": "The TSIMMIS Project: Integration of Heterogeneous Information Sources"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "An overview of the Tsimmis Project is given, describing components that extract properties from unstructured objects, that translate information into a common object model, that combine information from several sources, that allow browsing of information, and that manage constraints across heterogeneous sites."
            },
            "venue": {
                "fragments": [],
                "text": "IPSJ"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1703347"
                        ],
                        "name": "M. Carey",
                        "slug": "M.-Carey",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Carey",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Carey"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145704391"
                        ],
                        "name": "L. Haas",
                        "slug": "L.-Haas",
                        "structuredName": {
                            "firstName": "Laura",
                            "lastName": "Haas",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Haas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39055806"
                        ],
                        "name": "P. Schwarz",
                        "slug": "P.-Schwarz",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Schwarz",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Schwarz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "33886323"
                        ],
                        "name": "M. Arya",
                        "slug": "M.-Arya",
                        "structuredName": {
                            "firstName": "Manish",
                            "lastName": "Arya",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Arya"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40331405"
                        ],
                        "name": "W. Cody",
                        "slug": "W.-Cody",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Cody",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Cody"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144112511"
                        ],
                        "name": "Ronald Fagin",
                        "slug": "Ronald-Fagin",
                        "structuredName": {
                            "firstName": "Ronald",
                            "lastName": "Fagin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ronald Fagin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712991"
                        ],
                        "name": "M. Flickner",
                        "slug": "M.-Flickner",
                        "structuredName": {
                            "firstName": "Myron",
                            "lastName": "Flickner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Flickner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3059723"
                        ],
                        "name": "A. Luniewski",
                        "slug": "A.-Luniewski",
                        "structuredName": {
                            "firstName": "Allen",
                            "lastName": "Luniewski",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Luniewski"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2141915"
                        ],
                        "name": "W. Niblack",
                        "slug": "W.-Niblack",
                        "structuredName": {
                            "firstName": "Wayne",
                            "lastName": "Niblack",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Niblack"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143867341"
                        ],
                        "name": "D. Petkovic",
                        "slug": "D.-Petkovic",
                        "structuredName": {
                            "firstName": "Dragutin",
                            "lastName": "Petkovic",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Petkovic"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2115281729"
                        ],
                        "name": "Joachim Thomas",
                        "slug": "Joachim-Thomas",
                        "structuredName": {
                            "firstName": "Joachim",
                            "lastName": "Thomas",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Joachim Thomas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2111929692"
                        ],
                        "name": "John H. Williams",
                        "slug": "John-H.-Williams",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Williams",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "John H. Williams"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2855601"
                        ],
                        "name": "E. Wimmers",
                        "slug": "E.-Wimmers",
                        "structuredName": {
                            "firstName": "Edward",
                            "lastName": "Wimmers",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Wimmers"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 139,
                                "start": 124
                            }
                        ],
                        "text": "Recently, there has been much interest in systems (such as software agents [30,36,49,66] or information-integration systems [8,18,19,45,55]) that automatically access such resources, manipulating their content on a user\u2019s behalf."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 171,
                                "start": 167
                            }
                        ],
                        "text": "We were strongly influenced by the University of Washington \u201cSoftbot\u201d project [23,26,30,66,67]; related projects include ARIADNE [46], CARNOT [21], DISCO [32], GARLIC [18], HERMES [2], the Information Manifold [55],TSIMMIS [19], FUSION [68], BargainFinder [49], and the Knowledge Broker [4]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 6255878,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b6c60161f420481226453733f5c9293c3a8ebf18",
            "isKey": false,
            "numCitedBy": 479,
            "numCiting": 58,
            "paperAbstract": {
                "fragments": [],
                "text": "Provides an overview of the Garlic project, a new project at the IBM Almaden Research Center. The goal of this project is to develop a system and associated tools for the management of large quantities of heterogeneous multimedia information. Garlic permits traditional and multimedia data to he stored in a variety of existing data repositories, including databases, files, text managers, image managers, video servers, and so on; the data is seen through a unified schema expressed in an object-oriented data model and can be queried and manipulated using an object-oriented dialect of SQL, perhaps through an advanced query/browser tool that we are also developing. The Garlic architecture is designed to be extensible to new kinds of data repositories, and access efficiency is addressed via a \"middleware\" query processor that uses database query optimization techniques to exploit the native associative search capabilities of the underlying data repositories.<<ETX>>"
            },
            "slug": "Towards-heterogeneous-multimedia-information-the-Carey-Haas",
            "title": {
                "fragments": [],
                "text": "Towards heterogeneous multimedia information systems: the Garlic approach"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The Garlic architecture is designed to be extensible to new kinds of data repositories, and access efficiency is addressed via a \"middleware\" query processor that uses database query optimization techniques to exploit the native associative search capabilities of the underlying data repositories."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings RIDE-DOM'95. Fifth International Workshop on Research Issues in Data Engineering-Distributed Object Management"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1706276"
                        ],
                        "name": "S. Luke",
                        "slug": "S.-Luke",
                        "structuredName": {
                            "firstName": "Sean",
                            "lastName": "Luke",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Luke"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144665700"
                        ],
                        "name": "L. Spector",
                        "slug": "L.-Spector",
                        "structuredName": {
                            "firstName": "Lee",
                            "lastName": "Spector",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Spector"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1850356"
                        ],
                        "name": "D. Rager",
                        "slug": "D.-Rager",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Rager",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Rager"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1701341"
                        ],
                        "name": "J. Hendler",
                        "slug": "J.-Hendler",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Hendler",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Hendler"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 221,
                                "start": 214
                            }
                        ],
                        "text": "These challenges have lead to work on resource discovery [13], Web query languages [48,57], semi-structured data models [1,15], query planning [24,36,55], reasoning about local completeness [28,53] and ontological [31,56] knowledge, and handling heterogeneous identifiers [20,59]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7695193,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "98e857491b7774ea6c7e4d176d1ef8f636e087d8",
            "isKey": false,
            "numCitedBy": 281,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes SHOE, a set of Simple HTML Ontology Extensions which allow World-Wide Web authors to annotate their pages with semantic knowledge such as \u201cI am a graduate student\u201d or \u201cThis person is my graduate advisor\u201d. These annotations are expressed in terms of ontological knowledge which can be generated by using or extending standard ontologies available on the Web. This makes it possible to ask Web agent queries such as \u201cFind me all graduate students in Maryland who are working on a project funded by DoD initiative 123-4567\u201d, instead of simplistic keyword searches enabled by current search engines. We have also developed a web-crawling agent, Expos\u00b4 e, which interns SHOE knowledge from web documents, making these kinds queries a reality."
            },
            "slug": "Ontology-based-Web-agents-Luke-Spector",
            "title": {
                "fragments": [],
                "text": "Ontology-based Web agents"
            },
            "tldr": {
                "abstractSimilarityScore": 90,
                "text": "SHOE, a set of Simple HTML Ontology Extensions which allow World-Wide Web authors to annotate their pages with semantic knowledge such as \u201cI am a graduate student\u201d or \u201cThis person is my graduate advisor\u201d, is described."
            },
            "venue": {
                "fragments": [],
                "text": "AGENTS '97"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1770962"
                        ],
                        "name": "A. Halevy",
                        "slug": "A.-Halevy",
                        "structuredName": {
                            "firstName": "Alon",
                            "lastName": "Halevy",
                            "middleNames": [
                                "Y."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Halevy"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 197,
                                "start": 190
                            }
                        ],
                        "text": "These challenges have lead to work on resource discovery [13], Web query languages [48,57], semi-structured data models [1,15], query planning [24,36,55], reasoning about local completeness [28,53] and ontological [31,56] knowledge, and handling heterogeneous identifiers [20,59]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 10549616,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "318d44be0d45254bfc7a03ef36a9f0de3b985386",
            "isKey": false,
            "numCitedBy": 107,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "We consider the problem of answering queries from databases that may be incomplete. A database is incomplete if some tuples may be missing from some relations, and only a part of each relation is known to be complete. This problem arises in several contexts. For example, systems that provide access to multiple heterogeneous information sources often encounter incomplete sources. The question we address is to determine whether the answer to a specific given query is complete even when the database is incomplete. We present a novel sound and complete algorithm for the answer-completeness problem by relating it to the problem of independence of queries from updates. We also show an important case of the independence problem (and therefore ofthe answer-completeness problem) that can be decided in polynomial time, whereas the best known algorithm for this case is exponential. This case involves updates that are described using a conjunction of comparison predicates. We also describe an algorithm that determines whether the answer to the query is complete in the current state of the database. Finally, we show that our \u2018treatment extends naturally to partiallyincorrect databases. Permission to copy without fee all or part of this material is granted provided that the copies aTe not made OT distributed for direct commercial advantage, the VLDB copyright notice and the title of the publication and its date appear, and notice is given that copying is by permission of the Very Large Data Base Endowment. To copy otherwise, OT to republish, requirea a fee and/or special permission from the Endowment. Proceedings of the 22nd VLDB Conference Mumbai(Bombay), India, 1996"
            },
            "slug": "Obtaining-Complete-Answers-from-Incomplete-Halevy",
            "title": {
                "fragments": [],
                "text": "Obtaining Complete Answers from Incomplete Databases"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This work presents a novel sound and complete algorithm for the answer-completeness problem by relating it to the problem of independence of queries from updates and shows an important case of the independence problem that can be decided in polynomial time, whereas the best known algorithm for this case is exponential."
            },
            "venue": {
                "fragments": [],
                "text": "VLDB"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1717530"
                        ],
                        "name": "Y. Arens",
                        "slug": "Y.-Arens",
                        "structuredName": {
                            "firstName": "Yigal",
                            "lastName": "Arens",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Arens"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2081090860"
                        ],
                        "name": "C. Knobloch",
                        "slug": "C.-Knobloch",
                        "structuredName": {
                            "firstName": "C.",
                            "lastName": "Knobloch",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Knobloch"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3295983"
                        ],
                        "name": "C. Chee",
                        "slug": "C.-Chee",
                        "structuredName": {
                            "firstName": "Chin",
                            "lastName": "Chee",
                            "middleNames": [
                                "Yi"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Chee"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34607455"
                        ],
                        "name": "Chun-Nan Hsu",
                        "slug": "Chun-Nan-Hsu",
                        "structuredName": {
                            "firstName": "Chun-Nan",
                            "lastName": "Hsu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chun-Nan Hsu"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 139,
                                "start": 124
                            }
                        ],
                        "text": "Recently, there has been much interest in systems (such as software agents [30,36,49,66] or information-integration systems [8,18,19,45,55]) that automatically access such resources, manipulating their content on a user\u2019s behalf."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 38,
                                "start": 33
                            }
                        ],
                        "text": ", using the regular expression \u2018 [1-9][0-9]+ \u2019 to identify country codes."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 59996964,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1424a313382df0baa0ff9307268664bdef3f00c4",
            "isKey": false,
            "numCitedBy": 3,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract : With the current explosion of data, retrieving and integrating information from various sources is a critical problem. This report describes work performed at USC/ISI, aimed at developing a general and extensible approach to this problem. The SIMS approach exploits a semantic model of a problem domain to integrate the information from various sources, i.e., databases and knowledge bases. The domain and the information sources are modeled. Queries submitted to SIMS are mapped into a set of queries to individual information sources. The set of queries is then further optimized, using knowledge, about the domain and the information sources. The data obtained is then returned to the user. SIMS utilizes techniques from the areas of knowledge representation, planning, and learning"
            },
            "slug": "SIMS:-Single-Interface-to-Multiple-Sources-Arens-Knobloch",
            "title": {
                "fragments": [],
                "text": "SIMS: Single Interface to Multiple Sources"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "The SIMS approach exploits a semantic model of a problem domain to integrate the information from various sources, i.e., databases and knowledge bases, and utilizes techniques from the areas of knowledge representation, planning, and learning."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1766239"
                        ],
                        "name": "D. Fensel",
                        "slug": "D.-Fensel",
                        "structuredName": {
                            "firstName": "Dieter",
                            "lastName": "Fensel",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Fensel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685642"
                        ],
                        "name": "S. Decker",
                        "slug": "S.-Decker",
                        "structuredName": {
                            "firstName": "S.",
                            "lastName": "Decker",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Decker"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144006444"
                        ],
                        "name": "Michael Erdmann",
                        "slug": "Michael-Erdmann",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Erdmann",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael Erdmann"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144446653"
                        ],
                        "name": "R. Studer",
                        "slug": "R.-Studer",
                        "structuredName": {
                            "firstName": "Rudi",
                            "lastName": "Studer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Studer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 221,
                                "start": 214
                            }
                        ],
                        "text": "These challenges have lead to work on resource discovery [13], Web query languages [48,57], semi-structured data models [1,15], query planning [24,36,55], reasoning about local completeness [28,53] and ontological [31,56] knowledge, and handling heterogeneous identifiers [20,59]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 11728705,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "365f15608d03e1fc3af7da3afc3fe362080d4e72",
            "isKey": false,
            "numCitedBy": 174,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstraet The World Wide Web (WWW) is currently one of the most important electronic information sources. However, its query interfaces and the provided reasoning services are rather limited. Ontobroker consists of a number of languages and tools that enhance query access and inference service of the WWW. The technique is based on the use of ontologies. Ontologies are applied to annotate web documents and to provide query access and inference service that deal with the semantics of the presented information. In consequence, intelligent brokering services for web documents can be achieved without requiring to change the semiformal nature of web documents."
            },
            "slug": "Ontobroker:-The-Very-High-Idea-Fensel-Decker",
            "title": {
                "fragments": [],
                "text": "Ontobroker: The Very High Idea"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "Ontobroker consists of a number of languages and tools that enhance query access and inference service of the WWW that are based on the use of ontologies, and can be achieved without requiring to change the semiformal nature of web documents."
            },
            "venue": {
                "fragments": [],
                "text": "FLAIRS Conference"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "5963711"
                        ],
                        "name": "P. Buneman",
                        "slug": "P.-Buneman",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Buneman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Buneman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 126,
                                "start": 120
                            }
                        ],
                        "text": "These challenges have lead to work on resource discovery [13], Web query languages [48,57], semi-structured data models [1,15], query planning [24,36,55], reasoning about local completeness [28,53] and ontological [31,56] knowledge, and handling heterogeneous identifiers [20,59]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 207215544,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "dd0d6d75b55024521592e32064ea952a3419fd79",
            "isKey": false,
            "numCitedBy": 775,
            "numCiting": 51,
            "paperAbstract": {
                "fragments": [],
                "text": "In semistructured data, the information that is normally associated with a schema is contained within the data, which is sometimes called \u201cself-describing\u201d. In some forms of semistructured data there is no separate schema, in others it exists but only places loose constraints on the data. Semistructured data has recently emerged as an important topic of study for a variety of reasons. First, there are data sources such as the Web, which we would like to treat as databases but which cannot be constrained by a schema. Second, it may be desirable to have an extremely flexible format for data exchange between disparate databases. Third, even when dealing with structured data, it may be helpful to view it. as semistructured for the purposes of browsing. This tutorial will cover a number of issues surrounding such data: finding a concise formulation, building a sufficiently expressive language for querying and transformation, and optimizat,ion problems."
            },
            "slug": "Semistructured-data-Buneman",
            "title": {
                "fragments": [],
                "text": "Semistructured data"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A number of issues surrounding semistructured data are covered: finding a concise formulation, building a sufficiently expressive language for querying and transformation, and optimizat,ion problems."
            },
            "venue": {
                "fragments": [],
                "text": "PODS '97"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2911738"
                        ],
                        "name": "D. Angluin",
                        "slug": "D.-Angluin",
                        "structuredName": {
                            "firstName": "Dana",
                            "lastName": "Angluin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Angluin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Keywords:Information extraction; Wrapper induction; Machine learning; Internet information integration; Information agents"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7923260,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9899c9d7f3a5b5d9fc918675c0843754d160c986",
            "isKey": false,
            "numCitedBy": 210,
            "numCiting": 134,
            "paperAbstract": {
                "fragments": [],
                "text": "Permission to copy without fee all or part of this material ie granted provided that the copies are not made or distributed for direct commercial advantage, the ACM copyright notice and the title of the publication and its date appear, and notica is given that copying is by permission of the Association for Computing Machinery. To copy otherwise, or to republish, requires a fee and/or specific permission. 24th ANNUAL ACM STOC 5/92/VICTORiA, B. C., CANADA G 1992 ACM ()-89791.51 2-7/92/0004/03~j -..$1 .~() the only textbook in the field is Natarajan\u2019s [101]. Surveys by Laird [83] and Valiant [129] are valuable. Somewhat more peripheral are the European meetings on Analogical and Inductive Inference, AH, and the AI machine learning communit y\u2019s annual International Conference on Machine Learning. In addition, the general AI meetings, AAAI and IJCAI, currently have a large number of papers devoted to learning, as do the neural net meetings."
            },
            "slug": "Computational-learning-theory:-survey-and-selected-Angluin",
            "title": {
                "fragments": [],
                "text": "Computational learning theory: survey and selected bibliography"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "The general AI meetings, AAAI and IJCAI, currently have a large number of papers devoted to learning, as do the neural net meetings, and the European meetings on Analogical and Inductive Inference and the AI machine learning communit y\u2019s annual International Conference on Machine Learning."
            },
            "venue": {
                "fragments": [],
                "text": "STOC '92"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3139418"
                        ],
                        "name": "Sibel Adali",
                        "slug": "Sibel-Adali",
                        "structuredName": {
                            "firstName": "Sibel",
                            "lastName": "Adali",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sibel Adali"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1720972"
                        ],
                        "name": "K. Candan",
                        "slug": "K.-Candan",
                        "structuredName": {
                            "firstName": "K.",
                            "lastName": "Candan",
                            "middleNames": [
                                "Sel\u00e7uk"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Candan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1786049"
                        ],
                        "name": "Y. Papakonstantinou",
                        "slug": "Y.-Papakonstantinou",
                        "structuredName": {
                            "firstName": "Yannis",
                            "lastName": "Papakonstantinou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Papakonstantinou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1728462"
                        ],
                        "name": "V. S. Subrahmanian",
                        "slug": "V.-S.-Subrahmanian",
                        "structuredName": {
                            "firstName": "V.",
                            "lastName": "Subrahmanian",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. S. Subrahmanian"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 183,
                                "start": 180
                            }
                        ],
                        "text": "We were strongly influenced by the University of Washington \u201cSoftbot\u201d project [23,26,30,66,67]; related projects include ARIADNE [46], CARNOT [21], DISCO [32], GARLIC [18], HERMES [2], the Information Manifold [55],TSIMMIS [19], FUSION [68], BargainFinder [49], and the Knowledge Broker [4]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 38,
                                "start": 33
                            }
                        ],
                        "text": ", using the regular expression \u2018 [1-9][0-9]+ \u2019 to identify country codes."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 629579,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d3b35d849389be508572b6c2d798e9cd4d0b2d76",
            "isKey": false,
            "numCitedBy": 440,
            "numCiting": 129,
            "paperAbstract": {
                "fragments": [],
                "text": "Query processing and optimization in mediator systems that access distributed non-proprietary sources pose many novel problems. Cost-based query optimization is hard because the mediator does not have access to source statistics information and furthermore it may not be easy to model the source's performance. At the same time, querying remote sources may be very expensive because of high connection overhead, long computation time, financial charges, and temporary unavailability. We propose a cost-based optimization technique that caches statistics of actual calls to the sources and consequently estimates the cost of the possible execution plans based on the statistics cache. We investigate issues pertaining to the design of the statistics cache and experimentally analyze various tradeoffs. We also present a query result caching mechanism that allows us to effectively use results of prior queries when the source is not readily available. We employ the novel invariants mechanism, which shows how semantic information about data sources may be used to discover cached query results of interest."
            },
            "slug": "Query-caching-and-optimization-in-distributed-Adali-Candan",
            "title": {
                "fragments": [],
                "text": "Query caching and optimization in distributed mediator systems"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "A cost-based optimization technique that caches statistics of actual calls to the sources and consequently estimates the cost of the possible execution plans based on the statistics cache is proposed."
            },
            "venue": {
                "fragments": [],
                "text": "SIGMOD '96"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2911738"
                        ],
                        "name": "D. Angluin",
                        "slug": "D.-Angluin",
                        "structuredName": {
                            "firstName": "Dana",
                            "lastName": "Angluin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Angluin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 38,
                                "start": 33
                            }
                        ],
                        "text": ", using the regular expression \u2018 [1-9][0-9]+ \u2019 to identify country codes."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 11873053,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "225331d1700a9544545cc7c54a63c1b485269ce7",
            "isKey": false,
            "numCitedBy": 2037,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Learning-Regular-Sets-from-Queries-and-Angluin",
            "title": {
                "fragments": [],
                "text": "Learning Regular Sets from Queries and Counterexamples"
            },
            "venue": {
                "fragments": [],
                "text": "Inf. Comput."
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144456394"
                        ],
                        "name": "D. Florescu",
                        "slug": "D.-Florescu",
                        "structuredName": {
                            "firstName": "Daniela",
                            "lastName": "Florescu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Florescu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733877"
                        ],
                        "name": "L. Raschid",
                        "slug": "L.-Raschid",
                        "structuredName": {
                            "firstName": "Louiqa",
                            "lastName": "Raschid",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Raschid"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144255847"
                        ],
                        "name": "P. Valduriez",
                        "slug": "P.-Valduriez",
                        "structuredName": {
                            "firstName": "Patrick",
                            "lastName": "Valduriez",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Valduriez"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 17464597,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1608965184be3efeef0b4334ac92c56a79c5829e",
            "isKey": false,
            "numCitedBy": 45,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "In order to have signiicant practical impact on future information systems, multi-database management systems (MDBMS) must be both exible and eecient. We consider a MDBMS with a common object-oriented model, based on the ODMG standard, and local databases that may be relational or object-oriented. In this context , query rewriting (for optimization) is made diicult by schematic discrepancy, and the need to model mapping information between the multidatabase and local schemas. We address the exibility issue by representing the mappings from a local schema to the multidatabase schema, as a set of heterogeneous object equivalences, in a declarative language. EEciency is obtained by exploiting these equivalences to rewrite multidatabase OQL queries into equivalent, simpliied queries on the local schemas."
            },
            "slug": "Using-Heterogeneous-Equivalences-for-Query-in-Florescu-Raschid",
            "title": {
                "fragments": [],
                "text": "Using Heterogeneous Equivalences for Query Rewriting in Multidatabase Systems"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This work addresses the exibility issue by representing the mappings from a local schema to the multidatabase schema, as a set of heterogeneous object equivalences, in a declarative language, and exploiting these equivalences to rewrite multid atabase OQL queries into equivalent, simpliied queries on the local schemas."
            },
            "venue": {
                "fragments": [],
                "text": "CoopIS"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144826649"
                        ],
                        "name": "C. Bowman",
                        "slug": "C.-Bowman",
                        "structuredName": {
                            "firstName": "Carlos",
                            "lastName": "Bowman",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Bowman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2544751"
                        ],
                        "name": "P. Danzig",
                        "slug": "P.-Danzig",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Danzig",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Danzig"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1690411"
                        ],
                        "name": "U. Manber",
                        "slug": "U.-Manber",
                        "structuredName": {
                            "firstName": "Udi",
                            "lastName": "Manber",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "U. Manber"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34693971"
                        ],
                        "name": "M. Schwartz",
                        "slug": "M.-Schwartz",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Schwartz",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Schwartz"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 548701,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "29b5dbe0369b4b4a46c996d4eb94b2f62c1565dd",
            "isKey": false,
            "numCitedBy": 267,
            "numCiting": 73,
            "paperAbstract": {
                "fragments": [],
                "text": "Over the past several years, a number of information discovery and access tools have been introduced in the Internet, including Archie, Gopher, Net nd, and WAIS. These tools have become quite popular, and are helping to rede ne how people think about wide-area network applications. Yet, they are not well suited to supporting the future information infrastructure, which will be characterized by enormous data volume, rapid growth in the user base, and burgeoning data diversity. In this paper we indicate trends in these three dimensions and survey problems these trends will create for current approaches. We then suggest several promising directions of future resource discovery research, along with some initial results from projects carried out by members of the Internet Research Task Force Research Group on Resource Discovery and Directory Service."
            },
            "slug": "Scalable-Internet-resource-discovery:-research-and-Bowman-Danzig",
            "title": {
                "fragments": [],
                "text": "Scalable Internet resource discovery: research problems and approaches"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This paper indicates trends in these three dimensions of information infrastructure, and suggests several promising directions of future resource discovery research, along with some initial results from projects carried out by members of the Internet Research Task Force Research Group on Resource Discovery and Directory Service."
            },
            "venue": {
                "fragments": [],
                "text": "CACM"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1788525"
                        ],
                        "name": "J. Andreoli",
                        "slug": "J.-Andreoli",
                        "structuredName": {
                            "firstName": "Jean-Marc",
                            "lastName": "Andreoli",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Andreoli"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2067217778"
                        ],
                        "name": "Uwe M. Borghoff",
                        "slug": "Uwe-M.-Borghoff",
                        "structuredName": {
                            "firstName": "Uwe",
                            "lastName": "Borghoff",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Uwe M. Borghoff"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2617531"
                        ],
                        "name": "R. Pareschi",
                        "slug": "R.-Pareschi",
                        "structuredName": {
                            "firstName": "Remo",
                            "lastName": "Pareschi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Pareschi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "We were strongly influenced by the University of Washington \u201cSoftbot\u201d project [23,26,30,66,67]; related projects include ARIADNE [46], CARNOT [21], DISCO [32], GARLIC [18], HERMES [2], the Information Manifold [55], TSIMMIS [19], FUSION [68], BargainFinder [49], and the Knowledge Broker [ 4 ]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "The required recognition heuristics might be very primitive\u2014e.g., using the regular expression \u2018[ 1-9 ][0-9]+\u2019 to identify country codes."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 16756067,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4969a3f147a99043cd51460b46b32eb711d989a8",
            "isKey": false,
            "numCitedBy": 40,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract Imagine distributed knowledge processing with autonomous activities and decentralized control where the handling of partial knowledge does not result in unclear semantics or failure-prone behavior. In this paper, a modular approach is taken where concurrent agents, called constraint-based knowledge brokers (CBKBs), process and generate new knowledge in the presence of partial information. CBKBs apply constraint solving techniques to the domain of information gathering in distributed environments. Constraints are exploited to allow partial specification of the requested information, and to relate information requests from multiple sources. We present a mathematical model where the semantics of the knowledge system is described using a standard fixed-point procedure. A basic execution model is then provided. This is incrementally refined to tackle problems of inter-argument dependencies (that arise with constraints relating information requests from different sources), of knowledge reuse inside the knowledge generators, and of recursion control. The model refinements are illustrated by a detailed complexity analysis in terms of the number of agents needed and of the number of messages sent, distinguished by requests and answers of the involved broker agents. A detailed example shows a broker-based chart-parser for unification grammars with feature terms implemented using CBKBs. As we shall point out, this apparently abstract example can be easily generalized to full-fledged information gathering."
            },
            "slug": "The-Constraint-Based-Knowledge-Broker-Model:-and-Andreoli-Borghoff",
            "title": {
                "fragments": [],
                "text": "The Constraint-Based Knowledge Broker Model: Semantics, Implementation and Analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A modular approach is taken where concurrent agents, called constraint-based knowledge brokers (CBKBs), process and generate new knowledge in the presence of partial information in the domain of information gathering in distributed environments."
            },
            "venue": {
                "fragments": [],
                "text": "J. Symb. Comput."
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2911738"
                        ],
                        "name": "D. Angluin",
                        "slug": "D.-Angluin",
                        "structuredName": {
                            "firstName": "Dana",
                            "lastName": "Angluin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Angluin"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 38,
                                "start": 33
                            }
                        ],
                        "text": ", using the regular expression \u2018 [1-9][0-9]+ \u2019 to identify country codes."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 25,
                                "start": 22
                            }
                        ],
                        "text": ", reversible grammars [5]), but we do not know of algorithms that deliver the particular state topology we require."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 18300595,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "01fa2c3cc94a8d9de9b30a5488e67a5007e4856e",
            "isKey": false,
            "numCitedBy": 524,
            "numCiting": 64,
            "paperAbstract": {
                "fragments": [],
                "text": "A famdy of efficient algorithms for referring certain subclasses of the regular languages from fmtte posttwe samples is presented These subclasses are the k-reversible languages, for k = 0, 1, 2, . . . . For each k there is an algorithm for finding the smallest k-reversible language containing any fimte posluve sample. It ts shown how to use this algorithm to do correct identification m the ILmlt of the kreversible languages from posmve data A reversible language is one that Is k-reverstble for some k __ 0. An efficient algonthrn is presented for mfernng reversible languages from posmve and negative examples, and it is shown that it leads to correct identification m the hmlt of the class of reversible languages. Numerous examples are gtven to dlustrate the algorithms and their behawor"
            },
            "slug": "Inference-of-Reversible-Languages-Angluin",
            "title": {
                "fragments": [],
                "text": "Inference of Reversible Languages"
            },
            "tldr": {
                "abstractSimilarityScore": 52,
                "text": "An efficient algonthrn is presented for mfernng reversible languages from posmve and negative examples, and it is shown that it leads to correct identification m the hmlt of the class of reversible languages."
            },
            "venue": {
                "fragments": [],
                "text": "JACM"
            },
            "year": 1982
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2110094423"
                        ],
                        "name": "Amar Gupta",
                        "slug": "Amar-Gupta",
                        "structuredName": {
                            "firstName": "Amar",
                            "lastName": "Gupta",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Amar Gupta"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": ", [38,44,54, 75])."
                    },
                    "intents": []
                }
            ],
            "corpusId": 62144236,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "97061091c6f1afcb020f8c6c899a7ee6a3591f7a",
            "isKey": false,
            "numCitedBy": 97,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Where you can find the integration of information systems bridging heterogeneous databases easily? Is it in the book store? On-line book store? are you sure? Keep in mind that you will find the book in this site. This book is very referred for you because it gives not only the experience but also lesson. The lessons are very valuable to serve for you, that's not about who are reading this integration of information systems bridging heterogeneous databases book. It is about this book that will give wellness for all people from many societies."
            },
            "slug": "Integration-of-Information-Systems:-Bridging-Gupta",
            "title": {
                "fragments": [],
                "text": "Integration of Information Systems: Bridging Heterogeneous Databases"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This book is very referred for you because it gives not only the experience but also lesson, it is about this book that will give wellness for all people from many societies."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2076231991"
                        ],
                        "name": "T. Kirk",
                        "slug": "T.-Kirk",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Kirk",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kirk"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50874323"
                        ],
                        "name": "Alon Y. Levy",
                        "slug": "Alon-Y.-Levy",
                        "structuredName": {
                            "firstName": "Alon",
                            "lastName": "Levy",
                            "middleNames": [
                                "Y."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alon Y. Levy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1714472"
                        ],
                        "name": "Y. Sagiv",
                        "slug": "Y.-Sagiv",
                        "structuredName": {
                            "firstName": "Yehoshua",
                            "lastName": "Sagiv",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Sagiv"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145860176"
                        ],
                        "name": "D. Srivastava",
                        "slug": "D.-Srivastava",
                        "structuredName": {
                            "firstName": "Divesh",
                            "lastName": "Srivastava",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Srivastava"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 63440469,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a8450a2666891b0fa6be16d0fa320db25abe9bbb",
            "isKey": false,
            "numCitedBy": 378,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe the Information Manifold (IM), a system for browsing and querying of multiple networked information sources. As a first contribution, the system demonstrates the viability of knowledge representation technology for retrieval and organization of information from disparate (structured and unstructured) information sources. Such an organization allows the user to pose high-level queries that use data from multiple information sources. As a second contribution, we describe novel query processing algorithms used to combine information from multiple sources. In particular, our algorithms are guaranteed to find exactly the set of information sources relevant to a query, and to completely exploit knowledge about local closed world information (Etzioni et al. 1994)."
            },
            "slug": "The-Information-Manifold-Kirk-Levy",
            "title": {
                "fragments": [],
                "text": "The Information Manifold"
            },
            "tldr": {
                "abstractSimilarityScore": 84,
                "text": "The Information Manifold is described, a system for browsing and querying of multiple networked information sources that demonstrates the viability of knowledge representation technology for retrieval and organization of information from disparate information sources."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1741101"
                        ],
                        "name": "Oren Etzioni",
                        "slug": "Oren-Etzioni",
                        "structuredName": {
                            "firstName": "Oren",
                            "lastName": "Etzioni",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Oren Etzioni"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1780531"
                        ],
                        "name": "Daniel S. Weld",
                        "slug": "Daniel-S.-Weld",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Weld",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Daniel S. Weld"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 88,
                                "start": 75
                            }
                        ],
                        "text": "Recently, there has been much interest in systems (such as software agents [30,36,49,66] or information-integration systems [8,18,19,45,55]) that automatically access such resources, manipulating their content on a user\u2019s behalf."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 94,
                                "start": 78
                            }
                        ],
                        "text": "We were strongly influenced by the University of Washington \u201cSoftbot\u201d project [23,26,30,66,67]; related projects include ARIADNE [46], CARNOT [21], DISCO [32], GARLIC [18], HERMES [2], the Information Manifold [55],TSIMMIS [19], FUSION [68], BargainFinder [49], and the Knowledge Broker [4]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2447472,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "050584e3b74d1d7f5396d379510ca5204f02bfc1",
            "isKey": false,
            "numCitedBy": 602,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "The Internet Softbot (software robot) is a fullyimplemented AI agent developed at the University of Washington (Etzioni, Lcsh, & Segal 1993). The softbot uses a UNIX shell and the World-Wide Web to interact with a wide range of internet resources. The softbot\u2019s effectors include ftp, telnet, mail, and numerous file manipulation commaslds. Its sensors include internet facilities such as archie, gopher, netfind, and many more. The softbot is designed to incorporate new facilities into its repertoirc as they become available. The softbot\u2019s \"added value\" is three-fold. First, it provides an integrated and expressive interface to the internet. Second, the softbot dynamically chooses which facilities to invoke, and in what sequence. For example, the softbot might use netfind to determine David McAllester\u2019s e-mail address. Since it knows that netfind requires a person\u2019s institution as input, the softbot would first search bibliographic databases for a technical report by McAllester which would reveal his institutkm, and then feed that information to netfind. Third, the softbot fluidly backtracks from one facility to another based on information collected at run time. As a result., the softbot\u2019s behavior changes in response to transient system conditions (e.g., the UUCP gateway is down). In this article, we focus on the ideas underlying the softbot-based interface."
            },
            "slug": "A-softbot-based-interface-to-the-Internet-Etzioni-Weld",
            "title": {
                "fragments": [],
                "text": "A softbot-based interface to the Internet"
            },
            "tldr": {
                "abstractSimilarityScore": 85,
                "text": "The Internet Softbot (software robot) is a fullyimplemented AI agent developed at the University of Washington that uses a UNIX shell and the World-Wide Web to interact with a wide range of internet resources."
            },
            "venue": {
                "fragments": [],
                "text": "CACM"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1741101"
                        ],
                        "name": "Oren Etzioni",
                        "slug": "Oren-Etzioni",
                        "structuredName": {
                            "firstName": "Oren",
                            "lastName": "Etzioni",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Oren Etzioni"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 10145449,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cfdfc00d1bfd4fb635276f18d81bc6b79b7a0785",
            "isKey": false,
            "numCitedBy": 204,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "I view the World Wide Web as an information food chain (figure 1). The maze of pages and hyperlinks that comprise the Web are at the very bottom of the chain. The WebCrawlers and Alta Vistas of the world are information herbivores; they graze on Web pages and regurgitate them as searchable indices. Today, most Web users feed near the bottom of the information food chain, but the time is ripe to move up. Since 1991, we have been building information carnivores, which intelligently hunt and feast on herbivores in Unix (Etzioni, Lesh, & Segal 1993), on the Internet (Etzioni & Weld 1994), and on the Web (Doorenbos, Etzioni, & Weld 1996; Selberg & Etzioni 1995; Shakes, Langheinrich, & Etzioni 1996)."
            },
            "slug": "Moving-Up-the-Information-Food-Chain:-Deploying-on-Etzioni",
            "title": {
                "fragments": [],
                "text": "Moving Up the Information Food Chain: Deploying Softbots on the World Wide Web"
            },
            "tldr": {
                "abstractSimilarityScore": 87,
                "text": "I view the World Wide Web as an information food chain; the maze of pages and hyperlinks that comprise the Web are at the very bottom of the chain and the time is ripe to move up."
            },
            "venue": {
                "fragments": [],
                "text": "AI Mag."
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1681227"
                        ],
                        "name": "C. Collet",
                        "slug": "C.-Collet",
                        "structuredName": {
                            "firstName": "Christine",
                            "lastName": "Collet",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Collet"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1744170"
                        ],
                        "name": "M. Huhns",
                        "slug": "M.-Huhns",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Huhns",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Huhns"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2628069"
                        ],
                        "name": "Wei-Min Shen",
                        "slug": "Wei-Min-Shen",
                        "structuredName": {
                            "firstName": "Wei-Min",
                            "lastName": "Shen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wei-Min Shen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 146,
                                "start": 142
                            }
                        ],
                        "text": "We were strongly influenced by the University of Washington \u201cSoftbot\u201d project [23,26,30,66,67]; related projects include ARIADNE [46], CARNOT [21], DISCO [32], GARLIC [18], HERMES [2], the Information Manifold [55],TSIMMIS [19], FUSION [68], BargainFinder [49], and the Knowledge Broker [4]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14082993,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "495168474b5f963810cb1f6da3db0b239af1d655",
            "isKey": false,
            "numCitedBy": 316,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "A method for integrating separately developed information resources that overcomes incompatibilities in syntax and semantics and permits the resources to be accessed and modified coherently is described. The method provides logical connectivity among the information resources via a semantic service layer that automates the maintenance of data integrity and provides an approximation of global data integration across systems. This layer is a fundamental part of the Carnot architecture, which provides tools for interoperability across global enterprises.<<ETX>>"
            },
            "slug": "Resource-integration-using-a-large-knowledge-base-Collet-Huhns",
            "title": {
                "fragments": [],
                "text": "Resource integration using a large knowledge base in Carnot"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "The method provides logical connectivity among the information resources via a semantic service layer that automates the maintenance of data integrity and provides an approximation of global data integration across systems."
            },
            "venue": {
                "fragments": [],
                "text": "Computer"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1741124"
                        ],
                        "name": "L. Valiant",
                        "slug": "L.-Valiant",
                        "structuredName": {
                            "firstName": "Leslie",
                            "lastName": "Valiant",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Valiant"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Keywords:Information extraction; Wrapper induction; Machine learning; Internet information integration; Information agents"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 59712,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "10ddb646feddc12337b5a755c72e153e37088c02",
            "isKey": false,
            "numCitedBy": 4191,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "Humans appear to be able to learn new concepts without needing to be programmed explicitly in any conventional sense. In this paper we regard learning as the phenomenon of knowledge acquisition in the absence of explicit programming. We give a precise methodology for studying this phenomenon from a computational viewpoint. It consists of choosing an appropriate information gathering mechanism, the learning protocol, and exploring the class of concepts that can be learnt using it in a reasonable (polynomial) number of steps. We find that inherent algorithmic complexity appears to set serious limits to the range of concepts that can be so learnt. The methodology and results suggest concrete principles for designing realistic learning systems."
            },
            "slug": "A-theory-of-the-learnable-Valiant",
            "title": {
                "fragments": [],
                "text": "A theory of the learnable"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "This paper regards learning as the phenomenon of knowledge acquisition in the absence of explicit programming, and gives a precise methodology for studying this phenomenon from a computational viewpoint."
            },
            "venue": {
                "fragments": [],
                "text": "STOC '84"
            },
            "year": 1984
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1741101"
                        ],
                        "name": "Oren Etzioni",
                        "slug": "Oren-Etzioni",
                        "structuredName": {
                            "firstName": "Oren",
                            "lastName": "Etzioni",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Oren Etzioni"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1888618"
                        ],
                        "name": "K. Golden",
                        "slug": "K.-Golden",
                        "structuredName": {
                            "firstName": "Keith",
                            "lastName": "Golden",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Golden"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1780531"
                        ],
                        "name": "Daniel S. Weld",
                        "slug": "Daniel-S.-Weld",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Weld",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Daniel S. Weld"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 197,
                                "start": 190
                            }
                        ],
                        "text": "These challenges have lead to work on resource discovery [13], Web query languages [48,57], semi-structured data models [1,15], query planning [24,36,55], reasoning about local completeness [28,53] and ontological [31,56] knowledge, and handling heterogeneous identifiers [20,59]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 13600535,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7ffa695066b9a5d7438cf788fc0faba554ed6aed",
            "isKey": false,
            "numCitedBy": 140,
            "numCiting": 75,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Sound-and-Efficient-Closed-World-Reasoning-for-Etzioni-Golden",
            "title": {
                "fragments": [],
                "text": "Sound and Efficient Closed-World Reasoning for Planning"
            },
            "venue": {
                "fragments": [],
                "text": "Artif. Intell."
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3236427"
                        ],
                        "name": "E. Selberg",
                        "slug": "E.-Selberg",
                        "structuredName": {
                            "firstName": "Erik",
                            "lastName": "Selberg",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Selberg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1741101"
                        ],
                        "name": "Oren Etzioni",
                        "slug": "Oren-Etzioni",
                        "structuredName": {
                            "firstName": "Oren",
                            "lastName": "Etzioni",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Oren Etzioni"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 88,
                                "start": 75
                            }
                        ],
                        "text": "Recently, there has been much interest in systems (such as software agents [30,36,49,66] or information-integration systems [8,18,19,45,55]) that automatically access such resources, manipulating their content on a user\u2019s behalf."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 94,
                                "start": 78
                            }
                        ],
                        "text": "We were strongly influenced by the University of Washington \u201cSoftbot\u201d project [23,26,30,66,67]; related projects include ARIADNE [46], CARNOT [21], DISCO [32], GARLIC [18], HERMES [2], the Information Manifold [55],TSIMMIS [19], FUSION [68], BargainFinder [49], and the Knowledge Broker [4]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 72,
                                "start": 68
                            }
                        ],
                        "text": "We are interested in \u201cOC\u201d wrappers because the original Metacrawler [66] used them [65]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14643096,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "77e2e742d53ef382df9f896abadf291646eed3cc",
            "isKey": false,
            "numCitedBy": 314,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "The paper discusses the MetaCrawler Softbot parallel Web search service that has been available at the University of Washington since June 1995. It provides users with a single interface for querying popular general-purpose Web search services, such as Lycos and AltaVista, and has some sophisticated features that allow it to obtain results of much higher quality than simply regurgitating the output from each search service."
            },
            "slug": "The-MetaCrawler-architecture-for-resource-on-the-Selberg-Etzioni",
            "title": {
                "fragments": [],
                "text": "The MetaCrawler architecture for resource aggregation on the Web"
            },
            "tldr": {
                "abstractSimilarityScore": 68,
                "text": "The paper discusses the MetaCrawler Softbot parallel Web search service that has been available at the University of Washington since June 1995 and has some sophisticated features that allow it to obtain results of much higher quality than simply regurgitating the output from each search service."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1745117"
                        ],
                        "name": "Craig A. Knoblock",
                        "slug": "Craig-A.-Knoblock",
                        "structuredName": {
                            "firstName": "Craig",
                            "lastName": "Knoblock",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Craig A. Knoblock"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Recently, there has been much interest in systems (such as software agents [30,36,49,66] or information-integration systems [8,18,19, 45 ,55]) that automatically access such resources, manipulating their content on a user\u2019s behalf."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 297800,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "328df8732a4fcc387af4950470a9065edd2e1957",
            "isKey": false,
            "numCitedBy": 170,
            "numCiting": 62,
            "paperAbstract": {
                "fragments": [],
                "text": "Current specialized planners for query processing are designed to work in local, reliable, and predictable environments. However, a number of problems arise in gathering information from large networks of distributed information. In this environment, the same information may reside in multiple places, actions can be executed in parallel to exploit distributed resources, new goals come into the system during execution, actions may fail due to problems with remote databases or networks, and sensing may need to be interleaved with planning in order to formulate efficient queries. We have developed a planner called Sage that, addresses the issues that arise in this environment. This system integrates previous work on planning, execution, replanning, and sensing and extends this work to support simultaneous and interleaved planning and execution. Sage has been applied to the problem of information gathering to provide a flexible and efficient system for integrating heterogeneous and distributed data."
            },
            "slug": "Planning,-Executing,-Sensing,-and-Replanning-for-Knoblock",
            "title": {
                "fragments": [],
                "text": "Planning, Executing, Sensing, and Replanning for Information Gathering"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This work has developed a planner called Sage, which integrates previous work on planning, execution, replanning, and sensing and extends this work to support simultaneous and interleaved planning and execution."
            },
            "venue": {
                "fragments": [],
                "text": "IJCAI"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1717349"
                        ],
                        "name": "D. Knuth",
                        "slug": "D.-Knuth",
                        "structuredName": {
                            "firstName": "Donald",
                            "lastName": "Knuth",
                            "middleNames": [
                                "Ervin"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Knuth"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2118077243"
                        ],
                        "name": "James H. Morris",
                        "slug": "James-H.-Morris",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Morris",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "James H. Morris"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1691192"
                        ],
                        "name": "V. Pratt",
                        "slug": "V.-Pratt",
                        "structuredName": {
                            "firstName": "Vaughan",
                            "lastName": "Pratt",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Pratt"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 158,
                                "start": 154
                            }
                        ],
                        "text": "Since the candidates and strings being searched all have length bounded byV , each such search can be performed in time O (V ) using efficient techniques [47]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 11697579,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5253fead88bfeaaa2930daccb7324a264cb681a9",
            "isKey": false,
            "numCitedBy": 2974,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "An algorithm is presented which finds all occurrences of one given string within another, in running time proportional to the sum of the lengths of the strings. The constant of proportionality is low enough to make this algorithm of practical use, and the procedure can also be extended to deal with some more general pattern-matching problems. A theoretical application of the algorithm shows that the set of concatenations of even palindromes, i.e., the language $\\{\\alpha \\alpha ^R\\}^*$, can be recognized in linear time. Other algorithms which run even faster on the average are also considered."
            },
            "slug": "Fast-Pattern-Matching-in-Strings-Knuth-Morris",
            "title": {
                "fragments": [],
                "text": "Fast Pattern Matching in Strings"
            },
            "tldr": {
                "abstractSimilarityScore": 75,
                "text": "An algorithm is presented which finds all occurrences of one given string within another, in running time proportional to the sum of the lengths of the strings, showing that the set of concatenations of even palindromes, i.e., the language $\\{\\alpha \\alpha ^R\\}^*$, can be recognized in linear time."
            },
            "venue": {
                "fragments": [],
                "text": "SIAM J. Comput."
            },
            "year": 1977
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1736513"
                        ],
                        "name": "S. Wermter",
                        "slug": "S.-Wermter",
                        "structuredName": {
                            "firstName": "Stefan",
                            "lastName": "Wermter",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Wermter"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1691993"
                        ],
                        "name": "E. Riloff",
                        "slug": "E.-Riloff",
                        "structuredName": {
                            "firstName": "Ellen",
                            "lastName": "Riloff",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Riloff"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2576323"
                        ],
                        "name": "G. Scheler",
                        "slug": "G.-Scheler",
                        "structuredName": {
                            "firstName": "Gabriele",
                            "lastName": "Scheler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Scheler"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 21173842,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "319a3a51457b5fcaa179576de11305a045177eaa",
            "isKey": false,
            "numCitedBy": 159,
            "numCiting": 95,
            "paperAbstract": {
                "fragments": [],
                "text": "Learning approaches for natural language processing.- Separating learning and representation.- Natural language grammatical inference: A comparison of recurrent neural networks and machine learning methods.- Extracting rules for grammar recognition from Cascade-2 networks.- Generating English plural determiners from semantic representations: A neural network learning approach.- Knowledge acquisition in concept and document spaces by using self-organizing neural networks.- Using hybrid connectionist learning for speech/language analysis.- SKOPE: A connectionist/symbolic architecture of spoken Korean processing.- Integrating different learning approaches into a multilingual spoken language translation system.- Learning language using genetic algorithms.- A statistical syntactic disambiguation program and what it learns.- Training stochastic grammars on semantical categories.- Learning restricted probabilistic link grammars.- Learning PP attachment from corpus statistics.- A minimum description length approach to grammar inference.- Automatic classification of dialog acts with Semantic Classification Trees and Polygrams.- Sample selection in natural language learning.- Learning information extraction patterns from examples.- Implications of an automatic lexical acquisition system.- Using learned extraction patterns for text classification.- Issues in inductive learning of domain-specific text extraction rules.- Applying machine learning to anaphora resolution.- Embedded machine learning systems for natural language processing: A general framework.- Acquiring and updating hierarchical knowledge for machine translation based on a clustering technique.- Applying an existing machine learning algorithm to text categorization.- Comparative results on using inductive logic programming for corpus-based parser construction.- Learning the past tense of English verbs using inductive logic programming.- A dynamic approach to paradigm-driven analogy.- Can punctuation help learning?.- Using parsed corpora for circumventing parsing.- A symbolic and surgical acquisition of terms through variation.- A revision learner to acquire verb selection rules from human-made rules and examples.- Learning from texts - A terminological metareasoning perspective."
            },
            "slug": "Connectionist,-Statistical-and-Symbolic-Approaches-Wermter-Riloff",
            "title": {
                "fragments": [],
                "text": "Connectionist, Statistical and Symbolic Approaches to Learning for Natural Language Processing"
            },
            "tldr": {
                "abstractSimilarityScore": 55,
                "text": "Embedded machine learning systems for natural language processing: Acquiring and updating hierarchical knowledge for machine translation based on a clustering technique and applying an existing machine learning algorithm to text categorization."
            },
            "venue": {
                "fragments": [],
                "text": "Lecture Notes in Computer Science"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1714772"
                        ],
                        "name": "Dale Schuurmans",
                        "slug": "Dale-Schuurmans",
                        "structuredName": {
                            "firstName": "Dale",
                            "lastName": "Schuurmans",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dale Schuurmans"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143686063"
                        ],
                        "name": "R. Greiner",
                        "slug": "R.-Greiner",
                        "structuredName": {
                            "firstName": "Russell",
                            "lastName": "Greiner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Greiner"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 26,
                                "start": 22
                            }
                        ],
                        "text": "Shuurmans and Greiner [64] suggest another strategy: by replacing the \u201cbatch\u201d model on inductive learning with a \u201csequential\u201d model in which the PAC-theoretic analysis is repeated as each example is observed, many fewer examples are predicted."
                    },
                    "intents": []
                }
            ],
            "corpusId": 13241050,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e7ed8c715fe1a5a041faff5ff6fd7dded68f1b1f",
            "isKey": false,
            "numCitedBy": 9,
            "numCiting": 37,
            "paperAbstract": {
                "fragments": [],
                "text": "We present new strategies for \"probably approximately correct\" (par) learning that use fewer training examples than previous approaches. The idea is to observe training examples one-at-a-time and decide \"on-line\" when to return a hypothesis, rather than collect a large fixed-size training sample. This yields sequential learning procedures that par-learn by observing a small random number of examples. We provide theoretical bounds on the expected training sample size of our procedure -- but establish its efficiency primarily by a scries of experiments which show sequential learning actually uses many times fewer training examples in practice. These results demonstrate that pac-learning can be far more efficiently achieved in practice than previously thought."
            },
            "slug": "Practical-PAC-Learning-Schuurmans-Greiner",
            "title": {
                "fragments": [],
                "text": "Practical PAC Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 71,
                "text": "New strategies for \"probably approximately correct\" (par) learning that use fewer training examples than previous approaches are presented, demonstrating that pac-learning can be far more efficiently achieved in practice than previously thought."
            },
            "venue": {
                "fragments": [],
                "text": "IJCAI"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1745169"
                        ],
                        "name": "P. Bartlett",
                        "slug": "P.-Bartlett",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Bartlett",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Bartlett"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143957317"
                        ],
                        "name": "R. C. Williamson",
                        "slug": "R.-C.-Williamson",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Williamson",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. C. Williamson"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 98,
                                "start": 91
                            }
                        ],
                        "text": "A standard technique for tightening a PAC model is to assume that D has certain properties [10,12]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 34808786,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f8a25cfaa3a8da901962b06af6d460689b40b1bf",
            "isKey": false,
            "numCitedBy": 12,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Investigating-the-distribution-assumptions-in-the-Bartlett-Williamson",
            "title": {
                "fragments": [],
                "text": "Investigating the distribution assumptions in the Pac learning model"
            },
            "venue": {
                "fragments": [],
                "text": "COLT '91"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39045629"
                        ],
                        "name": "M. Bauer",
                        "slug": "M.-Bauer",
                        "structuredName": {
                            "firstName": "Mathias",
                            "lastName": "Bauer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Bauer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2262501"
                        ],
                        "name": "D. Dengler",
                        "slug": "D.-Dengler",
                        "structuredName": {
                            "firstName": "Dietmar",
                            "lastName": "Dengler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Dengler"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 35,
                                "start": 31
                            }
                        ],
                        "text": "In contrast, Bauer and Dengler [11] describe T RIA S, a wrapper induction system that relies more heavily on HTML."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 177,
                                "start": 161
                            }
                        ],
                        "text": "community has focused on free text [16,43,62,72], while the information integration and software agent communities have focused on structured Internet documents [9,11,41,52, 60]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 18168683,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9ac510032db62cce456052d6f4e7e874a29138ab",
            "isKey": false,
            "numCitedBy": 10,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "Software agents are intended to perform certain tasks on behalf of their users. In many cases, however, the agent\u2019s competence is not sufficient to produce the desired outcome. This paper presents an approach to cooperative problem solving in which a software agent and its user try to support each other in the achievement of a particular goal. As a side effect the user can extend the agent\u2019s capabilities in a programming-by-demonstration dialog, thus enabling it to autonomously perform similar tasks in the future."
            },
            "slug": "TrIAs-An-Architecture-for-Trainable-Information-Bauer-Dengler",
            "title": {
                "fragments": [],
                "text": "TrIAs - An Architecture for Trainable Information Assistants"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This paper presents an approach to cooperative problem solving in which a software agent and its user try to support each other in the achievement of a particular goal."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3187096"
                        ],
                        "name": "Jerry R. Hobbs",
                        "slug": "Jerry-R.-Hobbs",
                        "structuredName": {
                            "firstName": "Jerry",
                            "lastName": "Hobbs",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jerry R. Hobbs"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 133,
                                "start": 126
                            }
                        ],
                        "text": "Information extraction (IE) is the task of identifying fragments in a document that constitute its core semantic content; see [22,40] for surveys."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 639439,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e6a439ec029efaa370ac287f4ff9fe576ef0e925",
            "isKey": false,
            "numCitedBy": 130,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "An information extraction system is a cascade of transducers or modules that at each step add structure and often lose information, hopefully irrelevant, by applying rules that are acquired manually and/or automatically."
            },
            "slug": "The-generic-information-extraction-system-Hobbs",
            "title": {
                "fragments": [],
                "text": "The generic information extraction system"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "An information extraction system is a cascade of transducers or modules that at each step add structure and often lose information, hopefully irrelevant, by applying rules that are acquired manually and/or automatically."
            },
            "venue": {
                "fragments": [],
                "text": "MUC"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144497046"
                        ],
                        "name": "N. Nilsson",
                        "slug": "N.-Nilsson",
                        "structuredName": {
                            "firstName": "Nils",
                            "lastName": "Nilsson",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Nilsson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1028275,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b886f2c097b635ee9550ca29fff7dcbbb7727ff7",
            "isKey": false,
            "numCitedBy": 5912,
            "numCiting": 271,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper is a survey of Artifici'al Intelligence (AI). It divides the field into four cor~ topics (embodying the base fo\u00b7r a science of intelligence) and eight applications topics (in which research has been contributing to core ideas).. The paper discusses the history, the major landmarks, and some of the controversies in each of these twelve topics. Each topic is represented by a chart citing the major references. These references are contained in an extensive bibliography. The paper concludes with a discussion of some of the criticisms of 'AI and with some predictions about the course of future research."
            },
            "slug": "Artificial-Intelligence-Nilsson",
            "title": {
                "fragments": [],
                "text": "Artificial Intelligence"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "The history, the major landmarks, and some of the controversies in each of these twelve topics are discussed, as well as some predictions about the course of future research."
            },
            "venue": {
                "fragments": [],
                "text": "IFIP Congress"
            },
            "year": 1974
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2056642528"
                        ],
                        "name": "M. Kearns",
                        "slug": "M.-Kearns",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Kearns",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Kearns"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46753437"
                        ],
                        "name": "U. Vazirani",
                        "slug": "U.-Vazirani",
                        "structuredName": {
                            "firstName": "Umesh",
                            "lastName": "Vazirani",
                            "middleNames": [
                                "V."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "U. Vazirani"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 44944785,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "97e14147f2e61456bba016f720488410393f9e48",
            "isKey": false,
            "numCitedBy": 1786,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "The probably approximately correct learning model Occam's razor the Vapnik-Chervonenkis dimension weak and strong learning learning in the presence of noise inherent unpredictability reducibility in PAC learning learning finite automata by experimentation appendix - some tools for probabilistic analysis."
            },
            "slug": "An-Introduction-to-Computational-Learning-Theory-Kearns-Vazirani",
            "title": {
                "fragments": [],
                "text": "An Introduction to Computational Learning Theory"
            },
            "tldr": {
                "abstractSimilarityScore": 97,
                "text": "The probably approximately correct learning model Occam's razor the Vapnik-Chervonenkis dimension weak and strong learning learning in the presence of noise inherent unpredictability reducibility in PAC learning learning finite automata is described."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1821511"
                        ],
                        "name": "Gyora M. Benedek",
                        "slug": "Gyora-M.-Benedek",
                        "structuredName": {
                            "firstName": "Gyora",
                            "lastName": "Benedek",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Gyora M. Benedek"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1736744"
                        ],
                        "name": "A. Itai",
                        "slug": "A.-Itai",
                        "structuredName": {
                            "firstName": "Alon",
                            "lastName": "Itai",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Itai"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 98,
                                "start": 91
                            }
                        ],
                        "text": "A standard technique for tightening a PAC model is to assume that D has certain properties [10,12]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 5260687,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c23ed6b3bf16778c9f2a6a5b6b0b629e9b1b0af1",
            "isKey": false,
            "numCitedBy": 72,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Learnability-by-fixed-distributions-Benedek-Itai",
            "title": {
                "fragments": [],
                "text": "Learnability by fixed distributions"
            },
            "venue": {
                "fragments": [],
                "text": "COLT '88"
            },
            "year": 1988
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 169,
                                "start": 147
                            }
                        ],
                        "text": "There has been substantial research on specialized programming languages and graphical user interfaces to assist in manually writing such wrappers [3,25,37,39,42,63, 69]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "WysiWyg Web wrapper factory"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. World Wide Web Conference"
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The World Wide Web: Quagmire or gold mine?, Comm"
            },
            "venue": {
                "fragments": [],
                "text": "ACM"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 88,
                                "start": 75
                            }
                        ],
                        "text": "Recently, there has been much interest in systems (such as software agents [30,36,49,66] or information-integration systems [8,18,19,45,55]) that automatically access such resources, manipulating their content on a user\u2019s behalf."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 260,
                                "start": 256
                            }
                        ],
                        "text": "We were strongly influenced by the University of Washington \u201cSoftbot\u201d project [23,26,30,66,67]; related projects include ARIADNE [46], CARNOT [21], DISCO [32], GARLIC [18], HERMES [2], the Information Manifold [55],TSIMMIS [19], FUSION [68], BargainFinder [49], and the Knowledge Broker [4]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The BargainFinder agent: Comparison price shopping on the Internet"
            },
            "venue": {
                "fragments": [],
                "text": "Bots and Other Internet Beasties"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 87,
                                "start": 83
                            }
                        ],
                        "text": "We are interested in \u201cOC\u201d wrappers because the original Metacrawler [66] used them [65]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "May 1997"
            },
            "venue": {
                "fragments": [],
                "text": "Personal communication.  68  N. Kushmerick / Artificial Intelligence 118 "
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Working Notes of the AAAI Spring Symposium on Software Agents"
            },
            "venue": {
                "fragments": [],
                "text": "Working Notes of the AAAI Spring Symposium on Software Agents"
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Educating computer scientists"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 90,
                                "start": 83
                            }
                        ],
                        "text": "These challenges have lead to work on resource discovery [13], Web query languages [48,57], semi-structured data models [1,15], query planning [24,36,55], reasoning about local completeness [28,53] and ontological [31,56] knowledge, and handling heterogeneous identifiers [20,59]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "W3QL: A query system for the World Wide Web"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. Internat. Conference Very Large Data Bases"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 49,
                                "start": 45
                            }
                        ],
                        "text": "Furthermore, as Knoblock and Minton observed [54], wrapper induction algorithms may be able to use XML as a source of supervised training data."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Trends and controversies: Information integration"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Intelligent Systems"
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 94,
                                "start": 78
                            }
                        ],
                        "text": "We were strongly influenced by the University of Washington \u201cSoftbot\u201d project [23,26,30,66,67]; related projects include ARIADNE [46], CARNOT [21], DISCO [32], GARLIC [18], HERMES [2], the Information Manifold [55],TSIMMIS [19], FUSION [68], BargainFinder [49], and the Knowledge Broker [4]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Moving up the information food chain: Softbots as information carnivores"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. AAAI-96"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 61,
                                "start": 57
                            }
                        ],
                        "text": "These challenges have lead to work on resource discovery [13], Web query languages [48,57], semi-structured data models [1,15], query planning [24,36,55], reasoning about local completeness [28,53] and ontological [31,56] knowledge, and handling heterogeneous identifiers [20,59]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Scalable Internet discovery: Research problems and approaches"
            },
            "venue": {
                "fragments": [],
                "text": "Comm. ACM"
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Proc. Workshop on AI and Information Integration"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. Workshop on AI and Information Integration"
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 290,
                                "start": 287
                            }
                        ],
                        "text": "We were strongly influenced by the University of Washington \u201cSoftbot\u201d project [23,26,30,66,67]; related projects include ARIADNE [46], CARNOT [21], DISCO [32], GARLIC [18], HERMES [2], the Information Manifold [55],TSIMMIS [19], FUSION [68], BargainFinder [49], and the Knowledge Broker [4]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 38,
                                "start": 33
                            }
                        ],
                        "text": ", using the regular expression \u2018 [1-9][0-9]+ \u2019 to identify country codes."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The constraint-based knowledge broker mode: Semantics"
            },
            "venue": {
                "fragments": [],
                "text": "implementation and analysis, J. Symbolic Comput. 21 (4) "
            },
            "year": 1996
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 48,
            "methodology": 28,
            "result": 1
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 78,
        "totalPages": 8
    },
    "page_url": "https://www.semanticscholar.org/paper/Wrapper-induction:-Efficiency-and-expressiveness-Kushmerick/2f052f40a3307de1e45e11a3007a7552b36ebfc8?sort=total-citations"
}