{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3734276"
                        ],
                        "name": "G. Stent",
                        "slug": "G.-Stent",
                        "structuredName": {
                            "firstName": "Gunther",
                            "lastName": "Stent",
                            "middleNames": [
                                "Siegmund"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Stent"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 37447871,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "4b277f7462d3e0ecfe90352b430e23d1528d5463",
            "isKey": false,
            "numCitedBy": 652,
            "numCiting": 1,
            "paperAbstract": {
                "fragments": [],
                "text": "Hebb's postulate of learning envisages that activation or inactivation of extant synaptic contacts in plastic neural networks depends on the synchronous impulse activity of pre- and postsynaptic nerve cells. The physiological mechanism proposed here for this process posits that at synapses acting according to Hebb's postulate, the receptors for the neurotransmitter are eliminated from the postsynaptic membrane by the transient reversals of the sign of membrane polarization that occur during action potential impulses in the postsynaptic cell. But, since the release of neurotransmitter drives the membrane potential of the synaptic zone towards a level about half-way between the negative-inside resting potential and the positive-inside action potential, it would follow that the membrane patches surrounding the receptors of a synapse whose activity has contributed to setting off the postsynaptic impulse would be spared the full extent of the noxious polarity reversal. This mechanism can account for a neurophysiologically documented example of the operation of Hebb's postulate, namely the plasticity of the connections between fourth- and fifth-order neurons in the visual cortex of cats."
            },
            "slug": "A-physiological-mechanism-for-Hebb's-postulate-of-Stent",
            "title": {
                "fragments": [],
                "text": "A physiological mechanism for Hebb's postulate of learning."
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "The physiological mechanism proposed here for this process posits that at synapses acting according to Hebb's postulate, the receptors for the neurotransmitter are eliminated from the post Synaptic membrane by the transient reversals of the sign of membrane polarization that occur during action potential impulses in the postsynaptic cell."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the National Academy of Sciences of the United States of America"
            },
            "year": 1973
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3085659"
                        ],
                        "name": "H. Kushner",
                        "slug": "H.-Kushner",
                        "structuredName": {
                            "firstName": "Harold",
                            "lastName": "Kushner",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Kushner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35229585"
                        ],
                        "name": "D. Clark",
                        "slug": "D.-Clark",
                        "structuredName": {
                            "firstName": "Dean",
                            "lastName": "Clark",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Clark"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 167,
                                "start": 144
                            }
                        ],
                        "text": "Recent techniques of stochastic approximation theory are available for analyzing learning equations of the type given here (see Ljung, 1977 and Kushner and Clark, 1978)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 260,
                                "start": 237
                            }
                        ],
                        "text": "(8) and the stochastic equations (5) and (6) are close with a large probability and eventually the solution m(t) of (5) and (6) tends (with probability one) to a uniformly asymptotically stable solution of (8) (see e.g. Theorem 2.3.1 of Kushner and Clark, 1978)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 117328031,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "0009c5a2b4b07751a99bcf407d95e911a3064d0f",
            "isKey": true,
            "numCitedBy": 948,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "I. Introduction.- 1.1. General Remarks.- 1.2. The Robbins-Monro Process.- 1.3. A \"Continuous\" Process Version of Section 2.- 1.4. Regulation of a Dynamical System a simple example.- 1.5. Function Minimization: The Kiefer-Wolfowitz Procedure.- 1.6. Constrained Problems.- 1.7. An Economics Example.- II. Convergence w.p.1 for Unconstrained Systems.- 2.1. Preliminaries and Motivation.- 2.2. The Robbins-Monro and Kiefer-Wolfowitz Algorithms: Conditions and Discussion.- 2.3. Convergence Proofs for RM and KW-like Procedures.- 2.3.1. A Basic RM-like Procedure.- 2.3.2. One Dimensional RM and Accelerated RM Procedures.- 2.3.3. A Continuous Parameter RM Procedure.- 2.3.4. The Basic Kiefer-Wolfowitz Procedure.- 2.3.5. Random Directions KW Methods.- 2.4. A General Robbins-Monro Process: \"Exogenous Noise\".- 2.4.1. The Case of Bounded h(*,*).- 2.4.2. Unbounded h(*,*): Exogenous Noise.- 2.5. A General RM Process State Dependent Noise.- 2.5.1. Extensions and Localizations of Theorem 2.5.2.- 2.6. Some Applications.- 2.7. Mensov-Rademacher Estimates.- III. Weak Convergence of Probability Measures.- IV. Weak Convergence for Unconstrained Systems.- 4.1. Conditions and General Discussion.- 4.2. The Robbins-Monro and Kiefer-Wolfowitz Procedures.- 4.2.1. The Basic Robbins-Monro Procedure.- 4.2.2. The One-Dimensional Robbins-Monro Procedure.- 4.2.3. The Kiefer-Wolfowitz Procedure.- 4.2.4. A Case Where the Limit Satisfies a Generalized ODE.- 4.2.5. A Continuous Parameter KW Procedure.- 4.3. A General Robbins-Monro Process: Exogenous Noise.- 4.4. A General RM Process: State Dependent Noise.- 4.5. The Identification Problem.- 4.6. A Counter-Example to Tightness.- 4.7. Boundedness of {Xn} and Tightness of {Xn(*)}.- V. Convergence w.p.1 For Constrained Systems.- 5.1. A Penalty-Multiplier Algorithm for Equality Constraints.- 5.1.1. A Basic RM-like Algorithm, Conditions and Discussion.- 5.1.2. The Noise Condition, Discussion and Generalization.- 5.1.3. Boundedness of {Xn}.- 5.1.4. Proof of the Main Theorem.- 5.1.5. Constrained Function Minimization and Other Extensions.- 5.2. A Lagrangian Method for Inequality Constraints.- 5.2.1. The Algorithm and Conditions.- 5.2.2. The Convergence Theorem 18.- 5.2.3. A Non-Convergent but Useful Algorithm.- 5.2.4. An Application to the Identification Problem.- 5.3. A Projection Algorithm.- 5.4. A Penalty-Multiplier Method for Inequality Constraints.- VI. Weak Convergence: Constrained Systems.- 6.1. A Multiplier Type Algorithm for Equality Constraints.- 6.1.1. Boundedness of {Xn}.- 6.1.2. The Noise Condition, Discussion.- 6.1.3. The Convergence Theorem.- 6.2. The Lagrangian Method.- 6.3. A Projection Algorithm.- 6.4. A Penalty-Multiplier Algorithm for Inequality Constraints.- VII. Rates of Convergence.- 7.1. The Problem Formulation.- 7.2. Conditions and Discussions.- 7.3. Rates of Convergence for Case 1, the KW Algorithm.- 7.4. Discussion of Rates of Convergence for Two KW Algorithms."
            },
            "slug": "wchastic.-approximation-methods-for-constrained-and-Kushner-Clark",
            "title": {
                "fragments": [],
                "text": "wchastic. approximation methods for constrained and unconstrained systems"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The Robbins-Monro and Kiefer-Wolfowitz Algorithm for Inequality Constraints and the Weak Convergence of Probability Measures, a simple example, and the Convergence Theorem, a proof of the Main Theorem."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1978
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "69577099"
                        ],
                        "name": "T. W. Anderson",
                        "slug": "T.-W.-Anderson",
                        "structuredName": {
                            "firstName": "Theodore",
                            "lastName": "Anderson",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. W. Anderson"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 121297223,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "02f96e21e8f87f9e3cd59ccbe5eaee5f8357e766",
            "isKey": false,
            "numCitedBy": 6345,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Preface to the Third Edition.Preface to the Second Edition.Preface to the First Edition.1. Introduction.2. The Multivariate Normal Distribution.3. Estimation of the Mean Vector and the Covariance Matrix.4. The Distributions and Uses of Sample Correlation Coefficients.5. The Generalized T2-Statistic.6. Classification of Observations.7. The Distribution of the Sample Covariance Matrix and the Sample Generalized Variance.8. Testing the General Linear Hypothesis: Multivariate Analysis of Variance9. Testing Independence of Sets of Variates.10. Testing Hypotheses of Equality of Covariance Matrices and Equality of Mean Vectors and Covariance Matrices.11. Principal Components.12. Cononical Correlations and Cononical Variables.13. The Distributions of Characteristic Roots and Vectors.14. Factor Analysis.15. Pattern of Dependence Graphical Models.Appendix A: Matrix Theory.Appendix B: Tables.References.Index."
            },
            "slug": "An-Introduction-to-Multivariate-Statistical-Anderson",
            "title": {
                "fragments": [],
                "text": "An Introduction to Multivariate Statistical Analysis"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1959
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46945687"
                        ],
                        "name": "R. Redheffer",
                        "slug": "R.-Redheffer",
                        "structuredName": {
                            "firstName": "Raymond",
                            "lastName": "Redheffer",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Redheffer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48864956"
                        ],
                        "name": "J. Hale",
                        "slug": "J.-Hale",
                        "structuredName": {
                            "firstName": "Jack",
                            "lastName": "Hale",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Hale"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 119437710,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "d7938b3dc574c1675ae49fe329181f77679054ed",
            "isKey": false,
            "numCitedBy": 2618,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Ordinary-Differential-Equations.-Redheffer-Hale",
            "title": {
                "fragments": [],
                "text": "Ordinary Differential Equations."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1971
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688681"
                        ],
                        "name": "T. Kohonen",
                        "slug": "T.-Kohonen",
                        "structuredName": {
                            "firstName": "Teuvo",
                            "lastName": "Kohonen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kohonen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1726997"
                        ],
                        "name": "E. Oja",
                        "slug": "E.-Oja",
                        "structuredName": {
                            "firstName": "Erkki",
                            "lastName": "Oja",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Oja"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "67252661"
                        ],
                        "name": "P. Lehtio",
                        "slug": "P.-Lehtio",
                        "structuredName": {
                            "firstName": "Pirkko",
                            "lastName": "Lehtio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Lehtio"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 57899115,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8c9c15afc1d2e617b1adf7422c9d262c201edb94",
            "isKey": false,
            "numCitedBy": 108,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Storage-and-Processing-of-Information-in-Memory-Kohonen-Oja",
            "title": {
                "fragments": [],
                "text": "Storage and Processing of Information in Distributed Associative Memory Systems"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1981
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143886582"
                        ],
                        "name": "R. P\u00e9rez",
                        "slug": "R.-P\u00e9rez",
                        "structuredName": {
                            "firstName": "Rafael",
                            "lastName": "P\u00e9rez",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. P\u00e9rez"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145548576"
                        ],
                        "name": "L. Glass",
                        "slug": "L.-Glass",
                        "structuredName": {
                            "firstName": "Leon",
                            "lastName": "Glass",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Glass"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9640800"
                        ],
                        "name": "R. Shlaer",
                        "slug": "R.-Shlaer",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Shlaer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Shlaer"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 165,
                                "start": 147
                            }
                        ],
                        "text": "In many recent models, the feature detecting function has been emphasized (Cooper et al., 1979; v o n d e r Malsburg, 1973; Nass and Cooper, 1973; Perez et al., 1975; Takeuchi and Amari, 1979)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 181,
                                "start": 163
                            }
                        ],
                        "text": "In many model studies using related elements, inhibitory lateral connections have been assumed (Cooper et al., 1979; vonder Malsburg, 1973; Nass and Cooper, 1975; Perez et al., 1975; Takeuchi and Amari, 1979) which have an effect of enhancing selectivity to the incoming patterns."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 38522356,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "93ded91ec8dbb7a15aeb6b65d12346bfddf11507",
            "isKey": false,
            "numCitedBy": 61,
            "numCiting": 41,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Development-of-Specificity-in-the-Cat-Visual-Cortex-P\u00e9rez-Glass",
            "title": {
                "fragments": [],
                "text": "Development of Specificity in the Cat Visual Cortex"
            },
            "venue": {
                "fragments": [],
                "text": "Journal of mathematical biology"
            },
            "year": 1975
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47804608"
                        ],
                        "name": "R. Bek",
                        "slug": "R.-Bek",
                        "structuredName": {
                            "firstName": "Roman",
                            "lastName": "Bek",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Bek"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 20520403,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "a09d930fea5161406f735acf02e703e7824811dc",
            "isKey": false,
            "numCitedBy": 721,
            "numCiting": 1,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Discourse-on-one-way-in-which-a-quantum-mechanics-Bek",
            "title": {
                "fragments": [],
                "text": "Discourse on one way in which a quantum-mechanics language on the classical logical base can be built up"
            },
            "venue": {
                "fragments": [],
                "text": "Kybernetika"
            },
            "year": 1978
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 188,
                                "start": 164
                            }
                        ],
                        "text": "A similar algorithm, arising in the context of digital signal processing and numerical methods of mathematical statistics, has been analyzed in detail elsewhere by Oja and Karhunen (1981). The following can be proven:"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "On stochastic approximation of eigenvectors and eigenvalues of the expectation"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1975
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 2,
            "methodology": 2
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 8,
        "totalPages": 1
    },
    "page_url": "https://www.semanticscholar.org/paper/Simplified-neuron-model-as-a-principal-component-Oja/3e00dd12caea7c4dab1633a35d1da3cb2e76b420?sort=total-citations"
}