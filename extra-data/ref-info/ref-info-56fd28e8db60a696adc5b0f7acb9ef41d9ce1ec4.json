{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1693945"
                        ],
                        "name": "T. G\u00e4rtner",
                        "slug": "T.-G\u00e4rtner",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "G\u00e4rtner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. G\u00e4rtner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47840704"
                        ],
                        "name": "Peter A. Flach",
                        "slug": "Peter-A.-Flach",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Flach",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Peter A. Flach"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "97484233"
                        ],
                        "name": "A. Kowalczyk",
                        "slug": "A.-Kowalczyk",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Kowalczyk",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Kowalczyk"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46234526"
                        ],
                        "name": "Alex Smola",
                        "slug": "Alex-Smola",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Smola",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alex Smola"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 17874965,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "10c1ab4e9ad4b5c6f8298812e2aed1c615ee3ebb",
            "isKey": false,
            "numCitedBy": 527,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "Learning from structured data is becoming increasingly important. However, most prior work on kernel methods has focused on learning from attribute-value data. Only recently, research started investigating kernels for structured data. This paper considers kernels for multi-instance problems a class of concepts on individuals represented by sets. The main result of this paper is a kernel on multi-instance data that can be shown to separate positive and negative sets under natural assumptions. This kernel compares favorably with state of the art multi-instance learning algorithms in an empirical study. Finally, we give some concluding remarks and propose future work that might further improve the results."
            },
            "slug": "Multi-Instance-Kernels-G\u00e4rtner-Flach",
            "title": {
                "fragments": [],
                "text": "Multi-Instance Kernels"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A kernel on multi-instance data that can be shown to separate positive and negative sets under natural assumptions is shown and compares favorably with state of the art multi- instance learning algorithms in an empirical study."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1693945"
                        ],
                        "name": "T. G\u00e4rtner",
                        "slug": "T.-G\u00e4rtner",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "G\u00e4rtner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. G\u00e4rtner"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 3219195,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e1673eedc49aee031f07785eb96f557f451468b4",
            "isKey": false,
            "numCitedBy": 174,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "Learning from structured data is becoming increasingly important. However, most prior work on kernel methods has focused on learning from attribute-value data. Only recently have researchers started investigating kernels for structured data. This paper describes how kernel definitions can be simplified by identifying the structure of the data and how kernels can be defined on this structure. We propose a kernel for structured data, prove that it is positive definite, and show how it can be adapted in practical applications."
            },
            "slug": "Kernels-for-structured-data-G\u00e4rtner",
            "title": {
                "fragments": [],
                "text": "Kernels for structured data"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This paper proposes a kernel for structured data, proves that it is positive definite, and shows how it can be adapted in practical applications."
            },
            "venue": {
                "fragments": [],
                "text": "ILP"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1693945"
                        ],
                        "name": "T. G\u00e4rtner",
                        "slug": "T.-G\u00e4rtner",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "G\u00e4rtner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. G\u00e4rtner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47840704"
                        ],
                        "name": "Peter A. Flach",
                        "slug": "Peter-A.-Flach",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Flach",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Peter A. Flach"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145057418"
                        ],
                        "name": "S. Wrobel",
                        "slug": "S.-Wrobel",
                        "structuredName": {
                            "firstName": "Stefan",
                            "lastName": "Wrobel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Wrobel"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 10856944,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "647fdaacfcea319677175464b7db39e3b22c7808",
            "isKey": false,
            "numCitedBy": 883,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "As most \u2018real-world\u2019 data is structured, research in kernel methods has begun investigating kernels for various kinds of structured data. One of the most widely used tools for modeling structured data are graphs. An interesting and important challenge is thus to investigate kernels on instances that are represented by graphs. So far, only very specific graphs such as trees and strings have been considered."
            },
            "slug": "On-Graph-Kernels:-Hardness-Results-and-Efficient-G\u00e4rtner-Flach",
            "title": {
                "fragments": [],
                "text": "On Graph Kernels: Hardness Results and Efficient Alternatives"
            },
            "tldr": {
                "abstractSimilarityScore": 77,
                "text": "As most \u2018real-world\u2019 data is structured, research in kernel methods has begun investigating kernels for various kinds of structured data, but only very specific graphs such as trees and strings have been considered."
            },
            "venue": {
                "fragments": [],
                "text": "COLT"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2785830"
                        ],
                        "name": "H. Kashima",
                        "slug": "H.-Kashima",
                        "structuredName": {
                            "firstName": "Hisashi",
                            "lastName": "Kashima",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Kashima"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1775450"
                        ],
                        "name": "Teruo Koyanagi",
                        "slug": "Teruo-Koyanagi",
                        "structuredName": {
                            "firstName": "Teruo",
                            "lastName": "Koyanagi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Teruo Koyanagi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "A generalization ofthiskerneltoalsotakeintoaccountother substructures ofthetreesisdescribedin[ 22 ] .A substructure ofatreeisdefinedasatreesuchthatthereisadescendants preservingmappingfrom vertices inthesubstructure toverticesinthetree3.Anothergeneralization consideredinthat paperisthatofallowinglabelsto partially match.Promisingresultshave been achievedwiththiskernelfunctionin HTML document classification tasks."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 17397851,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2e24efd1d26dae508b34827b7f9e5bb92fc6f3b0",
            "isKey": false,
            "numCitedBy": 139,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "Semi-structured data such as XML and HTML is attracting considerable attention. It is important to develop various kinds of data mining techniques that can handle semistructured data. In this paper, we discuss applications of kernel methods for semistructured data. We model semi-structured data by labeled ordered trees, and present kernels for classifying labeled ordered trees based on their tag structures by generalizing the convolution kernel for parse trees introduced by Collins and Duffy (2001). We give algorithms to efficiently compute the kernels for labeled ordered trees. We also apply our kernels to node marking problems that are special cases of information extraction from trees. Preliminary experiments using artificial data and real HTML documents show encouraging results."
            },
            "slug": "Kernels-for-Semi-Structured-Data-Kashima-Koyanagi",
            "title": {
                "fragments": [],
                "text": "Kernels for Semi-Structured Data"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This paper model semi-structured data by labeled ordered trees, and presents kernels for classifying labeled ordering trees based on their tag structures by generalizing the convolution kernel for parse trees introduced by Collins and Duffy (2001)."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2834541"
                        ],
                        "name": "R. Kondor",
                        "slug": "R.-Kondor",
                        "structuredName": {
                            "firstName": "Risi",
                            "lastName": "Kondor",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Kondor"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1739581"
                        ],
                        "name": "J. Lafferty",
                        "slug": "J.-Lafferty",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Lafferty",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Lafferty"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5525836,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "6320770fe216ebbba769b9f0a006669b616a03d0",
            "isKey": false,
            "numCitedBy": 888,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "The application of kernel-based learning algorithms has, so far, largely been confined to realvalued data and a few special data types, such as strings. In this paper we propose a general method of constructing natural families of kernels over discrete structures, based on the matrix exponentiation idea. In particular, we focus on generating kernels on graphs, for which we propose a special class of exponential kernels called diffusion kernels, which are based on the heat equation and can be regarded as the discretization of the familiar Gaussian kernel of Euclidean space."
            },
            "slug": "Diffusion-Kernels-on-Graphs-and-Other-Discrete-Kondor-Lafferty",
            "title": {
                "fragments": [],
                "text": "Diffusion Kernels on Graphs and Other Discrete Input Spaces"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "This paper proposes a general method of constructing natural families of kernels over discrete structures, based on the matrix exponentiation idea, and focuses on generating kernels on graphs, for which a special class of exponential kernels called diffusion kernels are proposed."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34628173"
                        ],
                        "name": "K. Tsuda",
                        "slug": "K.-Tsuda",
                        "structuredName": {
                            "firstName": "Koji",
                            "lastName": "Tsuda",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Tsuda"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48271444"
                        ],
                        "name": "Taishin Kin",
                        "slug": "Taishin-Kin",
                        "structuredName": {
                            "firstName": "Taishin",
                            "lastName": "Kin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Taishin Kin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1699299"
                        ],
                        "name": "K. Asai",
                        "slug": "K.-Asai",
                        "structuredName": {
                            "firstName": "Kiyoshi",
                            "lastName": "Asai",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Asai"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9960390,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "44a07a1fc4143cab722751197b12dde3dcc6032b",
            "isKey": false,
            "numCitedBy": 202,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "MOTIVATION\nKernel methods such as support vector machines require a kernel function between objects to be defined a priori. Several works have been done to derive kernels from probability distributions, e.g., the Fisher kernel. However, a general methodology to design a kernel is not fully developed.\n\n\nRESULTS\nWe propose a reasonable way of designing a kernel when objects are generated from latent variable models (e.g., HMM). First of all, a joint kernel is designed for complete data which include both visible and hidden variables. Then a marginalized kernel for visible data is obtained by taking the expectation with respect to hidden variables. We will show that the Fisher kernel is a special case of marginalized kernels, which gives another viewpoint to the Fisher kernel theory. Although our approach can be applied to any object, we particularly derive several marginalized kernels useful for biological sequences (e.g., DNA and proteins). The effectiveness of marginalized kernels is illustrated in the task of classifying bacterial gyrase subunit B (gyrB) amino acid sequences."
            },
            "slug": "Marginalized-kernels-for-biological-sequences-Tsuda-Kin",
            "title": {
                "fragments": [],
                "text": "Marginalized kernels for biological sequences"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This work proposes a reasonable way of designing a kernel when objects are generated from latent variable models (e.g., HMM), and derives several marginalized kernels useful for biological sequences."
            },
            "venue": {
                "fragments": [],
                "text": "ISMB"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143707112"
                        ],
                        "name": "M. Collins",
                        "slug": "M.-Collins",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Collins",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Collins"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143857271"
                        ],
                        "name": "Nigel P. Duffy",
                        "slug": "Nigel-P.-Duffy",
                        "structuredName": {
                            "firstName": "Nigel",
                            "lastName": "Duffy",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nigel P. Duffy"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 396794,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e6c7adc28e20d361d5c35aa9808094b10f6a34d1",
            "isKey": false,
            "numCitedBy": 932,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe the application of kernel methods to Natural Language Processing (NLP) problems. In many NLP tasks the objects being modeled are strings, trees, graphs or other discrete structures which require some mechanism to convert them into feature vectors. We describe kernels for various natural language structures, allowing rich, high dimensional representations of these structures. We show how a kernel over trees can be applied to parsing using the voted perceptron algorithm, and we give experimental results on the ATIS corpus of parse trees."
            },
            "slug": "Convolution-Kernels-for-Natural-Language-Collins-Duffy",
            "title": {
                "fragments": [],
                "text": "Convolution Kernels for Natural Language"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "It is shown how a kernel over trees can be applied to parsing using the voted perceptron algorithm, and experimental results on the ATIS corpus of parse trees are given."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145034054"
                        ],
                        "name": "K. M\u00fcller",
                        "slug": "K.-M\u00fcller",
                        "structuredName": {
                            "firstName": "Klaus-Robert",
                            "lastName": "M\u00fcller",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. M\u00fcller"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2459012"
                        ],
                        "name": "S. Mika",
                        "slug": "S.-Mika",
                        "structuredName": {
                            "firstName": "Sebastian",
                            "lastName": "Mika",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Mika"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152597562"
                        ],
                        "name": "Gunnar R\u00e4tsch",
                        "slug": "Gunnar-R\u00e4tsch",
                        "structuredName": {
                            "firstName": "Gunnar",
                            "lastName": "R\u00e4tsch",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Gunnar R\u00e4tsch"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34628173"
                        ],
                        "name": "K. Tsuda",
                        "slug": "K.-Tsuda",
                        "structuredName": {
                            "firstName": "Koji",
                            "lastName": "Tsuda",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Tsuda"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1707625"
                        ],
                        "name": "B. Sch\u00f6lkopf",
                        "slug": "B.-Sch\u00f6lkopf",
                        "structuredName": {
                            "firstName": "Bernhard",
                            "lastName": "Sch\u00f6lkopf",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Sch\u00f6lkopf"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5894296,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1fcbefeb0beae4470cf40df74cd116b1d4bdcae4",
            "isKey": false,
            "numCitedBy": 3518,
            "numCiting": 211,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper provides an introduction to support vector machines, kernel Fisher discriminant analysis, and kernel principal component analysis, as examples for successful kernel-based learning methods. We first give a short background about Vapnik-Chervonenkis theory and kernel feature spaces and then proceed to kernel based learning in supervised and unsupervised scenarios including practical and algorithmic considerations. We illustrate the usefulness of kernel algorithms by discussing applications such as optical character recognition and DNA analysis."
            },
            "slug": "An-introduction-to-kernel-based-learning-algorithms-M\u00fcller-Mika",
            "title": {
                "fragments": [],
                "text": "An introduction to kernel-based learning algorithms"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "This paper provides an introduction to support vector machines, kernel Fisher discriminant analysis, and kernel principal component analysis, as examples for successful kernel-based learning methods."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Neural Networks"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "4562073"
                        ],
                        "name": "C. Watkins",
                        "slug": "C.-Watkins",
                        "structuredName": {
                            "firstName": "Chris",
                            "lastName": "Watkins",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Watkins"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 17875902,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7dd9743183f07b7653cc0335fcc1042aa71032c6",
            "isKey": false,
            "numCitedBy": 232,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": "There is much current interest in kernel methods for classi cation re gression PCA and other linear methods of data analysis Kernel methods may be particularly valuable for problems in which the input data is not readily described by explicit feature vectors One such problem is where input data consists of symbol sequences of di erent lengths and the re lationships between sequences are best captured by dynamic alignment scores This paper shows that the scores produced by certain dynamic align ment algorithms for sequences are in fact valid kernel functions This is proved by expressing the alignment scores explicitly as dot products Alignment kernels are potentially applicable to biological sequence data speech data and time series data The kernel construction may be extended from pair HMMs to pair probabilistic context free grammars Introduction Linear Methods using Kernel Functions Introduction Linear Methods using Kernel Functions In many types of machine learning the learner is given a training set of cases or examples a al A A denotes the set of all possible cases cases may be vectors pieces of text biological sequences sentences etc For supervised learning the cases are accompanied by a set of corresponding labels or values y yl The cases are mapped to feature vectors x xl X where the X is a real vector space termed the feature space The mapping from A to X is denoted by so that xi ai Sometimes the cases are given as feature vectors to start with in which case may be the identity mapping otherwise denotes the method of assigning numeric feature values to a case Once a feature vector xi has been de ned for each case ai it becomes pos sible to apply a wide range of linear methods such as support vector machines linear regression principal components analysis PCA and k means cluster analysis As shown in Vap for SV machines in for example Wah for linear re gression and in SSM for PCA and k means cluster analysis the calculations for all of these linear methods may be carried out using a dual rather than a primal formulation of the problem For example in linear least squares regression the primal formulation is to nd a coe cient vector that minimises kX yk whereX is the design matrix an l by d matrix in which the ith row is xi and each xi has d elements If l is larger than d the usual method of nding is to solve the normal equations XX Xy This requires the solution of a set of linear equations with coe cients given by the d d matrix XX The dual formulation is to nd a coe cient vector that minimises kXX yk so that one coe cient i is found for each case vector xi This requires the solution of a set of linear equations with coe cients given by the l l matrix XX Both methods lead to the same predicted value y for a new case x If there are more cases than features that is if l d the primal method is more economical because the d d matrix XX is smaller than the l l matrix XX For example if there are cases each described by a vector of measurements then the primal method requires solving a by system of linear equations while the dual method requires solving a by system which will have rank at most For such a problem the dual method has no advantage The potential advantage of the dual method for regression is that it can be applied to very large feature vectors The coe cient matrix XX contains the dot products of pairs of feature vectors the ijth element of XX is xi xj In the dual calculation it is only dot products of feature vectors that are used feature vectors never appear on their own As the feature vectors xi ai appear only in dot products it is often possible to avoid computing the feature vectors and to compute dot products directly in some economical fashion from the case descriptions ai instead A kernel is a function k that computes a dot product of feature vectors from the corresponding cases Applying Linear Methods to Structured Objects De nition A kernel is a function k such that for all a b A"
            },
            "slug": "Dynamic-Alignment-Kernels-Watkins",
            "title": {
                "fragments": [],
                "text": "Dynamic Alignment Kernels"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This paper shows that the scores produced by certain dynamic align ment algorithms for sequences are in fact valid kernel functions, proved by expressing the alignment scores explicitly as dot products."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2785830"
                        ],
                        "name": "H. Kashima",
                        "slug": "H.-Kashima",
                        "structuredName": {
                            "firstName": "Hisashi",
                            "lastName": "Kashima",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Kashima"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34628173"
                        ],
                        "name": "K. Tsuda",
                        "slug": "K.-Tsuda",
                        "structuredName": {
                            "firstName": "Koji",
                            "lastName": "Tsuda",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Tsuda"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35237557"
                        ],
                        "name": "Akihiro Inokuchi",
                        "slug": "Akihiro-Inokuchi",
                        "structuredName": {
                            "firstName": "Akihiro",
                            "lastName": "Inokuchi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Akihiro Inokuchi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5129873,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2dfd92c808487049ab4c9b45db77e9055b9da5a2",
            "isKey": false,
            "numCitedBy": 808,
            "numCiting": 56,
            "paperAbstract": {
                "fragments": [],
                "text": "A new kernel function between two labeled graphs is presented. Feature vectors are defined as the counts of label paths produced by random walks on graphs. The kernel computation finally boils down to obtaining the stationary state of a discrete-time linear system, thus is efficiently performed by solving simultaneous linear equations. Our kernel is based on an infinite dimensional feature space, so it is fundamentally different from other string or tree kernels based on dynamic programming. We will present promising empirical results in classification of chemical compounds."
            },
            "slug": "Marginalized-Kernels-Between-Labeled-Graphs-Kashima-Tsuda",
            "title": {
                "fragments": [],
                "text": "Marginalized Kernels Between Labeled Graphs"
            },
            "tldr": {
                "abstractSimilarityScore": 51,
                "text": "A new kernel function between two labeled graphs that is based on an infinite dimensional feature space, so it is fundamentally different from other string or tree kernels based on dynamic programming and presents promising empirical results in classification of chemical compounds."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733689"
                        ],
                        "name": "D. Haussler",
                        "slug": "D.-Haussler",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Haussler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Haussler"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 17702358,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "5ee0d8aeb2cb01ef4d8a858d234e72a7400c03ac",
            "isKey": false,
            "numCitedBy": 1371,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce a new method of constructing kernels on sets whose elements are discrete structures like strings, trees and graphs. The method can be applied iteratively to build a kernel on a innnite set from kernels involving generators of the set. The family of kernels generated generalizes the family of radial basis kernels. It can also be used to deene kernels in the form of joint Gibbs probability distributions. Kernels can be built from hidden Markov random elds, generalized regular expressions, pair-HMMs, or ANOVA de-compositions. Uses of the method lead to open problems involving the theory of innnitely divisible positive deenite functions. Fundamentals of this theory and the theory of reproducing kernel Hilbert spaces are reviewed and applied in establishing the validity of the method."
            },
            "slug": "Convolution-kernels-on-discrete-structures-Haussler",
            "title": {
                "fragments": [],
                "text": "Convolution kernels on discrete structures"
            },
            "tldr": {
                "abstractSimilarityScore": 92,
                "text": "A new method of constructing kernels on sets whose elements are discrete structures like strings, trees and graphs is introduced, which can be applied iteratively to build a kernel on a innnite set from kernels involving generators of the set."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685083"
                        ],
                        "name": "N. Cristianini",
                        "slug": "N.-Cristianini",
                        "structuredName": {
                            "firstName": "Nello",
                            "lastName": "Cristianini",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Cristianini"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1404459229"
                        ],
                        "name": "J. Shawe-Taylor",
                        "slug": "J.-Shawe-Taylor",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Shawe-Taylor",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Shawe-Taylor"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14727192,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5c04f8002e24a8c09bfbfedca3c6c346fe1e5d53",
            "isKey": false,
            "numCitedBy": 13352,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "From the publisher: This is the first comprehensive introduction to Support Vector Machines (SVMs), a new generation learning system based on recent advances in statistical learning theory. SVMs deliver state-of-the-art performance in real-world applications such as text categorisation, hand-written character recognition, image classification, biosequences analysis, etc., and are now established as one of the standard tools for machine learning and data mining. Students will find the book both stimulating and accessible, while practitioners will be guided smoothly through the material required for a good grasp of the theory and its applications. The concepts are introduced gradually in accessible and self-contained stages, while the presentation is rigorous and thorough. Pointers to relevant literature and web sites containing software ensure that it forms an ideal starting point for further study. Equally, the book and its associated web site will guide practitioners to updated literature, new applications, and on-line software."
            },
            "slug": "An-Introduction-to-Support-Vector-Machines-and-Cristianini-Shawe-Taylor",
            "title": {
                "fragments": [],
                "text": "An Introduction to Support Vector Machines and Other Kernel-based Learning Methods"
            },
            "tldr": {
                "abstractSimilarityScore": 80,
                "text": "This is the first comprehensive introduction to Support Vector Machines (SVMs), a new generation learning system based on recent advances in statistical learning theory, and will guide practitioners to updated literature, new applications, and on-line software."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1727076"
                        ],
                        "name": "H. Lodhi",
                        "slug": "H.-Lodhi",
                        "structuredName": {
                            "firstName": "Huma",
                            "lastName": "Lodhi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Lodhi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144884649"
                        ],
                        "name": "C. Saunders",
                        "slug": "C.-Saunders",
                        "structuredName": {
                            "firstName": "Craig",
                            "lastName": "Saunders",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Saunders"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1404459229"
                        ],
                        "name": "J. Shawe-Taylor",
                        "slug": "J.-Shawe-Taylor",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Shawe-Taylor",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Shawe-Taylor"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685083"
                        ],
                        "name": "N. Cristianini",
                        "slug": "N.-Cristianini",
                        "structuredName": {
                            "firstName": "Nello",
                            "lastName": "Cristianini",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Cristianini"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "4562073"
                        ],
                        "name": "C. Watkins",
                        "slug": "C.-Watkins",
                        "structuredName": {
                            "firstName": "Chris",
                            "lastName": "Watkins",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Watkins"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 669209,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f330f1f472f860212b980bb9be81eff884f7f0e1",
            "isKey": false,
            "numCitedBy": 1643,
            "numCiting": 43,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce a novel kernel for comparing two text documents. The kernel is an inner product in the feature space consisting of all subsequences of length k. A subsequence is any ordered sequence of k characters occurring in the text though not necessarily contiguously. The subsequences are weighted by an exponentially decaying factor of their full length in the text, hence emphasising those occurrences which are close to contiguous. A direct computation of this feature vector would involve a prohibitive amount of computation even for modest values of k, since the dimension of the feature space grows exponentially with k. The paper describes how despite this fact the inner product can be efficiently evaluated by a dynamic programming technique. A preliminary experimental comparison of the performance of the kernel compared with a standard word feature space kernel [6] is made showing encouraging results."
            },
            "slug": "Text-Classification-using-String-Kernels-Lodhi-Saunders",
            "title": {
                "fragments": [],
                "text": "Text Classification using String Kernels"
            },
            "tldr": {
                "abstractSimilarityScore": 70,
                "text": "A novel kernel is introduced for comparing two text documents consisting of an inner product in the feature space consisting of all subsequences of length k, which can be efficiently evaluated by a dynamic programming technique."
            },
            "venue": {
                "fragments": [],
                "text": "J. Mach. Learn. Res."
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2785830"
                        ],
                        "name": "H. Kashima",
                        "slug": "H.-Kashima",
                        "structuredName": {
                            "firstName": "Hisashi",
                            "lastName": "Kashima",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Kashima"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35237557"
                        ],
                        "name": "Akihiro Inokuchi",
                        "slug": "Akihiro-Inokuchi",
                        "structuredName": {
                            "firstName": "Akihiro",
                            "lastName": "Inokuchi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Akihiro Inokuchi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 118485817,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "01b835a2300107032298e2189a0318768a1378a2",
            "isKey": false,
            "numCitedBy": 81,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we apply kernel methods to graph classification problems. To achieve the goal, we have to design an appropriate kernel for computing inner products for pairs of graphs represented in a feature space. We define a graph kernel by a random walk on a vertex product graph of two graphs. Some experiments on predicting properties of chemical compounds show encouraging results."
            },
            "slug": "Kernels-for-graph-classification-Kashima-Inokuchi",
            "title": {
                "fragments": [],
                "text": "Kernels for graph classification"
            },
            "tldr": {
                "abstractSimilarityScore": 72,
                "text": "This paper defines a graph kernel by a random walk on a vertex product graph of two graphs to design an appropriate kernel for computing inner products for pairs of graphs represented in a feature space."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35132120"
                        ],
                        "name": "T. Jaakkola",
                        "slug": "T.-Jaakkola",
                        "structuredName": {
                            "firstName": "T.",
                            "lastName": "Jaakkola",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Jaakkola"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733689"
                        ],
                        "name": "D. Haussler",
                        "slug": "D.-Haussler",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Haussler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Haussler"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1888591,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c35cc80fe8c6cdea742d4fa1af1f2e698d41aba7",
            "isKey": false,
            "numCitedBy": 278,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce a class of exible conditional probability models and techniques for classi cation regression problems Many existing methods such as generalized linear models and support vector machines are subsumed under this class The exibility of this class of techniques comes from the use of kernel functions as in support vector machines and the generality from dual formulations of stan dard regression models"
            },
            "slug": "Probabilistic-kernel-regression-models-Jaakkola-Haussler",
            "title": {
                "fragments": [],
                "text": "Probabilistic kernel regression models"
            },
            "tldr": {
                "abstractSimilarityScore": 67,
                "text": "A class of exible conditional probability models and techniques for classi cation regression problems that comes from the use of kernel functions as in support vector machines and the generality from dual formulations of stan dard regression models is introduced."
            },
            "venue": {
                "fragments": [],
                "text": "AISTATS"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34628173"
                        ],
                        "name": "K. Tsuda",
                        "slug": "K.-Tsuda",
                        "structuredName": {
                            "firstName": "Koji",
                            "lastName": "Tsuda",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Tsuda"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716788"
                        ],
                        "name": "M. Kawanabe",
                        "slug": "M.-Kawanabe",
                        "structuredName": {
                            "firstName": "Motoaki",
                            "lastName": "Kawanabe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Kawanabe"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2414086"
                        ],
                        "name": "G. R\u00e4tsch",
                        "slug": "G.-R\u00e4tsch",
                        "structuredName": {
                            "firstName": "Gunnar",
                            "lastName": "R\u00e4tsch",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. R\u00e4tsch"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3029782"
                        ],
                        "name": "S. Sonnenburg",
                        "slug": "S.-Sonnenburg",
                        "structuredName": {
                            "firstName": "S\u00f6ren",
                            "lastName": "Sonnenburg",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Sonnenburg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145034054"
                        ],
                        "name": "K. M\u00fcller",
                        "slug": "K.-M\u00fcller",
                        "structuredName": {
                            "firstName": "Klaus-Robert",
                            "lastName": "M\u00fcller",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. M\u00fcller"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 11013893,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "84cccc9e14e49a6c56147e4cd36bda2ffd70b683",
            "isKey": false,
            "numCitedBy": 151,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "Recently, Jaakkola and Haussler (1999) proposed a method for constructing kernel functions from probabilistic models. Their so-called Fisher kernel has been combined with discriminative classifiers such as support vector machines and applied successfully in, for example, DNA and protein analysis. Whereas the Fisher kernel is calculated from the marginal log-likelihood, we propose the TOP kernel derived from tangent vectors of posterior log-odds. Furthermore, we develop a theoretical framework on feature extractors from probabilistic models and use it for analyzing the TOP kernel. In experiments, our new discriminative TOP kernel compares favorably to the Fisher kernel."
            },
            "slug": "A-New-Discriminative-Kernel-from-Probabilistic-Tsuda-Kawanabe",
            "title": {
                "fragments": [],
                "text": "A New Discriminative Kernel from Probabilistic Models"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This work proposes a new discriminative TOP kernel derived from tangent vectors of posterior log-odds and develops a theoretical framework on feature extractors from probabilistic models and uses it for analyzing the TOP kernel."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145728220"
                        ],
                        "name": "K. Bennett",
                        "slug": "K.-Bennett",
                        "structuredName": {
                            "firstName": "Kristin",
                            "lastName": "Bennett",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Bennett"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145990261"
                        ],
                        "name": "C. Campbell",
                        "slug": "C.-Campbell",
                        "structuredName": {
                            "firstName": "Colin",
                            "lastName": "Campbell",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Campbell"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 207753020,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "62bb14cc7c1a3c0841262846b3eb55a5da43df1c",
            "isKey": false,
            "numCitedBy": 693,
            "numCiting": 106,
            "paperAbstract": {
                "fragments": [],
                "text": "Support Vector Machines (SVMs) and related kernel methods have become increasingly popular tools for data mining tasks such as classification, regression, and novelty detection. The goal of this tutorial is to provide an intuitive explanation of SVMs from a geometric perspective. The classification problem is used to investigate the basic concepts behind SVMs and to examine their strengths and weaknesses from a data mining perspective. While this overview is not comprehensive, it does provide resources for those interested in further exploring SVMs."
            },
            "slug": "Support-vector-machines:-hype-or-hallelujah-Bennett-Campbell",
            "title": {
                "fragments": [],
                "text": "Support vector machines: hype or hallelujah?"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "An intuitive explanation of SVMs from a geometric perspective is provided and the classification problem is used to investigate the basic concepts behind SVMs and to examine their strengths and weaknesses from a data mining perspective."
            },
            "venue": {
                "fragments": [],
                "text": "SKDD"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3209133"
                        ],
                        "name": "C. Leslie",
                        "slug": "C.-Leslie",
                        "structuredName": {
                            "firstName": "Christina",
                            "lastName": "Leslie",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Leslie"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1709847"
                        ],
                        "name": "E. Eskin",
                        "slug": "E.-Eskin",
                        "structuredName": {
                            "firstName": "Eleazar",
                            "lastName": "Eskin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Eskin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145183709"
                        ],
                        "name": "J. Weston",
                        "slug": "J.-Weston",
                        "structuredName": {
                            "firstName": "Jason",
                            "lastName": "Weston",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Weston"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144458655"
                        ],
                        "name": "William Stafford Noble",
                        "slug": "William-Stafford-Noble",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Noble",
                            "middleNames": [
                                "Stafford"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "William Stafford Noble"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5112756,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2aec4a2aa286a0093bf124482ed106f7e965ee8b",
            "isKey": false,
            "numCitedBy": 334,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce a class of string kernels, called mismatch kernels, for use with support vector machines (SVMs) in a discriminative approach to the protein classification problem. These kernels measure sequence similarity based on shared occurrences of -length subsequences, counted with up to mismatches, and do not rely on any generative model for the positive training sequences. We compute the kernels efficiently using a mismatch tree data structure and report experiments on a benchmark SCOP dataset, where we show that the mismatch kernel used with an SVM classifier performs as well as the Fisher kernel, the most successful method for remote homology detection, while achieving considerable computational savings."
            },
            "slug": "Mismatch-String-Kernels-for-SVM-Protein-Leslie-Eskin",
            "title": {
                "fragments": [],
                "text": "Mismatch String Kernels for SVM Protein Classification"
            },
            "tldr": {
                "abstractSimilarityScore": 68,
                "text": "A class of string kernels, called mismatch kernels, are introduced for use with support vector machines (SVMs) in a discriminative approach to the protein classification problem, and show that the mismatch kernel used with an SVM classifier performs as well as the Fisher kernel, the most successful method for remote homology detection."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144884649"
                        ],
                        "name": "C. Saunders",
                        "slug": "C.-Saunders",
                        "structuredName": {
                            "firstName": "Craig",
                            "lastName": "Saunders",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Saunders"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1404459229"
                        ],
                        "name": "J. Shawe-Taylor",
                        "slug": "J.-Shawe-Taylor",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Shawe-Taylor",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Shawe-Taylor"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2916561"
                        ],
                        "name": "Alexei Vinokourov",
                        "slug": "Alexei-Vinokourov",
                        "structuredName": {
                            "firstName": "Alexei",
                            "lastName": "Vinokourov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alexei Vinokourov"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 13026481,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "21494ed027e1c067563776f63840565a6b2e6b0d",
            "isKey": false,
            "numCitedBy": 43,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we show how the generation of documents can be thought of as a k-stage Markov process, which leads to a Fisher kernel from which the n-gram and string kernels can be re-constructed. The Fisher kernel view gives a more flexible insight into the string kernel and suggests how it can be parametrised in a way that reflects the statistics of the training corpus. Furthermore, the probabilistic modelling approach suggests extending the Markov process to consider sub-sequences of varying length, rather than the standard fixed-length approach used in the string kernel. We give a procedure for determining which sub-sequences are informative features and hence generate a Finite State Machine model, which can again be used to obtain a Fisher kernel. By adjusting the parametrisation we can also influence the weighting received by the features. In this way we are able to obtain a logarithmic weighting in a Fisher kernel. Finally, experiments are reported comparing the different kernels using the standard Rag of Words kernel as a baseline."
            },
            "slug": "String-Kernels,-Fisher-Kernels-and-Finite-State-Saunders-Shawe-Taylor",
            "title": {
                "fragments": [],
                "text": "String Kernels, Fisher Kernels and Finite State Automata"
            },
            "tldr": {
                "abstractSimilarityScore": 93,
                "text": "This paper shows how the generation of documents can be thought of as a k-stage Markov process, which leads to a Fisher kernel from which the n-gram and string kernels can be re-constructed, and suggests how the Fisher kernel view gives a more flexible insight into the string kernel."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145713876"
                        ],
                        "name": "S. Vishwanathan",
                        "slug": "S.-Vishwanathan",
                        "structuredName": {
                            "firstName": "S.",
                            "lastName": "Vishwanathan",
                            "middleNames": [
                                "V.",
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Vishwanathan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46234526"
                        ],
                        "name": "Alex Smola",
                        "slug": "Alex-Smola",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Smola",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alex Smola"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5118862,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "72a7e7bc1911b6a327c4614553bfcde98194d4ef",
            "isKey": false,
            "numCitedBy": 350,
            "numCiting": 42,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we present a new algorithm suitable for matching discrete objects such as strings and trees in linear time, thus obviating dynamic programming with quadratic time complexity. Furthermore, prediction cost in many cases can be reduced to linear cost in the length of the sequence to be classified, regardless of the number of support vectors. This improvement on the currently available algorithms makes string kernels a viable alternative for the practitioner."
            },
            "slug": "Fast-Kernels-for-String-and-Tree-Matching-Vishwanathan-Smola",
            "title": {
                "fragments": [],
                "text": "Fast Kernels for String and Tree Matching"
            },
            "tldr": {
                "abstractSimilarityScore": 70,
                "text": "A new algorithm suitable for matching discrete objects such as strings and trees in linear time is presented, thus obviating dynamic programming with quadratic time complexity and improvement on the currently available algorithms makes string kernels a viable alternative for the practitioner."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145471897"
                        ],
                        "name": "S. Kramer",
                        "slug": "S.-Kramer",
                        "structuredName": {
                            "firstName": "Stefan",
                            "lastName": "Kramer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Kramer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1730104"
                        ],
                        "name": "N. Lavrac",
                        "slug": "N.-Lavrac",
                        "structuredName": {
                            "firstName": "Nada",
                            "lastName": "Lavrac",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Lavrac"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47840704"
                        ],
                        "name": "Peter A. Flach",
                        "slug": "Peter-A.-Flach",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Flach",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Peter A. Flach"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 118426129,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5ae377db282d5b7ab971da802bf733d677a23020",
            "isKey": false,
            "numCitedBy": 325,
            "numCiting": 46,
            "paperAbstract": {
                "fragments": [],
                "text": "This chapter surveys methods that transform a relational representation of a learning problem into a propositional (feature-based, attribute-value) representation. This kind of representation change is known as propositionalization. Taking such an approach, feature construction can be decoupled from model construction. It has been shown that in many relational data mining applications this can be done without loss of predictive performance. After reviewing both general-purpose and domain-dependent propositionalization approaches from the literature, an extension to the LINUS propositionalization method that overcomes the system's earlier inability to deal with non-determinate local variables is described."
            },
            "slug": "Propositionalization-approaches-to-relational-data-Kramer-Lavrac",
            "title": {
                "fragments": [],
                "text": "Propositionalization approaches to relational data mining"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "An extension to the LINUS propositionalization method that overcomes the system's earlier inability to deal with non-determinate local variables is described, and it is shown that in many relational data mining applications this can be done without loss of predictive performance."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3209133"
                        ],
                        "name": "C. Leslie",
                        "slug": "C.-Leslie",
                        "structuredName": {
                            "firstName": "Christina",
                            "lastName": "Leslie",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Leslie"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1709847"
                        ],
                        "name": "E. Eskin",
                        "slug": "E.-Eskin",
                        "structuredName": {
                            "firstName": "Eleazar",
                            "lastName": "Eskin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Eskin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144458655"
                        ],
                        "name": "William Stafford Noble",
                        "slug": "William-Stafford-Noble",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Noble",
                            "middleNames": [
                                "Stafford"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "William Stafford Noble"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9725578,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5c9071391823bd9b4458669c262344fd5daed676",
            "isKey": false,
            "numCitedBy": 1093,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce a new sequence-similarity kernel, the spectrum kernel, for use with support vector machines (SVMs) in a discriminative approach to the protein classification problem. Our kernel is conceptually simple and efficient to compute and, in experiments on the SCOP database, performs well in comparison with state-of-the-art methods for homology detection. Moreover, our method produces an SVM classifier that allows linear time classification of test sequences. Our experiments provide evidence that string-based kernels, in conjunction with SVMs, could offer a viable and computationally efficient alternative to other methods of protein classification and homology detection."
            },
            "slug": "The-Spectrum-Kernel:-A-String-Kernel-for-SVM-Leslie-Eskin",
            "title": {
                "fragments": [],
                "text": "The Spectrum Kernel: A String Kernel for SVM Protein Classification"
            },
            "tldr": {
                "abstractSimilarityScore": 74,
                "text": "A new sequence-similarity kernel, the spectrum kernel, is introduced for use with support vector machines (SVMs) in a discriminative approach to the protein classification problem and performs well in comparison with state-of-the-art methods for homology detection."
            },
            "venue": {
                "fragments": [],
                "text": "Pacific Symposium on Biocomputing"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3222653"
                        ],
                        "name": "Mark-A. Krogel",
                        "slug": "Mark-A.-Krogel",
                        "structuredName": {
                            "firstName": "Mark-A.",
                            "lastName": "Krogel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mark-A. Krogel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145057418"
                        ],
                        "name": "S. Wrobel",
                        "slug": "S.-Wrobel",
                        "structuredName": {
                            "firstName": "Stefan",
                            "lastName": "Wrobel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Wrobel"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 27035051,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2241335423a1e7129032ce5ea02973cbb2e3bd76",
            "isKey": false,
            "numCitedBy": 125,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "Given the very widespread use of multirelational databases, ILP systems are increasingly being used on data originating from such warehouses. Unfortunately, even though not complex in structure, such business data often contain highly non-determinate components, making them difficult for ILP learners geared towards structurally complex tasks. In this paper, we build on popular transformation-based approaches to ILP and describe how they can naturally be extended with relational aggregation. We experimentall y show that this results in a multirelational learner that outperforms a structurally-oriented ILP system both in speed and accuracy on this class of problems."
            },
            "slug": "Transformation-Based-Learning-Using-Multirelational-Krogel-Wrobel",
            "title": {
                "fragments": [],
                "text": "Transformation-Based Learning Using Multirelational Aggregation"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This paper builds on popular transformation-based approaches to ILP and describes how they can naturally be extended with relational aggregation and results in a multirelational learner that outperforms a structurally-oriented ILP system both in speed and accuracy on this class of problems."
            },
            "venue": {
                "fragments": [],
                "text": "ILP"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1680188"
                        ],
                        "name": "T. Joachims",
                        "slug": "T.-Joachims",
                        "structuredName": {
                            "firstName": "Thorsten",
                            "lastName": "Joachims",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Joachims"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 60532258,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "248a297d786228a183fcae64023092660550fcd2",
            "isKey": false,
            "numCitedBy": 1753,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Based on ideas from Support Vector Machines (SVMs), Learning To Classify Text Using Support Vector Machines presents a new approach to generating text classifiers from examples. The approach combines high performance and efficiency with theoretical understanding and improved robustness. In particular, it is highly effective without greedy heuristic components. The SVM approach is computationally efficient in training and classification, and it comes with a learning theory that can guide real-world applications. Learning To Classify Text Using Support Vector Machines gives a complete and detailed description of the SVM approach to learning text classifiers, including training algorithms, transductive text classification, efficient performance estimation, and a statistical learning model of text classification. In addition, it includes an overview of the field of text classification, making it self-contained even for newcomers to the field. This book gives a concise introduction to SVMs for pattern recognition, and it includes a detailed description of how to formulate text-classification tasks for machine learning."
            },
            "slug": "Learning-to-classify-text-using-support-vector-and-Joachims",
            "title": {
                "fragments": [],
                "text": "Learning to classify text using support vector machines - methods, theory and algorithms"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This book gives a concise introduction to SVMs for pattern recognition, and it includes a detailed description of how to formulate text-classification tasks for machine learning."
            },
            "venue": {
                "fragments": [],
                "text": "The Kluwer international series in engineering and computer science"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152303545"
                        ],
                        "name": "Jean-Philippe Vert",
                        "slug": "Jean-Philippe-Vert",
                        "structuredName": {
                            "firstName": "Jean-Philippe",
                            "lastName": "Vert",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jean-Philippe Vert"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "In [42] it is shown that this kernel function can be computed in time linear in the size of the tree."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "The phylogenetic information considered in [42] is represented as a tree such that each leaf (a vertex with no outgoing edge) corresponds to one living organism and every other vertex corresponds to some ancestor of the living organisms."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "A similar idea of defining a kernel function on the structure of the instance space is described in [42]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "As the genomes are only known for some ancestor organisms, a probabilistic model that can be used to estimate missing indicator variables is suggested in [42]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 11303414,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "e3fcafc0d62bcb62bf21c8a3094046cae9b74a1f",
            "isKey": true,
            "numCitedBy": 139,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "MOTIVATION\nThe phylogenetic profile of a protein is a string that encodes the presence or absence of the protein in every fully sequenced genome. Because proteins that participate in a common structural complex or metabolic pathway are likely to evolve in a correlated fashion, the phylogenetic profiles of such proteins are often 'similar' or at least 'related' to each other. The question we address in this paper is the following: how to measure the 'similarity' between two profiles, in an evolutionarily relevant way, in order to develop efficient function prediction methods?\n\n\nRESULTS\nWe show how the profiles can be mapped to a high-dimensional vector space which incorporates evolutionarily relevant information, and we provide an algorithm to compute efficiently the inner product in that space, which we call the tree kernel. The tree kernel can be used by any kernel-based analysis method for classification or data mining of phylogenetic profiles. As an application a Support Vector Machine (SVM) trained to predict the functional class of a gene from its phylogenetic profile is shown to perform better with the tree kernel than with a naive kernel that does not include any information about the phylogenetic relationships among species. Moreover a kernel principal component analysis (KPCA) of the phylogenetic profiles illustrates the sensitivity of the tree kernel to evolutionarily relevant variations."
            },
            "slug": "A-tree-kernel-to-analyse-phylogenetic-profiles-Vert",
            "title": {
                "fragments": [],
                "text": "A tree kernel to analyse phylogenetic profiles"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "It is shown how the phylogenetic profiles can be mapped to a high-dimensional vector space which incorporates evolutionarily relevant information, and an algorithm to compute efficiently the inner product in that space, which is called the tree kernel."
            },
            "venue": {
                "fragments": [],
                "text": "ISMB"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35132120"
                        ],
                        "name": "T. Jaakkola",
                        "slug": "T.-Jaakkola",
                        "structuredName": {
                            "firstName": "T.",
                            "lastName": "Jaakkola",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Jaakkola"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733689"
                        ],
                        "name": "D. Haussler",
                        "slug": "D.-Haussler",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Haussler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Haussler"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14336127,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e45c2420e6dc59ba6d357fb0c996ebf43c861560",
            "isKey": false,
            "numCitedBy": 1619,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "Generative probability models such as hidden Markov models provide a principled way of treating missing information and dealing with variable length sequences. On the other hand, discriminative methods such as support vector machines enable us to construct flexible decision boundaries and often result in classification performance superior to that of the model based approaches. An ideal classifier should combine these two complementary approaches. In this paper, we develop a natural way of achieving this combination by deriving kernel functions for use in discriminative methods such as support vector machines from generative probability models. We provide a theoretical justification for this combination as well as demonstrate a substantial improvement in the classification performance in the context of DNA and protein sequence analysis."
            },
            "slug": "Exploiting-Generative-Models-in-Discriminative-Jaakkola-Haussler",
            "title": {
                "fragments": [],
                "text": "Exploiting Generative Models in Discriminative Classifiers"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "A natural way of achieving this combination by deriving kernel functions for use in discriminative methods such as support vector machines from generative probability models is developed."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2219581"
                        ],
                        "name": "B. Boser",
                        "slug": "B.-Boser",
                        "structuredName": {
                            "firstName": "Bernhard",
                            "lastName": "Boser",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Boser"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1743797"
                        ],
                        "name": "I. Guyon",
                        "slug": "I.-Guyon",
                        "structuredName": {
                            "firstName": "Isabelle",
                            "lastName": "Guyon",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Guyon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50560492"
                        ],
                        "name": "V. Vapnik",
                        "slug": "V.-Vapnik",
                        "structuredName": {
                            "firstName": "Vladimir",
                            "lastName": "Vapnik",
                            "middleNames": [
                                "Naumovich"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Vapnik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 207165665,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2599131a4bc2fa957338732a37c744cfe3e17b24",
            "isKey": false,
            "numCitedBy": 10840,
            "numCiting": 40,
            "paperAbstract": {
                "fragments": [],
                "text": "A training algorithm that maximizes the margin between the training patterns and the decision boundary is presented. The technique is applicable to a wide variety of the classification functions, including Perceptrons, polynomials, and Radial Basis Functions. The effective number of parameters is adjusted automatically to match the complexity of the problem. The solution is expressed as a linear combination of supporting patterns. These are the subset of training patterns that are closest to the decision boundary. Bounds on the generalization performance based on the leave-one-out method and the VC-dimension are given. Experimental results on optical character recognition problems demonstrate the good generalization obtained when compared with other learning algorithms."
            },
            "slug": "A-training-algorithm-for-optimal-margin-classifiers-Boser-Guyon",
            "title": {
                "fragments": [],
                "text": "A training algorithm for optimal margin classifiers"
            },
            "tldr": {
                "abstractSimilarityScore": 93,
                "text": "A training algorithm that maximizes the margin between the training patterns and the decision boundary is presented, applicable to a wide variety of the classification functions, including Perceptrons, polynomials, and Radial Basis Functions."
            },
            "venue": {
                "fragments": [],
                "text": "COLT '92"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1800870"
                        ],
                        "name": "B. Fortuna",
                        "slug": "B.-Fortuna",
                        "structuredName": {
                            "firstName": "Bla\u017e",
                            "lastName": "Fortuna",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Fortuna"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 14,
                                "start": 10
                            }
                        ],
                        "text": "Recently, [36] has shown that syntactic string kernels (presented in section 4."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 16,
                                "start": 12
                            }
                        ],
                        "text": "As shown in [36] these kernels can be seen as a special case of the Fisher kernel (presented in section 3."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15372263,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "42e1cf6636b9020432ad9a08678c22920da86871",
            "isKey": false,
            "numCitedBy": 5,
            "numCiting": 3,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper provides an overview of string kernels. String kernels compare text documents by the substrings they contain. Because of high computational complexity, methods for approximating string kernels are shown. Several extensions for string kernels are also presented. Finally string kernels are compared to BOW."
            },
            "slug": "String-Kernels-Fortuna",
            "title": {
                "fragments": [],
                "text": "String Kernels"
            },
            "tldr": {
                "abstractSimilarityScore": 63,
                "text": "This paper provides an overview of string kernels and methods for approximating string kernels, and string kernels are compared to BOW."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152303545"
                        ],
                        "name": "Jean-Philippe Vert",
                        "slug": "Jean-Philippe-Vert",
                        "structuredName": {
                            "firstName": "Jean-Philippe",
                            "lastName": "Vert",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jean-Philippe Vert"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "87339519"
                        ],
                        "name": "M. Kanehisa",
                        "slug": "M.-Kanehisa",
                        "structuredName": {
                            "firstName": "Minoru",
                            "lastName": "Kanehisa",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Kanehisa"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8629843,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d74bfa3505b5350a7c84732f3d51cf9fd66bd8b3",
            "isKey": false,
            "numCitedBy": 96,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "We present an algorithm to extract features from high-dimensional gene expression profiles, based on the knowledge of a graph which links together genes known to participate to successive reactions in metabolic pathways. Motivated by the intuition that biologically relevant features are likely to exhibit smoothness with respect to the graph topology, the algorithm involves encoding the graph and the set of expression profiles into kernel functions, and performing a generalized form of canonical correlation analysis in the corresponding reproducible kernel Hilbert spaces. \n \nFunction prediction experiments for the genes of the yeast S. Cerevisiae validate this approach by showing a consistent increase in performance when a state-of-the-art classifier uses the vector of features instead of the original expression profile to predict the functional class of a gene."
            },
            "slug": "Graph-Driven-Feature-Extraction-From-Microarray-and-Vert-Kanehisa",
            "title": {
                "fragments": [],
                "text": "Graph-Driven Feature Extraction From Microarray Data Using Diffusion Kernels and Kernel CCA"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This approach is validated by showing a consistent increase in performance when a state-of-the-art classifier uses the vector of features instead of the original expression profile to predict the functional class of a gene."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46234526"
                        ],
                        "name": "Alex Smola",
                        "slug": "Alex-Smola",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Smola",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alex Smola"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 29871328,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d5051890e501117097eeffbd8ded87694f0d8063",
            "isKey": false,
            "numCitedBy": 6578,
            "numCiting": 66,
            "paperAbstract": {
                "fragments": [],
                "text": "All rights reserved. No part of this book may be reproduced in any form by any electronic or mechanical means (including photocopying, recording, or information storage and retrieval) without permission in writing from the publisher."
            },
            "slug": "Learning-with-kernels-Smola",
            "title": {
                "fragments": [],
                "text": "Learning with kernels"
            },
            "tldr": {
                "abstractSimilarityScore": 36,
                "text": "This book is intended to be a guide to the art of self-consistency and should not be used as a substitute for a comprehensive guide to self-confidence."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152303545"
                        ],
                        "name": "Jean-Philippe Vert",
                        "slug": "Jean-Philippe-Vert",
                        "structuredName": {
                            "firstName": "Jean-Philippe",
                            "lastName": "Vert",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jean-Philippe Vert"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 12053807,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "b1377fbc559ac7ecbb4b956aefb6bdde60d714c5",
            "isKey": false,
            "numCitedBy": 54,
            "numCiting": 52,
            "paperAbstract": {
                "fragments": [],
                "text": "Motivation: The phylogenetic profile of a protein is a string that encodes the presence or absence of the protein in every fully sequenced genome. Because proteins that participate in a common structural complex or metabolic pathway are likely to evolve in a correlated fashion, the phylogenetic profiles of such proteins are often \u201csimilar\u201d or at least \u201crelated\u201d to each other. The question we address in this paper is the following: how to measure the \u201csimilarity\u201d between two profiles, in an evolutionarily relevant way, in order to develop efficient function prediction methods? Results: We show how the profiles can be mapped to a high-dimensional vector space which incorporates evolutionarily relevant information, and we provide an algorithm to compute efficiently the inner product in that space, which we call the tree kernel. The tree kernel can be used by any kernel-based analysis method for classification or data mining of phylogenetic profiles. As an application a Support Vector Machine (SVM) trained to predict the functional class of a gene from its phylogenetic profile is shown to perform better with the tree kernel than with a naive kernel that does not include any information about the phylogenetic relationships among species. Moreover a kernel principal component analysis (KPCA) of the phylogenetic profiles illustrates the sensitivity of the tree kernel to evolutionarily relevant variations. Availability: All data and softwares used are freely and publicly available upon request. Contact: Jean-Philippe.Vert@mines.org"
            },
            "slug": "A-tree-kernel-to-analyze-phylog-enetic-profi-les-Vert",
            "title": {
                "fragments": [],
                "text": "A tree kernel to analyze phylog enetic profi les"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "It is shown how the phylogenetic profiles can be mapped to a high-dimensional vector space which incorporates evolutionarily relevant information, and an algorithm to compute efficiently the inner product in that space, which is called the tree kernel."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "16697538"
                        ],
                        "name": "N. Aronszajn",
                        "slug": "N.-Aronszajn",
                        "structuredName": {
                            "firstName": "N.",
                            "lastName": "Aronszajn",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Aronszajn"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 54040858,
            "fieldsOfStudy": [
                "Economics"
            ],
            "id": "fe697b4e2cb4c132da39aed8b8266a0e6113f9f2",
            "isKey": false,
            "numCitedBy": 5083,
            "numCiting": 54,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract : The present paper may be considered as a sequel to our previous paper in the Proceedings of the Cambridge Philosophical Society, Theorie generale de noyaux reproduisants-Premiere partie (vol. 39 (1944)) which was written in 1942-1943. In the introduction to this paper we outlined the plan of papers which were to follow. In the meantime, however, the general theory has been developed in many directions, and our original plans have had to be changed. Due to wartime conditions we were not able, at the time of writing the first paper, to take into account all the earlier investigations which, although sometimes of quite a different character, were, nevertheless, related to our subject. Our investigation is concerned with kernels of a special type which have been used under different names and in different ways in many domains of mathematical research. We shall therefore begin our present paper with a short historical introduction in which we shall attempt to indicate the different manners in which these kernels have been used by various investigators, and to clarify the terminology. We shall also discuss the more important trends of the application of these kernels without attempting, however, a complete bibliography of the subject matter. (KAR) P. 2"
            },
            "slug": "Theory-of-Reproducing-Kernels.-Aronszajn",
            "title": {
                "fragments": [],
                "text": "Theory of Reproducing Kernels."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1950
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144299726"
                        ],
                        "name": "Thomas G. Dietterich",
                        "slug": "Thomas-G.-Dietterich",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Dietterich",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thomas G. Dietterich"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145914024"
                        ],
                        "name": "R. Lathrop",
                        "slug": "R.-Lathrop",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Lathrop",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Lathrop"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1388700951"
                        ],
                        "name": "Tomas Lozano-Perez",
                        "slug": "Tomas-Lozano-Perez",
                        "structuredName": {
                            "firstName": "Tomas",
                            "lastName": "Lozano-Perez",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tomas Lozano-Perez"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7398727,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1c7d38f68fe1150895a186e30b60c02dd89a676a",
            "isKey": false,
            "numCitedBy": 2425,
            "numCiting": 81,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Solving-the-Multiple-Instance-Problem-with-Dietterich-Lathrop",
            "title": {
                "fragments": [],
                "text": "Solving the Multiple Instance Problem with Axis-Parallel Rectangles"
            },
            "venue": {
                "fragments": [],
                "text": "Artif. Intell."
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2281542"
                        ],
                        "name": "A. Zien",
                        "slug": "A.-Zien",
                        "structuredName": {
                            "firstName": "Alexander",
                            "lastName": "Zien",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Zien"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2414086"
                        ],
                        "name": "G. R\u00e4tsch",
                        "slug": "G.-R\u00e4tsch",
                        "structuredName": {
                            "firstName": "Gunnar",
                            "lastName": "R\u00e4tsch",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. R\u00e4tsch"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2459012"
                        ],
                        "name": "S. Mika",
                        "slug": "S.-Mika",
                        "structuredName": {
                            "firstName": "Sebastian",
                            "lastName": "Mika",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Mika"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1707625"
                        ],
                        "name": "B. Sch\u00f6lkopf",
                        "slug": "B.-Sch\u00f6lkopf",
                        "structuredName": {
                            "firstName": "Bernhard",
                            "lastName": "Sch\u00f6lkopf",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Sch\u00f6lkopf"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "21313583"
                        ],
                        "name": "C. Lemmen",
                        "slug": "C.-Lemmen",
                        "structuredName": {
                            "firstName": "Christian",
                            "lastName": "Lemmen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Lemmen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46234526"
                        ],
                        "name": "Alex Smola",
                        "slug": "Alex-Smola",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Smola",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alex Smola"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49370597"
                        ],
                        "name": "Thomas Lengauer",
                        "slug": "Thomas-Lengauer",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Lengauer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thomas Lengauer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145034054"
                        ],
                        "name": "K. M\u00fcller",
                        "slug": "K.-M\u00fcller",
                        "structuredName": {
                            "firstName": "Klaus-Robert",
                            "lastName": "M\u00fcller",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. M\u00fcller"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2154417,
            "fieldsOfStudy": [
                "Computer Science",
                "Biology"
            ],
            "id": "bdb4a67b8e83de538965181f27bc070e68ced84c",
            "isKey": false,
            "numCitedBy": 470,
            "numCiting": 65,
            "paperAbstract": {
                "fragments": [],
                "text": "MOTIVATION\nIn order to extract protein sequences from nucleotide sequences, it is an important step to recognize points at which regions start that code for proteins. These points are called translation initiation sites (TIS).\n\n\nRESULTS\nThe task of finding TIS can be modeled as a classification problem. We demonstrate the applicability of support vector machines for this task, and show how to incorporate prior biological knowledge by engineering an appropriate kernel function. With the described techniques the recognition performance can be improved by 26% over leading existing approaches. We provide evidence that existing related methods (e.g. ESTScan) could profit from advanced TIS recognition."
            },
            "slug": "Engineering-Support-Vector-Machine-Kerneis-That-Zien-R\u00e4tsch",
            "title": {
                "fragments": [],
                "text": "Engineering Support Vector Machine Kerneis That Recognize Translation Initialion Sites"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "With the described techniques the recognition performance can be improved by 26% over leading existing approaches, and there is evidence that existing related methods could profit from advanced TIS recognition."
            },
            "venue": {
                "fragments": [],
                "text": "German Conference on Bioinformatics"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46234526"
                        ],
                        "name": "Alex Smola",
                        "slug": "Alex-Smola",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Smola",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alex Smola"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1745169"
                        ],
                        "name": "P. Bartlett",
                        "slug": "P.-Bartlett",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Bartlett",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Bartlett"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1707625"
                        ],
                        "name": "B. Sch\u00f6lkopf",
                        "slug": "B.-Sch\u00f6lkopf",
                        "structuredName": {
                            "firstName": "Bernhard",
                            "lastName": "Sch\u00f6lkopf",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Sch\u00f6lkopf"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1714772"
                        ],
                        "name": "Dale Schuurmans",
                        "slug": "Dale-Schuurmans",
                        "structuredName": {
                            "firstName": "Dale",
                            "lastName": "Schuurmans",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dale Schuurmans"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 125105198,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e003f0a280275de163269d32046950ad37aa37f0",
            "isKey": false,
            "numCitedBy": 221,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "This chapter contains sections titled: Introduction: Linear Methods using Kernel function, Applying Linear Methods to Structured Objects, Conditional Symmetric Independence Kernels, Pair Hidden Markov Models, Conditionally Symmetrically Independent PHMMs, Conclusion"
            },
            "slug": "Dynamic-Alignment-Kernels-Smola-Bartlett",
            "title": {
                "fragments": [],
                "text": "Dynamic Alignment Kernels"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "This chapter contains sections titled: Introduction: Linear Methods using Kernel function, Applying Linear Methods to Structured Objects, Conditional Symmetric Independence Kernels, Pair Hidden Markov Models, Conditionally Symmetrically Independent PHMMs, Conclusion."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2681867"
                        ],
                        "name": "R. Karchin",
                        "slug": "R.-Karchin",
                        "structuredName": {
                            "firstName": "Rachel",
                            "lastName": "Karchin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Karchin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2476651"
                        ],
                        "name": "K. Karplus",
                        "slug": "K.-Karplus",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Karplus",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Karplus"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733689"
                        ],
                        "name": "D. Haussler",
                        "slug": "D.-Haussler",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Haussler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Haussler"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9284698,
            "fieldsOfStudy": [
                "Computer Science",
                "Biology"
            ],
            "id": "ff1145282e95d1852e60f5f64125c17c111e5dd6",
            "isKey": false,
            "numCitedBy": 289,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "MOTIVATION\nThe enormous amount of protein sequence data uncovered by genome research has increased the demand for computer software that can automate the recognition of new proteins. We discuss the relative merits of various automated methods for recognizing G-Protein Coupled Receptors (GPCRs), a superfamily of cell membrane proteins. GPCRs are found in a wide range of organisms and are central to a cellular signalling network that regulates many basic physiological processes. They are the focus of a significant amount of current pharmaceutical research because they play a key role in many diseases. However, their tertiary structures remain largely unsolved. The methods described in this paper use only primary sequence information to make their predictions. We compare a simple nearest neighbor approach (BLAST), methods based on multiple alignments generated by a statistical profile Hidden Markov Model (HMM), and methods, including Support Vector Machines (SVMs), that transform protein sequences into fixed-length feature vectors.\n\n\nRESULTS\nThe last is the most computationally expensive method, but our experiments show that, for those interested in annotation-quality classification, the results are worth the effort. In two-fold cross-validation experiments testing recognition of GPCR subfamilies that bind a specific ligand (such as a histamine molecule), the errors per sequence at the Minimum Error Point (MEP) were 13.7% for multi-class SVMs, 17.1% for our SVMtree method of hierarchical multi-class SVM classification, 25.5% for BLAST, 30% for profile HMMs, and 49% for classification based on nearest neighbor feature vector Kernel Nearest Neighbor (kernNN). The percentage of true positives recognized before the first false positive was 65% for both SVM methods, 13% for BLAST, 5% for profile HMMs and 4% for kernNN."
            },
            "slug": "Classifying-G-protein-coupled-receptors-with-vector-Karchin-Karplus",
            "title": {
                "fragments": [],
                "text": "Classifying G-protein coupled receptors with support vector machines"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A simple nearest neighbor approach (BLAST), methods based on multiple alignments generated by a statistical profile Hidden Markov Model (HMM), and methods, including Support Vector Machines (SVMs), that transform protein sequences into fixed-length feature vectors are compared."
            },
            "venue": {
                "fragments": [],
                "text": "Bioinform."
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2116829524"
                        ],
                        "name": "N. Smith",
                        "slug": "N.-Smith",
                        "structuredName": {
                            "firstName": "Nathan",
                            "lastName": "Smith",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Smith"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1740397"
                        ],
                        "name": "M. Gales",
                        "slug": "M.-Gales",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Gales",
                            "middleNames": [
                                "John",
                                "Francis"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Gales"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1435919,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f6bc69b22ea6418b70893ce3501a6a0cd9c0549d",
            "isKey": false,
            "numCitedBy": 184,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "An important issue in applying SVMs to speech recognition is the ability to classify variable length sequences. This paper presents extensions to a standard scheme for handling this variable length data, the Fisher score. A more useful mapping is introduced based on the likelihood-ratio. The score-space defined by this mapping avoids some limitations of the Fisher score. Class-conditional generative models are directly incorporated into the definition of the score-space. The mapping, and appropriate normalisation schemes, are evaluated on a speaker-independent isolated letter task where the new mapping outperforms both the Fisher score and HMMs trained to maximise likelihood."
            },
            "slug": "Speech-Recognition-using-SVMs-Smith-Gales",
            "title": {
                "fragments": [],
                "text": "Speech Recognition using SVMs"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "Extensions to a standard scheme for handling variable length data, the Fisher score, are presented and a more useful mapping is introduced based on the likelihood-ratio, which outperforms both the fisher score and HMMs trained to maximise likelihood."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35132120"
                        ],
                        "name": "T. Jaakkola",
                        "slug": "T.-Jaakkola",
                        "structuredName": {
                            "firstName": "T.",
                            "lastName": "Jaakkola",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Jaakkola"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2671293"
                        ],
                        "name": "M. Diekhans",
                        "slug": "M.-Diekhans",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Diekhans",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Diekhans"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733689"
                        ],
                        "name": "D. Haussler",
                        "slug": "D.-Haussler",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Haussler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Haussler"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2048632,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8e2dd064daaac3603581ec65b580b7b5385e2c2b",
            "isKey": false,
            "numCitedBy": 556,
            "numCiting": 59,
            "paperAbstract": {
                "fragments": [],
                "text": "A new method for detecting remote protein homologies is introduced and shown to perform well in classifying protein domains by SCOP superfamily. The method is a variant of support vector machines using a new kernel function. The kernel function is derived from a generative statistical model for a protein family, in this case a hidden Markov model. This general approach of combining generative models like HMMs with discriminative methods such as support vector machines may have applications in other areas of biosequence analysis as well."
            },
            "slug": "A-Discriminative-Framework-for-Detecting-Remote-Jaakkola-Diekhans",
            "title": {
                "fragments": [],
                "text": "A Discriminative Framework for Detecting Remote Protein Homologies"
            },
            "tldr": {
                "abstractSimilarityScore": 73,
                "text": "A new method for detecting remote protein homologies is introduced and shown to perform well in classifying protein domains by SCOP superfamily using a new kernel function derived from a generative statistical model for a protein family, in this case a hidden Markov model."
            },
            "venue": {
                "fragments": [],
                "text": "J. Comput. Biol."
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144187514"
                        ],
                        "name": "R. Durbin",
                        "slug": "R.-Durbin",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Durbin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Durbin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1708077"
                        ],
                        "name": "S. Eddy",
                        "slug": "S.-Eddy",
                        "structuredName": {
                            "firstName": "Sean",
                            "lastName": "Eddy",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Eddy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144197258"
                        ],
                        "name": "A. Krogh",
                        "slug": "A.-Krogh",
                        "structuredName": {
                            "firstName": "Anders",
                            "lastName": "Krogh",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Krogh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145666307"
                        ],
                        "name": "G. Mitchison",
                        "slug": "G.-Mitchison",
                        "structuredName": {
                            "firstName": "Graeme",
                            "lastName": "Mitchison",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Mitchison"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2852254,
            "fieldsOfStudy": [
                "Biology",
                "Computer Science"
            ],
            "id": "571f5bbecd3a083a2bb6844f59a3f8cea237252e",
            "isKey": false,
            "numCitedBy": 4477,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Probablistic models are becoming increasingly important in analyzing the huge amount of data being produced by large-scale DNA-sequencing efforts such as the Human Genome Project. For example, hidden Markov models are used for analyzing biological sequences, linguistic-grammar-based probabilistic models for identifying RNA secondary structure, and probabilistic evolutionary models for inferring phylogenies of sequences from different organisms. This book gives a unified, up-to-date and self-contained account, with a Bayesian slant, of such methods, and more generally to probabilistic methods of sequence analysis. Written by an interdisciplinary team of authors, it is accessible to molecular biologists, computer scientists, and mathematicians with no formal knowledge of the other fields, and at the same time presents the state of the art in this new and important field."
            },
            "slug": "Biological-Sequence-Analysis:-Probabilistic-Models-Durbin-Eddy",
            "title": {
                "fragments": [],
                "text": "Biological Sequence Analysis: Probabilistic Models of Proteins and Nucleic Acids"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This book gives a unified, up-to-date and self-contained account, with a Bayesian slant, of such methods, and more generally to probabilistic methods of sequence analysis."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144551309"
                        ],
                        "name": "P. Pavlidis",
                        "slug": "P.-Pavlidis",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Pavlidis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Pavlidis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716986"
                        ],
                        "name": "T. Furey",
                        "slug": "T.-Furey",
                        "structuredName": {
                            "firstName": "Terrence",
                            "lastName": "Furey",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Furey"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "52430482"
                        ],
                        "name": "M. Liberto",
                        "slug": "M.-Liberto",
                        "structuredName": {
                            "firstName": "M.",
                            "lastName": "Liberto",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Liberto"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733689"
                        ],
                        "name": "D. Haussler",
                        "slug": "D.-Haussler",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Haussler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Haussler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2361327"
                        ],
                        "name": "W. Grundy",
                        "slug": "W.-Grundy",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Grundy",
                            "middleNames": [
                                "Noble"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Grundy"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 17126889,
            "fieldsOfStudy": [
                "Computer Science",
                "Biology"
            ],
            "id": "f1c79a2db672c942198446ae634d71b30643948f",
            "isKey": false,
            "numCitedBy": 70,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we consider the problem of extracting information from the upstream untranslated regions of genes to make predictions about their transcriptional regulation. We present a method for classifying genes based on motif-based hidden Markov models (HMMs) of their promoter regions. Sequence motifs discovered in yeast promoters are used to construct HMMs that include parameters describing the number and relative locations of motifs within each sequence. Each model provides a Fisher kernel for a support vector machine, which can be used to predict the classifications of unannotated promoters. We demonstrate this method on two classes of genes from the budding yeast, S. cerevisiae. Our results suggest that the additional sequence features captured by the HMM assist in correctly classifying promoters."
            },
            "slug": "Promoter-Region-Based-Classification-of-Genes-Pavlidis-Furey",
            "title": {
                "fragments": [],
                "text": "Promoter Region-Based Classification of Genes"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "This paper presents a method for classifying genes based on motif-based hidden Markov models (HMMs) of their promoter regions, and suggests that the additional sequence features captured by the HMM assist in correctly classifying promoters."
            },
            "venue": {
                "fragments": [],
                "text": "Pacific Symposium on Biocomputing"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712517"
                        ],
                        "name": "L. Rabiner",
                        "slug": "L.-Rabiner",
                        "structuredName": {
                            "firstName": "Lawrence",
                            "lastName": "Rabiner",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Rabiner"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 13618539,
            "fieldsOfStudy": [
                "Geology"
            ],
            "id": "8fe2ea0a67954f1380b3387e3262f1cdb9f9b3e5",
            "isKey": false,
            "numCitedBy": 24804,
            "numCiting": 98,
            "paperAbstract": {
                "fragments": [],
                "text": "The fabric comprises a novel type of netting which will have particular utility in screening out mosquitoes and like insects and pests. The fabric is defined of voids having depth as well as width and length. The fabric is usable as a material from which to form clothing for wear, or bed coverings, or sleeping bags, etc., besides use simply as a netting."
            },
            "slug": "A-Tutorial-on-Hidden-Markov-Models-and-Selected-Rabiner",
            "title": {
                "fragments": [],
                "text": "A Tutorial on Hidden Markov Models and Selected Applications"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "The fabric comprises a novel type of netting which will have particular utility in screening out mosquitoes and like insects and pests."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1683459"
                        ],
                        "name": "G. Paass",
                        "slug": "G.-Paass",
                        "structuredName": {
                            "firstName": "Gerhard",
                            "lastName": "Paass",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Paass"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1745688"
                        ],
                        "name": "Edda Leopold",
                        "slug": "Edda-Leopold",
                        "structuredName": {
                            "firstName": "Edda",
                            "lastName": "Leopold",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Edda Leopold"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145980903"
                        ],
                        "name": "M. Larson",
                        "slug": "M.-Larson",
                        "structuredName": {
                            "firstName": "Martha",
                            "lastName": "Larson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Larson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716800"
                        ],
                        "name": "J. Kindermann",
                        "slug": "J.-Kindermann",
                        "structuredName": {
                            "firstName": "J\u00f6rg",
                            "lastName": "Kindermann",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Kindermann"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1769086"
                        ],
                        "name": "S. Eickeler",
                        "slug": "S.-Eickeler",
                        "structuredName": {
                            "firstName": "Stefan",
                            "lastName": "Eickeler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Eickeler"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 19675244,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9777fa0eed8d7bab053e64a6194c2e3d45f44e59",
            "isKey": false,
            "numCitedBy": 37,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we use SVMs to classify spoken and written documents. We show that classification accuracy for written material is improved by the utilization of strings of sub-word units with dramatic gains for small topic categories. The classification of spoken documents for large categories using sub-word units is only slightly worse than for written material, with a larger drop for small topicc ategories. Finally it is possible, without loss, to train SVMs on syllables generated from written material and use them to classify audio documents. Our results confirm the strong promise that SVMs hold for robust audio document classification, and suggest that SVMs can compensate for speech recognition error to an extent that allows a significant degree of topic independence to be introduced into the system."
            },
            "slug": "SVM-Classification-Using-Sequences-of-Phonemes-and-Paass-Leopold",
            "title": {
                "fragments": [],
                "text": "SVM Classification Using Sequences of Phonemes and Syllables"
            },
            "tldr": {
                "abstractSimilarityScore": 65,
                "text": "This paper shows that classification accuracy for written material is improved by the utilization of strings of sub-word units with dramatic gains for small topic categories, and suggests that SVMs can compensate for speech recognition error to an extent that allows a significant degree of topic independence to be introduced into the system."
            },
            "venue": {
                "fragments": [],
                "text": "PKDD"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34654269"
                        ],
                        "name": "J. Lloyd",
                        "slug": "J.-Lloyd",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Lloyd",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Lloyd"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 895681,
            "fieldsOfStudy": [
                "Economics"
            ],
            "id": "9c3163191e7a523bed84371cd7f5484b75718c4a",
            "isKey": false,
            "numCitedBy": 85,
            "numCiting": 79,
            "paperAbstract": {
                "fragments": [],
                "text": "The first \u20ac price and the \u00a3 and $ price are net prices, subject to local VAT. Prices indicated with * include VAT for books; the \u20ac(D) includes 7% for Germany, the \u20ac(A) includes 10% for Austria. Prices indicated with ** include VAT for electronic products; 19% for Germany, 20% for Austria. All prices exclusive of carriage charges. Prices and other details are subject to change without notice. All errors and omissions excepted. J.W. Lloyd Logic for Learning"
            },
            "slug": "Logic-for-Learning-Lloyd",
            "title": {
                "fragments": [],
                "text": "Logic for Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 78,
                "text": "The first \u20ac price and the \u00a3 and $ price are net prices, subject to local VAT, and the \u20ac(D) includes 7% for Germany, the\u20ac(A) includes 10% for Austria."
            },
            "venue": {
                "fragments": [],
                "text": "Cognitive Technologies"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50560492"
                        ],
                        "name": "V. Vapnik",
                        "slug": "V.-Vapnik",
                        "structuredName": {
                            "firstName": "Vladimir",
                            "lastName": "Vapnik",
                            "middleNames": [
                                "Naumovich"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Vapnik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7138354,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8213dbed4db44e113af3ed17d6dad57471a0c048",
            "isKey": false,
            "numCitedBy": 38755,
            "numCiting": 72,
            "paperAbstract": {
                "fragments": [],
                "text": "Setting of the learning problem consistency of learning processes bounds on the rate of convergence of learning processes controlling the generalization ability of learning processes constructing learning algorithms what is important in learning theory?."
            },
            "slug": "The-Nature-of-Statistical-Learning-Theory-Vapnik",
            "title": {
                "fragments": [],
                "text": "The Nature of Statistical Learning Theory"
            },
            "venue": {
                "fragments": [],
                "text": "Statistics for Engineering and Information Science"
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 76,
                                "start": 73
                            }
                        ],
                        "text": "Research in inductive logic programming and multi-relational data mining [8] aims to reduce these pre-processing efforts by considering learning from multi-relational data descriptions directly."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 208784962,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0ff65ac698013cdd9d61326cab49a1d75404e001",
            "isKey": false,
            "numCitedBy": 18721,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Editors",
            "title": {
                "fragments": [],
                "text": "Editors"
            },
            "venue": {
                "fragments": [],
                "text": "Brain Research Bulletin"
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1693549"
                        ],
                        "name": "S. D\u017eeroski",
                        "slug": "S.-D\u017eeroski",
                        "structuredName": {
                            "firstName": "Sa\u0161o",
                            "lastName": "D\u017eeroski",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. D\u017eeroski"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1402203600"
                        ],
                        "name": "S. Schulze-Kremer",
                        "slug": "S.-Schulze-Kremer",
                        "structuredName": {
                            "firstName": "Steffen",
                            "lastName": "Schulze-Kremer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Schulze-Kremer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2083655"
                        ],
                        "name": "Karsten R. Heidtke",
                        "slug": "Karsten-R.-Heidtke",
                        "structuredName": {
                            "firstName": "Karsten",
                            "lastName": "Heidtke",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Karsten R. Heidtke"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2546541"
                        ],
                        "name": "K. Siems",
                        "slug": "K.-Siems",
                        "structuredName": {
                            "firstName": "Karsten",
                            "lastName": "Siems",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Siems"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1782539"
                        ],
                        "name": "D. Wettschereck",
                        "slug": "D.-Wettschereck",
                        "structuredName": {
                            "firstName": "Dietrich",
                            "lastName": "Wettschereck",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Wettschereck"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1755851"
                        ],
                        "name": "H. Blockeel",
                        "slug": "H.-Blockeel",
                        "structuredName": {
                            "firstName": "Hendrik",
                            "lastName": "Blockeel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Blockeel"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 18448615,
            "fieldsOfStudy": [
                "Chemistry"
            ],
            "id": "be067ebb79f933fb1660470acd1e4bfc93d8e0a2",
            "isKey": false,
            "numCitedBy": 46,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a novel application ofInductive Logic Programming (ILP) to the problem of diterpene structure elucidation from 13 CNMR spectra. Diterpenes are organic compounds oflow molecular weight with a skeleton of 20 carbon atoms. They are of significant chemical and commercial interest because oftheir use as lead compounds in the search for new pharmaceutical effectors. The interpretation of diterpene 13 CNMR spectra normally requires specialists with detailed spectroscopic knowledge and substantial experience in natural products chemistry, specifically knowledge on peak patterns and chemical structures. Given a database ofpeak patterns for diterpenes with known structure, we apply several ILP approaches to discover correlations between peak patterns and chemical structure. The approaches used include first - order inductive learning, relational instance based learning, induction oflogical decision trees, and inductive constraint logic. Performance close to that of domain experts is achieved, which suffi..."
            },
            "slug": "Diterpene-Structure-Elucidation-from-13CNMR-Spectra-D\u017eeroski-Schulze-Kremer",
            "title": {
                "fragments": [],
                "text": "Diterpene Structure Elucidation from 13CNMR Spectra with Inductive Logic Programming"
            },
            "tldr": {
                "abstractSimilarityScore": 75,
                "text": "A novel application ofuctive Logic Programming (ILP) to the problem of diterpene structure elucidation from 13 CNMR spectra to discover correlations between peak patterns and chemical structure."
            },
            "venue": {
                "fragments": [],
                "text": "Appl. Artif. Intell."
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50560492"
                        ],
                        "name": "V. Vapnik",
                        "slug": "V.-Vapnik",
                        "structuredName": {
                            "firstName": "Vladimir",
                            "lastName": "Vapnik",
                            "middleNames": [
                                "Naumovich"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Vapnik"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 59752996,
            "fieldsOfStudy": [
                "Education"
            ],
            "id": "5451278e1a11cf3f1be28a05f38d36c8641e68f7",
            "isKey": false,
            "numCitedBy": 4580,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "The-Nature-of-Statistical-Learning-Vapnik",
            "title": {
                "fragments": [],
                "text": "The Nature of Statistical Learning"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Theory of reproducing kernels. Transactions of the"
            },
            "venue": {
                "fragments": [],
                "text": "Theory of reproducing kernels. Transactions of the"
            },
            "year": 1950
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Kernels from matching operations"
            },
            "venue": {
                "fragments": [],
                "text": "Kernels from matching operations"
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Kernels for semistructured data"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 19th International Conference on Machine Learning"
            },
            "year": 2002
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Exponential and geometric kernels for graphs"
            },
            "venue": {
                "fragments": [],
                "text": "NIPS Workshop on Unreal Data: Principles of Modeling Nonvectorial Data"
            },
            "year": 2002
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 150,
                                "start": 147
                            }
                        ],
                        "text": "For such functions \nit is know that there exists an embedding of the set inalinearspacesuchthat thekernelontheelementsof \nthe set corresponds to the inner product in this space."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Support vector machines : Hype or hallelujah? SIGKDD Explorations"
            },
            "venue": {
                "fragments": [],
                "text": "Support vector machines : Hype or hallelujah? SIGKDD Explorations"
            },
            "year": 2000
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 5
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 52,
        "totalPages": 6
    },
    "page_url": "https://www.semanticscholar.org/paper/A-survey-of-kernels-for-structured-data-G\u00e4rtner/56fd28e8db60a696adc5b0f7acb9ef41d9ce1ec4?sort=total-citations"
}