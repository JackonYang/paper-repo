{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34605517"
                        ],
                        "name": "F. Kristensen",
                        "slug": "F.-Kristensen",
                        "structuredName": {
                            "firstName": "Fredrik",
                            "lastName": "Kristensen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Kristensen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145441569"
                        ],
                        "name": "W. J. MacLean",
                        "slug": "W.-J.-MacLean",
                        "structuredName": {
                            "firstName": "W.",
                            "lastName": "MacLean",
                            "middleNames": [
                                "James"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. J. MacLean"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 10418890,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c15d0a1292a7df85a346609f1226921481bd9544",
            "isKey": false,
            "numCitedBy": 34,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes the implementation of a realtime maximally stable extremal region (MSER) detector. In order to reach real-time performance, both algorithmic and memory issues have been addressed. The union-find algorithm, which is the heart of the MSER detector, is extended to create linked regions that significantly decrease the time to extract MSERs. Hash indexed memory structures are used to locate stored regions fast while keeping the amount of stored data low. The design is verified by including it in a demonstrator circuit. Timing and memory requirements are presented for the demonstrator and as a function of image resolution"
            },
            "slug": "Real-Time-Extraction-of-Maximally-Stable-Extremal-Kristensen-MacLean",
            "title": {
                "fragments": [],
                "text": "Real-Time Extraction of Maximally Stable Extremal Regions on an FPGA"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "The union-find algorithm is extended to create linked regions that significantly decrease the time to extract MSERs and Hash indexed memory structures are used to locate stored regions fast while keeping the amount of stored data low."
            },
            "venue": {
                "fragments": [],
                "text": "2007 IEEE International Symposium on Circuits and Systems"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1934088"
                        ],
                        "name": "Per-Erik Forss\u00e9n",
                        "slug": "Per-Erik-Forss\u00e9n",
                        "structuredName": {
                            "firstName": "Per-Erik",
                            "lastName": "Forss\u00e9n",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Per-Erik Forss\u00e9n"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "They have also been used in recognition [16] as well as tracking [11] and have been extended to color [17] and volumetric images [18]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 6469259,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1903231edcf47533e9d9fc21119f6cd3fa3f136b",
            "isKey": false,
            "numCitedBy": 301,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper introduces a novel colour-based affine co-variant region detector. Our algorithm is an extension of the maximally stable extremal region (MSER) to colour. The extension to colour is done by looking at successive time-steps of an agglomerative clustering of image pixels. The selection of time-steps is stabilised against intensity scalings and image blur by modelling the distribution of edge magnitudes. The algorithm contains a novel edge significance measure based on a Poisson image noise model, which we show performs better than the commonly used Euclidean distance. We compare our algorithm to the original MSER detector and a competing colour-based blob feature detector, and show through a repeatability test that our detector performs better. We also extend the state of the art in feature repeatability tests, by using scenes consisting of two planes where one is piecewise transparent. This new test is able to evaluate how stable a feature is against changing backgrounds."
            },
            "slug": "Maximally-Stable-Colour-Regions-for-Recognition-and-Forss\u00e9n",
            "title": {
                "fragments": [],
                "text": "Maximally Stable Colour Regions for Recognition and Matching"
            },
            "tldr": {
                "abstractSimilarityScore": 52,
                "text": "A novel colour-based affine co-variant region detector based on a Poisson image noise model that performs better than the commonly used Euclidean distance and extends the state of the art in feature repeatability tests."
            },
            "venue": {
                "fragments": [],
                "text": "2007 IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1736088"
                        ],
                        "name": "H. Gabow",
                        "slug": "H.-Gabow",
                        "structuredName": {
                            "firstName": "Harold",
                            "lastName": "Gabow",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Gabow"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1721050"
                        ],
                        "name": "R. Tarjan",
                        "slug": "R.-Tarjan",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Tarjan",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Tarjan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Hence the expression \u2019quasi-linear\u2019 is well motivated, although a true linear time algorithm for the union-find problem to our knowledge requires limiting assumptions such as for example the existence of a computer with log(n) word length and incremental growing of the data structure [24]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 705851,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "25daae1a69ddd27f0f771954a2d31484833a3843",
            "isKey": false,
            "numCitedBy": 417,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a linear-time algorithm for the special case of the disjoint set union problem in which the structure of the unions (defined by a \u201cunion tree\u201d) is known in advance. The algorithm executes an intermixed sequence of m union and find operations on n elements in 0(m+n) time and 0(n) space. This is a slight but theoretically significant improvement over the fastest known algorithm for the general problem, which runs in 0(m&agr;(m+n, n)+n) time and 0(n) space, where &agr; is a functional inverse of Ackermann's function. Used as a subroutine, the algorithm gives similar improvements in the efficiency of algorithms for solving a number of other problems, including two-processor scheduling, the off-line min problem, matching on convex graphs, finding nearest common ancestors off-line, testing a flow graph for reducibility, and finding two disjoint directed spanning trees. The algorithm obtains its efficiency by combining a fast algorithm for the general problem with table look-up on small sets, and requires a random access machine for its implementation. The algorithm extends to the case in which single-node additions to the union tree are allowed. The extended algorithm is useful in finding maximum cardinality matchings on nonbipartite graphs."
            },
            "slug": "A-linear-time-algorithm-for-a-special-case-of-set-Gabow-Tarjan",
            "title": {
                "fragments": [],
                "text": "A linear-time algorithm for a special case of disjoint set union"
            },
            "tldr": {
                "abstractSimilarityScore": 75,
                "text": "A linear-time algorithm for the special case of the disjoint set union problem in which the structure of the unions (defined by a \u201cunion tree\u201d) is known in advance, which gives similar improvements in the efficiency of algorithms for solving a number of other problems."
            },
            "venue": {
                "fragments": [],
                "text": "J. Comput. Syst. Sci."
            },
            "year": 1985
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1793476"
                        ],
                        "name": "M. Donoser",
                        "slug": "M.-Donoser",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Donoser",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Donoser"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144746444"
                        ],
                        "name": "H. Bischof",
                        "slug": "H.-Bischof",
                        "structuredName": {
                            "firstName": "Horst",
                            "lastName": "Bischof",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Bischof"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "They have also been used in recognition [16] as well as tracking [11] and have been extended to color [17] and volumetric images [18]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Extraction of invariant regions has recently been the focus of intense study [1,2,3,4,5,6,7,8,9,10,11,12], supporting a wide variety of applications such as recognition, image retrieval, mosaicing, 3D reconstruction, tracking, robot navigation and more."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 206590641,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "dab688b834dc72da16841831eea92df5c0bfe7ed",
            "isKey": false,
            "numCitedBy": 305,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper introduces a tracking method for the well known local MSER (Maximally Stable Extremal Region) detector. The component tree is used as an efficient data structure, which allows the calculation of MSERs in quasi-linear time. It is demonstrated that the tree is able to manage the required data for tracking. We show that by means of MSER tracking the computational time for the detection of single MSERs can be improved by a factor of 4 to 10. Using a weighted feature vector for data association improves the tracking stability. Furthermore, the component tree enables backward tracking which further improves the robustness. The novel MSER tracking algorithm is evaluated on a variety of scenes. In addition, we demonstrate three different applications, tracking of license plates, faces and fibers in paper, showing in all three scenarios improved speed and stability."
            },
            "slug": "Efficient-Maximally-Stable-Extremal-Region-(MSER)-Donoser-Bischof",
            "title": {
                "fragments": [],
                "text": "Efficient Maximally Stable Extremal Region (MSER) Tracking"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "It is shown that by means of MSER tracking the computational time for the detection of single MSERs can be improved by a factor of 4 to 10 and using a weighted feature vector for data association improves the tracking stability."
            },
            "venue": {
                "fragments": [],
                "text": "2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'06)"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2831197"
                        ],
                        "name": "M. Couprie",
                        "slug": "M.-Couprie",
                        "structuredName": {
                            "firstName": "Michel",
                            "lastName": "Couprie",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Couprie"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688714"
                        ],
                        "name": "Laurent Najman",
                        "slug": "Laurent-Najman",
                        "structuredName": {
                            "firstName": "Laurent",
                            "lastName": "Najman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Laurent Najman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "37859863"
                        ],
                        "name": "G. Bertrand",
                        "slug": "G.-Bertrand",
                        "structuredName": {
                            "firstName": "Gilles",
                            "lastName": "Bertrand",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Bertrand"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "The union-find data structure with path-compression supports quasi-linear time in the number of pixels [21,22,23]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 936962,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a3022193c27abb362bf9748921b8db4d8c236bec",
            "isKey": false,
            "numCitedBy": 103,
            "numCiting": 59,
            "paperAbstract": {
                "fragments": [],
                "text": "The watershed transformation is an efficient tool for segmenting grayscale images. An original approach to the watershed (Bertrand, Journal of Mathematical Imaging and Vision, Vol. 22, Nos. 2/3, pp. 217\u2013230, 2005.; Couprie and Bertrand, Proc. SPIE Vision Geometry VI, Vol. 3168, pp. 136\u2013146, 1997.) consists in modifying the original image by lowering some points while preserving some topological properties, namely, the connectivity of each lower cross-section. Such a transformation (and its result) is called a W-thinning, a topological watershed being an \u201cultimate\u201d W-thinning. In this paper, we study algorithms to compute topological watersheds. We propose and prove a characterization of the points that can be lowered during a W-thinning, which may be checked locally and efficiently implemented thanks to a data structure called component tree. We introduce the notion of M-watershed of an image F, which is a W-thinning of F in which the minima cannot be extended anymore without changing the connectivity of the lower cross-sections. The set of points in an M-watershed of F which do not belong to any regional minimum corresponds to a binary watershed of F. We propose quasi-linear algorithms for computing M-watersheds and topological watersheds. These algorithms are proved to give correct results with respect to the definitions, and their time complexity is analyzed."
            },
            "slug": "Quasi-Linear-Algorithms-for-the-Topological-Couprie-Najman",
            "title": {
                "fragments": [],
                "text": "Quasi-Linear Algorithms for the Topological Watershed"
            },
            "tldr": {
                "abstractSimilarityScore": 37,
                "text": "This paper proposes and proves a characterization of the points that can be lowered during a W-thinning, which may be checked locally and efficiently implemented thanks to a data structure called component tree, and proposes quasi-linear algorithms for computing M-watersheds and topological watersheds."
            },
            "venue": {
                "fragments": [],
                "text": "Journal of Mathematical Imaging and Vision"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1820595"
                        ],
                        "name": "L. Vincent",
                        "slug": "L.-Vincent",
                        "structuredName": {
                            "firstName": "Luc",
                            "lastName": "Vincent",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Vincent"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2987794"
                        ],
                        "name": "P. Soille",
                        "slug": "P.-Soille",
                        "structuredName": {
                            "firstName": "Pierre",
                            "lastName": "Soille",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Soille"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "The standard algorithm for computing MSER follows the same lines as a very popular flooding simulation algorithm for computing a watershed segmentation, suggested in [20]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 15436061,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a3819dda9a5f00dbb8cd3413ca7422e37a0d5794",
            "isKey": false,
            "numCitedBy": 5731,
            "numCiting": 66,
            "paperAbstract": {
                "fragments": [],
                "text": "A fast and flexible algorithm for computing watersheds in digital gray-scale images is introduced. A review of watersheds and related motion is first presented, and the major methods to determine watersheds are discussed. The algorithm is based on an immersion process analogy, in which the flooding of the water in the picture is efficiently simulated using of queue of pixel. It is described in detail provided in a pseudo C language. The accuracy of this algorithm is proven to be superior to that of the existing implementations, and it is shown that its adaptation to any kind of digital grid and its generalization to n-dimensional images (and even to graphs) are straightforward. The algorithm is reported to be faster than any other watershed algorithm. Applications of this algorithm with regard to picture segmentation are presented for magnetic resonance (MR) imagery and for digital elevation models. An example of 3-D watershed is also provided. >"
            },
            "slug": "Watersheds-in-Digital-Spaces:-An-Efficient-Based-on-Vincent-Soille",
            "title": {
                "fragments": [],
                "text": "Watersheds in Digital Spaces: An Efficient Algorithm Based on Immersion Simulations"
            },
            "tldr": {
                "abstractSimilarityScore": 72,
                "text": "A fast and flexible algorithm for computing watersheds in digital gray-scale images is introduced, based on an immersion process analogy, which is reported to be faster than any other watershed algorithm."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145564537"
                        ],
                        "name": "Jiri Matas",
                        "slug": "Jiri-Matas",
                        "structuredName": {
                            "firstName": "Jiri",
                            "lastName": "Matas",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jiri Matas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1700928"
                        ],
                        "name": "O. Chum",
                        "slug": "O.-Chum",
                        "structuredName": {
                            "firstName": "Ond\u0159ej",
                            "lastName": "Chum",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Chum"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2067522034"
                        ],
                        "name": "Martin Urban",
                        "slug": "Martin-Urban",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "Urban",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Martin Urban"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1758039"
                        ],
                        "name": "T. Pajdla",
                        "slug": "T.-Pajdla",
                        "structuredName": {
                            "firstName": "Tom\u00e1s",
                            "lastName": "Pajdla",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Pajdla"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 41908779,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "996767727f783c1297d1fb0a4fd5e37e9bf0cd1c",
            "isKey": false,
            "numCitedBy": 1247,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Robust-wide-baseline-stereo-from-maximally-stable-Matas-Chum",
            "title": {
                "fragments": [],
                "text": "Robust wide-baseline stereo from maximally stable extremal regions"
            },
            "venue": {
                "fragments": [],
                "text": "Image Vis. Comput."
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712041"
                        ],
                        "name": "K. Mikolajczyk",
                        "slug": "K.-Mikolajczyk",
                        "structuredName": {
                            "firstName": "Krystian",
                            "lastName": "Mikolajczyk",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Mikolajczyk"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1704728"
                        ],
                        "name": "T. Tuytelaars",
                        "slug": "T.-Tuytelaars",
                        "structuredName": {
                            "firstName": "Tinne",
                            "lastName": "Tuytelaars",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Tuytelaars"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2462253"
                        ],
                        "name": "C. Schmid",
                        "slug": "C.-Schmid",
                        "structuredName": {
                            "firstName": "Cordelia",
                            "lastName": "Schmid",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Schmid"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688869"
                        ],
                        "name": "Andrew Zisserman",
                        "slug": "Andrew-Zisserman",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Zisserman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Zisserman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145564537"
                        ],
                        "name": "Jiri Matas",
                        "slug": "Jiri-Matas",
                        "structuredName": {
                            "firstName": "Jiri",
                            "lastName": "Matas",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jiri Matas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1775242"
                        ],
                        "name": "Frederik Schaffalitzky",
                        "slug": "Frederik-Schaffalitzky",
                        "structuredName": {
                            "firstName": "Frederik",
                            "lastName": "Schaffalitzky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Frederik Schaffalitzky"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2264779"
                        ],
                        "name": "T. Kadir",
                        "slug": "T.-Kadir",
                        "structuredName": {
                            "firstName": "Timor",
                            "lastName": "Kadir",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kadir"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1681236"
                        ],
                        "name": "L. Gool",
                        "slug": "L.-Gool",
                        "structuredName": {
                            "firstName": "Luc",
                            "lastName": "Gool",
                            "middleNames": [
                                "Van"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Gool"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "[5] with a dataset that allows testing the repeatability of a region detector under disturbances such as blur, viewpoint change, zoom, rotation, lighting changes and JPEG compression."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Extraction of invariant regions has recently been the focus of intense study [1,2,3,4,5,6,7,8,9,10,11,12], supporting a wide variety of applications such as recognition, image retrieval, mosaicing, 3D reconstruction, tracking, robot navigation and more."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6794491,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "514b8c50a5b427e2aae75f877454ec9ab3cb4e99",
            "isKey": false,
            "numCitedBy": 3358,
            "numCiting": 58,
            "paperAbstract": {
                "fragments": [],
                "text": "The paper gives a snapshot of the state of the art in affine covariant region detectors, and compares their performance on a set of test images under varying imaging conditions. Six types of detectors are included: detectors based on affine normalization around Harris\u00a0 (Mikolajczyk and \u00a0Schmid, 2002; Schaffalitzky and \u00a0Zisserman, 2002) and Hessian points\u00a0 (Mikolajczyk and \u00a0Schmid, 2002), a detector of \u2018maximally stable extremal regions', proposed by Matas et al.\u00a0(2002); an edge-based region detector\u00a0 (Tuytelaars and Van\u00a0Gool, 1999) and a detector based on intensity extrema (Tuytelaars and Van\u00a0Gool, 2000), and a detector of \u2018salient regions', proposed by Kadir, Zisserman and Brady\u00a0(2004). The performance is measured against changes in viewpoint, scale, illumination, defocus and image compression.The objective of this paper is also to establish a reference test set of images and performance software, so that future detectors can be evaluated in the same framework."
            },
            "slug": "A-Comparison-of-Affine-Region-Detectors-Mikolajczyk-Tuytelaars",
            "title": {
                "fragments": [],
                "text": "A Comparison of Affine Region Detectors"
            },
            "tldr": {
                "abstractSimilarityScore": 71,
                "text": "A snapshot of the state of the art in affine covariant region detectors, and compares their performance on a set of test images under varying imaging conditions to establish a reference test set of images and performance software so that future detectors can be evaluated in the same framework."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1756114"
                        ],
                        "name": "B. Triggs",
                        "slug": "B.-Triggs",
                        "structuredName": {
                            "firstName": "Bill",
                            "lastName": "Triggs",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Triggs"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Extraction of invariant regions has recently been the focus of intense study [1,2,3,4,5,6,7,8,9,10,11,12], supporting a wide variety of applications such as recognition, image retrieval, mosaicing, 3D reconstruction, tracking, robot navigation and more."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 12576337,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3571b814bc47e6503b63eba5be3eb12146f14c2f",
            "isKey": false,
            "numCitedBy": 106,
            "numCiting": 49,
            "paperAbstract": {
                "fragments": [],
                "text": "Local feature approaches to vision geometry and object recognition are based on selecting and matching sparse sets of visually salient image points, known as 'keypoints' or 'points of interest'. Their performance depends critically on the accuracy and reliability with which corresponding keypoints can be found in subsequent images. Among the many existing keypoint selection criteria, the popular Forstner-Harris approach explicitly targets geometric stability, defining keypoints to be points that have locally maximal self-matching precision under translational least squares template matching. However, many applications require stability in orientation and scale as well as in position. Detecting translational key- points and verifying orientation/scale behaviour post hoc is suboptimal, and can be misleading when different motion variables interact. We give a more principled formulation, based on extending the Forstner-Harris approach to general motion models and robust template matching. We also incorporate a simple local appear- ance model to ensure good resistance to the most common illumination variations. We illustrate the resulting methods and quantify their performance on test images."
            },
            "slug": "Detecting-Keypoints-with-Stable-Position,-and-Scale-Triggs",
            "title": {
                "fragments": [],
                "text": "Detecting Keypoints with Stable Position, Orientation, and Scale under Illumination Changes"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A more principled formulation of keypoint selection criteria is given, based on extending the Forstner-Harris approach to general motion models and robust template matching, and is incorporated into a simple local appear- ance model to ensure good resistance to the most common illumination variations."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3205375"
                        ],
                        "name": "T. Lindeberg",
                        "slug": "T.-Lindeberg",
                        "structuredName": {
                            "firstName": "Tony",
                            "lastName": "Lindeberg",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Lindeberg"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Extraction of invariant regions has recently been the focus of intense study [1,2,3,4,5,6,7,8,9,10,11,12], supporting a wide variety of applications such as recognition, image retrieval, mosaicing, 3D reconstruction, tracking, robot navigation and more."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 723210,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b02f474196fb9bd61fa3d418a7ba8ac500e8d422",
            "isKey": false,
            "numCitedBy": 2940,
            "numCiting": 80,
            "paperAbstract": {
                "fragments": [],
                "text": "The fact that objects in the world appear in different ways depending on the scale of observation has important implications if one aims at describing them. It shows that the notion of scale is of utmost importance when processing unknown measurement data by automatic methods. In their seminal works, Witkin (1983) and Koenderink (1984) proposed to approach this problem by representing image structures at different scales in a so-called scale-space representation. Traditional scale-space theory building on this work, however, does not address the problem of how to select local appropriate scales for further analysis. This article proposes a systematic methodology for dealing with this problem. A framework is presented for generating hypotheses about interesting scale levels in image data, based on a general principle stating that local extrema over scales of different combinations of \u03b3-normalized derivatives are likely candidates to correspond to interesting structures. Specifically, it is shown how this idea can be used as a major mechanism in algorithms for automatic scale selection, which adapt the local scales of processing to the local image structure.Support for the proposed approach is given in terms of a general theoretical investigation of the behaviour of the scale selection method under rescalings of the input pattern and by integration with different types of early visual modules, including experiments on real-world and synthetic data. Support is also given by a detailed analysis of how different types of feature detectors perform when integrated with a scale selection mechanism and then applied to characteristic model patterns. Specifically, it is described in detail how the proposed methodology applies to the problems of blob detection, junction detection, edge detection, ridge detection and local frequency estimation.In many computer vision applications, the poor performance of the low-level vision modules constitutes a major bottleneck. It is argued that the inclusion of mechanisms for automatic scale selection is essential if we are to construct vision systems to automatically analyse complex unknown environments."
            },
            "slug": "Feature-Detection-with-Automatic-Scale-Selection-Lindeberg",
            "title": {
                "fragments": [],
                "text": "Feature Detection with Automatic Scale Selection"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "It is shown how the proposed methodology applies to the problems of blob detection, junction detection, edge detection, ridge detection and local frequency estimation and how it can be used as a major mechanism in algorithms for automatic scale selection, which adapt the local scales of processing to the local image structure."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712041"
                        ],
                        "name": "K. Mikolajczyk",
                        "slug": "K.-Mikolajczyk",
                        "structuredName": {
                            "firstName": "Krystian",
                            "lastName": "Mikolajczyk",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Mikolajczyk"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2462253"
                        ],
                        "name": "C. Schmid",
                        "slug": "C.-Schmid",
                        "structuredName": {
                            "firstName": "Cordelia",
                            "lastName": "Schmid",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Schmid"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Maximally Stable Extremal Regions (MSER) described by Matas el al [3] have become one of the commonly used region detector types, partly because of their high repeatability and partly because they are somewhat complementary to many other commonly used detectors [7, 4 ,13]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Extraction of invariant regions has recently been the focus of intense study [1,2,3, 4 ,5,6,7,8,9,10,11,12], supporting a wide variety of applications such as recognition, image retrieval, mosaicing, 3D reconstruction, tracking, robot navigation and more."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1704741,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "8b440596b28dc6683caa2b5f6fbca70963e5909e",
            "isKey": false,
            "numCitedBy": 4161,
            "numCiting": 48,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we propose a novel approach for detecting interest points invariant to scale and affine transformations. Our scale and affine invariant detectors are based on the following recent results: (1) Interest points extracted with the Harris detector can be adapted to affine transformations and give repeatable results (geometrically stable). (2) The characteristic scale of a local structure is indicated by a local extremum over scale of normalized derivatives (the Laplacian). (3) The affine shape of a point neighborhood is estimated based on the second moment matrix.Our scale invariant detector computes a multi-scale representation for the Harris interest point detector and then selects points at which a local measure (the Laplacian) is maximal over scales. This provides a set of distinctive points which are invariant to scale, rotation and translation as well as robust to illumination changes and limited changes of viewpoint. The characteristic scale determines a scale invariant region for each point. We extend the scale invariant detector to affine invariance by estimating the affine shape of a point neighborhood. An iterative algorithm modifies location, scale and neighborhood of each point and converges to affine invariant points. This method can deal with significant affine transformations including large scale changes. The characteristic scale and the affine shape of neighborhood determine an affine invariant region for each point.We present a comparative evaluation of different detectors and show that our approach provides better results than existing methods. The performance of our detector is also confirmed by excellent matching results; the image is described by a set of scale/affine invariant descriptors computed on the regions associated with our points."
            },
            "slug": "Scale-&-Affine-Invariant-Interest-Point-Detectors-Mikolajczyk-Schmid",
            "title": {
                "fragments": [],
                "text": "Scale & Affine Invariant Interest Point Detectors"
            },
            "tldr": {
                "abstractSimilarityScore": 60,
                "text": "A comparative evaluation of different detectors is presented and it is shown that the proposed approach for detecting interest points invariant to scale and affine transformations provides better results than existing methods."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35238678"
                        ],
                        "name": "D. Lowe",
                        "slug": "D.-Lowe",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Lowe",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Lowe"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Extraction of invariant regions has recently been the focus of intense study [1,2,3,4,5,6,7,8,9,10,11,12], supporting a wide variety of applications such as recognition, image retrieval, mosaicing, 3D reconstruction, tracking, robot navigation and more."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Maximally Stable Extremal Regions (MSER) described by Matas el al [3] have become one of the commonly used region detector types, partly because of their high repeatability and partly because they are somewhat complementary to many other commonly used detectors [7,4,13]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 221242327,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8c04f169203f9e55056a6f7f956695babe622a38",
            "isKey": false,
            "numCitedBy": 12997,
            "numCiting": 75,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a method for extracting distinctive invariant features from images that can be used to perform reliable matching between different views of an object or scene. The features are invariant to image scale and rotation, and are shown to provide robust matching across a substantial range of affine distortion, change in 3D viewpoint, addition of noise, and change in illumination. The features are highly distinctive, in the sense that a single feature can be correctly matched with high probability against a large database of features from many images. This paper also describes an approach to using these features for object recognition. The recognition proceeds by matching individual features to a database of features from known objects using a fast nearest-neighbor algorithm, followed by a Hough transform to identify clusters belonging to a single object, and finally performing verification through least-squares solution for consistent pose parameters. This approach to recognition can robustly identify objects among clutter and occlusion while achieving near real-time performance."
            },
            "slug": "Distinctive-Image-Features-from-Scale-Invariant-Lowe",
            "title": {
                "fragments": [],
                "text": "Distinctive Image Features from Scale-Invariant Keypoints"
            },
            "tldr": {
                "abstractSimilarityScore": 77,
                "text": "This paper presents a method for extracting distinctive invariant features from images that can be used to perform reliable matching between different views of an object or scene and can robustly identify objects among clutter and occlusion while achieving near real-time performance."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144735785"
                        ],
                        "name": "Matthew A. Brown",
                        "slug": "Matthew-A.-Brown",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Brown",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Matthew A. Brown"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35238678"
                        ],
                        "name": "D. Lowe",
                        "slug": "D.-Lowe",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Lowe",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Lowe"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Extraction of invariant regions has recently been the focus of intense study [1,2,3,4,5,6,7,8,9,10,11,12], supporting a wide variety of applications such as recognition, image retrieval, mosaicing, 3D reconstruction, tracking, robot navigation and more."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2420060,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "45cb5262b1fb9f149e8f4171e0b1e52d748e062d",
            "isKey": false,
            "numCitedBy": 746,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper approaches the problem of \u00afnding correspondences between images in which there are large changes in viewpoint, scale and illumi- nation. Recent work has shown that scale-space `interest points' may be found with good repeatability in spite of such changes. Further- more, the high entropy of the surrounding image regions means that local descriptors are highly discriminative for matching. For descrip- tors at interest points to be robustly matched between images, they must be as far as possible invariant to the imaging process. In this work we introduce a family of features which use groups of interest points to form geometrically invariant descriptors of image regions. Feature descriptors are formed by resampling the image rel- ative to canonical frames de\u00afned by the points. In addition to robust matching, a key advantage of this approach is that each match implies a hypothesis of the local 2D (projective) transformation. This allows us to immediately reject most of the false matches using a Hough trans- form. We reject remaining outliers using RANSAC and the epipolar constraint. Results show that dense feature matching can be achieved in a few seconds of computation on 1GHz Pentium III machines."
            },
            "slug": "Invariant-Features-from-Interest-Point-Groups-Brown-Lowe",
            "title": {
                "fragments": [],
                "text": "Invariant Features from Interest Point Groups"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "This work introduces a family of features which use groups of interest points to form geometrically invariant descriptors of image regions to ensure robust matching between images in which there are large changes in viewpoint, scale and illumi- nation."
            },
            "venue": {
                "fragments": [],
                "text": "BMVC"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2189557"
                        ],
                        "name": "Step\u00e1n Obdrz\u00e1lek",
                        "slug": "Step\u00e1n-Obdrz\u00e1lek",
                        "structuredName": {
                            "firstName": "Step\u00e1n",
                            "lastName": "Obdrz\u00e1lek",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Step\u00e1n Obdrz\u00e1lek"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145564537"
                        ],
                        "name": "Jiri Matas",
                        "slug": "Jiri-Matas",
                        "structuredName": {
                            "firstName": "Jiri",
                            "lastName": "Matas",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jiri Matas"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "They have also been used in recognition [16] as well as tracking [11] and have been extended to color [17] and volumetric images [18]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 6400968,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "16cf7026acfdbcef00a6524c72dc7ee5a0660ef8",
            "isKey": false,
            "numCitedBy": 241,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "A novel approach to appearance based object recognition is introduced. The proposed method, based on matching of local image features, reliably recognises objects under very different viewing conditions. First, distinguished regions of data-dependent shape are robustly detected. On these regions, local affine frames are established using several affine invariant constructions. Direct comparison of photometrically normalised colour intensities in local, geometrically aligned frames results in a matching scheme that is invariant to piecewise-affine image deformations, but still remains very discriminative. The potential of the approach is experimentally verified on COIL-100 and SOIL-47 \u2010 publicly available image databases. On SOIL-47, 100% recognition rate is achieved for single training view per object. On COIL-100, 99.9% recognition rate is obtained for 18 training views per object. Robustness to severe occlusions is demonstrated by only a moderate decrease of recognition performance in an experiment where half of each test image is erased."
            },
            "slug": "Object-Recognition-using-Local-Affine-Frames-on-Obdrz\u00e1lek-Matas",
            "title": {
                "fragments": [],
                "text": "Object Recognition using Local Affine Frames on Distinguished Regions"
            },
            "tldr": {
                "abstractSimilarityScore": 74,
                "text": "A novel approach to appearance based object recognition based on matching of local image features, reliably recognises objects under very different viewing conditions that is invariant to piecewise-affine image deformations, but still remains very discriminative."
            },
            "venue": {
                "fragments": [],
                "text": "BMVC"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144968753"
                        ],
                        "name": "J. Roerdink",
                        "slug": "J.-Roerdink",
                        "structuredName": {
                            "firstName": "Jos",
                            "lastName": "Roerdink",
                            "middleNames": [
                                "B.",
                                "T.",
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Roerdink"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2796558"
                        ],
                        "name": "Arnold Meijster",
                        "slug": "Arnold-Meijster",
                        "structuredName": {
                            "firstName": "Arnold",
                            "lastName": "Meijster",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Arnold Meijster"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "The watershed segmentation has a long history and has been intensely studied, see [21] for a review."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "The union-find data structure with path-compression supports quasi-linear time in the number of pixels [21,22,23]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6050657,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f389e9f8d328443664f4792eb942e190a4d06f4d",
            "isKey": false,
            "numCitedBy": 1410,
            "numCiting": 54,
            "paperAbstract": {
                "fragments": [],
                "text": "The watershed transform is the method of choice for image segmentation in the field of mathematical morphology. We present a critical review of several definitions of the watershed transform and the associated sequential algorithms, and discuss various issues which often cause confusion in the literature. The need to distinguish between definition, algorithm specification and algorithm implementation is pointed out. Various examples are given which illustrate differences between watershed transforms based on different definitions and/or implementations. The second part of the paper surveys approaches for parallel implementation of sequential watershed algorithms."
            },
            "slug": "The-Watershed-Transform:-Definitions,-Algorithms-Roerdink-Meijster",
            "title": {
                "fragments": [],
                "text": "The Watershed Transform: Definitions, Algorithms and Parallelization Strategies"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A critical review of several definitions of the watershed transform and the associated sequential algorithms, and discusses various issues which often cause confusion in the literature are presented."
            },
            "venue": {
                "fragments": [],
                "text": "Fundam. Informaticae"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1793476"
                        ],
                        "name": "M. Donoser",
                        "slug": "M.-Donoser",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Donoser",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Donoser"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144746444"
                        ],
                        "name": "H. Bischof",
                        "slug": "H.-Bischof",
                        "structuredName": {
                            "firstName": "Horst",
                            "lastName": "Bischof",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Bischof"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "They have also been used in recognition [16] as well as tracking [11] and have been extended to color [17] and volumetric images [18]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14461734,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "ebaf0352bc66b70ee3f2b8df38ca481b7a0264a8",
            "isKey": false,
            "numCitedBy": 65,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper introduces an efficient 3D segmentation concept, which is based on extending the well-known maximally stable extremal region (MSER) detector to the third dimension. The extension allows the detection of stable 3D regions, which we call the maximally stable volumes (MSVs). We present a very efficient way to detect the MSVs in quasi-linear time by analysis of the component tree. Two applications - 3D segmentation within simulated MR brain images and analysis of the 3D fiber network within digitized paper samples $show that reasonably good segmentation results are achieved with low computational effort"
            },
            "slug": "3D-Segmentation-by-Maximally-Stable-Volumes-(MSVs)-Donoser-Bischof",
            "title": {
                "fragments": [],
                "text": "3D Segmentation by Maximally Stable Volumes (MSVs)"
            },
            "tldr": {
                "abstractSimilarityScore": 69,
                "text": "An efficient 3D segmentation concept based on extending the well-known maximally stable extremal region (MSER) detector to the third dimension is introduced and a very efficient way to detect the MSVs in quasi-linear time by analysis of the component tree is presented."
            },
            "venue": {
                "fragments": [],
                "text": "18th International Conference on Pattern Recognition (ICPR'06)"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3083483"
                        ],
                        "name": "D. Nist\u00e9r",
                        "slug": "D.-Nist\u00e9r",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Nist\u00e9r",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Nist\u00e9r"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3086037"
                        ],
                        "name": "Henrik Stew\u00e9nius",
                        "slug": "Henrik-Stew\u00e9nius",
                        "structuredName": {
                            "firstName": "Henrik",
                            "lastName": "Stew\u00e9nius",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Henrik Stew\u00e9nius"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "small number of regions per image, and are therefore well suited for large scale image retrieval tasks [14,15]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1654266,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b3e7d3e37e67af7f4546b46051063bea1b62dbae",
            "isKey": false,
            "numCitedBy": 3890,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "A recognition scheme that scales efficiently to a large number of objects is presented. The efficiency and quality is exhibited in a live demonstration that recognizes CD-covers from a database of 40000 images of popular music CD\u2019s. The scheme builds upon popular techniques of indexing descriptors extracted from local regions, and is robust to background clutter and occlusion. The local region descriptors are hierarchically quantized in a vocabulary tree. The vocabulary tree allows a larger and more discriminatory vocabulary to be used efficiently, which we show experimentally leads to a dramatic improvement in retrieval quality. The most significant property of the scheme is that the tree directly defines the quantization. The quantization and the indexing are therefore fully integrated, essentially being one and the same. The recognition quality is evaluated through retrieval on a database with ground truth, showing the power of the vocabulary tree approach, going as high as 1 million images."
            },
            "slug": "Scalable-Recognition-with-a-Vocabulary-Tree-Nist\u00e9r-Stew\u00e9nius",
            "title": {
                "fragments": [],
                "text": "Scalable Recognition with a Vocabulary Tree"
            },
            "tldr": {
                "abstractSimilarityScore": 54,
                "text": "A recognition scheme that scales efficiently to a large number of objects and allows a larger and more discriminatory vocabulary to be used efficiently is presented, which it is shown experimentally leads to a dramatic improvement in retrieval quality."
            },
            "venue": {
                "fragments": [],
                "text": "2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'06)"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40309692"
                        ],
                        "name": "C. G. Harris",
                        "slug": "C.-G.-Harris",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Harris",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. G. Harris"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40365651"
                        ],
                        "name": "M. Stephens",
                        "slug": "M.-Stephens",
                        "structuredName": {
                            "firstName": "M.",
                            "lastName": "Stephens",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Stephens"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1694378,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6818668fb895d95861a2eb9673ddc3a41e27b3b3",
            "isKey": false,
            "numCitedBy": 14111,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "The problem we are addressing in Alvey Project MMI149 is that of using computer vision to understand the unconstrained 3D world, in which the viewed scenes will in general contain too wide a diversity of objects for topdown recognition techniques to work. For example, we desire to obtain an understanding of natural scenes, containing roads, buildings, trees, bushes, etc., as typified by the two frames from a sequence illustrated in Figure 1. The solution to this problem that we are pursuing is to use a computer vision system based upon motion analysis of a monocular image sequence from a mobile camera. By extraction and tracking of image features, representations of the 3D analogues of these features can be constructed."
            },
            "slug": "A-Combined-Corner-and-Edge-Detector-Harris-Stephens",
            "title": {
                "fragments": [],
                "text": "A Combined Corner and Edge Detector"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "The problem the authors are addressing in Alvey Project MMI149 is that of using computer vision to understand the unconstrained 3D world, in which the viewed scenes will in general contain too wide a diversity of objects for topdown recognition techniques to work."
            },
            "venue": {
                "fragments": [],
                "text": "Alvey Vision Conference"
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1782755"
                        ],
                        "name": "Josef Sivic",
                        "slug": "Josef-Sivic",
                        "structuredName": {
                            "firstName": "Josef",
                            "lastName": "Sivic",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Josef Sivic"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688869"
                        ],
                        "name": "Andrew Zisserman",
                        "slug": "Andrew-Zisserman",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Zisserman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Zisserman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "small number of regions per image, and are therefore well suited for large scale image retrieval tasks [14,15]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14457153,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "642e328cae81c5adb30069b680cf60ba6b475153",
            "isKey": false,
            "numCitedBy": 6760,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe an approach to object and scene retrieval which searches for and localizes all the occurrences of a user outlined object in a video. The object is represented by a set of viewpoint invariant region descriptors so that recognition can proceed successfully despite changes in viewpoint, illumination and partial occlusion. The temporal continuity of the video within a shot is used to track the regions in order to reject unstable regions and reduce the effects of noise in the descriptors. The analogy with text retrieval is in the implementation where matches on descriptors are pre-computed (using vector quantization), and inverted file systems and document rankings are used. The result is that retrieved is immediate, returning a ranked list of key frames/shots in the manner of Google. The method is illustrated for matching in two full length feature films."
            },
            "slug": "Video-Google:-a-text-retrieval-approach-to-object-Sivic-Zisserman",
            "title": {
                "fragments": [],
                "text": "Video Google: a text retrieval approach to object matching in videos"
            },
            "tldr": {
                "abstractSimilarityScore": 92,
                "text": "An approach to object and scene retrieval which searches for and localizes all the occurrences of a user outlined object in a video, represented by a set of viewpoint invariant region descriptors so that recognition can proceed successfully despite changes in viewpoint, illumination and partial occlusion."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings Ninth IEEE International Conference on Computer Vision"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1736489"
                        ],
                        "name": "Fred Rothganger",
                        "slug": "Fred-Rothganger",
                        "structuredName": {
                            "firstName": "Fred",
                            "lastName": "Rothganger",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Fred Rothganger"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1749609"
                        ],
                        "name": "S. Lazebnik",
                        "slug": "S.-Lazebnik",
                        "structuredName": {
                            "firstName": "Svetlana",
                            "lastName": "Lazebnik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Lazebnik"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2462253"
                        ],
                        "name": "C. Schmid",
                        "slug": "C.-Schmid",
                        "structuredName": {
                            "firstName": "Cordelia",
                            "lastName": "Schmid",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Schmid"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144189388"
                        ],
                        "name": "J. Ponce",
                        "slug": "J.-Ponce",
                        "structuredName": {
                            "firstName": "Jean",
                            "lastName": "Ponce",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Ponce"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Extraction of invariant regions has recently been the focus of intense study [1,2,3,4,5,6,7,8,9,10,11,12], supporting a wide variety of applications such as recognition, image retrieval, mosaicing, 3D reconstruction, tracking, robot navigation and more."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1330784,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "a6f3b1d94193a76f9f06d26e67cb22fd31aa735f",
            "isKey": false,
            "numCitedBy": 402,
            "numCiting": 113,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract.This article introduces a novel representation for three-dimensional (3D) objects in terms of local affine-invariant descriptors of their images and the spatial relationships between the corresponding surface patches. Geometric constraints associated with different views of the same patches under affine projection are combined with a normalized representation of their appearance to guide matching and reconstruction, allowing the acquisition of true 3D affine and Euclidean models from multiple unregistered images, as well as their recognition in photographs taken from arbitrary viewpoints. The proposed approach does not require a separate segmentation stage, and it is applicable to highly cluttered scenes. Modeling and recognition results are presented."
            },
            "slug": "3D-Object-Modeling-and-Recognition-Using-Local-and-Rothganger-Lazebnik",
            "title": {
                "fragments": [],
                "text": "3D Object Modeling and Recognition Using Local Affine-Invariant Image Descriptors and Multi-View Spatial Constraints"
            },
            "tldr": {
                "abstractSimilarityScore": 68,
                "text": "A novel representation for three-dimensional objects in terms of local affine-invariant descriptors of their images and the spatial relationships between the corresponding surface patches is introduced, allowing the acquisition of true 3D affine and Euclidean models from multiple unregistered images, as well as their recognition in photographs taken from arbitrary viewpoints."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2264779"
                        ],
                        "name": "T. Kadir",
                        "slug": "T.-Kadir",
                        "structuredName": {
                            "firstName": "Timor",
                            "lastName": "Kadir",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kadir"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688869"
                        ],
                        "name": "Andrew Zisserman",
                        "slug": "Andrew-Zisserman",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Zisserman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Zisserman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144431498"
                        ],
                        "name": "M. Brady",
                        "slug": "M.-Brady",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Brady",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Brady"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Extraction of invariant regions has recently been the focus of intense study [1,2,3,4,5,6,7,8,9,10,11,12], supporting a wide variety of applications such as recognition, image retrieval, mosaicing, 3D reconstruction, tracking, robot navigation and more."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 8868228,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "5a3ad8b87e865665d6879a63578990af1bde8055",
            "isKey": false,
            "numCitedBy": 558,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we describe a novel technique for detecting salient regions in an image. The detector is a generalization to affine invariance of the method introduced by Kadir and Brady [10]. The detector deems a region salient if it exhibits unpredictability in both its attributes and its spatial scale."
            },
            "slug": "An-Affine-Invariant-Salient-Region-Detector-Kadir-Zisserman",
            "title": {
                "fragments": [],
                "text": "An Affine Invariant Salient Region Detector"
            },
            "tldr": {
                "abstractSimilarityScore": 80,
                "text": "A novel technique for detecting salient regions in an image is described, which is a generalization to affine invariance of the method introduced by Kadir and Brady."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2462253"
                        ],
                        "name": "C. Schmid",
                        "slug": "C.-Schmid",
                        "structuredName": {
                            "firstName": "Cordelia",
                            "lastName": "Schmid",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Schmid"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145299933"
                        ],
                        "name": "R. Mohr",
                        "slug": "R.-Mohr",
                        "structuredName": {
                            "firstName": "Roger",
                            "lastName": "Mohr",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Mohr"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1692283"
                        ],
                        "name": "C. Bauckhage",
                        "slug": "C.-Bauckhage",
                        "structuredName": {
                            "firstName": "Christian",
                            "lastName": "Bauckhage",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Bauckhage"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Extraction of invariant regions has recently been the focus of intense study [1,2,3,4,5,6,7,8,9,10,11,12], supporting a wide variety of applications such as recognition, image retrieval, mosaicing, 3D reconstruction, tracking, robot navigation and more."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14571093,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2713e7a59105a832e20c01c3c202b9dcd2b5f889",
            "isKey": false,
            "numCitedBy": 1730,
            "numCiting": 64,
            "paperAbstract": {
                "fragments": [],
                "text": "Many different low-level feature detectors exist and it is widely agreed that the evaluation of detectors is important. In this paper we introduce two evaluation criteria for interest points' repeatability rate and information content. Repeatability rate evaluates the geometric stability under different transformations. Information content measures the distinctiveness of features. Different interest point detectors are compared using these two criteria. We determine which detector gives the best results and show that it satisfies the criteria well."
            },
            "slug": "Evaluation-of-Interest-Point-Detectors-Schmid-Mohr",
            "title": {
                "fragments": [],
                "text": "Evaluation of Interest Point Detectors"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "Two evaluation criteria for interest points' repeatability rate and information content are introduced and different interest point detectors are compared using these two criteria."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1721050"
                        ],
                        "name": "R. Tarjan",
                        "slug": "R.-Tarjan",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Tarjan",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Tarjan"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "The union-find data structure with path-compression supports quasi-linear time in the number of pixels [21,22,23]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 116926536,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e60cbae0a44a5b5d94888946ef2a15c7036ce853",
            "isKey": false,
            "numCitedBy": 2153,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Foundations Disjoint Sets Heaps Search Trees Linking and Cutting Trees Minimum Spanning Trees Shortest Paths Network Flows Matchings."
            },
            "slug": "Data-structures-and-network-algorithms-Tarjan",
            "title": {
                "fragments": [],
                "text": "Data structures and network algorithms"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "This paper presents a meta-trees tree model that automates the very labor-intensive and therefore time-heavy and therefore expensive process of manually selecting trees to grow in a graph."
            },
            "venue": {
                "fragments": [],
                "text": "CBMS-NSF regional conference series in applied mathematics"
            },
            "year": 1983
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Hence the expression \u2019quasi-linear\u2019 is well motivated, although a true linear time algorithm for the union-find problem to our knowledge requires limiting assumptions such as for example the existence of a computer with log(n) word length and incremental growing of the data structure [24]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7483054,
            "fieldsOfStudy": [],
            "id": "6ad8624f90a1d025c12900ccc7e950921bc073aa",
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A Linear-Time Algorithm for a Special Case of Disjoint Set Union"
            },
            "venue": {
                "fragments": [],
                "text": "J. Comput. Syst. Sci."
            },
            "year": 1985
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1704728"
                        ],
                        "name": "T. Tuytelaars",
                        "slug": "T.-Tuytelaars",
                        "structuredName": {
                            "firstName": "Tinne",
                            "lastName": "Tuytelaars",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Tuytelaars"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1681236"
                        ],
                        "name": "L. Gool",
                        "slug": "L.-Gool",
                        "structuredName": {
                            "firstName": "Luc",
                            "lastName": "Gool",
                            "middleNames": [
                                "Van"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Gool"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Extraction of invariant regions has recently been the focus of intense study [1,2,3,4,5,6,7,8,9,10,11,12], supporting a wide variety of applications such as recognition, image retrieval, mosaicing, 3D reconstruction, tracking, robot navigation and more."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5107897,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2893662ec4001949b4afcba124492340216dfd7e",
            "isKey": false,
            "numCitedBy": 732,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract\u2018Invariant regions\u2019 are self-adaptive image patches that automatically deform with changing viewpoint as to keep on covering identical physical parts of a scene. Such regions can be extracted directly from a single image. They are then described by a set of invariant features, which makes it relatively easy to match them between views, even under wide baseline conditions. In this contribution, two methods to extract invariant regions are presented. The first one starts from corners and uses the nearby edges, while the second one is purely intensity-based. As a matter of fact, the goal is to build an opportunistic system that exploits several types of invariant regions as it sees fit. This yields more correspondences and a system that can deal with a wider range of images. To increase the robustness of the system, two semi-local constraints on combinations of region correspondences are derived (one geometric, the other photometric). They allow to test the consistency of correspondences and hence to reject falsely matched regions. Experiments on images of real-world scenes taken from substantially different viewpoints demonstrate the feasibility of the approach."
            },
            "slug": "Matching-Widely-Separated-Views-Based-on-Affine-Tuytelaars-Gool",
            "title": {
                "fragments": [],
                "text": "Matching Widely Separated Views Based on Affine Invariant Regions"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "To increase the robustness of the system, two semi-local constraints on combinations of region correspondences are derived (one geometric, the other photometric) allow to test the consistency of correspondences and hence to reject falsely matched regions."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2004
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 18,
            "methodology": 5
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 25,
        "totalPages": 3
    },
    "page_url": "https://www.semanticscholar.org/paper/Linear-Time-Maximally-Stable-Extremal-Regions-Nist\u00e9r-Stew\u00e9nius/c79a502b49f24597f818b08a3c67ec3100a36bcb?sort=total-citations"
}