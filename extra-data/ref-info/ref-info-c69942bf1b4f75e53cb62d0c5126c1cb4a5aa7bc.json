{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694974"
                        ],
                        "name": "Dimosthenis Karatzas",
                        "slug": "Dimosthenis-Karatzas",
                        "structuredName": {
                            "firstName": "Dimosthenis",
                            "lastName": "Karatzas",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dimosthenis Karatzas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2730090"
                        ],
                        "name": "L. G. I. Bigorda",
                        "slug": "L.-G.-I.-Bigorda",
                        "structuredName": {
                            "firstName": "Llu\u00eds",
                            "lastName": "Bigorda",
                            "middleNames": [
                                "G\u00f3mez",
                                "i"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. G. I. Bigorda"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143823474"
                        ],
                        "name": "Mar\u00e7al Rusi\u00f1ol",
                        "slug": "Mar\u00e7al-Rusi\u00f1ol",
                        "structuredName": {
                            "firstName": "Mar\u00e7al",
                            "lastName": "Rusi\u00f1ol",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mar\u00e7al Rusi\u00f1ol"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 125,
                                "start": 122
                            }
                        ],
                        "text": "For example, ICDAR 2019 Post-OCR Challenge introduced the Scanned Receipts OCR and Information Extraction (SROIE) dataset [6]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 27145020,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c3c70a2551f12df0133dfb719c02c1a8f14a2232",
            "isKey": false,
            "numCitedBy": 6,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "The ICDAR Robust Reading Competition (RRC), initiated in 2003 and re-established in 2011, has become a de-facto evaluation standard for robust reading systems and algorithms. Concurrent with its second incarnation in 2011, a continuous effort started to develop an on-line framework to facilitate the hosting and management of competitions. This paper outlines the Robust Reading Competition Annotation and Evaluation Platform, the backbone of the competitions. The RRC Annotation and Evaluation Platform is a modular framework, fully accessible through on-line interfaces. It comprises a collection of tools and services for managing all processes involved with defining and evaluating a research task, from dataset definition to annotation management, evaluation specification and results analysis. Although the framework has been designed with robust reading research in mind, many of the provided tools are generic by design. All aspects of the RRC Annotation and Evaluation Framework are available for research use."
            },
            "slug": "The-Robust-Reading-Competition-Annotation-and-Karatzas-Bigorda",
            "title": {
                "fragments": [],
                "text": "The Robust Reading Competition Annotation and Evaluation Platform"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "The RRC Annotation and Evaluation Framework is a modular framework that comprises a collection of tools and services for managing all processes involved with defining and evaluating a research task, from dataset definition to annotation management, evaluation specification and results analysis."
            },
            "venue": {
                "fragments": [],
                "text": "2018 13th IAPR International Workshop on Document Analysis Systems (DAS)"
            },
            "year": 2018
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694974"
                        ],
                        "name": "Dimosthenis Karatzas",
                        "slug": "Dimosthenis-Karatzas",
                        "structuredName": {
                            "firstName": "Dimosthenis",
                            "lastName": "Karatzas",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dimosthenis Karatzas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2730090"
                        ],
                        "name": "L. G. I. Bigorda",
                        "slug": "L.-G.-I.-Bigorda",
                        "structuredName": {
                            "firstName": "Llu\u00eds",
                            "lastName": "Bigorda",
                            "middleNames": [
                                "G\u00f3mez",
                                "i"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. G. I. Bigorda"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2098117"
                        ],
                        "name": "Anguelos Nicolaou",
                        "slug": "Anguelos-Nicolaou",
                        "structuredName": {
                            "firstName": "Anguelos",
                            "lastName": "Nicolaou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Anguelos Nicolaou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39937691"
                        ],
                        "name": "Suman K. Ghosh",
                        "slug": "Suman-K.-Ghosh",
                        "structuredName": {
                            "firstName": "Suman",
                            "lastName": "Ghosh",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Suman K. Ghosh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1749498"
                        ],
                        "name": "Andrew D. Bagdanov",
                        "slug": "Andrew-D.-Bagdanov",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Bagdanov",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew D. Bagdanov"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35613969"
                        ],
                        "name": "M. Iwamura",
                        "slug": "M.-Iwamura",
                        "structuredName": {
                            "firstName": "M.",
                            "lastName": "Iwamura",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Iwamura"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145564537"
                        ],
                        "name": "Jiri Matas",
                        "slug": "Jiri-Matas",
                        "structuredName": {
                            "firstName": "Jiri",
                            "lastName": "Matas",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jiri Matas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145532509"
                        ],
                        "name": "Luk\u00e1s Neumann",
                        "slug": "Luk\u00e1s-Neumann",
                        "structuredName": {
                            "firstName": "Luk\u00e1s",
                            "lastName": "Neumann",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Luk\u00e1s Neumann"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1802086"
                        ],
                        "name": "V. Chandrasekhar",
                        "slug": "V.-Chandrasekhar",
                        "structuredName": {
                            "firstName": "Vijay",
                            "lastName": "Chandrasekhar",
                            "middleNames": [
                                "Ramaseshan"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Chandrasekhar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1771189"
                        ],
                        "name": "Shijian Lu",
                        "slug": "Shijian-Lu",
                        "structuredName": {
                            "firstName": "Shijian",
                            "lastName": "Lu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shijian Lu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688013"
                        ],
                        "name": "F. Shafait",
                        "slug": "F.-Shafait",
                        "structuredName": {
                            "firstName": "Faisal",
                            "lastName": "Shafait",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Shafait"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1809705"
                        ],
                        "name": "S. Uchida",
                        "slug": "S.-Uchida",
                        "structuredName": {
                            "firstName": "Seiichi",
                            "lastName": "Uchida",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Uchida"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2864362"
                        ],
                        "name": "Ernest Valveny",
                        "slug": "Ernest-Valveny",
                        "structuredName": {
                            "firstName": "Ernest",
                            "lastName": "Valveny",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ernest Valveny"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 110,
                                "start": 107
                            }
                        ],
                        "text": "Over the past few years, a few post-OCR parsing datasets have been made public through post OCR challenges [5]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 13322740,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9b02f729e6d442f6872078f599fc9da5c3605cee",
            "isKey": false,
            "numCitedBy": 787,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "Results of the ICDAR 2015 Robust Reading Competition are presented. A new Challenge 4 on Incidental Scene Text has been added to the Challenges on Born-Digital Images, Focused Scene Images and Video Text. Challenge 4 is run on a newly acquired dataset of 1,670 images evaluating Text Localisation, Word Recognition and End-to-End pipelines. In addition, the dataset for Challenge 3 on Video Text has been substantially updated with more video sequences and more accurate ground truth data. Finally, tasks assessing End-to-End system performance have been introduced to all Challenges. The competition took place in the first quarter of 2015, and received a total of 44 submissions. Only the tasks newly introduced in 2015 are reported on. The datasets, the ground truth specification and the evaluation protocols are presented together with the results and a brief summary of the participating methods."
            },
            "slug": "ICDAR-2015-competition-on-Robust-Reading-Karatzas-Bigorda",
            "title": {
                "fragments": [],
                "text": "ICDAR 2015 competition on Robust Reading"
            },
            "tldr": {
                "abstractSimilarityScore": 65,
                "text": "A new Challenge 4 on Incidental Scene Text has been added to the Challenges on Born-Digital Images, Focused Scene Images and Video Text and tasks assessing End-to-End system performance have been introduced to all Challenges."
            },
            "venue": {
                "fragments": [],
                "text": "2015 13th International Conference on Document Analysis and Recognition (ICDAR)"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34133335"
                        ],
                        "name": "Jeonghun Baek",
                        "slug": "Jeonghun-Baek",
                        "structuredName": {
                            "firstName": "Jeonghun",
                            "lastName": "Baek",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jeonghun Baek"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2115988519"
                        ],
                        "name": "Geewook Kim",
                        "slug": "Geewook-Kim",
                        "structuredName": {
                            "firstName": "Geewook",
                            "lastName": "Kim",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geewook Kim"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39924323"
                        ],
                        "name": "Junyeop Lee",
                        "slug": "Junyeop-Lee",
                        "structuredName": {
                            "firstName": "Junyeop",
                            "lastName": "Lee",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Junyeop Lee"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "71537829"
                        ],
                        "name": "Sungrae Park",
                        "slug": "Sungrae-Park",
                        "structuredName": {
                            "firstName": "Sungrae",
                            "lastName": "Park",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sungrae Park"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2086576"
                        ],
                        "name": "Dongyoon Han",
                        "slug": "Dongyoon-Han",
                        "structuredName": {
                            "firstName": "Dongyoon",
                            "lastName": "Han",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dongyoon Han"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2151587"
                        ],
                        "name": "Sangdoo Yun",
                        "slug": "Sangdoo-Yun",
                        "structuredName": {
                            "firstName": "Sangdoo",
                            "lastName": "Yun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sangdoo Yun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2390510"
                        ],
                        "name": "Seong Joon Oh",
                        "slug": "Seong-Joon-Oh",
                        "structuredName": {
                            "firstName": "Seong Joon",
                            "lastName": "Oh",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Seong Joon Oh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "72152162"
                        ],
                        "name": "Hwalsuk Lee",
                        "slug": "Hwalsuk-Lee",
                        "structuredName": {
                            "firstName": "Hwalsuk",
                            "lastName": "Lee",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hwalsuk Lee"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 107,
                                "start": 101
                            }
                        ],
                        "text": "Recently, deep learning in computer vision domain has significantly improved the performances of OCR [3, 4]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 102481180,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9387ffc038bc744e5eb335fe54b4f3f184202d77",
            "isKey": false,
            "numCitedBy": 201,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "Many new proposals for scene text recognition (STR) models have been introduced in recent years. While each claim to have pushed the boundary of the technology, a holistic and fair comparison has been largely missing in the field due to the inconsistent choices of training and evaluation datasets. This paper addresses this difficulty with three major contributions. First, we examine the inconsistencies of training and evaluation datasets, and the performance gap results from inconsistencies. Second, we introduce a unified four-stage STR framework that most existing STR models fit into. Using this framework allows for the extensive evaluation of previously proposed STR modules and the discovery of previously unexplored module combinations. Third, we analyze the module-wise contributions to performance in terms of accuracy, speed, and memory demand, under one consistent set of training and evaluation datasets. Such analyses clean up the hindrance on the current comparisons to understand the performance gain of the existing modules. Our code is publicly available."
            },
            "slug": "What-Is-Wrong-With-Scene-Text-Recognition-Model-and-Baek-Kim",
            "title": {
                "fragments": [],
                "text": "What Is Wrong With Scene Text Recognition Model Comparisons? Dataset and Model Analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A unified four-stage STR framework is introduced that most existing STR models fit into and allows for the extensive evaluation of previously proposed STR modules and the discovery of previously unexplored module combinations."
            },
            "venue": {
                "fragments": [],
                "text": "2019 IEEE/CVF International Conference on Computer Vision (ICCV)"
            },
            "year": 2019
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2148927556"
                        ],
                        "name": "Xinyu Zhou",
                        "slug": "Xinyu-Zhou",
                        "structuredName": {
                            "firstName": "Xinyu",
                            "lastName": "Zhou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xinyu Zhou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2146721"
                        ],
                        "name": "C. Yao",
                        "slug": "C.-Yao",
                        "structuredName": {
                            "firstName": "Cong",
                            "lastName": "Yao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Yao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2075348632"
                        ],
                        "name": "He Wen",
                        "slug": "He-Wen",
                        "structuredName": {
                            "firstName": "He",
                            "lastName": "Wen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "He Wen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47905836"
                        ],
                        "name": "Yuzhi Wang",
                        "slug": "Yuzhi-Wang",
                        "structuredName": {
                            "firstName": "Yuzhi",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yuzhi Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35132667"
                        ],
                        "name": "Shuchang Zhou",
                        "slug": "Shuchang-Zhou",
                        "structuredName": {
                            "firstName": "Shuchang",
                            "lastName": "Zhou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shuchang Zhou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2416953"
                        ],
                        "name": "Weiran He",
                        "slug": "Weiran-He",
                        "structuredName": {
                            "firstName": "Weiran",
                            "lastName": "He",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Weiran He"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1387852255"
                        ],
                        "name": "Jiajun Liang",
                        "slug": "Jiajun-Liang",
                        "structuredName": {
                            "firstName": "Jiajun",
                            "lastName": "Liang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jiajun Liang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 129,
                                "start": 123
                            }
                        ],
                        "text": "1 Introduction Optical character recognition (OCR) is a technique for converting images of characters into digitized texts [1, 2]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 706860,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5f1630b4485027eb99ae59b745372ef1f3699c16",
            "isKey": false,
            "numCitedBy": 904,
            "numCiting": 55,
            "paperAbstract": {
                "fragments": [],
                "text": "Previous approaches for scene text detection have already achieved promising performances across various benchmarks. However, they usually fall short when dealing with challenging scenarios, even when equipped with deep neural network models, because the overall performance is determined by the interplay of multiple stages and components in the pipelines. In this work, we propose a simple yet powerful pipeline that yields fast and accurate text detection in natural scenes. The pipeline directly predicts words or text lines of arbitrary orientations and quadrilateral shapes in full images, eliminating unnecessary intermediate steps (e.g., candidate aggregation and word partitioning), with a single neural network. The simplicity of our pipeline allows concentrating efforts on designing loss functions and neural network architecture. Experiments on standard datasets including ICDAR 2015, COCO-Text and MSRA-TD500 demonstrate that the proposed algorithm significantly outperforms state-of-the-art methods in terms of both accuracy and efficiency. On the ICDAR 2015 dataset, the proposed algorithm achieves an F-score of 0.7820 at 13.2fps at 720p resolution."
            },
            "slug": "EAST:-An-Efficient-and-Accurate-Scene-Text-Detector-Zhou-Yao",
            "title": {
                "fragments": [],
                "text": "EAST: An Efficient and Accurate Scene Text Detector"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This work proposes a simple yet powerful pipeline that yields fast and accurate text detection in natural scenes, and significantly outperforms state-of-the-art methods in terms of both accuracy and efficiency."
            },
            "venue": {
                "fragments": [],
                "text": "2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8155680"
                        ],
                        "name": "Minghui Liao",
                        "slug": "Minghui-Liao",
                        "structuredName": {
                            "firstName": "Minghui",
                            "lastName": "Liao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Minghui Liao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2276155"
                        ],
                        "name": "Baoguang Shi",
                        "slug": "Baoguang-Shi",
                        "structuredName": {
                            "firstName": "Baoguang",
                            "lastName": "Shi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Baoguang Shi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145905113"
                        ],
                        "name": "X. Bai",
                        "slug": "X.-Bai",
                        "structuredName": {
                            "firstName": "Xiang",
                            "lastName": "Bai",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "X. Bai"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 129,
                                "start": 123
                            }
                        ],
                        "text": "1 Introduction Optical character recognition (OCR) is a technique for converting images of characters into digitized texts [1, 2]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 4526080,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4a674c0a7d8b741f808155a0762cc785406f6e24",
            "isKey": false,
            "numCitedBy": 442,
            "numCiting": 67,
            "paperAbstract": {
                "fragments": [],
                "text": "Scene text detection is an important step of scene text recognition system and also a challenging problem. Different from general object detections, the main challenges of scene text detection lie on arbitrary orientations, small sizes, and significantly variant aspect ratios of text in natural images. In this paper, we present an end-to-end trainable fast scene text detector, named TextBoxes++, which detects arbitrary-oriented scene text with both high accuracy and efficiency in a single network forward pass. No post-processing other than efficient non-maximum suppression is involved. We have evaluated the proposed TextBoxes++ on four public data sets. In all experiments, TextBoxes++ outperforms competing methods in terms of text localization accuracy and runtime. More specifically, TextBoxes++ achieves an f-measure of 0.817 at 11.6 frames/s for <inline-formula> <tex-math notation=\"LaTeX\">$1024 \\times 1024$ </tex-math></inline-formula> ICDAR 2015 incidental text images and an f-measure of 0.5591 at 19.8 frames/s for <inline-formula> <tex-math notation=\"LaTeX\">$768 \\times 768$ </tex-math></inline-formula> COCO-Text images. Furthermore, combined with a text recognizer, TextBoxes++ significantly outperforms the state-of-the-art approaches for word spotting and end-to-end text recognition tasks on popular benchmarks. Code is available at: <uri>https://github.com/MhLiao/TextBoxes_plusplus</uri>."
            },
            "slug": "TextBoxes++:-A-Single-Shot-Oriented-Scene-Text-Liao-Shi",
            "title": {
                "fragments": [],
                "text": "TextBoxes++: A Single-Shot Oriented Scene Text Detector"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "An end- to-end trainable fast scene text detector, named TextBoxes++, which detects arbitrary-oriented scene text with both high accuracy and efficiency in a single network forward pass, and significantly outperforms the state-of-the-art approaches for word spotting and end-to-end text recognition tasks on popular benchmarks."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Image Processing"
            },
            "year": 2018
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2057310228"
                        ],
                        "name": "Youngmin Baek",
                        "slug": "Youngmin-Baek",
                        "structuredName": {
                            "firstName": "Youngmin",
                            "lastName": "Baek",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Youngmin Baek"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2722273"
                        ],
                        "name": "Bado Lee",
                        "slug": "Bado-Lee",
                        "structuredName": {
                            "firstName": "Bado",
                            "lastName": "Lee",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bado Lee"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2086576"
                        ],
                        "name": "Dongyoon Han",
                        "slug": "Dongyoon-Han",
                        "structuredName": {
                            "firstName": "Dongyoon",
                            "lastName": "Han",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dongyoon Han"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2151587"
                        ],
                        "name": "Sangdoo Yun",
                        "slug": "Sangdoo-Yun",
                        "structuredName": {
                            "firstName": "Sangdoo",
                            "lastName": "Yun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sangdoo Yun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "72152162"
                        ],
                        "name": "Hwalsuk Lee",
                        "slug": "Hwalsuk-Lee",
                        "structuredName": {
                            "firstName": "Hwalsuk",
                            "lastName": "Lee",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hwalsuk Lee"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 107,
                                "start": 101
                            }
                        ],
                        "text": "Recently, deep learning in computer vision domain has significantly improved the performances of OCR [3, 4]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 102480461,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "206b2aeb81b29463968b8deb1efce51941f18208",
            "isKey": false,
            "numCitedBy": 290,
            "numCiting": 42,
            "paperAbstract": {
                "fragments": [],
                "text": "Scene text detection methods based on neural networks have emerged recently and have shown promising results. Previous methods trained with rigid word-level bounding boxes exhibit limitations in representing the text region in an arbitrary shape. In this paper, we propose a new scene text detection method to effectively detect text area by exploring each character and affinity between characters. To overcome the lack of individual character level annotations, our proposed framework exploits both the given character-level annotations for synthetic images and the estimated character-level ground-truths for real images acquired by the learned interim model. In order to estimate affinity between characters, the network is trained with the newly proposed representation for affinity. Extensive experiments on six benchmarks, including the TotalText and CTW-1500 datasets which contain highly curved texts in natural images, demonstrate that our character-level text detection significantly outperforms the state-of-the-art detectors. According to the results, our proposed method guarantees high flexibility in detecting complicated scene text images, such as arbitrarily-oriented, curved, or deformed texts."
            },
            "slug": "Character-Region-Awareness-for-Text-Detection-Baek-Lee",
            "title": {
                "fragments": [],
                "text": "Character Region Awareness for Text Detection"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "A new scene text detection method to effectively detect text area by exploring each character and affinity between characters by exploiting both the given character- level annotations for synthetic images and the estimated character-level ground-truths for real images acquired by the learned interim model."
            },
            "venue": {
                "fragments": [],
                "text": "2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)"
            },
            "year": 2019
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 3,
            "methodology": 3
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 6,
        "totalPages": 1
    },
    "page_url": "https://www.semanticscholar.org/paper/CORD:-A-Consolidated-Receipt-Dataset-for-Post-OCR-Park-Shin/c69942bf1b4f75e53cb62d0c5126c1cb4a5aa7bc?sort=total-citations"
}