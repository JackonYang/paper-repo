{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1783941"
                        ],
                        "name": "Y. Altun",
                        "slug": "Y.-Altun",
                        "structuredName": {
                            "firstName": "Yasemin",
                            "lastName": "Altun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Altun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143936663"
                        ],
                        "name": "Thomas Hofmann",
                        "slug": "Thomas-Hofmann",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Hofmann",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thomas Hofmann"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152465203"
                        ],
                        "name": "Mark Johnson",
                        "slug": "Mark-Johnson",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Johnson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mark Johnson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 295,
                                "start": 277
                            }
                        ],
                        "text": "\u2026a recent line of research that includes Maximum Entropy Markov Models (MEMMs) (McCallum et al., 2000; Punyakanok & Roth, 2001), Conditional Random Fields (CRFs) (Lafferty et al., 2001), perceptron re-ranking (Collins, 2002; Collins & Duffy, 2002) and label sequence boosting (Altun et al., 2003)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 118,
                                "start": 98
                            }
                        ],
                        "text": ", 2001), perceptron re-ranking (Collins, 2002; Collins & Duffy, 2002) and label sequence boosting (Altun et al., 2003)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14546839,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "61a559a5ab77b449758795c86c6ff8a42b389987",
            "isKey": false,
            "numCitedBy": 59,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper investigates a boosting approach to discriminative learning of label sequences based on a sequence rank loss function. The proposed method combines many of the advantages of boosting schemes with the efficiency of dynamic programming methods and is attractive both, conceptually and computationally. In addition, we also discuss alternative approaches based on the Hamming loss for label sequences. The sequence boosting algorithm offers an interesting alternative to methods based on HMMs and the more recently proposed Conditional Random Fields. Applications areas for the presented technique range from natural language processing and information extraction to computational biology. We include experiments on named entity recognition and part-of-speech tagging which demonstrate the validity and competitiveness of our approach."
            },
            "slug": "Discriminative-Learning-for-Label-Sequences-via-Altun-Hofmann",
            "title": {
                "fragments": [],
                "text": "Discriminative Learning for Label Sequences via Boosting"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "The proposed sequence boosting algorithm offers an interesting alternative to methods based on HMMs and the more recently proposed Conditional Random Fields and is attractive both, conceptually and computationally."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143753639"
                        ],
                        "name": "A. McCallum",
                        "slug": "A.-McCallum",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "McCallum",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. McCallum"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1758106"
                        ],
                        "name": "Dayne Freitag",
                        "slug": "Dayne-Freitag",
                        "structuredName": {
                            "firstName": "Dayne",
                            "lastName": "Freitag",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dayne Freitag"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145366908"
                        ],
                        "name": "Fernando C Pereira",
                        "slug": "Fernando-C-Pereira",
                        "structuredName": {
                            "firstName": "Fernando",
                            "lastName": "Pereira",
                            "middleNames": [
                                "C"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Fernando C Pereira"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 145,
                                "start": 97
                            }
                        ],
                        "text": "Our work continues a recent line of research that includes Maximum Entropy Markov Models (MEMMs) (McCallum et al., 2000; Punyakanok & Roth, 2001), Conditional Random Fields (CRFs) (Lafferty et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 119,
                                "start": 98
                            }
                        ],
                        "text": "Our work continues a recent line of research that includes Maximum Entropy Markov Models (MEMMs) (McCallum et al., 2000; Punyakanok & Roth, 2001), Conditional Random Fields (CRFs) (Lafferty et al., 2001), perceptron re-ranking (Collins, 2002; Collins & Duffy, 2002) and label sequence boosting\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 775373,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bece46ed303f8eaef2affae2cba4e0aef51fe636",
            "isKey": false,
            "numCitedBy": 1551,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "Hidden Markov models (HMMs) are a powerful probabilistic tool for modeling sequential data, and have been applied with success to many text-related tasks, such as part-of-speech tagging, text segmentation and information extraction. In these cases, the observations are usually modeled as multinomial distributions over a discrete vocabulary, and the HMM parameters are set to maximize the likelihood of the observations. This paper presents a new Markovian sequence model, closely related to HMMs, that allows observations to be represented as arbitrary overlapping features (such as word, capitalization, formatting, part-of-speech), and defines the conditional probability of state sequences given observation sequences. It does this by using the maximum entropy framework to fit a set of exponential models that represent the probability of a state given an observation and the previous state. We present positive experimental results on the segmentation of FAQ\u2019s."
            },
            "slug": "Maximum-Entropy-Markov-Models-for-Information-and-McCallum-Freitag",
            "title": {
                "fragments": [],
                "text": "Maximum Entropy Markov Models for Information Extraction and Segmentation"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "A new Markovian sequence model is presented that allows observations to be represented as arbitrary overlapping features (such as word, capitalization, formatting, part-of-speech), and defines the conditional probability of state sequences given observation sequences."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1781874"
                        ],
                        "name": "E. Osuna",
                        "slug": "E.-Osuna",
                        "structuredName": {
                            "firstName": "Edgar",
                            "lastName": "Osuna",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Osuna"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1771659"
                        ],
                        "name": "R. Freund",
                        "slug": "R.-Freund",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Freund",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Freund"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1804489"
                        ],
                        "name": "F. Girosi",
                        "slug": "F.-Girosi",
                        "structuredName": {
                            "firstName": "Federico",
                            "lastName": "Girosi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Girosi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 52,
                                "start": 32
                            }
                        ],
                        "text": "Adopting the proof presented in (Osuna et al., 1997), we prove the following result: Proposition 2."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 51,
                                "start": 33
                            }
                        ],
                        "text": "Adopting the proof presented in (Osuna et al., 1997), we prove the following result:\nProposition 2."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                }
            ],
            "corpusId": 2845602,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9008cdacbdcff8a218a6928e94fe7c6dfc237b24",
            "isKey": false,
            "numCitedBy": 2841,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "We investigate the application of Support Vector Machines (SVMs) in computer vision. SVM is a learning technique developed by V. Vapnik and his team (AT&T Bell Labs., 1985) that can be seen as a new method for training polynomial, neural network, or Radial Basis Functions classifiers. The decision surfaces are found by solving a linearly constrained quadratic programming problem. This optimization problem is challenging because the quadratic form is completely dense and the memory requirements grow with the square of the number of data points. We present a decomposition algorithm that guarantees global optimality, and can be used to train SVM's over very large data sets. The main idea behind the decomposition is the iterative solution of sub-problems and the evaluation of optimality conditions which are used both to generate improved iterative values, and also establish the stopping criteria for the algorithm. We present experimental results of our implementation of SVM, and demonstrate the feasibility of our approach on a face detection problem that involves a data set of 50,000 data points."
            },
            "slug": "Training-support-vector-machines:-an-application-to-Osuna-Freund",
            "title": {
                "fragments": [],
                "text": "Training support vector machines: an application to face detection"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "A decomposition algorithm that guarantees global optimality, and can be used to train SVM's over very large data sets is presented, and the feasibility of the approach on a face detection problem that involves a data set of 50,000 data points is demonstrated."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143707112"
                        ],
                        "name": "M. Collins",
                        "slug": "M.-Collins",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Collins",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Collins"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 229,
                                "start": 215
                            }
                        ],
                        "text": "As expected, CRFs perform better than the HM-Perceptron algorithm (HM-PC), since CRFs use the derivative of the logloss function at every step, whereas the Perceptron algorithm uses only an approximation of it (cf. Collins (2002))."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 223,
                                "start": 210
                            }
                        ],
                        "text": "\u2026a recent line of research that includes Maximum Entropy Markov Models (MEMMs) (McCallum et al., 2000; Punyakanok & Roth, 2001), Conditional Random Fields (CRFs) (Lafferty et al., 2001), perceptron re-ranking (Collins, 2002; Collins & Duffy, 2002) and label sequence boosting (Altun et al., 2003)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 216,
                                "start": 202
                            }
                        ],
                        "text": "\u2026\u03b1j(y\u0304)\u3008\u03a6(xi,y),\u03a6(xj , y\u0304)\u3009 5: if yi 6= y\u0302i then 6: \u03b1i(yi)\u2190 \u03b1i(yi) + 1 7: \u03b1i(y\u0302i)\u2190 \u03b1i(y\u0302i)\u2212 1 8: end if 9: end for\n10: until no more errors\nIn order to prove the convergence of this algorithm, it suffices to apply Theorem 1 in Collins (2002) which is a simple generalization of Novikoff\u2019s theorem."
                    },
                    "intents": []
                }
            ],
            "corpusId": 10888973,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5a7958b418bceb48a315384568091ab1898b1640",
            "isKey": false,
            "numCitedBy": 2272,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe new algorithms for training tagging models, as an alternative to maximum-entropy models or conditional random fields (CRFs). The algorithms rely on Viterbi decoding of training examples, combined with simple additive updates. We describe theory justifying the algorithms through a modification of the proof of convergence of the perceptron algorithm for classification problems. We give experimental results on part-of-speech tagging and base noun phrase chunking, in both cases showing improvements over results for a maximum-entropy tagger."
            },
            "slug": "Discriminative-Training-Methods-for-Hidden-Markov-Collins",
            "title": {
                "fragments": [],
                "text": "Discriminative Training Methods for Hidden Markov Models: Theory and Experiments with Perceptron Algorithms"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "Experimental results on part-of-speech tagging and base noun phrase chunking are given, in both cases showing improvements over results for a maximum-entropy tagger."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1783941"
                        ],
                        "name": "Y. Altun",
                        "slug": "Y.-Altun",
                        "structuredName": {
                            "firstName": "Yasemin",
                            "lastName": "Altun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Altun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143936663"
                        ],
                        "name": "Thomas Hofmann",
                        "slug": "Thomas-Hofmann",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Hofmann",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thomas Hofmann"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 12006035,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a8caaedda7e0372cb598b39a80f0ff485d432d27",
            "isKey": false,
            "numCitedBy": 33,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "Label sequence learning is the problem of inferring a state sequence from an observation sequence, where the state sequence may encode a labeling, annotation or segmentation of the sequence. In this paper we give an overview of discriminative methods developed for this problem. Special emphasis is put on large margin methods by generalizing multiclass Support Vector Machines and AdaBoost to the case of label sequences. An experimental evaluation demonstrates the advantages over classical approaches like Hidden Markov Models and the competitiveness with methods like Conditional Random Fields."
            },
            "slug": "Large-margin-methods-for-label-sequence-learning-Altun-Hofmann",
            "title": {
                "fragments": [],
                "text": "Large margin methods for label sequence learning"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "An overview of discriminative methods developed for label sequence learning by generalizing multiclass Support Vector Machines and AdaBoost to the case of label sequences and demonstrating the advantages over classical approaches and the competitiveness with methods like Conditional Random Fields."
            },
            "venue": {
                "fragments": [],
                "text": "INTERSPEECH"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1739581"
                        ],
                        "name": "J. Lafferty",
                        "slug": "J.-Lafferty",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Lafferty",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Lafferty"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143753639"
                        ],
                        "name": "A. McCallum",
                        "slug": "A.-McCallum",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "McCallum",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. McCallum"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "113414328"
                        ],
                        "name": "Fernando Pereira",
                        "slug": "Fernando-Pereira",
                        "structuredName": {
                            "firstName": "Fernando",
                            "lastName": "Pereira",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Fernando Pereira"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 184,
                                "start": 163
                            }
                        ],
                        "text": "\u2026a recent line of research that includes Maximum Entropy Markov Models (MEMMs) (McCallum et al., 2000; Punyakanok & Roth, 2001), Conditional Random Fields (CRFs) (Lafferty et al., 2001), perceptron re-ranking (Collins, 2002; Collins & Duffy, 2002) and label sequence boosting (Altun et al., 2003)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 219683473,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f4ba954b0412773d047dc41231c733de0c1f4926",
            "isKey": false,
            "numCitedBy": 13411,
            "numCiting": 75,
            "paperAbstract": {
                "fragments": [],
                "text": "We present conditional random fields , a framework for building probabilistic models to segment and label sequence data. Conditional random fields offer several advantages over hidden Markov models and stochastic grammars for such tasks, including the ability to relax strong independence assumptions made in those models. Conditional random fields also avoid a fundamental limitation of maximum entropy Markov models (MEMMs) and other discriminative Markov models based on directed graphical models, which can be biased towards states with few successor states. We present iterative parameter estimation algorithms for conditional random fields and compare the performance of the resulting models to HMMs and MEMMs on synthetic and natural-language data."
            },
            "slug": "Conditional-Random-Fields:-Probabilistic-Models-for-Lafferty-McCallum",
            "title": {
                "fragments": [],
                "text": "Conditional Random Fields: Probabilistic Models for Segmenting and Labeling Sequence Data"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This work presents iterative parameter estimation algorithms for conditional random fields and compares the performance of the resulting models to HMMs and MEMMs on synthetic and natural-language data."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145183709"
                        ],
                        "name": "J. Weston",
                        "slug": "J.-Weston",
                        "structuredName": {
                            "firstName": "Jason",
                            "lastName": "Weston",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Weston"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1730609"
                        ],
                        "name": "O. Chapelle",
                        "slug": "O.-Chapelle",
                        "structuredName": {
                            "firstName": "Olivier",
                            "lastName": "Chapelle",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Chapelle"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1766703"
                        ],
                        "name": "A. Elisseeff",
                        "slug": "A.-Elisseeff",
                        "structuredName": {
                            "firstName": "Andr\u00e9",
                            "lastName": "Elisseeff",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Elisseeff"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1707625"
                        ],
                        "name": "B. Sch\u00f6lkopf",
                        "slug": "B.-Sch\u00f6lkopf",
                        "structuredName": {
                            "firstName": "Bernhard",
                            "lastName": "Sch\u00f6lkopf",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Sch\u00f6lkopf"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50560492"
                        ],
                        "name": "V. Vapnik",
                        "slug": "V.-Vapnik",
                        "structuredName": {
                            "firstName": "Vladimir",
                            "lastName": "Vapnik",
                            "middleNames": [
                                "Naumovich"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Vapnik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 114,
                                "start": 94
                            }
                        ],
                        "text": "As will become clear later, the main design goal in defining \u03a6 is to make sure that f can be computed from F efficiently, i.e. using a Viterbi-like decoding algorithm."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 199,
                                "start": 179
                            }
                        ],
                        "text": "These features in turn may interact in non-trivial ways with certain properties of the input patterns, which is the main difference between our approach and the work presented in Weston et al. (2003)."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                }
            ],
            "corpusId": 813046,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "359300ac4a78687d60e18681925709b404b8fa54",
            "isKey": false,
            "numCitedBy": 183,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "We consider the learning problem of finding a dependency between a general class of objects and another, possibly different, general class of objects. The objects can be for example: vectors, images, strings, trees or graphs. Such a task is made possible by employing similarity measures in both input and output spaces using kernel functions, thus embedding the objects into vector spaces. We experimentally validate our approach on several tasks: mapping strings to strings, pattern recognition, and reconstruction from partial images."
            },
            "slug": "Kernel-Dependency-Estimation-Weston-Chapelle",
            "title": {
                "fragments": [],
                "text": "Kernel Dependency Estimation"
            },
            "tldr": {
                "abstractSimilarityScore": 73,
                "text": "This work considers the learning problem of finding a dependency between a general class of objects and another, possibly different, generalclass of objects, made possible by employing similarity measures in both input and output spaces using kernel functions, thus embedding the objects into vector spaces."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2474158"
                        ],
                        "name": "Vasin Punyakanok",
                        "slug": "Vasin-Punyakanok",
                        "structuredName": {
                            "firstName": "Vasin",
                            "lastName": "Punyakanok",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Vasin Punyakanok"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144590225"
                        ],
                        "name": "D. Roth",
                        "slug": "D.-Roth",
                        "structuredName": {
                            "firstName": "Dan",
                            "lastName": "Roth",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Roth"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 144,
                                "start": 121
                            }
                        ],
                        "text": "Our work continues a recent line of research that includes Maximum Entropy Markov Models (MEMMs) (McCallum et al., 2000; Punyakanok & Roth, 2001), Conditional Random Fields (CRFs) (Lafferty et al., 2001), perceptron re-ranking (Collins, 2002; Collins & Duffy, 2002) and label sequence boosting\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14509422,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3fab92869cfab684b3ffb1c16a771e9c3b774acd",
            "isKey": false,
            "numCitedBy": 220,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": "We study the problem of combining the outcomes of several different classifiers in a way that provides a coherent inference that satisfies some constraints. In particular, we develop two general approaches for an important subproblem - identifying phrase structure. The first is a Markovian approach that extends standard HMMs to allow the use of a rich observation structure and of general classifiers to model state-observation dependencies. The second is an extension of constraint satisfaction formalisms. We develop efficient combination algorithms under both models and study them experimentally in the context of shallow parsing."
            },
            "slug": "The-Use-of-Classifiers-in-Sequential-Inference-Punyakanok-Roth",
            "title": {
                "fragments": [],
                "text": "The Use of Classifiers in Sequential Inference"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A Markovian approach is developed that extends standard HMMs to allow the use of a rich observation structure and of general classifiers to model state-observation dependencies and an extension of constraint satisfaction formalisms are extended."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143707112"
                        ],
                        "name": "M. Collins",
                        "slug": "M.-Collins",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Collins",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Collins"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143857271"
                        ],
                        "name": "Nigel P. Duffy",
                        "slug": "Nigel-P.-Duffy",
                        "structuredName": {
                            "firstName": "Nigel",
                            "lastName": "Duffy",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nigel P. Duffy"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 246,
                                "start": 225
                            }
                        ],
                        "text": "\u2026a recent line of research that includes Maximum Entropy Markov Models (MEMMs) (McCallum et al., 2000; Punyakanok & Roth, 2001), Conditional Random Fields (CRFs) (Lafferty et al., 2001), perceptron re-ranking (Collins, 2002; Collins & Duffy, 2002) and label sequence boosting (Altun et al., 2003)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Our work continues a recent line of research that includes Maximum Entropy Markov Models (MEMMs) (McCallum et al., 2000; Punyakanok & Roth, 2001), Conditional Random Fields (CRFs) (Lafierty et al., 2001), perceptron re-ranking (Collins, 2002;  Collins & Dufiy, 2002 ) and label sequence boosting (Altun et al., 2003)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "We will flrst focus on an on-line learning approach to label sequence learning, which generalizes perceptron learning and was flrst proposed in the context of natural language processing in  Collins and Dufiy (2002) ."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 214,
                                "start": 190
                            }
                        ],
                        "text": "We will first focus on an on-line learning approach to label sequence learning, which generalizes perceptron learning and was first proposed in the context of natural language processing in Collins and Duffy (2002)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 396794,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e6c7adc28e20d361d5c35aa9808094b10f6a34d1",
            "isKey": true,
            "numCitedBy": 932,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe the application of kernel methods to Natural Language Processing (NLP) problems. In many NLP tasks the objects being modeled are strings, trees, graphs or other discrete structures which require some mechanism to convert them into feature vectors. We describe kernels for various natural language structures, allowing rich, high dimensional representations of these structures. We show how a kernel over trees can be applied to parsing using the voted perceptron algorithm, and we give experimental results on the ATIS corpus of parse trees."
            },
            "slug": "Convolution-Kernels-for-Natural-Language-Collins-Duffy",
            "title": {
                "fragments": [],
                "text": "Convolution Kernels for Natural Language"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "It is shown how a kernel over trees can be applied to parsing using the voted perceptron algorithm, and experimental results on the ATIS corpus of parse trees are given."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152465203"
                        ],
                        "name": "Mark Johnson",
                        "slug": "Mark-Johnson",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Johnson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mark Johnson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3194361"
                        ],
                        "name": "S. Geman",
                        "slug": "S.-Geman",
                        "structuredName": {
                            "firstName": "Stuart",
                            "lastName": "Geman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Geman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47428006"
                        ],
                        "name": "S. Canon",
                        "slug": "S.-Canon",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Canon",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Canon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3140471"
                        ],
                        "name": "Zhiyi Chi",
                        "slug": "Zhiyi-Chi",
                        "structuredName": {
                            "firstName": "Zhiyi",
                            "lastName": "Chi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zhiyi Chi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3289329"
                        ],
                        "name": "S. Riezler",
                        "slug": "S.-Riezler",
                        "structuredName": {
                            "firstName": "Stefan",
                            "lastName": "Riezler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Riezler"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Since optimizing log-loss functions (as is done in CRFs) may result in overfltting, especially with noisy data, we have followed the suggestion of ( Johnson et al., 1999 ) and used a regularized cost function."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 168,
                                "start": 148
                            }
                        ],
                        "text": "Since optimizing log-loss functions (as is done in CRFs) may result in overfitting, especially with noisy data, we have followed the suggestion of (Johnson et al., 1999) and used a regularized cost function."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 17435621,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "463dbd690d912b23d29b7581fb6b253b36f50394",
            "isKey": false,
            "numCitedBy": 233,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "Log-linear models provide a statistically sound framework for Stochastic \"Unification-Based\" Grammars (SUBGs) and stochastic versions of other kinds of grammars. We describe two computationally-tractable ways of estimating the parameters of such grammars from a training corpus of syntactic analyses, and apply these to estimate a stochastic version of Lexical-Functional Grammar."
            },
            "slug": "Estimators-for-Stochastic-\"Unification-Based\"-Johnson-Geman",
            "title": {
                "fragments": [],
                "text": "Estimators for Stochastic \"Unification-Based\" Grammars"
            },
            "tldr": {
                "abstractSimilarityScore": 51,
                "text": "Two computationally-tractable ways of estimating the parameters of Stochastic \"Unification-Based\" Grammars from a training corpus of syntactic analyses are described and applied to estimate a stochastic version of Lexical-Functional Grammar."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "52626911"
                        ],
                        "name": "T. Minka",
                        "slug": "T.-Minka",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Minka",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Minka"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "The CRFs have been optimized using a conjugate gradient method which has reportedly outperformed other techniques for minimizing the CRF loss function ( Minka, 2001 )."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 118158295,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f90e71df8f88a278b22920e2e976947e637efad8",
            "isKey": false,
            "numCitedBy": 107,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Algorithms-for-maximum-likelihood-logistic-Minka",
            "title": {
                "fragments": [],
                "text": "Algorithms for maximum-likelihood logistic regression"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2003
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 168,
                                "start": 148
                            }
                        ],
                        "text": "Since optimizing log-loss functions (as is done in CRFs) may result in overfitting, especially with noisy data, we have followed the suggestion of (Johnson et al., 1999) and used a regularized cost function."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Estimators for stochastic unificationbased grammars"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Thirty-Seventh Annual Meeting of the Association for Computational Linguistics (pp. 535\u2013541)"
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 210,
                                "start": 190
                            }
                        ],
                        "text": "Before focusing on the label learning problem, let us outline a more general framework for learning mappings to discrete output spaces of which the proposed HM-SVM method is a special case (Hofmann et al., 2002)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Learning over structured output spaces via joint kernel functions"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Sixth Kernel Workshop"
            },
            "year": 2002
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "criminative learning for label sequences via boost"
            },
            "venue": {
                "fragments": [],
                "text": "Advances in Neural Information Processing Systems 15 ."
            },
            "year": 2003
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The n-best algorithm: An efficient and exact procedure for finding the n most likely hypotheses"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the IEEE International Conference on Acoustics, Speech and Signal Processing (pp. 81\u201384)"
            },
            "year": 1990
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 4,
            "methodology": 9,
            "result": 2
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 15,
        "totalPages": 2
    },
    "page_url": "https://www.semanticscholar.org/paper/Hidden-Markov-Support-Vector-Machines-Altun-Tsochantaridis/5fe5ed2a3b50becdbbcd17e7733653d5ef6ac398?sort=total-citations"
}