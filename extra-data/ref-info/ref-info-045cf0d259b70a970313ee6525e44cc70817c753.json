{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3177109"
                        ],
                        "name": "Y. Kusachi",
                        "slug": "Y.-Kusachi",
                        "structuredName": {
                            "firstName": "Yoshinori",
                            "lastName": "Kusachi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Kusachi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2146982808"
                        ],
                        "name": "Akira Suzuki",
                        "slug": "Akira-Suzuki",
                        "structuredName": {
                            "firstName": "Akira",
                            "lastName": "Suzuki",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Akira Suzuki"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2054172965"
                        ],
                        "name": "N. Ito",
                        "slug": "N.-Ito",
                        "structuredName": {
                            "firstName": "Naoki",
                            "lastName": "Ito",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Ito"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1934433"
                        ],
                        "name": "K. Arakawa",
                        "slug": "K.-Arakawa",
                        "structuredName": {
                            "firstName": "Kenichi",
                            "lastName": "Arakawa",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Arakawa"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 101,
                                "start": 98
                            }
                        ],
                        "text": "Another approach is exhaustive search for deformed characters without character segmentation [6], [7]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 33756328,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f5186838748a10808188dfa232c33fb056a8d628",
            "isKey": false,
            "numCitedBy": 15,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "With the goal of indexing scene images, we propose a novel recognition method for Kanji characters captured in scene images. Our method scans multi-resolution images and classifies clipped regions with recognition dictionaries generated by learning a large amount of partial patterns of characters with large geometric transformation. The problem of scanning time, which tends to be unpractically long, is solved by using multi-compression coarse-to-fine scanning, and by detecting peak points after coarse searching. Despite the wrong results generated in the background, our method well supports image retrieval since it uses the regular spacing of characters. Experimental results show that this recognition method recognized characters at the rate of 82%. Precision was 84% and recall was 64% for image retrieval."
            },
            "slug": "Kanji-recognition-in-scene-images-without-detection-Kusachi-Suzuki",
            "title": {
                "fragments": [],
                "text": "Kanji recognition in scene images without detection of text fields - robust against variation of viewpoint, contrast, and background texture"
            },
            "tldr": {
                "abstractSimilarityScore": 62,
                "text": "This method scans multi-resolution images and classifies clipped regions with recognition dictionaries generated by learning a large amount of partial patterns of characters with large geometric transformation by using multi-compression coarse-to-fine scanning and detecting peak points after coarse searching."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 17th International Conference on Pattern Recognition, 2004. ICPR 2004."
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2114172383"
                        ],
                        "name": "Qi Zheng",
                        "slug": "Qi-Zheng",
                        "structuredName": {
                            "firstName": "Qi",
                            "lastName": "Zheng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Qi Zheng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "72387933"
                        ],
                        "name": "Kai Chen",
                        "slug": "Kai-Chen",
                        "structuredName": {
                            "firstName": "Kai",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kai Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46433090"
                        ],
                        "name": "Yi Zhou",
                        "slug": "Yi-Zhou",
                        "structuredName": {
                            "firstName": "Yi",
                            "lastName": "Zhou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yi Zhou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1882300"
                        ],
                        "name": "Congcong Gu",
                        "slug": "Congcong-Gu",
                        "structuredName": {
                            "firstName": "Congcong",
                            "lastName": "Gu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Congcong Gu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145676478"
                        ],
                        "name": "Haibing Guan",
                        "slug": "Haibing-Guan",
                        "structuredName": {
                            "firstName": "Haibing",
                            "lastName": "Guan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Haibing Guan"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 134,
                                "start": 130
                            }
                        ],
                        "text": "Only method to handle multiple characters in an image employs a simple sliding window strategy to determine each character region [11]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 72,
                                "start": 68
                            }
                        ],
                        "text": "That is use of local features such as SIFT and SURF [8], [9], [10], [11]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 100,
                                "start": 96
                            }
                        ],
                        "text": "For the problem, a method using sliding window to determine character regions has been proposed [11]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 41534100,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2bba21702743cac9460b03c5f227806ae3781b35",
            "isKey": false,
            "numCitedBy": 31,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe an approach using local features to resolve problems in text localization and recognition in complex scenes. Low image quality, complex background and variations of text make these problems challenging. Our approach includes the following stages: (1) Template images are generated automatically; (2) SIFT features are extracted and matched to template images; (3) Multiple single-character-areas are located using segmentation algorithm based upon multiple-size sliding subwindows; (4) An voting and geometric verification algorithm is used to identify final results. This framework thus is essentially simple by skipping many steps, such as normalization, binarization and OCR, which are required in previous methods. Moreover, this framework is robust as only SIFT feature is used. We evaluated our method using 200,000+ images in 3 scripts (Chinese, Japanese and Korean). We obtained average single-character success rate of 77.3% (highest 94.1%), average multiplecharacter success rate of 63.9% (highest 89.6%)."
            },
            "slug": "Text-Localization-and-Recognition-in-Complex-Scenes-Zheng-Chen",
            "title": {
                "fragments": [],
                "text": "Text Localization and Recognition in Complex Scenes Using Local Features"
            },
            "tldr": {
                "abstractSimilarityScore": 66,
                "text": "An approach using local features to resolve problems in text localization and recognition in complex scenes by skipping many steps, such as normalization, binarization and OCR, which are required in previous methods is described."
            },
            "venue": {
                "fragments": [],
                "text": "ACCV"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144228782"
                        ],
                        "name": "T. Campos",
                        "slug": "T.-Campos",
                        "structuredName": {
                            "firstName": "Te\u00f3filo",
                            "lastName": "Campos",
                            "middleNames": [
                                "Em\u00eddio",
                                "de"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Campos"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "6516879"
                        ],
                        "name": "Bodla Rakesh Babu",
                        "slug": "Bodla-Rakesh-Babu",
                        "structuredName": {
                            "firstName": "Bodla",
                            "lastName": "Babu",
                            "middleNames": [
                                "Rakesh"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bodla Rakesh Babu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145859952"
                        ],
                        "name": "M. Varma",
                        "slug": "M.-Varma",
                        "structuredName": {
                            "firstName": "Manik",
                            "lastName": "Varma",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Varma"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 55,
                                "start": 52
                            }
                        ],
                        "text": "That is use of local features such as SIFT and SURF [8], [9], [10], [11]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 4826173,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "dbbd5fdc09349bbfdee7aa7365a9d37716852b32",
            "isKey": false,
            "numCitedBy": 507,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper tackles the problem of recognizing characters in images of natural scenes. In particular, we focus on recognizing characters in situations that would traditionally not be handled well by OCR techniques. We present an annotated database of images containing English and Kannada characters. The database comprises of images of street scenes taken in Bangalore, India using a standard camera. The problem is addressed in an object cateogorization framework based on a bag-of-visual-words representation. We assess the performance of various features based on nearest neighbour and SVM classification. It is demonstrated that the performance of the proposed method, using as few as 15 training images, can be far superior to that of commercial OCR systems. Furthermore, the method can benefit from synthetically generated training data obviating the need for expensive data collection and annotation."
            },
            "slug": "Character-Recognition-in-Natural-Images-Campos-Babu",
            "title": {
                "fragments": [],
                "text": "Character Recognition in Natural Images"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "It is demonstrated that the performance of the proposed method can be far superior to that of commercial OCR systems, and can benefit from synthetically generated training data obviating the need for expensive data collection and annotation."
            },
            "venue": {
                "fragments": [],
                "text": "VISAPP"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2112559624"
                        ],
                        "name": "Tong Wu",
                        "slug": "Tong-Wu",
                        "structuredName": {
                            "firstName": "Tong",
                            "lastName": "Wu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tong Wu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2744060"
                        ],
                        "name": "Kaiyue Qi",
                        "slug": "Kaiyue-Qi",
                        "structuredName": {
                            "firstName": "Kaiyue",
                            "lastName": "Qi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kaiyue Qi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2114172383"
                        ],
                        "name": "Qi Zheng",
                        "slug": "Qi-Zheng",
                        "structuredName": {
                            "firstName": "Qi",
                            "lastName": "Zheng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Qi Zheng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "72387933"
                        ],
                        "name": "Kai Chen",
                        "slug": "Kai-Chen",
                        "structuredName": {
                            "firstName": "Kai",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kai Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108301843"
                        ],
                        "name": "Jianbo Chen",
                        "slug": "Jianbo-Chen",
                        "structuredName": {
                            "firstName": "Jianbo",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jianbo Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145676478"
                        ],
                        "name": "Haibing Guan",
                        "slug": "Haibing-Guan",
                        "structuredName": {
                            "firstName": "Haibing",
                            "lastName": "Guan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Haibing Guan"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 60,
                                "start": 57
                            }
                        ],
                        "text": "That is use of local features such as SIFT and SURF [8], [9], [10], [11]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 16856015,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4f75e4c3403e6f53e226d6b69e8dc1c34b7223d9",
            "isKey": false,
            "numCitedBy": 8,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "The reference [1] presents a novel approach for Chinese character recognition. Based on it, we know that we can treat character recognition as an image matching problem. Compared with traditional OCR, the new approach for character recognition uniquely uses local invariant descriptors as a new feature extraction method. In this paper, we present a new local descriptor which combines the scale-invariant feature descriptor with contrast distributions of a local region to produce highly efficient feature representation. We extensively evaluated the effectiveness of the new approach with various datasets acquired under varying circumstances. Our experiments demonstrate that our two-component descriptor can represent local region with more information and perform better than SIFT."
            },
            "slug": "An-Improved-Descriptor-for-Chinese-Character-Wu-Qi",
            "title": {
                "fragments": [],
                "text": "An Improved Descriptor for Chinese Character Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "A new local descriptor which combines the scale-invariant feature descriptor with contrast distributions of a local region to produce highly efficient feature representation to treat character recognition as an image matching problem."
            },
            "venue": {
                "fragments": [],
                "text": "2009 Third International Symposium on Intelligent Information Technology Application"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1809705"
                        ],
                        "name": "S. Uchida",
                        "slug": "S.-Uchida",
                        "structuredName": {
                            "firstName": "Seiichi",
                            "lastName": "Uchida",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Uchida"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1743758"
                        ],
                        "name": "M. Liwicki",
                        "slug": "M.-Liwicki",
                        "structuredName": {
                            "firstName": "Marcus",
                            "lastName": "Liwicki",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Liwicki"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 66,
                                "start": 62
                            }
                        ],
                        "text": "That is use of local features such as SIFT and SURF [8], [9], [10], [11]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 3049421,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4442a78886d8fd96d6904e7b28afc9222da5ea6c",
            "isKey": false,
            "numCitedBy": 21,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "In the part-based recognition method proposed in this paper, a handwritten character image is represented by just a set of local parts. Then, each local part of the input pattern is recognized by a nearest-neighbor classifier. Finally, the category of the input pattern is determined by aggregating the local recognition results. This approach is opposed to conventional character recognition approaches which try to benefit from the global structure information as much as possible. Despite a pessimistic expectation, we have reached recognition rates much higher than 90% for a digit recognition task. In this paper we provide a detailed analysis in order to understand the results and find the merits of the local approach."
            },
            "slug": "Part-Based-Recognition-of-Handwritten-Characters-Uchida-Liwicki",
            "title": {
                "fragments": [],
                "text": "Part-Based Recognition of Handwritten Characters"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This paper provides a detailed analysis in order to understand the results and find the merits of the local approach to part-based character recognition."
            },
            "venue": {
                "fragments": [],
                "text": "2010 12th International Conference on Frontiers in Handwriting Recognition"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46772547"
                        ],
                        "name": "Xilin Chen",
                        "slug": "Xilin-Chen",
                        "structuredName": {
                            "firstName": "Xilin",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xilin Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2118579343"
                        ],
                        "name": "Jie Yang",
                        "slug": "Jie-Yang",
                        "structuredName": {
                            "firstName": "Jie",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jie Yang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2155703534"
                        ],
                        "name": "Jing Zhang",
                        "slug": "Jing-Zhang",
                        "structuredName": {
                            "firstName": "Jing",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jing Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1724972"
                        ],
                        "name": "A. Waibel",
                        "slug": "A.-Waibel",
                        "structuredName": {
                            "firstName": "Alexander",
                            "lastName": "Waibel",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Waibel"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 113,
                                "start": 110
                            }
                        ],
                        "text": "One approach is the orthodox one, that is, segmenting characters from a scene image and recognizing them [2], [3], [4], [5]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6109448,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5295b6770ebbbc27a4651ed44b4b7e184d884f8e",
            "isKey": false,
            "numCitedBy": 330,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we present an approach to automatic detection and recognition of signs from natural scenes, and its application to a sign translation task. The proposed approach embeds multiresolution and multiscale edge detection, adaptive searching, color analysis, and affine rectification in a hierarchical framework for sign detection, with different emphases at each phase to handle the text in different sizes, orientations, color distributions and backgrounds. We use affine rectification to recover deformation of the text regions caused by an inappropriate camera view angle. The procedure can significantly improve text detection rate and optical character recognition (OCR) accuracy. Instead of using binary information for OCR, we extract features from an intensity image directly. We propose a local intensity normalization method to effectively handle lighting variations, followed by a Gabor transform to obtain local features, and finally a linear discriminant analysis (LDA) method for feature selection. We have applied the approach in developing a Chinese sign translation system, which can automatically detect and recognize Chinese signs as input from a camera, and translate the recognized text into English."
            },
            "slug": "Automatic-detection-and-recognition-of-signs-from-Chen-Yang",
            "title": {
                "fragments": [],
                "text": "Automatic detection and recognition of signs from natural scenes"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "This paper proposes a local intensity normalization method to effectively handle lighting variations, followed by a Gabor transform to obtain local features, and finally a linear discriminant analysis (LDA) method for feature selection."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Image Processing"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31693932"
                        ],
                        "name": "G. Myers",
                        "slug": "G.-Myers",
                        "structuredName": {
                            "firstName": "Gregory",
                            "lastName": "Myers",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Myers"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1764443"
                        ],
                        "name": "R. Bolles",
                        "slug": "R.-Bolles",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Bolles",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Bolles"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2624076"
                        ],
                        "name": "Q. Luong",
                        "slug": "Q.-Luong",
                        "structuredName": {
                            "firstName": "Quang-Tuan",
                            "lastName": "Luong",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Q. Luong"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48804780"
                        ],
                        "name": "James A. Herson",
                        "slug": "James-A.-Herson",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Herson",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "James A. Herson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3312922"
                        ],
                        "name": "H. Aradhye",
                        "slug": "H.-Aradhye",
                        "structuredName": {
                            "firstName": "Hrishikesh",
                            "lastName": "Aradhye",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Aradhye"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 108,
                                "start": 105
                            }
                        ],
                        "text": "One approach is the orthodox one, that is, segmenting characters from a scene image and recognizing them [2], [3], [4], [5]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 29394851,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4599b80a96821ed9276476edd17c6d70380f150c",
            "isKey": false,
            "numCitedBy": 63,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract.Real-world text on street signs, nameplates, etc. often lies in an oblique plane and hence cannot be recognized by traditional OCR systems due to perspective distortion. Furthermore, such text often comprises only one or two lines, preventing the use of existing perspective rectification methods that were primarily designed for images of document pages. We propose an approach that reliably rectifies and subsequently recognizes individual lines of text. Our system, which includes novel algorithms for extraction of text from real-world scenery, perspective rectification, and binarization, has been rigorously tested on still imagery as well as on MPEG-2 video clips in real time."
            },
            "slug": "Rectification-and-recognition-of-text-in-3-D-scenes-Myers-Bolles",
            "title": {
                "fragments": [],
                "text": "Rectification and recognition of text in 3-D scenes"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This work proposes an approach that reliably rectifies and subsequently recognizes individual lines of text in real-world text that has been rigorously tested on still imagery as well as on MPEG-2 video clips in real time."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Document Analysis and Recognition (IJDAR)"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2059876008"
                        ],
                        "name": "Matthijs C. Dorst",
                        "slug": "Matthijs-C.-Dorst",
                        "structuredName": {
                            "firstName": "Matthijs",
                            "lastName": "Dorst",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Matthijs C. Dorst"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 96,
                                "start": 92
                            }
                        ],
                        "text": "The sheets were captured at slant angles of 0 and 30 degrees with a digital camera and then SIFT features were extracted from the captured images."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 42,
                                "start": 38
                            }
                        ],
                        "text": "That is use of local features such as SIFT and SURF [8], [9], [10], [11]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "SIFT features extracted from a character image are shown in Fig."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 9,
                                "start": 5
                            }
                        ],
                        "text": "Then SIFT features were extracted from the images and their reverse color images to recognize white characters on darker background positioned in the left bottom of Fig."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 41,
                                "start": 37
                            }
                        ],
                        "text": "As the local feature, we employ SIFT [12]2."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 21,
                                "start": 17
                            }
                        ],
                        "text": "In total 353,900 SIFT features were stored in the database."
                    },
                    "intents": []
                }
            ],
            "corpusId": 130535382,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bcae70dce393c1796d4f15c7b8bbf0ed6f468be1",
            "isKey": true,
            "numCitedBy": 15907,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "The Scale-Invariant Feature Transform (or SIFT) algorithm is a highly robust method to extract and consequently match distinctive invariant features from images. These features can then be used to reliably match objects in diering images. The algorithm was rst proposed by Lowe [12] and further developed to increase performance resulting in the classic paper [13] that served as foundation for SIFT which has played an important role in robotic and machine vision in the past decade."
            },
            "slug": "Distinctive-Image-Features-from-Scale-Invariant-Dorst",
            "title": {
                "fragments": [],
                "text": "Distinctive Image Features from Scale-Invariant Keypoints"
            },
            "tldr": {
                "abstractSimilarityScore": 95,
                "text": "The Scale-Invariant Feature Transform (or SIFT) algorithm is a highly robust method to extract and consequently match distinctive invariant features from images that can then be used to reliably match objects in diering images."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35613969"
                        ],
                        "name": "M. Iwamura",
                        "slug": "M.-Iwamura",
                        "structuredName": {
                            "firstName": "M.",
                            "lastName": "Iwamura",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Iwamura"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38606738"
                        ],
                        "name": "Tomohiko Tsuji",
                        "slug": "Tomohiko-Tsuji",
                        "structuredName": {
                            "firstName": "Tomohiko",
                            "lastName": "Tsuji",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tomohiko Tsuji"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3277321"
                        ],
                        "name": "K. Kise",
                        "slug": "K.-Kise",
                        "structuredName": {
                            "firstName": "Koichi",
                            "lastName": "Kise",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Kise"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 150,
                                "start": 147
                            }
                        ],
                        "text": "This can be improved by employing better approximate nearest neighbor search method such as the one we used for camera-based character recognition [5]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 107,
                                "start": 104
                            }
                        ],
                        "text": "Future work includes (1) employing clustering technique to handle characters having similar parts as in [5], (2) employing different local features and combine them to improve recall, (3) improving computational efficiency including introduction of better approximate nearest neighbor search method such as the one we proposed [5], (4) storing handling multiple fonts in the database to improve performance on real use as in [5]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 123,
                                "start": 120
                            }
                        ],
                        "text": "One approach is the orthodox one, that is, segmenting characters from a scene image and recognizing them [2], [3], [4], [5]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 17702037,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "dd50d71bb3486d17ccea8c487c29d417eacada35",
            "isKey": false,
            "numCitedBy": 29,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper addresses how to quickly recognize a character pattern using a lot of case examples without learning. Here without learning means just finding the most similar example from the case examples, and pretend as if the OCR understands the definition of the character. This strategy is expected to work well in most cases with a large dataset, however, also expected to take a lot of time for finding the most similar example. In this paper, we show that a lot of case examples can be processed in a short time. As a testbed, we handle recognition problem of camera-captured printed characters. Using a database storing 100 fonts, the proposed method achieved 97.0% of recognition rate for images captured from the right angle and 95.8% for those from 45 deg. with 4.56ms of processing time, that is about 220 characters per second including every process."
            },
            "slug": "Memory-based-recognition-of-camera-captured-Iwamura-Tsuji",
            "title": {
                "fragments": [],
                "text": "Memory-based recognition of camera-captured characters"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "It is shown that a lot of case examples can be processed in a short time, and the proposed method achieved 97.0% of recognition rate for images captured from the right angle and 95.8% for those from 45 deg."
            },
            "venue": {
                "fragments": [],
                "text": "DAS '10"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2111818764"
                        ],
                        "name": "Linlin Li",
                        "slug": "Linlin-Li",
                        "structuredName": {
                            "firstName": "Linlin",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Linlin Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1679749"
                        ],
                        "name": "C. Tan",
                        "slug": "C.-Tan",
                        "structuredName": {
                            "firstName": "Chew",
                            "lastName": "Tan",
                            "middleNames": [
                                "Lim"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Tan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 118,
                                "start": 115
                            }
                        ],
                        "text": "One approach is the orthodox one, that is, segmenting characters from a scene image and recognizing them [2], [3], [4], [5]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 8257967,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "95e50d653974b4107a23c7de167fda6ae7a4a0a0",
            "isKey": false,
            "numCitedBy": 24,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "A common problem encountered in recognizing real-scene symbols is the perspective deformation. In this paper, a recognition method resistant to perspective deformation is proposed, based on Cross-Ratio Spectrum descriptor. This method shows good resistance to severe perspective deformation and good discriminating power to similar symbols."
            },
            "slug": "Recognizing-Planar-Symbols-with-Severe-Perspective-Li-Tan",
            "title": {
                "fragments": [],
                "text": "Recognizing Planar Symbols with Severe Perspective Deformation"
            },
            "tldr": {
                "abstractSimilarityScore": 55,
                "text": "A recognition method resistant to perspective deformation is proposed, based on Cross-Ratio Spectrum descriptor, which shows good resistance to severe perspectiveDeformation and good discriminating power to similar symbols."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35613969"
                        ],
                        "name": "M. Iwamura",
                        "slug": "M.-Iwamura",
                        "structuredName": {
                            "firstName": "M.",
                            "lastName": "Iwamura",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Iwamura"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38606738"
                        ],
                        "name": "Tomohiko Tsuji",
                        "slug": "Tomohiko-Tsuji",
                        "structuredName": {
                            "firstName": "Tomohiko",
                            "lastName": "Tsuji",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tomohiko Tsuji"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3277321"
                        ],
                        "name": "K. Kise",
                        "slug": "K.-Kise",
                        "structuredName": {
                            "firstName": "Koichi",
                            "lastName": "Kise",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Kise"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 324,
                                "start": 321
                            }
                        ],
                        "text": "Convincing applications include a camerabased translator which enables us to point with a web camera at text in a foreign language and obtain an instantaneous translation, and a voice-navigation service for visually disabled people which enables us to find useful keywords around the user with an omni-directional camera [1]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 55066721,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "21790ff8e9ed5be9ca8819dac162d7bb41c0d72f",
            "isKey": false,
            "numCitedBy": 2,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "Researchers have been pursuing the goal of effective character recognition for decades, and tools such as optical-characterreader (OCR) software have influenced everyday life. While flat-bed scanners have been able to capture character images with OCR for a long time, research into capturing characters with cameras is still ongoing. Recently, the research field of camera-based character recognition has grown because of the rapid growth in popularity of portable cameras and mobile phones that incorporate a camera. Camera-based character recognition has enormous potential for everyday applications. For example, it could enable us to point a camera at text in a foreign language and obtain an instantaneous translation: see Figure 1(a).1 This would be helpful when traveling but also for checking dictionaries or translating a foreign-language book. Another possible application is a voice-navigation service for visually disabled people\u2014 see Figure 1(b)\u2014who need help to use information provided as text. The service tells the user where texts are located and reads them out. However, it would be annoying to be notified of all texts in a scene, and so it would be preferable to be alerted only to pre-registered words or phrases, at least initially. To realize such applications, we have developed a quick, robust, and diverse (in terms of fonts) recognition technique for camera-captured characters.2\u20134 Real-time processing is essential for usability. In addition, it is vital to maintain accuracy under real-life conditions such as uneven lighting, occlusion, perspective distortion, and low resolution. A successful system should also be able to decode complex layouts and fonts, such as the rounded text logo of Starbucks coffee. Our system can recognise 220 camera-captured characters per second and has achieved a 95.8% recognition rates for characters captured from a slant angle of 45. It can recognize 100 fonts and nonstraight, including rounded, texts. We have developed a prototype system of a new interface that enables us to \u2018click\u2019 the physical world to obtain more information, like clicking anchor text on a web browser (see Figure 2). For instance, when the word \u2018Hawk\u2019 is pointed at with a Figure 1. Possible applications of camera-based character recognition. (a) Translation service for foreign travelers. (b) Voice navigation for visually impaired people."
            },
            "slug": "Real-life-clickable-text-Iwamura-Tsuji",
            "title": {
                "fragments": [],
                "text": "Real-life clickable text"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "A quick, robust, and diverse character recognition technique for camera-captured characters that can recognize 100 fonts and nonstraight, including rounded, texts and a prototype system of a new interface that enables the user to \u2018click\u2019 the physical world to obtain more information."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2066819269"
                        ],
                        "name": "James Philbin",
                        "slug": "James-Philbin",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Philbin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "James Philbin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1700928"
                        ],
                        "name": "O. Chum",
                        "slug": "O.-Chum",
                        "structuredName": {
                            "firstName": "Ond\u0159ej",
                            "lastName": "Chum",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Chum"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2090818"
                        ],
                        "name": "M. Isard",
                        "slug": "M.-Isard",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Isard",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Isard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1782755"
                        ],
                        "name": "Josef Sivic",
                        "slug": "Josef-Sivic",
                        "structuredName": {
                            "firstName": "Josef",
                            "lastName": "Sivic",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Josef Sivic"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688869"
                        ],
                        "name": "Andrew Zisserman",
                        "slug": "Andrew-Zisserman",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Zisserman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Zisserman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 66,
                                "start": 62
                            }
                        ],
                        "text": "While the similar idea is used for an object recognition task [13] using a variant of RANSAC algorithm [14], the assumption that only one object is contained in a query image holds."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 12203312,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "28e4b8ebbdb0e80f03b6f0578deeb38694af081e",
            "isKey": false,
            "numCitedBy": 2923,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we present a large-scale object retrieval system. The user supplies a query object by selecting a region of a query image, and the system returns a ranked list of images that contain the same object, retrieved from a large corpus. We demonstrate the scalability and performance of our system on a dataset of over 1 million images crawled from the photo-sharing site, Flickr [3], using Oxford landmarks as queries. Building an image-feature vocabulary is a major time and performance bottleneck, due to the size of our dataset. To address this problem we compare different scalable methods for building a vocabulary and introduce a novel quantization method based on randomized trees which we show outperforms the current state-of-the-art on an extensive ground-truth. Our experiments show that the quantization has a major effect on retrieval quality. To further improve query performance, we add an efficient spatial verification stage to re-rank the results returned from our bag-of-words model and show that this consistently improves search quality, though by less of a margin when the visual vocabulary is large. We view this work as a promising step towards much larger, \"web-scale \" image corpora."
            },
            "slug": "Object-retrieval-with-large-vocabularies-and-fast-Philbin-Chum",
            "title": {
                "fragments": [],
                "text": "Object retrieval with large vocabularies and fast spatial matching"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "To improve query performance, this work adds an efficient spatial verification stage to re-rank the results returned from the bag-of-words model and shows that this consistently improves search quality, though by less of a margin when the visual vocabulary is large."
            },
            "venue": {
                "fragments": [],
                "text": "2007 IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2465976"
                        ],
                        "name": "M. Fischler",
                        "slug": "M.-Fischler",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "Fischler",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Fischler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1764443"
                        ],
                        "name": "R. Bolles",
                        "slug": "R.-Bolles",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Bolles",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Bolles"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 107,
                                "start": 103
                            }
                        ],
                        "text": "While the similar idea is used for an object recognition task [13] using a variant of RANSAC algorithm [14], the assumption that only one object is contained in a query image holds."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 57871996,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4f37468a95ccc62debb9e5a4cb0d73489ca61190",
            "isKey": false,
            "numCitedBy": 6878,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-Paradigm-for-Model-Fitting-with-Applications-to-Fischler-Bolles",
            "title": {
                "fragments": [],
                "text": "A Paradigm for Model Fitting with Applications to Image Analysis and Automated Cartography"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1724709"
                        ],
                        "name": "S. Arya",
                        "slug": "S.-Arya",
                        "structuredName": {
                            "firstName": "Sunil",
                            "lastName": "Arya",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Arya"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1709509"
                        ],
                        "name": "D. Mount",
                        "slug": "D.-Mount",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Mount",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Mount"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712586"
                        ],
                        "name": "N. Netanyahu",
                        "slug": "N.-Netanyahu",
                        "structuredName": {
                            "firstName": "Nathan",
                            "lastName": "Netanyahu",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Netanyahu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "37746341"
                        ],
                        "name": "R. Silverman",
                        "slug": "R.-Silverman",
                        "structuredName": {
                            "firstName": "Ruth",
                            "lastName": "Silverman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Silverman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1736712"
                        ],
                        "name": "A. Wu",
                        "slug": "A.-Wu",
                        "structuredName": {
                            "firstName": "Angela",
                            "lastName": "Wu",
                            "middleNames": [
                                "Y."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Wu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8193729,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "219101fe724232acc330ff0910152931538f85c7",
            "isKey": false,
            "numCitedBy": 2723,
            "numCiting": 94,
            "paperAbstract": {
                "fragments": [],
                "text": "Consider a set of <italic>S</italic> of <italic>n</italic> data points  in real <italic>d</italic>-dimensional space, R<supscrpt>d</supscrpt>, where distances are measured using any Minkowski metric. In nearest neighbor searching, we preprocess <italic>S</italic> into a data structure, so that given any query point <italic>q</italic><inline-equation> <f>\u2208</f></inline-equation> R<supscrpt>d</supscrpt>, is the closest point of S to <italic>q</italic> can be reported quickly. Given any positive real \u03b5, data point <italic>p</italic> is a (1 +\u03b5)-<italic>approximate nearest neighbor</italic> of <italic>q</italic> if its distance from <italic>q</italic> is within a factor of (1 + \u03b5) of the distance to the true nearest neighbor. We show that it is possible to preprocess a    set of <italic>n</italic> points in     R<supscrpt>d</supscrpt> in <italic>O(dn</italic> log <italic>n</italic>) time and <italic>O(dn)</italic> space, so that given a query point <italic> q</italic> <inline-equation> <f>\u2208</f></inline-equation> R<supscrpt>d</supscrpt>, and \u03b5 > 0, a (1 + \u03b5)-approximate nearest neighbor of <italic>q</italic> can be computed in <italic>O</italic>(<italic>c</italic><subscrpt><italic>d</italic>, \u03b5</subscrpt> log <italic>n</italic>) time, where <italic>c<subscrpt>d,\u03b5</subscrpt></italic>\u2264<italic>d</italic> <inline-equation> <f><fen lp=\"ceil\">1 + 6d/<g>e</g><rp post=\"ceil\"></fen></f></inline-equation>;<supscrpt>d</supscrpt> is a factor depending only on dimension and \u03b5. In general, we show that given an integer <italic>k</italic> \u2265 1, (1 + \u03b5)-approximations  to the  <italic>k</italic> nearest neighbors of <italic>q</italic> can  be computed in additional <italic>O(kd</italic> log <italic>n</italic>) time."
            },
            "slug": "An-optimal-algorithm-for-approximate-nearest-fixed-Arya-Mount",
            "title": {
                "fragments": [],
                "text": "An optimal algorithm for approximate nearest neighbor searching fixed dimensions"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "It is shown that it is possible to preprocess a set of data points in real D-dimensional space in O(kd) time and in additional space, so that given a query point q, the closest point of S to S to q can be reported quickly."
            },
            "venue": {
                "fragments": [],
                "text": "JACM"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3177109"
                        ],
                        "name": "Y. Kusachi",
                        "slug": "Y.-Kusachi",
                        "structuredName": {
                            "firstName": "Yoshinori",
                            "lastName": "Kusachi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Kusachi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2146982808"
                        ],
                        "name": "Akira Suzuki",
                        "slug": "Akira-Suzuki",
                        "structuredName": {
                            "firstName": "Akira",
                            "lastName": "Suzuki",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Akira Suzuki"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2054172965"
                        ],
                        "name": "N. Ito",
                        "slug": "N.-Ito",
                        "structuredName": {
                            "firstName": "Naoki",
                            "lastName": "Ito",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Ito"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1934433"
                        ],
                        "name": "K. Arakawa",
                        "slug": "K.-Arakawa",
                        "structuredName": {
                            "firstName": "Kenichi",
                            "lastName": "Arakawa",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Arakawa"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1692251"
                        ],
                        "name": "T. Yasuno",
                        "slug": "T.-Yasuno",
                        "structuredName": {
                            "firstName": "Takayuki",
                            "lastName": "Yasuno",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Yasuno"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 96,
                                "start": 93
                            }
                        ],
                        "text": "Another approach is exhaustive search for deformed characters without character segmentation [6], [7]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 57606373,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3ccf98618d111c5181c89d4d47f7917cf2420544",
            "isKey": false,
            "numCitedBy": 3,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Scene-Image-Indexing-and-Retrieval-Using-Candidates-Kusachi-Suzuki",
            "title": {
                "fragments": [],
                "text": "Scene Image Indexing and Retrieval Using Candidates of Characters"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2007
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 7,
            "methodology": 8
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 15,
        "totalPages": 2
    },
    "page_url": "https://www.semanticscholar.org/paper/Recognition-of-Multiple-Characters-in-a-Scene-Image-Iwamura-Kobayashi/045cf0d259b70a970313ee6525e44cc70817c753?sort=total-citations"
}