{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1802785"
                        ],
                        "name": "S. Nowlan",
                        "slug": "S.-Nowlan",
                        "structuredName": {
                            "firstName": "Steven",
                            "lastName": "Nowlan",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Nowlan"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 250,
                                "start": 239
                            }
                        ],
                        "text": "\u2026model is a powerful estimation and prediction technique withroots in the statistics literature (Titterington, Smith, & Makov, 1985); it has, over the lastfew years, been adopted by researchers in machine learning (Cheeseman et al., 1988; Nowlan,1991; Specht, 1991; Ghahramani & Jordan, 1994)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 170,
                                "start": 113
                            }
                        ],
                        "text": "3 MIXTURES OF GAUSSIANS The mixture of Gaussians model is gaining popularity amongmachine learning practitioners [Nowlan, 1991; Specht, 1991; Ghahramani and Jordan, 1994]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 60866167,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "59fa47fc237a0781b4bf1c84fedb728d20db26a1",
            "isKey": false,
            "numCitedBy": 167,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "In this thesis, we consider learning algorithms for neural networks which are based on fitting a mixture probability density to a set of data. \nWe begin with an unsupervised algorithm which is an alternative to the classical winner-take-all competitive algorithms. Rather than updating only the parameters of the \"winner\" on each case, the parameters of all competitors are updated in proportion to their relative responsibility for the case. Use of such a \"soft\" competitive algorithm is shown to give better performance than the more traditional algorithms, with little additional cost. \nWe then consider a supervised modular architecture in which a number of simple \"expert\" networks compete to solve distinct pieces of a large task. A soft competitive mechanism is used to determine how much an expert learns on a case, based on how well the expert performs relative to the other expert networks. At the same time, a separate gating network learns to weight the output of each expert according to a prediction of its relative performance based on the input to the system. Experiments on a number of tasks illustrate that this architecture is capable of uncovering interesting task decompositions and of generalizing better than a single network with small training sets. \nFinally, we consider learning algorithms in which we assume that the actual output of the network should fall into one of a small number of classes or clusters. The objective of learning is to make the variance of these classes as small as possible. In the classical decision-directed algorithm, we decide that an output belongs to the class it is closest to and minimize the squared distance between the output and the center (mean) of this closest class. In the \"soft\" version of this algorithm, we minimize the squared distance between the actual output and a weighted average of the means of all of the classes. The weighting factors are the relative probability that the output belongs to each class. This idea may also be used to model the weights of a network, to produce networks which generalize better from small training sets."
            },
            "slug": "Soft-competitive-adaptation:-neural-network-based-Nowlan",
            "title": {
                "fragments": [],
                "text": "Soft competitive adaptation: neural network learning algorithms based on fitting statistical mixtures"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "An unsupervised algorithm which is an alternative to the classical winner-take-all competitive algorithms and a supervised modular architecture in which a number of simple \"expert\" networks compete to solve distinct pieces of a large task are considered."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3194361"
                        ],
                        "name": "S. Geman",
                        "slug": "S.-Geman",
                        "structuredName": {
                            "firstName": "Stuart",
                            "lastName": "Geman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Geman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2246319"
                        ],
                        "name": "E. Bienenstock",
                        "slug": "E.-Bienenstock",
                        "structuredName": {
                            "firstName": "Elie",
                            "lastName": "Bienenstock",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Bienenstock"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2330895"
                        ],
                        "name": "R. Doursat",
                        "slug": "R.-Doursat",
                        "structuredName": {
                            "firstName": "Ren\u00e9",
                            "lastName": "Doursat",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Doursat"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14215320,
            "fieldsOfStudy": [
                "Computer Science",
                "Psychology"
            ],
            "id": "a34e35dbbc6911fa7b94894dffdc0076a261b6f0",
            "isKey": false,
            "numCitedBy": 3532,
            "numCiting": 151,
            "paperAbstract": {
                "fragments": [],
                "text": "Feedforward neural networks trained by error backpropagation are examples of nonparametric regression estimators. We present a tutorial on nonparametric inference and its relation to neural networks, and we use the statistical viewpoint to highlight strengths and weaknesses of neural models. We illustrate the main points with some recognition experiments involving artificial data as well as handwritten numerals. In way of conclusion, we suggest that current-generation feedforward neural networks are largely inadequate for difficult problems in machine perception and machine learning, regardless of parallel-versus-serial hardware or other implementation issues. Furthermore, we suggest that the fundamental challenges in neural modeling are about representation rather than learning per se. This last point is supported by additional experiments with handwritten numerals."
            },
            "slug": "Neural-Networks-and-the-Bias/Variance-Dilemma-Geman-Bienenstock",
            "title": {
                "fragments": [],
                "text": "Neural Networks and the Bias/Variance Dilemma"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "It is suggested that current-generation feedforward neural networks are largely inadequate for difficult problems in machine perception and machine learning, regardless of parallel-versus-serial hardware or other implementation issues."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2285810"
                        ],
                        "name": "D. Specht",
                        "slug": "D.-Specht",
                        "structuredName": {
                            "firstName": "Donald",
                            "lastName": "Specht",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Specht"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6266210,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "45f43abc49a8a60e6b43ddbda5af9fc6c88d663d",
            "isKey": false,
            "numCitedBy": 3774,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "A memory-based network that provides estimates of continuous variables and converges to the underlying (linear or nonlinear) regression surface is described. The general regression neural network (GRNN) is a one-pass learning algorithm with a highly parallel structure. It is shown that, even with sparse data in a multidimensional measurement space, the algorithm provides smooth transitions from one observed value to another. The algorithmic form can be used for any regression problem in which an assumption of linearity is not justified."
            },
            "slug": "A-general-regression-neural-network-Specht",
            "title": {
                "fragments": [],
                "text": "A general regression neural network"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "The general regression neural network (GRNN) is a one-pass learning algorithm with a highly parallel structure that provides smooth transitions from one observed value to another."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Neural Networks"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1865251"
                        ],
                        "name": "M. Plutowski",
                        "slug": "M.-Plutowski",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Plutowski",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Plutowski"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2149702798"
                        ],
                        "name": "H. White",
                        "slug": "H.-White",
                        "structuredName": {
                            "firstName": "Halbert",
                            "lastName": "White",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. White"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 62,
                                "start": 36
                            }
                        ],
                        "text": "This contrasts with related work by Plutowski and White (1993), which is concernedwith ltering an existing data set."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                }
            ],
            "corpusId": 6936422,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3e06680314e1cf32706686e6520107976fdb7064",
            "isKey": false,
            "numCitedBy": 159,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": "The authors derive a method for selecting exemplars for training a multilayer feedforward network architecture to estimate an unknown (deterministic) mapping from clean data, i.e., data measured either without error or with negligible error. The objective is to minimize the data requirement of learning. The authors choose a criterion for selecting training examples that works well in conjunction with the criterion used for learning, here, least squares. They proceed sequentially, selecting an example that, when added to the previous set of training examples and learned, maximizes the decrement of network squared error over the input space. When dealing with clean data and deterministic relationships, concise training sets that minimize the integrated squared bias (ISB) are desired. The ISB is used to derive a selection criterion for evaluating individual training examples, the DISB, that is maximized to select new exemplars. They conclude with graphical illustrations of the method, and demonstrate its use during network training. Experimental results indicate that training upon exemplars selected in this fashion can save computation in general purpose use as well."
            },
            "slug": "Selecting-concise-training-sets-from-clean-data-Plutowski-White",
            "title": {
                "fragments": [],
                "text": "Selecting concise training sets from clean data"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "Experimental results indicate that training upon exemplars selected in this fashion can save computation in general purpose use as well, and its use during network training is demonstrated."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Neural Networks"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2976268"
                        ],
                        "name": "D. Cohn",
                        "slug": "D.-Cohn",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Cohn",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Cohn"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "We rst brie y review how the statistical approach can be applied to neural networks, as described in earlier work (MacKay, 1992; Cohn, 1994)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "It is worth noting that on the Arm2D domain, this form of locally weighted regression also signi cantly outperforms both the mixture of Gaussians and the neural networks discussed by Cohn (1994)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "See, for example, (Cohn, 1994)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Experimental Results For an experimental testbed, we used the \\Arm2D\" problem described by Cohn (1994). The task is to learn the kinematics of a toy 2-degree-of-freedom robot arm (see Figure 4)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "In practice, @\u0177=@w may be highly nonlinear, and P (yjx) may be far from Gaussian; in spite of this, empirical results show that it works well on some problems (Cohn, 1994)."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "See Cohn (1994) for details."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "2 Example: Active Learning with a Neural Network In this section we review the use of techniques from Optimal Experiment Design (OED) to minimize the estimated variance of a neural network (Fedorov, 1972; MacKay, 1992; Cohn, 1994)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 6170752,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "08627b368e6b7d142cfcece74d52d21d48cc64a6",
            "isKey": false,
            "numCitedBy": 411,
            "numCiting": 65,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Neural-Network-Exploration-Using-Optimal-Experiment-Cohn",
            "title": {
                "fragments": [],
                "text": "Neural Network Exploration Using Optimal Experiment Design"
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1683459"
                        ],
                        "name": "G. Paass",
                        "slug": "G.-Paass",
                        "structuredName": {
                            "firstName": "Gerhard",
                            "lastName": "Paass",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Paass"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716800"
                        ],
                        "name": "J. Kindermann",
                        "slug": "J.-Kindermann",
                        "structuredName": {
                            "firstName": "J\u00f6rg",
                            "lastName": "Kindermann",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Kindermann"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 18822604,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "962e1fce52f30c3d1c0c5120d0fb896d207f267a",
            "isKey": false,
            "numCitedBy": 35,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "If data collection is costly, there is much to be gained by actively selecting particularly informative data points in a sequential way. In a Bayesian decision-theoretic framework we develop a query selection criterion which explicitly takes into account the intended use of the model predictions. By Markov Chain Monte Carlo methods the necessary quantities can be approximated to a desired precision. As the number of data points grows, the model complexity is modified by a Bayesian model selection strategy. The properties of two versions of the criterion ate demonstrated in numerical experiments."
            },
            "slug": "Bayesian-Query-Construction-for-Neural-Network-Paass-Kindermann",
            "title": {
                "fragments": [],
                "text": "Bayesian Query Construction for Neural Network Models"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "A Bayesian decision-theoretic framework is developed which explicitly takes into account the intended use of the model predictions when selecting particularly informative data points in a sequential way."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1744700"
                        ],
                        "name": "Zoubin Ghahramani",
                        "slug": "Zoubin-Ghahramani",
                        "structuredName": {
                            "firstName": "Zoubin",
                            "lastName": "Ghahramani",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zoubin Ghahramani"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694621"
                        ],
                        "name": "Michael I. Jordan",
                        "slug": "Michael-I.-Jordan",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Jordan",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael I. Jordan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 18086786,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5db7dc2239f820eae498b07a955f31b3d113179f",
            "isKey": false,
            "numCitedBy": 634,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "Real-world learning tasks may involve high-dimensional data sets with arbitrary patterns of missing data. In this paper we present a framework based on maximum likelihood density estimation for learning from such data set.s. We use mixture models for the density estimates and make two distinct appeals to the Expectation-Maximization (EM) principle (Dempster et al., 1977) in deriving a learning algorithm--EM is used both for the estimation of mixture components and for coping with missing data. The resulting algorithm is applicable to a wide range of supervised as well as unsupervised learning problems. Results from a classification benchmark--the iris data set--are presented."
            },
            "slug": "Supervised-learning-from-incomplete-data-via-an-EM-Ghahramani-Jordan",
            "title": {
                "fragments": [],
                "text": "Supervised learning from incomplete data via an EM approach"
            },
            "tldr": {
                "abstractSimilarityScore": 60,
                "text": "A framework based on maximum likelihood density estimation for learning from high-dimensional data sets with arbitrary patterns of missing data is presented and results from a classification benchmark--the iris data set--are presented."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2976268"
                        ],
                        "name": "D. Cohn",
                        "slug": "D.-Cohn",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Cohn",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Cohn"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "es the bias comp onen t, whic h can lead to signican t errors when the learner&apos;s bias is non-negligible. W ork in progress examines eectiv e w a ys of measuring and optimally eliminating bias (Cohn, 1995); future w ork will examine ho to join tly minimize b oth bias and v ariance pro duce a criterion that truly minimizes the learner&apos;s exp ected error. Another direction for future researc h is the"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 11344037,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "a58fbbab5c1f8115cd63d71bfbd66c981831f384",
            "isKey": false,
            "numCitedBy": 36,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "I describe an exploration criterion that attempts to minimize the error of a learner by minimizing its estimated squared bias. I describe experiments with locally-weighted regression on two simple kinematics problems, and observe that this \"bias-only\" approach outperforms the more common \"variance-only\" exploration approach, even in the presence of noise."
            },
            "slug": "Minimizing-Statistical-Bias-with-Queries-Cohn",
            "title": {
                "fragments": [],
                "text": "Minimizing Statistical Bias with Queries"
            },
            "tldr": {
                "abstractSimilarityScore": 91,
                "text": "An exploration criterion is described that attempts to minimize the error of a learner by minimizing its estimated squared bias, and experiments with locally-weighted regression on two simple kinematics problems show that this \"bias- only\" approach outperforms the more common \"variance-only\" exploration approach, even in the presence of noise."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35157864"
                        ],
                        "name": "W. Cleveland",
                        "slug": "W.-Cleveland",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Cleveland",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Cleveland"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46660600"
                        ],
                        "name": "S. J. Devlin",
                        "slug": "S.-J.-Devlin",
                        "structuredName": {
                            "firstName": "Susan",
                            "lastName": "Devlin",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. J. Devlin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2077153109"
                        ],
                        "name": "E. Grosse",
                        "slug": "E.-Grosse",
                        "structuredName": {
                            "firstName": "Eric",
                            "lastName": "Grosse",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Grosse"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 41,
                                "start": 18
                            }
                        ],
                        "text": "The method usedby Cleveland et al. (1988) is to set k such that the reference point being predicted has apredetermined amount of support, that is, k is set so that n is close to some target value."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 117620955,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "64448ce5fe9f0d01097fe0a21395c21f895cecfc",
            "isKey": false,
            "numCitedBy": 581,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Regression-by-local-fitting:-Methods,-properties,-Cleveland-Devlin",
            "title": {
                "fragments": [],
                "text": "Regression by local fitting: Methods, properties, and computational algorithms"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2403454"
                        ],
                        "name": "E. Baum",
                        "slug": "E.-Baum",
                        "structuredName": {
                            "firstName": "Eric",
                            "lastName": "Baum",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Baum"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 19460515,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "a7404527c3a6aa542ea183da9c821efda05a2afc",
            "isKey": false,
            "numCitedBy": 183,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "An algorithm which trains networks using examples and queries is proposed. In a query, the algorithm supplies a y and is told t(y) by an oracle. Queries appear to be available in practice for most problems of interest, e.g. by appeal to a human expert. The author's algorithm is proved to PAC learn in polynomial time the class of target functions defined by layered, depth two, threshold nets having n inputs connected to k hidden threshold units connected to one or more output units, provided k=/<4. While target functions and input distributions can be described for which the algorithm will fail for larger k, it appears likely to work well in practice. Tests of a variant of the algorithm have consistently and rapidly learned random nets of this type. Computational efficiency figures are given. The algorithm can also be proved to learn intersections of k half-spaces in R(n) in time polynomial in both n and k. A variant of the algorithm can learn arbitrary depth layered threshold networks with n inputs and k units in the first hidden layer in time polynomial in the larger of n and k but exponential in the smaller of the two."
            },
            "slug": "Neural-net-algorithms-that-learn-in-polynomial-time-Baum",
            "title": {
                "fragments": [],
                "text": "Neural net algorithms that learn in polynomial time from examples and queries"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "The author's algorithm is proved to PAC learn in polynomial time the class of target functions defined by layered, depth two, threshold nets having n inputs connected to k hidden threshold units connected to one or more output units, provided k=/<4."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Neural Networks"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145852650"
                        ],
                        "name": "D. Mackay",
                        "slug": "D.-Mackay",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Mackay",
                            "middleNames": [
                                "J.",
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Mackay"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15819455,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "2046412fecff64e095cc5190b69172055afd2094",
            "isKey": false,
            "numCitedBy": 1202,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "Learning can be made more efficient if we can actively select particularly salient data points. Within a Bayesian learning framework, objective functions are discussed that measure the expected informativeness of candidate measurements. Three alternative specifications of what we want to gain information about lead to three different criteria for data selection. All these criteria depend on the assumption that the hypothesis space is correct, which may prove to be their main weakness."
            },
            "slug": "Information-Based-Objective-Functions-for-Active-Mackay",
            "title": {
                "fragments": [],
                "text": "Information-Based Objective Functions for Active Data Selection"
            },
            "tldr": {
                "abstractSimilarityScore": 55,
                "text": "Within a Bayesian learning framework, objective functions are discussed that measure the expected informativeness of candidate measurements that depend on the assumption that the hypothesis space is correct."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40484982"
                        ],
                        "name": "P. Cheeseman",
                        "slug": "P.-Cheeseman",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Cheeseman",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Cheeseman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144308823"
                        ],
                        "name": "Matthew Self",
                        "slug": "Matthew-Self",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Self",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Matthew Self"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2113380562"
                        ],
                        "name": "James Kelly",
                        "slug": "James-Kelly",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Kelly",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "James Kelly"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2114766082"
                        ],
                        "name": "Will Taylor",
                        "slug": "Will-Taylor",
                        "structuredName": {
                            "firstName": "Will",
                            "lastName": "Taylor",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Will Taylor"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2059655854"
                        ],
                        "name": "Don Freeman",
                        "slug": "Don-Freeman",
                        "structuredName": {
                            "firstName": "Don",
                            "lastName": "Freeman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Don Freeman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "87277825"
                        ],
                        "name": "J. Stutz",
                        "slug": "J.-Stutz",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Stutz",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Stutz"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 237,
                                "start": 215
                            }
                        ],
                        "text": "\u2026model is a powerful estimation and prediction technique withroots in the statistics literature (Titterington, Smith, & Makov, 1985); it has, over the lastfew years, been adopted by researchers in machine learning (Cheeseman et al., 1988; Nowlan,1991; Specht, 1991; Ghahramani & Jordan, 1994)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2951993,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "d88ffb6c9a6a6a834da4704224b5663a3a5cc430",
            "isKey": false,
            "numCitedBy": 200,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes a Bayesian technique for unsupervised classification of data and its computer implementation, AutoClass. Given real valued or discrete data, AutoClass determines the most probable number of classes present in the data, the most probable descriptions of those classes, and each object's probability of membership in each class. The program performs as well as or better than other automatic classification systems when run on the same data and contains no ad hoc similarity measures or stopping criteria. AutoClass has been applied to several databases in which it has discovered classes representing previously unsuspected phenomena."
            },
            "slug": "Bayesian-Classification-Cheeseman-Self",
            "title": {
                "fragments": [],
                "text": "Bayesian Classification"
            },
            "tldr": {
                "abstractSimilarityScore": 62,
                "text": "A Bayesian technique for unsupervised classification of data and its computer implementation, AutoClass, which performs as well as or better than other automatic classification systems when run on the same data and contains no ad hoc similarity measures or stopping criteria."
            },
            "venue": {
                "fragments": [],
                "text": "AAAI"
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1745219"
                        ],
                        "name": "S. Schaal",
                        "slug": "S.-Schaal",
                        "structuredName": {
                            "firstName": "Stefan",
                            "lastName": "Schaal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Schaal"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8483722"
                        ],
                        "name": "C. Atkeson",
                        "slug": "C.-Atkeson",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Atkeson",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Atkeson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 62,
                                "start": 36
                            }
                        ],
                        "text": "This contrasts with related work by Plutowski and White (1993), which is concernedwith ltering an existing data set."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                }
            ],
            "corpusId": 2004600,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "82479b544924ee734fb22f9dce78aace0f90cd3c",
            "isKey": false,
            "numCitedBy": 253,
            "numCiting": 134,
            "paperAbstract": {
                "fragments": [],
                "text": "Issues involved in implementing robot learning for a challenging dynamic task are explored in this article, using a case study from robot juggling. We use a memory-based local modeling approach (locally weighted regression) to represent a learned model of the task to be performed. Statistical tests are given to examine the uncertainty of a model, to optimize its prediction quality, and to deal with noisy and corrupted data. We develop an exploration algorithm that explicitly deals with prediction accuracy requirements during exploration. Using all these ingredients in combination with methods from optimal control, our robot achieves fast real-time learning of the task within 40 to 100 trials.<<ETX>>"
            },
            "slug": "Robot-juggling:-implementation-of-memory-based-Schaal-Atkeson",
            "title": {
                "fragments": [],
                "text": "Robot juggling: implementation of memory-based learning"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A memory-based local modeling approach (locally weighted regression) is used to represent a learned model of the task to be performed, and an exploration algorithm is developed that explicitly deals with prediction accuracy requirements during exploration."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Control Systems"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32381927"
                        ],
                        "name": "Jan Storck",
                        "slug": "Jan-Storck",
                        "structuredName": {
                            "firstName": "Jan",
                            "lastName": "Storck",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jan Storck"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3308557"
                        ],
                        "name": "S. Hochreiter",
                        "slug": "S.-Hochreiter",
                        "structuredName": {
                            "firstName": "Sepp",
                            "lastName": "Hochreiter",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Hochreiter"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 297,
                                "start": 271
                            }
                        ],
                        "text": "\u2026don't havedata (Whitehead, 1991), where we perform poorly (Linden & Weber, 1993), where we havelow con dence (Thrun & M oller, 1992), where we expect it to change our model (Cohn,Atlas, & Ladner, 1990, 1994), and where we previously found data that resulted in learning(Schmidhuber & Storck, 1993)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 6720319,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2547be25e1e07728aa0966a0354e90664816d15e",
            "isKey": false,
            "numCitedBy": 178,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "For an agent living in a nondeterministic Markov environment (NME), what is, in theory, the fastest way of acquiring information about its statistical properties? The answer is: to design \u201coptimal\u201d sequences of \u201cexperiments\u201d by performing action sequences that maximize expected information gain. This notion is implemented by combining concepts from information theory and reinforcement learning. Experiments show that the resulting method, reinforcement driven information acquisition, can explore certain NMEs much faster than conventional random exploration."
            },
            "slug": "REINFORCEMENT-DRIVEN-INFORMATION-ACQUISITION-IN-Storck-Hochreiter",
            "title": {
                "fragments": [],
                "text": "REINFORCEMENT DRIVEN INFORMATION ACQUISITION IN NONDETERMINISTIC ENVIRONMENTS"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "Experiments show that the resulting method, reinforcement driven information acquisition, can explore certain NMEs much faster than conventional random exploration."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152591573"
                        ],
                        "name": "D. Titterington",
                        "slug": "D.-Titterington",
                        "structuredName": {
                            "firstName": "D.",
                            "lastName": "Titterington",
                            "middleNames": [
                                "Michael"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Titterington"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "15974963"
                        ],
                        "name": "A. F. Smith",
                        "slug": "A.-F.-Smith",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Smith",
                            "middleNames": [
                                "F.",
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. F. Smith"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2580190"
                        ],
                        "name": "U. Makov",
                        "slug": "U.-Makov",
                        "structuredName": {
                            "firstName": "Udi",
                            "lastName": "Makov",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "U. Makov"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 124992180,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "54a1f6ab4cc6cb749c2b8d15c1dd3449e072362f",
            "isKey": false,
            "numCitedBy": 3447,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Statistical Problems. Applications of Finite Mixture Models. Mathematical Aspects of Mixtures. Learning About the Parameters of a Mixture. Learning About the Components of a Mixture. Sequential Problems and Procedures."
            },
            "slug": "Statistical-analysis-of-finite-mixture-Titterington-Smith",
            "title": {
                "fragments": [],
                "text": "Statistical analysis of finite mixture distributions"
            },
            "tldr": {
                "abstractSimilarityScore": 51,
                "text": "This course discusses Mathematical Aspects of Mixtures, Sequential Problems and Procedures, and Applications of Finite Mixture Models."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1705299"
                        ],
                        "name": "L. Atlas",
                        "slug": "L.-Atlas",
                        "structuredName": {
                            "firstName": "Les",
                            "lastName": "Atlas",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Atlas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2976268"
                        ],
                        "name": "D. Cohn",
                        "slug": "D.-Cohn",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Cohn",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Cohn"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1762656"
                        ],
                        "name": "R. Ladner",
                        "slug": "R.-Ladner",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Ladner",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Ladner"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 18986608,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b3c19172a59922fa7cbed8f09f30ed3a1ea74b4e",
            "isKey": false,
            "numCitedBy": 261,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "\"Selective sampling\" is a form of directed search that can greatly increase the ability of a connectionist network to generalize accurately. Based on information from previous batches of samples, a network may be trained on data selectively sampled from regions in the domain that are unknown. This is realizable in cases when the distribution is known, or when the cost of drawing points from the target distribution is negligible compared to the cost of labeling them with the proper classification. The approach is justified by its applicability to the problem of training a network for power system security analysis. The benefits of selective sampling are studied analytically, and the results are confirmed experimentally."
            },
            "slug": "Training-Connectionist-Networks-with-Queries-and-Atlas-Cohn",
            "title": {
                "fragments": [],
                "text": "Training Connectionist Networks with Queries and Selective Sampling"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "The approach is justified by its applicability to the problem of training a network for power system security analysis and the benefits are studied analytically, and the results are confirmed experimentally."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144867807"
                        ],
                        "name": "S. Thrun",
                        "slug": "S.-Thrun",
                        "structuredName": {
                            "firstName": "Sebastian",
                            "lastName": "Thrun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Thrun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2061144973"
                        ],
                        "name": "K. M\u00f6ller",
                        "slug": "K.-M\u00f6ller",
                        "structuredName": {
                            "firstName": "Knut",
                            "lastName": "M\u00f6ller",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. M\u00f6ller"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 157,
                                "start": 146
                            }
                        ],
                        "text": "\u2026choosing places where we don't havedata (Whitehead, 1991), where we perform poorly (Linden & Weber, 1993), where we havelow con dence (Thrun & M oller, 1992), where we expect it to change our model (Cohn,Atlas, & Ladner, 1990, 1994), and where we previously found data that resulted in\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2388567,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8c9a2e378e17bd86f30059ae29ce8c2ef7272acb",
            "isKey": false,
            "numCitedBy": 176,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "Whenever an agent learns to control an unknown environment, two opposing principles have to be combined, namely: exploration (long-term optimization) and exploitation (short-term optimization). Many real-valued connectionist approaches to learning control realize exploration by randomness in action selection. This might be disadvantageous when costs are assigned to \"negative experiences\". The basic idea presented in this paper is to make an agent explore unknown regions in a more directed manner. This is achieved by a so-called competence map, which is trained to predict the controller's accuracy, and is used for guiding exploration. Based on this, a bistable system enables smoothly switching attention between two behaviors - exploration and exploitation - depending on expected costs and knowledge gain. \n \nThe appropriateness of this method is demonstrated by a simple robot navigation task."
            },
            "slug": "Active-Exploration-in-Dynamic-Environments-Thrun-M\u00f6ller",
            "title": {
                "fragments": [],
                "text": "Active Exploration in Dynamic Environments"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A bistable system enables smoothly switching attention between two behaviors - exploration and exploitation - depending on expected costs and knowledge gain."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145430701"
                        ],
                        "name": "J. Pearl",
                        "slug": "J.-Pearl",
                        "structuredName": {
                            "firstName": "Judea",
                            "lastName": "Pearl",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Pearl"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 107,
                                "start": 96
                            }
                        ],
                        "text": "Of particular interest is the classof models known as \\belief networks\" or \\Bayesian networks\" (Pearl, 1988; Heckerman,Geiger, & Chickering, 1994)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 32583695,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "70ef29e6f0ce082bb8a47fd85b9bfb7cc0f20c93",
            "isKey": false,
            "numCitedBy": 18219,
            "numCiting": 230,
            "paperAbstract": {
                "fragments": [],
                "text": "From the Publisher: \nProbabilistic Reasoning in Intelligent Systems is a complete andaccessible account of the theoretical foundations and computational methods that underlie plausible reasoning under uncertainty. The author provides a coherent explication of probability as a language for reasoning with partial belief and offers a unifying perspective on other AI approaches to uncertainty, such as the Dempster-Shafer formalism, truth maintenance systems, and nonmonotonic logic. The author distinguishes syntactic and semantic approaches to uncertainty\u0097and offers techniques, based on belief networks, that provide a mechanism for making semantics-based systems operational. Specifically, network-propagation techniques serve as a mechanism for combining the theoretical coherence of probability theory with modern demands of reasoning-systems technology: modular declarative inputs, conceptually meaningful inferences, and parallel distributed computation. Application areas include diagnosis, forecasting, image interpretation, multi-sensor fusion, decision support systems, plan recognition, planning, speech recognition\u0097in short, almost every task requiring that conclusions be drawn from uncertain clues and incomplete information. \nProbabilistic Reasoning in Intelligent Systems will be of special interest to scholars and researchers in AI, decision theory, statistics, logic, philosophy, cognitive psychology, and the management sciences. Professionals in the areas of knowledge-based systems, operations research, engineering, and statistics will find theoretical and computational tools of immediate practical use. The book can also be used as an excellent text for graduate-level courses in AI, operations research, or applied probability."
            },
            "slug": "Probabilistic-reasoning-in-intelligent-systems-of-Pearl",
            "title": {
                "fragments": [],
                "text": "Probabilistic reasoning in intelligent systems - networks of plausible inference"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The author provides a coherent explication of probability as a language for reasoning with partial belief and offers a unifying perspective on other AI approaches to uncertainty, such as the Dempster-Shafer formalism, truth maintenance systems, and nonmonotonic logic."
            },
            "venue": {
                "fragments": [],
                "text": "Morgan Kaufmann series in representation and reasoning"
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145430701"
                        ],
                        "name": "J. Pearl",
                        "slug": "J.-Pearl",
                        "structuredName": {
                            "firstName": "Judea",
                            "lastName": "Pearl",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Pearl"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 148,
                                "start": 96
                            }
                        ],
                        "text": "Of particular interest is the class of models known as \\belief networks\" or \\Bayesian networks\" (Pearl, 1988; Heckerman, Geiger, & Chickering, 1994)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 107,
                                "start": 96
                            }
                        ],
                        "text": "Of particular interest is the classof models known as \\belief networks\" or \\Bayesian networks\" (Pearl, 1988; Heckerman,Geiger, & Chickering, 1994)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 57437891,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5bf6f01402e1648b7d1e6c9200ede6cb1af30123",
            "isKey": false,
            "numCitedBy": 4579,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Probabilistic-reasoning-in-intelligent-systems-Pearl",
            "title": {
                "fragments": [],
                "text": "Probabilistic reasoning in intelligent systems"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "70851852"
                        ],
                        "name": "E. Shoesmith",
                        "slug": "E.-Shoesmith",
                        "structuredName": {
                            "firstName": "Eddie",
                            "lastName": "Shoesmith",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Shoesmith"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145948621"
                        ],
                        "name": "G. Box",
                        "slug": "G.-Box",
                        "structuredName": {
                            "firstName": "G.",
                            "lastName": "Box",
                            "middleNames": [
                                "E.",
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Box"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40159987"
                        ],
                        "name": "N. Draper",
                        "slug": "N.-Draper",
                        "structuredName": {
                            "firstName": "Norman",
                            "lastName": "Draper",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Draper"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 122,
                                "start": 104
                            }
                        ],
                        "text": "The favored technique for this kind of optimization is usually a form of re-sponse surface methodology (Box & Draper, 1987), which performs experiments that guidehill-climbing through the input space."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 117364770,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "5d090074d5fa968d852e4468820cb683040d075a",
            "isKey": false,
            "numCitedBy": 4626,
            "numCiting": 1,
            "paperAbstract": {
                "fragments": [],
                "text": "Introduction to Response Surface Methodology. The Use of Graduating Functions. Least Squares for Response Surface Work. Factorial Designs at Two Levels. Blocking and Fractionating 2 k Factorial Designs. The Use of Steepest Ascent to Achieve System Improvement. Fitting Second--Order Models. Adequacy of Estimation and the Use of Transformation. Exploration of Maxima and Ridge Systems with Second--Order Response Surfaces. Occurrence and Elucidation of Ridge Systems, I. Occurrence and Elucidation of Ridge Systems, II. Links Between Emprirical and Theoretical Models. Design Aspects of Variance, Bias, and Lack of Fit. Variance----Optimal Designs. Practical Choice of a Response Surface Design. Subject Index. Index."
            },
            "slug": "Empirical-Model\u2010Building-and-Response-Surfaces-Shoesmith-Box",
            "title": {
                "fragments": [],
                "text": "Empirical Model\u2010Building and Response Surfaces"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "This work discusses the use of Graduating Functions, design Aspects of Variance, Bias, and Lack of Fit, and Practical Choice of a Response Surface Design in relation to Second--Order Response Surfaces."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "16243226"
                        ],
                        "name": "S. Weisberg",
                        "slug": "S.-Weisberg",
                        "structuredName": {
                            "firstName": "Sanford",
                            "lastName": "Weisberg",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Weisberg"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 121301894,
            "fieldsOfStudy": [
                "Mathematics",
                "Business"
            ],
            "id": "618288ca83856598cb047e5b053a24191225fb64",
            "isKey": false,
            "numCitedBy": 2466,
            "numCiting": 99,
            "paperAbstract": {
                "fragments": [],
                "text": "Preface.1 Scatterplots and Regression.1.1 Scatterplots.1.2 Mean Functions.1.3 Variance Functions.1.4 Summary Graph.1.5 Tools for Looking at Scatterplots.1.5.1 Size.1.5.2 Transformations.1.5.3 Smoothers for the Mean Function.1.6 Scatterplot Matrices.Problems.2 Simple Linear Regression.2.1 Ordinary Least Squares Estimation.2.2 Least Squares Criterion.2.3 Estimating sigma 2.2.4 Properties of Least Squares Estimates.2.5 Estimated Variances.2.6 Comparing Models: The Analysis of Variance.2.6.1 The F-Test for Regression.2.6.2 Interpreting p-values.2.6.3 Power of Tests.2.7 The Coefficient of Determination, R2.2.8 Confidence Intervals and Tests.2.8.1 The Intercept.2.8.2 Slope.2.8.3 Prediction.2.8.4 Fitted Values.2.9 The Residuals.Problems.3 Multiple Regression.3.1 Adding a Term to a Simple Linear Regression Model.3.1.1 Explaining Variability.3.1.2 Added-Variable Plots.3.2 The Multiple Linear Regression Model.3.3 Terms and Predictors.3.4 Ordinary Least Squares.3.4.1 Data and Matrix Notation.3.4.2 Variance-Covariance Matrix of e.3.4.3 Ordinary Least Squares Estimators.3.4.4 Properties of the Estimates.3.4.5 Simple Regression in Matrix Terms.3.5 The Analysis of Variance.3.5.1 The Coefficient of Determination.3.5.2 Hypotheses Concerning One of the Terms.3.5.3 Relationship to the t -Statistic.3.5.4 t-Tests and Added-Variable Plots.3.5.5 Other Tests of Hypotheses.3.5.6 Sequential Analysis of Variance Tables.3.6 Predictions and Fitted Values.Problems.4 Drawing Conclusions.4.1 Understanding Parameter Estimates.4.1.1 Rate of Change.4.1.2 Signs of Estimates.4.1.3 Interpretation Depends on Other Terms in the Mean Function.4.1.4 Rank Deficient and Over-Parameterized Mean Functions.4.1.5 Tests.4.1.6 Dropping Terms.4.1.7 Logarithms.4.2 Experimentation Versus Observation.4.3 Sampling from a Normal Population.4.4 More on R2.4.4.1 Simple Linear Regression and R2.4.4.2 Multiple Linear Regression.4.4.3 Regression through the Origin.4.5 Missing Data.4.5.1 Missing at Random.4.5.2 Alternatives.4.6 Computationally Intensive Methods.4.6.1 Regression Inference without Normality.4.6.2 Nonlinear Functions of Parameters.4.6.3 Predictors Measured with Error.Problems.5 Weights, Lack of Fit, and More.5.1 Weighted Least Squares.5.1.1 Applications of Weighted Least Squares.5.1.2 Additional Comments.5.2 Testing for Lack of Fit, Variance Known.5.3 Testing for Lack of Fit, Variance Unknown.5.4 General F Testing.5.4.1 Non-null Distributions.5.4.2 Additional Comments.5.5 Joint Confidence Regions.Problems.6 Polynomials and Factors.6.1 Polynomial Regression.6.1.1 Polynomials with Several Predictors.6.1.2 Using the Delta Method to Estimate a Minimum or a Maximum.6.1.3 Fractional Polynomials.6.2 Factors.6.2.1 No Other Predictors.6.2.2 Adding a Predictor: Comparing Regression Lines.6.2.3 Additional Comments.6.3 Many Factors.6.4 Partial One-Dimensional Mean Functions.6.5 Random Coefficient Models.Problems.7 Transformations.7.1 Transformations and Scatterplots.7.1.1 Power Transformations.7.1.2 Transforming Only the Predictor Variable.7.1.3 Transforming the Response Only.7.1.4 The Box and Cox Method.7.2 Transformations and Scatterplot Matrices.7.2.1 The 1D Estimation Result and Linearly Related Predictors.7.2.2 Automatic Choice of Transformation of Predictors.7.3 Transforming the Response.7.4 Transformations of Nonpositive Variables.Problems.8 Regression Diagnostics: Residuals.8.1 The Residuals.8.1.1 Difference Between e and e.8.1.2 The Hat Matrix.8.1.3 Residuals and the Hat Matrix with Weights.8.1.4 The Residuals When the Model Is Correct.8.1.5 The Residuals When the Model Is Not Correct.8.1.6 Fuel Consumption Data.8.2 Testing for Curvature.8.3 Nonconstant Variance.8.3.1 Variance Stabilizing Transformations.8.3.2 A Diagnostic for Nonconstant Variance.8.3.3 Additional Comments.8.4 Graphs for Model Assessment.8.4.1 Checking Mean Functions.8.4.2 Checking Variance Functions.Problems.9 Outliers and Influence.9.1 Outliers.9.1.1 An Outlier Test.9.1.2 Weighted Least Squares.9.1.3 Significance Levels for the Outlier Test.9.1.4 Additional Comments.9.2 Influence of Cases.9.2.1 Cook's Distance.9.2.2 Magnitude of Di .9.2.3 Computing Di .9.2.4 Other Measures of Influence.9.3 Normality Assumption.Problems.10 Variable Selection.10.1 The Active Terms.10.1.1 Collinearity.10.1.2 Collinearity and Variances.10.2 Variable Selection.10.2.1 Information Criteria.10.2.2 Computationally Intensive Criteria.10.2.3 Using Subject-Matter Knowledge.10.3 Computational Methods.10.3.1 Subset Selection Overstates Significance.10.4 Windmills.10.4.1 Six Mean Functions.10.4.2 A Computationally Intensive Approach.Problems.11 Nonlinear Regression.11.1 Estimation for Nonlinear Mean Functions.11.2 Inference Assuming Large Samples.11.3 Bootstrap Inference.11.4 References.Problems.12 Logistic Regression.12.1 Binomial Regression.12.1.1 Mean Functions for Binomial Regression.12.2 Fitting Logistic Regression.12.2.1 One-Predictor Example.12.2.2 Many Terms.12.2.3 Deviance.12.2.4 Goodness-of-Fit Tests.12.3 Binomial Random Variables.12.3.1 Maximum Likelihood Estimation.12.3.2 The Log-Likelihood for Logistic Regression.12.4 Generalized Linear Models.Problems.Appendix.A.1 Web Site.A.2 Means and Variances of Random Variables.A.2.1 E Notation.A.2.2 Var Notation.A.2.3 Cov Notation.A.2.4 Conditional Moments.A.3 Least Squares for Simple Regression.A.4 Means and Variances of Least Squares Estimates.A.5 Estimating E(Y |X) Using a Smoother.A.6 A Brief Introduction to Matrices and Vectors.A.6.1 Addition and Subtraction.A.6.2 Multiplication by a Scalar.A.6.3 Matrix Multiplication.A.6.4 Transpose of a Matrix.A.6.5 Inverse of a Matrix.A.6.6 Orthogonality.A.6.7 Linear Dependence and Rank of a Matrix.A.7 Random Vectors.A.8 Least Squares Using Matrices.A.8.1 Properties of Estimates.A.8.2 The Residual Sum of Squares.A.8.3 Estimate of Variance.A.9 The QR Factorization.A.10 Maximum Likelihood Estimates.A.11 The Box-Cox Method for Transformations.A.11.1 Univariate Case.A.11.2 Multivariate Case.A.12 Case Deletion in Linear Regression.References.Author Index.Subject Index."
            },
            "slug": "Applied-Linear-Regression-Weisberg",
            "title": {
                "fragments": [],
                "text": "Applied Linear Regression."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1981
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35043531"
                        ],
                        "name": "A. Dempster",
                        "slug": "A.-Dempster",
                        "structuredName": {
                            "firstName": "Arthur",
                            "lastName": "Dempster",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Dempster"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7890796"
                        ],
                        "name": "N. Laird",
                        "slug": "N.-Laird",
                        "structuredName": {
                            "firstName": "Nan",
                            "lastName": "Laird",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Laird"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2235217"
                        ],
                        "name": "D. Rubin",
                        "slug": "D.-Rubin",
                        "structuredName": {
                            "firstName": "Donald",
                            "lastName": "Rubin",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Rubin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 4193919,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "d36efb9ad91e00faa334b549ce989bfae7e2907a",
            "isKey": false,
            "numCitedBy": 48406,
            "numCiting": 134,
            "paperAbstract": {
                "fragments": [],
                "text": "Vibratory power unit for vibrating conveyers and screens comprising an asynchronous polyphase motor, at least one pair of associated unbalanced masses disposed on the shaft of said motor, with the first mass of a pair of said unbalanced masses being rigidly fastened to said shaft and with said second mass of said pair being movably arranged relative to said first mass, means for controlling and regulating the conveying rate during conveyer operation by varying the rotational speed of said motor between predetermined minimum and maximum values, said second mass being movably outwardly by centrifugal force against the pressure of spring means, said spring means being prestressed in such a manner that said second mass is, at rotational motor speeds lower than said minimum speed, held in its initial position, and at motor speeds between said lower and upper values in positions which are radially offset with respect to the axis of said motor to an extent depending on the value of said rotational motor speed."
            },
            "slug": "Maximum-likelihood-from-incomplete-data-via-the-EM-Dempster-Laird",
            "title": {
                "fragments": [],
                "text": "Maximum likelihood from incomplete data via the EM - algorithm plus discussions on the paper"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1977
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145496497"
                        ],
                        "name": "D. Naidu",
                        "slug": "D.-Naidu",
                        "structuredName": {
                            "firstName": "Desineni",
                            "lastName": "Naidu",
                            "middleNames": [
                                "Subbaram"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Naidu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145047681"
                        ],
                        "name": "S. Naidu",
                        "slug": "S.-Naidu",
                        "structuredName": {
                            "firstName": "S.",
                            "lastName": "Naidu",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Naidu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "69007722"
                        ],
                        "name": "R. Dorf",
                        "slug": "R.-Dorf",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Dorf",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Dorf"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 122603733,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "id": "70dbefa159314b1ed70b812501078dfcc1fa83e0",
            "isKey": false,
            "numCitedBy": 1105,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "INTRODUCTION Classical and Modern Control Optimization Optimal Control Historical Tour About This Book Chapter Overview Problems CALCULUS OF VARIATIONS AND OPTIMAL CONTROL Basic Concepts Optimum of a Function and a Functional The Basic Variational Problem The Second Variation Extrema of Functions with Conditions Extrema of Functionals with Conditions Variational Approach to Optimal Systems Summary of Variational Approach Problems LINEAR QUADRATIC OPTIMAL CONTROL SYSTEMS I Problem Formulation Finite-Time Linear Quadratic Regulator Analytical Solution to the Matrix Differential Riccati Equation Infinite-Time LQR System I Infinite-Time LQR System II Problems LINEAR QUADRATIC OPTIMAL CONTROL SYSTEMS II Linear Quadratic Tracking System: Finite-Time Case LQT System: Infinite-Time Case Fixed-End-Point Regulator System Frequency-Domain Interpretation Problems DISCRETE-TIME OPTIMAL CONTROL SYSTEMS Variational Calculus for Discrete-Time Systems Discrete-Time Optimal Control Systems Discrete-Time Linear State Regulator Systems Steady-State Regulator System Discrete-Time Linear Quadratic Tracking System Frequency-Domain Interpretation Problems PONTRYAGIN MINIMUM PRINCIPLE Constrained Systems Pontryagin Minimum Principle Dynamic Programming The Hamilton-Jacobi-Bellman Equation LQR System using H-J-B Equation CONSTRAINED OPTIMAL CONTROL SYSTEMS Constrained Optimal Control TOC of a Double Integral System Fuel-Optimal Control Systems Minimum Fuel System: LTI System Energy-Optimal Control Systems Optimal Control Systems with State Constraints Problems APPENDICES Vectors and Matrices State Space Analysis MATLAB Files REFERENCES INDEX"
            },
            "slug": "Optimal-Control-Systems-Naidu-Naidu",
            "title": {
                "fragments": [],
                "text": "Optimal control systems"
            },
            "tldr": {
                "abstractSimilarityScore": 68,
                "text": "This book discusses Classical and Modern Control Optimization Optimal Control Historical Tour, Variational Calculus for Discrete-Time Systems, and more."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1965
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40325722"
                        ],
                        "name": "V. Fedorov",
                        "slug": "V.-Fedorov",
                        "structuredName": {
                            "firstName": "Valerii",
                            "lastName": "Fedorov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Fedorov"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2636336"
                        ],
                        "name": "W. J. Studden",
                        "slug": "W.-J.-Studden",
                        "structuredName": {
                            "firstName": "W.",
                            "lastName": "Studden",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. J. Studden"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "98701042"
                        ],
                        "name": "E. Klimko",
                        "slug": "E.-Klimko",
                        "structuredName": {
                            "firstName": "Eugene",
                            "lastName": "Klimko",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Klimko"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 121909870,
            "fieldsOfStudy": [
                "Economics"
            ],
            "id": "65c1a71c5307492782177a9799bef2cdf539ea00",
            "isKey": false,
            "numCitedBy": 2567,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Theory-Of-Optimal-Experiments-Fedorov-Studden",
            "title": {
                "fragments": [],
                "text": "Theory Of Optimal Experiments"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1972
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 137,
                                "start": 127
                            }
                        ],
                        "text": "We rstbrie y review how the statistical approach can be applied to neural networks, as describedin earlier work (MacKay, 1992; Cohn, 1994)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 3409,
                                "start": 278
                            }
                        ],
                        "text": "There are many heuristics for choosing ~ x based on intuition, including choosing places where we don't have data [Whitehead, 1991], where we perform poorly [Linden andWeber, 1993], where we have low con dence [Thrun and M\u007f oller, 1992], where we expect it to change our model [Cohn et al, 1990], and where we previously found data that resulted in learning [Schmidhuber and Storck, 1993]. In this paper we consider how one may select ~ x \\optimally\" from a statistical viewpoint. We rst review how the statistical approach can be applied to neural networks, as described in MacKay [1992] and Cohn [1994]. We then consider two alternative, statisticallybased learning architectures: mixtures of Gaussians and locally weighted regression. While optimal data selection for a neural network is computationally expensive and approximate, we nd that optimal data selection for the two statistical models is e cient and accurate. 2 ACTIVE LEARNING { A STATISTICAL APPROACH We denote the learner's output given input x as \u0177(x). The mean squared error of this output can be expressed as the sum of the learner's bias and variance. The variance 2\u0302 y(x) indicates the learner's uncertainty in its estimate at x.1 Our goal will be to select a new example ~ x such that when the resulting example (~ x; ~ y) is added to the training set, the integrated variance IV is minimized: IV = Z 2\u0302 yP (x)dx: (1) Here, P (x) is the (known) distribution over X. In practice, we will compute a Monte Carlo approximation of this integral, evaluating 2\u0302 y at a number of random points drawn according to P (x). Selecting ~ x so as to minimize IV requires computing ~ 2\u0302 y, the new variance at x given (~ x; ~ y). Until we actually commit to an ~ x, we do not know what corresponding ~ y we will see, so the minimization cannot be performed deterministically.2 Many learning architec1Unless explicitly denoted, \u0177 and 2\u0302 y are functions of x. For simplicity, we present our results in the univariate setting. All results in the paper extend easily to the multivariate case. 2This contrasts with related work by Plutowski and White [1993], which is concerned with ltering an existing data set. tures, however, provide an estimate of P (~ yj~ x) based on current data, so we can use this estimate to compute the expectation of ~ 2\u0302 y. Selecting ~ x to minimize the expected integrated variance provides a solid statistical basis for choosing new examples. 2.1 EXAMPLE: ACTIVE LEARNING WITH A NEURAL NETWORK In this section we review the use of techniques from Optimal Experiment Design (OED) to minimize the estimated variance of a neural network [Fedorov, 1972; MacKay, 1992; Cohn, 1994]. We will assume we have been given a learner \u0177 = f\u0175(), a training set f(xi; yi)gmi=1 and a parameter vector \u0175 that maximizes a likelihood measure. One such measure is the minimum sum squared residual S2 = 1 m m Xi=1 (yi \u0177(xi))2 : The estimated output variance of the network is 2\u0302 y S2 @\u0177(x) @w T @2S2 @w2 1 @\u0177(x) @w The standard OED approach assumes normality and local linearity. These assumptions allow replacing the distribution P (~ yj~ x) by its estimated mean \u0177(~ x) and variance S2. The expected value of the new variance, ~ 2\u0302 y, is then: ~ 2\u0302 y 2\u0302 y 2\u0302 y(x; ~ x) S2 + 2\u0302 y(~ x) ; [MacKay, 1992]: (2) where we de ne \u0177(x; ~ x) S2 @\u0177(x) @w T @2S2 @w2 1 @\u0177(~ x) @w : For empirical results on the predictive power of Equation 2, see Cohn [1994]. The advantages of minimizing this criterion are that it is grounded in statistics, and is optimal given the assumptions."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 105,
                                "start": 79
                            }
                        ],
                        "text": "We review how these techniques have been used with feedforward neural networks [MacKay, 1992; Cohn, 1994]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 296,
                                "start": 287
                            }
                        ],
                        "text": "\u2026points, we have a solidstatistical basis for choosing new examples.2.2 Example: Active Learning with a Neural NetworkIn this section we review the use of techniques from Optimal Experiment Design (OED) tominimize the estimated variance of a neural network (Fedorov, 1972; MacKay, 1992; Cohn,1994)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 169,
                                "start": 159
                            }
                        ],
                        "text": "In practice, @y\u0302=@w may be highly nonlinear, and P (yjx) may be far from Gaussian; inspite of this, empirical results show that it works well on some problems (Cohn, 1994)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 589,
                                "start": 278
                            }
                        ],
                        "text": "There are many heuristics for choosing ~ x based on intuition, including choosing places where we don't have data [Whitehead, 1991], where we perform poorly [Linden andWeber, 1993], where we have low con dence [Thrun and M\u007f oller, 1992], where we expect it to change our model [Cohn et al, 1990], and where we previously found data that resulted in learning [Schmidhuber and Storck, 1993]. In this paper we consider how one may select ~ x \\optimally\" from a statistical viewpoint. We rst review how the statistical approach can be applied to neural networks, as described in MacKay [1992] and Cohn [1994]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 192,
                                "start": 181
                            }
                        ],
                        "text": "It is worth noting that on the Arm2D domain, this form of locally weighted regression alsosigni cantly outperforms both the mixture of Gaussians and the neural networks discussedby Cohn (1994)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 230,
                                "start": 189
                            }
                        ],
                        "text": "1 EXAMPLE: ACTIVE LEARNING WITH A NEURAL NETWORK In this section we review the use of techniques from Optimal Experiment Design (OED) to minimize the estimated variance of a neural network [Fedorov, 1972; MacKay, 1992; Cohn, 1994]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4077,
                                "start": 278
                            }
                        ],
                        "text": "There are many heuristics for choosing ~ x based on intuition, including choosing places where we don't have data [Whitehead, 1991], where we perform poorly [Linden andWeber, 1993], where we have low con dence [Thrun and M\u007f oller, 1992], where we expect it to change our model [Cohn et al, 1990], and where we previously found data that resulted in learning [Schmidhuber and Storck, 1993]. In this paper we consider how one may select ~ x \\optimally\" from a statistical viewpoint. We rst review how the statistical approach can be applied to neural networks, as described in MacKay [1992] and Cohn [1994]. We then consider two alternative, statisticallybased learning architectures: mixtures of Gaussians and locally weighted regression. While optimal data selection for a neural network is computationally expensive and approximate, we nd that optimal data selection for the two statistical models is e cient and accurate. 2 ACTIVE LEARNING { A STATISTICAL APPROACH We denote the learner's output given input x as \u0177(x). The mean squared error of this output can be expressed as the sum of the learner's bias and variance. The variance 2\u0302 y(x) indicates the learner's uncertainty in its estimate at x.1 Our goal will be to select a new example ~ x such that when the resulting example (~ x; ~ y) is added to the training set, the integrated variance IV is minimized: IV = Z 2\u0302 yP (x)dx: (1) Here, P (x) is the (known) distribution over X. In practice, we will compute a Monte Carlo approximation of this integral, evaluating 2\u0302 y at a number of random points drawn according to P (x). Selecting ~ x so as to minimize IV requires computing ~ 2\u0302 y, the new variance at x given (~ x; ~ y). Until we actually commit to an ~ x, we do not know what corresponding ~ y we will see, so the minimization cannot be performed deterministically.2 Many learning architec1Unless explicitly denoted, \u0177 and 2\u0302 y are functions of x. For simplicity, we present our results in the univariate setting. All results in the paper extend easily to the multivariate case. 2This contrasts with related work by Plutowski and White [1993], which is concerned with ltering an existing data set. tures, however, provide an estimate of P (~ yj~ x) based on current data, so we can use this estimate to compute the expectation of ~ 2\u0302 y. Selecting ~ x to minimize the expected integrated variance provides a solid statistical basis for choosing new examples. 2.1 EXAMPLE: ACTIVE LEARNING WITH A NEURAL NETWORK In this section we review the use of techniques from Optimal Experiment Design (OED) to minimize the estimated variance of a neural network [Fedorov, 1972; MacKay, 1992; Cohn, 1994]. We will assume we have been given a learner \u0177 = f\u0175(), a training set f(xi; yi)gmi=1 and a parameter vector \u0175 that maximizes a likelihood measure. One such measure is the minimum sum squared residual S2 = 1 m m Xi=1 (yi \u0177(xi))2 : The estimated output variance of the network is 2\u0302 y S2 @\u0177(x) @w T @2S2 @w2 1 @\u0177(x) @w The standard OED approach assumes normality and local linearity. These assumptions allow replacing the distribution P (~ yj~ x) by its estimated mean \u0177(~ x) and variance S2. The expected value of the new variance, ~ 2\u0302 y, is then: ~ 2\u0302 y 2\u0302 y 2\u0302 y(x; ~ x) S2 + 2\u0302 y(~ x) ; [MacKay, 1992]: (2) where we de ne \u0177(x; ~ x) S2 @\u0177(x) @w T @2S2 @w2 1 @\u0177(~ x) @w : For empirical results on the predictive power of Equation 2, see Cohn [1994]. The advantages of minimizing this criterion are that it is grounded in statistics, and is optimal given the assumptions. Furthermore, the criterion is continuous and di erentiable. As such, it is applicable in continuous domains with continuous action spaces, and allows hillclimbing to nd the \\best\" ~ x. For neural networks, however, this approach has many disadvantages. The criterion relies on simpli cations and strong assumptions which hold only approximately. Computing the variance estimate requires inversion of a jwj jwj matrix for each new example, and incorporating new examples into the network requires expensive retraining. Paass and Kindermann [1995] discuss an approach which addresses some of these problems."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 29,
                                "start": 19
                            }
                        ],
                        "text": "See, for example, (Cohn, 1994).4."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 153,
                                "start": 141
                            }
                        ],
                        "text": "In the second set of experiments, we applied the techniques of this paper to learning the kinematics of a twojoint planar arm (Figure 5; see Cohn [1994] for details)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 101,
                                "start": 90
                            }
                        ],
                        "text": "Experimental ResultsFor an experimental testbed, we used the \\Arm2D\" problem described by Cohn (1994)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 605,
                                "start": 278
                            }
                        ],
                        "text": "There are many heuristics for choosing ~ x based on intuition, including choosing places where we don't have data [Whitehead, 1991], where we perform poorly [Linden andWeber, 1993], where we have low con dence [Thrun and M\u007f oller, 1992], where we expect it to change our model [Cohn et al, 1990], and where we previously found data that resulted in learning [Schmidhuber and Storck, 1993]. In this paper we consider how one may select ~ x \\optimally\" from a statistical viewpoint. We rst review how the statistical approach can be applied to neural networks, as described in MacKay [1992] and Cohn [1994]. We then consider two alternative, statisticallybased learning architectures: mixtures of Gaussians and locally weighted regression."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 15,
                                "start": 4
                            }
                        ],
                        "text": "See Cohn (1994) for details."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 2110,
                                "start": 278
                            }
                        ],
                        "text": "There are many heuristics for choosing ~ x based on intuition, including choosing places where we don't have data [Whitehead, 1991], where we perform poorly [Linden andWeber, 1993], where we have low con dence [Thrun and M\u007f oller, 1992], where we expect it to change our model [Cohn et al, 1990], and where we previously found data that resulted in learning [Schmidhuber and Storck, 1993]. In this paper we consider how one may select ~ x \\optimally\" from a statistical viewpoint. We rst review how the statistical approach can be applied to neural networks, as described in MacKay [1992] and Cohn [1994]. We then consider two alternative, statisticallybased learning architectures: mixtures of Gaussians and locally weighted regression. While optimal data selection for a neural network is computationally expensive and approximate, we nd that optimal data selection for the two statistical models is e cient and accurate. 2 ACTIVE LEARNING { A STATISTICAL APPROACH We denote the learner's output given input x as \u0177(x). The mean squared error of this output can be expressed as the sum of the learner's bias and variance. The variance 2\u0302 y(x) indicates the learner's uncertainty in its estimate at x.1 Our goal will be to select a new example ~ x such that when the resulting example (~ x; ~ y) is added to the training set, the integrated variance IV is minimized: IV = Z 2\u0302 yP (x)dx: (1) Here, P (x) is the (known) distribution over X. In practice, we will compute a Monte Carlo approximation of this integral, evaluating 2\u0302 y at a number of random points drawn according to P (x). Selecting ~ x so as to minimize IV requires computing ~ 2\u0302 y, the new variance at x given (~ x; ~ y). Until we actually commit to an ~ x, we do not know what corresponding ~ y we will see, so the minimization cannot be performed deterministically.2 Many learning architec1Unless explicitly denoted, \u0177 and 2\u0302 y are functions of x. For simplicity, we present our results in the univariate setting. All results in the paper extend easily to the multivariate case. 2This contrasts with related work by Plutowski and White [1993], which is concerned with ltering an existing data set."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Neural network exploration using"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35043531"
                        ],
                        "name": "A. Dempster",
                        "slug": "A.-Dempster",
                        "structuredName": {
                            "firstName": "Arthur",
                            "lastName": "Dempster",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Dempster"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7890796"
                        ],
                        "name": "N. Laird",
                        "slug": "N.-Laird",
                        "structuredName": {
                            "firstName": "Nan",
                            "lastName": "Laird",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Laird"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2235217"
                        ],
                        "name": "D. Rubin",
                        "slug": "D.-Rubin",
                        "structuredName": {
                            "firstName": "Donald",
                            "lastName": "Rubin",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Rubin"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 60618317,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "ecb37a4e32d6faef4ac99b45d9ab9b2d92693985",
            "isKey": false,
            "numCitedBy": 1169,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Max-imum-Likelihood-from-Incomplete-Data-Dempster-Laird",
            "title": {
                "fragments": [],
                "text": "Max-imum Likelihood from Incomplete Data"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1972
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "66517364"
                        ],
                        "name": "A. Butkovskiy",
                        "slug": "A.-Butkovskiy",
                        "structuredName": {
                            "firstName": "Anatoliy",
                            "lastName": "Butkovskiy",
                            "middleNames": [
                                "Grigorjevich"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Butkovskiy"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 45,
                                "start": 28
                            }
                        ],
                        "text": "The sub eld of dual control (Fe'ldbaum, 1965) is speci cally concerned with nding an optimal balance of exploration and control while learning."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 44,
                                "start": 29
                            }
                        ],
                        "text": "The sub eld of dual control (Fe'ldbaum, 1965) is speci cally concerned with nding anoptimal balance of exploration and control while learning."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 60331799,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4343b7f3447b8d2f5e48cdd3e542ac3a015380d9",
            "isKey": false,
            "numCitedBy": 400,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Optimal-control-of-systems-Butkovskiy",
            "title": {
                "fragments": [],
                "text": "Optimal control of systems"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1966
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Regression by local tting"
            },
            "venue": {
                "fragments": [],
                "text": "Journal of Econometrics"
            },
            "year": 1988
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 94,
                                "start": 84
                            }
                        ],
                        "text": "Work inprogress examines e ective ways of measuring and optimally eliminating bias (Cohn, 1995);future work will examine how to jointly minimize both bias and variance to produce acriterion that truly minimizes the learner's expected error."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Minimizing statistical bias with queries. AI Lab memo AIM- 1552, Massachusetts Institute of Technology. Available by anonymous ftp from publications"
            },
            "venue": {
                "fragments": [],
                "text": "Minimizing statistical bias with queries. AI Lab memo AIM- 1552, Massachusetts Institute of Technology. Available by anonymous ftp from publications"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 131,
                                "start": 114
                            }
                        ],
                        "text": "There are many heuristics for choosing ~ x based on intuition, including choosing places where we don't have data [Whitehead, 1991], where we perform poorly [Linden andWeber, 1993], where we have low con dence [Thrun and M\u007foller, 1992], where we expect it to change our model [Cohn et al, 1990], and where we previously found data that resulted in learning [Schmidhuber and Storck, 1993]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 109,
                                "start": 94
                            }
                        ],
                        "text": "There are many heuristics for choosing ~x, including choosing places where we don't havedata (Whitehead, 1991), where we perform poorly (Linden & Weber, 1993), where we havelow con dence (Thrun & M oller, 1992), where we expect it to change our model (Cohn,Atlas, & Ladner, 1990, 1994), and where we\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A study of cooperative mechanisms for faster reinforcement learning. TR-365"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1991
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Statistical Analysis of Finite Mixture"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1985
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 319,
                                "start": 240
                            }
                        ],
                        "text": "The mixture of Gaussians model is a powerful estimation and prediction technique with roots in the statistics literature (Titterington, Smith, & Makov, 1985); it has, over the last few years, been adopted by researchers in machine learning (Cheeseman et al., 1988; Nowlan, 1991; Specht, 1991; Ghahramani & Jordan, 1994)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 237,
                                "start": 215
                            }
                        ],
                        "text": "\u2026model is a powerful estimation and prediction technique withroots in the statistics literature (Titterington, Smith, & Makov, 1985); it has, over the lastfew years, been adopted by researchers in machine learning (Cheeseman et al., 1988; Nowlan,1991; Specht, 1991; Ghahramani & Jordan, 1994)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Bayesian classi cation"
            },
            "venue": {
                "fragments": [],
                "text": "The 7th National Conference on Arti cial Intelligence,"
            },
            "year": 1988
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Neural networks and the biassvariance dilemma"
            },
            "venue": {
                "fragments": [],
                "text": "Neural networks and the biassvariance dilemma"
            },
            "year": 1158
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 52,
                                "start": 27
                            }
                        ],
                        "text": "Another technique, used by Schaal and Atkeson (1994), sets k tominimize the crossvalidated error on the training set."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 169,
                                "start": 147
                            }
                        ],
                        "text": "One recent study demonstrated that LWR was suitable for real-time control by constructingan LWR-based system that learned a di cult juggling task (Schaal & Atkeson, 1994). o o o o o o o o o o o o o xFigure 2: In locally weighted regression, points are weighted by proximity to the currentx in\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Robot Juggling: An Implementation of Memory-based"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "1 9 9 0 ) T raining Connectionist Networks with Queries and Selective Sampling"
            },
            "venue": {
                "fragments": [],
                "text": "Advances in Neural Information Processing Systems"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 157,
                                "start": 137
                            }
                        ],
                        "text": "There are many heuristics for choosing ~x, including choosing places where we don't havedata (Whitehead, 1991), where we perform poorly (Linden & Weber, 1993), where we havelow con dence (Thrun & M oller, 1992), where we expect it to change our model (Cohn,Atlas, & Ladner, 1990, 1994), and where we\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 161,
                                "start": 137
                            }
                        ],
                        "text": "There are many heuristics for choosing x based on intuition, including choosing places where we don't have data, where we perform poorly [Linden and Weber, 1993], where we have low confidence [Thrun and Moller, 1992], where we expect it"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Implementing inner drive by competence reflection"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. 2nd Int. Conf. on Simulation of Adaptive Behavior,"
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 157,
                                "start": 137
                            }
                        ],
                        "text": "There are many heuristics for choosing ~x, including choosing places where we don't havedata (Whitehead, 1991), where we perform poorly (Linden & Weber, 1993), where we havelow con dence (Thrun & M oller, 1992), where we expect it to change our model (Cohn,Atlas, & Ladner, 1990, 1994), and where we\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Implementing inner drive b y competence reeection"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 2nd International Conference on Simulation of Adaptive Behavior"
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 131,
                                "start": 114
                            }
                        ],
                        "text": "There are many heuristics for choosing ~ x based on intuition, including choosing places where we don't have data [Whitehead, 1991], where we perform poorly [Linden andWeber, 1993], where we have low con dence [Thrun and M\u007f oller, 1992], where we expect it to change our model [Cohn et al, 1990], and where we previously found data that resulted in learning [Schmidhuber and Storck, 1993]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 109,
                                "start": 94
                            }
                        ],
                        "text": "There are many heuristics for choosing ~x, including choosing places where we don't havedata (Whitehead, 1991), where we perform poorly (Linden & Weber, 1993), where we havelow con dence (Thrun & M oller, 1992), where we expect it to change our model (Cohn,Atlas, & Ladner, 1990, 1994), and where we\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A study of cooperative mecha"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1991
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Bayesian classiication"
            },
            "venue": {
                "fragments": [],
                "text": "AAAI 88, The 7th National Conference o n A rtiicial Intelligence"
            },
            "year": 1988
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 171,
                                "start": 114
                            }
                        ],
                        "text": "3 MIXTURES OF GAUSSIANS The mixture of Gaussians model is gaining popularity among machine learning practitioners [Nowlan, 1991; Specht, 1991; Ghahramani and Jordan, 1994]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 250,
                                "start": 239
                            }
                        ],
                        "text": "\u2026model is a powerful estimation and prediction technique withroots in the statistics literature (Titterington, Smith, & Makov, 1985); it has, over the lastfew years, been adopted by researchers in machine learning (Cheeseman et al., 1988; Nowlan,1991; Specht, 1991; Ghahramani & Jordan, 1994)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Soft Competitive Adaptation"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1991
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 109,
                                "start": 94
                            }
                        ],
                        "text": "There are many heuristics for choosing ~x, including choosing places where we don't havedata (Whitehead, 1991), where we perform poorly (Linden & Weber, 1993), where we havelow con dence (Thrun & M oller, 1992), where we expect it to change our model (Cohn,Atlas, & Ladner, 1990, 1994), and where we\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 112,
                                "start": 95
                            }
                        ],
                        "text": "There are many heuristics for choosing ~ x, including choosing places where we don't have data (Whitehead, 1991), where we perform poorly (Linden & Weber, 1993), where we have low con dence (Thrun & M\u007f oller, 1992), where we expect it to change our model (Cohn, Atlas, & Ladner, 1990, 1994), and where we previously found data that resulted in learning (Schmidhuber & Storck, 1993)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A study of cooperative mechanisms for faster reinforcement learning"
            },
            "venue": {
                "fragments": [],
                "text": "A study of cooperative mechanisms for faster reinforcement learning"
            },
            "year": 1991
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 163,
                                "start": 139
                            }
                        ],
                        "text": "There are many heuristics for choosing ~ x based on intuition, including choosing places where we don't have data, where we perform poorly [Linden and Weber, 1993], where we have low con dence [Thrun and M\u007f oller, 1992], where we expect it"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 157,
                                "start": 137
                            }
                        ],
                        "text": "There are many heuristics for choosing ~x, including choosing places where we don't havedata (Whitehead, 1991), where we perform poorly (Linden & Weber, 1993), where we havelow con dence (Thrun & M oller, 1992), where we expect it to change our model (Cohn,Atlas, & Ladner, 1990, 1994), and where we\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Implementing inner drive by competence re ection"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Training Connectionist Networks with Queries"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1990
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Regression by local fitting"
            },
            "venue": {
                "fragments": [],
                "text": "Journal of Econometrics"
            },
            "year": 1988
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 216,
                                "start": 199
                            }
                        ],
                        "text": "When actions/queries are selected properly, the data requirements for some problemsdecrease drastically, and some NP-complete learning problems become polynomial in com-putation time (Angluin, 1988; Baum & Lang, 1991)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Neural network algorithms that learn in polynomial time"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1991
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 172,
                                "start": 149
                            }
                        ],
                        "text": "We then show how the sameprinciples may be used to select data for two alternative, statistically-based learning ar-chitectures: mixtures of Gaussians and locally weighted regression."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 157,
                                "start": 137
                            }
                        ],
                        "text": "There are many heuristics for choosing ~x, including choosing places where we don't havedata (Whitehead, 1991), where we perform poorly (Linden & Weber, 1993), where we havelow con dence (Thrun & M oller, 1992), where we expect it to change our model (Cohn,Atlas, & Ladner, 1990, 1994), and where we\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Implementing inner drive by competence reeection"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. 2nd Int. Conf. on Simulation of Adaptive Behavior"
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Optimal control systems Active Learning with Statistical Models"
            },
            "venue": {
                "fragments": [],
                "text": "Optimal control systems Active Learning with Statistical Models"
            },
            "year": 1965
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Neural networks and the bias/variance"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 109,
                                "start": 94
                            }
                        ],
                        "text": "There are many heuristics for choosing ~x, including choosing places where we don't havedata (Whitehead, 1991), where we perform poorly (Linden & Weber, 1993), where we havelow con dence (Thrun & M oller, 1992), where we expect it to change our model (Cohn,Atlas, & Ladner, 1990, 1994), and where we\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A study of cooperative m e c hanisms for faster reinforcement learning"
            },
            "venue": {
                "fragments": [],
                "text": "A study of cooperative m e c hanisms for faster reinforcement learning"
            },
            "year": 1991
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 52,
                                "start": 27
                            }
                        ],
                        "text": "Another technique, used by Schaal and Atkeson (1994), sets k tominimize the crossvalidated error on the training set."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 169,
                                "start": 147
                            }
                        ],
                        "text": "One recent study demonstrated that LWR was suitable for real-time control by constructingan LWR-based system that learned a di cult juggling task (Schaal & Atkeson, 1994). o o o o o o o o o o o o o xFigure 2: In locally weighted regression, points are weighted by proximity to the currentx in\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Robot Juggling: An Implementation of Memory-based Learning. Control Systems Magazine, 14(1):57{71"
            },
            "venue": {
                "fragments": [],
                "text": "Neural Networks,"
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 131,
                                "start": 101
                            }
                        ],
                        "text": "to change our model [Cohn et al, 1990], and where we previously found data that resulted in learning [Schmidhuber and Storck, 1993]."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 297,
                                "start": 271
                            }
                        ],
                        "text": "\u2026don't havedata (Whitehead, 1991), where we perform poorly (Linden & Weber, 1993), where we havelow con dence (Thrun & M oller, 1992), where we expect it to change our model (Cohn,Atlas, & Ladner, 1990, 1994), and where we previously found data that resulted in learning(Schmidhuber & Storck, 1993)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Reinforcement driven information acquisition"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 122,
                                "start": 104
                            }
                        ],
                        "text": "The favored technique for this kind of optimization is usually a form of re-sponse surface methodology (Box & Draper, 1987), which performs experiments that guidehill-climbing through the input space."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Empirical model-building and response"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1987
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Neural networks and the bias / variancedilemma"
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Maximum likelihood from incomplete datavia the EM algorithm"
            },
            "venue": {
                "fragments": [],
                "text": "J . Royal Statistical Society Series B"
            },
            "year": 1977
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "( 1 9 8 8 ) Regression by local tting"
            },
            "venue": {
                "fragments": [],
                "text": "Journal of Econometrics"
            }
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 10,
            "methodology": 22,
            "result": 4
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 55,
        "totalPages": 6
    },
    "page_url": "https://www.semanticscholar.org/paper/Active-Learning-with-Statistical-Models-Cohn-Ghahramani/1150f9289c6151506e3f7cf0e6ebbcfd49f1dace?sort=total-citations"
}