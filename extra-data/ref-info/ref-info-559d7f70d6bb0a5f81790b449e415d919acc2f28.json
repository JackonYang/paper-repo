{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145820427"
                        ],
                        "name": "Fei Yin",
                        "slug": "Fei-Yin",
                        "structuredName": {
                            "firstName": "Fei",
                            "lastName": "Yin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Fei Yin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49046935"
                        ],
                        "name": "Cheng-Lin Liu",
                        "slug": "Cheng-Lin-Liu",
                        "structuredName": {
                            "firstName": "Cheng-Lin",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Cheng-Lin Liu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 6,
                                "start": 2
                            }
                        ],
                        "text": "Since the Kruskal\u2019s MST algorithm is well known and can be easily found in the literature, we will not give its details in this paper."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "The distance metric is specially treated in Section 4."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 894582,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8414ecb8e4e127ce5e45d2f6440e77955dbb7e56",
            "isKey": false,
            "numCitedBy": 27,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "Text line extraction from unconstrained handwritten documents is a challenge because the text lines are often skewed and curved and the space between lines is not obvious. To solve this problem, we propose an approach based on minimum spanning tree (MST) clustering with new distance measures. First, the connected components of the document image are grouped into a tree by MST clustering with a new distance measure. The edges of the tree are then dynamically cut to form text lines by using a new objective function for finding the number of clusters. This approach is totally parameter-free and can apply to various documents with multi-skewed and curved lines. Experiments on handwritten Chinese documents demonstrate the effectiveness of the approach."
            },
            "slug": "Handwritten-text-line-extraction-based-on-minimum-Yin-Liu",
            "title": {
                "fragments": [],
                "text": "Handwritten text line extraction based on minimum spanning tree clustering"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "An approach based on minimum spanning tree (MST) clustering with new distance measures that is totally parameter-free and can apply to various documents with multi-skewed and curved lines is proposed."
            },
            "venue": {
                "fragments": [],
                "text": "2007 International Conference on Wavelet Analysis and Pattern Recognition"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2153682487"
                        ],
                        "name": "Yi Li",
                        "slug": "Yi-Li",
                        "structuredName": {
                            "firstName": "Yi",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yi Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2145273401"
                        ],
                        "name": "Yefeng Zheng",
                        "slug": "Yefeng-Zheng",
                        "structuredName": {
                            "firstName": "Yefeng",
                            "lastName": "Zheng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yefeng Zheng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48471936"
                        ],
                        "name": "D. Doermann",
                        "slug": "D.-Doermann",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Doermann",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Doermann"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144230620"
                        ],
                        "name": "Stefan Jaeger",
                        "slug": "Stefan-Jaeger",
                        "structuredName": {
                            "firstName": "Stefan",
                            "lastName": "Jaeger",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Stefan Jaeger"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 80,
                                "start": 76
                            }
                        ],
                        "text": "Most of these errors can be corrected using some heuristic rules similar to [27]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 15,
                                "start": 11
                            }
                        ],
                        "text": "Similar to [27], we calculate the MatchScore matrix between a detected text line and a groundtruthed line:"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[27] is an effective hybrid approach for unconstrained handwritten documents."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 106,
                                "start": 102
                            }
                        ],
                        "text": "Nevertheless, the level set based method turns out to be more computationally demanding: according to [27], the segmentation of an image of 2000\u00d71500 pixels costs about 20 seconds on a CPU of 1."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[27] because that method is non-trivial to implement and their image database is not available for our evaluation."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 9187881,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "64e7f164c404d5b6d46036644fdbab0d73a1f31e",
            "isKey": true,
            "numCitedBy": 204,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": "Text line segmentation in freestyle handwritten documents remains an open document analysis problem. Curvilinear text lines and small gaps between neighboring text lines present a challenge to algorithms developed for machine printed or hand-printed documents. In this paper, we propose a novel approach based on density estimation and a state-of-the-art image segmentation technique, the level set method. From an input document image, we estimate a probability map, where each element represents the probability that the underlying pixel belongs to a text line. The level set method is then exploited to determine the boundary of neighboring text lines by evolving an initial estimate. Unlike connected component based methods ( [1], [2] for example), the proposed algorithm does not use any script-specific knowledge. Extensive quantitative experiments on freestyle handwritten documents with diverse scripts, such as Arabic, Chinese, Korean, and Hindi, demonstrate that our algorithm consistently outperforms previous methods. Further experiments show the proposed algorithm is robust to scale change, rotation, and noise."
            },
            "slug": "Script-Independent-Text-Line-Segmentation-in-Li-Zheng",
            "title": {
                "fragments": [],
                "text": "Script-Independent Text Line Segmentation in Freestyle Handwritten Documents"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A novel approach based on density estimation and a state-of-the-art image segmentation technique, the level set method, which consistently outperforms previous methods on text line segmentation in freestyle handwritten documents."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2066310463"
                        ],
                        "name": "M. Arivazhagan",
                        "slug": "M.-Arivazhagan",
                        "structuredName": {
                            "firstName": "Manivannan",
                            "lastName": "Arivazhagan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Arivazhagan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2334238"
                        ],
                        "name": "H. Srinivasan",
                        "slug": "H.-Srinivasan",
                        "structuredName": {
                            "firstName": "Harish",
                            "lastName": "Srinivasan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Srinivasan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1696384"
                        ],
                        "name": "S. Srihari",
                        "slug": "S.-Srihari",
                        "structuredName": {
                            "firstName": "Sargur",
                            "lastName": "Srihari",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Srihari"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 79,
                                "start": 76
                            }
                        ],
                        "text": "Zahour et al. proposed a partial projection-based method combined with slant detection and partial contour tracing [2]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Keywords: Handwritten Text Line Segmentation, Clustering, Minimal Spanning Tree (MST), Distance Metric Learning."
                    },
                    "intents": []
                }
            ],
            "corpusId": 10834729,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "48fc23665dfecdd4ecef6eb7f24b24076f194d6a",
            "isKey": false,
            "numCitedBy": 135,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "A new technique to segment a handwritten document into distinct lines of text is presented. Line segmentation is the first and the most critical pre-processing step for a document recognition/analysis task. The proposed algorithm starts, by obtaining an initial set of candidate lines from the piece-wise projection profile of the document. The lines traverse around any obstructing handwritten connected component by associating it to the line above or below. A decision of associating such a component is made by (i) modeling the lines as bivariate Gaussian densities and evaluating the probability of the component under each Gaussian or (ii)the probability obtained from a distance metric. The proposed method is robust to handle skewed documents and those with lines running into each other. Experimental results show that on 720 documents (which includes English, Arabic and children's handwriting) containing a total of 11, 581 lines, 97.31% of the lines were segmented correctly. On an experiment over 200 handwritten images with 78, 902 connected components, 98.81% of them were associated to the correct lines."
            },
            "slug": "A-statistical-approach-to-line-segmentation-in-Arivazhagan-Srinivasan",
            "title": {
                "fragments": [],
                "text": "A statistical approach to line segmentation in handwritten documents"
            },
            "tldr": {
                "abstractSimilarityScore": 71,
                "text": "A new technique to segment a handwritten document into distinct lines of text is presented, which is robust to handle skewed documents and those with lines running into each other."
            },
            "venue": {
                "fragments": [],
                "text": "Electronic Imaging"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2051579"
                        ],
                        "name": "Douglas J. Kennard",
                        "slug": "Douglas-J.-Kennard",
                        "structuredName": {
                            "firstName": "Douglas",
                            "lastName": "Kennard",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Douglas J. Kennard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144055367"
                        ],
                        "name": "W. Barrett",
                        "slug": "W.-Barrett",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Barrett",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Barrett"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Some efforts have been devoted to the difficult problem of handwritten text line segmentation [ 1-6 ]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Kennard and Barrett use a similar method with slight extension [ 5 ] to deal with free-form handwritten historical documents."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 12751642,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "20fa388984f966a88e59ed42fd7cbe79695ee5a8",
            "isKey": false,
            "numCitedBy": 55,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "We present an approach to finding (and separating) lines of text in free-form handwritten historical document images. After preprocessing, our method uses the count of foreground/background transitions in a binarized image to determine areas of the document that are likely to be text lines. Alternatively, an adaptive local connectivity map (ALCM) found in the literature can be used for this step of the process. We then use a min-cut/max-flow graph cut algorithm to split up text areas that appear to encompass more than one line of text. After removing text lines containing relatively little text information (or merging them with nearby text lines), we create output images for each line. A grayscale output image is created, as well as a special mask image containing both the foreground and information flagging ambiguous pixels. Foreground pixels that belong to other text lines are removed from the output images to provide cleaner line images useful for further processing. While some refinement is still necessary, the result of early experimentation with our method is encouraging"
            },
            "slug": "Separating-lines-of-text-in-free-form-handwritten-Kennard-Barrett",
            "title": {
                "fragments": [],
                "text": "Separating lines of text in free-form handwritten historical documents"
            },
            "tldr": {
                "abstractSimilarityScore": 66,
                "text": "This work presents an approach to finding (and separating) lines of text in free-form handwritten historical document images by using a min-cut/max-flow graph cut algorithm to split up text areas that appear to encompass more than one line of text."
            },
            "venue": {
                "fragments": [],
                "text": "Second International Conference on Document Image Analysis for Libraries (DIAL'06)"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2115871"
                        ],
                        "name": "C. Weliwitage",
                        "slug": "C.-Weliwitage",
                        "structuredName": {
                            "firstName": "C.",
                            "lastName": "Weliwitage",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Weliwitage"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32691211"
                        ],
                        "name": "A. Harvey",
                        "slug": "A.-Harvey",
                        "structuredName": {
                            "firstName": "Alan",
                            "lastName": "Harvey",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Harvey"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144813074"
                        ],
                        "name": "A. Jennings",
                        "slug": "A.-Jennings",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Jennings",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Jennings"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "013 line detection techniques, such as projection analysis [1\u20137] and K-nearest neighbor connected components (CCs) grouping [12\u201314], are not able to segment handwritten text lines successfully."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "[7] describe a modified projection-based method called cut text minimization (CTM), in which an optimization technique is applied to minimize the text pixels cut while tracking the boundary between two lines after the start points of lines are found using projection."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Many efforts have been devoted to the difficult problem of handwritten text line segmentation [1\u201328]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 13580763,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a88af3ba8cd718b877512288a0bb396650a0e871",
            "isKey": false,
            "numCitedBy": 45,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, a method of text segmentation into lines of text known as cut text minimization (CTM) is described. Results applying the CTM method to the NIST data base examples of fifty two word handwritten paragraphs of the American Constitutions are given. The method uses a modified projection method to obtain starting points. Then an optimisation technique is applied which varies the cutting angle and start location to minimize the text pixels cut while tracking between the text lines. Also the method attempts to track around projecting ascenders or descenders by a line following technique. A comparison with the projections method is given. From the results, it is evident that the method is successful on quite distorted documents, and can correctly cut the text block into text lines with minimal incorrect partitioning of data into adjacent lines even when text lines have varying slope and there are penetrations into the space of adjacent lines. The CTM method does not assume text lines have a constant slope."
            },
            "slug": "Handwritten-Document-Offline-Text-Line-Segmentation-Weliwitage-Harvey",
            "title": {
                "fragments": [],
                "text": "Handwritten Document Offline Text Line Segmentation"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "It is evident that the CTM method is successful on quite distorted documents, and can correctly cut the text block into text lines with minimal incorrect partitioning of data into adjacent lines even when text lines have varying slope and there are penetrations into the space of adjacent lines."
            },
            "venue": {
                "fragments": [],
                "text": "Digital Image Computing: Techniques and Applications (DICTA'05)"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2320185"
                        ],
                        "name": "Abderrazak Zahour",
                        "slug": "Abderrazak-Zahour",
                        "structuredName": {
                            "firstName": "Abderrazak",
                            "lastName": "Zahour",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Abderrazak Zahour"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2080593310"
                        ],
                        "name": "B. Taconet",
                        "slug": "B.-Taconet",
                        "structuredName": {
                            "firstName": "Bruno",
                            "lastName": "Taconet",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Taconet"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144484822"
                        ],
                        "name": "P. Mercy",
                        "slug": "P.-Mercy",
                        "structuredName": {
                            "firstName": "P.",
                            "lastName": "Mercy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Mercy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2102325551"
                        ],
                        "name": "Said Ramdane",
                        "slug": "Said-Ramdane",
                        "structuredName": {
                            "firstName": "Said",
                            "lastName": "Ramdane",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Said Ramdane"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Some efforts have been devoted to the difficult problem of handwritten text line segmentation [ 1-6 ]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Zahour et al. proposed a partial projection-based method combined with slant detection and partial contour tracing [ 2 ]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 35215159,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "36c0cbf2c7073d9bf5812d8a709a00241bb5f2ab",
            "isKey": false,
            "numCitedBy": 120,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes a text-line extraction based method. The typical segmentation for a printed binary document is based on the horizontal projection analysis and then the regrouping of the connected components. These techniques can't be used for handwritten unconstrained text because data frequently contain undulations and shifts in the baseline, baseline-skew variability and inter-line distance variability. So, we think that the border line for a handwritten unconstrained documents should be a collection of horizontal line segments. From this point of view, we use a partial contour following based method to detect the separating lines. In the current version of our algorithm, we proceed to text slant detection, text line number evaluation by using partial projection. Then we carry out a partial contour following of every line; first in the direction of the writing, then in the opposite direction. After the treatment, the adjacent lines are separated. In the experimental session, we describe the application of the algorithm used for the extraction of text line. Database images contains about one hundred handwritten Arabic texts written by different writers. Results about diacritical points affectation are also reported."
            },
            "slug": "Arabic-hand-written-text-line-extraction-Zahour-Taconet",
            "title": {
                "fragments": [],
                "text": "Arabic hand-written text-line extraction"
            },
            "tldr": {
                "abstractSimilarityScore": 57,
                "text": "This paper describes a text-line extraction based method that uses a partial contour following based method to detect the separating lines and describes the application of the algorithm used for the extraction of text line."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of Sixth International Conference on Document Analysis and Recognition"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145096292"
                        ],
                        "name": "Subhadip Basu",
                        "slug": "Subhadip-Basu",
                        "structuredName": {
                            "firstName": "Subhadip",
                            "lastName": "Basu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Subhadip Basu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2004266"
                        ],
                        "name": "C. Chaudhuri",
                        "slug": "C.-Chaudhuri",
                        "structuredName": {
                            "firstName": "Chitrita",
                            "lastName": "Chaudhuri",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Chaudhuri"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143995288"
                        ],
                        "name": "M. Kundu",
                        "slug": "M.-Kundu",
                        "structuredName": {
                            "firstName": "Mahantapas",
                            "lastName": "Kundu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Kundu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1729425"
                        ],
                        "name": "M. Nasipuri",
                        "slug": "M.-Nasipuri",
                        "structuredName": {
                            "firstName": "Mita",
                            "lastName": "Nasipuri",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Nasipuri"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143701816"
                        ],
                        "name": "D. K. Basu",
                        "slug": "D.-K.-Basu",
                        "structuredName": {
                            "firstName": "Dipak",
                            "lastName": "Basu",
                            "middleNames": [
                                "Kumar"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. K. Basu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "From a different viewpoint, some researchers proposed water reservoir based top-down methods [9\u201311]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Many efforts have been devoted to the difficult problem of handwritten text line segmentation [1\u201328]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14307584,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6dc378bef6c2f7a70d095ad892f4abd46749395b",
            "isKey": false,
            "numCitedBy": 83,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Text-line-extraction-from-multi-skewed-handwritten-Basu-Chaudhuri",
            "title": {
                "fragments": [],
                "text": "Text line extraction from multi-skewed handwritten documents"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit."
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1398902377"
                        ],
                        "name": "Laurence Likforman-Sulem",
                        "slug": "Laurence-Likforman-Sulem",
                        "structuredName": {
                            "firstName": "Laurence",
                            "lastName": "Likforman-Sulem",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Laurence Likforman-Sulem"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1409083785"
                        ],
                        "name": "Anahid Hanimyan",
                        "slug": "Anahid-Hanimyan",
                        "structuredName": {
                            "firstName": "Anahid",
                            "lastName": "Hanimyan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Anahid Hanimyan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38138508"
                        ],
                        "name": "C. Faure",
                        "slug": "C.-Faure",
                        "structuredName": {
                            "firstName": "Claudie",
                            "lastName": "Faure",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Faure"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 124,
                                "start": 120
                            }
                        ],
                        "text": "We compare this learning-based clustering method with that with artificially designed metric and show that supervised metric learning improves largely the accuracy of text line segmentation."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 16669882,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d96f289b858a12265897cde683cdb4e37831a190",
            "isKey": false,
            "numCitedBy": 176,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "The method herein proposed detects text lines on handwritten pages which may include either lines oriented in several directions, erasures, or annotations between main lines. The method has a hypothesis-validation strategy which is iteratively activated until the end of the segmentation is reached. At each stage of the process, the best text-line hypothesis is generated in the Hough domain. Taking into account the fluctuations of the text-line components. Afterwards, the validity of the line is checked in the image domain using a proximity criteria which analyses the context in which is perceived the alignment hypothesized. Ambiguous components belonging to several text lines are also marked."
            },
            "slug": "A-Hough-based-algorithm-for-extracting-text-lines-Likforman-Sulem-Hanimyan",
            "title": {
                "fragments": [],
                "text": "A Hough based algorithm for extracting text lines in handwritten documents"
            },
            "tldr": {
                "abstractSimilarityScore": 84,
                "text": "The method herein proposed detects text lines on handwritten pages which may include either lines oriented in several directions, erasures, or annotations between main lines, and generates the best text-line hypothesis in the Hough domain."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of 3rd International Conference on Document Analysis and Recognition"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1708019"
                        ],
                        "name": "Zhixin Shi",
                        "slug": "Zhixin-Shi",
                        "structuredName": {
                            "firstName": "Zhixin",
                            "lastName": "Shi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zhixin Shi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1800513"
                        ],
                        "name": "S. Setlur",
                        "slug": "S.-Setlur",
                        "structuredName": {
                            "firstName": "Srirangaraj",
                            "lastName": "Setlur",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Setlur"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1723877"
                        ],
                        "name": "V. Govindaraju",
                        "slug": "V.-Govindaraju",
                        "structuredName": {
                            "firstName": "Venu",
                            "lastName": "Govindaraju",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Govindaraju"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 10232002,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "088fdf647d2bdf7e94a95202e47a3c894690e36c",
            "isKey": false,
            "numCitedBy": 84,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents an algorithm using adaptive local connectivity map for retrieving text lines from the complex handwritten documents such as handwritten historical manuscripts. The algorithm is designed for solving the particularly complex problems seen in handwritten documents. These problems include fluctuating text lines, touching or crossing text lines and low quality image that do not lend themselves easily to binarizations. The algorithm is based on connectivity features similar to local projection profiles, which can be directly extracted from gray scale images. The proposed technique is robust and has been tested on a set of complex historical handwritten documents such as Newton's and Galileo's manuscripts. A preliminary testing shows a successful location rate of above 95% for the test set."
            },
            "slug": "Text-extraction-from-gray-scale-historical-document-Shi-Setlur",
            "title": {
                "fragments": [],
                "text": "Text extraction from gray scale historical document images using adaptive local connectivity map"
            },
            "tldr": {
                "abstractSimilarityScore": 85,
                "text": "An algorithm using adaptive local connectivity map for retrieving text lines from the complex handwritten documents such as handwritten historical manuscripts, designed for solving the particularly complex problems seen in handwritten documents."
            },
            "venue": {
                "fragments": [],
                "text": "Eighth International Conference on Document Analysis and Recognition (ICDAR'05)"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144167309"
                        ],
                        "name": "U. Pal",
                        "slug": "U.-Pal",
                        "structuredName": {
                            "firstName": "Umapada",
                            "lastName": "Pal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "U. Pal"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40813600"
                        ],
                        "name": "P. Roy",
                        "slug": "P.-Roy",
                        "structuredName": {
                            "firstName": "Partha",
                            "lastName": "Roy",
                            "middleNames": [
                                "Pratim"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Roy"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "From a different viewpoint, some researchers proposed water reservoir based top-down methods [9\u201311]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Many efforts have been devoted to the difficult problem of handwritten text line segmentation [1\u201328]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 21550039,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f5f6667a980f38d18c9dea671da7252dfffb078f",
            "isKey": false,
            "numCitedBy": 88,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "There are printed artistic documents where text lines of a single page may not be parallel to each other. These text lines may have different orientations or the text lines may be curved shapes. For the optical character recognition (OCR) of these documents, we need to extract such lines properly. In this paper, we propose a novel scheme, mainly based on the concept of water reservoir analogy, to extract individual text lines from printed Indian documents containing multioriented and/or curve text lines. A reservoir is a metaphor to illustrate the cavity region of a character where water can be stored. In the proposed scheme, at first, connected components are labeled and identified either as isolated or touching. Next, each touching component is classified either straight type (S-type) or curve type (C-type), depending on the reservoir base-area and envelope points of the component. Based on the type (S-type or C-type) of a component two candidate points are computed from each touching component. Finally, candidate regions (neighborhoods of the candidate points) of the candidate points of each component are detected and after analyzing these candidate regions, components are grouped to get individual text lines."
            },
            "slug": "Multioriented-and-curved-text-lines-extraction-from-Pal-Roy",
            "title": {
                "fragments": [],
                "text": "Multioriented and curved text lines extraction from Indian documents"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A novel scheme, mainly based on the concept of water reservoir analogy, to extract individual text lines from printed Indian documents containing multioriented and/or curve text lines is proposed."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics)"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2116415943"
                        ],
                        "name": "B. Yu",
                        "slug": "B.-Yu",
                        "structuredName": {
                            "firstName": "Bin",
                            "lastName": "Yu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Yu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145295484"
                        ],
                        "name": "Anil K. Jain",
                        "slug": "Anil-K.-Jain",
                        "structuredName": {
                            "firstName": "Anil",
                            "lastName": "Jain",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Anil K. Jain"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 41609314,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ca920e10343757ba0d4151bc8ce152cbd5191bee",
            "isKey": false,
            "numCitedBy": 166,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-robust-and-fast-skew-detection-algorithm-for-Yu-Jain",
            "title": {
                "fragments": [],
                "text": "A robust and fast skew detection algorithm for generic documents"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit."
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145820427"
                        ],
                        "name": "Fei Yin",
                        "slug": "Fei-Yin",
                        "structuredName": {
                            "firstName": "Fei",
                            "lastName": "Yin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Fei Yin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2140087937"
                        ],
                        "name": "Qiu-Feng Wang",
                        "slug": "Qiu-Feng-Wang",
                        "structuredName": {
                            "firstName": "Qiu-Feng",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Qiu-Feng Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1689269"
                        ],
                        "name": "Cheng-Lin Liu",
                        "slug": "Cheng-Lin-Liu",
                        "structuredName": {
                            "firstName": "Cheng-Lin",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Cheng-Lin Liu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6300575,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8fc7e0cb2919d8d78a547f1a0b2d2eb4922cb1d8",
            "isKey": false,
            "numCitedBy": 19,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "Annotating the regions, text lines and characters of document images is an important, but tedious and expensive task. A ground-truthing tool may largely alleviate the human burden in this process. This paper describes an automated recognition-based tool GTLC for finding the best alignment between the text transcript and the connected components of unconstrained handwritten document image. The alignment process is formulated as an optimization problem involving candidate character segmentation and recognition. We have validated the effectiveness of this tool and have used it for annotating a large number of handwritten Chinese documents."
            },
            "slug": "A-Tool-for-Ground-Truthing-Text-Lines-and-in-Yin-Wang",
            "title": {
                "fragments": [],
                "text": "A Tool for Ground-Truthing Text Lines and Characters in Off-Line Handwritten Chinese Documents"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "An automated recognition-based tool GTLC for finding the best alignment between the text transcript and the connected components of unconstrained handwritten document image is described."
            },
            "venue": {
                "fragments": [],
                "text": "2009 10th International Conference on Document Analysis and Recognition"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1746772"
                        ],
                        "name": "G. Louloudis",
                        "slug": "G.-Louloudis",
                        "structuredName": {
                            "firstName": "Georgios",
                            "lastName": "Louloudis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Louloudis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7232446"
                        ],
                        "name": "B. Gatos",
                        "slug": "B.-Gatos",
                        "structuredName": {
                            "firstName": "Basilios",
                            "lastName": "Gatos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Gatos"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1748249"
                        ],
                        "name": "I. Pratikakis",
                        "slug": "I.-Pratikakis",
                        "structuredName": {
                            "firstName": "Ioannis",
                            "lastName": "Pratikakis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Pratikakis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "70602633"
                        ],
                        "name": "K. Halatsis",
                        "slug": "K.-Halatsis",
                        "structuredName": {
                            "firstName": "K.",
                            "lastName": "Halatsis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Halatsis"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 92,
                                "start": 88
                            }
                        ],
                        "text": "Sometimes, the CCs are split into equally spaced blocks to be voted in the Hough domain [22]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14210437,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b29494e7b48ff93178ae9020620da0d6dce24f93",
            "isKey": false,
            "numCitedBy": 86,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we present a new text line detection method for unconstrained handwritten documents. The proposed technique is based on a strategy that consists of three distinct steps. The first step includes preprocessing for image enhancement, connected component extraction and average character height estimation. In the second step, a block-based Hough transform is used for the detection of potential text lines while a third step is used to correct possible false alarms. The performance of the proposed methodology is based on a consistent and concrete evaluation technique that relies on the comparison between the text line detection result and the corresponding ground truth annotation."
            },
            "slug": "A-Block-Based-Hough-Transform-Mapping-for-Text-Line-Louloudis-Gatos",
            "title": {
                "fragments": [],
                "text": "A Block-Based Hough Transform Mapping for Text Line Detection in Handwritten Documents"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "The performance of the proposed methodology is based on a consistent and concrete evaluation technique that relies on the comparison between the text line detection result and the corresponding ground truth annotation."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1689269"
                        ],
                        "name": "Cheng-Lin Liu",
                        "slug": "Cheng-Lin-Liu",
                        "structuredName": {
                            "firstName": "Cheng-Lin",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Cheng-Lin Liu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2887371"
                        ],
                        "name": "Masashi Koga",
                        "slug": "Masashi-Koga",
                        "structuredName": {
                            "firstName": "Masashi",
                            "lastName": "Koga",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Masashi Koga"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34878566"
                        ],
                        "name": "H. Fujisawa",
                        "slug": "H.-Fujisawa",
                        "structuredName": {
                            "firstName": "Hiromichi",
                            "lastName": "Fujisawa",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Fujisawa"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 26,
                                "start": 22
                            }
                        ],
                        "text": "Two important issues in clustering are the distance metric between units and the criterion for determining the number of clusters."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 42476557,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1e22b8123da0b35a4afa8ec6730a00991dc76e02",
            "isKey": false,
            "numCitedBy": 178,
            "numCiting": 45,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes a handwritten character string recognition system for Japanese mail address reading on a very large vocabulary. The address phrases are recognized as a whole because there is no extra space between words. The lexicon contains 111,349 address phrases, which are stored in a trie structure. In recognition, the text line image is matched with the lexicon entries (phrases) to obtain reliable segmentation and retrieve valid address phrases. The paper first introduces some effective techniques for text line image preprocessing and presegmentation. In presegmentation, the text line image is separated into primitive segments by connected component analysis and touching pattern splitting based on contour shape analysis. In lexicon matching, consecutive segments are dynamically combined into candidate character patterns. An accurate character classifier is embedded in lexicon matching to select characters matched with a candidate pattern from a dynamic category set. A beam search strategy is used to control the lexicon matching so as to achieve real-time recognition. In experiments on 3,589 live mail images, the proposed method achieved correct rate of 83.68 percent while the error rate is less than 1 percent."
            },
            "slug": "Lexicon-Driven-Segmentation-and-Recognition-of-for-Liu-Koga",
            "title": {
                "fragments": [],
                "text": "Lexicon-Driven Segmentation and Recognition of Handwritten Character Strings for Japanese Address Reading"
            },
            "tldr": {
                "abstractSimilarityScore": 73,
                "text": "A handwritten character string recognition system for Japanese mail address reading on a very large vocabulary because there is no extra space between words to achieve real-time recognition."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144167309"
                        ],
                        "name": "U. Pal",
                        "slug": "U.-Pal",
                        "structuredName": {
                            "firstName": "Umapada",
                            "lastName": "Pal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "U. Pal"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "52511272"
                        ],
                        "name": "S. Datta",
                        "slug": "S.-Datta",
                        "structuredName": {
                            "firstName": "S.",
                            "lastName": "Datta",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Datta"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 62,
                                "start": 59
                            }
                        ],
                        "text": "Text line segmentation of handwritten documents is much more difficult than that for printed documents."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Keywords: Handwritten Text Line Segmentation, Clustering, Minimal Spanning Tree (MST), Distance Metric Learning."
                    },
                    "intents": []
                }
            ],
            "corpusId": 17388229,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d4d5c6a422db1e0854b30c390a6b0095cbc73ee7",
            "isKey": false,
            "numCitedBy": 189,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "To take care of variability involved in the writing style ofdifferent individuals in this paper we propose a robustscheme to segment unconstrained handwritten Banglatexts into lines, words and characters. For linesegmentation, at first, we divide the text into verticalstripes. Stripe width of a document is computed bystatistical analysis of the text height in the document.Next we determine horizontal histogram of these stripesand the relationship of the minimal values of thehistograms is used to segment text lines. Based onvertical projection profile lines are segmented intowords. Segmentation of characters from handwrittenword is very tricky as the characters are seldomvertically separable. We use a concept based on waterreservoir principle for the purpose. Here we, at first,identify isolated and connected (touching) characters ina word. Next touching characters of the word aresegmented based on the reservoir base area points andstructural feature of the component."
            },
            "slug": "Segmentation-of-Bangla-unconstrained-handwritten-Pal-Datta",
            "title": {
                "fragments": [],
                "text": "Segmentation of Bangla unconstrained handwritten text"
            },
            "tldr": {
                "abstractSimilarityScore": 51,
                "text": "A robust scheme to segment unconstrained handwritten Banglatexts into lines, words and characters based on water reservoir principle is proposed to take care of variability involved in the writing style of different individuals."
            },
            "venue": {
                "fragments": [],
                "text": "Seventh International Conference on Document Analysis and Recognition, 2003. Proceedings."
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2130178"
                        ],
                        "name": "I. S. Abuhaiba",
                        "slug": "I.-S.-Abuhaiba",
                        "structuredName": {
                            "firstName": "Ibrahim",
                            "lastName": "Abuhaiba",
                            "middleNames": [
                                "Soliman",
                                "I"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. S. Abuhaiba"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "52511272"
                        ],
                        "name": "S. Datta",
                        "slug": "S.-Datta",
                        "structuredName": {
                            "firstName": "S.",
                            "lastName": "Datta",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Datta"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3018380"
                        ],
                        "name": "M. Holt",
                        "slug": "M.-Holt",
                        "structuredName": {
                            "firstName": "Murray",
                            "lastName": "Holt",
                            "middleNames": [
                                "J.",
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Holt"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 28,
                                "start": 25
                            }
                        ],
                        "text": "The distance metric between connected components is designed by supervised learning."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 42681590,
            "fieldsOfStudy": [
                "Psychology",
                "Computer Science"
            ],
            "id": "5ccdb5ce4db9d15c5ac1193ab1371295e4dde868",
            "isKey": false,
            "numCitedBy": 41,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "A method is developed to extract lines from pages of handwritten text by finding the shortest spanning tree of a graph formed from the set of main strokes. Main strokes of extracted lines are arranged in the same order as they were written by following the path in which they are contained. Then, every secondary stroke is assigned to the closest main stroke. At the end, an ordered list of main strokes each with the corresponding number of assigned secondary strokes is obtained. Each combination of main-secondary strokes can be the input to a subsequent recognition stage. The method is more suited to variable handwriting."
            },
            "slug": "Line-extraction-and-stroke-ordering-of-text-pages-Abuhaiba-Datta",
            "title": {
                "fragments": [],
                "text": "Line extraction and stroke ordering of text pages"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "A method is developed to extract lines from pages of handwritten text by finding the shortest spanning tree of a graph formed from the set of main strokes."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of 3rd International Conference on Document Analysis and Recognition"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "97014121"
                        ],
                        "name": "St\u00e9phane Nicolas",
                        "slug": "St\u00e9phane-Nicolas",
                        "structuredName": {
                            "firstName": "St\u00e9phane",
                            "lastName": "Nicolas",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "St\u00e9phane Nicolas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1690399"
                        ],
                        "name": "T. Paquet",
                        "slug": "T.-Paquet",
                        "structuredName": {
                            "firstName": "Thierry",
                            "lastName": "Paquet",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Paquet"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1804638"
                        ],
                        "name": "L. Heutte",
                        "slug": "L.-Heutte",
                        "structuredName": {
                            "firstName": "Laurent",
                            "lastName": "Heutte",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Heutte"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[16] use the artificial intelligence concept of production system to search for an optimal alignment of CCs into text lines."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 10130572,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a30d66294fd930cd189de4badf39c8a0f0e8c46c",
            "isKey": false,
            "numCitedBy": 67,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "We present in this paper a digitization project of cultural heritage manuscripts and we discuss the underlying problems, particularly those relative to document analysis. Considering the drawbacks of traditional methods for text line extraction in handwritten documents, we propose to adopt a new approach for handwritten page segmentation, based on a traditional problem solving framework used in artificial intelligence."
            },
            "slug": "Text-line-segmentation-in-handwritten-document-a-Nicolas-Paquet",
            "title": {
                "fragments": [],
                "text": "Text line segmentation in handwritten document using a production system"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "Considering the drawbacks of traditional methods for text line extraction in handwritten documents, a new approach for handwritten page segmentation is proposed, based on a traditional problem solving framework used in artificial intelligence."
            },
            "venue": {
                "fragments": [],
                "text": "Ninth International Workshop on Frontiers in Handwriting Recognition"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1708019"
                        ],
                        "name": "Zhixin Shi",
                        "slug": "Zhixin-Shi",
                        "structuredName": {
                            "firstName": "Zhixin",
                            "lastName": "Shi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zhixin Shi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1723877"
                        ],
                        "name": "V. Govindaraju",
                        "slug": "V.-Govindaraju",
                        "structuredName": {
                            "firstName": "Venu",
                            "lastName": "Govindaraju",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Govindaraju"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 16993962,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "87c3e5773958768b47ac5ff00f408f9fba5ab917",
            "isKey": false,
            "numCitedBy": 137,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "A new text line location and separation algorithm for complex handwritten documents is proposed. The algorithm is based on the application of a fuzzy directional runlength. The proposed technique was tested on a variety of complex handwritten document images including postal parcel images and historical handwritten documents such as Newton's and Galileo's manuscripts. A preliminary testing showed a successful rate of 93% of the test set."
            },
            "slug": "Line-separation-for-complex-document-images-using-Shi-Govindaraju",
            "title": {
                "fragments": [],
                "text": "Line separation for complex document images using fuzzy runlength"
            },
            "tldr": {
                "abstractSimilarityScore": 84,
                "text": "A new text line location and separation algorithm for complex handwritten documents is proposed based on the application of a fuzzy directional runlength that showed a successful rate of 93% of the test set."
            },
            "venue": {
                "fragments": [],
                "text": "First International Workshop on Document Image Analysis for Libraries, 2004. Proceedings."
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40523977"
                        ],
                        "name": "Tonghua Su",
                        "slug": "Tonghua-Su",
                        "structuredName": {
                            "firstName": "Tonghua",
                            "lastName": "Su",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tonghua Su"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1821107"
                        ],
                        "name": "Tianwen Zhang",
                        "slug": "Tianwen-Zhang",
                        "structuredName": {
                            "firstName": "Tianwen",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tianwen Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2438618"
                        ],
                        "name": "D. Guan",
                        "slug": "D.-Guan",
                        "structuredName": {
                            "firstName": "De-Jun",
                            "lastName": "Guan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Guan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 30,
                                "start": 24
                            }
                        ],
                        "text": "Since the images in the HIT-MW database are not labeled at connected components level (only a part of images have been segmented into text lines), we have annotated 105 document images using our ground truthing tool GTLC [19]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 102,
                                "start": 98
                            }
                        ],
                        "text": "We evaluated the performance of our algorithms on a Chinese handwritten documents database HIT-MW [22], which was collected by Harbin Institute of Technology and is publicly available for free use."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 7194635,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "960ef34612a05771fec5eb7db01fc33a70ad4759",
            "isKey": false,
            "numCitedBy": 138,
            "numCiting": 40,
            "paperAbstract": {
                "fragments": [],
                "text": "A Chinese handwriting database named HIT-MW is presented to facilitate the offline Chinese handwritten text recognition. Both the writers and the texts for handcopying are carefully sampled with a systematic scheme. To collect naturally written handwriting, forms are distributed by postal mail or middleman instead of face to face. The current version of HIT-MW includes 853 forms and 186,444 characters that are produced under an unconstrained condition without preprinted character boxes. The statistics show that the database has an excellent representation of the real handwriting. Many new applications concerning real handwriting recognition can be supported by the database."
            },
            "slug": "Corpus-based-HIT-MW-database-for-offline-of-Chinese-Su-Zhang",
            "title": {
                "fragments": [],
                "text": "Corpus-based HIT-MW database for offline recognition of general-purpose Chinese handwritten text"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "The statistics show that the HIT-MW database has an excellent representation of the real handwriting and many new applications concerning real handwriting recognition can be supported by the database."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Document Analysis and Recognition (IJDAR)"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1398550688"
                        ],
                        "name": "L. O'Gorman",
                        "slug": "L.-O'Gorman",
                        "structuredName": {
                            "firstName": "Lawrence",
                            "lastName": "O'Gorman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. O'Gorman"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 22995244,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d85097da36118fbccfeb7802abf89bf4b4c63a3e",
            "isKey": false,
            "numCitedBy": 728,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "Page layout analysis is a document processing technique used to determine the format of a page. This paper describes the document spectrum (or docstrum), which is a method for structural page layout analysis based on bottom-up, nearest-neighbor clustering of page components. The method yields an accurate measure of skew, within-line, and between-line spacings and locates text lines and text blocks. It is advantageous over many other methods in three main ways: independence from skew angle, independence from different text spacings, and the ability to process local regions of different text orientations within the same image. Results of the method shown for several different page formats and for randomly oriented subpages on the same image illustrate the versatility of the method. We also discuss the differences, advantages, and disadvantages of the docstrum with respect to other lay-out methods. >"
            },
            "slug": "The-Document-Spectrum-for-Page-Layout-Analysis-O'Gorman",
            "title": {
                "fragments": [],
                "text": "The Document Spectrum for Page Layout Analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 57,
                "text": "The document spectrum (or docstrum), which is a method for structural page layout analysis based on bottom-up, nearest-neighbor clustering of page components, yields an accurate measure of skew, within-line, and between-line spacings and locates text lines and text blocks."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "97014121"
                        ],
                        "name": "St\u00e9phane Nicolas",
                        "slug": "St\u00e9phane-Nicolas",
                        "structuredName": {
                            "firstName": "St\u00e9phane",
                            "lastName": "Nicolas",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "St\u00e9phane Nicolas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1690399"
                        ],
                        "name": "T. Paquet",
                        "slug": "T.-Paquet",
                        "structuredName": {
                            "firstName": "Thierry",
                            "lastName": "Paquet",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Paquet"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1804638"
                        ],
                        "name": "L. Heutte",
                        "slug": "L.-Heutte",
                        "structuredName": {
                            "firstName": "Laurent",
                            "lastName": "Heutte",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Heutte"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Many efforts have been devoted to the difficult problem of handwritten text line segmentation [1\u201328]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "treat document image segmentation as a labeling problem [26]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14668577,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "53b17f9dc8c611363ad71bf5b50248a7cc14e97b",
            "isKey": false,
            "numCitedBy": 11,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "We consider in this paper the problem of complex handwritten page segmentation such as novelist drafts or authorial manuscripts. We propose to use stochastic and contextual models in order to cope with local spatial variability, and to take into account some prior knowledge about the global structure of the document image. The models we propose to use are Markov Random Field models. Using this model, the segmentation is performed using optimization techniques. Using the MRF framework, the segmentation is equivalent to an image labeling problem and is performed using optimization techniques."
            },
            "slug": "Markov-Random-Field-Models-to-Extract-The-Layout-of-Nicolas-Paquet",
            "title": {
                "fragments": [],
                "text": "Markov Random Field Models to Extract The Layout of Complex Handwritten Documents"
            },
            "tldr": {
                "abstractSimilarityScore": 88,
                "text": "The problem of complex handwritten page segmentation such as novelist drafts or authorial manuscripts is considered and stochastic and contextual models are proposed in order to cope with local spatial variability, and to take into account some prior knowledge about the global structure of the document image."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145916951"
                        ],
                        "name": "G. Nagy",
                        "slug": "G.-Nagy",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Nagy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Nagy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145062511"
                        ],
                        "name": "S. Seth",
                        "slug": "S.-Seth",
                        "structuredName": {
                            "firstName": "Sharad",
                            "lastName": "Seth",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Seth"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145266621"
                        ],
                        "name": "M. Viswanathan",
                        "slug": "M.-Viswanathan",
                        "structuredName": {
                            "firstName": "Mahesh",
                            "lastName": "Viswanathan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Viswanathan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 159,
                                "start": 156
                            }
                        ],
                        "text": "Whereas the difficulty of machine-printed document analysis mainly lies in the complex layout structure and degraded image quality, handwritten document analysis is difficult mainly due to the irregularity of layout and character shapes originated from the variability of writing styles."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2530196,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "62a53caea5213ea177298d7b2aff292b1386c37a",
            "isKey": false,
            "numCitedBy": 434,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "Gobbledoc, a system providing remote access to stored documents, which is based on syntactic document analysis and optical character recognition (OCR), is discussed. In Gobbledoc, image processing, document analysis, and OCR operations take place in batch mode when the documents are acquired. The document image acquisition process and the knowledge base that must be entered into the system to process a family of page images are described. The process by which the X-Y tree data structure converts a 2-D page-segmentation problem into a series of 1-D string-parsing problems that can be tackled using conventional compiler tools is also described. Syntactic analysis is used in Gobbledoc to divide each page into labeled rectangular blocks. Blocks labeled text are converted by OCR to obtain a secondary (ASCII) document representation. Since such symbolic files are better suited for computerized search than for human access to the document content and because too many visual layout clues are lost in the OCR process (including some special characters), Gobbledoc preserves the original block images for human browsing. Storage, networking, and display issues specific to document images are also discussed.<<ETX>>"
            },
            "slug": "A-prototype-document-image-analysis-system-for-Nagy-Seth",
            "title": {
                "fragments": [],
                "text": "A prototype document image analysis system for technical journals"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "The document image acquisition process and the knowledge base that must be entered into the system to process a family of page images are described, and the process by which the X-Y tree data structure converts a 2-D page-segmentation problem into a series of 1-D string-parsing problems that can be tackled using conventional compiler tools."
            },
            "venue": {
                "fragments": [],
                "text": "Computer"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145048780"
                        ],
                        "name": "F. Chang",
                        "slug": "F.-Chang",
                        "structuredName": {
                            "firstName": "Fu",
                            "lastName": "Chang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Chang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2109485309"
                        ],
                        "name": "Chun-Jen Chen",
                        "slug": "Chun-Jen-Chen",
                        "structuredName": {
                            "firstName": "Chun-Jen",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chun-Jen Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1390518825"
                        ],
                        "name": "Chi-Jen Lu",
                        "slug": "Chi-Jen-Lu",
                        "structuredName": {
                            "firstName": "Chi-Jen",
                            "lastName": "Lu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chi-Jen Lu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "In preprocessing, the CCs are labeled using a fast algorithm based on contour tracing [29]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14567805,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "61e05914f1889c8a1f52a96a831a8ba538dab6cb",
            "isKey": false,
            "numCitedBy": 614,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-linear-time-component-labeling-algorithm-using-Chang-Chen",
            "title": {
                "fragments": [],
                "text": "A linear-time component-labeling algorithm using contour tracing technique"
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Vis. Image Underst."
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3277321"
                        ],
                        "name": "K. Kise",
                        "slug": "K.-Kise",
                        "structuredName": {
                            "firstName": "Koichi",
                            "lastName": "Kise",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Kise"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2064863306"
                        ],
                        "name": "A. Sato",
                        "slug": "A.-Sato",
                        "structuredName": {
                            "firstName": "Akinori",
                            "lastName": "Sato",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Sato"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40411993"
                        ],
                        "name": "M. Iwata",
                        "slug": "M.-Iwata",
                        "structuredName": {
                            "firstName": "Motoi",
                            "lastName": "Iwata",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Iwata"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 54,
                                "start": 50
                            }
                        ],
                        "text": "To do this, we construct the area Voronoi diagram [20] of the training document, which represents the spatial adjacency between the"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 23399574,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "be80678c0eeedf754647a8b9adccd5d6d9be3e86",
            "isKey": false,
            "numCitedBy": 275,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a method of page segmentation based on the approximated area Voronoi diagram. The characteristics of the proposed method are as follows: (1) The Voronoi diagram enables us to obtain the candidates of boundaries of document components from page images with non-Manhattan layout and a skew. (2) The candidates are utilized to estimate the intercharacter and interline gaps without the use of domain-specific parameters to select the boundaries. From the experimental results for 128 images with non-Manhattan layout and the skew of 0\u00b0~45\u00b0 as well as 98 images with Manhattan layout, we have confirmed that the method is effective for extraction of body text regions, and it is as efficient as other methods based on connected component analysis."
            },
            "slug": "Segmentation-of-Page-Images-Using-the-Area-Voronoi-Kise-Sato",
            "title": {
                "fragments": [],
                "text": "Segmentation of Page Images Using the Area Voronoi Diagram"
            },
            "tldr": {
                "abstractSimilarityScore": 59,
                "text": "It is confirmed that the proposed method of page segmentation based on the approximated area Voronoi diagram is effective for extraction of body text regions, and it is as efficient as other methods based on connected component analysis."
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Vis. Image Underst."
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2115888"
                        ],
                        "name": "C. T. Zahn",
                        "slug": "C.-T.-Zahn",
                        "structuredName": {
                            "firstName": "Charles",
                            "lastName": "Zahn",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. T. Zahn"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "The authors of [37] demonstrated that this method was more efficient than the algorithm in [36]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Although several algorithms [36\u201339] on this problem have been proposed, they do not perform satisfactorily in our case of handwritten Chinese text line segmentation."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14739967,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4ae384fb530f986e4f80d03ada0abd3acf89dbc0",
            "isKey": false,
            "numCitedBy": 1810,
            "numCiting": 41,
            "paperAbstract": {
                "fragments": [],
                "text": "A family of graph-theoretical algorithms based on the minimal spanning tree are capable of detecting several kinds of cluster structure in arbitrary point sets; description of the detected clusters is possible in some cases by extensions of the method. Development of these clustering algorithms was based on examples from two-dimensional space because we wanted to copy the human perception of gestalts or point groupings. On the other hand, all the methods considered apply to higher dimensional spaces and even to general metric spaces. Advantages of these methods include determinacy, easy interpretation of the resulting clusters, conformity to gestalt principles of perceptual organization, and invariance of results under monotone transformations of interpoint distance. Brief discussion is made of the application of cluster detection to taxonomy and the selection of good feature spaces for pattern recognition. Detailed analyses of several planar cluster detection problems are illustrated by text and figures. The well-known Fisher iris data, in four-dimensional space, have been analyzed by these methods also. PL/1 programs to implement the minimal spanning tree methods have been fully debugged."
            },
            "slug": "Graph-Theoretical-Methods-for-Detecting-and-Gestalt-Zahn",
            "title": {
                "fragments": [],
                "text": "Graph-Theoretical Methods for Detecting and Describing Gestalt Clusters"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "A family of graph-theoretical algorithms based on the minimal spanning tree are capable of detecting several kinds of cluster structure in arbitrary point sets; description of the detected clusters is possible in some cases by extensions of the method."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Computers"
            },
            "year": 1971
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145809751"
                        ],
                        "name": "F. Kimura",
                        "slug": "F.-Kimura",
                        "structuredName": {
                            "firstName": "Fumitaka",
                            "lastName": "Kimura",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Kimura"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2224415"
                        ],
                        "name": "Y. Miyake",
                        "slug": "Y.-Miyake",
                        "structuredName": {
                            "firstName": "Yasuji",
                            "lastName": "Miyake",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Miyake"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145492601"
                        ],
                        "name": "M. Shridhar",
                        "slug": "M.-Shridhar",
                        "structuredName": {
                            "firstName": "Malayappan",
                            "lastName": "Shridhar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Shridhar"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "013 line detection techniques, such as projection analysis [1\u20137] and K-nearest neighbor connected components (CCs) grouping [12\u201314], are not able to segment handwritten text lines successfully."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "In [13], each CC is represented by its vertical coordinates of the bounding box, and the CCs are grouped by weighted k-means clustering under the spatial constraints of valid address lines."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Many efforts have been devoted to the difficult problem of handwritten text line segmentation [1\u201328]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 11840930,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a6e91cd9084f63c59359377b3cde5f17139551ac",
            "isKey": false,
            "numCitedBy": 38,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "The paper describes a new approach to ZIP code recognition using a word recognition algorithm, where a numeral string is recognized as a word. The paper also describes an end to end ZIP code recognition system consisting of tilt/slant correction, line segmentation, word segmentation, ZIP code location, as well as the ZIP code recognition. Evaluation tests are performed using address block image samples collected from United States mail pieces. The results of isolated numeral recognition, manually extracted ZIP code recognition, and end to end ZIP code recognition are presented to show and discuss the advantage of the word recognition based numeral string recognition."
            },
            "slug": "Handwritten-ZIP-code-recognition-using-lexicon-free-Kimura-Miyake",
            "title": {
                "fragments": [],
                "text": "Handwritten ZIP code recognition using lexicon free word recognition algorithm"
            },
            "tldr": {
                "abstractSimilarityScore": 50,
                "text": "The results of isolated numeral recognition, manually extracted ZIP code recognition, and end to end Zip code recognition are presented to show and discuss the advantage of the word recognition based numeral string recognition."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of 3rd International Conference on Document Analysis and Recognition"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1863322"
                        ],
                        "name": "Anik\u00f3 Simon",
                        "slug": "Anik\u00f3-Simon",
                        "structuredName": {
                            "firstName": "Anik\u00f3",
                            "lastName": "Simon",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Anik\u00f3 Simon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1907819"
                        ],
                        "name": "Jean-Christophe Pret",
                        "slug": "Jean-Christophe-Pret",
                        "structuredName": {
                            "firstName": "Jean-Christophe",
                            "lastName": "Pret",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jean-Christophe Pret"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1406054409"
                        ],
                        "name": "A. Johnson",
                        "slug": "A.-Johnson",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Johnson",
                            "middleNames": [
                                "Peter"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Johnson"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 32,
                                "start": 28
                            }
                        ],
                        "text": "The distance metric between connected components is designed by supervised learning."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 29276706,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7094063edf765c44dcce4aada3ed0ca725b74d96",
            "isKey": false,
            "numCitedBy": 140,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes a new bottom-up method for document layout analysis. The algorithm was implemented in the CLIDE (Chemical Literature Data Extraction) system, but the method described here is suitable for a broader range of documents. It is based on Kruskal's algorithm and uses a special distance-metric between the components to construct the physical page structure. The method has all the major advantages of bottom-up systems: independence from different text spacing and independence from different block alignments. The algorithms computational complexity is reduced to linear by using heuristics and path-compression."
            },
            "slug": "A-Fast-Algorithm-for-Bottom-Up-Document-Layout-Simon-Pret",
            "title": {
                "fragments": [],
                "text": "A Fast Algorithm for Bottom-Up Document Layout Analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 57,
                "text": "A new bottom-up method for document layout analysis based on Kruskal's algorithm and uses a special distance-metric between the components to construct the physical page structure."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145695526"
                        ],
                        "name": "S. Mao",
                        "slug": "S.-Mao",
                        "structuredName": {
                            "firstName": "Song",
                            "lastName": "Mao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Mao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143626870"
                        ],
                        "name": "T. Kanungo",
                        "slug": "T.-Kanungo",
                        "structuredName": {
                            "firstName": "Tapas",
                            "lastName": "Kanungo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kanungo"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 79,
                                "start": 75
                            }
                        ],
                        "text": "algorithm each has four parameters optimized by simplex search, as done in [45]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 101,
                                "start": 97
                            }
                        ],
                        "text": "We used in our experiments a public domain implementation of the X\u2013Y cut and Docstrum algorithms [45]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 5453548,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "82328a31d7366c4ecfd339deeae41c3152b43c98",
            "isKey": false,
            "numCitedBy": 98,
            "numCiting": 64,
            "paperAbstract": {
                "fragments": [],
                "text": "While numerous page segmentation algorithms have been proposed in the literature, there is lack of comparative evaluation of these algorithms. In the existing performance evaluation methods, two crucial components are usually missing: 1) automatic training of algorithms with free parameters and 2) statistical and error analysis of experimental results. We use the following five-step methodology to quantitatively compare the performance of page segmentation algorithms: 1) first, we create mutually exclusive training and test data sets with groundtruth, 2) we then select a meaningful and computable performance metric, 3) an optimization procedure is then used to search automatically for the optimal parameter values of the segmentation algorithms on the training data set, 4) the segmentation algorithms are then evaluated on the test data set, and, finally, 5) a statistical and error analysis is performed to give the statistical significance of the experimental results. In particular, instead of the ad hoc and manual approach typically used in the literature for training algorithms, we pose the automatic training of algorithms as an optimization problem and use the simplex algorithm to search for the optimal parameter value. A paired-model statistical analysis and an error analysis are then conducted to provide confidence intervals for the experimental results of the algorithms. This methodology is applied to the evaluation of live page segmentation algorithms of which, three are representative research algorithms and the other two are well-known commercial products, on 978 images from the University of Washington III data set. It is found that the performance indices of the Voronoi, Docstrum, and Caere segmentation algorithms are not significantly different from each other, but they are significantly better than that of ScanSoft's segmentation algorithm, which, in turn, is significantly better than that of X-Y cut."
            },
            "slug": "Empirical-Performance-Evaluation-Methodology-and-to-Mao-Kanungo",
            "title": {
                "fragments": [],
                "text": "Empirical Performance Evaluation Methodology and Its Application to Page Segmentation Algorithms"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "The performance indices of the Voronoi, Docstrum, and Caere segmentation algorithms are not significantly different from each other, but they are significantly better than that of ScanSoft's segmentation algorithm, which, in turn, is significantly betterthan that of X-Y cut."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145695526"
                        ],
                        "name": "S. Mao",
                        "slug": "S.-Mao",
                        "structuredName": {
                            "firstName": "Song",
                            "lastName": "Mao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Mao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143626870"
                        ],
                        "name": "T. Kanungo",
                        "slug": "T.-Kanungo",
                        "structuredName": {
                            "firstName": "Tapas",
                            "lastName": "Kanungo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kanungo"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2458952,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "184cbf368348a250d005047e269bb96b7e34a460",
            "isKey": false,
            "numCitedBy": 12,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "Most page segmentation algorithms have user-specifiable free parameters. However, algorithm designers typically do not provide a quantitative/rigorous method for choosing values for these parameters. The free parameter values can affect the segmentation result quite drastically and are very dependent on the particular dataset that the algorithm is being used on. We present an automatic training method for choosing free parameters of page segmentation algorithms. The automatic training problem is posed as a multivariate non-smooth function optimization problem. An efficient direct search method-simplex method-is used to solve this optimization problem. This training method is used applied to the training of Kise's page segmentation algorithm. It is found that a set of optimal parameter values and their corresponding performance index can be found using relatively few function evaluations. The UW III dataset was used for conducting our experiments."
            },
            "slug": "Automatic-training-of-page-segmentation-algorithms:-Mao-Kanungo",
            "title": {
                "fragments": [],
                "text": "Automatic training of page segmentation algorithms: an optimization approach"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "An automatic training method for choosing free parameters of page segmentation algorithms and it is found that a set of optimal parameter values and their corresponding performance index can be found using relatively few function evaluations."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings 15th International Conference on Pattern Recognition. ICPR-2000"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144899680"
                        ],
                        "name": "Christian Wolf",
                        "slug": "Christian-Wolf",
                        "structuredName": {
                            "firstName": "Christian",
                            "lastName": "Wolf",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christian Wolf"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1680935"
                        ],
                        "name": "J. Jolion",
                        "slug": "J.-Jolion",
                        "structuredName": {
                            "firstName": "Jean-Michel",
                            "lastName": "Jolion",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Jolion"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Several evaluation schemes have been proposed for document image segmentation [43\u201345], but they were designed for printed documents or graphics and to evaluate the performance based on bounding boxes."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 4106614,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1deaf2a58ac783d1f89ff3b4711f6383c7550a80",
            "isKey": false,
            "numCitedBy": 326,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "Evaluation of object detection algorithms is a non-trivial task: a detection result is usually evaluated by comparing the bounding box of the detected object with the bounding box of the ground truth object. The commonly used precision and recall measures are computed from the overlap area of these two rectangles. However, these measures have several drawbacks: they don't give intuitive information about the proportion of the correctly detected objects and the number of false alarms, and they cannot be accumulated across multiple images without creating ambiguity in their interpretation. Furthermore, quantitative and qualitative evaluation is often mixed resulting in ambiguous measures.In this paper we propose a new approach which tackles these problems. The performance of a detection algorithm is illustrated intuitively by performance graphs which present object level precision and recall depending on constraints on detection quality. In order to compare different detection algorithms, a representative single performance value is computed from the graphs. The influence of the test database on the detection performance is illustrated by performance/generality graphs. The evaluation method can be applied to different types of object detection algorithms. It has been tested on different text detection algorithms, among which are the participants of the ICDAR 2003 text detection competition."
            },
            "slug": "Object-count/area-graphs-for-the-evaluation-of-and-Wolf-Jolion",
            "title": {
                "fragments": [],
                "text": "Object count/area graphs for the evaluation of object detection and segmentation algorithms"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "The performance of a detection algorithm is illustrated intuitively by performance graphs which present object level precision and recall depending on constraints on detection quality, and a representative single performance value is computed from the graphs."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Document Analysis and Recognition (IJDAR)"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2168619284"
                        ],
                        "name": "Jingyu He",
                        "slug": "Jingyu-He",
                        "structuredName": {
                            "firstName": "Jingyu",
                            "lastName": "He",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jingyu He"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1798094"
                        ],
                        "name": "A. Downton",
                        "slug": "A.-Downton",
                        "structuredName": {
                            "firstName": "Andy",
                            "lastName": "Downton",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Downton"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 24,
                                "start": 21
                            }
                        ],
                        "text": "The X-Y cut algorithm [7] is a projection-based topdown segmentation method but performs well only on printed documents because of the assumption of parallel text lines and large between-line gaps."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Keywords: Handwritten Text Line Segmentation, Clustering, Minimal Spanning Tree (MST), Distance Metric Learning."
                    },
                    "intents": []
                }
            ],
            "corpusId": 2070419,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2131c5dc71a849b30ca9c7bf23acc8b7ebe10167",
            "isKey": false,
            "numCitedBy": 29,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "A configurable archive document image analysis system for digital library construction has been designed using rapid prototyping and top-down iterative development methods. This approach has been found to be essential in order to capture the curators' expertise about existing card archive structures, content and databases. The design currently achieves about 93% correct segmentation of the required archive card fields overall, with 81.3% of all archive cards in a testset of 2000 images having all fields correctly segmented and labeled. Analysis of errors in the testset indicates that heavily-annotated cards and non-standard card formats comprise 5-10% of the overall archive, and a significant proportion of these are unlikely to be resolvable without curatorial intervention."
            },
            "slug": "User-assisted-archive-document-image-analysis-for-He-Downton",
            "title": {
                "fragments": [],
                "text": "User-assisted archive document image analysis for digital library construction"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "Analysis of errors in the testset indicates that heavily-annotated cards and non-standard card formats comprise 5-10% of the overall archive, and a significant proportion of these are unlikely to be resolvable without curatorial intervention."
            },
            "venue": {
                "fragments": [],
                "text": "Seventh International Conference on Document Analysis and Recognition, 2003. Proceedings."
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2441811"
                        ],
                        "name": "O. Grygorash",
                        "slug": "O.-Grygorash",
                        "structuredName": {
                            "firstName": "Oleksandr",
                            "lastName": "Grygorash",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Grygorash"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50981788"
                        ],
                        "name": "Yan Zhou",
                        "slug": "Yan-Zhou",
                        "structuredName": {
                            "firstName": "Yan",
                            "lastName": "Zhou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yan Zhou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1682463"
                        ],
                        "name": "Zach Jorgensen",
                        "slug": "Zach-Jorgensen",
                        "structuredName": {
                            "firstName": "Zach",
                            "lastName": "Jorgensen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zach Jorgensen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 660097,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4cdaabca3eb08f56c31ffe074cc4c7cdb99f405a",
            "isKey": false,
            "numCitedBy": 222,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "The minimum spanning tree clustering algorithm is known to be capable of detecting clusters with irregular boundaries. In this paper, we propose two minimum spanning tree based clustering algorithms. The first algorithm produces a k-partition of a set of points for any given k. The algorithm constructs a minimum spanning tree of the point set and removes edges that satisfy a predefined criterion. The process is repeated until k clusters are produced. The second algorithm partitions a point set into a group of clusters by maximizing the overall standard deviation reduction, without a given k value. We present our experimental results comparing our proposed algorithms to k-means and EM. We also apply our algorithms to image color clustering and compare our algorithms to the standard minimum spanning tree clustering algorithm"
            },
            "slug": "Minimum-Spanning-Tree-Based-Clustering-Algorithms-Grygorash-Zhou",
            "title": {
                "fragments": [],
                "text": "Minimum Spanning Tree Based Clustering Algorithms"
            },
            "tldr": {
                "abstractSimilarityScore": 52,
                "text": "This paper proposes two minimum spanning tree based clustering algorithms that partitions a point set into a group of clusters by maximizing the overall standard deviation reduction, without a given k value."
            },
            "venue": {
                "fragments": [],
                "text": "2006 18th IEEE International Conference on Tools with Artificial Intelligence (ICTAI'06)"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2137101"
                        ],
                        "name": "A. Schenker",
                        "slug": "A.-Schenker",
                        "structuredName": {
                            "firstName": "Adam",
                            "lastName": "Schenker",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Schenker"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3045152"
                        ],
                        "name": "Mark Last",
                        "slug": "Mark-Last",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Last",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mark Last"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1720945"
                        ],
                        "name": "H. Bunke",
                        "slug": "H.-Bunke",
                        "structuredName": {
                            "firstName": "Horst",
                            "lastName": "Bunke",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Bunke"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145608940"
                        ],
                        "name": "A. Kandel",
                        "slug": "A.-Kandel",
                        "structuredName": {
                            "firstName": "Abraham",
                            "lastName": "Kandel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Kandel"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "For improving the performance of fuzzy c-means clustering, an evolutionary algorithm was used to optimize the scales of the dimensions of input data set [32]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "As many clustering algorithms rely critically on the distance metric between pairs of input units, some recent studies have contributed to metric learning from data [32\u201334]."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                }
            ],
            "corpusId": 19737368,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9e7d19e7dbf4d964af9694abbd7c748081f86c13",
            "isKey": false,
            "numCitedBy": 1,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we present a genetically enhanced version of the classical fuzzy c-means clustering algorithm. Our algorithm uses an evolutionary method to find optimal values for some scaling constants which are used to scale the various dimensions of the given data set so that clusters can be more easily detected by compensating for differences in distributions among features. We demonstrate how using un-scaled data with the conventional fuzzy c-means algorithm can lead to incorrect classification and how our algorithm overcomes the problem. We present the results of applying our method to both a synthetic data set, which we created to demonstrate the problem, and the standard Iris data set. In both cases, reduction of misclassifications was obtained by the new method, demonstrating improvement over the standard fuzzy c-means algorithm."
            },
            "slug": "Fuzzy-Clustering-with-Genetically-Adaptive-Scaling-Schenker-Last",
            "title": {
                "fragments": [],
                "text": "Fuzzy Clustering with Genetically Adaptive Scaling"
            },
            "tldr": {
                "abstractSimilarityScore": 90,
                "text": "A genetically enhanced version of the classical fuzzy c-means clustering algorithm that uses an evolutionary method to find optimal values for some scaling constants which are used to scale the various dimensions of the given data set so that clusters can be more easily detected by compensating for differences in distributions among features."
            },
            "venue": {
                "fragments": [],
                "text": "Int. J. Image Graph."
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143977260"
                        ],
                        "name": "E. Xing",
                        "slug": "E.-Xing",
                        "structuredName": {
                            "firstName": "Eric",
                            "lastName": "Xing",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Xing"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34699434"
                        ],
                        "name": "A. Ng",
                        "slug": "A.-Ng",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Ng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Ng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694621"
                        ],
                        "name": "Michael I. Jordan",
                        "slug": "Michael-I.-Jordan",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Jordan",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael I. Jordan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145107462"
                        ],
                        "name": "Stuart J. Russell",
                        "slug": "Stuart-J.-Russell",
                        "structuredName": {
                            "firstName": "Stuart",
                            "lastName": "Russell",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Stuart J. Russell"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "We were inspired by the work of distance metric learning of [ 18 ] and herein design our distance metric for text line segmentation by supervised learning."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2643381,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d1a2d203733208deda7427c8e20318334193d9d7",
            "isKey": false,
            "numCitedBy": 3026,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "Many algorithms rely critically on being given a good metric over their inputs. For instance, data can often be clustered in many \"plausible\" ways, and if a clustering algorithm such as K-means initially fails to find one that is meaningful to a user, the only recourse may be for the user to manually tweak the metric until sufficiently good clusters are found. For these and other applications requiring good metrics, it is desirable that we provide a more systematic way for users to indicate what they consider \"similar.\" For instance, we may ask them to provide examples. In this paper, we present an algorithm that, given examples of similar (and, if desired, dissimilar) pairs of points in \u211dn, learns a distance metric over \u211dn that respects these relationships. Our method is based on posing metric learning as a convex optimization problem, which allows us to give efficient, local-optima-free algorithms. We also demonstrate empirically that the learned metrics can be used to significantly improve clustering performance."
            },
            "slug": "Distance-Metric-Learning-with-Application-to-with-Xing-Ng",
            "title": {
                "fragments": [],
                "text": "Distance Metric Learning with Application to Clustering with Side-Information"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This paper presents an algorithm that, given examples of similar (and, if desired, dissimilar) pairs of points in \ufffd\u201dn, learns a distance metric over \u211dn that respects these relationships."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1741392"
                        ],
                        "name": "C. Domeniconi",
                        "slug": "C.-Domeniconi",
                        "structuredName": {
                            "firstName": "Carlotta",
                            "lastName": "Domeniconi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Domeniconi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1736832"
                        ],
                        "name": "D. Gunopulos",
                        "slug": "D.-Gunopulos",
                        "structuredName": {
                            "firstName": "Dimitrios",
                            "lastName": "Gunopulos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Gunopulos"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 15,
                                "start": 11
                            }
                        ],
                        "text": "Domeniconi [33] proposed a variant of k-means algorithm in which individual Euclidean metric weights were learned for each cluster."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7758001,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "adf0cad22e6f6b32fbe68dbacd87d7426732ce50",
            "isKey": false,
            "numCitedBy": 16,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "Pattern classification faces a difficult challenge in finite settings and high dimensional spaces due to the curse of dimensionality. Nearest neighbor methods are especially sensitive to this problem. The need for large neighborhoods in high dimensional spaces is the cause of highly biased estimates. Due to the local nature of feature relevance, any chosen fixed metric violates the assumption of locally constant class posterior probabilities, and therefore fails in making correct predictions in different regions of the input space. In order to achieve accurate predictions, it becomes crucial to be able to estimate the different degrees of relevance that input features may have in various locations of the feature space. \nThis dissertation introduces novel approaches to computing local feature relevance for nearest neighbor methods that overcome limitations of previous techniques. It makes four specific contributions: (1)\u00a0ADAMENN algorithm: A novel approach to computing local feature relevance for pattern classification. It uses the Chi-squared distance to design a flexible metric that approximates the theoretical infinite sample risk at the query point. No assumption is made on the probability distribution of data. It is formally shown that the measure of feature relevance derived by ADAMENN reduces the overall mean-squared estimation error. (2)\u00a0LFM-SVM algorithm : A new local flexible metric technique based on support vector machines. This method overcomes the limitations of lazy learning approaches concerned with scalability and efficiency issues. It is shown that the weighting scheme performed by the LFM-SVM algorithm increases the margin of the solution provided in input by the SVM. (3)\u00a0GenProClus algorithm: A novel algorithm that computes intra-cluster adaptive metrics for clustering. This algorithm represents an attempt to dodge the curse of dimensionality for clustering, and provides information to what features are relevant for each partition. It is shown that the algorithm converges to a local minimum of the associated error function. (4)\u00a0AdaBand algorithm: A new locally adaptive technique to set the bandwidth parameters for kernel density estimation. This approach can serve as an efficient approximation of nearest neighbor methods. It is shown how this algorithm can be used to efficiently solve classification, clustering, and range query approximation problems. \nThe efficacy of the techniques presented is demonstrated through extensive experimental evaluations, using a variety of simulated and real world problems, such as texture recognition in images and letter classification."
            },
            "slug": "Locally-Adaptive-Techniques-for-Pattern-Domeniconi-Gunopulos",
            "title": {
                "fragments": [],
                "text": "Locally Adaptive Techniques for Pattern Classification"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This dissertation introduces novel approaches to computing local feature relevance for nearest neighbor methods that overcome limitations of previous techniques and demonstrates how this algorithm can be used to efficiently solve classification, clustering, and range query approximation problems."
            },
            "venue": {
                "fragments": [],
                "text": "Encyclopedia of Data Warehousing and Mining"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35083509"
                        ],
                        "name": "Liangjia Zhu",
                        "slug": "Liangjia-Zhu",
                        "structuredName": {
                            "firstName": "Liangjia",
                            "lastName": "Zhu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Liangjia Zhu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8526311"
                        ],
                        "name": "Zongtan Zhou",
                        "slug": "Zongtan-Zhou",
                        "structuredName": {
                            "firstName": "Zongtan",
                            "lastName": "Zhou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zongtan Zhou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46570618"
                        ],
                        "name": "D. Hu",
                        "slug": "D.-Hu",
                        "structuredName": {
                            "firstName": "Dewen",
                            "lastName": "Hu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Hu"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 14794517,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "94d3f746a7cc52f8c4c3cbb4373c24ddc2cfaf78",
            "isKey": false,
            "numCitedBy": 128,
            "numCiting": 37,
            "paperAbstract": {
                "fragments": [],
                "text": "One of the most crucial steps for automatically reconstructing ripped-up documents is to find a globally consistent solution from the ambiguous candidate matches. However, little work has been done so far to solve this problem in a general computational framework without using application-specific features. In this paper, we propose a global approach for reconstructing ripped-up documents by first finding candidate matches from document fragments using curve matching and then disambiguating these candidates through a relaxation process to reconstruct the original document. The candidate disambiguation problem is formulated in a relaxation scheme in which the definition of compatibility between neighboring matches is proposed, and global consistency is defined as the global criterion. Initially, global match confidences are assigned to each of the candidate matches. After that, the overall local relationships among neighboring matches are evaluated by computing their global consistency. Then, these confidences are iteratively updated using the gradient projection method to maximize the criterion. This leads to a globally consistent solution and, thus, provides a sound document reconstruction. The overall performance of our approach in several practical experiments is illustrated. The results indicate that the reconstruction of ripped-up documents up to 50 pieces is possibly accomplished automatically."
            },
            "slug": "Globally-Consistent-Reconstruction-of-Ripped-Up-Zhu-Zhou",
            "title": {
                "fragments": [],
                "text": "Globally Consistent Reconstruction of Ripped-Up Documents"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "A global approach for reconstructing ripped-up documents by first finding candidate matches from document fragments using curve matching and then disambiguating these candidates through a relaxation process to reconstruct the original document, indicating that the reconstruction of ripped- up documents up to 50 pieces is possibly accomplished automatically."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3195474"
                        ],
                        "name": "Li Yujian",
                        "slug": "Li-Yujian",
                        "structuredName": {
                            "firstName": "Li",
                            "lastName": "Yujian",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Li Yujian"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 120057908,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ed1a37e320fad29ec6e3c67630834f28044ac331",
            "isKey": false,
            "numCitedBy": 25,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-clustering-algorithm-based-on-maximal-\u03b8-distant-Yujian",
            "title": {
                "fragments": [],
                "text": "A clustering algorithm based on maximal \u03b8-distant subtrees"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2119288562"
                        ],
                        "name": "Yu He",
                        "slug": "Yu-He",
                        "structuredName": {
                            "firstName": "Yu",
                            "lastName": "He",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yu He"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "6187400"
                        ],
                        "name": "Lihui Chen",
                        "slug": "Lihui-Chen",
                        "structuredName": {
                            "firstName": "Lihui",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lihui Chen"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 44509988,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8ce31a189615096f1a0a47f078d43d1903935a69",
            "isKey": false,
            "numCitedBy": 6,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "Clustering is to group data points into homogenous clusters so that data points within the same cluster are more similar than data points belonging to different clusters. There are many effective clustering algorithms for discovering arbitrary shaped clusters, but one common problem of many algorithms is the difficulty for users to decide appropriate parameters for these algorithms. To reduce the dependence of clustering performance on parameters, this paper proposes a threshold criterion for the single linkage cluster analysis and incorporates it into the Minimum Spanning Tree (MST) based clustering method. Since the threshold can be automatically decided according to the underlying data distributions, arbitrary shaped clusters can be discovered with little human intervention. The experimental results on spatial data are very encouraging."
            },
            "slug": "A-threshold-criterion,-auto-detection-and-its-use-He-Chen",
            "title": {
                "fragments": [],
                "text": "A threshold criterion, auto-detection and its use in MST-based clustering"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This paper proposes a threshold criterion for the single linkage cluster analysis and incorporates it into the Minimum Spanning Tree (MST) based clustering method, which can be automatically decided according to the underlying data distributions."
            },
            "venue": {
                "fragments": [],
                "text": "Intell. Data Anal."
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1744200"
                        ],
                        "name": "I. T. Phillips",
                        "slug": "I.-T.-Phillips",
                        "structuredName": {
                            "firstName": "Ihsin",
                            "lastName": "Phillips",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. T. Phillips"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34817063"
                        ],
                        "name": "A. Chhabra",
                        "slug": "A.-Chhabra",
                        "structuredName": {
                            "firstName": "Atul",
                            "lastName": "Chhabra",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Chhabra"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 31517603,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "34a78626bf0277710cb9ab192ec0c094d2bfb784",
            "isKey": false,
            "numCitedBy": 173,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "Presents a methodology for evaluating graphics recognition systems operating on images that contain straight lines, circles, circular arcs, and text blocks. It enables an empirical comparison of vectorization software packages and uses practical performance evaluation methods that can be applied to complete vectorization systems. The methodology includes a set of matching criteria for pairs of graphical entities, a set of performance evaluation metrics, and a benchmark for the evaluation of graphics recognition systems. The benchmark was tested on three systems. The results are reported and analyzed in the paper."
            },
            "slug": "Empirical-Performance-Evaluation-of-Graphics-Phillips-Chhabra",
            "title": {
                "fragments": [],
                "text": "Empirical Performance Evaluation of Graphics Recognition Systems"
            },
            "tldr": {
                "abstractSimilarityScore": 99,
                "text": "Presents a methodology for evaluating graphics recognition systems operating on images that contain straight lines, circles, circular arcs, and text blocks that enables an empirical comparison of vectorization software packages and uses practical performance evaluation methods that can be applied to complete vectorization systems."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2146562400"
                        ],
                        "name": "Gang Liu",
                        "slug": "Gang-Liu",
                        "structuredName": {
                            "firstName": "Gang",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Gang Liu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1710238"
                        ],
                        "name": "R. Haralick",
                        "slug": "R.-Haralick",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Haralick",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Haralick"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 3345452,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0d29af3fa50e2ecab4360584638995a9f3d889c7",
            "isKey": false,
            "numCitedBy": 45,
            "numCiting": 46,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Optimal-matching-problem-in-detection-and-Liu-Haralick",
            "title": {
                "fragments": [],
                "text": "Optimal matching problem in detection and recognition performance evaluation"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit."
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2853851"
                        ],
                        "name": "I. Gath",
                        "slug": "I.-Gath",
                        "structuredName": {
                            "firstName": "Isak",
                            "lastName": "Gath",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Gath"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "6848408"
                        ],
                        "name": "Amir B. Geva",
                        "slug": "Amir-B.-Geva",
                        "structuredName": {
                            "firstName": "Amir",
                            "lastName": "Geva",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Amir B. Geva"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 57,
                                "start": 53
                            }
                        ],
                        "text": "The components with height or width larger than three times of the dominant character height are split using the method in [15] because they are almost formed by touched multiple characters and such big components affect the result of MST clustering."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 42203199,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fd3828d1465baf3719195ad98971fad66162ce67",
            "isKey": false,
            "numCitedBy": 1728,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "This study reports on a method for carrying out fuzzy classification without a priori assumptions on the number of clusters in the data set. Assessment of cluster validity is based on performance measures using hypervolume and density criteria. An algorithm is derived from a combination of the fuzzy K-means algorithm and fuzzy maximum-likelihood estimation. The unsupervised fuzzy partition-optimal number of classes algorithm performs well in situations of large variability of cluster shapes, densities, and number of data points in each cluster. The algorithm was tested on different classes of simulated data, and on a real data set derived from sleep EEG signal. >"
            },
            "slug": "Unsupervised-Optimal-Fuzzy-Clustering-Gath-Geva",
            "title": {
                "fragments": [],
                "text": "Unsupervised Optimal Fuzzy Clustering"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "The unsupervised fuzzy partition-optimal number of classes algorithm performs well in situations of large variability of cluster shapes, densities, and number of data points in each cluster."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "65923678"
                        ],
                        "name": "J. Beidler",
                        "slug": "J.-Beidler",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Beidler",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Beidler"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 101,
                                "start": 98
                            }
                        ],
                        "text": "We previously used a hand-crafted distance metric [13], which works fairly well but not sufficiently."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 32058048,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f3cfa954d3a741629da043697b4a89214791a5d0",
            "isKey": false,
            "numCitedBy": 885,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "I m p 1 e m e n t a t i o n development process. In basic physics, there are two primitives, force and mass. Force acts on mass and mass is changed by the force. In software development, the analogy to mass is objects and the analogy to force is operations, or algorithms. The term \"object-oriented\" means various things to different groups of software developers. To some it may imply the use of a particular object-oriented programming language, like Smalltalk, Actor, or C++. To others it could mean the step before system implementation, or coding, in the software development process, an object-oriented approach to design. Object-oriented purists may view this book as one on object-based programming, using object-oriented analysis and design with implementation in Ada 95. In any case, whether we call it objectoriented or object-based, the approach transcends the specifics in any particular programming language. During the analysis phase, solution details are not important; the overriding concern is understanding the problem. An object-based approach to analysis"
            },
            "slug": "Data-Structures-and-Algorithms-Beidler",
            "title": {
                "fragments": [],
                "text": "Data Structures and Algorithms"
            },
            "tldr": {
                "abstractSimilarityScore": 37,
                "text": "Object-oriented purists may view this book as one on object-based programming, using object-oriented analysis and design with implementation in Ada 95, and the approach transcends the specifics in any particular programming language."
            },
            "venue": {
                "fragments": [],
                "text": "Undergraduate Texts in Computer Science"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145323121"
                        ],
                        "name": "J. Nelder",
                        "slug": "J.-Nelder",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Nelder",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Nelder"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144189443"
                        ],
                        "name": "R. Mead",
                        "slug": "R.-Mead",
                        "structuredName": {
                            "firstName": "Roger",
                            "lastName": "Mead",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Mead"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "To yield best performance for the above algorithms (MST clustering with hand-crafted metric, X\u2013Y cut, Docstrum, piece-wise projection), we use the Nelder\u2013Mead simplex search method [47] to optimize the free parameters of them based on ground-truthed data as Mao et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2208295,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "017ddb7e815236defd0566bc46f6ed8401cc6ba6",
            "isKey": false,
            "numCitedBy": 25603,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "A method is described for the minimization of a function of n variables, which depends on the comparison of function values at the (n 41) vertices of a general simplex, followed by the replacement of the vertex with the highest value by another point. The simplex adapts itself to the local landscape, and contracts on to the final minimum. The method is shown to be effective and computationally compact. A procedure is given for the estimation of the Hessian matrix in the neighbourhood of the minimum, needed in statistical estimation problems."
            },
            "slug": "A-Simplex-Method-for-Function-Minimization-Nelder-Mead",
            "title": {
                "fragments": [],
                "text": "A Simplex Method for Function Minimization"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "A method is described for the minimization of a function of n variables, which depends on the comparison of function values at the (n 41) vertices of a general simplex, followed by the replacement of the vertex with the highest value by another point."
            },
            "venue": {
                "fragments": [],
                "text": "Comput. J."
            },
            "year": 1965
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2014414"
                        ],
                        "name": "L. Vandenberghe",
                        "slug": "L.-Vandenberghe",
                        "structuredName": {
                            "firstName": "Lieven",
                            "lastName": "Vandenberghe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Vandenberghe"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1843103"
                        ],
                        "name": "Stephen P. Boyd",
                        "slug": "Stephen-P.-Boyd",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Boyd",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Stephen P. Boyd"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Hence, we formulate the problem of metric learning as a convex programming problem [35]:"
                    },
                    "intents": []
                }
            ],
            "corpusId": 10531091,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "e309a155425162cf3b363b9393291b4f568416a0",
            "isKey": false,
            "numCitedBy": 2642,
            "numCiting": 265,
            "paperAbstract": {
                "fragments": [],
                "text": "In semidefinite programming, one minimizes a linear function subject to the constraint that an affine combination of symmetric matrices is positive semidefinite. Such a constraint is nonlinear and nonsmooth, but convex, so semidefinite programs are convex optimization problems. Semidefinite programming unifies several standard problems (e.g., linear and quadratic programming) and finds many applications in engineering and combinatorial optimization. Although semidefinite programs are much more general than linear programs, they are not much harder to solve. Most interior-point methods for linear programming have been generalized to semidefinite programs. As in linear programming, these methods have polynomial worst-case complexity and perform very well in practice. This paper gives a survey of the theory and applications of semidefinite programs and an introduction to primaldual interior-point methods for their solution."
            },
            "slug": "Semidefinite-Programming-Vandenberghe-Boyd",
            "title": {
                "fragments": [],
                "text": "Semidefinite Programming"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "A survey of the theory and applications of semidefinite programs and an introduction to primaldual interior-point methods for their solution are given."
            },
            "venue": {
                "fragments": [],
                "text": "SIAM Rev."
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 220,
                                "start": 216
                            }
                        ],
                        "text": "Since the images in the HIT-MW database are not labeled at connected components level (only a part of images have been segmented into text lines), we have annotated 105 document images using our ground truthing tool GTLC [19]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 215,
                                "start": 211
                            }
                        ],
                        "text": "Since the images in the HIT-MW database are not labeled at CCs level (only a part of images have been segmented into text lines), we have annotated all the 853 document images using our groundtruthing tool GTLC [42]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 90,
                                "start": 86
                            }
                        ],
                        "text": "To do this, we annotated some training document images using our ground-truthing tool GTLC (Ground-truthing tool for Text Lines and Characters) [19], which label the text lines and characters by automated transcript alignment and hand correction."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 168,
                                "start": 164
                            }
                        ],
                        "text": "To do this, we annotated some training document images using our ground-truthing tool GTLC (Ground-truthing tool for handwritten Chinese Text Lines and Characters) [42], which labels text lines and characters by automated transcript alignment and hand correction."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A tool for ground-truthing text lines and characters in handwritten Chinese documents, submitted to ICDAR2009"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2009
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 29,
                                "start": 25
                            }
                        ],
                        "text": "3 using the algorithm in [37] (a) and the algorithm in [39] (b)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 196,
                                "start": 189
                            }
                        ],
                        "text": "In addition to comparison with our previous clustering algorithm with hand-crafted metric [28], we compared the hypervolume reduction criterion in text line grouping with other criteria in [37,39]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 19,
                                "start": 15
                            }
                        ],
                        "text": "The authors of [37] demonstrated that this method was more efficient than the algorithm in [36]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 27,
                                "start": 23
                            }
                        ],
                        "text": "Since the criterion in [37] finds a global threshold of edge length, between-line Table 3"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 33,
                                "start": 26
                            }
                        ],
                        "text": "3 using the algorithms of [37,39] are shown in Fig."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 15,
                                "start": 11
                            }
                        ],
                        "text": "The one in [37] finds a global threshold of edge length according to the edge length histogram of the linkage graph, then, all the edges with length over the threshold are cut."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 143,
                                "start": 136
                            }
                        ],
                        "text": "To compare the text line segmentation performance of the proposed hypervolume reduction criterion with other MST clustering criteria in [37,39], we used the same 150 images as in Section 6."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 47,
                                "start": 40
                            }
                        ],
                        "text": "After MST clustering, the algorithms in [37,39] cut edges in difference ways."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A threshold criterion"
            },
            "venue": {
                "fragments": [],
                "text": "auto-detection and its use in MST-based clustering, Intelligence Data Analysis 9 (3) "
            },
            "year": 2005
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 59,
                                "start": 55
                            }
                        ],
                        "text": "3 using the algorithm in [37] (a) and the algorithm in [39] (b)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 196,
                                "start": 189
                            }
                        ],
                        "text": "In addition to comparison with our previous clustering algorithm with hand-crafted metric [28], we compared the hypervolume reduction criterion in text line grouping with other criteria in [37,39]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 24,
                                "start": 20
                            }
                        ],
                        "text": "By the criterion in [39], we observed that the local minimum of the standard deviation reduction function always gives fewer clusters than the real number of text lines."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 33,
                                "start": 26
                            }
                        ],
                        "text": "3 using the algorithms of [37,39] are shown in Fig."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 143,
                                "start": 136
                            }
                        ],
                        "text": "To compare the text line segmentation performance of the proposed hypervolume reduction criterion with other MST clustering criteria in [37,39], we used the same 150 images as in Section 6."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 21,
                                "start": 17
                            }
                        ],
                        "text": "The algorithm in [39] measures each hypothesized cluster (subtree) using the standard deviation of edge lengths within the subtree."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 47,
                                "start": 40
                            }
                        ],
                        "text": "After MST clustering, the algorithms in [37,39] cut edges in difference ways."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Minimum spanning tree based clustering algorithm"
            },
            "venue": {
                "fragments": [],
                "text": "in: Proceeding of the 18th International Conference on Tools with Artificial Intelligence"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2139654987"
                        ],
                        "name": "Yao Pu",
                        "slug": "Yao-Pu",
                        "structuredName": {
                            "firstName": "Yao",
                            "lastName": "Pu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yao Pu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1708019"
                        ],
                        "name": "Zhixin Shi",
                        "slug": "Zhixin-Shi",
                        "structuredName": {
                            "firstName": "Zhixin",
                            "lastName": "Shi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zhixin Shi"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "The Hough transform algorithm has also been applied to handwritten text line detection [ 11 ][12], with the gravity centers or minima points of connected components as the points to be fitted, but needs a sophisticated post-processing procedure to extract the lines."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 60062262,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "761b5b3a2c8dff088c8f32fb8933c4681f9223ff",
            "isKey": false,
            "numCitedBy": 66,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-natural-learning-algorithm-based-on-Hough-for-in-Pu-Shi",
            "title": {
                "fragments": [],
                "text": "A natural learning algorithm based on Hough transform for text lines extraction in handwritten documents"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38138508"
                        ],
                        "name": "C. Faure",
                        "slug": "C.-Faure",
                        "structuredName": {
                            "firstName": "Claudie",
                            "lastName": "Faure",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Faure"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3806481"
                        ],
                        "name": "P. Keuss",
                        "slug": "P.-Keuss",
                        "structuredName": {
                            "firstName": "P.",
                            "lastName": "Keuss",
                            "middleNames": [
                                "J.",
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Keuss"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2915873"
                        ],
                        "name": "G. Lorette",
                        "slug": "G.-Lorette",
                        "structuredName": {
                            "firstName": "Guy",
                            "lastName": "Lorette",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Lorette"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2377682"
                        ],
                        "name": "A. Vinter",
                        "slug": "A.-Vinter",
                        "structuredName": {
                            "firstName": "Annie",
                            "lastName": "Vinter",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Vinter"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Keywords: Handwritten Text Line Segmentation, Clustering, Minimal Spanning Tree (MST), Distance Metric Learning."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 140,
                                "start": 137
                            }
                        ],
                        "text": "Bottom-up grouping is more complicated in computation than top-down partitioning, and its performance relies on some heuristic rules or artificial parameters, such as the betweencomponent distance metric for clustering."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 57510553,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "d09be06f19cff6114ed7d0037f38de212dc29d91",
            "isKey": false,
            "numCitedBy": 135,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Advances-in-Handwriting-and-Drawing:-a-approach-Faure-Keuss",
            "title": {
                "fragments": [],
                "text": "Advances in Handwriting and Drawing: a multidisciplinary approach"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Keywords: Handwritten Text Line Segmentation, Clustering, Minimal Spanning Tree (MST), Distance Metric Learning."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 101,
                                "start": 98
                            }
                        ],
                        "text": "Top-down methods partition the document image recursively into text regions, text lines, and words/characters."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Scriptindependent text line segmentation in freestyle handwritten document"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Analysis and Machine Intelligence"
            },
            "year": 2008
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Keywords: Handwritten Text Line Segmentation, Clustering, Minimal Spanning Tree (MST), Distance Metric Learning."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 101,
                                "start": 98
                            }
                        ],
                        "text": "Top-down methods partition the document image recursively into text regions, text lines, and words/characters."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Scriptindependent text line segmentation in freestyle handwritten document"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Analysis and Machine Intelligence"
            },
            "year": 2008
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 15,
                                "start": 11
                            }
                        ],
                        "text": "It merges neighboring connected components using rules based on the geometric relationship between K nearest neighbor units, and performs well on printed documents as well as slightly curved handwritten documents."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Text line extraction from India document"
            },
            "venue": {
                "fragments": [],
                "text": "Proceeding of Fifth International Conference on Advances in Pattern Recognition"
            },
            "year": 2003
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A tool for ground-truthing text lines and characters in handwritten documents"
            },
            "venue": {
                "fragments": [],
                "text": "A tool for ground-truthing text lines and characters in handwritten documents"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 109,
                                "start": 102
                            }
                        ],
                        "text": "The Hough transform has also been applied to handwritten text line detection with the gravity centers [19,20] or minima points [21] of CCs as the points to be fitted."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A robust and fast skew detection algorithm for generic document"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognition 29 (10) "
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 29,
                                "start": 26
                            }
                        ],
                        "text": "Likforman-Sulem and Faure [1] developed an iterative method based on perceptual grouping using three Gestalt criteria, namely, proximity, similarity and direction continuity, to group connected components."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 99,
                                "start": 94
                            }
                        ],
                        "text": "Some efforts have been devoted to the difficult problem of handwritten text line segmentation [1-6]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Extracting lines on handwritten document by perceptual grouping"
            },
            "venue": {
                "fragments": [],
                "text": "In: Advances in Handwriting and Drawing: A Multidisciplinary Approach, pp. 21-38"
            },
            "year": 1994
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 22,
            "methodology": 28,
            "result": 1
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 55,
        "totalPages": 6
    },
    "page_url": "https://www.semanticscholar.org/paper/Handwritten-Chinese-text-line-segmentation-by-with-Yin-Liu/559d7f70d6bb0a5f81790b449e415d919acc2f28?sort=total-citations"
}