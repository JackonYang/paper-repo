{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694191"
                        ],
                        "name": "J. Hull",
                        "slug": "J.-Hull",
                        "structuredName": {
                            "firstName": "Jonathan",
                            "lastName": "Hull",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Hull"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 8148915,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "62a134740314b4469c83c8921ae2e1beea22b8f5",
            "isKey": false,
            "numCitedBy": 1725,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "An image database for handwritten text recognition research is described. Digital images of approximately 5000 city names, 5000 state names, 10000 ZIP Codes, and 50000 alphanumeric characters are included. Each image was scanned from mail in a working post office at 300 pixels/in in 8-bit gray scale on a high-quality flat bed digitizer. The data were unconstrained for the writer, style, and method of preparation. These characteristics help overcome the limitations of earlier databases that contained only isolated characters or were prepared in a laboratory setting under prescribed circumstances. Also, the database is divided into explicit training and testing sets to facilitate the sharing of results among researchers as well as performance comparisons. >"
            },
            "slug": "A-Database-for-Handwritten-Text-Recognition-Hull",
            "title": {
                "fragments": [],
                "text": "A Database for Handwritten Text Recognition Research"
            },
            "tldr": {
                "abstractSimilarityScore": 81,
                "text": "An image database for handwritten text recognition research is described that contains digital images of approximately 5000 city names, 5000 state names, 10000 ZIP Codes, and 50000 alphanumeric characters to overcome the limitations of earlier databases."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1744200"
                        ],
                        "name": "I. T. Phillips",
                        "slug": "I.-T.-Phillips",
                        "structuredName": {
                            "firstName": "Ihsin",
                            "lastName": "Phillips",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. T. Phillips"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2122930"
                        ],
                        "name": "J. Ha",
                        "slug": "J.-Ha",
                        "structuredName": {
                            "firstName": "Jaekyu",
                            "lastName": "Ha",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Ha"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1710238"
                        ],
                        "name": "R. Haralick",
                        "slug": "R.-Haralick",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Haralick",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Haralick"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144964966"
                        ],
                        "name": "D. Dori",
                        "slug": "D.-Dori",
                        "structuredName": {
                            "firstName": "Dov",
                            "lastName": "Dori",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Dori"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 206774383,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "db39e919eb934b70e2cd76ddfbe4cd88138e4acd",
            "isKey": false,
            "numCitedBy": 29,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Producing a database of scanned document images for development or evaluation of OCR and document image understanding algorithms is neither easy nor inexpensive. The authors first briefly describe the makeup of a database of scanned document images of scientific and technical documents written in English which are being produced in a CD-ROM format. Then, the authors concentrate on the implementation methodology used to prepare the database. The methodology gives the protocols for each step of the database preparation, and the error model used for the estimation of the ground-truth errors that may exist in the database is discussed.<<ETX>>"
            },
            "slug": "The-implementation-methodology-for-a-CD-ROM-English-Phillips-Ha",
            "title": {
                "fragments": [],
                "text": "The implementation methodology for a CD-ROM English document database"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "The authors first briefly describe the makeup of a database of scanned document images of scientific and technical documents written in English which are being produced in a CD-ROM format and concentrate on the implementation methodology used to prepare the database."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of 2nd International Conference on Document Analysis and Recognition (ICDAR '93)"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1720945"
                        ],
                        "name": "H. Bunke",
                        "slug": "H.-Bunke",
                        "structuredName": {
                            "firstName": "Horst",
                            "lastName": "Bunke",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Bunke"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152702577"
                        ],
                        "name": "P. Wang",
                        "slug": "P.-Wang",
                        "structuredName": {
                            "firstName": "Patrick",
                            "lastName": "Wang",
                            "middleNames": [
                                "Shen-Pei"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Wang"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 50,
                                "start": 47
                            }
                        ],
                        "text": "The databases are distributed on a CDROM media [9]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 61127346,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "254f2099bf162b75add8f4606f56221cce5d595a",
            "isKey": false,
            "numCitedBy": 343,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Arabic character recognition, A. Amin automatic reading of braille documents, A. Antonacopoulos techniques for improving OCR results, A. Dengel offline handwritten word recognition using hidden Markov models, A. Kundu combinations of multiple classifier decisions for OCR, L. Lam and C.Y. Suen classification techniques - statistical pattern recognition, neural networks and their relations, J. Schurmann cursive handwriting recognition - contextual and context - free techniques, M. Shridhar and Kimura multilingual document recognition, L. Spitz information retrieval and OCR, K. Taghva technical drawing analysis - including vectorization, D. Dori and K. Tombre reading of music notation, N. Carter and D. Bainbridge benchmarking, T. Nartker et al automatic signature verification, S. Impedovo. (Part Contents)."
            },
            "slug": "Handbook-of-Character-Recognition-and-Document-Bunke-Wang",
            "title": {
                "fragments": [],
                "text": "Handbook of Character Recognition and Document Image Analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 98,
                "text": "Arabic character recognition, A. Amin automatic reading of braille documents, and Antonacopoulos techniques for improving OCR results."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1743797"
                        ],
                        "name": "I. Guyon",
                        "slug": "I.-Guyon",
                        "structuredName": {
                            "firstName": "Isabelle",
                            "lastName": "Guyon",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Guyon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1799278"
                        ],
                        "name": "Lambert Schomaker",
                        "slug": "Lambert-Schomaker",
                        "structuredName": {
                            "firstName": "Lambert",
                            "lastName": "Schomaker",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lambert Schomaker"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144586498"
                        ],
                        "name": "R. Plamondon",
                        "slug": "R.-Plamondon",
                        "structuredName": {
                            "firstName": "R\u00e9jean",
                            "lastName": "Plamondon",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Plamondon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144173823"
                        ],
                        "name": "M. Liberman",
                        "slug": "M.-Liberman",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Liberman",
                            "middleNames": [
                                "Y."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Liberman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2123720"
                        ],
                        "name": "S. Janet",
                        "slug": "S.-Janet",
                        "structuredName": {
                            "firstName": "Stanley",
                            "lastName": "Janet",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Janet"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 46942410,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "841c2fd138791b06e4afa01ac2b828618343f1af",
            "isKey": false,
            "numCitedBy": 441,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "We report the status of the UNIPEN project of data exchange and recognizer benchmarks started two years ago at the initiative of the International Association of Pattern Recognition (Technical Committee 11). The purpose of the project is to propose and implement solutions to the growing need of handwriting samples for online handwriting recognizers used by pen-based computers. Researchers from several companies and universities have agreed on a data format, a platform of data exchange and a protocol for recognizer benchmarks. The online handwriting data of concern may include handprint and cursive from various alphabets (including Latin and Chinese), signatures and pen gestures. These data will be compiled and distributed by the Linguistic Data Consortium. The benchmarks will be arbitrated the US National Institute of Standards and Technologies. We give a brief introduction to the UNIPEN format. We explain the protocol of data exchange and benchmarks."
            },
            "slug": "UNIPEN-project-of-on-line-data-exchange-and-Guyon-Schomaker",
            "title": {
                "fragments": [],
                "text": "UNIPEN project of on-line data exchange and recognizer benchmarks"
            },
            "tldr": {
                "abstractSimilarityScore": 61,
                "text": "The status of the UNIPEN project of data exchange and recognizer benchmarks started two years ago is reported, to propose and implement solutions to the growing need of handwriting samples for online handwriting recognizers used by pen-based computers."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 12th IAPR International Conference on Pattern Recognition, Vol. 3 - Conference C: Signal Processing (Cat. No.94CH3440-5)"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2122930"
                        ],
                        "name": "J. Ha",
                        "slug": "J.-Ha",
                        "structuredName": {
                            "firstName": "Jaekyu",
                            "lastName": "Ha",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Ha"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1710238"
                        ],
                        "name": "R. Haralick",
                        "slug": "R.-Haralick",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Haralick",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Haralick"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153064717"
                        ],
                        "name": "S. Chen",
                        "slug": "S.-Chen",
                        "structuredName": {
                            "firstName": "S.",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1744200"
                        ],
                        "name": "I. T. Phillips",
                        "slug": "I.-T.-Phillips",
                        "structuredName": {
                            "firstName": "Ihsin",
                            "lastName": "Phillips",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. T. Phillips"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 63033759,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7f8e70fd5de8a4dd3bf4bf5c444e9b334f5924da",
            "isKey": false,
            "numCitedBy": 3,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Document database preparation is a very time-consuming job and usually requires the involvement of many people. Any database is likely to have some errors however carefully it has been constructed. This paper discusses how to estimate the distribution of errors contained in a database which has been constructed either with a double data entry and single correction procedure or with a double data entry and double correction procedure. We validate the approach on a large synthetically generated data set and on the UW English Document Image Database I which has about 2.6 million characters. The results indicate that the expected number of errors that remain in the database is about 75 for an error rate of about 29 per million characters."
            },
            "slug": "Estimating-errors-in-document-databases-Ha-Haralick",
            "title": {
                "fragments": [],
                "text": "Estimating errors in document databases"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "The approach is validated on a large synthetically generated data set and on the UW English Document Image Database I which has about 2.6 million characters and indicates that the expected number of errors that remain in the database is about 75 for an error rate of about 29 per million characters."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145916951"
                        ],
                        "name": "G. Nagy",
                        "slug": "G.-Nagy",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Nagy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Nagy"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 61651523,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "19b2308e9bbe77d2059706891a757bb90cb73049",
            "isKey": false,
            "numCitedBy": 130,
            "numCiting": 40,
            "paperAbstract": {
                "fragments": [],
                "text": "It is argued that it is time for a major change of approach to optical character recognition (OCR) research. The traditional approach, focusing on the correct classification of isolated characters, has been exhausted. The demonstration of the superiority of a new classification method under operational conditions requires large experimental facilities and databases beyond the resources of most researchers. In any case, even perfect classification of individual characters is insufficient for the conversion of complex archival documents to a useful computer-readable form. Many practical OCR tasks require integrated treatment of entire documents and well-organized typographic and domain-specific knowledge. New OCR systems should take advantage of the typographic uniformity of paragraphs or other layout components. They should also exploit the unavoidable interaction with human operators to improve themselves without explicit 'training'. >"
            },
            "slug": "At-the-frontiers-of-OCR-Nagy",
            "title": {
                "fragments": [],
                "text": "At the frontiers of OCR"
            },
            "tldr": {
                "abstractSimilarityScore": 67,
                "text": "It is argued that it is time for a major change of approach to optical character recognition (OCR) research, and new OCR systems should take advantage of the typographic uniformity of paragraphs or other layout components."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1743797"
                        ],
                        "name": "I. Guyon",
                        "slug": "I.-Guyon",
                        "structuredName": {
                            "firstName": "Isabelle",
                            "lastName": "Guyon",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Guyon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "10080270"
                        ],
                        "name": "J. Makhoul",
                        "slug": "J.-Makhoul",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Makhoul",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Makhoul"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35442155"
                        ],
                        "name": "R. Schwartz",
                        "slug": "R.-Schwartz",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Schwartz",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Schwartz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50560492"
                        ],
                        "name": "V. Vapnik",
                        "slug": "V.-Vapnik",
                        "structuredName": {
                            "firstName": "Vladimir",
                            "lastName": "Vapnik",
                            "middleNames": [
                                "Naumovich"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Vapnik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 11967381,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9df9376862331adc22907fbf4a9dd3f83edc2c51",
            "isKey": false,
            "numCitedBy": 160,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "We address the problem of determining what size test set guarantees statistically significant results in a character recognition task, as a function of the expected error rate. We provide a statistical analysis showing that if, for example, the expected character error rate is around 1 percent, then, with a test set of at least 10,000 statistically independent handwritten characters (which could be obtained by taking 100 characters from each of 100 different writers), we guarantee, with 95 percent confidence, that: (1) the expected value of the character error rate is not worse than 1.25 E, where E is the empirical character error rate of the best recognizer, calculated on the test set; and (2) a difference of 0.3 E between the error rates of two recognizers is significant. We developed this framework with character recognition applications in mind, but it applies as well to speech recognition and to other pattern recognition problems."
            },
            "slug": "What-Size-Test-Set-Gives-Good-Error-Rate-Estimates-Guyon-Makhoul",
            "title": {
                "fragments": [],
                "text": "What Size Test Set Gives Good Error Rate Estimates?"
            },
            "tldr": {
                "abstractSimilarityScore": 93,
                "text": "This work addresses the problem of determining what size test set guarantees statistically significant results in a character recognition task, as a function of the expected error rate, by providing a statistical analysis showing that if, for example, the expected character error rate is around 1 percent, then, with a test set of at least 10,000 statistically independent handwritten characters, that is guaranteed."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1723766"
                        ],
                        "name": "H. Baird",
                        "slug": "H.-Baird",
                        "structuredName": {
                            "firstName": "Henry",
                            "lastName": "Baird",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Baird"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 61076153,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b0eb7232dc0ceae32aad26c918a24e2775020d46",
            "isKey": false,
            "numCitedBy": 339,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": "A lack of explicit quantitative models of imaging defects due to printing, optics, and digitization has retarded progress in some areas of document image analysis, including syntactic and structural approaches. Establishing the essential properties of such models, such as completeness (expressive power) and calibration (closeness of fit to actual image populations) remain open research problems. Work-in-progress towards a parameterized model of local imaging defects is described, together with a variety of motivating theoretical arguments and empirical evidence. A pseudo-random image generator implementing the model has been built. Applications of the generator are described, including a polyfont classifier for ASCII and a single-font classifier for a large alphabet (Tibetan U-Chen), both of which which were constructed with a minimum of manual effort. Image defect models and their associated generators permit a new kind of image database which is explicitly parameterized and indefinitely extensible, alleviating some drawbacks of existing databases."
            },
            "slug": "Document-image-defect-models-Baird",
            "title": {
                "fragments": [],
                "text": "Document image defect models"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "Work-in-progress towards a parameterized model of local imaging defects is described, together with a variety of motivating theoretical arguments and empirical evidence, and a pseudo-random image generator implementing the model has been built."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143677016"
                        ],
                        "name": "K. Mohiuddin",
                        "slug": "K.-Mohiuddin",
                        "structuredName": {
                            "firstName": "K.",
                            "lastName": "Mohiuddin",
                            "middleNames": [
                                "Moidin"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Mohiuddin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 195867354,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "15dedaa657ff7cbb283aaf96d9be2f4c5dcea694",
            "isKey": false,
            "numCitedBy": 34,
            "numCiting": 49,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "International-Conference-On-Document-Analysis-and-Mohiuddin",
            "title": {
                "fragments": [],
                "text": "International Conference On Document Analysis and Recognition"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of 3rd International Conference on Document Analysis and Recognition"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "CD-ROM Document Database Standard, International Conference on Document Analysis and Recognition 478{4833 reprinted in Document Image Analysis by"
            },
            "venue": {
                "fragments": [],
                "text": "CD-ROM Document Database Standard, International Conference on Document Analysis and Recognition 478{4833 reprinted in Document Image Analysis by"
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A speciication for an ink storage and interchange format Slate Corporation"
            },
            "venue": {
                "fragments": [],
                "text": "A speciication for an ink storage and interchange format Slate Corporation"
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A t the frontiers of OCR"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. of the IEEE"
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 50,
                                "start": 47
                            }
                        ],
                        "text": "The databases are distributed on a CDROM media [9]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "CD-ROM Document Database  Standard, International Conference on Document Analysis and Recognition"
            },
            "venue": {
                "fragments": [],
                "text": "Tsukuba Japan,"
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A specification for an ink storage and interchange format Slate Corporation"
            },
            "venue": {
                "fragments": [],
                "text": "A specification for an ink storage and interchange format Slate Corporation"
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "English document database design and implementation methodology"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. of the Second Annual Symposium on Document Analysis and Information Retrieval"
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 15853,
                                "start": 15850
                            }
                        ],
                        "text": "Seattle WA yun seattleu edu\nSeveral signi cant sets of labeled samples of image data are surveyed that can be used in the development of algorithms for o ine and online handwriting recognition as well as for machine printed text recognition The method used to gather each data set the numbers of samples they contain and the associated truth data are discussed In the domain of o ine handwriting the CEDAR NIST and CENPARMI data sets are pre sented These contain primarily isolated digits and alphabetic characters The UNIPEN data set of online handwriting was collected from a number of independent sources and it contains individual characters as well as handwritten phrases The University of Wash ington document image databases are also discussed They contain a large number of English and Japanese document images that were selected from a range of publications\nKeywords Data sets databases text images online handwriting o ine handwriting machine printed text CEDAR NIST CENPARMI UNIPEN University of Washington\nIntroduction\nThe availability of a data set that contains an appropriate number and selection of samples is a critical part of any experimental research project This is especially true in an image based application such as optical character recognition OCR\nwhere it is sometimes di cult for individual researchers to gather the number and type of data they need because of the costs involved Ideally a data set would allow a researcher to project the performance achieved experimentally to the appli cation domain represented by the data set This implies that the data set used for algorithm development should re ect the application domain as closely as possible\nA signi cant advance in the experimental integrity of OCR research has been made possible in recent years with the availability of several image data sets These data sets allow researchers to train and test algorithms on signi cant numbers of data items and to compare performance on speci c images This has improved productivity since researchers can conduct experiments without rst gathering data\nThere are three areas of OCR research o ine handwriting online handwriting and machine printed text that require specialized data sets O ine handwriting is produced by an individual typically by writing with a pen or pencil on paper and is scanned into a digital format Online handwriting is written directly on a digitizing tablet with a stylus The output is a sequence of x y coordinates that express pen position as well as other information such as pressure Machine printed text occurs commonly in daily use and is produced by o set processes laser inkjet or dot matrix printing Each area has unique characteristics that a ect the design of a data set These characteristics determine how well experimental results on that data set can be generalized to another application\nO ine handwritten text data sets typically contain isolated alphanumeric char acters or words These data sets are often produced by choosing subjects to write on sample forms that are subsequently digitized An important consideration in the design of data sets in this area is how well the subjects that produce the data and the conditions under which the data are gathered represent the eventual ap plication Ideally the subjects should be chosen from the same population and the data gathered under the same conditions e g data gathered in the eld same data form used etc that will be used in the nal application Otherwise signi cant di erences in performance can occur between the data set and the data used in practice\nDatabases of online handwriting also contain isolated characters and words as well as text phrases Research in online handwriting recognition has been conducted for many years at a large number of research labs Each project typically developed their own databases for internal use The UNIPEN project has taken advantage of this existing body of data by asking individual research groups to contribute their databases to a common set This data set will rst be used for a comparative benchmark It will then be shared with the rest of the research community A signi cant issue in UNIPEN was the large number of di erent formats used for online handwriting This was solved by the development of a common data format which is described in this chapter The background history and future of the UNIPEN e ort are also discussed\nMachine printed text data sets often include images of complete pages These pages can be chosen from a large number of di erent classes of machine printed document e g scienti c papers memorandums newspapers etc and can vary widely in format fonts point size column layout etc A signi cant consideration is the document classes and variations in format represented in the data set Also the ground truth information supplied with such a data set should be comprehensive so that it can be used to improve the performance of OCR algorithms This is signi cant since modern OCR systems are a ected by many aspects of the data format which are often inter related This chapter describes the CDROM data sets developed by the University of Washington which include several document classes and extensive truth data\nThe rest of this paper describes several data sets of o ine and online handwrit ing as well as machine printed text We discuss the contents of these data sets and describe how they address various research considerations\nO ine Handwritten Text\nThere are at least two classes of databases of o ine handwritten text that are of interest to most researchers Datasets that contain isolated handprinted characters and digits have been used in the development of many pattern recognition algo rithms The recognition problem represented by these data is well de ned e g or classes and the recognition task is relatively easy for ordinary people A reliable solution to this problem could have signi cant economic consequences since many handwritten forms could be read automatically\nData sets can also contain isolated handwritten words and phrases The recog nition problem represented by these data is more challenging since the number of classes is larger e g there are more than legal ZIP Codes in the U S and there may be few constraints on how users prepare the samples However a robust solution to this problem would be even more signi cant than for isolated character recognition since it would provide a general purpose computer input medium\nImportant considerations when evaluating the usefulness of a data set for ex perimental purposes include the number of samples it contains the sampling rate at which it was captured and the pixel depth at which the data is furnished Com monly used sampling rates include or pixels per inch ppi and pixel depths are usually one or eight bits Such image characteristics are also important system design parameters since they in uence the ultimate cost of an implementation\nIsolated Digits and Alphabetic Characters\nIsolated digit and character recognition is one of the most extensively studied ap plication domains in pattern recognition Some of the earliest databases of digital images beginning at least in were composed of single characters see for\na review In recent years several signi cant collections of such data have been issued\nThe CEDAR data set contains nearly examples of isolated handwritten characters and digits that were extracted from images of postal addresses En velopes with handwritten addresses on them were sampled from the mail as it was being processed in a post o ce This assured that the people that prepared the original data were not aware that their addresses would be included in the data set The address images were scanned at ppi in bit gray scale and later reduced to one bit images Individual characters and digits were segmented from the address images by a semi automatic process that extracted single connected components These were displayed to a human operator who entered their truth values\nAn additional group of about digits were also extracted from ZIP Codes in the CEDAR data set by a fully automatic segmentation algorithm These digits were manually screened for quality and placed into a good set if they contained no segmentation artifacts that could be considered errors such as one digit split into two All the digits output by the segmentation algorithm are also provided in the data set This provides some challenging examples for testing the performance of an algorithm since artifacts caused by segmentation are preserved in the individual images\nThe CENPARMI data set contains isolated digits that were extracted from images of about postal ZIP Codes The ZIP Codes were selected from dead letter mail in a working post o ce and thus the preparers of the data also were separated from the data collection task The ZIP Codes were scanned at ppi with a one bit digitizer The isolated digits were extracted from the ZIP Codes by a manual segmentation process that displayed individual images to operators who entered their identities\nThe NIST data set SD contains one of the largest selections of isolated digits and characters that are publically available Altogether it contains over character images that were extracted from data collection forms lled out by individuals Employees of the U S Bureau of the Census were instructed to ll the boxes on a form with a particular sequence of digits or characters and were asked to make sure that the individual digits or characters did not touch one another or the surrounding box The forms were subsequently scanned at ppi in binary mode and automatically segmented The string of digits that should have been written in each box was used to assign a truth value to each individual image The truth values were subsequently veri ed by a human operator\nAn interesting issue in data set design is presented by the NIST images The initial collection process described above was done in preparation for a competition that evaluated the performance of more than di erent algorithms in isolated digit and character recognition The images on SD were provided as a training set and were used by most of the competing organizations in developing their methods A separate data set called TD was collected to provide test data The same\ncollection process was used However the subjects were high school students The quality of the data varied more widely in TD than it did in SD and was on the whole more sloppy This caused a signi cant drop in performance on the test data because most systems had been trained on the neater images This experience shows that a given technique may perform very well on a speci c data set However this does not necessarily mean that the recognition problem represented by that data has been solved It can mean that the recognition problem has been solved for that data set only The generalization of any results to a larger population should only be made after careful consideration and comparison of the training and test data to the real life application\nWord and Phrase Recognition\nWord and phrase recognition is a less frequently studied application of pattern recognition than digit or character recognition However words or phrases o er contextual constraints such as dictionaries that make it possible to model interac tions between image processing operations such as segmentation and the recognition of isolated symbols given that only certain sequences of symbols occur in the dic tionary\nZIP Codes city names and state names are examples of handwritten word images that are available in the CEDAR data set Approximately ZIP Codes city names and state name images are included These data were scanned by the process described above However the ppi bit gray scale versions of the whole word images are provided and the speci c address in which each image occurred is identi ed Thus experimentation can be performed with isolated word recognition on gray scale data and a comprehensive system could be developed that used partial results from recognition of the city or state name to in uence the recognition of speci c digits in the corresponding ZIP Code\nA signi cant amount of running English text is also available in the NIST SD and TD data sets Each collection form contained a Constitution box in which subjects wrote the word preamble to the Constitution of the United States This data was scanned at ppi in bit format as part of the normal data capture process These images also make it possible to develop algorithms that integrate early processing with contextual analysis The domain is constrained enough that a range of contextual constraints can be investigated and at the same time the physical format is su ciently unconstrained the subjects could have written the preamble anywhere in a given box that it reasonably represents the way people would like to use handwriting to communicate with a computer\nThere are three other NIST data sets SD SD that contain examples of phrases that were written by respondents to the U S Census to describe their jobs Three boxes were lled in with the title of a person s job the work they do and the work done by the company they are employed by SD SD di er from SD and\nTD in that the people that prepared the data were from the general population and had no idea that their writing would be scanned Altogether handwritten phrases were scanned at ppi in binary mode of the phrases were scanned from micro lm and were scanned from the original paper versions These data are also provided with a dictionary of legal entries for each box that was derived from the previous census Thus there is no guarantee that the letter for letter transcription of each image appears in the dictionary The recognition task is to identify the dictionary entry that is the closest match to the phrase written in the box\nOnline Handwritten Text\nIn this section we present the design of a database for On Line Handwriting Recog nition OLHR The database is composed of isolated characters words and sen tences written in a variety of styles handprinted cursive or mixed The alphabet is restricted to the ASCII keyboard set The data were donated by di erent institutions and therefore includes a variety of writers and recording conditions The database size approaches million characters We provide some details about the data exchange platform which could inspire other similar e orts The database will be distributed to the public for a small fee by the Linguistic Data Consortium LDC in\nHistory of UNIPEN\nOn line handwriting recognition OLHR addresses the problem of recognizing hand writing from data collected with a sensitive pad which provides discretized pen tra jectory information OLHR has long been the poor parent of pattern recognition in terms of publicly available large corpora of data To remedy this problem the UNIPEN project was started in September at the initiative of the Technical Committee of the International Association for Pattern Recognition IAPR Two IAPR delegates Isabelle Guyon and Lambert Schomaker were appointed to explore the possibility of creating large OLHR databases\nIn the eld of OLHR there exist many privately owned databases These databases constitute a potential resource which is much richer than any single database because of the diversity of text entered recording conditions and writers Therefore data exchange is a natural way to constitute a sizable database which is representative of the tasks of interest to research and development groups\nA small working group of experts from Apple AT T HP GO IBM and NICI laid the foundations of UNIPEN in May and proposed that a common data format would be designed to facilitate data exchange In the summer of the UNIPEN format was designed incorporating features of the internal formats of several institutions including IBM Apple Tap Microsoft Slate Jot HP\nAT T NICI GO and CIC The format was then tested independently by members of the working group soon followed by many other volunteers A second iteration of the test was organized in autumn to check the changes and additions to the format In parallel a set of tools to parse the format and browse the data were developed at NICI with the sponsorship of HP and at AT T\nIn January NIST and LDC committed to help UNIPEN NIST has been supervising the data gathering and the organization of a benchmark test LDC will publish a CD ROM and distribute the data There is already an FTP site at LDC where data and programs can be exchanged\nIn June the instructions for participation in the rst UNIPEN benchmark limited to the Latin alphabet were released Potential participants were requested to donate isolated characters words or sentences containing at least charac ters Forty institutions responded to the call for data Further negotiations between owners of large databases succeeded in gathering larger data sets There are nearly ve million individual character samples in the database\nIn February the data donators met for a one day workshop to determine how the data will be split into training and test sets A benchmark test using these data will take place in During the test the data will remain the property of the data donators After the test it will become publicly available and will be distributed by LDC for a nominal fee\nThe activities of UNIPEN will expand in the future according to the needs and desires of the participants\nCollecting donated samples\nA common data format\nThe UNIPEN format is an ASCII format designed speci cally for data collected with any touch sensitive resistive or electro magnetic device providing discretized pen trajectory information Users can easily convert their own format to and from the UNIPEN format or collect data directly in that format\nThe minimum number of signal channels is two X and Y but more signals are allowed e g pen angle or pressure information In contrast with binary formats such as Jot the UNIPEN format is not optimized for data storage or real time data transmission and it is not designed to handle ink manipulation applications involving colors image rotations rescaling etc However in the UNIPEN format there are provisions for data annotation about recording conditions writers seg mentation data layout data quality labeling and recognition results\nE orts were made to make the format human intelligible without documenta tion keywords are explicit English words easily machine readable an awk parser was developed in conjunction with the development of the format itself compact few keywords complete enough keywords and expandable\nThe format is a succession of instructions consisting of a keyword followed by arguments Keywords are reserved words starting with a dot in the rst column of a line Arguments are strings or numbers separated by spaces tabs or new lines The arguments relative to a given keyword start after that keyword and end with the appearance of the next keyword or the end of le see Fig\nAlmost everything is optional so that simple data sets can be described in a simple way All variables are global declared variables retain their values until the next similar declaration Databases written in the UNIPEN format may be con catenated in a single le or they may be organized in di erent les and directories\nThe format can be thought of as a sequence of pen coordinates annotated with various information including segmentation and labeling The pen trajectory is encoded as a sequence of components A pen down component is a trace recorded when the pen is in contact with the surface of the digitizer A pen up component is a trace recorded when the pen is near the digitizer without touching it Compo nents are not necessarily delimited by pen lifts and may or may not coincide with strokes PEN DOWN and PEN UP contain pen coordinates e g XY or XY T as declared in COORD The instruction DT speci es the elapsed time between two components The database is divided into one or several data sets starting with START SET Within a set components are implicitly numbered starting from zero\nSegmentation and labeling are provided by the SEGMENT instruction Com ponent numbers are used by SEGMENT to delineate sentences words and char acters A segmentation hierarchy e g SENTENCE WORD CHARACTER is declared with HIERARCHY Because components are referred to by a unique combination of set name and order number in that set it is possible to separate the SEGMENT from the data itself\nThe format also provides a uni ed way of encoding recognizer outputs to be used for benchmark purposes To obtain more information about the format it is possible to access its full de nition electronically see next section\nInternet connections\nWithout the internet the Unipen project would not have been possible Electronic mail has been the primary means of communication between organizers and partic ipants The data and the tools were exchanged by FTP\nIn March UNIPEN advertised its existence on several electronic mailing lists resulting in nearly subscriptions to the UNIPEN newsletter People in terested in UNIPEN can send a request to be added to the Scrib L mailing list Scrib L is a mailing list for researchers and developers in the eld of handwriting Electronic mail to\nSCRIB L NIC SURFNET NL\nVERSION DATA SOURCE ATT DATA ID Example\nCOMMENT Documentation\nDATA CONTACT Isabelle Guyon isabelle research att com DATA INFO Latin alphabet isolated characters Data cleaned manually SETUP Volunteer staff members People sitting at a desk PAD WACOM HD A LCD Digitizer\nCOMMENT Declarations\nX DIM Y DIM H LINE X POINTS PER INCH Y POINTS PER INCH POINTS PER SECOND COORD X Y HIERARCHY PAGE TEXT WORD\nCOMMENT Data\nMost of the point have been removed to shorten the example\nINCLUDE lexicon lex DATE WRITER ID STYLE MIXED START BOX SEGMENT PAGE SEGMENT TEXT CHUNK that nothing more happened SEGMENT WORD that PEN DOWN\nPEN UP DT PEN DOWN\nPEN UP\netc\nCOMMENT For more examples please ftp data samples\nFig Example of UNIPEN formatted data This example is simpli ed Real data are more richly annotated\nwill be forwarded to all subscribers Please refrain from sending messages which are not in the general interest of researchers in handwriting\nScrib L resides on the computers of the national node of the Nijmegen University Computing Centre in The Netherlands Scrib L subscribers represent as many as countries of the world Messages are in ASCII max columns wide concise and formal\nSummary\nASCII MESSAGES chars line to Scrib L NIC SURFNET NL COMMANDS to the boss of Scrib L LISTSERV NIC SURFNET NL\nSubscribe SUBSCRIBE SCRIB L Name Fax Get list of subscribers REVIEW SCRIB L COUNTRIES Get Archive of June SEND SCRIB L log\nAn FTP site has been set up at the Linguistic Data Consortium for data and software exchange Currently most of the directories can be read only by data donators When the database becomes public more directories will be open\nTo access the directories that are publicly available proceed as follows\nftp ftp cis upenn edu Name anonymous Password use your email address ftp cd pub UNIPEN pub documents ftp get call for data ps benchmark instructions ftp cd definition ftp get unipen def format definition ftp quit\nPeople having access to WWW through Mosaic will nd images of UNIPEN example les as produced by the Upview program developed at NICI at\nhttp www nici kun nl unipen\nOrganizing the database\nComputing statistics\nFor each data set donated a data sheet with relevant statistics was computed see Fig These statistics serve as a basis to determine how to split the data into di erent subsets\nDe ning tasks\nBecause the database is composed of many data sets of limited size it is important to group the data sets that address similar tasks This will also be important for de ning a set of standard benchmarks\nSEGMENTATION Type Totals Intersections\nboth WORD CHAR neither TEXT writers\nsegments both TEXT CHAR neither\nWORD writers segments both TEXT WORD neither CHAR writers segments TOTAL writers\nsegments characters components\nALPHABET s l u d sl su lu sd ld ud slu sld sud lud slud\nTEXT segments writers WORD segments writers CHAR segments writers\nSTYLE PRINTED CURSIVE MIXED unspec bad\nTEXT segments WORD segments WD LU segments CHAR segments TOTAL segments LEXICON From labels lexicon TEXT WORD WD LU WRITER Total number of characters Total number of writers Average number of characters writer Std dev of characters writer Minimum number of characters writer Maximum number of characters writer\nFig Example of data sheet The statistics of each data set donated to UNIPEN are computed and summarized in a data sheet This example shows one of the HP data sheets In the AL PHABET section the symbols s l u and d stand for symbols lowercase letters uppercase letters and digits In the STYLE and LEXICON sections WORD LU means words contain only lowercase or uppercase letters no symbols or digits\nExamples of tasks that were de ned include\nIsolated characters case separated\nIsolated characters mixed case\nIsolated characters in the context of words with a dictionary\nIsolated printed words\nIsolated cursive words\nText sentences\nThe number of characters available for each task was computed Tasks may overlap some characters may be used in more than one task There is a total of characters For tests and there are digits uppercase letters lowercase letters and symbols For tests and there are respectively and characters available\nDe ning training and test set\nThe next problem is to determine what size test set will give statistically signi cant results for each task The remainder of the data if any will serve as training data Since training data is valuable it is important not to be wasteful when de ning the test sets\nObviously de ning a statistically signi cant test set size is a chicken and egg problem before obtaining recognizer performance it is not possible to determine statistical signi cance Nevertheless since approximate values of the error rates of particular recognizers on given tasks are known it is possible to estimate the size of a test set using straightforward statistical arguments\nFor identically and independently distributed i i d data if E is the error rate of a recognizer it is possible to compute the number n of test examples such that with probability the actual error rate on an in nite size test set will not be higher than E\nn\nz\nE\nE\nwhere z is a tabulated coe cient which is a function of For typical values of the parameters z and E character error the number of test examples obtained is less than\nIn reality data are far from being i i d In particular the data usually come from a limited number of writers which necessarily introduces correlations The data donators who are experts in on line handwriting recognition advocated a minimum of di erent writers in every test set each writer providing at least\ncharacters Di erent writers must gure in the training data and the test data for writer independent tests\nThe test set size recommended by the donators is times larger than what the theory predicts At the time of writing this paper there were still open discussions regarding this matter\nMachine Printed Text\nThe UW I and UW II document image databases contain the following types of document image pages English technical journal articles pages UW I pages UW II Japanese technical journal articles pages UW II English memorandums pages UW II Each document image page is zoned and the text zones have line by line associated character ground truth generated by a double data entry and triple veri cation protocol The UW III document image database which will be issued in will have line drawings and word bounding boxes for each English page in the UW I and UW II document image databases\nUW I contains a large set of isolated degraded characters generated by Baird s degradation model In addition UW I contains software for determining OCR accuracy by comparing OCR generated text with the ground truth text and software for degrading a document image UW II contains a document image viewer called Illuminator provided by RAF Inc The databases are distributed on a CDROM media\nThe pages from both English and Japanese journals and reports come from the University of Washington libraries Some of the English report pages come from the University of Nevada Information Sciences Research Institute database The memorandums come from sta members of Seattle University The pages contain a diverse sample of document styles found in technical journals and other documents\nThe document image pages are scanned at ppi on either a Fujitsu document scanner or a Ricoh IS scanner They consist of binary images scanned directly from the original document pages binary images scanned from rst gener ation photocopies of the original document pages binary images scanned from the second or later generation photocopies of the original document pages gray scale images scanned from the original document pages and synthetic noise free binary images from LATEX generated documents\nIn addition to these images the document image database is annotated with information about the contents of the pages Qualitative information about the condition of each page in terms of the nature of noise present including the page rotation angle are presented in its page condition le Information about the docu ment page such as the journal from which it is taken its page number speci cation of the dominant font on the page speci cation as to whether gures etc are present on the page are in its page attribute le\nMost OCR algorithms proceed rst with a segmentation of the page into zones which are usually rectangular areas that are semantically homogeneous The UW document image data bases provide this kind of annotation At the coarsest level a page is decomposed into header footer and live matter areas Standard de nitions of what constitutes a header etc from the publishing and page descrip tion world are used The header is de ned to be ancillary text that appears above the main body of the page For the world of technical journals this usually includes information such as the name of the article the journal the authors and the page number A similar eld may be present below the main body of the page and is referred to as the footer The main body of the page is referred to as the live matter Information about the pixel location and size of each of these zones on the page are provided in its associated page bounding box annotation le\nAt the next ner level the page is decomposed into zones Zones can be of various types text gures tables half tones and mathematical equations among others Zone delineation information for each page is provided in its zone bounding box annotation le\nEach zone has attributes which include things such as the semantic meaning of each zone for example a text zone could be a section heading reference list item or page number the dominant font in the zone the font style etc This information is provided in the page s zone attribute annotation le\nFinally there is the ground truth data les For each non text zone the zone type gure displayed math table line drawing etc is given For each text zone the text within the zone is speci ed in terms of its ASCII text line for line\nPage Attributes\nFor each document page in the database there is a set of attributes that describe the top level attributes of the page The page attributes contain the page ID the page contents the page layout the font and publication information of a document page The group of attributes associated with publication information includes name volume number issue number and publication date of the journal It also has the corresponding page number of the document page from the publication The page attributes also include the type of language script font type and the character orientation and reading direction of the document page The font types are de ned to be of two varieties those with and without serifs Thus fonts such as Times are part of the Serif font type and fonts such as Helvetica are part of the Sans Serif font type Where more than one font type is present the dominant font type is de ned to be the one which occupies the largest fraction of the page in terms of physical area\nThe various page attributes and their possible values are as follows Document ID character string Document language English Japanese Document script Roman Katakana Kanji Hiragana Document type journal letter memo Publi\ncation Information Multiple pages from the same article yes no Text zone present yes no Special symbols present in text zone yes no Displayed Math zone present yes no Table zone present yes no Half tone zone present yes no Drawing zone present yes no Page header present yes no Page footer present yes no Max imum number of text columns non text Page Column layout regular irregular non text Character orientation up right rotated right rotated left non text Text reading direction left right right left top down bottom up non text Dominant font type serif sans serif non text Dominant character spacing pro portional xed non text Dominant font size pts non text Dominant font style plain bold italic underline script non text\nPage Condition\nThe page condition of a document page describes the visual condition or qualities of a given document page For example it contains information on the presence or absence of visible salt and pepper noise or visible vertical and horizontal streaks or extraneous symbols from other pages It also indicates if the document page is smeared or blurred because of poor focusing It contains the measured page rotation angle and its standard deviation It contains information about how many times the document page was successively copied Thus if the page is scanned from a rst generation copy the Nth copy attribute will have the value of\nQuite often when a bound journal is scanned or photocopied the portion of the page that is close to the spine of the journal is subject to perspective distortion In regions of the document page that are close to the spine the lines of text appear to curve skew towards either the top or bottom of the page The page skewed left or right attribute value pairs indicate whether such distortion is present on the document page\nWhen a bound journal page is scanned or photocopied there are sometimes sections of the page close to the spine that contain dark blotches which smear the text together This is because the page appears darker in grayscale close to the spine and a uniform binarization threshold would then result in dark blotches The page smeared left or right attribute values indicate whether such distortions are present on the document page The page rotation angle is de ned as the orientation of the lines of text relative to the horizontal These orientations and their standard deviations are estimated using a triangulation scheme on multiple sets of manually entered groups of three points on each document page\nThe page condition le has the following elds Document ID character string Degradation type original photocopy fax Nth copy noise free original Visible salt pepper noise yes no Visible vertical streaks yes no Visible horizontal streaks yes no Extraneous symbols on the top yes no Extraneous symbols on the bottom yes no Extraneous symbols on the left yes no Extraneous\nsymbols on the right yes no Page skewed on the left yes no Page skewed on the right yes no Page smeared on the left yes no Page smeared on the right yes no Page rotation angle in degrees Page rotation angle standard deviation\nZones on a Page\nA document page can be geometrically partitioned into several rectangular regions called zones In general any section of text that is clearly demarcated from adjacent areas of a page by white space is a text zone\nThe rules for de ning zones on a page are as follows A zone is geometrically de ned as a rectangular region on a document page A zone is con ned to a single column of text Font type style and size are mostly homogeneous across one zone A zone must not be nested completely within another zone A drawing table or half tone without its caption is a zone A line that demarcates two sections of text or lines that make up a box that encloses a section of text is a special kind of drawing and is called a ruling zone Another special case of a drawing is called the logo zone and usually consists of the business logo of the company that publishes the journal Other kinds of drawings that make up distinct zones are geographic maps map zones and advertisements advertisement zone The caption of a drawing table or half tone is a zone A list is de ned as any sequence of text zones each associated with an alphanumeric counter or index tag The index tag could be a symbol or any other string for e g references are often indexed by a string made up of the initials of the authors and the year of publication Every item in a list constitutes a zone Every paragraph of text that remains unbroken with or without in line mathematical equations constitutes a zone A drop cap is in a zone by itself Every displayed mathematical equation is a zone Section headings which are distinguished in many cases from the text body by being either bold faced or underlined constitute a zone The section heading could be part of a line of text Headings that indicate that the following text is part of the abstract of a paper or the keywords used to index the paper or the start of a list of references constitute legitimate zones They are referred to as abstract keyword and reference heading zones respectively The page number of a page constitutes a separate zone even if there is no white space separating it from nearby text\nSections of text that represent computer algorithms in pseudo code are also zones called pseudo code zones Sections of the text that form part of the title area of a journal article have special semantic meanings and are each assigned to a separate zone These include the title title zones the names of the authors author zone where more than one appears on a line they are all part of the same zone the organizational a liation of the authors a liation zone any diplomas or edu cational quali cations of the authors diploma zone and memberships in academic societies membership zones Information pertaining to the date on which an article was submitted or accepted for publication has important semantic information and\nconstitutes an article submission information zone Some articles contain a blurb of text that appears on the same page in order to emphasize the point the authors are trying to make These text regions are called highlight zones Some articles contain a brief summary of the contents of the page in a separate text region Such a zone is referred to as a synopsis zone The area that contains the key words used to index a paper has special semantic meaning and constitutes a keyword zone\nSome of the document pages contain handwritten annotations These constitute zones which are called handwriting zones No ground truth is entered for these zones Sometimes there are extra text symbols from the opposite page that appear on a document image this happens when photocopying from a bound journal These symbols are not zoned\nBounding box information\nBounding boxes are given relative to the page as a whole and relative to each zone on the page Page bounding box information speci es the size and the location of the three types of special zones i e page header zone page footer zone and live matter zone The location of the zone is speci ed in terms of the row and column pixel coordinates of the top left hand corner of each type of zone box The size is speci ed by giving the row and column pixel coordinates of the bottom right hand corner of the zone box These zone boxes have been delineated by hand using an interactive zone boxing tool These zone boxes are by no means the smallest bounding rectangle but are guaranteed to contain the page area they are meant to Where unavoidable as a result of page rotation or too small a separation between zone boxes there may also be an overlap area between adjacent zone boxes\nFor each of the zones in the page the size and location of the zone bounding boxes is similarly speci ed\nZone threading\nThe zones of each document page are grouped into several logical units Within each logical unit the reading order is sequential Such a logical unit is called a semantic thread Thus associated with each zone in a thread is a pointer to the next zone within the thread Figures and their captions make up a thread So do tables and their captions Zones in the header or the footer areas make up threads individually All other sets of text zones constitute the main thread of the document page In general the last zone within a thread has a nil pointer In some cases zone threading may cross pages When consecutive document pages are presented within the database the last zone of a given page that is in the live matter area may thread with the appropriate zone on the following page\nZone attributes\nZone attributes de ne the properties of a zone on a document page The zone attributes contain information on the Page ID the Zone ID the zone contents the zone label the text alignment the font the column number the language and the script the character orientation and reading direction of the zone It also has zone threading information which was explained in the previous section\nThe text alignment attribute is de ned relative to the zone bounding box for the zone If the lines of text are aligned with the left edge of the bounding box it is referred to as left aligned There are similar de nitions for right and center aligned zones If the text is aligned with both the right and left edge of the zone bounding box it is referred to as justi ed Text alignment within the zone can have the values left center right justi ed justi ed hanging and left hanging\nZone attributes include Dominant font type serif sans serif non text Dom inant character spacing proportional xed non text Dominant font size pts non text Dominant font style plain bold italic underline script non text Character orientation up right rotated right rotated left non text Text reading direction left right right left top down bottom up non text Zone s column number header area footer area non text Next Zone ID within the same thread nil\nOther zone attributes include Document ID character string Zone ID character string Language English French German Japanese Script Roman Katakana Kanji Hiragana Zone content text text with special symbols text with non japanese symbols text with special symbols non japanese text with rubi text with non japanese and rubi text with special symbols non japanese and rubi math table halftone drawing ruling bounding box logo map form advertisement an nouncement handwriting seal halftone with drawing gurative text english gu rative text chinese gurative text korean signature initials new de nition block\ngurative text gurative text japanese Text zone label text body list item drop cap caption section heading synopsis highlight pseudo code reference heading de nition reference list reference list item footnote biography list not clear Page headers and footers can have these zone labels page header page footer page num ber\nTitle pages of documents can have zone labels title author a liation diploma membership abstract heading abstract body abstract heading and body correspon dence executive abstract heading executive abstract body keyword heading keyword body reader service keyword heading and body publication infomation article sub mission information not clear\nMemos and Letter documents can also have the following zone attributes date to from subject cc memo heading complement street address city address PO Box phone number e mail address fax number telex number laboratory depart ment group division institution subject matter sender s reference sender s name\nrecipient s name secretary s initials sender s title sender s initials opening salu tation closing salutation home o ce information founding date enclosure Japanese documents can have these other label values subject title illustrator author a liation membership title author a liation\nGround Truth Data\nThe database provides the ground truth for all text zones on a document page For non text zones such as the displayed mathematical formulas line art gures table zones and etc an indication of such will be given\nIn UW II a zone based ground truth method is used The zone based ground truth consists of the symbol strings which are contained in the text zone This includes the standard ASCII characters as well as special symbol escape sequences for non ASCII characters The lines in the ground truth data are broken at the same position of the string where the physical line is broken on the page Tabbing or indentations are ignored Single blank characters spaces are used for one or more spaces within a text line Ground truth for Japanese text is provided in unicode The methodology used for accurate ground truthing involves double data entry and triple veri cation The character substitution error rate is estimated at about characters per million for UW I and characters per million for UW II\nDiscussion and Conclusions\nSeveral signi cant data sets for OCR and document image understanding research were surveyed The CEDAR CENPARMI and NIST data sets were designed to address the needs of researchers in o ine handwriting recognition\nThe UNIPEN data set contains a large number of samples of online handwriting The success of the UNIPEN project demonstrates that it is possible to exchange data on a large scale The keys to the success of UNIPEN were to develop a common data format and to keep all decisions democratic so that they would re ect the desires of the majority of the participants Exchanging data also raises some di culties One of them is that it can take a long time the project is already two years old Another one is that transforming many di erent data sets into a standard format can be time consuming\nThe University of Washington data sets of machine printed text images have helped many researchers in document recognition The large number of truthed images on the UW CDROMs have seen widespread use and have been one of the factors in improving the performance of various commercial OCR packages This project recently provided a signi cant sample of scanned and truthed Japanese text\nSome interesting practical problems in the design of a data set are illustrated by these e orts For example in the UNIPEN project the splitting of the data set into training and test sets while retaining a statistically signi cant test set size was\nconsidered Another open problem in data set design is in non English language text The University of Washington has begun to address this issue but collections of truthed images from other languages besides English and Japanese e g French Russian Chinese etc are needed so that problems in non English OCR can be investigated by many researchers"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 48,
                                "start": 45
                            }
                        ],
                        "text": "In contrast with binary formats, such as Jot [2], the UNIPEN format is not optimized for data storage or real time data transmission and it is not designed to handle ink manipulation applications involving colors, image rotations, rescaling, etc."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A speci cation for an ink storage and interchange format,  Technical Report draft version"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 164,
                                "start": 161
                            }
                        ],
                        "text": "Introduction The availability of a data set that contains an appropriate number and selection of samples is a critical part of any experimental research project [8]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Haralick, English document database  design and implementation methodology"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. of the Second Annual Sympo-  sium on Document Analysis and Information Retrieval,"
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 100,
                                "start": 97
                            }
                        ],
                        "text": "UW-I contains a large set of isolated degraded characters generated by Baird's degradation model [1]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Document image defect models, in Structured Document Image  Analysis, eds"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 69,
                                "start": 65
                            }
                        ],
                        "text": "Machine Printed Text The UW-I and UW-II document image databases [10] contain the following types of document image pages: English technical journal articles, 1147 pages UW-I, 623 pages UW-II; Japanese technical journal articles, 477 pages UW-II; English memorandums, 62 pages UW-II."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The implementation method-  ology for a CD-ROM English document database, International Conference on  Document Analysis and Recognition"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "478-483; reprinted in Document Image Analysis by"
            },
            "venue": {
                "fragments": [],
                "text": "478-483; reprinted in Document Image Analysis by"
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "UNIPEN project of on-line data exchange and benchmarks"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. of the 12th IAPR International Conference on Pattern Recognition"
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 112,
                                "start": 109
                            }
                        ],
                        "text": "A second iteration of the test was organized in autumn 1993 to check the changes and additions to the format [4]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "UNIPEN  project of on-line data exchange and benchmarks"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. of the 12th IAPR  International Conference on Pattern Recognition,"
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Document image defect models, in Structured Document Image Analysis"
            },
            "venue": {
                "fragments": [],
                "text": "Document image defect models, in Structured Document Image Analysis"
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 15853,
                                "start": 15850
                            }
                        ],
                        "text": "Seattle WA yun seattleu edu\nSeveral signi cant sets of labeled samples of image data are surveyed that can be used in the development of algorithms for o ine and online handwriting recognition as well as for machine printed text recognition The method used to gather each data set the numbers of samples they contain and the associated truth data are discussed In the domain of o ine handwriting the CEDAR NIST and CENPARMI data sets are pre sented These contain primarily isolated digits and alphabetic characters The UNIPEN data set of online handwriting was collected from a number of independent sources and it contains individual characters as well as handwritten phrases The University of Wash ington document image databases are also discussed They contain a large number of English and Japanese document images that were selected from a range of publications\nKeywords Data sets databases text images online handwriting o ine handwriting machine printed text CEDAR NIST CENPARMI UNIPEN University of Washington\nIntroduction\nThe availability of a data set that contains an appropriate number and selection of samples is a critical part of any experimental research project This is especially true in an image based application such as optical character recognition OCR\nwhere it is sometimes di cult for individual researchers to gather the number and type of data they need because of the costs involved Ideally a data set would allow a researcher to project the performance achieved experimentally to the appli cation domain represented by the data set This implies that the data set used for algorithm development should re ect the application domain as closely as possible\nA signi cant advance in the experimental integrity of OCR research has been made possible in recent years with the availability of several image data sets These data sets allow researchers to train and test algorithms on signi cant numbers of data items and to compare performance on speci c images This has improved productivity since researchers can conduct experiments without rst gathering data\nThere are three areas of OCR research o ine handwriting online handwriting and machine printed text that require specialized data sets O ine handwriting is produced by an individual typically by writing with a pen or pencil on paper and is scanned into a digital format Online handwriting is written directly on a digitizing tablet with a stylus The output is a sequence of x y coordinates that express pen position as well as other information such as pressure Machine printed text occurs commonly in daily use and is produced by o set processes laser inkjet or dot matrix printing Each area has unique characteristics that a ect the design of a data set These characteristics determine how well experimental results on that data set can be generalized to another application\nO ine handwritten text data sets typically contain isolated alphanumeric char acters or words These data sets are often produced by choosing subjects to write on sample forms that are subsequently digitized An important consideration in the design of data sets in this area is how well the subjects that produce the data and the conditions under which the data are gathered represent the eventual ap plication Ideally the subjects should be chosen from the same population and the data gathered under the same conditions e g data gathered in the eld same data form used etc that will be used in the nal application Otherwise signi cant di erences in performance can occur between the data set and the data used in practice\nDatabases of online handwriting also contain isolated characters and words as well as text phrases Research in online handwriting recognition has been conducted for many years at a large number of research labs Each project typically developed their own databases for internal use The UNIPEN project has taken advantage of this existing body of data by asking individual research groups to contribute their databases to a common set This data set will rst be used for a comparative benchmark It will then be shared with the rest of the research community A signi cant issue in UNIPEN was the large number of di erent formats used for online handwriting This was solved by the development of a common data format which is described in this chapter The background history and future of the UNIPEN e ort are also discussed\nMachine printed text data sets often include images of complete pages These pages can be chosen from a large number of di erent classes of machine printed document e g scienti c papers memorandums newspapers etc and can vary widely in format fonts point size column layout etc A signi cant consideration is the document classes and variations in format represented in the data set Also the ground truth information supplied with such a data set should be comprehensive so that it can be used to improve the performance of OCR algorithms This is signi cant since modern OCR systems are a ected by many aspects of the data format which are often inter related This chapter describes the CDROM data sets developed by the University of Washington which include several document classes and extensive truth data\nThe rest of this paper describes several data sets of o ine and online handwrit ing as well as machine printed text We discuss the contents of these data sets and describe how they address various research considerations\nO ine Handwritten Text\nThere are at least two classes of databases of o ine handwritten text that are of interest to most researchers Datasets that contain isolated handprinted characters and digits have been used in the development of many pattern recognition algo rithms The recognition problem represented by these data is well de ned e g or classes and the recognition task is relatively easy for ordinary people A reliable solution to this problem could have signi cant economic consequences since many handwritten forms could be read automatically\nData sets can also contain isolated handwritten words and phrases The recog nition problem represented by these data is more challenging since the number of classes is larger e g there are more than legal ZIP Codes in the U S and there may be few constraints on how users prepare the samples However a robust solution to this problem would be even more signi cant than for isolated character recognition since it would provide a general purpose computer input medium\nImportant considerations when evaluating the usefulness of a data set for ex perimental purposes include the number of samples it contains the sampling rate at which it was captured and the pixel depth at which the data is furnished Com monly used sampling rates include or pixels per inch ppi and pixel depths are usually one or eight bits Such image characteristics are also important system design parameters since they in uence the ultimate cost of an implementation\nIsolated Digits and Alphabetic Characters\nIsolated digit and character recognition is one of the most extensively studied ap plication domains in pattern recognition Some of the earliest databases of digital images beginning at least in were composed of single characters see for\na review In recent years several signi cant collections of such data have been issued\nThe CEDAR data set contains nearly examples of isolated handwritten characters and digits that were extracted from images of postal addresses En velopes with handwritten addresses on them were sampled from the mail as it was being processed in a post o ce This assured that the people that prepared the original data were not aware that their addresses would be included in the data set The address images were scanned at ppi in bit gray scale and later reduced to one bit images Individual characters and digits were segmented from the address images by a semi automatic process that extracted single connected components These were displayed to a human operator who entered their truth values\nAn additional group of about digits were also extracted from ZIP Codes in the CEDAR data set by a fully automatic segmentation algorithm These digits were manually screened for quality and placed into a good set if they contained no segmentation artifacts that could be considered errors such as one digit split into two All the digits output by the segmentation algorithm are also provided in the data set This provides some challenging examples for testing the performance of an algorithm since artifacts caused by segmentation are preserved in the individual images\nThe CENPARMI data set contains isolated digits that were extracted from images of about postal ZIP Codes The ZIP Codes were selected from dead letter mail in a working post o ce and thus the preparers of the data also were separated from the data collection task The ZIP Codes were scanned at ppi with a one bit digitizer The isolated digits were extracted from the ZIP Codes by a manual segmentation process that displayed individual images to operators who entered their identities\nThe NIST data set SD contains one of the largest selections of isolated digits and characters that are publically available Altogether it contains over character images that were extracted from data collection forms lled out by individuals Employees of the U S Bureau of the Census were instructed to ll the boxes on a form with a particular sequence of digits or characters and were asked to make sure that the individual digits or characters did not touch one another or the surrounding box The forms were subsequently scanned at ppi in binary mode and automatically segmented The string of digits that should have been written in each box was used to assign a truth value to each individual image The truth values were subsequently veri ed by a human operator\nAn interesting issue in data set design is presented by the NIST images The initial collection process described above was done in preparation for a competition that evaluated the performance of more than di erent algorithms in isolated digit and character recognition The images on SD were provided as a training set and were used by most of the competing organizations in developing their methods A separate data set called TD was collected to provide test data The same\ncollection process was used However the subjects were high school students The quality of the data varied more widely in TD than it did in SD and was on the whole more sloppy This caused a signi cant drop in performance on the test data because most systems had been trained on the neater images This experience shows that a given technique may perform very well on a speci c data set However this does not necessarily mean that the recognition problem represented by that data has been solved It can mean that the recognition problem has been solved for that data set only The generalization of any results to a larger population should only be made after careful consideration and comparison of the training and test data to the real life application\nWord and Phrase Recognition\nWord and phrase recognition is a less frequently studied application of pattern recognition than digit or character recognition However words or phrases o er contextual constraints such as dictionaries that make it possible to model interac tions between image processing operations such as segmentation and the recognition of isolated symbols given that only certain sequences of symbols occur in the dic tionary\nZIP Codes city names and state names are examples of handwritten word images that are available in the CEDAR data set Approximately ZIP Codes city names and state name images are included These data were scanned by the process described above However the ppi bit gray scale versions of the whole word images are provided and the speci c address in which each image occurred is identi ed Thus experimentation can be performed with isolated word recognition on gray scale data and a comprehensive system could be developed that used partial results from recognition of the city or state name to in uence the recognition of speci c digits in the corresponding ZIP Code\nA signi cant amount of running English text is also available in the NIST SD and TD data sets Each collection form contained a Constitution box in which subjects wrote the word preamble to the Constitution of the United States This data was scanned at ppi in bit format as part of the normal data capture process These images also make it possible to develop algorithms that integrate early processing with contextual analysis The domain is constrained enough that a range of contextual constraints can be investigated and at the same time the physical format is su ciently unconstrained the subjects could have written the preamble anywhere in a given box that it reasonably represents the way people would like to use handwriting to communicate with a computer\nThere are three other NIST data sets SD SD that contain examples of phrases that were written by respondents to the U S Census to describe their jobs Three boxes were lled in with the title of a person s job the work they do and the work done by the company they are employed by SD SD di er from SD and\nTD in that the people that prepared the data were from the general population and had no idea that their writing would be scanned Altogether handwritten phrases were scanned at ppi in binary mode of the phrases were scanned from micro lm and were scanned from the original paper versions These data are also provided with a dictionary of legal entries for each box that was derived from the previous census Thus there is no guarantee that the letter for letter transcription of each image appears in the dictionary The recognition task is to identify the dictionary entry that is the closest match to the phrase written in the box\nOnline Handwritten Text\nIn this section we present the design of a database for On Line Handwriting Recog nition OLHR The database is composed of isolated characters words and sen tences written in a variety of styles handprinted cursive or mixed The alphabet is restricted to the ASCII keyboard set The data were donated by di erent institutions and therefore includes a variety of writers and recording conditions The database size approaches million characters We provide some details about the data exchange platform which could inspire other similar e orts The database will be distributed to the public for a small fee by the Linguistic Data Consortium LDC in\nHistory of UNIPEN\nOn line handwriting recognition OLHR addresses the problem of recognizing hand writing from data collected with a sensitive pad which provides discretized pen tra jectory information OLHR has long been the poor parent of pattern recognition in terms of publicly available large corpora of data To remedy this problem the UNIPEN project was started in September at the initiative of the Technical Committee of the International Association for Pattern Recognition IAPR Two IAPR delegates Isabelle Guyon and Lambert Schomaker were appointed to explore the possibility of creating large OLHR databases\nIn the eld of OLHR there exist many privately owned databases These databases constitute a potential resource which is much richer than any single database because of the diversity of text entered recording conditions and writers Therefore data exchange is a natural way to constitute a sizable database which is representative of the tasks of interest to research and development groups\nA small working group of experts from Apple AT T HP GO IBM and NICI laid the foundations of UNIPEN in May and proposed that a common data format would be designed to facilitate data exchange In the summer of the UNIPEN format was designed incorporating features of the internal formats of several institutions including IBM Apple Tap Microsoft Slate Jot HP\nAT T NICI GO and CIC The format was then tested independently by members of the working group soon followed by many other volunteers A second iteration of the test was organized in autumn to check the changes and additions to the format In parallel a set of tools to parse the format and browse the data were developed at NICI with the sponsorship of HP and at AT T\nIn January NIST and LDC committed to help UNIPEN NIST has been supervising the data gathering and the organization of a benchmark test LDC will publish a CD ROM and distribute the data There is already an FTP site at LDC where data and programs can be exchanged\nIn June the instructions for participation in the rst UNIPEN benchmark limited to the Latin alphabet were released Potential participants were requested to donate isolated characters words or sentences containing at least charac ters Forty institutions responded to the call for data Further negotiations between owners of large databases succeeded in gathering larger data sets There are nearly ve million individual character samples in the database\nIn February the data donators met for a one day workshop to determine how the data will be split into training and test sets A benchmark test using these data will take place in During the test the data will remain the property of the data donators After the test it will become publicly available and will be distributed by LDC for a nominal fee\nThe activities of UNIPEN will expand in the future according to the needs and desires of the participants\nCollecting donated samples\nA common data format\nThe UNIPEN format is an ASCII format designed speci cally for data collected with any touch sensitive resistive or electro magnetic device providing discretized pen trajectory information Users can easily convert their own format to and from the UNIPEN format or collect data directly in that format\nThe minimum number of signal channels is two X and Y but more signals are allowed e g pen angle or pressure information In contrast with binary formats such as Jot the UNIPEN format is not optimized for data storage or real time data transmission and it is not designed to handle ink manipulation applications involving colors image rotations rescaling etc However in the UNIPEN format there are provisions for data annotation about recording conditions writers seg mentation data layout data quality labeling and recognition results\nE orts were made to make the format human intelligible without documenta tion keywords are explicit English words easily machine readable an awk parser was developed in conjunction with the development of the format itself compact few keywords complete enough keywords and expandable\nThe format is a succession of instructions consisting of a keyword followed by arguments Keywords are reserved words starting with a dot in the rst column of a line Arguments are strings or numbers separated by spaces tabs or new lines The arguments relative to a given keyword start after that keyword and end with the appearance of the next keyword or the end of le see Fig\nAlmost everything is optional so that simple data sets can be described in a simple way All variables are global declared variables retain their values until the next similar declaration Databases written in the UNIPEN format may be con catenated in a single le or they may be organized in di erent les and directories\nThe format can be thought of as a sequence of pen coordinates annotated with various information including segmentation and labeling The pen trajectory is encoded as a sequence of components A pen down component is a trace recorded when the pen is in contact with the surface of the digitizer A pen up component is a trace recorded when the pen is near the digitizer without touching it Compo nents are not necessarily delimited by pen lifts and may or may not coincide with strokes PEN DOWN and PEN UP contain pen coordinates e g XY or XY T as declared in COORD The instruction DT speci es the elapsed time between two components The database is divided into one or several data sets starting with START SET Within a set components are implicitly numbered starting from zero\nSegmentation and labeling are provided by the SEGMENT instruction Com ponent numbers are used by SEGMENT to delineate sentences words and char acters A segmentation hierarchy e g SENTENCE WORD CHARACTER is declared with HIERARCHY Because components are referred to by a unique combination of set name and order number in that set it is possible to separate the SEGMENT from the data itself\nThe format also provides a uni ed way of encoding recognizer outputs to be used for benchmark purposes To obtain more information about the format it is possible to access its full de nition electronically see next section\nInternet connections\nWithout the internet the Unipen project would not have been possible Electronic mail has been the primary means of communication between organizers and partic ipants The data and the tools were exchanged by FTP\nIn March UNIPEN advertised its existence on several electronic mailing lists resulting in nearly subscriptions to the UNIPEN newsletter People in terested in UNIPEN can send a request to be added to the Scrib L mailing list Scrib L is a mailing list for researchers and developers in the eld of handwriting Electronic mail to\nSCRIB L NIC SURFNET NL\nVERSION DATA SOURCE ATT DATA ID Example\nCOMMENT Documentation\nDATA CONTACT Isabelle Guyon isabelle research att com DATA INFO Latin alphabet isolated characters Data cleaned manually SETUP Volunteer staff members People sitting at a desk PAD WACOM HD A LCD Digitizer\nCOMMENT Declarations\nX DIM Y DIM H LINE X POINTS PER INCH Y POINTS PER INCH POINTS PER SECOND COORD X Y HIERARCHY PAGE TEXT WORD\nCOMMENT Data\nMost of the point have been removed to shorten the example\nINCLUDE lexicon lex DATE WRITER ID STYLE MIXED START BOX SEGMENT PAGE SEGMENT TEXT CHUNK that nothing more happened SEGMENT WORD that PEN DOWN\nPEN UP DT PEN DOWN\nPEN UP\netc\nCOMMENT For more examples please ftp data samples\nFig Example of UNIPEN formatted data This example is simpli ed Real data are more richly annotated\nwill be forwarded to all subscribers Please refrain from sending messages which are not in the general interest of researchers in handwriting\nScrib L resides on the computers of the national node of the Nijmegen University Computing Centre in The Netherlands Scrib L subscribers represent as many as countries of the world Messages are in ASCII max columns wide concise and formal\nSummary\nASCII MESSAGES chars line to Scrib L NIC SURFNET NL COMMANDS to the boss of Scrib L LISTSERV NIC SURFNET NL\nSubscribe SUBSCRIBE SCRIB L Name Fax Get list of subscribers REVIEW SCRIB L COUNTRIES Get Archive of June SEND SCRIB L log\nAn FTP site has been set up at the Linguistic Data Consortium for data and software exchange Currently most of the directories can be read only by data donators When the database becomes public more directories will be open\nTo access the directories that are publicly available proceed as follows\nftp ftp cis upenn edu Name anonymous Password use your email address ftp cd pub UNIPEN pub documents ftp get call for data ps benchmark instructions ftp cd definition ftp get unipen def format definition ftp quit\nPeople having access to WWW through Mosaic will nd images of UNIPEN example les as produced by the Upview program developed at NICI at\nhttp www nici kun nl unipen\nOrganizing the database\nComputing statistics\nFor each data set donated a data sheet with relevant statistics was computed see Fig These statistics serve as a basis to determine how to split the data into di erent subsets\nDe ning tasks\nBecause the database is composed of many data sets of limited size it is important to group the data sets that address similar tasks This will also be important for de ning a set of standard benchmarks\nSEGMENTATION Type Totals Intersections\nboth WORD CHAR neither TEXT writers\nsegments both TEXT CHAR neither\nWORD writers segments both TEXT WORD neither CHAR writers segments TOTAL writers\nsegments characters components\nALPHABET s l u d sl su lu sd ld ud slu sld sud lud slud\nTEXT segments writers WORD segments writers CHAR segments writers\nSTYLE PRINTED CURSIVE MIXED unspec bad\nTEXT segments WORD segments WD LU segments CHAR segments TOTAL segments LEXICON From labels lexicon TEXT WORD WD LU WRITER Total number of characters Total number of writers Average number of characters writer Std dev of characters writer Minimum number of characters writer Maximum number of characters writer\nFig Example of data sheet The statistics of each data set donated to UNIPEN are computed and summarized in a data sheet This example shows one of the HP data sheets In the AL PHABET section the symbols s l u and d stand for symbols lowercase letters uppercase letters and digits In the STYLE and LEXICON sections WORD LU means words contain only lowercase or uppercase letters no symbols or digits\nExamples of tasks that were de ned include\nIsolated characters case separated\nIsolated characters mixed case\nIsolated characters in the context of words with a dictionary\nIsolated printed words\nIsolated cursive words\nText sentences\nThe number of characters available for each task was computed Tasks may overlap some characters may be used in more than one task There is a total of characters For tests and there are digits uppercase letters lowercase letters and symbols For tests and there are respectively and characters available\nDe ning training and test set\nThe next problem is to determine what size test set will give statistically signi cant results for each task The remainder of the data if any will serve as training data Since training data is valuable it is important not to be wasteful when de ning the test sets\nObviously de ning a statistically signi cant test set size is a chicken and egg problem before obtaining recognizer performance it is not possible to determine statistical signi cance Nevertheless since approximate values of the error rates of particular recognizers on given tasks are known it is possible to estimate the size of a test set using straightforward statistical arguments\nFor identically and independently distributed i i d data if E is the error rate of a recognizer it is possible to compute the number n of test examples such that with probability the actual error rate on an in nite size test set will not be higher than E\nn\nz\nE\nE\nwhere z is a tabulated coe cient which is a function of For typical values of the parameters z and E character error the number of test examples obtained is less than\nIn reality data are far from being i i d In particular the data usually come from a limited number of writers which necessarily introduces correlations The data donators who are experts in on line handwriting recognition advocated a minimum of di erent writers in every test set each writer providing at least\ncharacters Di erent writers must gure in the training data and the test data for writer independent tests\nThe test set size recommended by the donators is times larger than what the theory predicts At the time of writing this paper there were still open discussions regarding this matter\nMachine Printed Text\nThe UW I and UW II document image databases contain the following types of document image pages English technical journal articles pages UW I pages UW II Japanese technical journal articles pages UW II English memorandums pages UW II Each document image page is zoned and the text zones have line by line associated character ground truth generated by a double data entry and triple veri cation protocol The UW III document image database which will be issued in will have line drawings and word bounding boxes for each English page in the UW I and UW II document image databases\nUW I contains a large set of isolated degraded characters generated by Baird s degradation model In addition UW I contains software for determining OCR accuracy by comparing OCR generated text with the ground truth text and software for degrading a document image UW II contains a document image viewer called Illuminator provided by RAF Inc The databases are distributed on a CDROM media\nThe pages from both English and Japanese journals and reports come from the University of Washington libraries Some of the English report pages come from the University of Nevada Information Sciences Research Institute database The memorandums come from sta members of Seattle University The pages contain a diverse sample of document styles found in technical journals and other documents\nThe document image pages are scanned at ppi on either a Fujitsu document scanner or a Ricoh IS scanner They consist of binary images scanned directly from the original document pages binary images scanned from rst gener ation photocopies of the original document pages binary images scanned from the second or later generation photocopies of the original document pages gray scale images scanned from the original document pages and synthetic noise free binary images from LATEX generated documents\nIn addition to these images the document image database is annotated with information about the contents of the pages Qualitative information about the condition of each page in terms of the nature of noise present including the page rotation angle are presented in its page condition le Information about the docu ment page such as the journal from which it is taken its page number speci cation of the dominant font on the page speci cation as to whether gures etc are present on the page are in its page attribute le\nMost OCR algorithms proceed rst with a segmentation of the page into zones which are usually rectangular areas that are semantically homogeneous The UW document image data bases provide this kind of annotation At the coarsest level a page is decomposed into header footer and live matter areas Standard de nitions of what constitutes a header etc from the publishing and page descrip tion world are used The header is de ned to be ancillary text that appears above the main body of the page For the world of technical journals this usually includes information such as the name of the article the journal the authors and the page number A similar eld may be present below the main body of the page and is referred to as the footer The main body of the page is referred to as the live matter Information about the pixel location and size of each of these zones on the page are provided in its associated page bounding box annotation le\nAt the next ner level the page is decomposed into zones Zones can be of various types text gures tables half tones and mathematical equations among others Zone delineation information for each page is provided in its zone bounding box annotation le\nEach zone has attributes which include things such as the semantic meaning of each zone for example a text zone could be a section heading reference list item or page number the dominant font in the zone the font style etc This information is provided in the page s zone attribute annotation le\nFinally there is the ground truth data les For each non text zone the zone type gure displayed math table line drawing etc is given For each text zone the text within the zone is speci ed in terms of its ASCII text line for line\nPage Attributes\nFor each document page in the database there is a set of attributes that describe the top level attributes of the page The page attributes contain the page ID the page contents the page layout the font and publication information of a document page The group of attributes associated with publication information includes name volume number issue number and publication date of the journal It also has the corresponding page number of the document page from the publication The page attributes also include the type of language script font type and the character orientation and reading direction of the document page The font types are de ned to be of two varieties those with and without serifs Thus fonts such as Times are part of the Serif font type and fonts such as Helvetica are part of the Sans Serif font type Where more than one font type is present the dominant font type is de ned to be the one which occupies the largest fraction of the page in terms of physical area\nThe various page attributes and their possible values are as follows Document ID character string Document language English Japanese Document script Roman Katakana Kanji Hiragana Document type journal letter memo Publi\ncation Information Multiple pages from the same article yes no Text zone present yes no Special symbols present in text zone yes no Displayed Math zone present yes no Table zone present yes no Half tone zone present yes no Drawing zone present yes no Page header present yes no Page footer present yes no Max imum number of text columns non text Page Column layout regular irregular non text Character orientation up right rotated right rotated left non text Text reading direction left right right left top down bottom up non text Dominant font type serif sans serif non text Dominant character spacing pro portional xed non text Dominant font size pts non text Dominant font style plain bold italic underline script non text\nPage Condition\nThe page condition of a document page describes the visual condition or qualities of a given document page For example it contains information on the presence or absence of visible salt and pepper noise or visible vertical and horizontal streaks or extraneous symbols from other pages It also indicates if the document page is smeared or blurred because of poor focusing It contains the measured page rotation angle and its standard deviation It contains information about how many times the document page was successively copied Thus if the page is scanned from a rst generation copy the Nth copy attribute will have the value of\nQuite often when a bound journal is scanned or photocopied the portion of the page that is close to the spine of the journal is subject to perspective distortion In regions of the document page that are close to the spine the lines of text appear to curve skew towards either the top or bottom of the page The page skewed left or right attribute value pairs indicate whether such distortion is present on the document page\nWhen a bound journal page is scanned or photocopied there are sometimes sections of the page close to the spine that contain dark blotches which smear the text together This is because the page appears darker in grayscale close to the spine and a uniform binarization threshold would then result in dark blotches The page smeared left or right attribute values indicate whether such distortions are present on the document page The page rotation angle is de ned as the orientation of the lines of text relative to the horizontal These orientations and their standard deviations are estimated using a triangulation scheme on multiple sets of manually entered groups of three points on each document page\nThe page condition le has the following elds Document ID character string Degradation type original photocopy fax Nth copy noise free original Visible salt pepper noise yes no Visible vertical streaks yes no Visible horizontal streaks yes no Extraneous symbols on the top yes no Extraneous symbols on the bottom yes no Extraneous symbols on the left yes no Extraneous\nsymbols on the right yes no Page skewed on the left yes no Page skewed on the right yes no Page smeared on the left yes no Page smeared on the right yes no Page rotation angle in degrees Page rotation angle standard deviation\nZones on a Page\nA document page can be geometrically partitioned into several rectangular regions called zones In general any section of text that is clearly demarcated from adjacent areas of a page by white space is a text zone\nThe rules for de ning zones on a page are as follows A zone is geometrically de ned as a rectangular region on a document page A zone is con ned to a single column of text Font type style and size are mostly homogeneous across one zone A zone must not be nested completely within another zone A drawing table or half tone without its caption is a zone A line that demarcates two sections of text or lines that make up a box that encloses a section of text is a special kind of drawing and is called a ruling zone Another special case of a drawing is called the logo zone and usually consists of the business logo of the company that publishes the journal Other kinds of drawings that make up distinct zones are geographic maps map zones and advertisements advertisement zone The caption of a drawing table or half tone is a zone A list is de ned as any sequence of text zones each associated with an alphanumeric counter or index tag The index tag could be a symbol or any other string for e g references are often indexed by a string made up of the initials of the authors and the year of publication Every item in a list constitutes a zone Every paragraph of text that remains unbroken with or without in line mathematical equations constitutes a zone A drop cap is in a zone by itself Every displayed mathematical equation is a zone Section headings which are distinguished in many cases from the text body by being either bold faced or underlined constitute a zone The section heading could be part of a line of text Headings that indicate that the following text is part of the abstract of a paper or the keywords used to index the paper or the start of a list of references constitute legitimate zones They are referred to as abstract keyword and reference heading zones respectively The page number of a page constitutes a separate zone even if there is no white space separating it from nearby text\nSections of text that represent computer algorithms in pseudo code are also zones called pseudo code zones Sections of the text that form part of the title area of a journal article have special semantic meanings and are each assigned to a separate zone These include the title title zones the names of the authors author zone where more than one appears on a line they are all part of the same zone the organizational a liation of the authors a liation zone any diplomas or edu cational quali cations of the authors diploma zone and memberships in academic societies membership zones Information pertaining to the date on which an article was submitted or accepted for publication has important semantic information and\nconstitutes an article submission information zone Some articles contain a blurb of text that appears on the same page in order to emphasize the point the authors are trying to make These text regions are called highlight zones Some articles contain a brief summary of the contents of the page in a separate text region Such a zone is referred to as a synopsis zone The area that contains the key words used to index a paper has special semantic meaning and constitutes a keyword zone\nSome of the document pages contain handwritten annotations These constitute zones which are called handwriting zones No ground truth is entered for these zones Sometimes there are extra text symbols from the opposite page that appear on a document image this happens when photocopying from a bound journal These symbols are not zoned\nBounding box information\nBounding boxes are given relative to the page as a whole and relative to each zone on the page Page bounding box information speci es the size and the location of the three types of special zones i e page header zone page footer zone and live matter zone The location of the zone is speci ed in terms of the row and column pixel coordinates of the top left hand corner of each type of zone box The size is speci ed by giving the row and column pixel coordinates of the bottom right hand corner of the zone box These zone boxes have been delineated by hand using an interactive zone boxing tool These zone boxes are by no means the smallest bounding rectangle but are guaranteed to contain the page area they are meant to Where unavoidable as a result of page rotation or too small a separation between zone boxes there may also be an overlap area between adjacent zone boxes\nFor each of the zones in the page the size and location of the zone bounding boxes is similarly speci ed\nZone threading\nThe zones of each document page are grouped into several logical units Within each logical unit the reading order is sequential Such a logical unit is called a semantic thread Thus associated with each zone in a thread is a pointer to the next zone within the thread Figures and their captions make up a thread So do tables and their captions Zones in the header or the footer areas make up threads individually All other sets of text zones constitute the main thread of the document page In general the last zone within a thread has a nil pointer In some cases zone threading may cross pages When consecutive document pages are presented within the database the last zone of a given page that is in the live matter area may thread with the appropriate zone on the following page\nZone attributes\nZone attributes de ne the properties of a zone on a document page The zone attributes contain information on the Page ID the Zone ID the zone contents the zone label the text alignment the font the column number the language and the script the character orientation and reading direction of the zone It also has zone threading information which was explained in the previous section\nThe text alignment attribute is de ned relative to the zone bounding box for the zone If the lines of text are aligned with the left edge of the bounding box it is referred to as left aligned There are similar de nitions for right and center aligned zones If the text is aligned with both the right and left edge of the zone bounding box it is referred to as justi ed Text alignment within the zone can have the values left center right justi ed justi ed hanging and left hanging\nZone attributes include Dominant font type serif sans serif non text Dom inant character spacing proportional xed non text Dominant font size pts non text Dominant font style plain bold italic underline script non text Character orientation up right rotated right rotated left non text Text reading direction left right right left top down bottom up non text Zone s column number header area footer area non text Next Zone ID within the same thread nil\nOther zone attributes include Document ID character string Zone ID character string Language English French German Japanese Script Roman Katakana Kanji Hiragana Zone content text text with special symbols text with non japanese symbols text with special symbols non japanese text with rubi text with non japanese and rubi text with special symbols non japanese and rubi math table halftone drawing ruling bounding box logo map form advertisement an nouncement handwriting seal halftone with drawing gurative text english gu rative text chinese gurative text korean signature initials new de nition block\ngurative text gurative text japanese Text zone label text body list item drop cap caption section heading synopsis highlight pseudo code reference heading de nition reference list reference list item footnote biography list not clear Page headers and footers can have these zone labels page header page footer page num ber\nTitle pages of documents can have zone labels title author a liation diploma membership abstract heading abstract body abstract heading and body correspon dence executive abstract heading executive abstract body keyword heading keyword body reader service keyword heading and body publication infomation article sub mission information not clear\nMemos and Letter documents can also have the following zone attributes date to from subject cc memo heading complement street address city address PO Box phone number e mail address fax number telex number laboratory depart ment group division institution subject matter sender s reference sender s name\nrecipient s name secretary s initials sender s title sender s initials opening salu tation closing salutation home o ce information founding date enclosure Japanese documents can have these other label values subject title illustrator author a liation membership title author a liation\nGround Truth Data\nThe database provides the ground truth for all text zones on a document page For non text zones such as the displayed mathematical formulas line art gures table zones and etc an indication of such will be given\nIn UW II a zone based ground truth method is used The zone based ground truth consists of the symbol strings which are contained in the text zone This includes the standard ASCII characters as well as special symbol escape sequences for non ASCII characters The lines in the ground truth data are broken at the same position of the string where the physical line is broken on the page Tabbing or indentations are ignored Single blank characters spaces are used for one or more spaces within a text line Ground truth for Japanese text is provided in unicode The methodology used for accurate ground truthing involves double data entry and triple veri cation The character substitution error rate is estimated at about characters per million for UW I and characters per million for UW II\nDiscussion and Conclusions\nSeveral signi cant data sets for OCR and document image understanding research were surveyed The CEDAR CENPARMI and NIST data sets were designed to address the needs of researchers in o ine handwriting recognition\nThe UNIPEN data set contains a large number of samples of online handwriting The success of the UNIPEN project demonstrates that it is possible to exchange data on a large scale The keys to the success of UNIPEN were to develop a common data format and to keep all decisions democratic so that they would re ect the desires of the majority of the participants Exchanging data also raises some di culties One of them is that it can take a long time the project is already two years old Another one is that transforming many di erent data sets into a standard format can be time consuming\nThe University of Washington data sets of machine printed text images have helped many researchers in document recognition The large number of truthed images on the UW CDROMs have seen widespread use and have been one of the factors in improving the performance of various commercial OCR packages This project recently provided a signi cant sample of scanned and truthed Japanese text\nSome interesting practical problems in the design of a data set are illustrated by these e orts For example in the UNIPEN project the splitting of the data set into training and test sets while retaining a statistically signi cant test set size was\nconsidered Another open problem in data set design is in non English language text The University of Washington has begun to address this issue but collections of truthed images from other languages besides English and Japanese e g French Russian Chinese etc are needed so that problems in non English OCR can be investigated by many researchers"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 48,
                                "start": 45
                            }
                        ],
                        "text": "In contrast with binary formats, such as Jot [2], the UNIPEN format is not optimized for data storage or real time data transmission and it is not designed to handle ink manipulation applications involving colors, image rotations, rescaling, etc."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A specification for an ink storage and interchange format, Technical Report draft version"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1993
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 2,
            "methodology": 6
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 24,
        "totalPages": 3
    },
    "page_url": "https://www.semanticscholar.org/paper/DATA-SETS-FOR-OCR-AND-DOCUMENT-IMAGE-UNDERSTANDING-Guyon-Haralick/6a76e38292960c7fc7576463225938fe74131611?sort=total-citations"
}