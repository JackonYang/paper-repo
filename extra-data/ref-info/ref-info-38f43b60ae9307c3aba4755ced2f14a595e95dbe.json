{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2111237291"
                        ],
                        "name": "Su S. Chen",
                        "slug": "Su-S.-Chen",
                        "structuredName": {
                            "firstName": "Su",
                            "lastName": "Chen",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Su S. Chen"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 63629817,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "068bc334298658330e9df2ceebeb5f4c76b60b90",
            "isKey": false,
            "numCitedBy": 12,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "The aim of this study is to apply solid statistical methods to systematically model and extract various layout structures on document images, such as words, text lines and text blocks. \nWe first establish the computation theory of the recursive morphological transforms, namely the recursive erosion transform, the recursive dilation transform, the recursive opening transform, and the recursive closing transform. The transforms serve as a set of powerful tools for the document image shape analysis. \nThen we describe our efforts to construct a series of carefully ground-truthed document image databases, such as the UW English document image database (I). The database offers a platform based on which we can develop, train and evaluate our document layout analysis system. \nWe present three sub-components of our document layout analysis system. They are the text skew estimation, the word segmentation, and the object spatial analysis: \nThe text skew estimation finds the text skew angle of a document image. We develop an automatic text skew estimation algorithm using the recursive opening and closing transforms. It computes the estimated text skew angles which are within 0.5$\\sp\\circ$ of the true text skew angles with a probability of 0.95 on real images. \nThe word segmentation detects all the words on a document image. We describe a word segmentation algorithm that utilizes the recursive closing transform. We derive the quantitative measures, such as the rates of miss, false, correct, splitting, merging and spurious detections, to evaluate its performance. The results show that the algorithm correctly detects the words on a document image at a rate of about 95%. \nThe object spatial analysis treats the detected words as atomic and employs a probabilistic linear displacement model (PLDM) and an augmented PLDM model to model and extract the text lines and text blocks in a document image. By gathering statistics from a large population of document images, we are able to validate our models and determine the proper model parameters. The correct text line and text block detection rates are about 92% and 81% respectively."
            },
            "slug": "Document-layout-analysis-using-recursive-transforms-Chen",
            "title": {
                "fragments": [],
                "text": "Document layout analysis using recursive morphological transforms"
            },
            "tldr": {
                "abstractSimilarityScore": 94,
                "text": "The aim of this study is to apply solid statistical methods to systematically model and extract various layout structures on document images, such as words, text lines and text blocks, through the computation theory of the recursive morphological transforms."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143626870"
                        ],
                        "name": "T. Kanungo",
                        "slug": "T.-Kanungo",
                        "structuredName": {
                            "firstName": "Tapas",
                            "lastName": "Kanungo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kanungo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1710238"
                        ],
                        "name": "R. Haralick",
                        "slug": "R.-Haralick",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Haralick",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Haralick"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 3373995,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "621fe65aed6a8cfeff6294cc60a51764b0640c62",
            "isKey": false,
            "numCitedBy": 19,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "Character groundtruth for scanned document images is crucial for evaluating OCR system performance, training OCR algorithms, and validating document degradation models. Manual collection of accurate character groundtruth in a real (scanned) document image is not possible because (i) accuracy in delineating groundtruth character bounding boxes is too low, (ii) it is very laborious and time consuming and (iii) the manual labor required is prohibitively expensive. We present a closed-loop methodology. We first create ideal documents using a typesetting language. Next we create the groundtruth for the ideal document. The document is then printed, photocopied and scanned. A registration algorithm estimates the geometric transformation that registers the ideal document image to the scanned document image. Finally, groundtruth associated with the ideal document image is transformed using the estimated geometric transform to create the groundtruth for the scanned document image. This methodology is very general and can be used for creating groundtruth for documents typeset in any language, layout, font, and style. The cost of creating groundtruth using our methodology is minimal. We use this methodology to groundtruth 33 English documents consisting of over 62000 symbols. The procedure takes approximately 5 minutes per page on a SUN Sparc 10. We also use the method for Hindi and FAX documents."
            },
            "slug": "Automatic-generation-of-character-groundtruth-for-a-Kanungo-Haralick",
            "title": {
                "fragments": [],
                "text": "Automatic generation of character groundtruth for scanned documents: a closed-loop approach"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This methodology is very general and can be used for creating groundtruth for documents typeset in any language, layout, font, and style and is used to groundtruth 33 English documents consisting of over 62000 symbols."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of 13th International Conference on Pattern Recognition"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1710238"
                        ],
                        "name": "R. Haralick",
                        "slug": "R.-Haralick",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Haralick",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Haralick"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 13615381,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d91e0d202fa23b7a2e81c5b3b04eb4cc5327b0f9",
            "isKey": false,
            "numCitedBy": 144,
            "numCiting": 66,
            "paperAbstract": {
                "fragments": [],
                "text": "Document image understanding encompasses the technology required to make paper documents equivalent to other computer exchange media like floppies, tapes, and CDROMs. The physical reader of the paper document is the scanner just like the physical reader of the floppy is the floppy drive and the physical reader of the tape cartridge is the tape cartridge drive, and the physical reader of the CDROM is the CDROM drive. In the survey presented, we restrict ourselves to documents such as business letters, forms, and scientific and technical articles such as those found in archival journals and technical conferences. Understanding such documents involves estimating the rotation skew of each document page, determining the geometric page layout, labeling blocks as text or non-text, determining the read order for text blocks, recognizing the text of text blocks through an OCR system, determining the logical page layout, and formatting the data and information of the document in a suitable way for use by a word processing system or by an information retrieval system.<<ETX>>"
            },
            "slug": "Document-image-understanding:-geometric-and-logical-Haralick",
            "title": {
                "fragments": [],
                "text": "Document image understanding: geometric and logical layout"
            },
            "tldr": {
                "abstractSimilarityScore": 71,
                "text": "Document image understanding encompasses the technology required to make paper documents equivalent to other computer exchange media like floppies, tapes, and CDROMs and restricts ourselves to documents such as business letters, forms, and scientific and technical articles such as those found in archival journals and technical conferences."
            },
            "venue": {
                "fragments": [],
                "text": "1994 Proceedings of IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2122930"
                        ],
                        "name": "J. Ha",
                        "slug": "J.-Ha",
                        "structuredName": {
                            "firstName": "Jaekyu",
                            "lastName": "Ha",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Ha"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1744200"
                        ],
                        "name": "I. T. Phillips",
                        "slug": "I.-T.-Phillips",
                        "structuredName": {
                            "firstName": "Ihsin",
                            "lastName": "Phillips",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. T. Phillips"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1710238"
                        ],
                        "name": "R. Haralick",
                        "slug": "R.-Haralick",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Haralick",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Haralick"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 6826352,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ebbbb7c50c5a5bc6f402230c8c77b83c83db4b48",
            "isKey": false,
            "numCitedBy": 24,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "Segmentation of document images can be performed by projecting image pixels. This pixel projection approach is one of widely used top-down segmentation methods and is based on the assumption that the document image has been correctly deskewed. Unfortunately, the pixel projection approach is computationally inefficient. It is because each symbol is not treated as a computational unit. In this paper, we explain a new technique which is highly tactical in the profiling analysis. Instead of projecting image pixels, we first compute the bounding box of each connected component in a document image and then we project those bounding boxes. Using the new technique, this paper describes how to extract words, text lines, and text blocks (e.g., paragraphs). This bounding box projection approach has many advantages over the pixel projection approach. It is less computationally involved. When applied to text zones, it is also possible to infer from the projection profiles how bounding boxes (and, therefore, primitive symbols) are aligned and/or where significant horizontal and vertical gaps are present. Since the new technique manipulates only bounding boxes, it can be applied to any noncursive language documents."
            },
            "slug": "Document-page-decomposition-using-bounding-boxes-of-Ha-Phillips",
            "title": {
                "fragments": [],
                "text": "Document page decomposition using bounding boxes of connected components of black pixels"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "This paper describes how to extract words, text lines, and text blocks (e.g., paragraphs) using a new technique which is highly tactical in the profiling analysis and has many advantages over the pixel projection approach."
            },
            "venue": {
                "fragments": [],
                "text": "Electronic Imaging"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1780258"
                        ],
                        "name": "Jisheng Liang",
                        "slug": "Jisheng-Liang",
                        "structuredName": {
                            "firstName": "Jisheng",
                            "lastName": "Liang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jisheng Liang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1744200"
                        ],
                        "name": "I. T. Phillips",
                        "slug": "I.-T.-Phillips",
                        "structuredName": {
                            "firstName": "Ihsin",
                            "lastName": "Phillips",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. T. Phillips"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2122930"
                        ],
                        "name": "J. Ha",
                        "slug": "J.-Ha",
                        "structuredName": {
                            "firstName": "Jaekyu",
                            "lastName": "Ha",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Ha"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1710238"
                        ],
                        "name": "R. Haralick",
                        "slug": "R.-Haralick",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Haralick",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Haralick"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 14089161,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "34228adee4914700d2544cf177b6173c74fdcead",
            "isKey": false,
            "numCitedBy": 19,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we describe a feature based supervised zone classifier using only the knowledge of the widths and the heights of the connected-components within a given zone. The distribution of the widths and the heights of the connected-components is encoded into a n multiplied by m dimensional vector in the decision making. Thus, the computational complexity is in the order of the number of connected-components within the given zone. A binary decision tree is used to assign a zone class on the basis of its feature vector. The training and testing data sets for the algorithm are drawn from the scientific document pages in the UW-I database. The classifier is able to classify each given scientific and technical document zone into one of the eight labels: text of font size 8-12, text of font size 13-18, text of font size 19-36, display math, table, halftone, line drawing, and ruling, in real time. The classifier is able to discriminate text from non-text with an accuracy greater than 97%."
            },
            "slug": "Document-zone-classification-using-sizes-of-Liang-Phillips",
            "title": {
                "fragments": [],
                "text": "Document zone classification using sizes of connected components"
            },
            "tldr": {
                "abstractSimilarityScore": 78,
                "text": "A feature based supervised zone classifier using only the knowledge of the widths and the heights of the connected-components within a given zone that is able to discriminate text from non-text with an accuracy greater than 97%."
            },
            "venue": {
                "fragments": [],
                "text": "Electronic Imaging"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 6,
                                "start": 0
                            }
                        ],
                        "text": "UW-III [8] is the third in a series of UW documentimage databases."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 36,
                                "start": 30
                            }
                        ],
                        "text": "The algorithms were tested on UW-IIIdatabase with a total of 105,439 text-lines (See Ta-ble 2)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 10,
                                "start": 7
                            }
                        ],
                        "text": "UW-III [8] is the third in a series of UW document image databases."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 34,
                                "start": 28
                            }
                        ],
                        "text": "These methods were testedon UW-III database with a total of 21,738 text blocks(See Table 4)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 240,
                                "start": 234
                            }
                        ],
                        "text": "Correct Splitting Merging Miss SpuriousAlignment 75.64% 7.42% 15.10% 0.00% 1.83%APLDM 72.96% 6.50% 15.24% 0.04% 5.26%4.2 Style DetectionThe formatting properties for each zone entity inthe document are ground-truthed as attributes in UW-III database."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 89,
                                "start": 83
                            }
                        ],
                        "text": "The performance of each algorithm has been evaluatedbased on these metrics and the UW-III document im-age database which contains a total of 1600 Englishdocument images randomly selected from scienti c andtechnical journals.1 IntroductionThe goal of document image analysis is to trans-form document images into a hierarchical representa-tion of their structure and content."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 35,
                                "start": 29
                            }
                        ],
                        "text": "These methods were tested on UW-III database witha total of 828,201 words (See Table 3)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 9,
                                "start": 3
                            }
                        ],
                        "text": "In UW-III database,a software package for the automatic generation ofcharacter-level ground-truth for scanned documents isprovided [10]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 6,
                                "start": 0
                            }
                        ],
                        "text": "UW-III English/Technical Docu-ment Image Database Manual, 1996."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 32,
                                "start": 26
                            }
                        ],
                        "text": "This method was tested on UW-III database with atotal of 24,243 zones."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "User's Reference Manual for  the UW English/Technical Document Image  Database III. UW-III English/Technical"
            },
            "venue": {
                "fragments": [],
                "text": "Docu-  ment Image Database Manual,"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 308,
                                "start": 305
                            }
                        ],
                        "text": "15% have developed a method using feature vector generation and classi cation to classify each given scienti c and technical document zone into one of the eight labels: text of font size 8-12pt, text of font size 13-18pt, text of font size 19-36pt, display math, table, halftone, line drawing, and ruling [6]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Document Zone Classi cation Using the Sizes of  Connected Components"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the SPIE,"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The Prototype of A Complete Document Understanding System"
            },
            "venue": {
                "fragments": [],
                "text": "Proc . IAPR Workshop on Document Analysis Systems"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Performance Evaluation of Algorithms in ISL Document Layout Analysis Toolbox User's Reference Manual for the UW English/Technical Document Image Database 111"
            },
            "venue": {
                "fragments": [],
                "text": "UW-I11 EnglishjTechnical Document Image Database Manual"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Document Zone Classijcation Using the Sixes of Connected Components"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the SPIE, Vo12660, Document Recognition 111"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The Prototype of A Complete Document Understanding System"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. IAPR Workshop on Document Analysis Systems"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "DAFS: Document Attribute Format Specification"
            },
            "venue": {
                "fragments": [],
                "text": "DAFS: Document Attribute Format Specification"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Per-  formance Evaluation of Algorithms in ISL Docu-  ment Layout Analysis Toolbox"
            },
            "venue": {
                "fragments": [],
                "text": "ISL Technical Re-  port, University of Washington,"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "DAFS: Document Attribute Format Speciication"
            },
            "venue": {
                "fragments": [],
                "text": "DAFS: Document Attribute Format Speciication"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "OCR Performance Evaluation Software User's Manual"
            },
            "venue": {
                "fragments": [],
                "text": "ISL Report, E.E. Dept"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Performance Evaluation of Algorithms in ISL Document Layout Analysis Toolbox"
            },
            "venue": {
                "fragments": [],
                "text": "Performance Evaluation of Algorithms in ISL Document Layout Analysis Toolbox"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "ICPR'96"
            },
            "venue": {
                "fragments": [],
                "text": "ICPR'96"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "User's Reference Manual for the UW English/Technical Document Image Database III. UW-III English/Technical Document Image Database Manual"
            },
            "venue": {
                "fragments": [],
                "text": "User's Reference Manual for the UW English/Technical Document Image Database III. UW-III English/Technical Document Image Database Manual"
            },
            "year": 1996
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 1,
            "methodology": 1
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 18,
        "totalPages": 2
    },
    "page_url": "https://www.semanticscholar.org/paper/UW-ISL-document-image-analysis-toolbox:-an-Liang-Rogers/38f43b60ae9307c3aba4755ced2f14a595e95dbe?sort=total-citations"
}