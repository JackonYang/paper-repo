{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1752769"
                        ],
                        "name": "Wenyuan Dai",
                        "slug": "Wenyuan-Dai",
                        "structuredName": {
                            "firstName": "Wenyuan",
                            "lastName": "Dai",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wenyuan Dai"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152290618"
                        ],
                        "name": "Qiang Yang",
                        "slug": "Qiang-Yang",
                        "structuredName": {
                            "firstName": "Qiang",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Qiang Yang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1701421"
                        ],
                        "name": "Gui-Rong Xue",
                        "slug": "Gui-Rong-Xue",
                        "structuredName": {
                            "firstName": "Gui-Rong",
                            "lastName": "Xue",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Gui-Rong Xue"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1811427"
                        ],
                        "name": "Yong Yu",
                        "slug": "Yong-Yu",
                        "structuredName": {
                            "firstName": "Yong",
                            "lastName": "Yu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yong Yu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 14,
                                "start": 11
                            }
                        ],
                        "text": "Dai et al. [6] proposed a boosting algorithm, TrAdaBoost, which is an extension of the AdaBoost algorithm, to address the inductive transfer learning problems."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 10,
                                "start": 0
                            }
                        ],
                        "text": "Dai et al. [26] studied a new case of clustering problems, known as self-taught clustering."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 110,
                                "start": 107
                            }
                        ],
                        "text": "Jiang and Zhai [30] proposed a heuristic method to remove \u201cmisleading\u201d training examples from the source domain based on the difference between conditional probabilities P \u00f0yT jxT \u00de and P \u00f0ySjxS\u00de."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 38,
                                "start": 28
                            }
                        ],
                        "text": "On the 20 Newsgroups1 data, Dai et al. [6] showed the comparison experiments between standard SVM and the proposed TrAdaBoost algorithm."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 19,
                                "start": 9
                            }
                        ],
                        "text": "In [36], Dai et al. proposed a coclustering-based algorithm to propagate the label information across different domains."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 18,
                                "start": 15
                            }
                        ],
                        "text": "Thus, the data are clustered based on the task parameters, where tasks in the same cluster are supposed to be related to each other."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 49,
                                "start": 39
                            }
                        ],
                        "text": "Besides sample reweighting techniques, Dai et al. [28]\nextended a traditional Naive Bayesian classifier for the\ntransductive transfer learning problems."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 81,
                                "start": 78
                            }
                        ],
                        "text": "Rosenstein et al. [70] empirically showed that if two tasks are too dissimilar, then brute-force transfer may hurt the performance of the target task."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 32,
                                "start": 22
                            }
                        ],
                        "text": "Raina et al. [74] and Dai et al. [36], [28] proposed to use transfer learning techniques to learn text data across domains, respectively."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 56,
                                "start": 53
                            }
                        ],
                        "text": "In the inductive transfer learning setting, the target task is different from the source task, no matter when the source and target domains are the same or not."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 34,
                                "start": 31
                            }
                        ],
                        "text": "Index Terms\u2014Transfer learning, survey, machine learning, data mining."
                    },
                    "intents": []
                }
            ],
            "corpusId": 8153773,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "884895a86fe15cb9601df4a15a1475c07f28da3c",
            "isKey": false,
            "numCitedBy": 1455,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "Traditional machine learning makes a basic assumption: the training and test data should be under the same distribution. However, in many cases, this identical-distribution assumption does not hold. The assumption might be violated when a task from one new domain comes, while there are only labeled data from a similar old domain. Labeling the new data can be costly and it would also be a waste to throw away all the old data. In this paper, we present a novel transfer learning framework called TrAdaBoost, which extends boosting-based learning algorithms (Freund & Schapire, 1997). TrAdaBoost allows users to utilize a small amount of newly labeled data to leverage the old data to construct a high-quality classification model for the new data. We show that this method can allow us to learn an accurate model using only a tiny amount of new data and a large amount of old data, even when the new data are not sufficient to train a model alone. We show that TrAdaBoost allows knowledge to be effectively transferred from the old data to the new. The effectiveness of our algorithm is analyzed theoretically and empirically to show that our iterative algorithm can converge well to an accurate model."
            },
            "slug": "Boosting-for-transfer-learning-Dai-Yang",
            "title": {
                "fragments": [],
                "text": "Boosting for transfer learning"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This paper presents a novel transfer learning framework called TrAdaBoost, which extends boosting-based learning algorithms and shows that this method can allow us to learn an accurate model using only a tiny amount of new data and a large amount of old data, even when the new data are not sufficient to train a model alone."
            },
            "venue": {
                "fragments": [],
                "text": "ICML '07"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "15146619"
                        ],
                        "name": "Dikan Xing",
                        "slug": "Dikan-Xing",
                        "structuredName": {
                            "firstName": "Dikan",
                            "lastName": "Xing",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dikan Xing"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1752769"
                        ],
                        "name": "Wenyuan Dai",
                        "slug": "Wenyuan-Dai",
                        "structuredName": {
                            "firstName": "Wenyuan",
                            "lastName": "Dai",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wenyuan Dai"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1701421"
                        ],
                        "name": "Gui-Rong Xue",
                        "slug": "Gui-Rong-Xue",
                        "structuredName": {
                            "firstName": "Gui-Rong",
                            "lastName": "Xue",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Gui-Rong Xue"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1811427"
                        ],
                        "name": "Yong Yu",
                        "slug": "Yong-Yu",
                        "structuredName": {
                            "firstName": "Yong",
                            "lastName": "Yu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yong Yu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "5"
                    },
                    "intents": []
                }
            ],
            "corpusId": 12034756,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "126113d251297812e091c5990064c8300effa684",
            "isKey": false,
            "numCitedBy": 77,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "There is usually an assumption in traditional machine learning that the training and test data are governed by the same distribution. This assumption might be violated when the training and test data come from different time periods or domains. In such situations, traditional machine learning methods not aware of the shift of distribution may fail. This paper proposes a novel algorithm, namely bridged refinement, to take the shift into consideration. The algorithm corrects the labels predicted by a shift-unaware classifier towards a target distribution and takes the mixture distribution of the training and test data as a bridge to better transfer from the training data to the test data. In the experiments, our algorithm successfully refines the classification labels predicted by three state-of-the-art algorithms: the Support Vector Machine, the naive Bayes classifier and the Transductive Support Vector Machine on eleven data sets. The relative reduction of error rates is about 50% in average."
            },
            "slug": "Bridged-Refinement-for-Transfer-Learning-Xing-Dai",
            "title": {
                "fragments": [],
                "text": "Bridged Refinement for Transfer Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A novel algorithm, namely bridged refinement, to take the shift of distribution into consideration is proposed, which corrects the labels predicted by a shift-unaware classifier towards a target distribution and takes the mixture distribution of the training and test data as a bridge to better transfer from the training data to the test data."
            },
            "venue": {
                "fragments": [],
                "text": "PKDD"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1409068337"
                        ],
                        "name": "Joaquin Quionero-Candela",
                        "slug": "Joaquin-Quionero-Candela",
                        "structuredName": {
                            "firstName": "Joaquin",
                            "lastName": "Quionero-Candela",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Joaquin Quionero-Candela"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "67154907"
                        ],
                        "name": "Masashi Sugiyama",
                        "slug": "Masashi-Sugiyama",
                        "structuredName": {
                            "firstName": "Masashi",
                            "lastName": "Sugiyama",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Masashi Sugiyama"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2071649"
                        ],
                        "name": "Anton Schwaighofer",
                        "slug": "Anton-Schwaighofer",
                        "structuredName": {
                            "firstName": "Anton",
                            "lastName": "Schwaighofer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Anton Schwaighofer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145306271"
                        ],
                        "name": "Neil D. Lawrence",
                        "slug": "Neil-D.-Lawrence",
                        "structuredName": {
                            "firstName": "Neil",
                            "lastName": "Lawrence",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Neil D. Lawrence"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 68,
                                "start": 64
                            }
                        ],
                        "text": "In the inductive transfer learning setting, the target task is different from the source task, no matter when the source and target domains are the same or not."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 262,
                                "start": 258
                            }
                        ],
                        "text": "For more informa-\ntion on importance sampling and reweighting methods for\ncovariate shift or sample selection bias, readers can refer to a\nrecently published book [29] by Quionero-Candela et al. One\ncan also consult a tutorial on Sample Selection Bias by Fan and Sugiyama in ICDM-08."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 3,
                                "start": 0
                            }
                        ],
                        "text": "Fan et al. [35] further analyzed the problems by using\nvarious classifiers to estimate the probability ratio."
                    },
                    "intents": []
                }
            ],
            "corpusId": 61294087,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c62043a7d2537bbf40a84b9913957452a47fdb83",
            "isKey": false,
            "numCitedBy": 1217,
            "numCiting": 159,
            "paperAbstract": {
                "fragments": [],
                "text": "Dataset shift is a common problem in predictive modeling that occurs when the joint distribution of inputs and outputs differs between training and test stages. Covariate shift, a particular case of dataset shift, occurs when only the input distribution changes. Dataset shift is present in most practical applications, for reasons ranging from the bias introduced by experimental design to the irreproducibility of the testing conditions at training time. (An example is -email spam filtering, which may fail to recognize spam that differs in form from the spam the automatic filter has been built on.) Despite this, and despite the attention given to the apparently similar problems of semi-supervised learning and active learning, dataset shift has received relatively little attention in the machine learning community until recently. This volume offers an overview of current efforts to deal with dataset and covariate shift. The chapters offer a mathematical and philosophical introduction to the problem, place dataset shift in relationship to transfer learning, transduction, local learning, active learning, and semi-supervised learning, provide theoretical views of dataset and covariate shift (including decision theoretic and Bayesian perspectives), and present algorithms for covariate shift. Contributors: Shai Ben-David, Steffen Bickel, Karsten Borgwardt, Michael Brckner, David Corfield, Amir Globerson, Arthur Gretton, Lars Kai Hansen, Matthias Hein, Jiayuan Huang, Takafumi Kanamori, Klaus-Robert Mller, Sam Roweis, Neil Rubens, Tobias Scheffer, Marcel Schmittfull, Bernhard Schlkopf, Hidetoshi Shimodaira, Alex Smola, Amos Storkey, Masashi Sugiyama, Choon Hui Teo Neural Information Processing series"
            },
            "slug": "Dataset-Shift-in-Machine-Learning-Quionero-Candela-Sugiyama",
            "title": {
                "fragments": [],
                "text": "Dataset Shift in Machine Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This volume offers an overview of current efforts to deal with dataset and covariate shift, and places dataset shift in relationship to transfer learning, transduction, local learning, active learning, and semi-supervised learning."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1752769"
                        ],
                        "name": "Wenyuan Dai",
                        "slug": "Wenyuan-Dai",
                        "structuredName": {
                            "firstName": "Wenyuan",
                            "lastName": "Dai",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wenyuan Dai"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1701421"
                        ],
                        "name": "Gui-Rong Xue",
                        "slug": "Gui-Rong-Xue",
                        "structuredName": {
                            "firstName": "Gui-Rong",
                            "lastName": "Xue",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Gui-Rong Xue"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152290618"
                        ],
                        "name": "Qiang Yang",
                        "slug": "Qiang-Yang",
                        "structuredName": {
                            "firstName": "Qiang",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Qiang Yang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1811427"
                        ],
                        "name": "Yong Yu",
                        "slug": "Yong-Yu",
                        "structuredName": {
                            "firstName": "Yong",
                            "lastName": "Yu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yong Yu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 62,
                                "start": 58
                            }
                        ],
                        "text": "In the inductive transfer learning setting, the target task is different from the source task, no matter when the source and target domains are the same or not."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 151,
                                "start": 147
                            }
                        ],
                        "text": "Besides sample reweighting techniques, Dai et al. [28]\nextended a traditional Naive Bayesian classifier for the\ntransductive transfer learning problems."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 54,
                                "start": 50
                            }
                        ],
                        "text": "Self-taught clustering is an instance of unsupervised transfer learning, which aims at clustering a small collection of unlabeled data in the target domain with the help of a large amount of unlabeled data in the source domain."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 281573,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bae533297207bb64597afa3b86a699ed6c4c98b1",
            "isKey": false,
            "numCitedBy": 372,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "A basic assumption in traditional machine learning is that the training and test data distributions should be identical. This assumption may not hold in many situations in practice, but we may be forced to rely on a different-distribution data to learn a prediction model. For example, this may be the case when it is expensive to label the data in a domain of interest, although in a related but different domain there may be plenty of labeled data available. In this paper, we propose a novel transfer-learning algorithm for text classification based on an EM-based Naive Bayes classifiers. Our solution is to first estimate the initial probabilities under a distribution Dl of one labeled data set, and then use an EM algorithm to revise the model for a different distribution Du of the test data which are unlabeled. We show that our algorithm is very effective in several different pairs of domains, where the distances between the different distributions are measured using the Kullback-Leibler (KL) divergence. Moreover, KL-divergence is used to decide the trade-off parameters in our algorithm. In the experiment, our algorithm outperforms the traditional supervised and semi-supervised learning algorithms when the distributions of the training and test sets are increasingly different."
            },
            "slug": "Transferring-Naive-Bayes-Classifiers-for-Text-Dai-Xue",
            "title": {
                "fragments": [],
                "text": "Transferring Naive Bayes Classifiers for Text Classification"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This paper proposes a novel transfer-learning algorithm for text classification based on an EM-based Naive Bayes classifiers and shows that the algorithm outperforms the traditional supervised and semi-supervised learning algorithms when the distributions of the training and test sets are increasingly different."
            },
            "venue": {
                "fragments": [],
                "text": "AAAI"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1746914"
                        ],
                        "name": "Sinno Jialin Pan",
                        "slug": "Sinno-Jialin-Pan",
                        "structuredName": {
                            "firstName": "Sinno",
                            "lastName": "Pan",
                            "middleNames": [
                                "Jialin"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sinno Jialin Pan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145193332"
                        ],
                        "name": "J. Kwok",
                        "slug": "J.-Kwok",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Kwok",
                            "middleNames": [
                                "Tin-Yau"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Kwok"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152290618"
                        ],
                        "name": "Qiang Yang",
                        "slug": "Qiang-Yang",
                        "structuredName": {
                            "firstName": "Qiang",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Qiang Yang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "5"
                    },
                    "intents": []
                }
            ],
            "corpusId": 6953522,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1de5c530716de032d89aa6bf0e0b618494d74bda",
            "isKey": false,
            "numCitedBy": 597,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "Transfer learning addresses the problem of how to utilize plenty of labeled data in a source domain to solve related but different problems in a target domain, even when the training and testing problems have different distributions or features. In this paper, we consider transfer learning via dimensionality reduction. To solve this problem, we learn a low-dimensional latent feature space where the distributions between the source domain data and the target domain data are the same or close to each other. Onto this latent feature space, we project the data in related domains where we can apply standard learning algorithms to train classification or regression models. Thus, the latent feature space can be treated as a bridge of transferring knowledge from the source domain to the target domain. The main contribution of our work is that we propose a new dimensionality reduction method to find a latent space, which minimizes the distance between distributions of the data in different domains in a latent space. The effectiveness of our approach to transfer learning is verified by experiments in two real world applications: indoor WiFi localization and binary text classification."
            },
            "slug": "Transfer-Learning-via-Dimensionality-Reduction-Pan-Kwok",
            "title": {
                "fragments": [],
                "text": "Transfer Learning via Dimensionality Reduction"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A new dimensionality reduction method is proposed to find a latent space, which minimizes the distance between distributions of the data in different domains in a latentspace, which can be treated as a bridge of transferring knowledge from the source domain to the target domain."
            },
            "venue": {
                "fragments": [],
                "text": "AAAI"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145727186"
                        ],
                        "name": "R. Caruana",
                        "slug": "R.-Caruana",
                        "structuredName": {
                            "firstName": "Rich",
                            "lastName": "Caruana",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Caruana"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 190,
                                "start": 186
                            }
                        ],
                        "text": "\u2026problems, which aims to detect a user\u2019s current location based on previously collected WiFi data, it is very expensive to calibrate WiFi data for building localization models in a large-scale environment, because a user needs to label a large collection of WiFi signal data at each location."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 45998148,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "161ffb54a3fdf0715b198bb57bd22f910242eb49",
            "isKey": false,
            "numCitedBy": 3258,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Multitask Learning is an approach to inductive transfer that improves generalization by using the domain information contained in the training signals of related tasks as an inductive bias. It does this by learning tasks in parallel while using a shared representation; what is learned for each task can help other tasks be learned better. This paper reviews prior work on MTL, presents new evidence that MTL in backprop nets discovers task relatedness without the need of supervisory signals, and presents new results for MTL with k-nearest neighbor and kernel regression. In this paper we demonstrate multitask learning in three domains. We explain how multitask learning works, and show that there are many opportunities for multitask learning in real domains. We present an algorithm and results for multitask learning with case-based methods like k-nearest neighbor and kernel regression, and sketch an algorithm for multitask learning in decision trees. Because multitask learning works, can be applied to many different kinds of domains, and can be used with different learning algorithms, we conjecture there will be many opportunities for its use on real-world problems."
            },
            "slug": "Multitask-Learning-Caruana",
            "title": {
                "fragments": [],
                "text": "Multitask Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "Prior work on MTL is reviewed, new evidence that MTL in backprop nets discovers task relatedness without the need of supervisory signals is presented, and new results for MTL with k-nearest neighbor and kernel regression are presented."
            },
            "venue": {
                "fragments": [],
                "text": "Machine Learning"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145787377"
                        ],
                        "name": "Xiao Ling",
                        "slug": "Xiao-Ling",
                        "structuredName": {
                            "firstName": "Xiao",
                            "lastName": "Ling",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xiao Ling"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1752769"
                        ],
                        "name": "Wenyuan Dai",
                        "slug": "Wenyuan-Dai",
                        "structuredName": {
                            "firstName": "Wenyuan",
                            "lastName": "Dai",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wenyuan Dai"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1701421"
                        ],
                        "name": "Gui-Rong Xue",
                        "slug": "Gui-Rong-Xue",
                        "structuredName": {
                            "firstName": "Gui-Rong",
                            "lastName": "Xue",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Gui-Rong Xue"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152290618"
                        ],
                        "name": "Qiang Yang",
                        "slug": "Qiang-Yang",
                        "structuredName": {
                            "firstName": "Qiang",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Qiang Yang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1811427"
                        ],
                        "name": "Yong Yu",
                        "slug": "Yong-Yu",
                        "structuredName": {
                            "firstName": "Yong",
                            "lastName": "Yu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yong Yu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "5"
                    },
                    "intents": []
                }
            ],
            "corpusId": 5176875,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "dc55274bd31d3d1a917ec1e3cf46a7688522566e",
            "isKey": false,
            "numCitedBy": 135,
            "numCiting": 40,
            "paperAbstract": {
                "fragments": [],
                "text": "Traditional spectral classification has been proved to be effective in dealing with both labeled and unlabeled data when these data are from the same domain. In many real world applications, however, we wish to make use of the labeled data from one domain (called in-domain) to classify the unlabeled data in a different domain (out-of-domain). This problem often happens when obtaining labeled data in one domain is difficult while there are plenty of labeled data from a related but different domain. In general, this is a transfer learning problem where we wish to classify the unlabeled data through the labeled data even though these data are not from the same domain. In this paper, we formulate this domain-transfer learning problem under a novel spectral classification framework, where the objective function is introduced to seek consistency between the in-domain supervision and the out-of-domain intrinsic structure. Through optimization of the cost function, the label information from the in-domain data is effectively transferred to help classify the unlabeled data from the out-of-domain. We conduct extensive experiments to evaluate our method and show that our algorithm achieves significant improvements on classification performance over many state-of-the-art algorithms."
            },
            "slug": "Spectral-domain-transfer-learning-Ling-Dai",
            "title": {
                "fragments": [],
                "text": "Spectral domain-transfer learning"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This paper formulate this domain-transfer learning problem under a novel spectral classification framework, where the objective function is introduced to seek consistency between the in-domain supervision and the out-of-domain intrinsic structure through optimization of the cost function."
            },
            "venue": {
                "fragments": [],
                "text": "KDD"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2979876"
                        ],
                        "name": "R. Raina",
                        "slug": "R.-Raina",
                        "structuredName": {
                            "firstName": "Rajat",
                            "lastName": "Raina",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Raina"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2078284037"
                        ],
                        "name": "Alexis Battle",
                        "slug": "Alexis-Battle",
                        "structuredName": {
                            "firstName": "Alexis",
                            "lastName": "Battle",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alexis Battle"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1697141"
                        ],
                        "name": "Honglak Lee",
                        "slug": "Honglak-Lee",
                        "structuredName": {
                            "firstName": "Honglak",
                            "lastName": "Lee",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Honglak Lee"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1409971380"
                        ],
                        "name": "Ben Packer",
                        "slug": "Ben-Packer",
                        "structuredName": {
                            "firstName": "Ben",
                            "lastName": "Packer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ben Packer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34699434"
                        ],
                        "name": "A. Ng",
                        "slug": "A.-Ng",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Ng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Ng"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 7,
                                "start": 3
                            }
                        ],
                        "text": "Supervised feature construction methods for the inductive transfer learning setting are similar to those used in multitask learning."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 47,
                                "start": 43
                            }
                        ],
                        "text": "Given a specific domain, D \u00bc fX ; P \u00f0X\u00deg, a task consists of two components: a label space Y and an objective predictive function f\u00f0 \u00de (denoted by T \u00bc fY; f\u00f0 \u00deg), which is not observed but can be learned from the training data, which consist of pairs fxi; yig, where xi 2 X and yi 2 Y."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 106,
                                "start": 102
                            }
                        ],
                        "text": "In addition, according to different situations of labeled and unlabeled data in the source domain, we can further categorize the inductive transfer learning setting into two cases:\na."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6692382,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b3852f0113fcf8a3913c55ae92393ae6ccde347e",
            "isKey": false,
            "numCitedBy": 1611,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a new machine learning framework called \"self-taught learning\" for using unlabeled data in supervised classification tasks. We do not assume that the unlabeled data follows the same class labels or generative distribution as the labeled data. Thus, we would like to use a large number of unlabeled images (or audio samples, or text documents) randomly downloaded from the Internet to improve performance on a given image (or audio, or text) classification task. Such unlabeled data is significantly easier to obtain than in typical semi-supervised or transfer learning settings, making self-taught learning widely applicable to many practical learning problems. We describe an approach to self-taught learning that uses sparse coding to construct higher-level features using the unlabeled data. These features form a succinct input representation and significantly improve classification performance. When using an SVM for classification, we further show how a Fisher kernel can be learned for this representation."
            },
            "slug": "Self-taught-learning:-transfer-learning-from-data-Raina-Battle",
            "title": {
                "fragments": [],
                "text": "Self-taught learning: transfer learning from unlabeled data"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "An approach to self-taught learning that uses sparse coding to construct higher-level features using the unlabeled data to form a succinct input representation and significantly improve classification performance."
            },
            "venue": {
                "fragments": [],
                "text": "ICML '07"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1401829700"
                        ],
                        "name": "Shai Ben-David",
                        "slug": "Shai-Ben-David",
                        "structuredName": {
                            "firstName": "Shai",
                            "lastName": "Ben-David",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shai Ben-David"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2116927"
                        ],
                        "name": "John Blitzer",
                        "slug": "John-Blitzer",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Blitzer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "John Blitzer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1693407"
                        ],
                        "name": "K. Crammer",
                        "slug": "K.-Crammer",
                        "structuredName": {
                            "firstName": "Koby",
                            "lastName": "Crammer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Crammer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145366908"
                        ],
                        "name": "Fernando C Pereira",
                        "slug": "Fernando-C-Pereira",
                        "structuredName": {
                            "firstName": "Fernando",
                            "lastName": "Pereira",
                            "middleNames": [
                                "C"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Fernando C Pereira"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "5"
                    },
                    "intents": []
                }
            ],
            "corpusId": 10908021,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "96c6bc559b79d8fd518f431c707e8b44ce3bc4de",
            "isKey": false,
            "numCitedBy": 1387,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "Discriminative learning methods for classification perform well when training and test data are drawn from the same distribution. In many situations, though, we have labeled training data for a source domain, and we wish to learn a classifier which performs well on a target domain with a different distribution. Under what conditions can we adapt a classifier trained on the source domain for use in the target domain? Intuitively, a good feature representation is a crucial factor in the success of domain adaptation. We formalize this intuition theoretically with a generalization bound for domain adaption. Our theory illustrates the tradeoffs inherent in designing a representation for domain adaptation and gives a new justification for a recently proposed model. It also points toward a promising new model for domain adaptation: one which explicitly minimizes the difference between the source and target domains, while at the same time maximizing the margin of the training set."
            },
            "slug": "Analysis-of-Representations-for-Domain-Adaptation-Ben-David-Blitzer",
            "title": {
                "fragments": [],
                "text": "Analysis of Representations for Domain Adaptation"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The theory illustrates the tradeoffs inherent in designing a representation for domain adaptation and gives a new justification for a recently proposed model which explicitly minimizes the difference between the source and target domains, while at the same time maximizing the margin of the training set."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2585822"
                        ],
                        "name": "X. Liao",
                        "slug": "X.-Liao",
                        "structuredName": {
                            "firstName": "X.",
                            "lastName": "Liao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "X. Liao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145644275"
                        ],
                        "name": "Y. Xue",
                        "slug": "Y.-Xue",
                        "structuredName": {
                            "firstName": "Ya",
                            "lastName": "Xue",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Xue"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145006560"
                        ],
                        "name": "L. Carin",
                        "slug": "L.-Carin",
                        "structuredName": {
                            "firstName": "Lawrence",
                            "lastName": "Carin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Carin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 80,
                                "start": 76
                            }
                        ],
                        "text": "In the inductive transfer learning setting, the target task is different from the source task, no matter when the source and target domains are the same or not."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 136,
                                "start": 132
                            }
                        ],
                        "text": "Liao et al. [31] proposed a new active learning method to select the unlabeled data in a target domain to be labeled with the help of the source domain data."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 18365911,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "03efbabaf80d6f5fa7b55256d25f1b2af386aa5b",
            "isKey": false,
            "numCitedBy": 207,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "To achieve good generalization in supervised learning, the training and testing examples are usually required to be drawn from the same source distribution. In this paper we propose a method to relax this requirement in the context of logistic regression. Assuming Dp and Da are two sets of examples drawn from two mismatched distributions, where Da are fully labeled and Dp partially labeled, our objective is to complete the labels of Dp. We introduce an auxiliary variable \u03bc for each example in Da to reflect its mismatch with Dp. Under an appropriate constraint the \u03bc's are estimated as a byproduct, along with the classifier. We also present an active learning approach for selecting the labeled examples in Dp. The proposed algorithm, called \"Migratory-Logit\" or M-Logit, is demonstrated successfully on simulated as well as real data sets."
            },
            "slug": "Logistic-regression-with-an-auxiliary-data-source-Liao-Xue",
            "title": {
                "fragments": [],
                "text": "Logistic regression with an auxiliary data source"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "This paper proposes a method to relax the requirement to draw examples from the same source distribution in the context of logistic regression, called \"Migratory-Logit\" or M- logit, which is demonstrated successfully on simulated as well as real data sets."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2406415"
                        ],
                        "name": "Pengcheng Wu",
                        "slug": "Pengcheng-Wu",
                        "structuredName": {
                            "firstName": "Pengcheng",
                            "lastName": "Wu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Pengcheng Wu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144299726"
                        ],
                        "name": "Thomas G. Dietterich",
                        "slug": "Thomas-G.-Dietterich",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Dietterich",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thomas G. Dietterich"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 142,
                                "start": 138
                            }
                        ],
                        "text": "Wu and Dietterich [53] integrated the source domain (auxiliary) data an Support Vector Machine (SVM) framework for improving the classification performance."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 96,
                                "start": 92
                            }
                        ],
                        "text": "STC tries to learn a common feature space across domains, which helps in clustering in the target domain."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 11695825,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "38f4afbc55d3e68d450392a7fce5ef6b3ecc4829",
            "isKey": false,
            "numCitedBy": 292,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "The standard model of supervised learning assumes that training and test data are drawn from the same underlying distribution. This paper explores an application in which a second, auxiliary, source of data is available drawn from a different distribution. This auxiliary data is more plentiful, but of significantly lower quality, than the training and test data. In the SVM framework, a training example has two roles: (a) as a data point to constrain the learning process and (b) as a candidate support vector that can form part of the definition of the classifier. The paper considers using the auxiliary data in either (or both) of these roles. This auxiliary data framework is applied to a problem of classifying images of leaves of maple and oak trees using a kernel derived from the shapes of the leaves. Experiments show that when the training data set is very small, training with auxiliary data can produce large improvements in accuracy, even when the auxiliary data is significantly different from the training (and test) data. The paper also introduces techniques for adjusting the kernel scores of the auxiliary data points to make them more comparable to the training data points."
            },
            "slug": "Improving-SVM-accuracy-by-training-on-auxiliary-Wu-Dietterich",
            "title": {
                "fragments": [],
                "text": "Improving SVM accuracy by training on auxiliary data sources"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "Experiments show that when the training data set is very small, training with auxiliary data can produce large improvements in accuracy, even when the auxiliary data is significantly different from the training (and test) data."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1722360"
                        ],
                        "name": "Hal Daum\u00e9",
                        "slug": "Hal-Daum\u00e9",
                        "structuredName": {
                            "firstName": "Hal",
                            "lastName": "Daum\u00e9",
                            "middleNames": [],
                            "suffix": "III"
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hal Daum\u00e9"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695463"
                        ],
                        "name": "D. Marcu",
                        "slug": "D.-Marcu",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Marcu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Marcu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 143,
                                "start": 139
                            }
                        ],
                        "text": "The latter case of thetransductive transfer learning setting is related to domain adaptation for knowledge transfer in text classification [23] and sample selection bias [24] or co-variate shift [25], whose assumptions are"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14154185,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "47f5682448cdc0b650b54e7f59d22d72f4976c2d",
            "isKey": false,
            "numCitedBy": 840,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "The most basic assumption used in statistical learning theory is that training data and test data are drawn from the same underlying distribution. Unfortunately, in many applications, the \"in-domain\" test data is drawn from a distribution that is related, but not identical, to the \"out-of-domain\" distribution of the training data. We consider the common case in which labeled out-of-domain data is plentiful, but labeled in-domain data is scarce. We introduce a statistical formulation of this problem in terms of a simple mixture model and present an instantiation of this framework to maximum entropy classifiers and their linear chain counterparts. We present efficient inference algorithms for this special case based on the technique of conditional expectation maximization. Our experimental results show that our approach leads to improved performance on three real world tasks on four different data sets from the natural language processing domain."
            },
            "slug": "Domain-Adaptation-for-Statistical-Classifiers-Daum\u00e9-Marcu",
            "title": {
                "fragments": [],
                "text": "Domain Adaptation for Statistical Classifiers"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This work introduces a statistical formulation of this problem in terms of a simple mixture model and presents an instantiation of this framework to maximum entropy classifiers and their linear chain counterparts and leads to improved performance on three real world tasks on four different data sets from the natural language processing domain."
            },
            "venue": {
                "fragments": [],
                "text": "J. Artif. Intell. Res."
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145553026"
                        ],
                        "name": "Andrew O. Arnold",
                        "slug": "Andrew-O.-Arnold",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Arnold",
                            "middleNames": [
                                "O."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew O. Arnold"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1701451"
                        ],
                        "name": "Ramesh Nallapati",
                        "slug": "Ramesh-Nallapati",
                        "structuredName": {
                            "firstName": "Ramesh",
                            "lastName": "Nallapati",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ramesh Nallapati"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50056360"
                        ],
                        "name": "William W. Cohen",
                        "slug": "William-W.-Cohen",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Cohen",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "William W. Cohen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 13,
                                "start": 0
                            }
                        ],
                        "text": "Arnold et al. [58] proposed to use transductive transfer learning methods to solve name-entity recognition problems."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 80,
                                "start": 76
                            }
                        ],
                        "text": "The term transductive transfer learning was first proposed by Arnold et al. [58], where they required that the source and target tasks be the same, although the domains may be different."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 64,
                                "start": 60
                            }
                        ],
                        "text": "This definition covers the work of Arnold et al. [58], since the latter considered domain adaptation, where the difference lies between the marginal probability distributions of source and target data; i.e., the tasks are the same but the domains are different."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 140,
                                "start": 136
                            }
                        ],
                        "text": "The objective function of STC is shown as follows:\nJ\u00f0 ~XT ; ~XS; ~Z\u00de \u00bc I\u00f0XT ;Z\u00de I\u00f0 ~XT ; ~Z\u00de \u00fe I\u00f0XS;Z\u00de I\u00f0 ~XS; ~Z\u00de ; \u00f07\u00de\nwhere XS and XT are the source and target domain data, respectively."
                    },
                    "intents": []
                }
            ],
            "corpusId": 16151238,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d00a403028eb0786915dab7a76692e5eeadf60be",
            "isKey": true,
            "numCitedBy": 204,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "The problem of transfer learning, where information gained in one learning task is used to improve performance in another related task, is an important new area of research. While previous work has studied the supervised version of this problem, we study the more challenging case of unsupervised transductive transfer learning, where no labeled data from the target domain are available at training. We describe some current state-of-the-art inductive and transductive approaches and then adapt these models to the problem of transfer learning for protein name extraction. In the process, we introduce a novel maximum entropy based technique, iterative feature transformation (IFT), and show that it achieves comparable performance with state-of-the-art transductive SVMs. We also show how simple relaxations, such as providing additional information like the proportion of positive examples in the test data, can significantly improve the performance of some of the transductive transfer learners."
            },
            "slug": "A-Comparative-Study-of-Methods-for-Transductive-Arnold-Nallapati",
            "title": {
                "fragments": [],
                "text": "A Comparative Study of Methods for Transductive Transfer Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "A novel maximum entropy based technique, iterative feature transformation (IFT), is introduced and it is shown how simple relaxations, such as providing additional information like the proportion of positive examples in the test data, can significantly improve the performance of some of the transductive transfer learners."
            },
            "venue": {
                "fragments": [],
                "text": "Seventh IEEE International Conference on Data Mining Workshops (ICDMW 2007)"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145815677"
                        ],
                        "name": "U. R\u00fcckert",
                        "slug": "U.-R\u00fcckert",
                        "structuredName": {
                            "firstName": "Ulrich",
                            "lastName": "R\u00fcckert",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "U. R\u00fcckert"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145471896"
                        ],
                        "name": "Stefan Kramer",
                        "slug": "Stefan-Kramer",
                        "structuredName": {
                            "firstName": "Stefan",
                            "lastName": "Kramer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Stefan Kramer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "[54] designed a kernel-based approach to inductive transfer, which aims at finding a suitable kernel for the target data."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 8905975,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "45b132687d62da38ca2ce0a05e4b52bcf51f1f6f",
            "isKey": false,
            "numCitedBy": 53,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "Methods for inductive transfer take advantage of knowledge from previous learning tasks to solve a newly given task. In the context of supervised learning, the task is to find a suitable bias for a new dataset, given a set of known datasets. In this paper, we take a kernel-based approach to inductive transfer, that is, we aim at finding a suitable kernel for the new data. In our setup, the kernel is taken from the linear span of a set of predefined kernels. To find such a kernel, we apply convex optimization on two levels. On the base level, we propose an iterative procedure to generate kernels that generalize well on the known datasets. On the meta level, we combine those kernels in a minimization criterion to predict a suitable kernel for the new data. The criterion is based on a meta kernel capturing the similarity of two datasets. In experiments on small molecule and text data, kernel-based inductive transfer showed a statistically significant improvement over the best individual kernel in almost all cases."
            },
            "slug": "Kernel-Based-Inductive-Transfer-R\u00fcckert-Kramer",
            "title": {
                "fragments": [],
                "text": "Kernel-Based Inductive Transfer"
            },
            "tldr": {
                "abstractSimilarityScore": 51,
                "text": "Kernel-based inductive transfer is taken, that is, the kernel is taken from the linear span of a set of predefined kernels and combined in a minimization criterion to predict a suitable kernel for the new data."
            },
            "venue": {
                "fragments": [],
                "text": "ECML/PKDD"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1400207886"
                        ],
                        "name": "Jing Gao",
                        "slug": "Jing-Gao",
                        "structuredName": {
                            "firstName": "Jing",
                            "lastName": "Gao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jing Gao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144934701"
                        ],
                        "name": "W. Fan",
                        "slug": "W.-Fan",
                        "structuredName": {
                            "firstName": "Wei",
                            "lastName": "Fan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Fan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2118239775"
                        ],
                        "name": "Jing Jiang",
                        "slug": "Jing-Jiang",
                        "structuredName": {
                            "firstName": "Jing",
                            "lastName": "Jiang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jing Jiang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145325584"
                        ],
                        "name": "Jiawei Han",
                        "slug": "Jiawei-Han",
                        "structuredName": {
                            "firstName": "Jiawei",
                            "lastName": "Han",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jiawei Han"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 196,
                                "start": 192
                            }
                        ],
                        "text": "Most parameter-transfer approaches to the inductive transfer learning setting assume that individual models for related tasks should share some parameters or prior distributions of hyperparameters."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 93,
                                "start": 89
                            }
                        ],
                        "text": "Rosenstein et al. [70] empirically showed that if two tasks are too dissimilar, then brute-force transfer may hurt the performance of the target task."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 65,
                                "start": 61
                            }
                        ],
                        "text": "Tasks within each group are related by sharing a low-dimensional representation, which differs among different groups."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 240,
                                "start": 239
                            }
                        ],
                        "text": "However, the inductive transfer learning setting only aims at achieving high performance in the target task by transferring knowledge from the source task while multitask learning tries to learn the target and source task simultaneously. b."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 17429744,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cebbd6e489d03410ff178ffe2efce3451ea28790",
            "isKey": true,
            "numCitedBy": 314,
            "numCiting": 77,
            "paperAbstract": {
                "fragments": [],
                "text": "The effectiveness of knowledge transfer using classification algorithms depends on the difference between the distribution that generates the training examples and the one from which test examples are to be drawn. The task can be especially difficult when the training examples are from one or several domains different from the test domain. In this paper, we propose a locally weighted ensemble framework to combine multiple models for transfer learning, where the weights are dynamically assigned according to a model's predictive power on each test example. It can integrate the advantages of various learning algorithms and the labeled information from multiple training domains into one unified classification model, which can then be applied on a different domain. Importantly, different from many previously proposed methods, none of the base learning method is required to be specifically designed for transfer learning. We show the optimality of a locally weighted ensemble framework as a general approach to combine multiple models for domain transfer. We then propose an implementation of the local weight assignments by mapping the structures of a model onto the structures of the test domain, and then weighting each model locally according to its consistency with the neighborhood structure around the test example. Experimental results on text classification, spam filtering and intrusion detection data sets demonstrate significant improvements in classification accuracy gained by the framework. On a transfer learning task of newsgroup message categorization, the proposed locally weighted ensemble framework achieves 97% accuracy when the best single model predicts correctly only on 73% of the test examples. In summary, the improvement in accuracy is over 10% and up to 30% across different problems."
            },
            "slug": "Knowledge-transfer-via-multiple-model-local-mapping-Gao-Fan",
            "title": {
                "fragments": [],
                "text": "Knowledge transfer via multiple model local structure mapping"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A locally weighted ensemble framework to combine multiple models for transfer learning, where the weights are dynamically assigned according to a model's predictive power on each test example, is proposed."
            },
            "venue": {
                "fragments": [],
                "text": "KDD"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1801089"
                        ],
                        "name": "T. Evgeniou",
                        "slug": "T.-Evgeniou",
                        "structuredName": {
                            "firstName": "Theodoros",
                            "lastName": "Evgeniou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Evgeniou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1704699"
                        ],
                        "name": "M. Pontil",
                        "slug": "M.-Pontil",
                        "structuredName": {
                            "firstName": "Massimiliano",
                            "lastName": "Pontil",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Pontil"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "In [44], Wang and Mahadevan proposed a Procrustes analysis-based approach to manifold alignment without correspondences, which can be used to transfer the knowledge across domains via the aligned manifolds."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 237,
                                "start": 233
                            }
                        ],
                        "text": "However, the inductive transfer learning setting only aims at achieving high performance in the target task by transferring knowledge from the source task while multitask learning tries to learn the target and source task simultaneously. b."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 719551,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e219a61354d972a28954e655a7c53373508a08b6",
            "isKey": false,
            "numCitedBy": 1468,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "Past empirical work has shown that learning multiple related tasks from data simultaneously can be advantageous in terms of predictive performance relative to learning these tasks independently. In this paper we present an approach to multi--task learning based on the minimization of regularization functionals similar to existing ones, such as the one for Support Vector Machines (SVMs), that have been successfully used in the past for single--task learning. Our approach allows to model the relation between tasks in terms of a novel kernel function that uses a task--coupling parameter. We implement an instance of the proposed approach similar to SVMs and test it empirically using simulated as well as real data. The experimental results show that the proposed method performs better than existing multi--task learning methods and largely outperforms single--task learning using SVMs."
            },
            "slug": "Regularized-multi--task-learning-Evgeniou-Pontil",
            "title": {
                "fragments": [],
                "text": "Regularized multi--task learning"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "An approach to multi--task learning based on the minimization of regularization functionals similar to existing ones, such as the one for Support Vector Machines, that have been successfully used in the past for single-- task learning is presented."
            },
            "venue": {
                "fragments": [],
                "text": "KDD"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1752769"
                        ],
                        "name": "Wenyuan Dai",
                        "slug": "Wenyuan-Dai",
                        "structuredName": {
                            "firstName": "Wenyuan",
                            "lastName": "Dai",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wenyuan Dai"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1701421"
                        ],
                        "name": "Gui-Rong Xue",
                        "slug": "Gui-Rong-Xue",
                        "structuredName": {
                            "firstName": "Gui-Rong",
                            "lastName": "Xue",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Gui-Rong Xue"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152290618"
                        ],
                        "name": "Qiang Yang",
                        "slug": "Qiang-Yang",
                        "structuredName": {
                            "firstName": "Qiang",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Qiang Yang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1811427"
                        ],
                        "name": "Yong Yu",
                        "slug": "Yong-Yu",
                        "structuredName": {
                            "firstName": "Yong",
                            "lastName": "Yu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yong Yu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "5"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 48,
                                "start": 44
                            }
                        ],
                        "text": "Self-taught clustering is an instance of unsupervised transfer learning, which aims at clustering a small collection of unlabeled data in the target domain with the help of a large amount of unlabeled data in the source domain."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 112,
                                "start": 108
                            }
                        ],
                        "text": "In addition, according to different situations of labeled and unlabeled data in the source domain, we can further categorize the inductive transfer learning setting into two cases:\na."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7518182,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "33c83eb6ccdf6e34f1431e5aa9df6ae5646ae919",
            "isKey": false,
            "numCitedBy": 353,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "In many real world applications, labeled data are in short supply. It often happens that obtaining labeled data in a new domain is expensive and time consuming, while there may be plenty of labeled data from a related but different domain. Traditional machine learning is not able to cope well with learning across different domains. In this paper, we address this problem for a text-mining task, where the labeled data are under one distribution in one domain known as in-domain data, while the unlabeled data are under a related but different domain known as out-of-domain data. Our general goal is to learn from the in-domain and apply the learned knowledge to out-of-domain. We propose a co-clustering based classification (CoCC) algorithm to tackle this problem. Co-clustering is used as a bridge to propagate the class structure and knowledge from the in-domain to the out-of-domain. We present theoretical and empirical analysis to show that our algorithm is able to produce high quality classification results, even when the distributions between the two data are different. The experimental results show that our algorithm greatly improves the classification performance over the traditional learning algorithms."
            },
            "slug": "Co-clustering-based-classification-for-documents-Dai-Xue",
            "title": {
                "fragments": [],
                "text": "Co-clustering based classification for out-of-domain documents"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This paper proposes a co-clustering based classification (CoCC) algorithm, used as a bridge to propagate the class structure and knowledge from the in-domain to the out-of-domain, and shows that the algorithm greatly improves the classification performance over the traditional learning algorithms."
            },
            "venue": {
                "fragments": [],
                "text": "KDD '07"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2116927"
                        ],
                        "name": "John Blitzer",
                        "slug": "John-Blitzer",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Blitzer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "John Blitzer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1693407"
                        ],
                        "name": "K. Crammer",
                        "slug": "K.-Crammer",
                        "structuredName": {
                            "firstName": "Koby",
                            "lastName": "Crammer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Crammer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145500336"
                        ],
                        "name": "Alex Kulesza",
                        "slug": "Alex-Kulesza",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Kulesza",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alex Kulesza"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145366908"
                        ],
                        "name": "Fernando C Pereira",
                        "slug": "Fernando-C-Pereira",
                        "structuredName": {
                            "firstName": "Fernando",
                            "lastName": "Pereira",
                            "middleNames": [
                                "C"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Fernando C Pereira"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "4006636"
                        ],
                        "name": "Jennifer Wortman Vaughan",
                        "slug": "Jennifer-Wortman-Vaughan",
                        "structuredName": {
                            "firstName": "Jennifer",
                            "lastName": "Vaughan",
                            "middleNames": [
                                "Wortman"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jennifer Wortman Vaughan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "5"
                    },
                    "intents": []
                }
            ],
            "corpusId": 2497886,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e0e00f8a5c31403f8871a823f000ab38ac0fe2c0",
            "isKey": false,
            "numCitedBy": 402,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "Empirical risk minimization offers well-known learning guarantees when training and test data come from the same domain. In the real world, though, we often wish to adapt a classifier from a source domain with a large amount of training data to different target domain with very little training data. In this work we give uniform convergence bounds for algorithms that minimize a convex combination of source and target empirical risk. The bounds explicitly model the inherent trade-off between training on a large but inaccurate source data set and a small but accurate target training set. Our theory also gives results when we have multiple source domains, each of which may have a different number of instances, and we exhibit cases in which minimizing a non-uniform combination of source risks can achieve much lower target error than standard empirical risk minimization."
            },
            "slug": "Learning-Bounds-for-Domain-Adaptation-Blitzer-Crammer",
            "title": {
                "fragments": [],
                "text": "Learning Bounds for Domain Adaptation"
            },
            "tldr": {
                "abstractSimilarityScore": 62,
                "text": "Uniform convergence bounds are given for algorithms that minimize a convex combination of source and target empirical risk in order to adapt a classifier from a source domain with a large amount of training data to different target domain with very little training data."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1690967"
                        ],
                        "name": "A. Blum",
                        "slug": "A.-Blum",
                        "structuredName": {
                            "firstName": "Avrim",
                            "lastName": "Blum",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Blum"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144135485"
                        ],
                        "name": "Tom. Mitchell",
                        "slug": "Tom.-Mitchell",
                        "structuredName": {
                            "firstName": "Tom.",
                            "lastName": "Mitchell",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tom. Mitchell"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 63,
                                "start": 59
                            }
                        ],
                        "text": "However, many machine learning methods work well only under a common assumption: the training and test data are drawn from the same feature space and the same distribution."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 207228399,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "278841ab0cb24c1abcb75e363aeed1fa741c8cc4",
            "isKey": false,
            "numCitedBy": 5471,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "We consider the problem of using a large unlabeled sample to boost performance of a learning algorit,hrn when only a small set of labeled examples is available. In particular, we consider a problem setting motivated by the task of learning to classify web pages, in which the description of each example can be partitioned into two distinct views. For example, the description of a web page can be partitioned into the words occurring on that page, and the words occurring in hyperlinks t,hat point to that page. We assume that either view of the example would be sufficient for learning if we had enough labeled data, but our goal is to use both views together to allow inexpensive unlabeled data to augment, a much smaller set of labeled examples. Specifically, the presence of two distinct views of each example suggests strategies in which two learning algorithms are trained separately on each view, and then each algorithm\u2019s predictions on new unlabeled examples are used to enlarge the training set of the other. Our goal in this paper is to provide a PAC-style analysis for this setting, and, more broadly, a PAC-style framework for the general problem of learning from both labeled and unlabeled data. We also provide empirical results on real web-page data indicating that this use of unlabeled examples can lead to significant improvement of hypotheses in practice. *This research was supported in part by the DARPA HPKB program under contract F30602-97-1-0215 and by NSF National Young investigator grant CCR-9357793. Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. TO copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. COLT 98 Madison WI USA Copyright ACM 1998 l-58113-057--0/98/ 7...%5.00 92 Tom Mitchell School of Computer Science Carnegie Mellon University Pittsburgh, PA 15213-3891 mitchell+@cs.cmu.edu"
            },
            "slug": "Combining-labeled-and-unlabeled-data-with-Blum-Mitchell",
            "title": {
                "fragments": [],
                "text": "Combining labeled and unlabeled data with co-training"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A PAC-style analysis is provided for a problem setting motivated by the task of learning to classify web pages, in which the description of each example can be partitioned into two distinct views, to allow inexpensive unlabeled data to augment, a much smaller set of labeled examples."
            },
            "venue": {
                "fragments": [],
                "text": "COLT' 98"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1746914"
                        ],
                        "name": "Sinno Jialin Pan",
                        "slug": "Sinno-Jialin-Pan",
                        "structuredName": {
                            "firstName": "Sinno",
                            "lastName": "Pan",
                            "middleNames": [
                                "Jialin"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sinno Jialin Pan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1807998"
                        ],
                        "name": "I. Tsang",
                        "slug": "I.-Tsang",
                        "structuredName": {
                            "firstName": "Ivor",
                            "lastName": "Tsang",
                            "middleNames": [
                                "Wai-Hung"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Tsang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145193332"
                        ],
                        "name": "J. Kwok",
                        "slug": "J.-Kwok",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Kwok",
                            "middleNames": [
                                "Tin-Yau"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Kwok"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152290618"
                        ],
                        "name": "Qiang Yang",
                        "slug": "Qiang-Yang",
                        "structuredName": {
                            "firstName": "Qiang",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Qiang Yang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "5"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "As a result, tasks within a group can find it easier to transfer useful knowledge."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 788838,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1dae4d61cd74cc919ecc638bde6b7125728ea97b",
            "isKey": false,
            "numCitedBy": 2570,
            "numCiting": 65,
            "paperAbstract": {
                "fragments": [],
                "text": "Domain adaptation allows knowledge from a source domain to be transferred to a different but related target domain. Intuitively, discovering a good feature representation across domains is crucial. In this paper, we first propose to find such a representation through a new learning method, transfer component analysis (TCA), for domain adaptation. TCA tries to learn some transfer components across domains in a reproducing kernel Hilbert space using maximum mean miscrepancy. In the subspace spanned by these transfer components, data properties are preserved and data distributions in different domains are close to each other. As a result, with the new representations in this subspace, we can apply standard machine learning methods to train classifiers or regression models in the source domain for use in the target domain. Furthermore, in order to uncover the knowledge hidden in the relations between the data labels from the source and target domains, we extend TCA in a semisupervised learning setting, which encodes label information into transfer components learning. We call this extension semisupervised TCA. The main contribution of our work is that we propose a novel dimensionality reduction framework for reducing the distance between domains in a latent space for domain adaptation. We propose both unsupervised and semisupervised feature extraction approaches, which can dramatically reduce the distance between domain distributions by projecting data onto the learned transfer components. Finally, our approach can handle large datasets and naturally lead to out-of-sample generalization. The effectiveness and efficiency of our approach are verified by experiments on five toy datasets and two real-world applications: cross-domain indoor WiFi localization and cross-domain text classification."
            },
            "slug": "Domain-Adaptation-via-Transfer-Component-Analysis-Pan-Tsang",
            "title": {
                "fragments": [],
                "text": "Domain Adaptation via Transfer Component Analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This work proposes a novel dimensionality reduction framework for reducing the distance between domains in a latent space for domain adaptation and proposes both unsupervised and semisupervised feature extraction approaches, which can dramatically reduce thedistance between domain distributions by projecting data onto the learned transfer components."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Neural Networks"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1752769"
                        ],
                        "name": "Wenyuan Dai",
                        "slug": "Wenyuan-Dai",
                        "structuredName": {
                            "firstName": "Wenyuan",
                            "lastName": "Dai",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wenyuan Dai"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153096457"
                        ],
                        "name": "Qiang Yang",
                        "slug": "Qiang-Yang",
                        "structuredName": {
                            "firstName": "Qiang",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Qiang Yang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1701421"
                        ],
                        "name": "Gui-Rong Xue",
                        "slug": "Gui-Rong-Xue",
                        "structuredName": {
                            "firstName": "Gui-Rong",
                            "lastName": "Xue",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Gui-Rong Xue"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1811427"
                        ],
                        "name": "Yong Yu",
                        "slug": "Yong-Yu",
                        "structuredName": {
                            "firstName": "Yong",
                            "lastName": "Yu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yong Yu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 110,
                                "start": 106
                            }
                        ],
                        "text": "In their follow-up work, the researchers proposed to use Mutual Information (MI) to choose the pivot features instead of using more heuristic criteria [8]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 80,
                                "start": 76
                            }
                        ],
                        "text": "Then, SCL removes these pivot features from the data and treats each pivot feature as a new label vector."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 55,
                                "start": 51
                            }
                        ],
                        "text": "However, how to avoid negative transfer is an important open issue that is attracting more and more attention in the future."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6587929,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c6d014a8528e6476616936b983886b3fcde5a762",
            "isKey": false,
            "numCitedBy": 209,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper focuses on a new clustering task, called self-taught clustering. Self-taught clustering is an instance of unsupervised transfer learning, which aims at clustering a small collection of target unlabeled data with the help of a large amount of auxiliary unlabeled data. The target and auxiliary data can be different in topic distribution. We show that even when the target data are not sufficient to allow effective learning of a high quality feature representation, it is possible to learn the useful features with the help of the auxiliary data on which the target data can be clustered effectively. We propose a co-clustering based self-taught clustering algorithm to tackle this problem, by clustering the target and auxiliary data simultaneously to allow the feature representation from the auxiliary data to influence the target data through a common set of features. Under the new data representation, clustering on the target data can be improved. Our experiments on image clustering show that our algorithm can greatly outperform several state-of-the-art clustering methods when utilizing irrelevant unlabeled auxiliary data."
            },
            "slug": "Self-taught-clustering-Dai-Yang",
            "title": {
                "fragments": [],
                "text": "Self-taught clustering"
            },
            "tldr": {
                "abstractSimilarityScore": 54,
                "text": "This paper proposes a co-clustering based self-taught clustering algorithm, which can greatly outperform several state-of-the-art clustering methods when utilizing irrelevant unlabeled auxiliary data."
            },
            "venue": {
                "fragments": [],
                "text": "ICML '08"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143626983"
                        ],
                        "name": "B. Bakker",
                        "slug": "B.-Bakker",
                        "structuredName": {
                            "firstName": "Bart",
                            "lastName": "Bakker",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Bakker"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1790356"
                        ],
                        "name": "T. Heskes",
                        "slug": "T.-Heskes",
                        "structuredName": {
                            "firstName": "Tom",
                            "lastName": "Heskes",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Heskes"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 17,
                                "start": 0
                            }
                        ],
                        "text": "Bakker and Heskes [72] adopted a Bayesian approach in which some of the model parameters are shared for all tasks and others more loosely connected through a joint prior distribution that can be learned from the data."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 116,
                                "start": 112
                            }
                        ],
                        "text": "Some works have been exploited to analyze relatedness among tasks and task clustering techniques, such as [71], [72], which may help provide guidance on how to avoid negative transfer automatically."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 22,
                                "start": 18
                            }
                        ],
                        "text": "Bakker and Heskes [72] adopted a Bayesian"
                    },
                    "intents": []
                }
            ],
            "corpusId": 10436583,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a43d7b8e5e1bcb7c3fbf82164cfc9d12737176e8",
            "isKey": true,
            "numCitedBy": 594,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "Modeling a collection of similar regression or classification tasks can be improved by making the tasks 'learn from each other'. In machine learning, this subject is approached through 'multitask learning', where parallel tasks are modeled as multiple outputs of the same network. In multilevel analysis this is generally implemented through the mixed-effects linear model where a distinction is made between 'fixed effects', which are the same for all tasks, and 'random effects', which may vary between tasks. In the present article we will adopt a Bayesian approach in which some of the model parameters are shared (the same for all tasks) and others more loosely connected through a joint prior distribution that can be learned from the data. We seek in this way to combine the best parts of both the statistical multilevel approach and the neural network machinery. The standard assumption expressed in both approaches is that each task can learn equally well from any other task. In this article we extend the model by allowing more differentiation in the similarities between tasks. One such extension is to make the prior mean depend on higher-level task characteristics. More unsupervised clustering of tasks is obtained if we go from a single Gaussian prior to a mixture of Gaussians. This can be further generalized to a mixture of experts architecture with the gates depending on task characteristics. All three extensions are demonstrated through application both on an artificial data set and on two real-world problems, one a school problem and the other involving single-copy newspaper sales."
            },
            "slug": "Task-Clustering-and-Gating-for-Bayesian-Multitask-Bakker-Heskes",
            "title": {
                "fragments": [],
                "text": "Task Clustering and Gating for Bayesian Multitask Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A Bayesian approach is adopted in which some of the model parameters are shared and others more loosely connected through a joint prior distribution that can be learned from the data to combine the best parts of both the statistical multilevel approach and the neural network machinery."
            },
            "venue": {
                "fragments": [],
                "text": "J. Mach. Learn. Res."
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50033175"
                        ],
                        "name": "Andreas Argyriou",
                        "slug": "Andreas-Argyriou",
                        "structuredName": {
                            "firstName": "Andreas",
                            "lastName": "Argyriou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andreas Argyriou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1801089"
                        ],
                        "name": "T. Evgeniou",
                        "slug": "T.-Evgeniou",
                        "structuredName": {
                            "firstName": "Theodoros",
                            "lastName": "Evgeniou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Evgeniou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1704699"
                        ],
                        "name": "M. Pontil",
                        "slug": "M.-Pontil",
                        "structuredName": {
                            "firstName": "Massimiliano",
                            "lastName": "Pontil",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Pontil"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Wu and Dietterich [53] integrated the source domain (auxiliary) data an Support Vector Machine (SVM) framework for improving the classification performance."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 50,
                                "start": 46
                            }
                        ],
                        "text": "If a lot of labeled data in the source domain are available, supervised learning methods can be used to construct a feature representation."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 141,
                                "start": 137
                            }
                        ],
                        "text": "In addition, according to different situations of labeled and unlabeled data in the source domain, we can further categorize the inductive transfer learning setting into two cases:\na."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7502194,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "dbb3342599c9b431a3152a0d5c813d3e56967a27",
            "isKey": false,
            "numCitedBy": 1379,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a method for learning a low-dimensional representation which is shared across a set of multiple related tasks. The method builds upon the well-known 1-norm regularization problem using a new regularizer which controls the number of learned features common for all the tasks. We show that this problem is equivalent to a convex optimization problem and develop an iterative algorithm for solving it. The algorithm has a simple interpretation: it alternately performs a supervised and an unsupervised step, where in the latter step we learn commonacross-tasks representations and in the former step we learn task-specific functions using these representations. We report experiments on a simulated and a real data set which demonstrate that the proposed method dramatically improves the performance relative to learning each task independently. Our algorithm can also be used, as a special case, to simply select \u2013 not learn \u2013 a few common features across the tasks."
            },
            "slug": "Multi-Task-Feature-Learning-Argyriou-Evgeniou",
            "title": {
                "fragments": [],
                "text": "Multi-Task Feature Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "The method builds upon the well-known 1-norm regularization problem using a new regularizer which controls the number of learned features common for all the tasks, and develops an iterative algorithm for solving it."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1713704"
                        ],
                        "name": "Xiaoxiao Shi",
                        "slug": "Xiaoxiao-Shi",
                        "structuredName": {
                            "firstName": "Xiaoxiao",
                            "lastName": "Shi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xiaoxiao Shi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144934701"
                        ],
                        "name": "W. Fan",
                        "slug": "W.-Fan",
                        "structuredName": {
                            "firstName": "Wei",
                            "lastName": "Fan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Fan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46606181"
                        ],
                        "name": "Jiangtao Ren",
                        "slug": "Jiangtao-Ren",
                        "structuredName": {
                            "firstName": "Jiangtao",
                            "lastName": "Ren",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jiangtao Ren"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 16,
                                "start": 12
                            }
                        ],
                        "text": "Argyriou et al. [73] considered situations in which the learning tasks can be divided into groups."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 87,
                                "start": 83
                            }
                        ],
                        "text": "Rosenstein et al. [70] empirically showed that if two tasks are too dissimilar, then brute-force transfer may hurt the performance of the target task."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 8042650,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ac4b14dedffde0706a44796364443e21401d9782",
            "isKey": false,
            "numCitedBy": 136,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "When labeled examples are not readily available, active learning and transfer learning are separate efforts to obtain labeled examples for inductive learning. Active learning asks domain experts to label a small set of examples, but there is a cost incurred for each answer. While transfer learning could borrow labeled examples from a different domain without incurring any labeling cost, there is no guarantee that the transferred examples will actually help improve the learning accuracy. To solve both problems, we propose a framework to actively transfer the knowledge across domains, and the key intuition is to use the knowledge transferred from other domain as often as possible to help learn the current domain, and query experts only when necessary. To do so, labeled examples from the other domain (out-of-domain) are examined on the basis of their likelihood to correctly label the examples of the current domain (in-domain). When this likelihood is low, these out-of-domain examples will not be used to label the in-domain example, but domain experts are consulted to provide class label. We derive a sampling error bound and a querying bound to demonstrate that the proposed method can effectively mitigate risk of domain difference by transferring domain knowledge only when they are useful, and query domain experts only when necessary. Experimental studies have employed synthetic datasets and two types of real world datasets, including remote sensing and text classification problems. The proposed method is compared with previously proposed transfer learning and active learning methods. Across all comparisons, the proposed approach can evidently outperform the transfer learning model in classification accuracy given different out-of-domain datasets. For example, upon the remote sensing dataset, the proposed approach achieves an accuracy around 94.5%, while the comparable transfer learning model drops to less than 89% in most cases. The software and datasets are available from the authors."
            },
            "slug": "Actively-Transfer-Domain-Knowledge-Shi-Fan",
            "title": {
                "fragments": [],
                "text": "Actively Transfer Domain Knowledge"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A sampling error bound and a querying bound are derived to demonstrate that the proposed method can effectively mitigate risk of domain difference by transferring domain knowledge only when they are useful, and query domain experts only when necessary."
            },
            "venue": {
                "fragments": [],
                "text": "ECML/PKDD"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144934701"
                        ],
                        "name": "W. Fan",
                        "slug": "W.-Fan",
                        "structuredName": {
                            "firstName": "Wei",
                            "lastName": "Fan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Fan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143763341"
                        ],
                        "name": "I. Davidson",
                        "slug": "I.-Davidson",
                        "structuredName": {
                            "firstName": "Ian",
                            "lastName": "Davidson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Davidson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1735228"
                        ],
                        "name": "B. Zadrozny",
                        "slug": "B.-Zadrozny",
                        "structuredName": {
                            "firstName": "Bianca",
                            "lastName": "Zadrozny",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Zadrozny"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144019071"
                        ],
                        "name": "Philip S. Yu",
                        "slug": "Philip-S.-Yu",
                        "structuredName": {
                            "firstName": "Philip",
                            "lastName": "Yu",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Philip S. Yu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 110,
                                "start": 106
                            }
                        ],
                        "text": "In the inductive transfer learning setting, the target task is different from the source task, no matter when the source and target domains are the same or not."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 54,
                                "start": 50
                            }
                        ],
                        "text": "Fan et al. [35] further analyzed the problems by using\nvarious classifiers to estimate the probability ratio."
                    },
                    "intents": []
                }
            ],
            "corpusId": 1283479,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bf0da2976416b2e24366a340f080625f0aa4caa1",
            "isKey": false,
            "numCitedBy": 90,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "A recent paper categorizes classifier learning algorithms according to their sensitivity to a common type of sample selection bias where the chance of an example being selected into the training sample depends on its feature vector x but not (directly) on its class label y. A classifier learner is categorized as \"local\" if it is insensitive to this type of sample selection bias, otherwise, it is considered \"global\". In that paper, the true model is not clearly distinguished from the model that the algorithm outputs. In their discussion of Bayesian classifiers, logistic regression and hard-margin SVMs, the true model (or the model that generates the true class label for every example) is implicitly assumed to be contained in the model space of the learner, and the true class probabilities and model estimated class probabilities are assumed to asymptotically converge as the training data set size increases. However, in the discussion of naive Bayes, decision trees and soft-margin SVMs, the model space is assumed not to contain the true model, and these three algorithms are instead argued to be \"global learners\". We argue that most classifier learners may or may not be affected by sample selection bias; this depends on the dataset as well as the heuristics or inductive bias implied by the learning algorithm and their appropriateness to the particular dataset."
            },
            "slug": "An-improved-categorization-of-classifier's-on-bias-Fan-Davidson",
            "title": {
                "fragments": [],
                "text": "An improved categorization of classifier's sensitivity on sample selection bias"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "It is argued that most classifier learners may or may not be affected by sample selection bias; this depends on the dataset as well as the heuristics or inductive bias implied by the learning algorithm and their appropriateness to the particular dataset."
            },
            "venue": {
                "fragments": [],
                "text": "Fifth IEEE International Conference on Data Mining (ICDM'05)"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1701421"
                        ],
                        "name": "Gui-Rong Xue",
                        "slug": "Gui-Rong-Xue",
                        "structuredName": {
                            "firstName": "Gui-Rong",
                            "lastName": "Xue",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Gui-Rong Xue"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1752769"
                        ],
                        "name": "Wenyuan Dai",
                        "slug": "Wenyuan-Dai",
                        "structuredName": {
                            "firstName": "Wenyuan",
                            "lastName": "Dai",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wenyuan Dai"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152290618"
                        ],
                        "name": "Qiang Yang",
                        "slug": "Qiang-Yang",
                        "structuredName": {
                            "firstName": "Qiang",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Qiang Yang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1811427"
                        ],
                        "name": "Yong Yu",
                        "slug": "Yong-Yu",
                        "structuredName": {
                            "firstName": "Yong",
                            "lastName": "Yu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yong Yu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "5"
                    },
                    "intents": []
                }
            ],
            "corpusId": 15353445,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d6bfc777d9753ea18f994f70fe5dbc24c9ec3df7",
            "isKey": false,
            "numCitedBy": 218,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "In many Web applications, such as blog classification and new-sgroup classification, labeled data are in short supply. It often happens that obtaining labeled data in a new domain is expensive and time consuming, while there may be plenty of labeled data in a related but different domain. Traditional text classification ap-proaches are not able to cope well with learning across different domains. In this paper, we propose a novel cross-domain text classification algorithm which extends the traditional probabilistic latent semantic analysis (PLSA) algorithm to integrate labeled and unlabeled data, which come from different but related domains, into a unified probabilistic model. We call this new model Topic-bridged PLSA, or TPLSA. By exploiting the common topics between two domains, we transfer knowledge across different domains through a topic-bridge to help the text classification in the target domain. A unique advantage of our method is its ability to maximally mine knowledge that can be transferred between domains, resulting in superior performance when compared to other state-of-the-art text classification approaches. Experimental eval-uation on different kinds of datasets shows that our proposed algorithm can improve the performance of cross-domain text classification significantly."
            },
            "slug": "Topic-bridged-PLSA-for-cross-domain-text-Xue-Dai",
            "title": {
                "fragments": [],
                "text": "Topic-bridged PLSA for cross-domain text classification"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "A novel cross-domain text classification algorithm which extends the traditional probabilistic latent semantic analysis (PLSA) algorithm to integrate labeled and unlabeled data, which come from different but related domains, into a unified probabilism model, called Topic-bridged PLSA, or TPLSA."
            },
            "venue": {
                "fragments": [],
                "text": "SIGIR '08"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2180463"
                        ],
                        "name": "Su-In Lee",
                        "slug": "Su-In-Lee",
                        "structuredName": {
                            "firstName": "Su-In",
                            "lastName": "Lee",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Su-In Lee"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2482074"
                        ],
                        "name": "Vassil Chatalbashev",
                        "slug": "Vassil-Chatalbashev",
                        "structuredName": {
                            "firstName": "Vassil",
                            "lastName": "Chatalbashev",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Vassil Chatalbashev"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2925442"
                        ],
                        "name": "David Vickrey",
                        "slug": "David-Vickrey",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Vickrey",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David Vickrey"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1736370"
                        ],
                        "name": "D. Koller",
                        "slug": "D.-Koller",
                        "structuredName": {
                            "firstName": "Daphne",
                            "lastName": "Koller",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Koller"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 10319833,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d1582489ec4befc365fcd3bee5b546ed17425acb",
            "isKey": false,
            "numCitedBy": 167,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "In many prediction tasks, selecting relevant features is essential for achieving good generalization performance. Most feature selection algorithms consider all features to be a priori equally likely to be relevant. In this paper, we use transfer learning---learning on an ensemble of related tasks---to construct an informative prior on feature relevance. We assume that features themselves have meta-features that are predictive of their relevance to the prediction task, and model their relevance as a function of the meta-features using hyperparameters (called meta-priors). We present a convex optimization algorithm for simultaneously learning the meta-priors and feature weights from an ensemble of related prediction tasks which share a similar relevance structure. Our approach transfers the \"meta-priors\" among different tasks, which makes it possible to deal with settings where tasks have nonoverlapping features or the relevance of the features vary over the tasks. We show that learning feature relevance improves performance on two real data sets which illustrate such settings: (1) predicting ratings in a collaborative filtering task, and (2) distinguishing arguments of a verb in a sentence."
            },
            "slug": "Learning-a-meta-level-prior-for-feature-relevance-Lee-Chatalbashev",
            "title": {
                "fragments": [],
                "text": "Learning a meta-level prior for feature relevance from multiple related tasks"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "Transfer learning is used to construct an informative prior on feature relevance, and it is shown that learning feature relevance improves performance on two real data sets which illustrate such settings: predicting ratings in a collaborative filtering task, and distinguishing arguments of a verb in a sentence."
            },
            "venue": {
                "fragments": [],
                "text": "ICML '07"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38070424"
                        ],
                        "name": "R. Ando",
                        "slug": "R.-Ando",
                        "structuredName": {
                            "firstName": "Rie",
                            "lastName": "Ando",
                            "middleNames": [
                                "Kubota"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Ando"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2117881943"
                        ],
                        "name": "Tong Zhang",
                        "slug": "Tong-Zhang",
                        "structuredName": {
                            "firstName": "Tong",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tong Zhang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "5"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 118,
                                "start": 114
                            }
                        ],
                        "text": "In addition, according to different situations of labeled and unlabeled data in the source domain, we can further categorize the inductive transfer learning setting into two cases:\na."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 16629334,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b4299baa815ca5a815a70fba94a9f6f2b42fff19",
            "isKey": false,
            "numCitedBy": 235,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "In machine learning, whether one can build a more accurate classifier by using unlabeled data (semi-supervised learning) is an important issue. Although a number of semi-supervised methods have been proposed, their effectiveness on NLP tasks is not always clear. This paper presents a novel semi-supervised method that employs a learning paradigm which we call structural learning. The idea is to find \"what good classifiers are like\" by learning from thousands of automatically generated auxiliary classification problems on unlabeled data. By doing so, the common predictive structure shared by the multiple classification problems can be discovered, which can then be used to improve performance on the target problem. The method produces performance higher than the previous best results on CoNLL'00 syntactic chunking and CoNLL'03 named entity chunking (English and German)."
            },
            "slug": "A-High-Performance-Semi-Supervised-Learning-Method-Ando-Zhang",
            "title": {
                "fragments": [],
                "text": "A High-Performance Semi-Supervised Learning Method for Text Chunking"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A novel semi-supervised method that employs a learning paradigm which is to find \"what good classifiers are like\" by learning from thousands of automatically generated auxiliary classification problems on unlabeled data, which produces performance higher than the previous best results."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694121"
                        ],
                        "name": "Xingquan Zhu",
                        "slug": "Xingquan-Zhu",
                        "structuredName": {
                            "firstName": "Xingquan",
                            "lastName": "Zhu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xingquan Zhu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1748808"
                        ],
                        "name": "Xindong Wu",
                        "slug": "Xindong-Wu",
                        "structuredName": {
                            "firstName": "Xindong",
                            "lastName": "Wu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xindong Wu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9135114,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1c42f6b196f38673b7c679cea509135789dfbbc8",
            "isKey": false,
            "numCitedBy": 40,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "Recent research in machine learning, data mining, and related areas has produced a wide variety of algorithms for cost-sensitive (CS) classification, where instead of maximizing the classification accuracy, minimizing the misclassification cost becomes the objective. These methods often assume that their input is quality data without conflict or erroneous values, or the noise impact is trivial, which is seldom the case in real-world environments. In this paper, we propose a cost-guided iterative classification filter (CICF) to identify noise for effective CS learning. Instead of putting equal weights on handling noise in all classes in existing efforts, CICF puts more emphasis on expensive classes, which makes it attractive in dealing with data sets with a large cost-ratio. Experimental results and comparative studies indicate that the existence of noise may seriously corrupt the performance of the underlying CS learners and by adopting the proposed CICF algorithm, we can significantly reduce the misclassification cost of a CS classifier in noisy environments"
            },
            "slug": "Class-Noise-Handling-for-Effective-Cost-Sensitive-Zhu-Wu",
            "title": {
                "fragments": [],
                "text": "Class Noise Handling for Effective Cost-Sensitive Learning by Cost-Guided Iterative Classification Filtering"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "Experimental results and comparative studies indicate that the existence of noise may seriously corrupt the performance of the underlying CS learners and by adopting the proposed CICF algorithm, the misclassification cost of a CS classifier in noisy environments is significantly reduced."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Knowledge and Data Engineering"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2979876"
                        ],
                        "name": "R. Raina",
                        "slug": "R.-Raina",
                        "structuredName": {
                            "firstName": "Rajat",
                            "lastName": "Raina",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Raina"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34699434"
                        ],
                        "name": "A. Ng",
                        "slug": "A.-Ng",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Ng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Ng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1736370"
                        ],
                        "name": "D. Koller",
                        "slug": "D.-Koller",
                        "structuredName": {
                            "firstName": "Daphne",
                            "lastName": "Koller",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Koller"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 28,
                                "start": 24
                            }
                        ],
                        "text": "Self-taught clustering is an instance of unsupervised transfer learning, which aims at clustering a small collection of unlabeled data in the target domain with the help of a large amount of unlabeled data in the source domain."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 3056583,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "328f88380422573a4ff9ada1fc5aa9f198a32bc5",
            "isKey": false,
            "numCitedBy": 315,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "Many applications of supervised learning require good generalization from limited labeled data. In the Bayesian setting, we can try to achieve this goal by using an informative prior over the parameters, one that encodes useful domain knowledge. Focusing on logistic regression, we present an algorithm for automatically constructing a multivariate Gaussian prior with a full covariance matrix for a given supervised learning task. This prior relaxes a commonly used but overly simplistic independence assumption, and allows parameters to be dependent. The algorithm uses other \"similar\" learning problems to estimate the covariance of pairs of individual parameters. We then use a semidefinite program to combine these estimates and learn a good prior for the current learning task. We apply our methods to binary text classification, and demonstrate a 20 to 40% test error reduction over a commonly used prior."
            },
            "slug": "Constructing-informative-priors-using-transfer-Raina-Ng",
            "title": {
                "fragments": [],
                "text": "Constructing informative priors using transfer learning"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "An algorithm for automatically constructing a multivariate Gaussian prior with a full covariance matrix for a given supervised learning task, which relaxes a commonly used but overly simplistic independence assumption, and allows parameters to be dependent."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144774720"
                        ],
                        "name": "M. H. Mahmud",
                        "slug": "M.-H.-Mahmud",
                        "structuredName": {
                            "firstName": "M.",
                            "lastName": "Mahmud",
                            "middleNames": [
                                "M.",
                                "Hassan"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. H. Mahmud"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1874339"
                        ],
                        "name": "S. Ray",
                        "slug": "S.-Ray",
                        "structuredName": {
                            "firstName": "Sylvian",
                            "lastName": "Ray",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Ray"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 40,
                                "start": 36
                            }
                        ],
                        "text": "Given a source domainDS with a learning task T S , a target domainDT and a corresponding learning task T T , unsupervised transfer learning aims to help improve the learning of the target predictive function fT \u00f0 \u00de7 inDT using the knowledge inDS and T S , where T S 6\u00bc T T and YS and YT are not\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 717220,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3f63cdc711a4f42a65d3b2b3cbe9e2b919a995f5",
            "isKey": false,
            "numCitedBy": 59,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "In transfer learning we aim to solve new problems using fewer examples using information gained from solving related problems. Transfer learning has been successful in practice, and extensive PAC analysis of these methods has been developed. However it is not yet clear how to define relatedness between tasks. This is considered as a major problem as it is conceptually troubling and it makes it unclear how much information to transfer and when and how to transfer it. In this paper we propose to measure the amount of information one task contains about another using conditional Kolmogorov complexity between the tasks. We show how existing theory neatly solves the problem of measuring relatedness and transferring the 'right' amount of information in sequential transfer learning in a Bayesian setting. The theory also suggests that, in a very formal and precise sense, no other reasonable transfer method can do much better than our Kolmogorov Complexity theoretic transfer method, and that sequential transfer is always justified. We also develop a practical approximation to the method and use it to transfer information between 8 arbitrarily chosen databases from the UCI ML repository."
            },
            "slug": "Transfer-Learning-using-Kolmogorov-Complexity:-and-Mahmud-Ray",
            "title": {
                "fragments": [],
                "text": "Transfer Learning using Kolmogorov Complexity: Basic Theory and Empirical Evaluations"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "This paper shows how existing theory neatly solves the problem of measuring relatedness and transferring the 'right' amount of information in sequential transfer learning in a Bayesian setting, and suggests that no other reasonable transfer method can do much better than the Kolmogorov Complexity theoretic transfer method."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50033175"
                        ],
                        "name": "Andreas Argyriou",
                        "slug": "Andreas-Argyriou",
                        "structuredName": {
                            "firstName": "Andreas",
                            "lastName": "Argyriou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andreas Argyriou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144009046"
                        ],
                        "name": "Andreas Maurer",
                        "slug": "Andreas-Maurer",
                        "structuredName": {
                            "firstName": "Andreas",
                            "lastName": "Maurer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andreas Maurer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1704699"
                        ],
                        "name": "M. Pontil",
                        "slug": "M.-Pontil",
                        "structuredName": {
                            "firstName": "Massimiliano",
                            "lastName": "Pontil",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Pontil"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Recently, Self-taught clustering (STC) [26] and transferred discriminative analysis (TDA) [27] algorithms are proposed to transfer clustering and transfer dimensionality reduction problems, respectively."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15177899,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "63c2261af261ea8a98920f796675916e70b538c1",
            "isKey": false,
            "numCitedBy": 83,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "We consider the problem of learning in an environment of classification tasks. Tasks sampled from the environment are used to improve classification performance on future tasks. We consider situations in which the tasks can be divided into groups. Tasks within each group are related by sharing a low dimensional representation, which differs across the groups. We present an algorithm which divides the sampled tasks into groups and computes a common representation for each group. We report experiments on a synthetic and two image data sets, which show the advantage of the approach over single-task learning and a previous transfer learning method."
            },
            "slug": "An-Algorithm-for-Transfer-Learning-in-a-Environment-Argyriou-Maurer",
            "title": {
                "fragments": [],
                "text": "An Algorithm for Transfer Learning in a Heterogeneous Environment"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "An algorithm is presented which divides the sampled tasks into groups and computes a common representation for each group, which shows the advantage of the approach over single-task learning and a previous transfer learning method."
            },
            "venue": {
                "fragments": [],
                "text": "ECML/PKDD"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152290618"
                        ],
                        "name": "Qiang Yang",
                        "slug": "Qiang-Yang",
                        "structuredName": {
                            "firstName": "Qiang",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Qiang Yang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688204"
                        ],
                        "name": "C. Ling",
                        "slug": "C.-Ling",
                        "structuredName": {
                            "firstName": "Charles",
                            "lastName": "Ling",
                            "middleNames": [
                                "X."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Ling"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2059102"
                        ],
                        "name": "Xiaoyong Chai",
                        "slug": "Xiaoyong-Chai",
                        "structuredName": {
                            "firstName": "Xiaoyong",
                            "lastName": "Chai",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xiaoyong Chai"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2066007146"
                        ],
                        "name": "Rong Pan",
                        "slug": "Rong-Pan",
                        "structuredName": {
                            "firstName": "Rong",
                            "lastName": "Pan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Rong Pan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 59,
                                "start": 55
                            }
                        ],
                        "text": "It would be nice to reduce the need and effort to recollect the training data."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 10970994,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e30848e55536c604a842d72ac379bdc01233d2c3",
            "isKey": false,
            "numCitedBy": 64,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "In the area of cost-sensitive learning, inductive learning algorithms have been extended to handle different types of costs to better represent misclassification errors. Most of the previous works have only focused on how to deal with misclassification costs. In this paper, we address the equally important issue of how to handle the test costs associated with querying the missing values in a test case. When an attribute contains a missing value in a test case, it may or may not be worthwhile to take the extra effort in order to obtain a value for that attribute, or attributes, depending on how much benefit the new value bring about in increasing the accuracy. In this paper, we consider how to integrate test-cost-sensitive learning with the handling of missing values in a unified framework that includes model building and a testing strategy. The testing strategies determine which attributes to perform the test on in order to minimize the sum of the classification costs and test costs. We show how to instantiate this framework in two popular machine learning algorithms: decision trees and naive Bayesian method. We empirically evaluate the test-cost-sensitive methods for handling missing values on several data sets."
            },
            "slug": "Test-cost-sensitive-classification-on-data-with-Yang-Ling",
            "title": {
                "fragments": [],
                "text": "Test-cost sensitive classification on data with missing values"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This paper considers how to integrate test-cost-sensitive learning with the handling of missing values in a unified framework that includes model building and a testing strategy, and shows how to instantiate this framework in two popular machine learning algorithms: decision trees and naive Bayesian method."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Knowledge and Data Engineering"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1735228"
                        ],
                        "name": "B. Zadrozny",
                        "slug": "B.-Zadrozny",
                        "structuredName": {
                            "firstName": "Bianca",
                            "lastName": "Zadrozny",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Zadrozny"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 86,
                                "start": 82
                            }
                        ],
                        "text": "In the inductive transfer learning setting, the target task is different from the source task, no matter when the source and target domains are the same or not."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 48,
                                "start": 44
                            }
                        ],
                        "text": "Zadrozny [24] proposed to estimate the terms P \u00f0xSi\u00de and P \u00f0xTi\u00de independently by constructing simple classification problems."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 98,
                                "start": 94
                            }
                        ],
                        "text": "In some situations, when the source domain and target domain are not related to each other, brute-force transfer may be unsuccessful."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1314568,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6d5965a76f88a8ebab4fc9c43a3ae2630628966a",
            "isKey": false,
            "numCitedBy": 752,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "Classifier learning methods commonly assume that the training data consist of randomly drawn examples from the same distribution as the test examples about which the learned model is expected to make predictions. In many practical situations, however, this assumption is violated, in a problem known in econometrics as sample selection bias. In this paper, we formalize the sample selection bias problem in machine learning terms and study analytically and experimentally how a number of well-known classifier learning methods are affected by it. We also present a bias correction method that is particularly useful for classifier evaluation under sample selection bias."
            },
            "slug": "Learning-and-evaluating-classifiers-under-sample-Zadrozny",
            "title": {
                "fragments": [],
                "text": "Learning and evaluating classifiers under sample selection bias"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This paper formalizes the sample selection bias problem in machine learning terms and study analytically and experimentally how a number of well-known classifier learning methods are affected by it."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144815446"
                        ],
                        "name": "Jesse Davis",
                        "slug": "Jesse-Davis",
                        "structuredName": {
                            "firstName": "Jesse",
                            "lastName": "Davis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jesse Davis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1740213"
                        ],
                        "name": "Pedro M. Domingos",
                        "slug": "Pedro-M.-Domingos",
                        "structuredName": {
                            "firstName": "Pedro",
                            "lastName": "Domingos",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Pedro M. Domingos"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 97,
                                "start": 93
                            }
                        ],
                        "text": "TAMAR to the single-entity-centered setting of transfer learning, where only one entity in a target domain is available."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 10,
                                "start": 6
                            }
                        ],
                        "text": "In addition, according to different situations between the source and target domains, we can further categorize the transductive transfer learning setting into two cases.\na."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 317248,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "11d10dbe0802afa19525aaa137d56f2832e38d1e",
            "isKey": false,
            "numCitedBy": 217,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "Standard inductive learning requires that training and test instances come from the same distribution. Transfer learning seeks to remove this restriction. In shallow transfer, test instances are from the same domain, but have a different distribution. In deep transfer, test instances are from a different domain entirely (i.e., described by different predicates). Humans routinely perform deep transfer, but few learning systems, if any, are capable of it. In this paper we propose an approach based on a form of second-order Markov logic. Our algorithm discovers structural regularities in the source domain in the form of Markov logic formulas with predicate variables, and instantiates these formulas with predicates from the target domain. Using this approach, we have successfully transferred learned knowledge among molecular biology, social network and Web domains. The discovered patterns include broadly useful properties of predicates, like symmetry and transitivity, and relations among predicates, such as various forms of homophily."
            },
            "slug": "Deep-transfer-via-second-order-Markov-logic-Davis-Domingos",
            "title": {
                "fragments": [],
                "text": "Deep transfer via second-order Markov logic"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The algorithm discovers structural regularities in the source domain in the form of Markov logic formulas with predicate variables, and instantiates these formulas with predicates from the target domain, and has successfully transferred learned knowledge among molecular biology, social network and Web domains."
            },
            "venue": {
                "fragments": [],
                "text": "ICML '09"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145172877"
                        ],
                        "name": "K. Nigam",
                        "slug": "K.-Nigam",
                        "structuredName": {
                            "firstName": "Kamal",
                            "lastName": "Nigam",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Nigam"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143753639"
                        ],
                        "name": "A. McCallum",
                        "slug": "A.-McCallum",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "McCallum",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. McCallum"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144867807"
                        ],
                        "name": "S. Thrun",
                        "slug": "S.-Thrun",
                        "structuredName": {
                            "firstName": "Sebastian",
                            "lastName": "Thrun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Thrun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40975594"
                        ],
                        "name": "Tom Michael Mitchell",
                        "slug": "Tom-Michael-Mitchell",
                        "structuredName": {
                            "firstName": "Tom",
                            "lastName": "Mitchell",
                            "middleNames": [
                                "Michael"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tom Michael Mitchell"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 57,
                                "start": 53
                            }
                        ],
                        "text": "However, many machine learning methods work well only under a common assumption: the training and test data are drawn from the same feature space and the same distribution."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 686980,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e2de29049d62de925cf709024b92774cd82b0a5a",
            "isKey": false,
            "numCitedBy": 3072,
            "numCiting": 79,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper shows that the accuracy of learned text classifiers can be improved by augmenting a small number of labeled training documents with a large pool of unlabeled documents. This is important because in many text classification problems obtaining training labels is expensive, while large quantities of unlabeled documents are readily available.We introduce an algorithm for learning from labeled and unlabeled documents based on the combination of Expectation-Maximization (EM) and a naive Bayes classifier. The algorithm first trains a classifier using the available labeled documents, and probabilistically labels the unlabeled documents. It then trains a new classifier using the labels for all the documents, and iterates to convergence. This basic EM procedure works well when the data conform to the generative assumptions of the model. However these assumptions are often violated in practice, and poor performance can result. We present two extensions to the algorithm that improve classification accuracy under these conditions: (1) a weighting factor to modulate the contribution of the unlabeled data, and (2) the use of multiple mixture components per class. Experimental results, obtained using text from three different real-world tasks, show that the use of unlabeled data reduces classification error by up to 30%."
            },
            "slug": "Text-Classification-from-Labeled-and-Unlabeled-EM-Nigam-McCallum",
            "title": {
                "fragments": [],
                "text": "Text Classification from Labeled and Unlabeled Documents using EM"
            },
            "tldr": {
                "abstractSimilarityScore": 78,
                "text": "This paper shows that the accuracy of learned text classifiers can be improved by augmenting a small number of labeled training documents with a large pool of unlabeled documents, and presents two extensions to the algorithm that improve classification accuracy under these conditions."
            },
            "venue": {
                "fragments": [],
                "text": "Machine Learning"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2116927"
                        ],
                        "name": "John Blitzer",
                        "slug": "John-Blitzer",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Blitzer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "John Blitzer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143957226"
                        ],
                        "name": "Ryan T. McDonald",
                        "slug": "Ryan-T.-McDonald",
                        "structuredName": {
                            "firstName": "Ryan",
                            "lastName": "McDonald",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ryan T. McDonald"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145366908"
                        ],
                        "name": "Fernando C Pereira",
                        "slug": "Fernando-C-Pereira",
                        "structuredName": {
                            "firstName": "Fernando",
                            "lastName": "Pereira",
                            "middleNames": [
                                "C"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Fernando C Pereira"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15978939,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9fa8d73e572c3ca824a04a5f551b602a17831bc5",
            "isKey": false,
            "numCitedBy": 1518,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "Discriminative learning methods are widely used in natural language processing. These methods work best when their training and test data are drawn from the same distribution. For many NLP tasks, however, we are confronted with new domains in which labeled data is scarce or non-existent. In such cases, we seek to adapt existing models from a resource-rich source domain to a resource-poor target domain. We introduce structural correspondence learning to automatically induce correspondences among features from different domains. We test our technique on part of speech tagging and show performance gains for varying amounts of source and target training data, as well as improvements in target domain parsing accuracy using our improved tagger."
            },
            "slug": "Domain-Adaptation-with-Structural-Correspondence-Blitzer-McDonald",
            "title": {
                "fragments": [],
                "text": "Domain Adaptation with Structural Correspondence Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This work introduces structural correspondence learning to automatically induce correspondences among features from different domains in order to adapt existing models from a resource-rich source domain to aresource-poor target domain."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2153814"
                        ],
                        "name": "Lilyana Mihalkova",
                        "slug": "Lilyana-Mihalkova",
                        "structuredName": {
                            "firstName": "Lilyana",
                            "lastName": "Mihalkova",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lilyana Mihalkova"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1770643"
                        ],
                        "name": "Tuyen N. Huynh",
                        "slug": "Tuyen-N.-Huynh",
                        "structuredName": {
                            "firstName": "Tuyen",
                            "lastName": "Huynh",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tuyen N. Huynh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1797655"
                        ],
                        "name": "R. Mooney",
                        "slug": "R.-Mooney",
                        "structuredName": {
                            "firstName": "Raymond",
                            "lastName": "Mooney",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Mooney"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 15,
                                "start": 11
                            }
                        ],
                        "text": "Thus, it\u2019s similar to the inductive transfer learning setting where the labeled data in the source domain are unavailable."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 21,
                                "start": 17
                            }
                        ],
                        "text": "Mihalkova et al. [50] proposed an algorithm TAMAR that transfers relational knowledge with Markov Logic Networks (MLNs) across relational domains."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 11943552,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0fbf373d25f2710e2e4eaf64e00e071f734ad84f",
            "isKey": false,
            "numCitedBy": 299,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "Transfer learning addresses the problem of how to leverage knowledge acquired in a source domain to improve the accuracy and speed of learning in a related target domain. This paper considers transfer learning with Markov logic networks (MLNs), a powerful formalism for learning in relational domains. We present a complete MLN transfer system that first autonomously maps the predicates in the source MLN to the target domain and then revises the mapped structure to further improve its accuracy. Our results in several real-world domains demonstrate that our approach successfully reduces the amount of time and training data needed to learn an accurate model of a target domain over learning from scratch."
            },
            "slug": "Mapping-and-Revising-Markov-Logic-Networks-for-Mihalkova-Huynh",
            "title": {
                "fragments": [],
                "text": "Mapping and Revising Markov Logic Networks for Transfer Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "This paper considers transfer learning with Markov logic networks (MLNs), a powerful formalism for learning in relational domains and presents a complete MLN transfer system that first autonomously maps the predicates in the source MLN to the target domain and then revises the mapped structure to further improve its accuracy."
            },
            "venue": {
                "fragments": [],
                "text": "AAAI"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50033175"
                        ],
                        "name": "Andreas Argyriou",
                        "slug": "Andreas-Argyriou",
                        "structuredName": {
                            "firstName": "Andreas",
                            "lastName": "Argyriou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andreas Argyriou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1708279"
                        ],
                        "name": "C. Micchelli",
                        "slug": "C.-Micchelli",
                        "structuredName": {
                            "firstName": "Charles",
                            "lastName": "Micchelli",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Micchelli"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1704699"
                        ],
                        "name": "M. Pontil",
                        "slug": "M.-Pontil",
                        "structuredName": {
                            "firstName": "Massimiliano",
                            "lastName": "Pontil",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Pontil"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144359603"
                        ],
                        "name": "Yiming Ying",
                        "slug": "Yiming-Ying",
                        "structuredName": {
                            "firstName": "Yiming",
                            "lastName": "Ying",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yiming Ying"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "If no labeled data in the source domain are available, unsupervised learning methods are proposed to construct the feature representation."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 147,
                                "start": 143
                            }
                        ],
                        "text": "In addition, according to different situations of labeled and unlabeled data in the source domain, we can further categorize the inductive transfer learning setting into two cases:\na."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1813055,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "637bbf3dd3adc74272a8069ce2fcee812acf1432",
            "isKey": false,
            "numCitedBy": 243,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "Learning the common structure shared by a set of supervised tasks is an important practical and theoretical problem. Knowledge of this structure may lead to better generalization performance on the tasks and may also facilitate learning new tasks. We propose a framework for solving this problem, which is based on regularization with spectral functions of matrices. This class of regularization problems exhibits appealing computational properties and can be optimized efficiently by an alternating minimization algorithm. In addition, we provide a necessary and sufficient condition for convexity of the regularizer. We analyze concrete examples of the framework, which are equivalent to regularization with Lp matrix norms. Experiments on two real data sets indicate that the algorithm scales well with the number of tasks and improves on state of the art statistical performance."
            },
            "slug": "A-Spectral-Regularization-Framework-for-Multi-Task-Argyriou-Micchelli",
            "title": {
                "fragments": [],
                "text": "A Spectral Regularization Framework for Multi-Task Structure Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "A framework for solving this problem, which is based on regularization with spectral functions of matrices, and indicates that the algorithm scales well with the number of tasks and improves on state of the art statistical performance."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144324925"
                        ],
                        "name": "Zheng Wang",
                        "slug": "Zheng-Wang",
                        "structuredName": {
                            "firstName": "Zheng",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zheng Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1809614"
                        ],
                        "name": "Yangqiu Song",
                        "slug": "Yangqiu-Song",
                        "structuredName": {
                            "firstName": "Yangqiu",
                            "lastName": "Song",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yangqiu Song"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "14966740"
                        ],
                        "name": "Changshui Zhang",
                        "slug": "Changshui-Zhang",
                        "structuredName": {
                            "firstName": "Changshui",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Changshui Zhang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 139,
                                "start": 135
                            }
                        ],
                        "text": "In their follow-up work, the researchers proposed to use Mutual Information (MI) to choose the pivot features instead of using more heuristic criteria [8]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 61,
                                "start": 57
                            }
                        ],
                        "text": "However, how to avoid negative transfer is an important open issue that is attracting more and more attention in the future."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 25,
                                "start": 21
                            }
                        ],
                        "text": "The m classification problems can be constructed."
                    },
                    "intents": []
                }
            ],
            "corpusId": 6388997,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ffc5a9610df0341369aa75c0331ef021de0a02a9",
            "isKey": false,
            "numCitedBy": 112,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "Dimensionality reduction is one of the widely used techniques for data analysis. However, it is often hard to get a demanded low-dimensional representation with only the unlabeled data, especially for the discriminative task. In this paper, we put forward a novel problem of Transferred Dimensionality Reduction, which is to do unsupervised discriminative dimensionality reduction with the help of related prior knowledge from other classes in the same type of concept. We propose an algorithm named Transferred Discriminative Analysis to tackle this problem. It uses clustering to generate class labels for the target unlabeled data, and use dimensionality reduction for them joint with prior labeled data to do subspace selection. This two steps run adaptively to find a better discriminative subspace, and get better clustering results simultaneously. The experimental results on both constrained and unconstrained face recognition demonstrate significant improvements of our algorithm over the state-of-the-art methods."
            },
            "slug": "Transferred-Dimensionality-Reduction-Wang-Song",
            "title": {
                "fragments": [],
                "text": "Transferred Dimensionality Reduction"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This paper proposes an algorithm named Transferred Discriminative Analysis, which uses clustering to generate class labels for the target unlabeled data, and use dimensionality reduction for them joint with prior labeled data to do subspace selection."
            },
            "venue": {
                "fragments": [],
                "text": "ECML/PKDD"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1750105"
                        ],
                        "name": "E. Baralis",
                        "slug": "E.-Baralis",
                        "structuredName": {
                            "firstName": "Elena",
                            "lastName": "Baralis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Baralis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694792"
                        ],
                        "name": "S. Chiusano",
                        "slug": "S.-Chiusano",
                        "structuredName": {
                            "firstName": "Silvia",
                            "lastName": "Chiusano",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Chiusano"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712027"
                        ],
                        "name": "P. Garza",
                        "slug": "P.-Garza",
                        "structuredName": {
                            "firstName": "Paolo",
                            "lastName": "Garza",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Garza"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 15,
                                "start": 11
                            }
                        ],
                        "text": "However, many machine learning methods work well only under a common assumption: the training and test data are drawn from the same feature space and the same distribution."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14829459,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a41a922b3a241537047222181d32d903b74c6d41",
            "isKey": false,
            "numCitedBy": 115,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "Associative classification is a promising technique to build accurate classifiers. However, in large or correlated data sets, association rule mining may yield huge rule sets. Hence, several pruning techniques have been proposed to select a small subset of high-quality rules. Since the availability of a \"rich\" rule set may improve the accuracy of the classifier, we argue that rule pruning should be reduced to a minimum. The L3 associative classifier is built by means of a lazy pruning technique that discards exclusively rules that only misclassify training data. The classification of unlabeled data is performed in two steps. A small subset of high-quality rules is first considered. When this set is not able to classify the data, a larger rule set is exploited. This second set includes rules usually discarded by previous approaches. To cope with the need of mining large rule sets and to efficiently use them for classification, a compact form is proposed to represent a complete rule set in a space-efficient way and without information loss. An extensive experimental evaluation on real and synthetic data sets shows that L:i improves the classification accuracy with respect to previous approaches."
            },
            "slug": "A-Lazy-Approach-to-Associative-Classification-Baralis-Chiusano",
            "title": {
                "fragments": [],
                "text": "A Lazy Approach to Associative Classification"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "An extensive experimental evaluation on real and synthetic data sets shows that L:i improves the classification accuracy with respect to previous approaches, and it is argued that rule pruning should be reduced to a minimum."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Knowledge and Data Engineering"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2437915"
                        ],
                        "name": "Kanoksri Sarinnapakorn",
                        "slug": "Kanoksri-Sarinnapakorn",
                        "structuredName": {
                            "firstName": "Kanoksri",
                            "lastName": "Sarinnapakorn",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kanoksri Sarinnapakorn"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1713687"
                        ],
                        "name": "M. Kub\u00e1t",
                        "slug": "M.-Kub\u00e1t",
                        "structuredName": {
                            "firstName": "Miroslav",
                            "lastName": "Kub\u00e1t",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Kub\u00e1t"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 166,
                                "start": 163
                            }
                        ],
                        "text": "In this survey, we discuss the relationship between transfer learning and other related machine learning techniques such as domain adaptation, multitask learning and sample selection bias, as well as covariate shift."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1830833,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4c0f6819e683f7eba20bd4a16e025b2c5bfbf1d0",
            "isKey": false,
            "numCitedBy": 72,
            "numCiting": 52,
            "paperAbstract": {
                "fragments": [],
                "text": "Text categorization systems often use machine learning techniques to induce document classifiers from preclassified examples. The fact that each example document belongs to many classes often leads to very high computational costs that sometimes grow exponentially in the number of features. Seeking to reduce these costs, we explored the possibility of running a \"baseline induction algorithm\" separately for subsets of features, obtaining a set of classifiers to be combined. For the specific case of classifiers that return not only class labels but also confidences in these labels, we investigate here a few alternative fusion techniques, including our own mechanism that was inspired by the Dempster-Shafer Theory. The paper describes the algorithm and, in our specific case study, compares its performance to that of more traditional mechanisms."
            },
            "slug": "Combining-Subclassifiers-in-Text-Categorization:-A-Sarinnapakorn-Kub\u00e1t",
            "title": {
                "fragments": [],
                "text": "Combining Subclassifiers in Text Categorization: A DST-Based Solution and a Case Study"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This paper explores the possibility of running a \"baseline induction algorithm\" separately for subsets of features, obtaining a set of classifiers to be combined, and investigates a few alternative fusion techniques, including its own mechanism that was inspired by the Dempster-Shafer Theory."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Knowledge and Data Engineering"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145306271"
                        ],
                        "name": "Neil D. Lawrence",
                        "slug": "Neil-D.-Lawrence",
                        "structuredName": {
                            "firstName": "Neil",
                            "lastName": "Lawrence",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Neil D. Lawrence"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144189092"
                        ],
                        "name": "John C. Platt",
                        "slug": "John-C.-Platt",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Platt",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "John C. Platt"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 13,
                                "start": 9
                            }
                        ],
                        "text": "approach [45], [46], [47], [48], [49], which assumes that the"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 23,
                                "start": 19
                            }
                        ],
                        "text": "Lawrence and Platt [45] proposed an efficient algorithm known as MT-IVM, which is based on Gaussian Processes (GP), to handle the multitask learning case."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 15764546,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "73e1c4a1152a75ec7310adfb4b8daea16d627bc7",
            "isKey": false,
            "numCitedBy": 342,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes an efficient method for learning the parameters of a Gaussian process (GP). The parameters are learned from multiple tasks which are assumed to have been drawn independently from the same GP prior. An efficient algorithm is obtained by extending the informative vector machine (IVM) algorithm to handle the multi-task learning case. The multi-task IVM (MTIVM) saves computation by greedily selecting the most informative examples from the separate tasks. The MT-IVM is also shown to be more efficient than random sub-sampling on an artificial data-set and more effective than the traditional IVM in a speaker dependent phoneme recognition task."
            },
            "slug": "Learning-to-learn-with-the-informative-vector-Lawrence-Platt",
            "title": {
                "fragments": [],
                "text": "Learning to learn with the informative vector machine"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The multi-task IVM (MTIVM) saves computation by greedily selecting the most informative examples from the separate tasks and is shown to be more efficient than random sub-sampling on an artificial data-set and more effective than the traditional IVM in a speaker dependent phoneme recognition task."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1398560253"
                        ],
                        "name": "H. Al-Mubaid",
                        "slug": "H.-Al-Mubaid",
                        "structuredName": {
                            "firstName": "Hisham",
                            "lastName": "Al-Mubaid",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Al-Mubaid"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1407773521"
                        ],
                        "name": "Syed A. Umair",
                        "slug": "Syed-A.-Umair",
                        "structuredName": {
                            "firstName": "Syed",
                            "lastName": "Umair",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Syed A. Umair"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "example is Web-document classification [3], [4], [5], where"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15144406,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "95ceceec15a34948ba53ff8e8c806982aafa115c",
            "isKey": false,
            "numCitedBy": 127,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "Text categorization is continuing to be one of the most researched NLP problems due to the ever-increasing amounts of electronic documents and digital libraries. In this paper, we present a new text categorization method that combines the distributional clustering of words and a learning logic technique, called Lsquare, for constructing text classifiers. The high dimensionality of text in a document has not been fruitful for the task of categorization, for which reason, feature clustering has been proven to be an ideal alternative to feature selection for reducing the dimensionality. We, therefore, use distributional clustering method (IB) to generate an efficient representation of documents and apply Lsquare for training text classifiers. The method was extensively tested and evaluated. The proposed method achieves higher or comparable classification accuracy and F1 results compared with SVM on exact experimental settings with a small number of training documents on three benchmark data sets WebKB, 20Newsgroup, and Reuters-21578. The results prove that the method is a good choice for applications with a limited amount of labeled training data. We also demonstrate the effect of changing training size on the classification performance of the learners"
            },
            "slug": "A-New-Text-Categorization-Technique-Using-and-Logic-Al-Mubaid-Umair",
            "title": {
                "fragments": [],
                "text": "A New Text Categorization Technique Using Distributional Clustering and Learning Logic"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "A new text categorization method is presented that combines the distributional clustering of words and a learning logic technique, called Lsquare, for constructing text classifiers, that achieves higher or comparable classification accuracy and F1 results compared with SVM on exact experimental settings with a small number of training documents."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Knowledge and Data Engineering"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2704747"
                        ],
                        "name": "S. Bickel",
                        "slug": "S.-Bickel",
                        "structuredName": {
                            "firstName": "Steffen",
                            "lastName": "Bickel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Bickel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2057847091"
                        ],
                        "name": "Michael Br\u00fcckner",
                        "slug": "Michael-Br\u00fcckner",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Br\u00fcckner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael Br\u00fcckner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751348"
                        ],
                        "name": "T. Scheffer",
                        "slug": "T.-Scheffer",
                        "structuredName": {
                            "firstName": "Tobias",
                            "lastName": "Scheffer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Scheffer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 98,
                                "start": 94
                            }
                        ],
                        "text": "In the inductive transfer learning setting, the target task is different from the source task, no matter when the source and target domains are the same or not."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 115,
                                "start": 111
                            }
                        ],
                        "text": "Bickel et al. [33] combined the two steps in a unified\nframework by deriving a kernel-logistic regression classifier."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15781767,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ebd6a4442cff5d20d1f8f4ac435e9b809592ad07",
            "isKey": false,
            "numCitedBy": 392,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "We address classification problems for which the training instances are governed by a distribution that is allowed to differ arbitrarily from the test distribution---problems also referred to as classification under covariate shift. We derive a solution that is purely discriminative: neither training nor test distribution are modeled explicitly. We formulate the general problem of learning under covariate shift as an integrated optimization problem. We derive a kernel logistic regression classifier for differing training and test distributions."
            },
            "slug": "Discriminative-learning-for-differing-training-and-Bickel-Br\u00fcckner",
            "title": {
                "fragments": [],
                "text": "Discriminative learning for differing training and test distributions"
            },
            "tldr": {
                "abstractSimilarityScore": 76,
                "text": "This work addresses classification problems for which the training instances are governed by a distribution that is allowed to differ arbitrarily from the test distribution, and derives a kernel logistic regression classifier for differing training and test distributions."
            },
            "venue": {
                "fragments": [],
                "text": "ICML '07"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39286677"
                        ],
                        "name": "Matthew E. Taylor",
                        "slug": "Matthew-E.-Taylor",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Taylor",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Matthew E. Taylor"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144848112"
                        ],
                        "name": "P. Stone",
                        "slug": "P.-Stone",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Stone",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Stone"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "\u00c7"
                    },
                    "intents": []
                }
            ],
            "corpusId": 6447995,
            "fieldsOfStudy": [
                "Computer Science",
                "Psychology"
            ],
            "id": "9db77cb43da46de6b0c5350348d74c949112e1e1",
            "isKey": false,
            "numCitedBy": 195,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "A typical goal for transfer learning algorithms is to utilize knowledge gained in a source task to learn a target task faster. Recently introduced transfer methods in reinforcement learning settings have shown considerable promise, but they typically transfer between pairs of very similar tasks. This work introduces Rule Transfer, a transfer algorithm that first learns rules to summarize a source task policy and then leverages those rules to learn faster in a target task. This paper demonstrates that Rule Transfer can effectively speed up learning in Keepaway, a benchmark RL problem in the robot soccer domain, based on experience from source tasks in the gridworld domain. We empirically show, through the use of three distinct transfer metrics, that Rule Transfer is effective across these domains."
            },
            "slug": "Cross-domain-transfer-for-reinforcement-learning-Taylor-Stone",
            "title": {
                "fragments": [],
                "text": "Cross-domain transfer for reinforcement learning"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "It is demonstrated that Rule Transfer can effectively speed up learning in Keepaway, a benchmark RL problem in the robot soccer domain, based on experience from source tasks in the gridworld domain through the use of three distinct transfer metrics."
            },
            "venue": {
                "fragments": [],
                "text": "ICML '07"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "67154907"
                        ],
                        "name": "Masashi Sugiyama",
                        "slug": "Masashi-Sugiyama",
                        "structuredName": {
                            "firstName": "Masashi",
                            "lastName": "Sugiyama",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Masashi Sugiyama"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3187484"
                        ],
                        "name": "Shinichi Nakajima",
                        "slug": "Shinichi-Nakajima",
                        "structuredName": {
                            "firstName": "Shinichi",
                            "lastName": "Nakajima",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shinichi Nakajima"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2785830"
                        ],
                        "name": "H. Kashima",
                        "slug": "H.-Kashima",
                        "structuredName": {
                            "firstName": "Hisashi",
                            "lastName": "Kashima",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Kashima"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7581975"
                        ],
                        "name": "P. V. B\u00fcnau",
                        "slug": "P.-V.-B\u00fcnau",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "B\u00fcnau",
                            "middleNames": [
                                "von"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. V. B\u00fcnau"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716788"
                        ],
                        "name": "M. Kawanabe",
                        "slug": "M.-Kawanabe",
                        "structuredName": {
                            "firstName": "Motoaki",
                            "lastName": "Kawanabe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Kawanabe"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 114,
                                "start": 110
                            }
                        ],
                        "text": "Sugiyama et al. [34] proposed an algorithm\nknown as Kullback-Leibler Importance Estimation Procedure (KLIEP) to estimate P \u00f0xSi \u00de P \u00f0xTi \u00de directly, based on the minimization of the Kullback-Leibler divergence. can be\nintegrated with cross-validation to perform model selection\nautomatically in two\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 104,
                                "start": 100
                            }
                        ],
                        "text": "In the inductive transfer learning setting, the target task is different from the source task, no matter when the source and target domains are the same or not."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 9133542,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1fc971fc394fd7a00922b082973568850e77a163",
            "isKey": false,
            "numCitedBy": 709,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "A situation where training and test samples follow different input distributions is called covariate shift. Under covariate shift, standard learning methods such as maximum likelihood estimation are no longer consistent\u2014weighted variants according to the ratio of test and training input densities are consistent. Therefore, accurately estimating the density ratio, called the importance, is one of the key issues in covariate shift adaptation. A naive approach to this task is to first estimate training and test input densities separately and then estimate the importance by taking the ratio of the estimated densities. However, this naive approach tends to perform poorly since density estimation is a hard task particularly in high dimensional cases. In this paper, we propose a direct importance estimation method that does not involve density estimation. Our method is equipped with a natural cross validation procedure and hence tuning parameters such as the kernel width can be objectively optimized. Simulations illustrate the usefulness of our approach."
            },
            "slug": "Direct-Importance-Estimation-with-Model-Selection-Sugiyama-Nakajima",
            "title": {
                "fragments": [],
                "text": "Direct Importance Estimation with Model Selection and Its Application to Covariate Shift Adaptation"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This paper proposes a direct importance estimation method that does not involve density estimation and is equipped with a natural cross validation procedure and hence tuning parameters such as the kernel width can be objectively optimized."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152290618"
                        ],
                        "name": "Qiang Yang",
                        "slug": "Qiang-Yang",
                        "structuredName": {
                            "firstName": "Qiang",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Qiang Yang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1748808"
                        ],
                        "name": "Xindong Wu",
                        "slug": "Xindong-Wu",
                        "structuredName": {
                            "firstName": "Xindong",
                            "lastName": "Wu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xindong Wu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 68,
                                "start": 65
                            }
                        ],
                        "text": "For example, we sometimes have a classification task in one domain of interest, but we only have sufficient training data in another domain of interest, where the latter data may be in a different feature space or follow a different data distribution."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 9891263,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5f3b369eb088a62e2f7e27632973cf8a7a347c8f",
            "isKey": false,
            "numCitedBy": 857,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "In October 2005, we took an initiative to identify 10 challenging problems in data mining research, by consulting some of the most active researchers in data mining and machine learning for their opinions on what are considered important and worthy topics for future research in data mining. We hope their insights will inspire new research efforts, and give young researchers (including PhD students) a high-level guideline as to where the hot problems are located in data mining.Due to the limited amount of time, we were only able to send out our survey requests to the organizers of the IEEE ICDM and ACM KDD conferences, and we received an overwhelming response. We are very grateful for the contributions provided by these researchers despite their busy schedules. This short article serves to summarize the 10 most challenging problems of the 14 responses we have received from this survey. The order of the listing does not reflect their level of importance."
            },
            "slug": "10-Challenging-Problems-in-Data-Mining-Research-Yang-Wu",
            "title": {
                "fragments": [],
                "text": "10 Challenging Problems in Data Mining Research"
            },
            "tldr": {
                "abstractSimilarityScore": 66,
                "text": "This short article serves to summarize the 10 most challenging problems of the 14 responses the authors have received from this survey, by consulting some of the most active researchers in data mining and machine learning."
            },
            "venue": {
                "fragments": [],
                "text": "Int. J. Inf. Technol. Decis. Mak."
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3113725"
                        ],
                        "name": "V. Zheng",
                        "slug": "V.-Zheng",
                        "structuredName": {
                            "firstName": "Vincent",
                            "lastName": "Zheng",
                            "middleNames": [
                                "Wenchen"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Zheng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1687976"
                        ],
                        "name": "E. Xiang",
                        "slug": "E.-Xiang",
                        "structuredName": {
                            "firstName": "Evan",
                            "lastName": "Xiang",
                            "middleNames": [
                                "Wei"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Xiang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152290618"
                        ],
                        "name": "Qiang Yang",
                        "slug": "Qiang-Yang",
                        "structuredName": {
                            "firstName": "Qiang",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Qiang Yang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "37643602"
                        ],
                        "name": "Dou Shen",
                        "slug": "Dou-Shen",
                        "structuredName": {
                            "firstName": "Dou",
                            "lastName": "Shen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dou Shen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 68,
                                "start": 64
                            }
                        ],
                        "text": "Z is a shared feature space by XS and XT , and I\u00f0 ; \u00de is the mutual information between two random variables."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 8365865,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9693034f08c634521f60b764d666e595e756b4c3",
            "isKey": false,
            "numCitedBy": 95,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "Learning-based localization methods typically consist of an offline phase to collect the wireless signal data to build a statistical model, and an online phase to apply the model on new data. Many of these methods treat the training data as if their distributions are fixed across time. However, due to complex environmental changes such as temperature changes and multi-path fading effect, the signals can significantly vary from time to time, causing the localization accuracy to drop. We address this problem by introducing a novel semi-supervised Hidden Markov Model (HMM) to transfer the learned model from one time period to another. This adaptive model is referred to as transferred HMM (TrHMM), in which we aim to transfer as much knowledge from the old model as possible to reduce the calibration effort for the current time period. Our contribution is that we can successfully transfer out-of-date model to fit a current model through learning, even though the training data have very different distributions. Experimental results show that the TrHMM method can greatly improve the localization accuracy while saving a great amount of the calibration effort."
            },
            "slug": "Transferring-Localization-Models-over-Time-Zheng-Xiang",
            "title": {
                "fragments": [],
                "text": "Transferring Localization Models over Time"
            },
            "tldr": {
                "abstractSimilarityScore": 36,
                "text": "This work introduces a novel semi-supervised Hidden Markov Model (HMM) to transfer the learned model from one time period to another to reduce the calibration effort for the current time period."
            },
            "venue": {
                "fragments": [],
                "text": "AAAI"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3113725"
                        ],
                        "name": "V. Zheng",
                        "slug": "V.-Zheng",
                        "structuredName": {
                            "firstName": "Vincent",
                            "lastName": "Zheng",
                            "middleNames": [
                                "Wenchen"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Zheng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1746914"
                        ],
                        "name": "Sinno Jialin Pan",
                        "slug": "Sinno-Jialin-Pan",
                        "structuredName": {
                            "firstName": "Sinno",
                            "lastName": "Pan",
                            "middleNames": [
                                "Jialin"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sinno Jialin Pan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152290618"
                        ],
                        "name": "Qiang Yang",
                        "slug": "Qiang-Yang",
                        "structuredName": {
                            "firstName": "Qiang",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Qiang Yang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1730133"
                        ],
                        "name": "J. J. Pan",
                        "slug": "J.-J.-Pan",
                        "structuredName": {
                            "firstName": "Jeffrey",
                            "lastName": "Pan",
                            "middleNames": [
                                "Junfeng"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. J. Pan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 80,
                                "start": 76
                            }
                        ],
                        "text": "Z is a shared feature space by XS and XT , and I\u00f0 ; \u00de is the mutual information between two random variables."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2467509,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e618d29c48500ad84e215ed0be35c776cd59f7bd",
            "isKey": false,
            "numCitedBy": 99,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we propose a latent multi-task learning algorithm to solve the multi-device indoor localization problem. Traditional indoor localization systems often assume that the collected signal data distributions are fixed, and thus the localization model learned on one device can be used on other devices without adaptation. However, by empirically studying the signal variation over different devices, we found this assumption to be invalid in practice. To solve this problem, we treat multiple devices as multiple learning tasks, and propose a multi-task learning algorithm. Different from algorithms assuming that the hypotheses learned from the original data space for related tasks can be similar, we only require the hypotheses learned in a latent feature space are similar. To establish our algorithm, we employ an alternating optimization approach to iteratively learn feature mappings and multi-task regression models for the devices. We apply our latent multi-task learning algorithm to real-world indoor localization data and demonstrate its effectiveness."
            },
            "slug": "Transferring-Multi-device-Localization-Models-using-Zheng-Pan",
            "title": {
                "fragments": [],
                "text": "Transferring Multi-device Localization Models using Latent Multi-task Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 50,
                "text": "A latent multi-task learning algorithm that treats multiple devices as multiple learning tasks, and requires the hypotheses learned in a latent feature space are similar to solve the multi-device indoor localization problem."
            },
            "venue": {
                "fragments": [],
                "text": "AAAI"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2116927"
                        ],
                        "name": "John Blitzer",
                        "slug": "John-Blitzer",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Blitzer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "John Blitzer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1782853"
                        ],
                        "name": "Mark Dredze",
                        "slug": "Mark-Dredze",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Dredze",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mark Dredze"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145366908"
                        ],
                        "name": "Fernando C Pereira",
                        "slug": "Fernando-C-Pereira",
                        "structuredName": {
                            "firstName": "Fernando",
                            "lastName": "Pereira",
                            "middleNames": [
                                "C"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Fernando C Pereira"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 85,
                                "start": 82
                            }
                        ],
                        "text": "In such cases, transfer learning can save a significant amount of labeling effort [8]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 109,
                                "start": 106
                            }
                        ],
                        "text": "A second case can be referred to as feature-representationtransfer approach [22], [36], [37], [38], [39], [8], [40], [41], [42], [43], [44]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 36,
                                "start": 33
                            }
                        ],
                        "text": "extension of SCL was proposed in [8] for solving sentiment"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 39,
                                "start": 36
                            }
                        ],
                        "text": "Sen This data set was first used in [8] 11."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 154,
                                "start": 151
                            }
                        ],
                        "text": "In their follow-up work, the researchers proposed to use Mutual Information (MI) to choose the pivot features instead of using more heuristic criteria [8]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 119,
                                "start": 116
                            }
                        ],
                        "text": "In addition, in the table, we also show the comparison results on the sentiment classification data set reported in [8]."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 222,
                                "start": 219
                            }
                        ],
                        "text": "Feature-representation-transfer Find a \u201cgood\u201d feature representation that reduces difference between the source and the target domains and the error of classification and regression models [22], [36], [37], [38], [39], [8], [40], [41], [42], [43], [44]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14688775,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d895647b4a80861703851ef55930a2627fe19492",
            "isKey": true,
            "numCitedBy": 2089,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "Automatic sentiment classification has been extensively studied and applied in recent years. However, sentiment is expressed differently in different domains, and annotating corpora for every possible domain of interest is impractical. We investigate domain adaptation for sentiment classifiers, focusing on online reviews for different types of products. First, we extend to sentiment classification the recently-proposed structural correspondence learning (SCL) algorithm, reducing the relative error due to adaptation between domains by an average of 30% over the original SCL algorithm and 46% over a supervised baseline. Second, we identify a measure of domain similarity that correlates well with the potential for adaptation of a classifier from one domain to another. This measure could for instance be used to select a small set of domains to annotate whose trained classifiers would transfer well to many other domains."
            },
            "slug": "Biographies,-Bollywood,-Boom-boxes-and-Blenders:-Blitzer-Dredze",
            "title": {
                "fragments": [],
                "text": "Biographies, Bollywood, Boom-boxes and Blenders: Domain Adaptation for Sentiment Classification"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "This work extends to sentiment classification the recently-proposed structural correspondence learning (SCL) algorithm, reducing the relative error due to adaptation between domains by an average of 30% over the original SCL algorithm and 46% over a supervised baseline."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1768120"
                        ],
                        "name": "T. Jebara",
                        "slug": "T.-Jebara",
                        "structuredName": {
                            "firstName": "Tony",
                            "lastName": "Jebara",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Jebara"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "If no labeled data in the source domain are available, unsupervised learning methods are proposed to construct the feature representation."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 159,
                                "start": 155
                            }
                        ],
                        "text": "In addition, according to different situations of labeled and unlabeled data in the source domain, we can further categorize the inductive transfer learning setting into two cases:\na."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14128785,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8559ff5718b5a5ff1ffaaf5f91efaf25ee518457",
            "isKey": false,
            "numCitedBy": 241,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "We compute a common feature selection or kernel selection configuration for multiple support vector machines (SVMs) trained on different yet inter-related datasets. The method is advantageous when multiple classification tasks and differently labeled datasets exist over a common input space. Different datasets can mutually reinforce a common choice of representation or relevant features for their various classifiers. We derive a multi-task representation learning approach using the maximum entropy discrimination formalism. The resulting convex algorithms maintain the global solution properties of support vector machines. However, in addition to multiple SVM classification/regression parameters they also jointly estimate an optimal subset of features or optimal combination of kernels. Experiments are shown on standardized datasets."
            },
            "slug": "Multi-task-feature-and-kernel-selection-for-SVMs-Jebara",
            "title": {
                "fragments": [],
                "text": "Multi-task feature and kernel selection for SVMs"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "A multi-task representation learning approach using the maximum entropy discrimination formalism is derived and the resulting convex algorithms maintain the global solution properties of support vector machines."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1746914"
                        ],
                        "name": "Sinno Jialin Pan",
                        "slug": "Sinno-Jialin-Pan",
                        "structuredName": {
                            "firstName": "Sinno",
                            "lastName": "Pan",
                            "middleNames": [
                                "Jialin"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sinno Jialin Pan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "37643602"
                        ],
                        "name": "Dou Shen",
                        "slug": "Dou-Shen",
                        "structuredName": {
                            "firstName": "Dou",
                            "lastName": "Shen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dou Shen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152290618"
                        ],
                        "name": "Qiang Yang",
                        "slug": "Qiang-Yang",
                        "structuredName": {
                            "firstName": "Qiang",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Qiang Yang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145193332"
                        ],
                        "name": "J. Kwok",
                        "slug": "J.-Kwok",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Kwok",
                            "middleNames": [
                                "Tin-Yau"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Kwok"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 74,
                                "start": 70
                            }
                        ],
                        "text": "Z is a shared feature space by XS and XT , and I\u00f0 ; \u00de is the mutual information between two random variables."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6766352,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "798c3a6eb6ffa6bf2c3559ca702b1333ef5d4094",
            "isKey": false,
            "numCitedBy": 65,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "Machine learning approaches to indoor WiFi localization involve an offline phase and an online phase. In the offline phase, data are collected from an environment to build a localization model, which will be applied to new data collected in the online phase for location estimation. However, collecting the labeled data across an entire building would be too time consuming. In this paper, we present a novel approach to transferring the learning model trained on data from one area of a building to another. We learn a mapping function between the signal space and the location space by solving an optimization problem based on manifold learning techniques. A low-dimensional manifold is shared between data collected in different areas in an environment as a bridge to propagate the knowledge across the whole environment. With the help of the transferred knowledge, we can significantly reduce the amount of labeled data which are required for building the localization model. We test the effectiveness of our proposed solution in a real indoor WiFi environment."
            },
            "slug": "Transferring-Localization-Models-across-Space-Pan-Shen",
            "title": {
                "fragments": [],
                "text": "Transferring Localization Models across Space"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A novel approach to transferring the learning model trained on data from one area of a building to another by solving an optimization problem based on manifold learning techniques and can significantly reduce the amount of labeled data which are required for building the localization model."
            },
            "venue": {
                "fragments": [],
                "text": "AAAI"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "30561807"
                        ],
                        "name": "Edwin V. Bonilla",
                        "slug": "Edwin-V.-Bonilla",
                        "structuredName": {
                            "firstName": "Edwin",
                            "lastName": "Bonilla",
                            "middleNames": [
                                "V."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Edwin V. Bonilla"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1890071"
                        ],
                        "name": "K. M. A. Chai",
                        "slug": "K.-M.-A.-Chai",
                        "structuredName": {
                            "firstName": "Kian",
                            "lastName": "Chai",
                            "middleNames": [
                                "Ming",
                                "Adam"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. M. A. Chai"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145715698"
                        ],
                        "name": "Christopher K. I. Williams",
                        "slug": "Christopher-K.-I.-Williams",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Williams",
                            "middleNames": [
                                "K.",
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christopher K. I. Williams"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 7,
                                "start": 3
                            }
                        ],
                        "text": "In [44], Wang and Mahadevan proposed a Procrustes analysis-based approach to manifold alignment without correspondences, which can be used to transfer the knowledge across domains via the aligned manifolds."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 225,
                                "start": 221
                            }
                        ],
                        "text": "However, the inductive transfer learning setting only aims at achieving high performance in the target task by transferring knowledge from the source task while multitask learning tries to learn the target and source task simultaneously. b."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 10790217,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "10d10df314c1b58f5c83629e73a35185876cd4e2",
            "isKey": false,
            "numCitedBy": 889,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we investigate multi-task learning in the context of Gaussian Processes (GP). We propose a model that learns a shared covariance function on input-dependent features and a \"free-form\" covariance matrix over tasks. This allows for good flexibility when modelling inter-task dependencies while avoiding the need for large amounts of data for training. We show that under the assumption of noise-free observations and a block design, predictions for a given task only depend on its target values and therefore a cancellation of inter-task transfer occurs. We evaluate the benefits of our model on two practical applications: a compiler performance prediction problem and an exam score prediction task. Additionally, we make use of GP approximations and properties of our model in order to provide scalability to large data sets."
            },
            "slug": "Multi-task-Gaussian-Process-Prediction-Bonilla-Chai",
            "title": {
                "fragments": [],
                "text": "Multi-task Gaussian Process Prediction"
            },
            "tldr": {
                "abstractSimilarityScore": 59,
                "text": "A model that learns a shared covariance function on input-dependent features and a \"free-form\" covariance matrix over tasks allows for good flexibility when modelling inter-task dependencies while avoiding the need for large amounts of data for training."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40479470"
                        ],
                        "name": "B. Li",
                        "slug": "B.-Li",
                        "structuredName": {
                            "firstName": "Bin",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152290618"
                        ],
                        "name": "Qiang Yang",
                        "slug": "Qiang-Yang",
                        "structuredName": {
                            "firstName": "Qiang",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Qiang Yang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145905953"
                        ],
                        "name": "X. Xue",
                        "slug": "X.-Xue",
                        "structuredName": {
                            "firstName": "X.",
                            "lastName": "Xue",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "X. Xue"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 72,
                                "start": 68
                            }
                        ],
                        "text": "Arnold et al. [58] proposed to use transductive transfer learning methods to solve name-entity recognition problems."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5644766,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bebfd1e9f14616aeaeae0ab6cc9ff6f8127a7127",
            "isKey": false,
            "numCitedBy": 327,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "Cross-domain collaborative filtering solves the sparsity problem by transferring rating knowledge across multiple domains. In this paper, we propose a rating-matrix generative model (RMGM) for effective cross-domain collaborative filtering. We first show that the relatedness across multiple rating matrices can be established by finding a shared implicit cluster-level rating matrix, which is next extended to a cluster-level rating model. Consequently, a rating matrix of any related task can be viewed as drawing a set of users and items from a user-item joint mixture model as well as drawing the corresponding ratings from the cluster-level rating model. The combination of these two models gives the RMGM, which can be used to fill the missing ratings for both existing and new users. A major advantage of RMGM is that it can share the knowledge by pooling the rating data from multiple tasks even when the users and items of these tasks do not overlap. We evaluate the RMGM empirically on three real-world collaborative filtering data sets to show that RMGM can outperform the individual models trained separately."
            },
            "slug": "Transfer-learning-for-collaborative-filtering-via-a-Li-Yang",
            "title": {
                "fragments": [],
                "text": "Transfer learning for collaborative filtering via a rating-matrix generative model"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The proposed rating-matrix generative model (RMGM) can share the knowledge by pooling the rating data from multiple tasks even when the users and items of these tasks do not overlap, and can outperform the individual models trained separately."
            },
            "venue": {
                "fragments": [],
                "text": "ICML '09"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3261971"
                        ],
                        "name": "Hidetoshi Shimodaira",
                        "slug": "Hidetoshi-Shimodaira",
                        "structuredName": {
                            "firstName": "Hidetoshi",
                            "lastName": "Shimodaira",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hidetoshi Shimodaira"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 9238949,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "235723a15c86c369c99a42e7b666dfe156ad2cba",
            "isKey": false,
            "numCitedBy": 1413,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Improving-predictive-inference-under-covariate-by-Shimodaira",
            "title": {
                "fragments": [],
                "text": "Improving predictive inference under covariate shift by weighting the log-likelihood function"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2721040"
                        ],
                        "name": "S. Ramachandran",
                        "slug": "S.-Ramachandran",
                        "structuredName": {
                            "firstName": "Sowmya",
                            "lastName": "Ramachandran",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Ramachandran"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1797655"
                        ],
                        "name": "R. Mooney",
                        "slug": "R.-Mooney",
                        "structuredName": {
                            "firstName": "Raymond",
                            "lastName": "Mooney",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Mooney"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 117,
                                "start": 113
                            }
                        ],
                        "text": "In the second step, a revision is done for the mapped structure in the target domain through the FORTE algorithm [57], which is an inductive logic programming (ILP) algorithm for revising first-order theories."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 29536010,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0021e48a1552e77f4fcc3a4c625384add9f2ca73",
            "isKey": false,
            "numCitedBy": 39,
            "numCiting": 142,
            "paperAbstract": {
                "fragments": [],
                "text": "Research in theory refinement has shown that biasing a learner with initial, approximately correct knowledge produces more accurate results than learning from data alone. While techniques have been developed to revise logical and connectionist representations, little has been done to revise probabilistic representations. \nBayesian networks are well-established as a sound formalism for representing and reasoning with probabilistic knowledge, and are widely used. There has been a growing interest in the problem of learning Bayesian networks from data. However, there is no existing technique for learning or revising Bayesian networks with hidden variables (i.e., variables not represented in the data), that has been shown to be efficient, effective, and scalable through evaluation on real data. The few techniques that exist for revising such networks perform a blind search through a large space of revisions, and are therefore computationally expensive. \nThis dissertation presents B sc ANNER, a technique for using data to revise a given Bayesian network with Noisy-Or and Noisy-And nodes, to improve its classification accuracy. Additionally, the initial network can be derived directly from a logical theory expressed as propositional Horn-clause rules. B sc ANNER can revise networks with hidden variables, and add hidden variables when necessary. Unlike previous approaches to this problem, B sc ANNER employs mechanisms similar to those used in logical theory refinement techniques for using the data to focus the search for effective modifications to the network. It can also be used to learn networks with hidden variables from data alone. We also introduce B sc ANNER-P sc R, a technique for revising the parameters of a Bayesian network with Noisy-Or/And nodes, that directly exploits the computational efficiency afforded by these models. \nExperiments on several real-world learning problems in domains such as molecular biology and intelligent tutoring systems demonstrate that B sc ANNER can effectively and efficiently revise networks to significantly improve their accuracies, and thus learn highly accurate classifiers. Comparisons with the Naive Bayes algorithm show that using the theory refinement approach gives B sc ANNER a substantial edge over learning from data alone. We also show that B sc ANNER-P sc R converges faster and produces more accurate classifiers than an existing algorithm for learning the parameters of a network."
            },
            "slug": "Theory-Refinement-of-Bayesian-Networks-with-Hidden-Ramachandran-Mooney",
            "title": {
                "fragments": [],
                "text": "Theory Refinement of Bayesian Networks with Hidden Variables"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "Experiments on several real-world learning problems in domains such as molecular biology and intelligent tutoring systems demonstrate that B sc ANNER can effectively and efficiently revise networks to significantly improve their accuracies, and thus learn highly accurate classifiers."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144020269"
                        ],
                        "name": "Eric Eaton",
                        "slug": "Eric-Eaton",
                        "structuredName": {
                            "firstName": "Eric",
                            "lastName": "Eaton",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Eric Eaton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144980202"
                        ],
                        "name": "M. desJardins",
                        "slug": "M.-desJardins",
                        "structuredName": {
                            "firstName": "Marie",
                            "lastName": "desJardins",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. desJardins"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143673956"
                        ],
                        "name": "T. Lane",
                        "slug": "T.-Lane",
                        "structuredName": {
                            "firstName": "Terran",
                            "lastName": "Lane",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Lane"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 106,
                                "start": 102
                            }
                        ],
                        "text": "Based on the definition of the unsupervised transfer learning setting, no labeled data are observed in the source and target domains in training."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14414833,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f7b84424f235e9cfbc3bcd6cb5197fade1ebbac0",
            "isKey": false,
            "numCitedBy": 81,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we propose a novel graph-based method for knowledge transfer. We model the transfer relationships between source tasks by embedding the set of learned source models in a graph using transferability as the metric. Transfer to a new problem proceeds by mapping the problem into the graph, then learning a function on this graph that automatically determines the parameters to transfer to the new learning task. This method is analogous to inductive transfer along a manifold that captures the transfer relationships between the tasks. We demonstrate improved transfer performance using this method against existing approaches in several real-world domains."
            },
            "slug": "Modeling-Transfer-Relationships-Between-Learning-Eaton-desJardins",
            "title": {
                "fragments": [],
                "text": "Modeling Transfer Relationships Between Learning Tasks for Improved Inductive Transfer"
            },
            "tldr": {
                "abstractSimilarityScore": 66,
                "text": "A novel graph-based method for knowledge transfer is proposed by embedding the set of learned source models in a graph using transferability as the metric and demonstrating improved transfer performance against existing approaches in several real-world domains."
            },
            "venue": {
                "fragments": [],
                "text": "ECML/PKDD"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1680188"
                        ],
                        "name": "T. Joachims",
                        "slug": "T.-Joachims",
                        "structuredName": {
                            "firstName": "Thorsten",
                            "lastName": "Joachims",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Joachims"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14591650,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "74b1a9e50f18af8a7b9f8dd38f40e0466ad7a8e8",
            "isKey": false,
            "numCitedBy": 3047,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper introduces Transductive Support Vector Machines (TSVMs) for text classi cation. While regular Support Vector Machines (SVMs) try to induce a general decision function for a learning task, Transductive Support Vector Machines take into account a particular test set and try to minimize misclassi cations of just those particular examples. The paper presents an analysis of why TSVMs are well suited for text classi cation. These theoretical ndings are supported by experiments on three test collections. The experiments show substantial improvements over inductive methods, especially for small training sets, cutting the number of labeled training examples down to a twentieth on some tasks. This work also proposes an algorithm for training TSVMs e ciently, handling 10,000 examples and more."
            },
            "slug": "Transductive-Inference-for-Text-Classification-Joachims",
            "title": {
                "fragments": [],
                "text": "Transductive Inference for Text Classification using Support Vector Machines"
            },
            "tldr": {
                "abstractSimilarityScore": 53,
                "text": "An analysis of why Transductive Support Vector Machines are well suited for text classi cation is presented, and an algorithm for training TSVMs, handling 10,000 examples and more is proposed."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145075990"
                        ],
                        "name": "G. Fung",
                        "slug": "G.-Fung",
                        "structuredName": {
                            "firstName": "Gabriel",
                            "lastName": "Fung",
                            "middleNames": [
                                "Pui",
                                "Cheong"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Fung"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144666776"
                        ],
                        "name": "J. Yu",
                        "slug": "J.-Yu",
                        "structuredName": {
                            "firstName": "Jeffrey",
                            "lastName": "Yu",
                            "middleNames": [
                                "Xu"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Yu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1775519"
                        ],
                        "name": "Hongjun Lu",
                        "slug": "Hongjun-Lu",
                        "structuredName": {
                            "firstName": "Hongjun",
                            "lastName": "Lu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hongjun Lu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144019071"
                        ],
                        "name": "Philip S. Yu",
                        "slug": "Philip-S.-Yu",
                        "structuredName": {
                            "firstName": "Philip",
                            "lastName": "Yu",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Philip S. Yu"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 156,
                                "start": 153
                            }
                        ],
                        "text": "In this survey, we discuss the relationship between transfer learning and other related machine learning techniques such as domain adaptation, multitask learning and sample selection bias, as well as covariate shift."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7079167,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8234133aa400093db4d38e21e31e722e04f0961a",
            "isKey": false,
            "numCitedBy": 221,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "Traditionally, building a classifier requires two sets of examples: positive examples and negative examples. This paper studies the problem of building a text classifier using positive examples (P) and unlabeled examples (U). The unlabeled examples are mixed with both positive and negative examples. Since no negative example is given explicitly, the task of building a reliable text classifier becomes far more challenging. Simply treating all of the unlabeled examples as negative examples and building a classifier thereafter is undoubtedly a poor approach to tackling this problem. Generally speaking, most of the studies solved this problem by a two-step heuristic: first, extract negative examples (N) from U. Second, build a classifier based on P and N. Surprisingly, most studies did not try to extract positive examples from U. Intuitively, enlarging P by P' (positive examples extracted from U) and building a classifier thereafter should enhance the effectiveness of the classifier. Throughout our study, we find that extracting P' is very difficult. A document in U that possesses the features exhibited in P does not necessarily mean that it is a positive example, and vice versa. The very large size of and very high diversity in U also contribute to the difficulties of extracting P'. In this paper, we propose a labeling heuristic called PNLH to tackle this problem. PNLH aims at extracting high quality positive examples and negative examples from U and can be used on top of any existing classifiers. Extensive experiments based on several benchmarks are conducted. The results indicated that PNLH is highly feasible, especially in the situation where |P| is extremely small."
            },
            "slug": "Text-classification-without-negative-examples-Fung-Yu",
            "title": {
                "fragments": [],
                "text": "Text classification without negative examples revisit"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "A labeling heuristic called PNLH is proposed, which aims at extracting high quality positive examples and negative examples from U and can be used on top of any existing classifiers and is highly feasible, especially in the situation where |P| is extremely small."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Knowledge and Data Engineering"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1401829700"
                        ],
                        "name": "Shai Ben-David",
                        "slug": "Shai-Ben-David",
                        "structuredName": {
                            "firstName": "Shai",
                            "lastName": "Ben-David",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shai Ben-David"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2952147"
                        ],
                        "name": "Reba Schuller Borbely",
                        "slug": "Reba-Schuller-Borbely",
                        "structuredName": {
                            "firstName": "Reba",
                            "lastName": "Borbely",
                            "middleNames": [
                                "Schuller"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Reba Schuller Borbely"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Recently, Self-taught clustering (STC) [26] and transferred discriminative analysis (TDA) [27] algorithms are proposed to transfer clustering and transfer dimensionality reduction problems, respectively."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 13967968,
            "fieldsOfStudy": [
                "Computer Science",
                "Psychology"
            ],
            "id": "3a4551508f84a3f5447d3490b2db95b4d87a7969",
            "isKey": false,
            "numCitedBy": 344,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "The approach of learning of multiple \u201crelated\u201d tasks simultaneously has proven quite successful in practice; however, theoretical justification for this success has remained elusive. The starting point for previous work on multiple task learning has been that the tasks to be learned jointly are somehow \u201calgorithmically related\u201d, in the sense that the results of applying a specific learning algorithm to these tasks are assumed to be similar. We offer an alternative approach, defining relatedness of tasks on the basis of similarity between the example generating distributions that underline these task."
            },
            "slug": "Exploiting-Task-Relatedness-for-Mulitple-Task-Ben-David-Borbely",
            "title": {
                "fragments": [],
                "text": "Exploiting Task Relatedness for Mulitple Task Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "This work offers an alternative approach to multiple task learning, defining relatedness of tasks on the basis of similarity between the example generating distributions that underline these task."
            },
            "venue": {
                "fragments": [],
                "text": "COLT"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8192534"
                        ],
                        "name": "Jiayuan Huang",
                        "slug": "Jiayuan-Huang",
                        "structuredName": {
                            "firstName": "Jiayuan",
                            "lastName": "Huang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jiayuan Huang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46234526"
                        ],
                        "name": "Alex Smola",
                        "slug": "Alex-Smola",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Smola",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alex Smola"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1708497"
                        ],
                        "name": "A. Gretton",
                        "slug": "A.-Gretton",
                        "structuredName": {
                            "firstName": "Arthur",
                            "lastName": "Gretton",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Gretton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1704422"
                        ],
                        "name": "K. Borgwardt",
                        "slug": "K.-Borgwardt",
                        "structuredName": {
                            "firstName": "Karsten",
                            "lastName": "Borgwardt",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Borgwardt"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1707625"
                        ],
                        "name": "B. Sch\u00f6lkopf",
                        "slug": "B.-Sch\u00f6lkopf",
                        "structuredName": {
                            "firstName": "Bernhard",
                            "lastName": "Sch\u00f6lkopf",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Sch\u00f6lkopf"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 92,
                                "start": 88
                            }
                        ],
                        "text": "In the inductive transfer learning setting, the target task is different from the source task, no matter when the source and target domains are the same or not."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 56,
                                "start": 52
                            }
                        ],
                        "text": "Huang\net al. [32] proposed a kernel-mean matching (KMM) algorithm to learn P \u00f0xSi \u00de P \u00f0xTi \u00de directly by matching the means between the source domain data and the target domain data\nin a reproducing-kernel Hilbert space (RKHS)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 85,
                                "start": 81
                            }
                        ],
                        "text": "An advantage of using\nKMM is that it can avoid performing density estimation of either P \u00f0xSi\u00de or P \u00f0xTi\u00de, which is difficult when the size of the data set is small."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 70831,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "af8835c8960e539cc33f5375861efaedec1fb0b2",
            "isKey": false,
            "numCitedBy": 1393,
            "numCiting": 44,
            "paperAbstract": {
                "fragments": [],
                "text": "We consider the scenario where training and test data are drawn from different distributions, commonly referred to as sample selection bias. Most algorithms for this setting try to first recover sampling distributions and then make appropriate corrections based on the distribution estimate. We present a nonparametric method which directly produces resampling weights without distribution estimation. Our method works by matching distributions between training and testing sets in feature space. Experimental results demonstrate that our method works well in practice."
            },
            "slug": "Correcting-Sample-Selection-Bias-by-Unlabeled-Data-Huang-Smola",
            "title": {
                "fragments": [],
                "text": "Correcting Sample Selection Bias by Unlabeled Data"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A nonparametric method which directly produces resampling weights without distribution estimation is presented, which works by matching distributions between training and testing sets in feature space."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2064762485"
                        ],
                        "name": "Hankui Zhuo",
                        "slug": "Hankui-Zhuo",
                        "structuredName": {
                            "firstName": "Hankui",
                            "lastName": "Zhuo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hankui Zhuo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152290618"
                        ],
                        "name": "Qiang Yang",
                        "slug": "Qiang-Yang",
                        "structuredName": {
                            "firstName": "Qiang",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Qiang Yang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1811433"
                        ],
                        "name": "D. Hu",
                        "slug": "D.-Hu",
                        "structuredName": {
                            "firstName": "Derek",
                            "lastName": "Hu",
                            "middleNames": [
                                "Hao"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Hu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2151530377"
                        ],
                        "name": "Lei Li",
                        "slug": "Lei-Li",
                        "structuredName": {
                            "firstName": "Lei",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lei Li"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 201,
                                "start": 199
                            }
                        ],
                        "text": "The goal of STC is to learn ~XT by solving the optimization problem (7):\narg min ~XT ; ~XS; ~Z\nJ\u00f0 ~XT ; ~XS; ~Z\u00de: \u00f08\u00de\nAn iterative algorithm for solving the optimization function (8) was given in [26]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 9195678,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a012fea50038bc6fb3b67c501190989a18c89c48",
            "isKey": false,
            "numCitedBy": 20,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "Learning action models is an important and difficult task for AI planning, since it is both time-consuming and tedious for a human to encode the action models by hand using a formal language such as PDDL. In this paper, we present a new algorithm to learn action models from plan traces by transferring useful knowledge from another domain whose action models are already known. We call this algorithm t -LAMP , (transfer Learning Action Models from Plan traces) which can learn action models in PDDL language with quantifiers from plan traces where the intermediate states can contain noise and partial information. We apply Markov Logic Network to enable knowledge transfer, and show that using the transfer learning framework, the quality of the learned action models are generally better than the case when not using an existing domain for transfer."
            },
            "slug": "Transferring-Knowledge-from-Another-Domain-for-Zhuo-Yang",
            "title": {
                "fragments": [],
                "text": "Transferring Knowledge from Another Domain for Learning Action Models"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This paper presents a new algorithm to learn action models from plan traces by transferring useful knowledge from another domain whose action models are already known, and applies Markov Logic Network to enable knowledge transfer."
            },
            "venue": {
                "fragments": [],
                "text": "PRICAI"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144563617"
                        ],
                        "name": "J. Ramon",
                        "slug": "J.-Ramon",
                        "structuredName": {
                            "firstName": "Jan",
                            "lastName": "Ramon",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Ramon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695114"
                        ],
                        "name": "K. Driessens",
                        "slug": "K.-Driessens",
                        "structuredName": {
                            "firstName": "Kurt",
                            "lastName": "Driessens",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Driessens"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2136788"
                        ],
                        "name": "T. Croonenborghs",
                        "slug": "T.-Croonenborghs",
                        "structuredName": {
                            "firstName": "Tom",
                            "lastName": "Croonenborghs",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Croonenborghs"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "\u00c7"
                    },
                    "intents": []
                }
            ],
            "corpusId": 3561339,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "76ab1dbebd8e8842c023346c9a7c8173305e190b",
            "isKey": false,
            "numCitedBy": 80,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "We investigate the relation between transfer learning in reinforcement learning with function approximation and supervised learning with concept drift. We present a new incremental relational regression tree algorithm that is capable of dealing with concept drift through tree restructuring and show that it enables a Q-learner to transfer knowledge from one task to another by recycling those parts of the generalized Q-function that still hold interesting information for the new task. We illustrate the performance of the algorithm in several experiments."
            },
            "slug": "Transfer-Learning-in-Reinforcement-Learning-Through-Ramon-Driessens",
            "title": {
                "fragments": [],
                "text": "Transfer Learning in Reinforcement Learning Problems Through Partial Policy Recycling"
            },
            "tldr": {
                "abstractSimilarityScore": 56,
                "text": "This work presents a new incremental relational regression tree algorithm that is capable of dealing with concept drift through tree restructuring and shows that it enables a Q-learner to transfer knowledge from one task to another by recycling those parts of the generalized Q-function that still hold interesting information for the new task."
            },
            "venue": {
                "fragments": [],
                "text": "ECML"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145787377"
                        ],
                        "name": "Xiao Ling",
                        "slug": "Xiao-Ling",
                        "structuredName": {
                            "firstName": "Xiao",
                            "lastName": "Ling",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xiao Ling"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1701421"
                        ],
                        "name": "Gui-Rong Xue",
                        "slug": "Gui-Rong-Xue",
                        "structuredName": {
                            "firstName": "Gui-Rong",
                            "lastName": "Xue",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Gui-Rong Xue"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1752769"
                        ],
                        "name": "Wenyuan Dai",
                        "slug": "Wenyuan-Dai",
                        "structuredName": {
                            "firstName": "Wenyuan",
                            "lastName": "Dai",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wenyuan Dai"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "122376750"
                        ],
                        "name": "Yun Jiang",
                        "slug": "Yun-Jiang",
                        "structuredName": {
                            "firstName": "Yun",
                            "lastName": "Jiang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yun Jiang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152290618"
                        ],
                        "name": "Qiang Yang",
                        "slug": "Qiang-Yang",
                        "structuredName": {
                            "firstName": "Qiang",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Qiang Yang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1811427"
                        ],
                        "name": "Yong Yu",
                        "slug": "Yong-Yu",
                        "structuredName": {
                            "firstName": "Yong",
                            "lastName": "Yu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yong Yu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 65,
                                "start": 61
                            }
                        ],
                        "text": "These two steps run iteratively to find the best subspace for the target data."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2660077,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9fc06b8c1f637887728b457864b311ffea976916",
            "isKey": false,
            "numCitedBy": 124,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "As the World Wide Web in China grows rapidly, mining knowledge in Chinese Web pages becomes more and more important. Mining Web information usually relies on the machine learning techniques which require a large amount of labeled data to train credible models. Although the number of Chinese Web pages increases quite fast, it still lacks Chinese labeled data. However, there are relatively sufficient English labeled Web pages. These labeled data, though in different linguistic representations, share a substantial amount of semantic information with Chinese ones, and can be utilized to help classify Chinese Web pages. In this paper, we propose an information bottleneck based approach to address this cross-language classification problem. Our algorithm first translates all the Chinese Web pages to English. Then, all the Web pages, including Chinese and English ones, are encoded through an information bottleneck which can allow only limited information to pass. Therefore, in order to retain as much useful information as possible, the common part between Chinese and English Web pages is inclined to be encoded to the same code (i.e. class label), which makes the cross-language classification accurate. We evaluated our approach using the Web pages collected from Open Directory Project (ODP). The experimental results show that our method significantly improves several existing supervised and semi-supervised classifiers."
            },
            "slug": "Can-chinese-web-pages-be-classified-with-english-Ling-Xue",
            "title": {
                "fragments": [],
                "text": "Can chinese web pages be classified with english data source?"
            },
            "tldr": {
                "abstractSimilarityScore": 36,
                "text": "This paper proposes an information bottleneck based approach to address the cross-language classification problem of Chinese and English Web pages, and significantly improves several existing supervised and semi-supervised classifiers."
            },
            "venue": {
                "fragments": [],
                "text": "WWW"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39601583"
                        ],
                        "name": "Xiaoxin Yin",
                        "slug": "Xiaoxin-Yin",
                        "structuredName": {
                            "firstName": "Xiaoxin",
                            "lastName": "Yin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xiaoxin Yin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145325584"
                        ],
                        "name": "Jiawei Han",
                        "slug": "Jiawei-Han",
                        "structuredName": {
                            "firstName": "Jiawei",
                            "lastName": "Han",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jiawei Han"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49500141"
                        ],
                        "name": "Jiong Yang",
                        "slug": "Jiong-Yang",
                        "structuredName": {
                            "firstName": "Jiong",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jiong Yang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144019071"
                        ],
                        "name": "Philip S. Yu",
                        "slug": "Philip-S.-Yu",
                        "structuredName": {
                            "firstName": "Philip",
                            "lastName": "Yu",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Philip S. Yu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "DATA mining and machine learning technologies havealready achieved significant success in many knowledge engineering areas including classification, regression, and clustering (e.g., [1], [2])."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 10307315,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0329fe2b6d4a7424b818714d5fc8c76ff67b9e73",
            "isKey": false,
            "numCitedBy": 96,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "Relational databases are the most popular repository for structured data, and is thus one of the richest sources of knowledge in the world. In a relational database, multiple relations are linked together via entity-relationship links. Multirelational classification is the procedure of building a classifier based on information stored in multiple relations and making predictions with it. Existing approaches of inductive logic programming (recently, also known as relational mining) have proven effective with high accuracy in multirelational classification. Unfortunately, most of them suffer from scalability problems with regard to the number of relations in databases. In this paper, we propose a new approach, called CrossMine, which includes a set of novel and powerful methods for multirelational classification, including 1) tuple ID propagation, an efficient and flexible method for virtually joining relations, which enables convenient search among different relations, 2) new definitions for predicates and decision-tree nodes, which involve aggregated information to provide essential statistics for classification, and 3) a selective sampling method for improving scalability with regard to the number of tuples. Based on these techniques, we propose two scalable and accurate methods for multirelational classification: CrossMine-Rule, a rule-based method and CrossMine-Tree, a decision-tree-based method. Our comprehensive experiments on both real and synthetic data sets demonstrate the high scalability and accuracy of the CrossMine approach"
            },
            "slug": "Efficient-classification-across-multiple-database-a-Yin-Han",
            "title": {
                "fragments": [],
                "text": "Efficient classification across multiple database relations: a CrossMine approach"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This paper proposes a new approach, called CrossMine, which includes a set of novel and powerful methods for multirelational classification, including 1) tuple ID propagation, an efficient and flexible method for virtually joining relations, which enables convenient search among different relations, and new definitions for predicates and decision-tree nodes."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Knowledge and Data Engineering"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46302818"
                        ],
                        "name": "M. Rosenstein",
                        "slug": "M.-Rosenstein",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Rosenstein",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Rosenstein"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Recently, Self-taught clustering (STC) [26] and transferred discriminative analysis (TDA) [27] algorithms are proposed to transfer clustering and transfer dimensionality reduction problems, respectively."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 597779,
            "fieldsOfStudy": [
                "Computer Science",
                "Psychology"
            ],
            "id": "db8dbe07af7eebc1eed662be268592f00f4882e0",
            "isKey": false,
            "numCitedBy": 415,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "With transfer learning, one set of tasks is used to bias learning and improve performance on another task. However, transfer learning may actually hinder performance if the tasks are too dissimilar. As described in this paper, one challenge for transfer learning research is to develop approaches that detect and avoid negative transfer using very little data from the target task."
            },
            "slug": "To-transfer-or-not-to-transfer-Rosenstein",
            "title": {
                "fragments": [],
                "text": "To transfer or not to transfer"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "One challenge for transfer learning research is to develop approaches that detect and avoid negative transfer using very little data from the target task."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS 2005"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2118239775"
                        ],
                        "name": "Jing Jiang",
                        "slug": "Jing-Jiang",
                        "structuredName": {
                            "firstName": "Jing",
                            "lastName": "Jiang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jing Jiang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1736467"
                        ],
                        "name": "ChengXiang Zhai",
                        "slug": "ChengXiang-Zhai",
                        "structuredName": {
                            "firstName": "ChengXiang",
                            "lastName": "Zhai",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "ChengXiang Zhai"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 74,
                                "start": 70
                            }
                        ],
                        "text": "In the inductive transfer learning setting, the target task is different from the source task, no matter when the source and target domains are the same or not."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 131,
                                "start": 127
                            }
                        ],
                        "text": "Jiang and Zhai [30] proposed a heuristic method to remove \u201cmisleading\u201d training examples from the source domain based on the difference between conditional probabilities P \u00f0yT jxT \u00de and P \u00f0ySjxS\u00de."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 15036406,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b672ef69f60aea81220d658963445c41e60bb0e3",
            "isKey": false,
            "numCitedBy": 816,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "Domain adaptation is an important problem in natural language processing (NLP) due to the lack of labeled data in novel domains. In this paper, we study the domain adaptation problem from the instance weighting perspective. We formally analyze and characterize the domain adaptation problem from a distributional view, and show that there are two distinct needs for adaptation, corresponding to the different distributions of instances and classification functions in the source and the target domains. We then propose a general instance weighting framework for domain adaptation. Our empirical results on three NLP tasks show that incorporating and exploiting more information from the target domain through instance weighting is effective."
            },
            "slug": "Instance-Weighting-for-Domain-Adaptation-in-NLP-Jiang-Zhai",
            "title": {
                "fragments": [],
                "text": "Instance Weighting for Domain Adaptation in NLP"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This paper formally analyze and characterize the domain adaptation problem from a distributional view, and shows that there are two distinct needs for adaptation, corresponding to the different distributions of instances and classification functions in the source and the target domains."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40479470"
                        ],
                        "name": "B. Li",
                        "slug": "B.-Li",
                        "structuredName": {
                            "firstName": "Bin",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152290618"
                        ],
                        "name": "Qiang Yang",
                        "slug": "Qiang-Yang",
                        "structuredName": {
                            "firstName": "Qiang",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Qiang Yang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145905953"
                        ],
                        "name": "X. Xue",
                        "slug": "X.-Xue",
                        "structuredName": {
                            "firstName": "X.",
                            "lastName": "Xue",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "X. Xue"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 672476,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d5a55a548fc7cd703c1dd8d867ca1eb6b0c0764c",
            "isKey": false,
            "numCitedBy": 374,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "The sparsity problem in collaborative filtering (CF) is a major bottleneck for most CF methods. In this paper, we consider a novel approach for alleviating the sparsity problem in CF by transferring useritem rating patterns from a dense auxiliary rating matrix in other domains (e.g., a popular movie rating website) to a sparse rating matrix in a target domain (e.g., a new book rating website). We do not require that the users and items in the two domains be identical or even overlap. Based on the limited ratings in the target matrix, we establish a bridge between the two rating matrices at a cluster-level of user-item rating patterns in order to transfer more useful knowledge from the auxiliary task domain. We first compress the ratings in the auxiliary rating matrix into an informative and yet compact cluster-level rating pattern representation referred to as a codebook. Then, we propose an efficient algorithm for reconstructing the target rating matrix by expanding the codebook. We perform extensive empirical tests to show that our method is effective in addressing the data sparsity problem by transferring the useful knowledge from the auxiliary tasks, as compared to many state-of-the-art CF methods."
            },
            "slug": "Can-Movies-and-Books-Collaborate-Cross-Domain-for-Li-Yang",
            "title": {
                "fragments": [],
                "text": "Can Movies and Books Collaborate? Cross-Domain Collaborative Filtering for Sparsity Reduction"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This paper proposes an efficient algorithm for reconstructing the target rating matrix by expanding the codebook, a compact and informative and yet compact cluster-level rating pattern representation referred to as a codebook for transferring useful knowledge from the auxiliary task domain."
            },
            "venue": {
                "fragments": [],
                "text": "IJCAI"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145769639"
                        ],
                        "name": "V. Raykar",
                        "slug": "V.-Raykar",
                        "structuredName": {
                            "firstName": "Vikas",
                            "lastName": "Raykar",
                            "middleNames": [
                                "Chandrakant"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Raykar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1765150"
                        ],
                        "name": "B. Krishnapuram",
                        "slug": "B.-Krishnapuram",
                        "structuredName": {
                            "firstName": "Balaji",
                            "lastName": "Krishnapuram",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Krishnapuram"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38370684"
                        ],
                        "name": "J. Bi",
                        "slug": "J.-Bi",
                        "structuredName": {
                            "firstName": "Jinbo",
                            "lastName": "Bi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Bi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7816476"
                        ],
                        "name": "M. Dundar",
                        "slug": "M.-Dundar",
                        "structuredName": {
                            "firstName": "Murat",
                            "lastName": "Dundar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Dundar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144725064"
                        ],
                        "name": "R. B. Rao",
                        "slug": "R.-B.-Rao",
                        "structuredName": {
                            "firstName": "R.",
                            "lastName": "Rao",
                            "middleNames": [
                                "Bharat"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. B. Rao"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 13,
                                "start": 9
                            }
                        ],
                        "text": "TDA first applies clustering methods to generate pseudoclass labels for the target unlabeled data."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 9000884,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1037387773ad02fae162f3ee0df8122a6bbd90f9",
            "isKey": false,
            "numCitedBy": 145,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a novel Bayesian multiple instance learning (MIL) algorithm. This algorithm automatically identifies the relevant feature subset, and utilizes inductive transfer when learning multiple (conceptually related) classifiers. Experimental results indicate that the proposed MIL method is more accurate than previous MIL algorithms and selects a much smaller set of useful features. Inductive transfer further improves the accuracy of the classifier as compared to learning each task individually."
            },
            "slug": "Bayesian-multiple-instance-learning:-automatic-and-Raykar-Krishnapuram",
            "title": {
                "fragments": [],
                "text": "Bayesian multiple instance learning: automatic feature selection and inductive transfer"
            },
            "tldr": {
                "abstractSimilarityScore": 88,
                "text": "A novel Bayesian multiple instance learning algorithm that automatically identifies the relevant feature subset, and utilizes inductive transfer when learning multiple (conceptually related) classifiers."
            },
            "venue": {
                "fragments": [],
                "text": "ICML '08"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2071649"
                        ],
                        "name": "Anton Schwaighofer",
                        "slug": "Anton-Schwaighofer",
                        "structuredName": {
                            "firstName": "Anton",
                            "lastName": "Schwaighofer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Anton Schwaighofer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1700754"
                        ],
                        "name": "Volker Tresp",
                        "slug": "Volker-Tresp",
                        "structuredName": {
                            "firstName": "Volker",
                            "lastName": "Tresp",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Volker Tresp"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2114075909"
                        ],
                        "name": "Kai Yu",
                        "slug": "Kai-Yu",
                        "structuredName": {
                            "firstName": "Kai",
                            "lastName": "Yu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kai Yu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "In [44], Wang and Mahadevan proposed a Procrustes analysis-based approach to manifold alignment without correspondences, which can be used to transfer the knowledge across domains via the aligned manifolds."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 231,
                                "start": 227
                            }
                        ],
                        "text": "However, the inductive transfer learning setting only aims at achieving high performance in the target task by transferring knowledge from the source task while multitask learning tries to learn the target and source task simultaneously. b."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5726093,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "578c81b77915593f49c5f39d99eb414ef968e2c9",
            "isKey": false,
            "numCitedBy": 186,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a novel method for learning with Gaussian process regression in a hierarchical Bayesian framework. In a first step, kernel matrices on a fixed set of input points are learned from data using a simple and efficient EM algorithm. This step is nonparametric, in that it does not require a parametric form of covariance function. In a second step, kernel functions are fitted to approximate the learned covariance matrix using a generalized Nystrom method, which results in a complex, data driven kernel. We evaluate our approach as a recommendation engine for art images, where the proposed hierarchical Bayesian method leads to excellent prediction performance."
            },
            "slug": "Learning-Gaussian-Process-Kernels-via-Hierarchical-Schwaighofer-Tresp",
            "title": {
                "fragments": [],
                "text": "Learning Gaussian Process Kernels via Hierarchical Bayes"
            },
            "tldr": {
                "abstractSimilarityScore": 63,
                "text": "This work presents a novel method for learning with Gaussian process regression in a hierarchical Bayesian framework, and evaluates the approach as a recommendation engine for art images, where the proposed hierarchicalBayesian method leads to excellent prediction performance."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50617749"
                        ],
                        "name": "Jialin Pan",
                        "slug": "Jialin-Pan",
                        "structuredName": {
                            "firstName": "Jialin",
                            "lastName": "Pan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jialin Pan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2152935325"
                        ],
                        "name": "Wen-Jian Zheng",
                        "slug": "Wen-Jian-Zheng",
                        "structuredName": {
                            "firstName": "Wen-Jian",
                            "lastName": "Zheng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wen-Jian Zheng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153096457"
                        ],
                        "name": "Qiang Yang",
                        "slug": "Qiang-Yang",
                        "structuredName": {
                            "firstName": "Qiang",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Qiang Yang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2118879485"
                        ],
                        "name": "Hao Hu",
                        "slug": "Hao-Hu",
                        "structuredName": {
                            "firstName": "Hao",
                            "lastName": "Hu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hao Hu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "\u00c7"
                    },
                    "intents": []
                }
            ],
            "corpusId": 10598373,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ffb64a3bb67f529eddbdcf28127f7682b54b2baf",
            "isKey": false,
            "numCitedBy": 92,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "The WiFi-based indoor localization problem (WILP) aims to detect the location of a client device given the signals received from various access points. WILP is a complex and very important task for many AI and ubiquitous computing applications. A major approach to solving this task is through machine learning, where upto-date labeled training data are required in a large scale indoor environment. In this paper, we identify WILP as a transfer learning problem, because the WiFi data are highly dependent on contextual changes. We show that WILP can be modeled as a transfer learning problem for regression modeling, where we identify several important cases of knowledge transfer that range from transferring the localization models over time, across space and across client devices. We also share our working experience in WILP and transfer learning research in a realistic problem solving setting, and discuss a data set we have made public for advancing this research."
            },
            "slug": "Transfer-learning-for-WiFi-based-indoor-Pan-Zheng",
            "title": {
                "fragments": [],
                "text": "Transfer learning for WiFi-based indoor localization"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "It is shown that WILP can be modeled as a transfer learning problem for regression modeling, where several important cases of knowledge transfer can be identified that range from transferring the localization models over time, across space and across client devices."
            },
            "venue": {
                "fragments": [],
                "text": "AAAI 2008"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2153814"
                        ],
                        "name": "Lilyana Mihalkova",
                        "slug": "Lilyana-Mihalkova",
                        "structuredName": {
                            "firstName": "Lilyana",
                            "lastName": "Mihalkova",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lilyana Mihalkova"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1797655"
                        ],
                        "name": "R. Mooney",
                        "slug": "R.-Mooney",
                        "structuredName": {
                            "firstName": "Raymond",
                            "lastName": "Mooney",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Mooney"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 93,
                                "start": 89
                            }
                        ],
                        "text": "In the AAAI-2008 workshop on transfer learning for complex tasks,4 Mihalkova and Mooney [51] extended\n4. http://www.cs.utexas.edu/~mtaylor/AAAI08TL/."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "In addition, according to different situations between the source and target domains, we can further categorize the transductive transfer learning setting into two cases.\na."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 8892729,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0e2b751140567ed3fd8329cb5e5bf8e1776c58f8",
            "isKey": false,
            "numCitedBy": 78,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper introduces the single-entity-centered setting for transfer across two relational domains. In this setting, target domain data contains information about only a single entity. We present the SR2LR algorithm that finds an effective mapping of the source model to the target domain in this setting and demonstsrate its effectiveness in three relational domains. Our experiments additionally show that the most accurate model for the source domain is not always the best model to use for transfer."
            },
            "slug": "Transfer-Learning-by-Mapping-with-Minimal-Target-Mihalkova-Mooney",
            "title": {
                "fragments": [],
                "text": "Transfer Learning by Mapping with Minimal Target Data"
            },
            "tldr": {
                "abstractSimilarityScore": 53,
                "text": "The SR2LR algorithm is presented that finds an effective mapping of the source model to the target domain in this single-entity-centered setting for transfer across two relational domains and its effectiveness in three relational domains is evaluated."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2146408409"
                        ],
                        "name": "Chang Wang",
                        "slug": "Chang-Wang",
                        "structuredName": {
                            "firstName": "Chang",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chang Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1850503"
                        ],
                        "name": "S. Mahadevan",
                        "slug": "S.-Mahadevan",
                        "structuredName": {
                            "firstName": "Sridhar",
                            "lastName": "Mahadevan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Mahadevan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 94,
                                "start": 90
                            }
                        ],
                        "text": "Lee et al. [42] proposed a convex optimization algorithm for simultaneously learning metapriors and feature weights from an ensemble of related prediction tasks."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 165,
                                "start": 161
                            }
                        ],
                        "text": "In addition, according to different situations of labeled and unlabeled data in the source domain, we can further categorize the inductive transfer learning setting into two cases:\na."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 207168317,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a6c3392d12b00a4fac8b82dd9a1ff7bad8f29b74",
            "isKey": false,
            "numCitedBy": 255,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we introduce a novel approach to manifold alignment, based on Procrustes analysis. Our approach differs from \"semi-supervised alignment\" in that it results in a mapping that is defined everywhere - when used with a suitable dimensionality reduction method - rather than just on the training data points. We describe and evaluate our approach both theoretically and experimentally, providing results showing useful knowledge transfer from one domain to another. Novel applications of our method including cross-lingual information retrieval and transfer learning in Markov decision processes are presented."
            },
            "slug": "Manifold-alignment-using-Procrustes-analysis-Wang-Mahadevan",
            "title": {
                "fragments": [],
                "text": "Manifold alignment using Procrustes analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "Novel applications of the approach including cross-lingual information retrieval and transfer learning in Markov decision processes are presented, providing results showing useful knowledge transfer from one domain to another."
            },
            "venue": {
                "fragments": [],
                "text": "ICML '08"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1743073"
                        ],
                        "name": "L. Kuncheva",
                        "slug": "L.-Kuncheva",
                        "structuredName": {
                            "firstName": "Ludmila",
                            "lastName": "Kuncheva",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Kuncheva"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1715754"
                        ],
                        "name": "Juan Jos\u00e9 Rodr\u00edguez Diez",
                        "slug": "Juan-Jos\u00e9-Rodr\u00edguez-Diez",
                        "structuredName": {
                            "firstName": "Juan",
                            "lastName": "Rodr\u00edguez Diez",
                            "middleNames": [
                                "Jos\u00e9"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Juan Jos\u00e9 Rodr\u00edguez Diez"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 9,
                                "start": 5
                            }
                        ],
                        "text": "However, many machine learning methods work well only under a common assumption: the training and test data are drawn from the same feature space and the same distribution."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15513949,
            "fieldsOfStudy": [
                "Computer Science",
                "Environmental Science"
            ],
            "id": "99ab0db460775a5a09ba46d39f0373ba83b82b82",
            "isKey": false,
            "numCitedBy": 156,
            "numCiting": 52,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a combined fusion-selection approach to classifier ensemble design. Each classifier in the ensemble is replaced by a miniensemble of a pair of subclassifiers with a random linear oracle to choose between the two. It is argued that this approach encourages extra diversity in the ensemble while allowing for high accuracy of the individual ensemble members. Experiments were carried out with 35 data sets from UCI and 11 ensemble models. Each ensemble model was examined with and without the oracle. The results showed that all ensemble methods benefited from the new approach, most markedly so random subspace and bagging. A further experiment with seven real medical data sets demonstrates the validity of these findings outside the UCI data collection"
            },
            "slug": "Classifier-Ensembles-with-a-Random-Linear-Oracle-Kuncheva-Diez",
            "title": {
                "fragments": [],
                "text": "Classifier Ensembles with a Random Linear Oracle"
            },
            "tldr": {
                "abstractSimilarityScore": 95,
                "text": "A combined fusion-selection approach to classifier ensemble design where each classifier in the ensemble is replaced by a miniensemble of a pair of subclassifiers with a random linear oracle to choose between the two."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Knowledge and Data Engineering"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1746914"
                        ],
                        "name": "Sinno Jialin Pan",
                        "slug": "Sinno-Jialin-Pan",
                        "structuredName": {
                            "firstName": "Sinno",
                            "lastName": "Pan",
                            "middleNames": [
                                "Jialin"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sinno Jialin Pan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145193332"
                        ],
                        "name": "J. Kwok",
                        "slug": "J.-Kwok",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Kwok",
                            "middleNames": [
                                "Tin-Yau"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Kwok"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152290618"
                        ],
                        "name": "Qiang Yang",
                        "slug": "Qiang-Yang",
                        "structuredName": {
                            "firstName": "Qiang",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Qiang Yang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1730133"
                        ],
                        "name": "J. J. Pan",
                        "slug": "J.-J.-Pan",
                        "structuredName": {
                            "firstName": "Jeffrey",
                            "lastName": "Pan",
                            "middleNames": [
                                "Junfeng"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. J. Pan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 62,
                                "start": 58
                            }
                        ],
                        "text": "Z is a shared feature space by XS and XT , and I\u00f0 ; \u00de is the mutual information between two random variables."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 114924,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4398c25bcea058c7006a741a5d613da8506d52e5",
            "isKey": false,
            "numCitedBy": 127,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "Accurately locating users in a wireless environment is an important task for many pervasive computing and AI applications, such as activity recognition. In a WiFi environment, a mobile device can be localized using signals received from various transmitters, such as access points (APs). Most localization approaches build a map between the signal space and the physical location space in a offline phase, and then using the received-signal-strength (RSS) map to estimate the location in an online phase. However, the map can be outdated when the signal-strength values change with time due to environmental dynamics. It is infeasible or expensive to repeat data calibration for reconstructing the RSS map. In such a case, it is important to adapt the model learnt in one time period to another time period without too much recalibration. In this paper, we present a location-estimation approach based on Manifold co-Regularization, which is a machine learning technique for building a mapping function between data. We describe LeManCoR, a system for adapting the mapping function between the signal space and physical location space over different time periods based on Manifold Co-Regularization. We show that LeManCoR can effectively transfer the knowledge between two time periods without requiring too much new calibration effort. We illustrate LeMan-CoR's effectiveness in a real 802.11 WiFi environment."
            },
            "slug": "Adaptive-Localization-in-a-Dynamic-WiFi-Environment-Pan-Kwok",
            "title": {
                "fragments": [],
                "text": "Adaptive Localization in a Dynamic WiFi Environment through Multi-view Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "LeManCoR, a system for adapting the mapping function between the signal space and physical location space over different time periods based on Manifold Co-Regularization is described and it is shown that LeMan co-CoR can effectively transfer the knowledge between two time periods without requiring too much new calibration effort."
            },
            "venue": {
                "fragments": [],
                "text": "AAAI"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50560492"
                        ],
                        "name": "V. Vapnik",
                        "slug": "V.-Vapnik",
                        "structuredName": {
                            "firstName": "Vladimir",
                            "lastName": "Vapnik",
                            "middleNames": [
                                "Naumovich"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Vapnik"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 100,
                                "start": 97
                            }
                        ],
                        "text": "However, since it is hard to estimate the probability distribution P , we choose to minimize the ERM instead,\n\u00bc arg min 2\n1\nn Xn i\u00bc1 \u00bdl\u00f0xi; yi; \u00de ;\nwhere n is size of the training data."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 140,
                                "start": 136
                            }
                        ],
                        "text": "To see how importance-sampling-based methods may help in this setting, we first review the problem of empirical risk minimization (ERM) [60]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 28637672,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "385197d4c02593e2823c71e4f90a0993b703620e",
            "isKey": false,
            "numCitedBy": 26320,
            "numCiting": 1,
            "paperAbstract": {
                "fragments": [],
                "text": "A comprehensive look at learning and generalization theory. The statistical theory of learning and generalization concerns the problem of choosing desired functions on the basis of empirical data. Highly applicable to a variety of computer science and robotics fields, this book offers lucid coverage of the theory as a whole. Presenting a method for determining the necessary and sufficient conditions for consistency of learning process, the author covers function estimates from small data pools, applying these estimations to real-life problems, and much more."
            },
            "slug": "Statistical-learning-theory-Vapnik",
            "title": {
                "fragments": [],
                "text": "Statistical learning theory"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "Presenting a method for determining the necessary and sufficient conditions for consistency of learning process, the author covers function estimates from small data pools, applying these estimations to real-life problems, and much more."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1749714"
                        ],
                        "name": "M. Berlingerio",
                        "slug": "M.-Berlingerio",
                        "structuredName": {
                            "firstName": "Michele",
                            "lastName": "Berlingerio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Berlingerio"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1705764"
                        ],
                        "name": "F. Bonchi",
                        "slug": "F.-Bonchi",
                        "structuredName": {
                            "firstName": "Francesco",
                            "lastName": "Bonchi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Bonchi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685102"
                        ],
                        "name": "F. Giannotti",
                        "slug": "F.-Giannotti",
                        "structuredName": {
                            "firstName": "Fosca",
                            "lastName": "Giannotti",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Giannotti"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1707206"
                        ],
                        "name": "F. Turini",
                        "slug": "F.-Turini",
                        "structuredName": {
                            "firstName": "Franco",
                            "lastName": "Turini",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Turini"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 16571296,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5cc17f1da353fb6ae2cff5ad5d131a776b2611a2",
            "isKey": false,
            "numCitedBy": 9,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "A typical structure of medical data is a sequence of observations of clinical parameters taken at different time moments. In this kind of contexts, the temporal dimension of data is a fundamental variable that should be taken into account in the mining process and returned as part of the extracted knowledge. Therefore, the classical and well established framework of sequential pattern mining is not enough, because it only focuses on the sequentiality of events, without extracting the typical time elapsing between two particular events. Time-annotated sequences (IAS) is a novel mining paradigm that solves this problem. Recently defined in our laboratory [4] together with an efficient algorithm for extracting them, TAS are sequential patterns where each transition between two events is annotated with a typical transition time that is found frequent in the data. In this paper we report a real-world medical case study, in which the TAS mining paradigm is applied to clinical data regarding a set of patients in the follow-up of a liver transplantation. The aim of the data analysis is that of assessing the effectiveness of the extracorporeal photopheresis (ECP) as a therapy to prevent rejection in solid organ transplantation. We believe that this case study does not only show the interestingness of extracting TAS patterns in this particular context but, more ambitiously, it suggests a general methodology for clinical data mining, whenever the time dimension is an important variable of the problem under investigation."
            },
            "slug": "Time-Annotated-Sequences-for-Medical-Data-Mining-Berlingerio-Bonchi",
            "title": {
                "fragments": [],
                "text": "Time-Annotated Sequences for Medical Data Mining"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A real-world medical case study, in which the TAS mining paradigm is applied to clinical data regarding a set of patients in the follow-up of a liver transplantation, which suggests a general methodology for clinical data mining, whenever the time dimension is an important variable of the problem under investigation."
            },
            "venue": {
                "fragments": [],
                "text": "Seventh IEEE International Conference on Data Mining Workshops (ICDMW 2007)"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1722360"
                        ],
                        "name": "Hal Daum\u00e9",
                        "slug": "Hal-Daum\u00e9",
                        "structuredName": {
                            "firstName": "Hal",
                            "lastName": "Daum\u00e9",
                            "middleNames": [],
                            "suffix": "III"
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hal Daum\u00e9"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "5"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 130,
                                "start": 126
                            }
                        ],
                        "text": "In addition, according to different situations of labeled and unlabeled data in the source domain, we can further categorize the inductive transfer learning setting into two cases:\na."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5360764,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9f62067945d991cd78a62cf647de17f01d1b54d3",
            "isKey": false,
            "numCitedBy": 1618,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe an approach to domain adaptation that is appropriate exactly in the case when one has enough \u201ctarget\u201d data to do slightly better than just using only \u201csource\u201d data. Our approach is incredibly simple, easy to implement as a preprocessing step (10 lines of Perl!) and outperforms stateof-the-art approaches on a range of datasets. Moreover, it is trivially extended to a multidomain adaptation problem, where one has data from a variety of different domains."
            },
            "slug": "Frustratingly-Easy-Domain-Adaptation-Daum\u00e9",
            "title": {
                "fragments": [],
                "text": "Frustratingly Easy Domain Adaptation"
            },
            "tldr": {
                "abstractSimilarityScore": 94,
                "text": "This work describes an approach to domain adaptation that is appropriate exactly in the case when one has enough \u201ctarget\u201d data to do slightly better than just using only \u201csource\u2019 data."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1748808"
                        ],
                        "name": "Xindong Wu",
                        "slug": "Xindong-Wu",
                        "structuredName": {
                            "firstName": "Xindong",
                            "lastName": "Wu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xindong Wu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2107978833"
                        ],
                        "name": "Vipin Kumar",
                        "slug": "Vipin-Kumar",
                        "structuredName": {
                            "firstName": "Vipin",
                            "lastName": "Kumar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Vipin Kumar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145341779"
                        ],
                        "name": "J. R. Quinlan",
                        "slug": "J.-R.-Quinlan",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Quinlan",
                            "middleNames": [
                                "Ross"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. R. Quinlan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34724702"
                        ],
                        "name": "Joydeep Ghosh",
                        "slug": "Joydeep-Ghosh",
                        "structuredName": {
                            "firstName": "Joydeep",
                            "lastName": "Ghosh",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Joydeep Ghosh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152290618"
                        ],
                        "name": "Qiang Yang",
                        "slug": "Qiang-Yang",
                        "structuredName": {
                            "firstName": "Qiang",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Qiang Yang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1748072"
                        ],
                        "name": "H. Motoda",
                        "slug": "H.-Motoda",
                        "structuredName": {
                            "firstName": "Hiroshi",
                            "lastName": "Motoda",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Motoda"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1690163"
                        ],
                        "name": "G. McLachlan",
                        "slug": "G.-McLachlan",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "McLachlan",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. McLachlan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48284155"
                        ],
                        "name": "Angus F. M. Ng",
                        "slug": "Angus-F.-M.-Ng",
                        "structuredName": {
                            "firstName": "Angus",
                            "lastName": "Ng",
                            "middleNames": [
                                "F.",
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Angus F. M. Ng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145321667"
                        ],
                        "name": "B. Liu",
                        "slug": "B.-Liu",
                        "structuredName": {
                            "firstName": "B.",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Liu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144019071"
                        ],
                        "name": "Philip S. Yu",
                        "slug": "Philip-S.-Yu",
                        "structuredName": {
                            "firstName": "Philip",
                            "lastName": "Yu",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Philip S. Yu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145624000"
                        ],
                        "name": "Zhi-Hua Zhou",
                        "slug": "Zhi-Hua-Zhou",
                        "structuredName": {
                            "firstName": "Zhi-Hua",
                            "lastName": "Zhou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zhi-Hua Zhou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1707756"
                        ],
                        "name": "M. Steinbach",
                        "slug": "M.-Steinbach",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Steinbach",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Steinbach"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1781982"
                        ],
                        "name": "D. Hand",
                        "slug": "D.-Hand",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Hand",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Hand"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39566019"
                        ],
                        "name": "D. Steinberg",
                        "slug": "D.-Steinberg",
                        "structuredName": {
                            "firstName": "Dan",
                            "lastName": "Steinberg",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Steinberg"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 63,
                                "start": 60
                            }
                        ],
                        "text": "For example, we sometimes have a classification task in one domain of interest, but we only have sufficient training data in another domain of interest, where the latter data may be in a different feature space or follow a different data distribution."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2367747,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a83d6476bd25c3cc1cbfb89eab245a8fa895ece8",
            "isKey": false,
            "numCitedBy": 4736,
            "numCiting": 172,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents the top 10 data mining algorithms identified by the IEEE International Conference on Data Mining (ICDM) in December 2006: C4.5, k-Means, SVM, Apriori, EM, PageRank, AdaBoost, kNN, Naive Bayes, and CART. These top 10 algorithms are among the most influential data mining algorithms in the research community. With each algorithm, we provide a description of the algorithm, discuss the impact of the algorithm, and review current and further research on the algorithm. These 10 algorithms cover classification, clustering, statistical learning, association analysis, and link mining, which are all among the most important topics in data mining research and development."
            },
            "slug": "Top-10-algorithms-in-data-mining-Wu-Kumar",
            "title": {
                "fragments": [],
                "text": "Top 10 algorithms in data mining"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "This paper presents the top 10 data mining algorithms identified by the IEEE International Conference on Data Mining (ICDM) in December 2006: C4.5, k-Means, SVM, Apriori, EM, PageRank, AdaBoost, kNN, Naive Bayes, and CART."
            },
            "venue": {
                "fragments": [],
                "text": "Knowledge and Information Systems"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145805766"
                        ],
                        "name": "Gregory Kuhlmann",
                        "slug": "Gregory-Kuhlmann",
                        "structuredName": {
                            "firstName": "Gregory",
                            "lastName": "Kuhlmann",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Gregory Kuhlmann"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144848112"
                        ],
                        "name": "P. Stone",
                        "slug": "P.-Stone",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Stone",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Stone"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 19,
                                "start": 15
                            }
                        ],
                        "text": "Raina et al. [74] and Dai et al. [36], [28] proposed to use transfer learning techniques to learn text data across domains, respectively."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1357490,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e67a25faa0ecfb1860f76febc511571bbdfacdcf",
            "isKey": false,
            "numCitedBy": 63,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "A general game player is an agent capable of taking as input a description of a game's rules in a formal language and proceeding to play without any subsequent human input. To do well, an agent should learn from experience with past games and transfer the learned knowledge to new problems. We introduce a graph-based method for identifying previously encountered games and prove its robustness formally. We then describe how the same basic approach can be used to identify similar but non-identical games. We apply this technique to automate domain mapping for value function transfer and speed up reinforcement learning on variants of previously played games. Our approach is fully implemented with empirical results in the general game playing system."
            },
            "slug": "Graph-Based-Domain-Mapping-for-Transfer-Learning-in-Kuhlmann-Stone",
            "title": {
                "fragments": [],
                "text": "Graph-Based Domain Mapping for Transfer Learning in General Games"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This work introduces a graph-based method for identifying previously encountered games and proves its robustness formally, and describes how the same basic approach can be used to identify similar but non-identical games."
            },
            "venue": {
                "fragments": [],
                "text": "ECML"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1697141"
                        ],
                        "name": "Honglak Lee",
                        "slug": "Honglak-Lee",
                        "structuredName": {
                            "firstName": "Honglak",
                            "lastName": "Lee",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Honglak Lee"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2078284037"
                        ],
                        "name": "Alexis Battle",
                        "slug": "Alexis-Battle",
                        "structuredName": {
                            "firstName": "Alexis",
                            "lastName": "Battle",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alexis Battle"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2979876"
                        ],
                        "name": "R. Raina",
                        "slug": "R.-Raina",
                        "structuredName": {
                            "firstName": "Rajat",
                            "lastName": "Raina",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Raina"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34699434"
                        ],
                        "name": "A. Ng",
                        "slug": "A.-Ng",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Ng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Ng"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 58,
                                "start": 54
                            }
                        ],
                        "text": "Supervised feature construction methods for the inductive transfer learning setting are similar to those used in multitask learning."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 303727,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e64a9960734215e2b1866ea3cb723ffa5585ac14",
            "isKey": false,
            "numCitedBy": 2683,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "Sparse coding provides a class of algorithms for finding succinct representations of stimuli; given only unlabeled input data, it discovers basis functions that capture higher-level features in the data. However, finding sparse codes remains a very difficult computational problem. In this paper, we present efficient sparse coding algorithms that are based on iteratively solving two convex optimization problems: an L1-regularized least squares problem and an L2-constrained least squares problem. We propose novel algorithms to solve both of these optimization problems. Our algorithms result in a significant speedup for sparse coding, allowing us to learn larger sparse codes than possible with previously described algorithms. We apply these algorithms to natural images and demonstrate that the inferred sparse codes exhibit end-stopping and non-classical receptive field surround suppression and, therefore, may provide a partial explanation for these two phenomena in V1 neurons."
            },
            "slug": "Efficient-sparse-coding-algorithms-Lee-Battle",
            "title": {
                "fragments": [],
                "text": "Efficient sparse coding algorithms"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "These algorithms are applied to natural images and it is demonstrated that the inferred sparse codes exhibit end-stopping and non-classical receptive field surround suppression and, therefore, may provide a partial explanation for these two phenomena in V1 neurons."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144422314"
                        ],
                        "name": "Matthew Richardson",
                        "slug": "Matthew-Richardson",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Richardson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Matthew Richardson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1740213"
                        ],
                        "name": "Pedro M. Domingos",
                        "slug": "Pedro-M.-Domingos",
                        "structuredName": {
                            "firstName": "Pedro",
                            "lastName": "Domingos",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Pedro M. Domingos"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 9,
                                "start": 5
                            }
                        ],
                        "text": "MLNs [56] is a powerful formalism, which combines the compact expressiveness of first-order logic with flexibility of probability, for statistical relational learning."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 12698795,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "950a3c89dacbc3e7ddcd43d7ff6f985697e41cdb",
            "isKey": false,
            "numCitedBy": 2803,
            "numCiting": 97,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a simple approach to combining first-order logic and probabilistic graphical models in a single representation. A Markov logic network (MLN) is a first-order knowledge base with a weight attached to each formula (or clause). Together with a set of constants representing objects in the domain, it specifies a ground Markov network containing one feature for each possible grounding of a first-order formula in the KB, with the corresponding weight. Inference in MLNs is performed by MCMC over the minimal subset of the ground network required for answering the query. Weights are efficiently learned from relational databases by iteratively optimizing a pseudo-likelihood measure. Optionally, additional clauses are learned using inductive logic programming techniques. Experiments with a real-world database and knowledge base in a university domain illustrate the promise of this approach."
            },
            "slug": "Markov-logic-networks-Richardson-Domingos",
            "title": {
                "fragments": [],
                "text": "Markov logic networks"
            },
            "tldr": {
                "abstractSimilarityScore": 55,
                "text": "Experiments with a real-world database and knowledge base in a university domain illustrate the promise of this approach to combining first-order logic and probabilistic graphical models in a single representation."
            },
            "venue": {
                "fragments": [],
                "text": "Machine Learning"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2111609861"
                        ],
                        "name": "Jie Yin",
                        "slug": "Jie-Yin",
                        "structuredName": {
                            "firstName": "Jie",
                            "lastName": "Yin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jie Yin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152290618"
                        ],
                        "name": "Qiang Yang",
                        "slug": "Qiang-Yang",
                        "structuredName": {
                            "firstName": "Qiang",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Qiang Yang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1726587"
                        ],
                        "name": "L. Ni",
                        "slug": "L.-Ni",
                        "structuredName": {
                            "firstName": "Lionel",
                            "lastName": "Ni",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Ni"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1805342,
            "fieldsOfStudy": [
                "Business"
            ],
            "id": "a640f5ec9c1cc573ae04f3720329f0f382b349f5",
            "isKey": false,
            "numCitedBy": 182,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we present a novel method to adapt the temporal radio maps for indoor location estimation by offsetting the variational environmental factors using data mining techniques and reference points. Environmental variations, which cause the signals to change from time to time even at the same location, present a challenging task for indoor location estimation in the IEEE 802.11b infrastructure. In such a dynamic environment, the radio maps obtained in one time period may not be applicable in other time periods. To solve this problem, we apply a regression analysis to learn the temporal predictive relationship between the signal-strength values received by sparsely located reference points and that received by the mobile device. This temporal prediction model can then be used for online localization based on the newly observed signal-strength values at the client side and the reference points. We show that this technique can effectively accommodate the variations of signal-strength values over different time periods without the need to rebuild the radio maps repeatedly. We also show that the location of mobile device can be accurately determined using this technique with lower density in the distribution of the reference points"
            },
            "slug": "Adaptive-Temporal-Radio-Maps-for-Indoor-Location-Yin-Yang",
            "title": {
                "fragments": [],
                "text": "Adaptive Temporal Radio Maps for Indoor Location Estimation"
            },
            "tldr": {
                "abstractSimilarityScore": 72,
                "text": "A novel method to adapt the temporal radio maps for indoor location estimation by offsetting the variational environmental factors using data mining techniques and reference points and can effectively accommodate the variations of signal-strength values over different time periods without the need to rebuild the radio maps repeatedly."
            },
            "venue": {
                "fragments": [],
                "text": "Third IEEE International Conference on Pervasive Computing and Communications"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1832364"
                        ],
                        "name": "Xiaojin Zhu",
                        "slug": "Xiaojin-Zhu",
                        "structuredName": {
                            "firstName": "Xiaojin",
                            "lastName": "Zhu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xiaojin Zhu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 51,
                                "start": 47
                            }
                        ],
                        "text": "However, many machine learning methods work well only under a common assumption: the training and test data are drawn from the same feature space and the same distribution."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2731141,
            "fieldsOfStudy": [
                "Education"
            ],
            "id": "a007f46b3303bdb50e705b441c367e595666538c",
            "isKey": false,
            "numCitedBy": 3963,
            "numCiting": 324,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Semi-Supervised-Learning-Literature-Survey-Zhu",
            "title": {
                "fragments": [],
                "text": "Semi-Supervised Learning Literature Survey"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152290618"
                        ],
                        "name": "Qiang Yang",
                        "slug": "Qiang-Yang",
                        "structuredName": {
                            "firstName": "Qiang",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Qiang Yang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1746914"
                        ],
                        "name": "Sinno Jialin Pan",
                        "slug": "Sinno-Jialin-Pan",
                        "structuredName": {
                            "firstName": "Sinno",
                            "lastName": "Pan",
                            "middleNames": [
                                "Jialin"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sinno Jialin Pan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3113725"
                        ],
                        "name": "V. Zheng",
                        "slug": "V.-Zheng",
                        "structuredName": {
                            "firstName": "Vincent",
                            "lastName": "Zheng",
                            "middleNames": [
                                "Wenchen"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Zheng"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "These two steps run iteratively to find the best subspace for the target data."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14699493,
            "fieldsOfStudy": [
                "Economics"
            ],
            "id": "40f7eec32a7d23380f519f3f48fdbdf734d44a14",
            "isKey": false,
            "numCitedBy": 115,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "This department presents the results of the first Data Mining Contest held at the 2007 International Conference on Data Mining."
            },
            "slug": "Estimating-Location-Using-Wi-Fi-Yang-Pan",
            "title": {
                "fragments": [],
                "text": "Estimating Location Using Wi-Fi"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "This department presents the results of the first Data Mining Contest held at the 2007 International Conference on Data Mining."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Intelligent Systems"
            },
            "year": 2008
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 161,
                                "start": 157
                            }
                        ],
                        "text": "Transfer Learning Approaches Brief Description Instance-transfer To re-weight some labeled data in the source domain for use in the target domain [6], [28], [29], [30], [31], [24], [32], [33], [34], [35]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 119,
                                "start": 115
                            }
                        ],
                        "text": "The first context can be referred to as instance-based transferlearning (or instance-transfer) approach [6], [28], [29], [30], [31], [24], [32], [33], [34], [35], which assumes that certain parts of the data in the source domain can be reused for learning in the target domain by re-weighting."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 166,
                                "start": 162
                            }
                        ],
                        "text": "For more information on importance sampling and re-weighting methods for covariate shift or sample selection bias, readers can refer to a recently published book [29] by Quionero-Candela et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Shift in Machine Learning"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34308834"
                        ],
                        "name": "G. Engel",
                        "slug": "G.-Engel",
                        "structuredName": {
                            "firstName": "Gerald",
                            "lastName": "Engel",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Engel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46658944"
                        ],
                        "name": "D. Cooper",
                        "slug": "D.-Cooper",
                        "structuredName": {
                            "firstName": "Deborah",
                            "lastName": "Cooper",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Cooper"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1756014"
                        ],
                        "name": "Carl K. Chang",
                        "slug": "Carl-K.-Chang",
                        "structuredName": {
                            "firstName": "Carl",
                            "lastName": "Chang",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Carl K. Chang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2116400329"
                        ],
                        "name": "Michael R. Williams",
                        "slug": "Michael-R.-Williams",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Williams",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael R. Williams"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "66722930"
                        ],
                        "name": "Christina M. Schober",
                        "slug": "Christina-M.-Schober",
                        "structuredName": {
                            "firstName": "Christina",
                            "lastName": "Schober",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christina M. Schober"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712133"
                        ],
                        "name": "Y. Zorian",
                        "slug": "Y.-Zorian",
                        "structuredName": {
                            "firstName": "Yervant",
                            "lastName": "Zorian",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Zorian"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1453031811"
                        ],
                        "name": "M. Varanasi",
                        "slug": "M.-Varanasi",
                        "structuredName": {
                            "firstName": "Murali",
                            "lastName": "Varanasi",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Varanasi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143960253"
                        ],
                        "name": "S. White",
                        "slug": "S.-White",
                        "structuredName": {
                            "firstName": "Stephanie",
                            "lastName": "White",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. White"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35193279"
                        ],
                        "name": "S. Seidman",
                        "slug": "S.-Seidman",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Seidman",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Seidman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3110392"
                        ],
                        "name": "R. Kasturi",
                        "slug": "R.-Kasturi",
                        "structuredName": {
                            "firstName": "Rangachar",
                            "lastName": "Kasturi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Kasturi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2974860"
                        ],
                        "name": "G. Hoffnagle",
                        "slug": "G.-Hoffnagle",
                        "structuredName": {
                            "firstName": "Gene",
                            "lastName": "Hoffnagle",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Hoffnagle"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2587829"
                        ],
                        "name": "S. Diamond",
                        "slug": "S.-Diamond",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Diamond",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Diamond"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144554222"
                        ],
                        "name": "O. N. Garcia",
                        "slug": "O.-N.-Garcia",
                        "structuredName": {
                            "firstName": "Oscar",
                            "lastName": "Garcia",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. N. Garcia"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1793680"
                        ],
                        "name": "D. Carver",
                        "slug": "D.-Carver",
                        "structuredName": {
                            "firstName": "Doris",
                            "lastName": "Carver",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Carver"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "69382766"
                        ],
                        "name": "D. Hennage",
                        "slug": "D.-Hennage",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Hennage",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Hennage"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2057061677"
                        ],
                        "name": "Mark A. Grant",
                        "slug": "Mark-A.-Grant",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Grant",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mark A. Grant"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2071664429"
                        ],
                        "name": "Michel Israel",
                        "slug": "Michel-Israel",
                        "structuredName": {
                            "firstName": "Michel",
                            "lastName": "Israel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michel Israel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144041399"
                        ],
                        "name": "R. Kapur",
                        "slug": "R.-Kapur",
                        "structuredName": {
                            "firstName": "Rohit",
                            "lastName": "Kapur",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Kapur"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1682743"
                        ],
                        "name": "K. Swigger",
                        "slug": "K.-Swigger",
                        "structuredName": {
                            "firstName": "Kathleen",
                            "lastName": "Swigger",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Swigger"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145146663"
                        ],
                        "name": "M. Takizawa",
                        "slug": "M.-Takizawa",
                        "structuredName": {
                            "firstName": "Makoto",
                            "lastName": "Takizawa",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Takizawa"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "89715335"
                        ],
                        "name": "M. Christensen",
                        "slug": "M.-Christensen",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Christensen",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Christensen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145877549"
                        ],
                        "name": "A. Clements",
                        "slug": "A.-Clements",
                        "structuredName": {
                            "firstName": "Alan",
                            "lastName": "Clements",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Clements"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3018222"
                        ],
                        "name": "Annie Combelles",
                        "slug": "Annie-Combelles",
                        "structuredName": {
                            "firstName": "Annie",
                            "lastName": "Combelles",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Annie Combelles"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39449921"
                        ],
                        "name": "A. Gates",
                        "slug": "A.-Gates",
                        "structuredName": {
                            "firstName": "Ann",
                            "lastName": "Gates",
                            "middleNames": [
                                "Q."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Gates"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3003427"
                        ],
                        "name": "J. Isaak",
                        "slug": "J.-Isaak",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Isaak",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Isaak"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32147354"
                        ],
                        "name": "S. Mengel",
                        "slug": "S.-Mengel",
                        "structuredName": {
                            "firstName": "Susan",
                            "lastName": "Mengel",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Mengel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144047708"
                        ],
                        "name": "J. Bacon",
                        "slug": "J.-Bacon",
                        "structuredName": {
                            "firstName": "Jean",
                            "lastName": "Bacon",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Bacon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2416462"
                        ],
                        "name": "G. Cybenko",
                        "slug": "G.-Cybenko",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Cybenko",
                            "middleNames": [
                                "V."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Cybenko"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1789015"
                        ],
                        "name": "R. Kemmerer",
                        "slug": "R.-Kemmerer",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Kemmerer",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Kemmerer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "65893547"
                        ],
                        "name": "I. Mimura",
                        "slug": "I.-Mimura",
                        "structuredName": {
                            "firstName": "Itaru",
                            "lastName": "Mimura",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Mimura"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "70545629"
                        ],
                        "name": "Watanabe Building",
                        "slug": "Watanabe-Building",
                        "structuredName": {
                            "firstName": "Watanabe",
                            "lastName": "Building",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Watanabe Building"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1409191904"
                        ],
                        "name": "Ieee Officers",
                        "slug": "Ieee-Officers",
                        "structuredName": {
                            "firstName": "Ieee",
                            "lastName": "Officers",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ieee Officers"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145343371"
                        ],
                        "name": "W. C. Anderson",
                        "slug": "W.-C.-Anderson",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Anderson",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. C. Anderson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1809013"
                        ],
                        "name": "M. Lightner",
                        "slug": "M.-Lightner",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Lightner",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Lightner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3020779"
                        ],
                        "name": "A. Winston",
                        "slug": "A.-Winston",
                        "structuredName": {
                            "firstName": "Arthur",
                            "lastName": "Winston",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Winston"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1401784737"
                        ],
                        "name": "M. El-Hawary",
                        "slug": "M.-El-Hawary",
                        "structuredName": {
                            "firstName": "Mohamed",
                            "lastName": "El-Hawary",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. El-Hawary"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "70397400"
                        ],
                        "name": "Joseph V. Lillie",
                        "slug": "Joseph-V.-Lillie",
                        "structuredName": {
                            "firstName": "Joseph",
                            "lastName": "Lillie",
                            "middleNames": [
                                "V."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Joseph V. Lillie"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143844664"
                        ],
                        "name": "M. Kam",
                        "slug": "M.-Kam",
                        "structuredName": {
                            "firstName": "Moshe",
                            "lastName": "Kam",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Kam"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2667435"
                        ],
                        "name": "L. Jamieson",
                        "slug": "L.-Jamieson",
                        "structuredName": {
                            "firstName": "Leah",
                            "lastName": "Jamieson",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Jamieson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50820911"
                        ],
                        "name": "M. Apter",
                        "slug": "M.-Apter",
                        "structuredName": {
                            "firstName": "Marc",
                            "lastName": "Apter",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Apter"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "70468344"
                        ],
                        "name": "J. Carlo",
                        "slug": "J.-Carlo",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Carlo",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Carlo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1420111125"
                        ],
                        "name": "R. Wyndrum",
                        "slug": "R.-Wyndrum",
                        "structuredName": {
                            "firstName": "Ralph",
                            "lastName": "Wyndrum",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Wyndrum"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145271058"
                        ],
                        "name": "G. Alphonse",
                        "slug": "G.-Alphonse",
                        "structuredName": {
                            "firstName": "G.",
                            "lastName": "Alphonse",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Alphonse"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 209,
                                "start": 205
                            }
                        ],
                        "text": "Traditional data mining and machine learning algorithms make predictions on the future data using statistical models that are trained on previously collected labeled or unlabeled training data [11], [12], [13]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 62412225,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a44c9f5658955781b439312340c5e0e7b489931a",
            "isKey": false,
            "numCitedBy": 561,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "TRANSACTIONS-ON-KNOWLEDGE-AND-DATA-ENGINEERING-Engel-Cooper",
            "title": {
                "fragments": [],
                "text": "TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2005
        },
        {
            "authors": [],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 199,
                                "start": 195
                            }
                        ],
                        "text": "The latter case of thetransductive transfer learning setting is related to domain adaptation for knowledge transfer in text classification [23] and sample selection bias [24] or co-variate shift [25], whose assumptions are"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 160001139,
            "fieldsOfStudy": [
                "Economics"
            ],
            "id": "5e338e2345d89f2729a8744bcd4da319032d5758",
            "isKey": false,
            "numCitedBy": 413,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Journal-of-Statistical-Planning-and-Inference",
            "title": {
                "fragments": [],
                "text": "Journal of Statistical Planning and Inference"
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "corpusId": 218479160,
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Coordinated Adaptive Robust Contouring Control of an Industrial Biaxial Precision Gantry with C"
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Bridged re fi nement for transfer learning , \u201d in 11 th European Conference on Principles and Practice of Knowledge Discovery in Databases"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 21 st Annual Conference on Neural Information Processing Systems"
            },
            "year": 2008
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "For more information on this or any other computing topic, please visit our Digital Library at www.computer.org/publications/dlib"
            },
            "venue": {
                "fragments": [],
                "text": "For more information on this or any other computing topic, please visit our Digital Library at www.computer.org/publications/dlib"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Vapnik, Statistical Learning Theory"
            },
            "venue": {
                "fragments": [],
                "text": "Vapnik, Statistical Learning Theory"
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 46,
                                "start": 42
                            }
                        ],
                        "text": "Arnold et al. [58] proposed to use transductive transfer learning methods to solve name-entity recognition problems."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Translated Learning"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. 21st Ann. Conf. Neural Information Processing Systems"
            },
            "year": 2008
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Spectral domaintransfer learning"
            },
            "venue": {
                "fragments": [],
                "text": "inProceedings of the 14th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining  . Las Vegas, Nevada: ACM, August 2008, pp. 488\u2013496."
            },
            "year": 2008
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Self - taught clustering , \u201d in Proceedings of the 25 th International Conference of Machine Learning"
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 67,
            "methodology": 23,
            "result": 1
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 96,
        "totalPages": 10
    },
    "page_url": "https://www.semanticscholar.org/paper/A-Survey-on-Transfer-Learning-Pan-Yang/a25fbcbbae1e8f79c4360d26aa11a3abf1a11972?sort=total-citations"
}