{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1400556488"
                        ],
                        "name": "Aharon Bar-Hillel",
                        "slug": "Aharon-Bar-Hillel",
                        "structuredName": {
                            "firstName": "Aharon",
                            "lastName": "Bar-Hillel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Aharon Bar-Hillel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1774536"
                        ],
                        "name": "T. Hertz",
                        "slug": "T.-Hertz",
                        "structuredName": {
                            "firstName": "Tomer",
                            "lastName": "Hertz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Hertz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1789171"
                        ],
                        "name": "D. Weinshall",
                        "slug": "D.-Weinshall",
                        "structuredName": {
                            "firstName": "Daphna",
                            "lastName": "Weinshall",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Weinshall"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 125,
                                "start": 121
                            }
                        ],
                        "text": "Unlike in mcl, the recurring elements in these methods are fairly simple, including edge fragments [11], Gaussian models [12], or image fragments [13]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 201,
                                "start": 197
                            }
                        ],
                        "text": "An alternative approach involves searching for repeatedly occurring elements using different criteria such as frequency of appearance in the training data [11], lowering an empirical risk function [12], or increasing mutual information [13]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1327744,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c93b9fa05a96b241135c83ed117415203d170a36",
            "isKey": false,
            "numCitedBy": 50,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a new technique for object class recognition, which learns a generative appearance model in a discriminative manner. The technique is based on the intermediate representation of an image as a set of patches, which are extracted using an interest point detector. The learning problem becomes an instance of supervised learning from sets of unordered features. In order to solve this problem, we designed a classifier based on a simple, part based, generative object model. Only the appearance of each part is modeled. When learning the model parameters, we use a discriminative boosting algorithm which minimizes the loss of the training error directly. The models thus learnt have clear probabilistic semantics, and also maintain good classification performance. The performance of the algorithm has been tested using publicly available benchmark data, and shown to be comparable to other state of the art algorithms for this task; our main advantage in these comparisons is speed (order of magnitudes faster) and scalability."
            },
            "slug": "Object-class-recognition-by-boosting-a-part-based-Bar-Hillel-Hertz",
            "title": {
                "fragments": [],
                "text": "Object class recognition by boosting a part-based model"
            },
            "tldr": {
                "abstractSimilarityScore": 89,
                "text": "A new technique for object class recognition is proposed, which learns a generative appearance model in a discriminative manner, based on the intermediate representation of an image as a set of patches, which are extracted using an interest point detector."
            },
            "venue": {
                "fragments": [],
                "text": "2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05)"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1731948"
                        ],
                        "name": "Paul A. Viola",
                        "slug": "Paul-A.-Viola",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Viola",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Paul A. Viola"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144189092"
                        ],
                        "name": "John C. Platt",
                        "slug": "John-C.-Platt",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Platt",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "John C. Platt"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2109292017"
                        ],
                        "name": "Cha Zhang",
                        "slug": "Cha-Zhang",
                        "structuredName": {
                            "firstName": "Cha",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Cha Zhang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 276,
                                "start": 265
                            }
                        ],
                        "text": "In order to learn component classifiers we turn to weakly supervised learning methods developed for object detection, where positive training images contain the object of interest, but, unlike the fully supervised case, the object location in each image is unknown [4, 17, 19]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[19] introduced a boosting variant of mil called mil-boost which is effective and robust."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 42,
                                "start": 38
                            }
                        ],
                        "text": "Also, consistent with the findings of [19], mil outperformed labeled even though it was trained in a weakly supervised manner (presumably our labeling is imperfect)."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                }
            ],
            "corpusId": 7564408,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "521768f7772163bc7c57ae2c9855889abb747fbb",
            "isKey": false,
            "numCitedBy": 772,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "A good image object detection algorithm is accurate, fast, and does not require exact locations of objects in a training set. We can create such an object detector by taking the architecture of the Viola-Jones detector cascade and training it with a new variant of boosting that we call MIL-Boost. MILBoost uses cost functions from the Multiple Instance Learning literature combined with the AnyBoost framework. We adapt the feature selection criterion of MILBoost to optimize the performance of the Viola-Jones cascade. Experiments show that the detection rate is up to 1.6 times better using MILBoost. This increased detection rate shows the advantage of simultaneously learning the locations and scales of the objects in the training set along with the parameters of the classifier."
            },
            "slug": "Multiple-Instance-Boosting-for-Object-Detection-Viola-Platt",
            "title": {
                "fragments": [],
                "text": "Multiple Instance Boosting for Object Detection"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "MILBoost adapts the feature selection criterion of MILBoost to optimize the performance of the Viola-Jones cascade to show the advantage of simultaneously learning the locations and scales of the objects in the training set along with the parameters of the classifier."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2124866301"
                        ],
                        "name": "A. Mohan",
                        "slug": "A.-Mohan",
                        "structuredName": {
                            "firstName": "Anuj",
                            "lastName": "Mohan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Mohan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145030811"
                        ],
                        "name": "C. Papageorgiou",
                        "slug": "C.-Papageorgiou",
                        "structuredName": {
                            "firstName": "Constantine",
                            "lastName": "Papageorgiou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Papageorgiou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685292"
                        ],
                        "name": "T. Poggio",
                        "slug": "T.-Poggio",
                        "structuredName": {
                            "firstName": "Tomaso",
                            "lastName": "Poggio",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Poggio"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 115,
                                "start": 108
                            }
                        ],
                        "text": "One approach involves designing part detectors by hand [8] or providing a system with labeled part examples [9, 10]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2559322,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "448bd4e124175ad358078a7b930ecad994c97812",
            "isKey": false,
            "numCitedBy": 1137,
            "numCiting": 58,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a general example-based framework for detecting objects in static images by components. The technique is demonstrated by developing a system that locates people in cluttered scenes. The system is structured with four distinct example-based detectors that are trained to separately find the four components of the human body: the head, legs, left arm, and right arm. After ensuring that these components are present in the proper geometric configuration, a second example-based classifier combines the results of the component detectors to classify a pattern as either a \"person\" or a \"nonperson.\" We call this type of hierarchical architecture, in which learning occurs at multiple stages, an adaptive combination of classifiers (ACC). We present results that show that this system performs significantly better than a similar full-body person detector. This suggests that the improvement in performance is due to the component-based approach and the ACC data classification architecture. The algorithm is also more robust than the full-body person detection method in that it is capable of locating partially occluded views of people and people whose body parts have little contrast with the background."
            },
            "slug": "Example-Based-Object-Detection-in-Images-by-Mohan-Papageorgiou",
            "title": {
                "fragments": [],
                "text": "Example-Based Object Detection in Images by Components"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "Results suggest that the improvement in performance is due to the component-based approach and the ACC data classification architecture, which is capable of locating partially occluded views of people and people whose body parts have little contrast with the background."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2797063"
                        ],
                        "name": "S. Agarwal",
                        "slug": "S.-Agarwal",
                        "structuredName": {
                            "firstName": "Shivani",
                            "lastName": "Agarwal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Agarwal"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144590225"
                        ],
                        "name": "D. Roth",
                        "slug": "D.-Roth",
                        "structuredName": {
                            "firstName": "Dan",
                            "lastName": "Roth",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Roth"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 262977,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3d081b80b1850df9b1e382f97a7a244890d6485e",
            "isKey": false,
            "numCitedBy": 638,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "We present an approach for learning to detect objects in still gray images, that is based on a sparse, part-based representation of objects. A vocabulary of information-rich object parts is automatically constructed from a set of sample images of the object class of interest. Images are then represented using parts from this vocabulary, along with spatial relations observed among them. Based on this representation, a feature-efficient learning algorithm is used to learn to detect instances of the object class. The framework developed can be applied to any object with distinguishable parts in a relatively fixed spatial configuration. We report experiments on images of side views of cars. Our experiments show that the method achieves high detection accuracy on a difficult test set of real-world images, and is highly robust to partial occlusion and background variation.In addition, we discuss and offer solutions to several methodological issues that are significant for the research community to be able to evaluate object detection approaches."
            },
            "slug": "Learning-a-Sparse-Representation-for-Object-Agarwal-Roth",
            "title": {
                "fragments": [],
                "text": "Learning a Sparse Representation for Object Detection"
            },
            "tldr": {
                "abstractSimilarityScore": 65,
                "text": "An approach for learning to detect objects in still gray images, that is based on a sparse, part-based representation of objects, that achieves high detection accuracy on a difficult test set of real-world images, and is highly robust to partial occlusion and background variation."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2821130"
                        ],
                        "name": "David J. Crandall",
                        "slug": "David-J.-Crandall",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Crandall",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David J. Crandall"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1713089"
                        ],
                        "name": "D. Huttenlocher",
                        "slug": "D.-Huttenlocher",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Huttenlocher",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Huttenlocher"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 52,
                                "start": 41
                            }
                        ],
                        "text": "the constellation model and its variants [16, 4, 17] have proven robust and capable of operating with little training data."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 276,
                                "start": 265
                            }
                        ],
                        "text": "In order to learn component classifiers we turn to weakly supervised learning methods developed for object detection, where positive training images contain the object of interest, but, unlike the fully supervised case, the object location in each image is unknown [4, 17, 19]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 13539342,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "dbf98990383ee38413f55c831f89095a1b009420",
            "isKey": false,
            "numCitedBy": 210,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we investigate a new method of learning part-based models for visual object recognition, from training data that only provides information about class membership (and not object location or configuration). This method learns both a model of local part appearance and a model of the spatial relations between those parts. In contrast, other work using such a weakly supervised learning paradigm has not considered the problem of simultaneously learning appearance and spatial models. Some of these methods use a \u201cbag\u201d model where only part appearance is considered whereas other methods learn spatial models but only given the output of a particular feature detector. Previous techniques for learning both part appearance and spatial relations have instead used a highly supervised learning process that provides substantial information about object part location. We show that our weakly supervised technique produces better results than these previous highly supervised methods. Moreover, we investigate the degree to which both richer spatial models and richer appearance models are helpful in improving recognition performance. Our results show that while both spatial and appearance information can be useful, the effect on performance depends substantially on the particular object class and on the difficulty of the test dataset."
            },
            "slug": "Weakly-Supervised-Learning-of-Part-Based-Spatial-Crandall-Huttenlocher",
            "title": {
                "fragments": [],
                "text": "Weakly Supervised Learning of Part-Based Spatial Models for Visual Object Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 83,
                "text": "This paper investigates a new method of learning part-based models for visual object recognition, from training data that only provides information about class membership (and not object location or configuration), and shows that this weakly supervised technique produces better results."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685089"
                        ],
                        "name": "Pedro F. Felzenszwalb",
                        "slug": "Pedro-F.-Felzenszwalb",
                        "structuredName": {
                            "firstName": "Pedro",
                            "lastName": "Felzenszwalb",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Pedro F. Felzenszwalb"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145689002"
                        ],
                        "name": "David A. McAllester",
                        "slug": "David-A.-McAllester",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "McAllester",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David A. McAllester"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1770537"
                        ],
                        "name": "D. Ramanan",
                        "slug": "D.-Ramanan",
                        "structuredName": {
                            "firstName": "Deva",
                            "lastName": "Ramanan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Ramanan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 40,
                                "start": 36
                            }
                        ],
                        "text": "Most closely related to our work is [18], which uses a formalism called latent SVMs to simultaneously learn part and object models."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 58,
                                "start": 54
                            }
                        ],
                        "text": "We emphasize that, as far as we are aware, aside from [18] mcl is the first part-based method that uses rich part appearance models without relying on part labels during training."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14327585,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "860a9d55d87663ca88e74b3ca357396cd51733d0",
            "isKey": false,
            "numCitedBy": 2616,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes a discriminatively trained, multiscale, deformable part model for object detection. Our system achieves a two-fold improvement in average precision over the best performance in the 2006 PASCAL person detection challenge. It also outperforms the best results in the 2007 challenge in ten out of twenty categories. The system relies heavily on deformable parts. While deformable part models have become quite popular, their value had not been demonstrated on difficult benchmarks such as the PASCAL challenge. Our system also relies heavily on new methods for discriminative training. We combine a margin-sensitive approach for data mining hard negative examples with a formalism we call latent SVM. A latent SVM, like a hidden CRF, leads to a non-convex training problem. However, a latent SVM is semi-convex and the training problem becomes convex once latent information is specified for the positive examples. We believe that our training methods will eventually make possible the effective use of more latent information such as hierarchical (grammar) models and models involving latent three dimensional pose."
            },
            "slug": "A-discriminatively-trained,-multiscale,-deformable-Felzenszwalb-McAllester",
            "title": {
                "fragments": [],
                "text": "A discriminatively trained, multiscale, deformable part model"
            },
            "tldr": {
                "abstractSimilarityScore": 87,
                "text": "A discriminatively trained, multiscale, deformable part model for object detection, which achieves a two-fold improvement in average precision over the best performance in the 2006 PASCAL person detection challenge and outperforms the best results in the 2007 challenge in ten out of twenty categories."
            },
            "venue": {
                "fragments": [],
                "text": "2008 IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2276554"
                        ],
                        "name": "R. Fergus",
                        "slug": "R.-Fergus",
                        "structuredName": {
                            "firstName": "Rob",
                            "lastName": "Fergus",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Fergus"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1690922"
                        ],
                        "name": "P. Perona",
                        "slug": "P.-Perona",
                        "structuredName": {
                            "firstName": "Pietro",
                            "lastName": "Perona",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Perona"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688869"
                        ],
                        "name": "Andrew Zisserman",
                        "slug": "Andrew-Zisserman",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Zisserman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Zisserman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 124,
                                "start": 121
                            }
                        ],
                        "text": "different types of patch descriptors have been widely used as the basis of many successful object recognition algorithms [5]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 5745749,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "62837ab473124ea43cb8d7c6a4b4ee0f6f14e8c5",
            "isKey": false,
            "numCitedBy": 2487,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a method to learn and recognize object class models from unlabeled and unsegmented cluttered scenes in a scale invariant manner. Objects are modeled as flexible constellations of parts. A probabilistic representation is used for all aspects of the object: shape, appearance, occlusion and relative scale. An entropy-based feature detector is used to select regions and their scale within the image. In learning the parameters of the scale-invariant object model are estimated. This is done using expectation-maximization in a maximum-likelihood setting. In recognition, this model is used in a Bayesian manner to classify images. The flexible nature of the model is demonstrated by excellent results over a range of datasets including geometrically constrained classes (e.g. faces, cars) and flexible objects (such as animals)."
            },
            "slug": "Object-class-recognition-by-unsupervised-learning-Fergus-Perona",
            "title": {
                "fragments": [],
                "text": "Object class recognition by unsupervised scale-invariant learning"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The flexible nature of the model is demonstrated by excellent results over a range of datasets including geometrically constrained classes (e.g. faces, cars) and flexible objects (such as animals)."
            },
            "venue": {
                "fragments": [],
                "text": "2003 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2003. Proceedings."
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2490700"
                        ],
                        "name": "Boris Babenko",
                        "slug": "Boris-Babenko",
                        "structuredName": {
                            "firstName": "Boris",
                            "lastName": "Babenko",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Boris Babenko"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144035504"
                        ],
                        "name": "Z. Tu",
                        "slug": "Z.-Tu",
                        "structuredName": {
                            "firstName": "Zhuowen",
                            "lastName": "Tu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Z. Tu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50172592"
                        ],
                        "name": "Serge J. Belongie",
                        "slug": "Serge-J.-Belongie",
                        "structuredName": {
                            "firstName": "Serge",
                            "lastName": "Belongie",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Serge J. Belongie"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15366005,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a03cfd5c0059825c87d51f5dbf12f8a76fe9ff60",
            "isKey": false,
            "numCitedBy": 96,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "In object recognition in general and in face detection in par- ticular, data alignment is necessary to achieve good classification results with certain statistical learning approaches such as Viola-Jones. Data can be aligned in one of two ways: (1) by separating the data into coherent groups and training separate classifiers for each; (2) by adjusting training samples so they lie in correspondence. If done manually, both procedures are labor intensive and can significantly add to the cost of labeling. In this paper we present a unified boosting framework for simultaneous learn- ing and alignment. We present a novel boosting algorithm for Multiple Pose Learning (mpl), where the goal is to simultaneously split data into groups and train classifiers for each. We also review Multiple Instance Learning (mil), and in particular mil-boost, and describe how to use it to simultaneously train a classifier and bring data into correspondence. We show results on variations of LFW and MNIST, demonstrating the potential of these approaches."
            },
            "slug": "Simultaneous-Learning-and-Alignment:-Multi-Instance-Babenko-Tu",
            "title": {
                "fragments": [],
                "text": "Simultaneous Learning and Alignment: Multi-Instance and Multi-Pose Learning ?"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A unified boosting framework for simultaneous learn- ing and alignment is presented and a novel boosting algorithm for Multiple Pose Learning (mpl) is presented, where the goal is to simultaneously split data into groups and train classifiers for each."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2110604335"
                        ],
                        "name": "Markus Weber",
                        "slug": "Markus-Weber",
                        "structuredName": {
                            "firstName": "Markus",
                            "lastName": "Weber",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Markus Weber"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1678311"
                        ],
                        "name": "M. Welling",
                        "slug": "M.-Welling",
                        "structuredName": {
                            "firstName": "Max",
                            "lastName": "Welling",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Welling"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1690922"
                        ],
                        "name": "P. Perona",
                        "slug": "P.-Perona",
                        "structuredName": {
                            "firstName": "Pietro",
                            "lastName": "Perona",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Perona"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 59,
                                "start": 56
                            }
                        ],
                        "text": "The patches can be vector quantized to form \u2018codebooks\u2019 [4], and an image can then be represented using a \u2018bag of words\u2019 model [6]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 52,
                                "start": 41
                            }
                        ],
                        "text": "the constellation model and its variants [16, 4, 17] have proven robust and capable of operating with little training data."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 276,
                                "start": 265
                            }
                        ],
                        "text": "In order to learn component classifiers we turn to weakly supervised learning methods developed for object detection, where positive training images contain the object of interest, but, unlike the fully supervised case, the object location in each image is unknown [4, 17, 19]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 129,
                                "start": 122
                            }
                        ],
                        "text": "A simple but effective method of extracting parts is to crop small image patches, either using an interest point operator [4, 14] or by dense sampling [6]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 8970876,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1cf1527807ebb16020b04d4166e7ba8d27652302",
            "isKey": false,
            "numCitedBy": 757,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a method to learn object class models from unlabeled and unsegmented cluttered scenes for the purpose of visual object recognition. We focus on a particular type of model where objects are represented as flexible constellations of rigid parts (features). The variability within a class is represented by a joint probability density function (pdf) on the shape of the constellation and the output of part detectors. In a first stage, the method automatically identifies distinctive parts in the training set by applying a clustering algorithm to patterns selected by an interest operator. It then learns the statistical shape model using expectation maximization. The method achieves very good classification results on human faces and rear views of cars."
            },
            "slug": "Unsupervised-Learning-of-Models-for-Recognition-Weber-Welling",
            "title": {
                "fragments": [],
                "text": "Unsupervised Learning of Models for Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 70,
                "text": "A method to learn object class models from unlabeled and unsegmented cluttered cluttered scenes for the purpose of visual object recognition that achieves very good classification results on human faces and rear views of cars."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1789756"
                        ],
                        "name": "B. Leibe",
                        "slug": "B.-Leibe",
                        "structuredName": {
                            "firstName": "B.",
                            "lastName": "Leibe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Leibe"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1732672"
                        ],
                        "name": "A. Leonardis",
                        "slug": "A.-Leonardis",
                        "structuredName": {
                            "firstName": "Ale\u0161",
                            "lastName": "Leonardis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Leonardis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48920094"
                        ],
                        "name": "B. Schiele",
                        "slug": "B.-Schiele",
                        "structuredName": {
                            "firstName": "Bernt",
                            "lastName": "Schiele",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Schiele"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 105,
                                "start": 101
                            }
                        ],
                        "text": "Spatial information can be encoded using pairwise relationships [14] or with a spatial voting scheme [15]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14144539,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1c41c1f86b92a8c011e0324d90624d539a849b8b",
            "isKey": false,
            "numCitedBy": 1060,
            "numCiting": 95,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract\nThis paper presents a novel method for detecting and localizing objects of a visual category in cluttered real-world scenes. Our approach considers object categorization and figure-ground segmentation as two interleaved processes that closely collaborate towards a common goal. As shown in our work, the tight coupling between those two processes allows them to benefit from each other and improve the combined performance.\n\nThe core part of our approach is a highly flexible learned representation for object shape that can combine the information observed on different training examples in a probabilistic extension of the Generalized Hough Transform. The resulting approach can detect categorical objects in novel images and automatically infer a probabilistic segmentation from the recognition result. This segmentation is then in turn used to again improve recognition by allowing the system to focus its efforts on object pixels and to discard misleading influences from the background. Moreover, the information from where in the image a hypothesis draws its support is employed in an MDL based hypothesis verification stage to resolve ambiguities between overlapping hypotheses and factor out the effects of partial occlusion.\n\nAn extensive evaluation on several large data sets shows that the proposed system is applicable to a range of different object categories, including both rigid and articulated objects. In addition, its flexible representation allows it to achieve competitive object detection performance already from training sets that are between one and two orders of magnitude smaller than those used in comparable systems.\n"
            },
            "slug": "Robust-Object-Detection-with-Interleaved-and-Leibe-Leonardis",
            "title": {
                "fragments": [],
                "text": "Robust Object Detection with Interleaved Categorization and Segmentation"
            },
            "tldr": {
                "abstractSimilarityScore": 57,
                "text": "A novel method for detecting and localizing objects of a visual category in cluttered real-world scenes that is applicable to a range of different object categories, including both rigid and articulated objects and able to achieve competitive object detection performance from training sets that are between one and two orders of magnitude smaller than those used in comparable systems."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2109292017"
                        ],
                        "name": "Cha Zhang",
                        "slug": "Cha-Zhang",
                        "structuredName": {
                            "firstName": "Cha",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Cha Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1731948"
                        ],
                        "name": "Paul A. Viola",
                        "slug": "Paul-A.-Viola",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Viola",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Paul A. Viola"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 77,
                                "start": 73
                            }
                        ],
                        "text": "For comparison we also implemented the SoftCascade approach described in [30], using the same candidate Haar features we use in mcl."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 15830034,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9a21dd3aa138f4cb494f01400f9be8a0286d3340",
            "isKey": false,
            "numCitedBy": 147,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "Cascade detectors have been shown to operate extremely rapidly, with high accuracy, and have important applications such as face detection. Driven by this success, cascade learning has been an area of active research in recent years. Nevertheless, there are still challenging technical problems during the training process of cascade detectors. In particular, determining the optimal target detection rate for each stage of the cascade remains an unsolved issue. In this paper, we propose the multiple instance pruning (MIP) algorithm for soft cascades. This algorithm computes a set of thresholds which aggressively terminate computation with no reduction in detection rate or increase in false positive rate on the training dataset. The algorithm is based on two key insights: i) examples that are destined to be rejected by the complete classifier can be safely pruned early; ii) face detection is a multiple instance learning problem. The MIP process is fully automatic and requires no assumptions of probability distributions, statistical independence, or ad hoc intermediate rejection targets. Experimental results on the MIT+CMU dataset demonstrate significant performance advantages."
            },
            "slug": "Multiple-Instance-Pruning-For-Learning-Efficient-Zhang-Viola",
            "title": {
                "fragments": [],
                "text": "Multiple-Instance Pruning For Learning Efficient Cascade Detectors"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "The multiple instance pruning (MIP) algorithm for soft cascades is proposed, which computes a set of thresholds which aggressively terminate computation with no reduction in detection rate or increase in false positive rate on the training dataset."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712041"
                        ],
                        "name": "K. Mikolajczyk",
                        "slug": "K.-Mikolajczyk",
                        "structuredName": {
                            "firstName": "Krystian",
                            "lastName": "Mikolajczyk",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Mikolajczyk"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2462253"
                        ],
                        "name": "C. Schmid",
                        "slug": "C.-Schmid",
                        "structuredName": {
                            "firstName": "Cordelia",
                            "lastName": "Schmid",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Schmid"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688869"
                        ],
                        "name": "Andrew Zisserman",
                        "slug": "Andrew-Zisserman",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Zisserman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Zisserman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 115,
                                "start": 108
                            }
                        ],
                        "text": "One approach involves designing part detectors by hand [8] or providing a system with labeled part examples [9, 10]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 3870070,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f9cc6155cd69023a736a7b8f8680bcd6232c840e",
            "isKey": false,
            "numCitedBy": 764,
            "numCiting": 47,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a novel method for human detection in single images which can detect full bodies as well as close-up views in the presence of clutter and occlusion. Humans are modeled as flexible assemblies of parts, and robust part detection is the key to the approach. The parts are represented by co-occurrences of local features which captures the spatial layout of the partrsquos appearance. Feature selection and the part detectors are learnt from training images using AdaBoost. The detection algorithm is very efficient as (i) all part detectors use the same initial features, (ii) a coarse-to-fine cascade approach is used for part detection, (iii) a part assembly strategy reduces the number of spurious detections and the search space. The results outperform existing human detectors."
            },
            "slug": "Human-Detection-Based-on-a-Probabilistic-Assembly-Mikolajczyk-Schmid",
            "title": {
                "fragments": [],
                "text": "Human Detection Based on a Probabilistic Assembly of Robust Part Detectors"
            },
            "tldr": {
                "abstractSimilarityScore": 92,
                "text": "A novel method for human detection in single images which can detect full bodies as well as close-up views in the presence of clutter and occlusion is described."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2570029"
                        ],
                        "name": "P. Sabzmeydani",
                        "slug": "P.-Sabzmeydani",
                        "structuredName": {
                            "firstName": "Payam",
                            "lastName": "Sabzmeydani",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Sabzmeydani"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "10771328"
                        ],
                        "name": "Greg Mori",
                        "slug": "Greg-Mori",
                        "structuredName": {
                            "firstName": "Greg",
                            "lastName": "Mori",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Greg Mori"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 13420116,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b09d132046f3b21f98206eb514ebfcbd73f32513",
            "isKey": false,
            "numCitedBy": 356,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we address the problem of detecting pedestrians in still images. We introduce an algorithm for learning shapelet features, a set of mid-level features. These features are focused on local regions of the image and are built from low-level gradient information that discriminates between pedestrian and non-pedestrian classes. Using Ad-aBoost, these shapelet features are created as a combination of oriented gradient responses. To train the final classifier, we use AdaBoost for a second time to select a subset of our learned shapelets. By first focusing locally on smaller feature sets, our algorithm attempts to harvest more useful information than by examining all the low-level features together. We present quantitative results demonstrating the effectiveness of our algorithm. In particular, we obtain an error rate 14 percentage points lower (at 10-6 FPPW) than the previous state of the art detector of Dalal and Triggs on the INRIA dataset."
            },
            "slug": "Detecting-Pedestrians-by-Learning-Shapelet-Features-Sabzmeydani-Mori",
            "title": {
                "fragments": [],
                "text": "Detecting Pedestrians by Learning Shapelet Features"
            },
            "tldr": {
                "abstractSimilarityScore": 56,
                "text": "This paper introduces an algorithm for learning shapelet features, a set of mid-level features that are built from low-level gradient information that discriminates between pedestrian and non-pedestrian classes on the INRIA dataset."
            },
            "venue": {
                "fragments": [],
                "text": "2007 IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1398995671"
                        ],
                        "name": "Michel Vidal-Naquet",
                        "slug": "Michel-Vidal-Naquet",
                        "structuredName": {
                            "firstName": "Michel",
                            "lastName": "Vidal-Naquet",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michel Vidal-Naquet"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1743045"
                        ],
                        "name": "S. Ullman",
                        "slug": "S.-Ullman",
                        "structuredName": {
                            "firstName": "Shimon",
                            "lastName": "Ullman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Ullman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 150,
                                "start": 146
                            }
                        ],
                        "text": "Unlike in mcl, the recurring elements in these methods are fairly simple, including edge fragments [11], Gaussian models [12], or image fragments [13]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 240,
                                "start": 236
                            }
                        ],
                        "text": "An alternative approach involves searching for repeatedly occurring elements using different criteria such as frequency of appearance in the training data [11], lowering an empirical risk function [12], or increasing mutual information [13]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15620181,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a0d4b0618eb4e5ebcd3f86e9948921ba9f49b77c",
            "isKey": false,
            "numCitedBy": 303,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "We show that efficient object recognition can be obtained by combining informative features with linear classification. The results demonstrate the superiority of informative class-specific features, as compared with generic type features such as wavelets, for the task of object recognition. We show that information rich features can reach optimal performance with simple linear separation rules, while generic feature based classifiers require more complex classification schemes. This is significant because efficient and optimal methods have been developed for spaces that allow linear separation. To compare different strategies for feature extraction, we trained and compared classifiers working in feature spaces of the same low dimensionality, using two feature types (image fragments vs. wavelets) and two classification rules (linear hyperplane and a Bayesian network). The results show that by maximizing the individual information of the features, it is possible to obtain efficient classification by a simple linear separating rule, as well as more efficient learning."
            },
            "slug": "Object-recognition-with-informative-features-and-Vidal-Naquet-Ullman",
            "title": {
                "fragments": [],
                "text": "Object recognition with informative features and linear classification"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "The results show that by maximizing the individual information of the features, it is possible to obtain efficient classification by a simple linear separating rule, as well as more efficient learning."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings Ninth IEEE International Conference on Computer Vision"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "4801654"
                        ],
                        "name": "Y. Amit",
                        "slug": "Y.-Amit",
                        "structuredName": {
                            "firstName": "Yali",
                            "lastName": "Amit",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Amit"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1707642"
                        ],
                        "name": "D. Geman",
                        "slug": "D.-Geman",
                        "structuredName": {
                            "firstName": "Donald",
                            "lastName": "Geman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Geman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 103,
                                "start": 99
                            }
                        ],
                        "text": "Unlike in mcl, the recurring elements in these methods are fairly simple, including edge fragments [11], Gaussian models [12], or image fragments [13]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 159,
                                "start": 155
                            }
                        ],
                        "text": "An alternative approach involves searching for repeatedly occurring elements using different criteria such as frequency of appearance in the training data [11], lowering an empirical risk function [12], or increasing mutual information [13]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7784637,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "61b2d0383b186c4d634c5f51421cab67c16d90a1",
            "isKey": false,
            "numCitedBy": 197,
            "numCiting": 46,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a computational model for detecting and localizing instances from an object class in static gray-level images. We divide detection into visual selection and final classification, concentrating on the former: drastically reducing the number of candidate regions that require further, usually more intensive, processing, but with a minimum of computation and missed detections. Bottom-up processing is based on local groupings of edge fragments constrained by loose geometrical relationships. They have no a priori semantic or geometric interpretation. The role of training is to select special groupings that are moderately likely at certain places on the object but rare in the background. We show that the statistics in both populations are stable. The candidate regions are those that contain global arrangements of several local groupings. Whereas our model was not conceived to explain brain functions, it does cohere with evidence about the functions of neurons in V1 and V2, such as responses to coarse or incomplete patterns (e.g., illusory contours) and to scale and translation invariance in IT. Finally, the algorithm is applied to face and symbol detection."
            },
            "slug": "A-Computational-Model-for-Visual-Selection-Amit-Geman",
            "title": {
                "fragments": [],
                "text": "A Computational Model for Visual Selection"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "The model was not conceived to explain brain functions, but it does cohere with evidence about the functions of neurons in V1 and V2, such as responses to coarse or incomplete patterns and to scale and translation invariance in IT."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145319478"
                        ],
                        "name": "Michael J. Jones",
                        "slug": "Michael-J.-Jones",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Jones",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael J. Jones"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1731948"
                        ],
                        "name": "Paul A. Viola",
                        "slug": "Paul-A.-Viola",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Viola",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Paul A. Viola"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "4. 1.1 Related Work A number of discriminative detection systems that learn from simple low-level features and large amounts of data have been proposed; typically their focus is either on the learning aspect [ 1 , 3] or the design of appropriate features [2]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Our classier is composed of 20K Haar features (256 per mil), compared to 6K in the Viola & Jones real-time face detector [ 1 ]; however, they are organized into multiple shallow cascades as opposed to a single deep cascade, so evaluation is slower."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "For AdaBoost and mcl we used Haar features [ 1 ]; for bof we use Euclidean distance on pixels to perform clustering."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Train a mil classier ^ Ft :X m ! [0;  1 ] using distribution Dt. Let ^ t (Xi) = (2 1[ ^"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Recall that mil, given input data organized in sets Xi2X m , learns a function ^ F :X m ! [0;  1 ] of the form ^"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "F (Xi) is essentially the maximum of f(xij) over j. If f outputs a probability or condence in [0 ;  1 ], then we can dene a \u2018soft\u2019 version of ^ F (Xi) = softmaxj(f(xij)); (2) where \u2018softmax\u2019 is some dierentiable real-valued approximation of the max over [0; 1]. We use the model of mil dened in Equation (2) throughout this paper."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "We compute 10K random Haar features [ 1 ] per patch, using the original grayscale image, as well as gradient magnitude and 6 channels of gradient quantized by orientation."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "F (Xi) is essentially the maximum of f(xij) over j. If f outputs a probability or condence in [0 ; 1], then we can dene a \u2018soft\u2019 version of ^ F (Xi) = softmaxj(f(xij)); (2) where \u2018softmax\u2019 is some dierentiable real-valued approximation of the max over [0;  1 ]. We use the model of mil dened in Equation (2) throughout this paper."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 15810545,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "548ab5770b89650158f99caee1bed3a986b0dcdf",
            "isKey": true,
            "numCitedBy": 724,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract This paper extends the face detection framework proposedby Viola and Jones 2001 to handle pro\ufb01le views and rotatedfaces. As in the work of Rowley et al 1998. and Schneider-man et al. 2000, we build different detectors for differentviews of the face. A decision tree is then trained to deter-mine the viewpoint class (such as right pro\ufb01le or rotated60 degrees) for a given window of the image being exam-ined. This is similar to the approach of Rowley et al. 1998.The appropriate detector for that viewpoint can then be runinstead of running all detectors on all windows. This tech-niqueyields goodresults and maintainsthe speed advantageof the Viola-Jones detector. 1. Introduction There are a number of techniques that can successfullydetect frontal upright faces in a wide variety of images[11, 7, 10, 12, 3, 6]. While the de\ufb01nition of \u201cfrontal\u201d and\u201cupright\u201dmayvaryfromsystem to system, the reality is thatmany natural images contain rotated or pro\ufb01le faces thatare not reliably detected. There are a small number of sys-tems which explicitly address non-frontal, or non-uprightface detection [8, 10, 2]. This paper describes progress to-ward a system which can detect faces regardless of posereliably and in real-time.This paperextendsthe frameworkproposedby Viola andJones [12]. This approach is selected because of its compu-tational ef\ufb01ciency and simplicity.One observation which is shared among all previous re-lated work is that a multi-view detector must be carefullyconstructed by combining a collection of detectors eachtrained for a single viewpoint. It appears that a monolithicapproach, where a single classi\ufb01er is trained to detect allposes of a face, is unlearnable with existing classi\ufb01ers. Ourinformal experiments lend support to this conclusion, sincea classi\ufb01er trained on all poses appears to be hopelessly in-accurate.This paper addresses two types of pose variation: non-frontal faces, which are rotated out of the image plane, andnon-upright faces, which are rotated in the image plane.In both cases the multi-view detector presented in this pa-per is a combination of Viola-Jones detectors, each detectortrained on face data taken from a single viewpoint.Reliable non-upright face detection was \ufb01rst presentedin a paper by Rowley, Baluja and Kanade [8]. They traintwo neural network classi\ufb01ers. The \ufb01rst estimates the poseof a face in the detection window. The second is a conven-tional face detector. Faces are detected in three steps: foreach image window the pose of \u201cface\u201d is \ufb01rst estimated; thepose estimate is then used to de-rotate the image window;the window is then classi\ufb01ed by the second detector. Fornon-face windows, the poses estimate must be consideredrandom. Nevertheless, a rotated non-faceshouldbe rejectedby the conventional detector. One potential \ufb02aw of such asystem is that the \ufb01nal detection rate is roughly the productof the correct classi\ufb01cation rates of the two classi\ufb01ers (sincethe errors of the two classi\ufb01ers are somewhat independent).One could adopt the Rowley et al. three step approachwhile replacingthe classi\ufb01ers with those of Viola andJones.The \ufb01nal system would be more ef\ufb01cient, but not signi\ufb01-cantly. Classi\ufb01cation by the Viola-Jones system is so ef\ufb01-cient, that derotation would dominate the computational ex-pense. In principle derotation is not strictly necessary sinceit should be possible to construct a detector for rotated facesdirectly. Detection becomes a two stage process. First thepose of the window is estimated and then one ofrotationspeci\ufb01c detectors is called upon to classify the window.In this paper detection of non-upright faces is handledusing the two stage approach. In the \ufb01rst stage the pose ofeach window is estimated using a decision tree constructedusing features like those described by Viola and Jones. Inthe second stage one ofpose speci\ufb01c Viola-Jones dete-tectors are used to classify the window.Oncepose speci\ufb01c detectors are trained and available,an alternative detection process can be tested as well. In thiscase alldetectors are evaluated and the union of their de-"
            },
            "slug": "Fast-Multi-view-Face-Detection-Jones-Viola",
            "title": {
                "fragments": [],
                "text": "Fast Multi-view Face Detection"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A multi-view detector presented in this pa-per is a combination of Viola-Jones detectors, each detectortrained on face data taken from a single viewpoint, which appears that a monolithic approach to face detection is unlearnable with existing classi\ufb01er trained on all poses."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2272096"
                        ],
                        "name": "Guo-Jun Qi",
                        "slug": "Guo-Jun-Qi",
                        "structuredName": {
                            "firstName": "Guo-Jun",
                            "lastName": "Qi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Guo-Jun Qi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143863244"
                        ],
                        "name": "Xiansheng Hua",
                        "slug": "Xiansheng-Hua",
                        "structuredName": {
                            "firstName": "Xiansheng",
                            "lastName": "Hua",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xiansheng Hua"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145459057"
                        ],
                        "name": "Y. Rui",
                        "slug": "Y.-Rui",
                        "structuredName": {
                            "firstName": "Yong",
                            "lastName": "Rui",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Rui"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144025741"
                        ],
                        "name": "Tao Mei",
                        "slug": "Tao-Mei",
                        "structuredName": {
                            "firstName": "Tao",
                            "lastName": "Mei",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tao Mei"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8053308"
                        ],
                        "name": "Jinhui Tang",
                        "slug": "Jinhui-Tang",
                        "structuredName": {
                            "firstName": "Jinhui",
                            "lastName": "Tang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jinhui Tang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108698841"
                        ],
                        "name": "HongJiang Zhang",
                        "slug": "HongJiang-Zhang",
                        "structuredName": {
                            "firstName": "HongJiang",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "HongJiang Zhang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 138,
                                "start": 130
                            }
                        ],
                        "text": "Another example includes recent work that proposes to extend mil so the set classifier depends on more than one instance in a set [26, 27]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 115,
                                "start": 107
                            }
                        ],
                        "text": "These last methods are similar in spirit to mcl; however, the instance models are constrained to be simple [26, 27] and for computational reasons the set classifier can only depend on a few instances [27]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 13121675,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "aa273b84633fd5355374abdc6df76da18d0ec4da",
            "isKey": false,
            "numCitedBy": 51,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a new multiple instance learning (MIL) algorithm to learn image categories. Unlike existing MIL algorithms, in which the individual instances in a bag are assumed to be independent with each other, we develop concurrent tensors to explicitly model the inter-dependency between the instances to better capture image's inherent semantics. Rank-1 tensor factorization is then applied to obtain the label of each instance. Furthermore, we formulate the classification problem in the reproducing kernel Hilbert space (RKHS) to extend instance label prediction to the whole feature space. Finally, a regularizer is introduced, which avoids overfitting and significantly improves learning machine's generalization capability, similar to that in SVMs. We report superior categorization performances compared with key existing approaches on both the COREL and the Caltech datasets."
            },
            "slug": "Concurrent-Multiple-Instance-Learning-for-Image-Qi-Hua",
            "title": {
                "fragments": [],
                "text": "Concurrent Multiple Instance Learning for Image Categorization"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A regularizer is introduced, which avoids overfitting and significantly improves learning machine's generalization capability, similar to that in SVMs, in a new multiple instance learning algorithm to learn image categories."
            },
            "venue": {
                "fragments": [],
                "text": "2007 IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "93847855"
                        ],
                        "name": "S. Scott",
                        "slug": "S.-Scott",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Scott",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Scott"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2155661696"
                        ],
                        "name": "Jun Zhang",
                        "slug": "Jun-Zhang",
                        "structuredName": {
                            "firstName": "Jun",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jun Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2116700096"
                        ],
                        "name": "Joshua Brown",
                        "slug": "Joshua-Brown",
                        "structuredName": {
                            "firstName": "Joshua",
                            "lastName": "Brown",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Joshua Brown"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 138,
                                "start": 130
                            }
                        ],
                        "text": "Another example includes recent work that proposes to extend mil so the set classifier depends on more than one instance in a set [26, 27]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 115,
                                "start": 107
                            }
                        ],
                        "text": "These last methods are similar in spirit to mcl; however, the instance models are constrained to be simple [26, 27] and for computational reasons the set classifier can only depend on a few instances [27]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 6910194,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9993acdb19c299593e6d3c522eea1a7fd6c1ff9c",
            "isKey": false,
            "numCitedBy": 74,
            "numCiting": 52,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a generalisation of the multiple-instance learning model in which a bag's label is not based on a single instance's proximity to a single target point. Rather, a bag is positive if and only if it contains a collection of instances, each near one of a set of target points. We then adapt a learning-theoretic algorithm for learning in this model and present empirical results on data from robot vision, content-based image retrieval, and protein sequence identification."
            },
            "slug": "On-Generalized-Multiple-instance-Learning-Scott-Zhang",
            "title": {
                "fragments": [],
                "text": "On Generalized Multiple-instance Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 78,
                "text": "A generalisation of the multiple-instance learning model in which a bag's label is not based on a single instance's proximity to a single target point, but on a collection of instances, each near one of a set of target points."
            },
            "venue": {
                "fragments": [],
                "text": "Int. J. Comput. Intell. Appl."
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1794409"
                        ],
                        "name": "K. Grauman",
                        "slug": "K.-Grauman",
                        "structuredName": {
                            "firstName": "Kristen",
                            "lastName": "Grauman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Grauman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1753210"
                        ],
                        "name": "Trevor Darrell",
                        "slug": "Trevor-Darrell",
                        "structuredName": {
                            "firstName": "Trevor",
                            "lastName": "Darrell",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Trevor Darrell"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 138,
                                "start": 134
                            }
                        ],
                        "text": "A good example of this style of approach is kernel methods that implicitly or explicitly try to find correspondences between elements [25]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2363818,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d582df7250124b0523e07f61766cfa422eb5cde2",
            "isKey": false,
            "numCitedBy": 227,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "Sets of local features that are invariant to common image transformations are an effective representation to use when comparing images; current methods typically judge feature sets' similarity via a voting scheme (which ignores co-occurrence statistics) or by comparing histograms over a set of prototypes (which must be found by clustering). We present a method for efficiently comparing images based on their discrete distributions (bags) of distinctive local invariant features, without clustering descriptors. Similarity between images is measured with an approximation of the Earth Mover's Distance (EMD), which quickly computes minimal-cost correspondences between two bags of features. Each image's feature distribution is mapped into a normed space with a low-distortion embedding of EMD. Examples most similar to a novel query image are retrieved in time sublinear in the number of examples via approximate nearest neighbor search in the embedded space. We evaluate our method with scene, object, and texture recognition tasks."
            },
            "slug": "Efficient-image-matching-with-distributions-of-Grauman-Darrell",
            "title": {
                "fragments": [],
                "text": "Efficient image matching with distributions of local invariant features"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This work presents a method for efficiently comparing images based on their discrete distributions of distinctive local invariant features, without clustering descriptors, and evaluates the method with scene, object, and texture recognition tasks."
            },
            "venue": {
                "fragments": [],
                "text": "2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05)"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145246674"
                        ],
                        "name": "A. Heyden",
                        "slug": "A.-Heyden",
                        "structuredName": {
                            "firstName": "Anders",
                            "lastName": "Heyden",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Heyden"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2561175"
                        ],
                        "name": "G. Sparr",
                        "slug": "G.-Sparr",
                        "structuredName": {
                            "firstName": "Gunnar",
                            "lastName": "Sparr",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Sparr"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145118299"
                        ],
                        "name": "M. Nielsen",
                        "slug": "M.-Nielsen",
                        "structuredName": {
                            "firstName": "Mads",
                            "lastName": "Nielsen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Nielsen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153623949"
                        ],
                        "name": "P. Johansen",
                        "slug": "P.-Johansen",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Johansen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Johansen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 19228750,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "435ace68aa855103d76f869a88d34fee0771383b",
            "isKey": false,
            "numCitedBy": 1087,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a novel algorithm for recovering a smooth manifold of unknown dimension and topology from a set of points known to belong to it. Numerous applications in computer vision can be naturally interpreted as instanciations of this fundamental problem. Recently, a non-iterative discrete approach, tensor voting, has been introduced to solve this problem and has been applied successfully to various applications. As an alternative, we propose a variational formulation of this problem in the continuous setting and derive an iterative algorithm which approximates its solutions. This method and tensor voting are somewhat the differential and integral form of one another. Although iterative methods are slower in general, the strength of the suggested method is that it can easily be applied when the ambient space is not Euclidean, which is important in many applications. The algorithm consists in solving a partial differential equation that performs a special anisotropic diffusion on an implicit representation of the known set of points. This results in connecting isolated neighbouring points. This approach is very simple, mathematically sound, robust and powerful since it handles in a homogeneous way manifolds of arbitrary dimension and topology, embedded in Euclidean or non-Euclidean spaces, with or without border. We shall present this approach and demonstrate both its benefits and shortcomings in two different contexts: (i) data visual analysis, (ii) skin detection in color images."
            },
            "slug": "Computer-Vision-\u2014-ECCV-2002-Heyden-Sparr",
            "title": {
                "fragments": [],
                "text": "Computer Vision \u2014 ECCV 2002"
            },
            "tldr": {
                "abstractSimilarityScore": 69,
                "text": "A novel algorithm for recovering a smooth manifold of unknown dimension and topology from a set of points known to belong to it is presented and it can easily be applied when the ambient space is not Euclidean, which is important in many applications."
            },
            "venue": {
                "fragments": [],
                "text": "Lecture Notes in Computer Science"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1792884"
                        ],
                        "name": "Charles M. Bishop",
                        "slug": "Charles-M.-Bishop",
                        "structuredName": {
                            "firstName": "Charles",
                            "lastName": "Bishop",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Charles M. Bishop"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "33652486"
                        ],
                        "name": "J. Winn",
                        "slug": "J.-Winn",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Winn",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Winn"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1702814,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "f61abb7a18d5ef3455dc3f22d5e6370cd189e5ef",
            "isKey": false,
            "numCitedBy": 414,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "In recent years several techniques have been proposed for modelling the low-dimensional manifolds, or 'subspaces', of natural images. Examples include principal component analysis (as used for instance in 'eigen-faces'), independent component analysis, and auto-encoder neural networks. Such methods suffer from a number of restrictions such as the limitation to linear manifolds or the absence of a probablistic representation. In this paper we exploit recent developments in the fields of variational inference and latent variable models to develop a novel and tractable probabilistic approach to modelling manifolds which can handle complex non-linearities. Our framework comprises a mixture of sub-space components in which both the number of components and the effective dimensionality of the subspaces are determined automatically as part of the Bayesian inference procedure. We illustrate our approach using two classical problems: modelling the manifold of face images and modelling the manifolds of hand-written digits."
            },
            "slug": "Non-linear-Bayesian-Image-Modelling-Bishop-Winn",
            "title": {
                "fragments": [],
                "text": "Non-linear Bayesian Image Modelling"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A novel and tractable probabilistic approach to modelling manifolds which can handle complex non-linearities and is illustrated using two classical problems: modelling the manifold of face images and modelling the manifolds of hand-written digits."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3056361"
                        ],
                        "name": "J. Friedman",
                        "slug": "J.-Friedman",
                        "structuredName": {
                            "firstName": "Jerome",
                            "lastName": "Friedman",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Friedman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 61,
                                "start": 57
                            }
                        ],
                        "text": "Additive models have been shown to be robust and general [21], so their use for g is reasonable."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 45,
                                "start": 41
                            }
                        ],
                        "text": "We begin with a brief review of AdaBoost [21]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 26,
                                "start": 22
                            }
                        ],
                        "text": "The first is AdaBoost [21] applied to a standard, not set-based, representation of the data."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 87,
                                "start": 83
                            }
                        ],
                        "text": "Derivation of mcl with other boosting algorithms, such as RealBoost or GentleBoost [21], are similar to the derivation for mcl-AdaBoost."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 79,
                                "start": 75
                            }
                        ],
                        "text": "To learn a diverse collection of component classifiers we turn to boosting [21]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 9913392,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6f4493eff2531536a7aeb3fc11d62c30a8f487f6",
            "isKey": true,
            "numCitedBy": 4828,
            "numCiting": 72,
            "paperAbstract": {
                "fragments": [],
                "text": "Boosting is one of the most important recent developments in classification methodology. Boosting works by sequentially applying a classification algorithm to reweighted versions of the training data and then taking a weighted majority vote of the sequence of classifiers thus produced. For many classification algorithms, this simple strategy results in dramatic improvements in performance. We show that this seemingly mysterious phenomenon can be understood in terms of well-known statistical principles, namely additive modeling and maximum likelihood. For the two-class problem, boosting can be viewed as an approximation to additive modeling on the logistic scale using maximum Bernoulli likelihood as a criterion. We develop more direct approximations and show that they exhibit nearly identical results to boosting. Direct multiclass generalizations based on multinomial likelihood are derived that exhibit performance comparable to other recently proposed multiclass generalizations of boosting in most situations, and far superior in some. We suggest a minor modification to boosting that can reduce computation, often by factors of 10 to 50. Finally, we apply these insights to produce an alternative formulation of boosting decision trees. This approach, based on best-first truncated tree induction, often leads to better performance, and can provide interpretable descriptions of the aggregate decision rule. It is also much faster computationally, making it more suitable to large-scale data mining applications."
            },
            "slug": "Special-Invited-Paper-Additive-logistic-regression:-Friedman",
            "title": {
                "fragments": [],
                "text": "Special Invited Paper-Additive logistic regression: A statistical view of boosting"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "This work shows that this seemingly mysterious phenomenon of boosting can be understood in terms of well-known statistical principles, namely additive modeling and maximum likelihood, and develops more direct approximations and shows that they exhibit nearly identical results to boosting."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "82117876"
                        ],
                        "name": "F. Jurie",
                        "slug": "F.-Jurie",
                        "structuredName": {
                            "firstName": "Fr\u00e9d\u00e9ric",
                            "lastName": "Jurie",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Jurie"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1756114"
                        ],
                        "name": "B. Triggs",
                        "slug": "B.-Triggs",
                        "structuredName": {
                            "firstName": "Bill",
                            "lastName": "Triggs",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Triggs"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 11117513,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8d32093cd04d6beffb6d757f58b5ac950543ff7d",
            "isKey": false,
            "numCitedBy": 896,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "Visual codebook based quantization of robust appearance descriptors extracted from local image patches is an effective means of capturing image statistics for texture analysis and scene classification. Codebooks are usually constructed by using a method such as k-means to cluster the descriptor vectors of patches sampled either densely ('textons') or sparsely ('bags of features' based on key-points or salience measures) from a set of training images. This works well for texture analysis in homogeneous images, but the images that arise in natural object recognition tasks have far less uniform statistics. We show that for dense sampling, k-means over-adapts to this, clustering centres almost exclusively around the densest few regions in descriptor space and thus failing to code other informative regions. This gives suboptimal codes that are no better than using randomly selected centres. We describe a scalable acceptance-radius based clusterer that generates better codebooks and study its performance on several image classification tasks. We also show that dense representations outperform equivalent keypoint based ones on these tasks and that SVM or mutual information based feature selection starting from a dense codebook further improves the performance."
            },
            "slug": "Creating-efficient-codebooks-for-visual-recognition-Jurie-Triggs",
            "title": {
                "fragments": [],
                "text": "Creating efficient codebooks for visual recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "It is shown that dense representations outperform equivalent keypoint based ones on these tasks and that SVM or mutual information based feature selection starting from a dense codebook further improves the performance."
            },
            "venue": {
                "fragments": [],
                "text": "Tenth IEEE International Conference on Computer Vision (ICCV'05) Volume 1"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2577513"
                        ],
                        "name": "Oncel Tuzel",
                        "slug": "Oncel-Tuzel",
                        "structuredName": {
                            "firstName": "Oncel",
                            "lastName": "Tuzel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Oncel Tuzel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "29905643"
                        ],
                        "name": "F. Porikli",
                        "slug": "F.-Porikli",
                        "structuredName": {
                            "firstName": "Fatih",
                            "lastName": "Porikli",
                            "middleNames": [
                                "Murat"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Porikli"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145776090"
                        ],
                        "name": "P. Meer",
                        "slug": "P.-Meer",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Meer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Meer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 85,
                                "start": 79
                            }
                        ],
                        "text": "We then regenerated the ROC curves for mcl as well as SoftCascade (which, like [2, 3], is not part-based)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 61,
                                "start": 51
                            }
                        ],
                        "text": "A number of recent methods have targeted this data [2, 3, 31], We compare our results to each, using the training and evaluation methodology presented in [2], except to [31] as it appears the results reported in that work are inaccurate(2)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 136,
                                "start": 133
                            }
                        ],
                        "text": "At a false positive per window rate (FPPW) of 10\u22124, a commonly used reference point, mcl has a miss rate of \u223c4%, compared to \u223c7% for [3] and \u223c10% for [2]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 194,
                                "start": 188
                            }
                        ],
                        "text": "A number of discriminative detection systems that learn from simple low-level features and large amounts of data have been proposed; typically their focus is either on the learning aspect [1, 3] or the design of appropriate features [2]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2161048,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "b5702b5726b3dc58d97100061b4f54020631d9e6",
            "isKey": true,
            "numCitedBy": 535,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a new algorithm to detect humans in still images utilizing covariance matrices as object descriptors. Since these descriptors do not lie on a vector space, well known machine learning techniques are not adequate to learn the classifiers. The space of d-dimensional nonsingular covariance matrices can be represented as a connected Riemannian manifold. We present a novel approach for classifying points lying on a Riemannian manifold by incorporating the a priori information about the geometry of the space. The algorithm is tested on INRIA human database where superior detection rates are observed over the previous approaches."
            },
            "slug": "Human-Detection-via-Classification-on-Riemannian-Tuzel-Porikli",
            "title": {
                "fragments": [],
                "text": "Human Detection via Classification on Riemannian Manifolds"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "A novel approach for classifying points lying on a Riemannian manifold by incorporating the a priori information about the geometry of the space."
            },
            "venue": {
                "fragments": [],
                "text": "2007 IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1758039"
                        ],
                        "name": "T. Pajdla",
                        "slug": "T.-Pajdla",
                        "structuredName": {
                            "firstName": "Tom\u00e1s",
                            "lastName": "Pajdla",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Pajdla"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145564537"
                        ],
                        "name": "Jiri Matas",
                        "slug": "Jiri-Matas",
                        "structuredName": {
                            "firstName": "Jiri",
                            "lastName": "Matas",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jiri Matas"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 36942589,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "09bb44311ab5ed6e7312d9c03fafcdd48a3d2c14",
            "isKey": false,
            "numCitedBy": 896,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": "We present an analytic solution to the problem of estimating multiple 2-D and 3-D motion models from two-view correspondences or optical flow. The key to our approach is to view the estimation of multiple motion models as the estimation of a single multibody motion model. This is possible thanks to two important algebraic facts. First, we show that all the image measurements, regardless of their associated motion model, can be fit with a real or complex polynomial. Second, we show that the parameters of the motion model associated with an image measurement can be obtained from the derivatives of the polynomial at the measurement. This leads to a novel motion segmentation algorithm that applies to most of the two-view motion models adopted in computer vision. Our experiments show that the proposed algorithm outperforms existing algebraic methods in terms of efficiency and robustness, and provides a good initialization for iterative techniques, such as EM, which is strongly dependent on correct initialization."
            },
            "slug": "Computer-Vision-ECCV-2004-Pajdla-Matas",
            "title": {
                "fragments": [],
                "text": "Computer Vision - ECCV 2004"
            },
            "tldr": {
                "abstractSimilarityScore": 69,
                "text": "This work presents an analytic solution to the problem of estimating multiple 2-D and 3-D motion models from two-view correspondences or optical flow and proposes a novel motion segmentation algorithm that outperforms existing algebraic methods in terms of efficiency and robustness."
            },
            "venue": {
                "fragments": [],
                "text": "Lecture Notes in Computer Science"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145266088"
                        ],
                        "name": "T. Leung",
                        "slug": "T.-Leung",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Leung",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Leung"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2511655"
                        ],
                        "name": "M. Burl",
                        "slug": "M.-Burl",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Burl",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Burl"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1690922"
                        ],
                        "name": "P. Perona",
                        "slug": "P.-Perona",
                        "structuredName": {
                            "firstName": "Pietro",
                            "lastName": "Perona",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Perona"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "the constellation model and its variants [ 16 , 4, 17] have proven robust and capable of operating with little training data."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2904067,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0d50d0e2af0b45cc7ed25fe4aa97af900c9bd32a",
            "isKey": false,
            "numCitedBy": 389,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "An algorithm for locating quasi-frontal views of human faces in cluttered scenes is presented. The algorithm works by coupling a set of local feature detectors with a statistical model of the mutual distances between facial features it is invariant with respect to translation, rotation (in the plane), and scale and can handle partial occlusions of the face. On a challenging database with complicated and varied backgrounds, the algorithm achieved a correct localization rate of 95% in images where the face appeared quasi-frontally.<<ETX>>"
            },
            "slug": "Finding-faces-in-cluttered-scenes-using-random-Leung-Burl",
            "title": {
                "fragments": [],
                "text": "Finding faces in cluttered scenes using random labeled graph matching"
            },
            "tldr": {
                "abstractSimilarityScore": 66,
                "text": "An algorithm for locating quasi-frontal views of human faces in cluttered scenes is presented and it is found that it is invariant with respect to translation, rotation, and scale and can handle partial occlusions of the face."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IEEE International Conference on Computer Vision"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1952587"
                        ],
                        "name": "J. Keeler",
                        "slug": "J.-Keeler",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Keeler",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Keeler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2681887"
                        ],
                        "name": "D. Rumelhart",
                        "slug": "D.-Rumelhart",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Rumelhart",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Rumelhart"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1787377"
                        ],
                        "name": "W. Leow",
                        "slug": "W.-Leow",
                        "structuredName": {
                            "firstName": "W.",
                            "lastName": "Leow",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Leow"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[22] trained a digit recognition system using unaligned image data."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 894091,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "847d6ece37d22430a0d9e061b5dc1d1b8c679055",
            "isKey": false,
            "numCitedBy": 159,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "Neural network algorithms have proven useful for recognition of individual, segmented characters. However, their recognition accuracy has been limited by the accuracy of the underlying segmentation algorithm. Conventional, rule-based segmentation algorithms encounter difficulty if the characters are touching, broken, or noisy. The problem in these situations is that often one cannot properly segment a character until it is recognized yet one cannot properly recognize a character until it is segmented. We present here a neural network algorithm that simultaneously segments and recognizes in an integrated system. This algorithm has several novel features: it uses a supervised learning algorithm (backpropagation), but is able to take position-independent information as targets and self-organize the activities of the units in a competitive fashion to infer the positional information. We demonstrate this ability with overlapping handprinted numerals."
            },
            "slug": "Integrated-Segmentation-and-Recognition-of-Numerals-Keeler-Rumelhart",
            "title": {
                "fragments": [],
                "text": "Integrated Segmentation and Recognition of Hand-Printed Numerals"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "A neural network algorithm that simultaneously segments and recognizes in an integrated system that uses a supervised learning algorithm (backpropagation), but is able to take position-independent information as targets and self-organize the activities of the units in a competitive fashion to infer the positional information."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144299726"
                        ],
                        "name": "Thomas G. Dietterich",
                        "slug": "Thomas-G.-Dietterich",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Dietterich",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thomas G. Dietterich"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145914024"
                        ],
                        "name": "R. Lathrop",
                        "slug": "R.-Lathrop",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Lathrop",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Lathrop"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1388700951"
                        ],
                        "name": "Tomas Lozano-Perez",
                        "slug": "Tomas-Lozano-Perez",
                        "structuredName": {
                            "firstName": "Tomas",
                            "lastName": "Lozano-Perez",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tomas Lozano-Perez"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[20] in their study of drug activity prediction, and in earlier work, Keeler et al ."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 141,
                                "start": 137
                            }
                        ],
                        "text": "Thus, we can use weakly supervised learning to learn a single component classifier; specifically we use multiple instance learning (mil) [20]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 7398727,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1c7d38f68fe1150895a186e30b60c02dd89a676a",
            "isKey": false,
            "numCitedBy": 2425,
            "numCiting": 81,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Solving-the-Multiple-Instance-Problem-with-Dietterich-Lathrop",
            "title": {
                "fragments": [],
                "text": "Solving the Multiple Instance Problem with Axis-Parallel Rectangles"
            },
            "venue": {
                "fragments": [],
                "text": "Artif. Intell."
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1713089"
                        ],
                        "name": "D. Huttenlocher",
                        "slug": "D.-Huttenlocher",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Huttenlocher",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Huttenlocher"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2901136"
                        ],
                        "name": "G. Klanderman",
                        "slug": "G.-Klanderman",
                        "structuredName": {
                            "firstName": "Gregory",
                            "lastName": "Klanderman",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Klanderman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2116003"
                        ],
                        "name": "W. Rucklidge",
                        "slug": "W.-Rucklidge",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Rucklidge",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Rucklidge"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 129,
                                "start": 125
                            }
                        ],
                        "text": "For example, the Hausdorff distance is a straightforward way of defining a distance over sets given a distance over elements [28]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 8027136,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "85efeeb25d8e363606d94c8fadaa922ba9b93a37",
            "isKey": false,
            "numCitedBy": 3912,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "The Hausdorff distance measures the extent to which each point of a model set lies near some point of an image set and vice versa. Thus, this distance can be used to determine the degree of resemblance between two objects that are superimposed on one another. Efficient algorithms for computing the Hausdorff distance between all possible relative positions of a binary image and a model are presented. The focus is primarily on the case in which the model is only allowed to translate with respect to the image. The techniques are extended to rigid motion. The Hausdorff distance computation differs from many other shape comparison methods in that no correspondence between the model and the image is derived. The method is quite tolerant of small position errors such as those that occur with edge detectors and other feature extraction methods. It is shown that the method extends naturally to the problem of comparing a portion of a model against an image. >"
            },
            "slug": "Comparing-Images-Using-the-Hausdorff-Distance-Huttenlocher-Klanderman",
            "title": {
                "fragments": [],
                "text": "Comparing Images Using the Hausdorff Distance"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "Efficient algorithms for computing the Hausdorff distance between all possible relative positions of a binary image and a model are presented and it is shown that the method extends naturally to the problem of comparing a portion of a model against an image."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144586498"
                        ],
                        "name": "R. Plamondon",
                        "slug": "R.-Plamondon",
                        "structuredName": {
                            "firstName": "R\u00e9jean",
                            "lastName": "Plamondon",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Plamondon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1696384"
                        ],
                        "name": "S. Srihari",
                        "slug": "S.-Srihari",
                        "structuredName": {
                            "firstName": "Sargur",
                            "lastName": "Srihari",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Srihari"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 157,
                                "start": 153
                            }
                        ],
                        "text": "In the first experiment we apply mcl to the offline, text-independent handwriting identification problem (recognizing the author by his/her handwriting) [29]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 15782139,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d12864a8acbab1830be755bfb9cb177e31ca5e20",
            "isKey": false,
            "numCitedBy": 2743,
            "numCiting": 719,
            "paperAbstract": {
                "fragments": [],
                "text": "Handwriting has continued to persist as a means of communication and recording information in day-to-day life even with the introduction of new technologies. Given its ubiquity in human transactions, machine recognition of handwriting has practical significance, as in reading handwritten notes in a PDA, in postal addresses on envelopes, in amounts in bank checks, in handwritten fields in forms, etc. This overview describes the nature of handwritten language, how it is transduced into electronic data, and the basic concepts behind written language recognition algorithms. Both the online case (which pertains to the availability of trajectory data during writing) and the off-line case (which pertains to scanned images) are considered. Algorithms for preprocessing, character and word recognition, and performance with practical systems are indicated. Other fields of application, like signature verification, writer authentification, handwriting learning tools are also considered."
            },
            "slug": "On-Line-and-Off-Line-Handwriting-Recognition:-A-Plamondon-Srihari",
            "title": {
                "fragments": [],
                "text": "On-Line and Off-Line Handwriting Recognition: A Comprehensive Survey"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The nature of handwritten language, how it is transduced into electronic data, and the basic concepts behind written language recognition algorithms are described."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47246616"
                        ],
                        "name": "R. Brunelli",
                        "slug": "R.-Brunelli",
                        "structuredName": {
                            "firstName": "Roberto",
                            "lastName": "Brunelli",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Brunelli"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685292"
                        ],
                        "name": "T. Poggio",
                        "slug": "T.-Poggio",
                        "structuredName": {
                            "firstName": "Tomaso",
                            "lastName": "Poggio",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Poggio"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 16859093,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "239beb3861ceceb4c7c7f229234d97198d5c7697",
            "isKey": false,
            "numCitedBy": 2828,
            "numCiting": 49,
            "paperAbstract": {
                "fragments": [],
                "text": "Two new algorithms for computer recognition of human faces, one based on the computation of a set of geometrical features, such as nose width and length, mouth position, and chin shape, and the second based on almost-gray-level template matching, are presented. The results obtained for the testing sets show about 90% correct recognition using geometrical features and perfect recognition using template matching. >"
            },
            "slug": "Face-Recognition:-Features-Versus-Templates-Brunelli-Poggio",
            "title": {
                "fragments": [],
                "text": "Face Recognition: Features Versus Templates"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "Two new algorithms for computer recognition of human faces, one based on the computation of a set of geometrical features, such as nose width and length, mouth position, and chin shape, and the second based on almost-gray-level template matching are presented."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3127386"
                        ],
                        "name": "D. Reynolds",
                        "slug": "D.-Reynolds",
                        "structuredName": {
                            "firstName": "Douglas",
                            "lastName": "Reynolds",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Reynolds"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1786323"
                        ],
                        "name": "R. Rose",
                        "slug": "R.-Rose",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Rose",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Rose"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7319345,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "381a00152b08160b0802c34eb66aa44317911089",
            "isKey": false,
            "numCitedBy": 3154,
            "numCiting": 61,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper introduces and motivates the use of Gaussian mixture models (GMM) for robust text-independent speaker identification. The individual Gaussian components of a GMM are shown to represent some general speaker-dependent spectral shapes that are effective for modeling speaker identity. The focus of this work is on applications which require high identification rates using short utterance from unconstrained conversational speech and robustness to degradations produced by transmission over a telephone channel. A complete experimental evaluation of the Gaussian mixture speaker model is conducted on a 49 speaker, conversational telephone speech database. The experiments examine algorithmic issues (initialization, variance limiting, model order selection), spectral variability robustness techniques, large population performance, and comparisons to other speaker modeling techniques (uni-modal Gaussian, VQ codebook, tied Gaussian mixture, and radial basis functions). The Gaussian mixture speaker model attains 96.8% identification accuracy using 5 second clean speech utterances and 80.8% accuracy using 15 second telephone speech utterances with a 49 speaker population and is shown to outperform the other speaker modeling techniques on an identical 16 speaker telephone speech task. >"
            },
            "slug": "Robust-text-independent-speaker-identification-Reynolds-Rose",
            "title": {
                "fragments": [],
                "text": "Robust text-independent speaker identification using Gaussian mixture speaker models"
            },
            "tldr": {
                "abstractSimilarityScore": 54,
                "text": "The individual Gaussian components of a GMM are shown to represent some general speaker-dependent spectral shapes that are effective for modeling speaker identity and is shown to outperform the other speaker modeling techniques on an identical 16 speaker telephone speech task."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Speech Audio Process."
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2465976"
                        ],
                        "name": "M. Fischler",
                        "slug": "M.-Fischler",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "Fischler",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Fischler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3394928"
                        ],
                        "name": "R. Elschlager",
                        "slug": "R.-Elschlager",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Elschlager",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Elschlager"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 96,
                                "start": 93
                            }
                        ],
                        "text": "Part-based approaches have a rich history; one of the earliest approaches dates back to 1973 [7]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14554383,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "719da2a0ddd38e78151e1cb2db31703ea8b2e490",
            "isKey": false,
            "numCitedBy": 1527,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "The primary problem dealt with in this paper is the following. Given some description of a visual object, find that object in an actual photograph. Part of the solution to this problem is the specification of a descriptive scheme, and a metric on which to base the decision of \"goodness\" of matching or detection."
            },
            "slug": "The-Representation-and-Matching-of-Pictorial-Fischler-Elschlager",
            "title": {
                "fragments": [],
                "text": "The Representation and Matching of Pictorial Structures"
            },
            "tldr": {
                "abstractSimilarityScore": 59,
                "text": "The primary problem dealt with in this paper is the specification of a descriptive scheme, and a metric on which to base the decision of \"goodness\" of matching or detection."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Computers"
            },
            "year": 1973
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 58,
                                "start": 55
                            }
                        ],
                        "text": "We now present results on the INRIA pedestrian dataset [2]."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 153,
                                "start": 150
                            }
                        ],
                        "text": "At a false positive per window rate (FPPW) of 10\u22124, a commonly used reference point, mcl has a miss rate of \u223c4%, compared to \u223c7% for [3] and \u223c10% for [2]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 236,
                                "start": 233
                            }
                        ],
                        "text": "A number of discriminative detection systems that learn from simple low-level features and large amounts of data have been proposed; typically their focus is either on the learning aspect [1, 3] or the design of appropriate features [2]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 61,
                                "start": 51
                            }
                        ],
                        "text": "A number of recent methods have targeted this data [2, 3, 29], We compare our results to each, using the training and evaluation methodology presented in [2], except to [29] as it appears the results reported in that work are inaccurate(2)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 57,
                                "start": 54
                            }
                        ],
                        "text": "ROC curves comparing our method with Dalal and Triggs [2] and Tuzel et al ."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 100,
                                "start": 97
                            }
                        ],
                        "text": "We compile datasets for the first two domains; for the third we use the INRIA pedestrian dataset [2]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 85,
                                "start": 79
                            }
                        ],
                        "text": "We then regenerated the ROC curves for mcl as well as SoftCascade (which, like [2, 3], is not part-based)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Hist"
            },
            "venue": {
                "fragments": [],
                "text": "of oriented gradient for human det. In: CVPR."
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2112683288"
                        ],
                        "name": "Srinath Sridhar",
                        "slug": "Srinath-Sridhar",
                        "structuredName": {
                            "firstName": "Srinath",
                            "lastName": "Sridhar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Srinath Sridhar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49876729"
                        ],
                        "name": "Franziska Mueller",
                        "slug": "Franziska-Mueller",
                        "structuredName": {
                            "firstName": "Franziska",
                            "lastName": "Mueller",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Franziska Mueller"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1699058"
                        ],
                        "name": "M. Zollh\u00f6fer",
                        "slug": "M.-Zollh\u00f6fer",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Zollh\u00f6fer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Zollh\u00f6fer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1863006"
                        ],
                        "name": "D. Casas",
                        "slug": "D.-Casas",
                        "structuredName": {
                            "firstName": "Dan",
                            "lastName": "Casas",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Casas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2663734"
                        ],
                        "name": "Antti Oulasvirta",
                        "slug": "Antti-Oulasvirta",
                        "structuredName": {
                            "firstName": "Antti",
                            "lastName": "Oulasvirta",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Antti Oulasvirta"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1680185"
                        ],
                        "name": "C. Theobalt",
                        "slug": "C.-Theobalt",
                        "structuredName": {
                            "firstName": "Christian",
                            "lastName": "Theobalt",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Theobalt"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 5238630,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fdbcf7d898f25bb745519e705ed31b2327ff24e7",
            "isKey": false,
            "numCitedBy": 878,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Computer-Vision-\u2013-ECCV-2006-Sridhar-Mueller",
            "title": {
                "fragments": [],
                "text": "Computer Vision \u2013 ECCV 2006"
            },
            "venue": {
                "fragments": [],
                "text": "Lecture Notes in Computer Science"
            },
            "year": 2006
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Learning a sparse repr. for object det"
            },
            "venue": {
                "fragments": [],
                "text": "Learning a sparse repr. for object det"
            },
            "year": 2002
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 130,
                                "start": 127
                            }
                        ],
                        "text": "The patches can be vector quantized to form \u2018codebooks\u2019 [4], and an image can then be represented using a \u2018bag of words\u2019 model [6]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 144,
                                "start": 141
                            }
                        ],
                        "text": "Examples include using statistical tests on histograms of quantized feature vectors to determine if two sets belong to the same distribution [6] and methods in computer audition that fit Gaussian Mixture Models (GMM) to the"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 154,
                                "start": 151
                            }
                        ],
                        "text": "A simple but effective method of extracting parts is to crop small image patches, either using an interest point operator [4, 14] or by dense sampling [6]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Creating efficient codebooks for vis"
            },
            "venue": {
                "fragments": [],
                "text": "recog. In: ICCV."
            },
            "year": 2005
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Creating efficient codebooks for vis. recog"
            },
            "venue": {
                "fragments": [],
                "text": "Creating efficient codebooks for vis. recog"
            },
            "year": 2005
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 246,
                                "start": 242
                            }
                        ],
                        "text": "Examples include using statistical tests on histograms of quantized feature vectors to determine if two sets belong to the same distribution [6] and methods in computer audition that fit Gaussian Mixture Models (GMM) to the set distributions [24]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 73,
                                "start": 69
                            }
                        ],
                        "text": "We used MFCC features which are commonly used in speaker recognition [24]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Robust text-indep"
            },
            "venue": {
                "fragments": [],
                "text": "speaker ident. using gaussian mixture speaker models. In: IEEE Trans. on Speech and Audio Processing."
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 68,
                                "start": 64
                            }
                        ],
                        "text": "Spatial information can be encoded using pairwise relationships [14] or with a spatial voting scheme [15]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 129,
                                "start": 122
                            }
                        ],
                        "text": "A simple but effective method of extracting parts is to crop small image patches, either using an interest point operator [4, 14] or by dense sampling [6]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Learning a sparse repr"
            },
            "venue": {
                "fragments": [],
                "text": "for object det. In: ECCV."
            },
            "year": 2002
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Hist. of oriented gradient for human det"
            },
            "venue": {
                "fragments": [],
                "text": "Hist. of oriented gradient for human det"
            },
            "year": 2005
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Det. peds. by learning shapelet ftrs"
            },
            "venue": {
                "fragments": [],
                "text": "Det. peds. by learning shapelet ftrs"
            },
            "year": 2007
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 61,
                                "start": 51
                            }
                        ],
                        "text": "A number of recent methods have targeted this data [2, 3, 29], We compare our results to each, using the training and evaluation methodology presented in [2], except to [29] as it appears the results reported in that work are inaccurate(2)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Det"
            },
            "venue": {
                "fragments": [],
                "text": "peds. by learning shapelet ftrs. In: CVPR."
            },
            "year": 2007
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Multiple instance boosting for obj. detect"
            },
            "venue": {
                "fragments": [],
                "text": "Multiple instance boosting for obj. detect"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Robust textindep . speaker ident . using gaussian mixture speaker models"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans . on Speech and Audio Processing"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Robust text-indep. speaker ident. using gaussian mixture speaker models"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. on Speech and Audio Processing"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 58,
                                "start": 55
                            }
                        ],
                        "text": "One approach involves designing part detectors by hand [8] or providing a system with labeled part examples [9, 10]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Face recog.: features vs. templates"
            },
            "venue": {
                "fragments": [],
                "text": "PAMI"
            },
            "year": 1993
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 20,
            "methodology": 19,
            "result": 2
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 47,
        "totalPages": 5
    },
    "page_url": "https://www.semanticscholar.org/paper/Multiple-Component-Learning-for-Object-Detection-Doll\u00e1r-Babenko/6b1a05759f570f13ebdc5ea7f7a957e41f43203d?sort=total-citations"
}