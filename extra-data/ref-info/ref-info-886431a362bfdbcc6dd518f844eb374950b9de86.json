{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144429686"
                        ],
                        "name": "James W. Davis",
                        "slug": "James-W.-Davis",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Davis",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "James W. Davis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688328"
                        ],
                        "name": "A. Bobick",
                        "slug": "A.-Bobick",
                        "structuredName": {
                            "firstName": "Aaron",
                            "lastName": "Bobick",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Bobick"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 16135896,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cf8e9dc8a261ea9cf2a4bd4e15a2bd9e6237a5ab",
            "isKey": false,
            "numCitedBy": 558,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "A new view-based approach to the representation and recognition of action is presented. The basis of the representation is a temporal template-a static vector-image where the vector value at each point is a function of the motion properties at the corresponding spatial location in an image sequence. Using 18 aerobics exercises as a test domain, we explore the representational power of a simple, two component version of the templates: the first value is a binary value indicating the presence of motion, and the second value is a function of the recency of motion in a sequence. We then develop a recognition method which matches these temporal templates against stored instances of views of known actions. The method automatically performs temporal segmentation, is invariant to linear changes in speed, and runs in real-time on a standard platform. We recently incorporated this technique into the KIDSROOM: an interactive, narrative play-space for children."
            },
            "slug": "The-representation-and-recognition-of-human-using-Davis-Bobick",
            "title": {
                "fragments": [],
                "text": "The representation and recognition of human movement using temporal templates"
            },
            "tldr": {
                "abstractSimilarityScore": 88,
                "text": "A new view-based approach to the representation and recognition of action is presented, using a temporal template-a static vector-image where the vector value at each point is a function of the motion properties at the corresponding spatial location in an image sequence."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1710980"
                        ],
                        "name": "J. Little",
                        "slug": "J.-Little",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Little",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Little"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35062754"
                        ],
                        "name": "J. Boyd",
                        "slug": "J.-Boyd",
                        "structuredName": {
                            "firstName": "Jeffrey",
                            "lastName": "Boyd",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Boyd"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 26,
                                "start": 11
                            }
                        ],
                        "text": "Similarly, Little and Boyd recognize people walking by analyzing the motion associated with two ellipsoids fit to the body."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 42,
                                "start": 38
                            }
                        ],
                        "text": "Direct motion recognition [22], [25], [20], [4], [28], [26], [12], [7] approaches attempt to characterize the motion itself without reference to the underlying static poses of the body."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 125,
                                "start": 121
                            }
                        ],
                        "text": "Of the ablob-analysiso approaches, the work of Polana and Nelson [22], Shavit and Jepson [25] and, also, Little and Boyd [20] are most applicable."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 118,
                                "start": 103
                            }
                        ],
                        "text": "Of the \u00aablob-analysis\u00ba approaches, the work of Polana and Nelson [22], Shavit and Jepson [25] and, also, Little and Boyd [20] are most applicable."
                    },
                    "intents": []
                }
            ],
            "corpusId": 122539329,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "50837c95dc9bd236b6c1fe1a13d8541bda285880",
            "isKey": true,
            "numCitedBy": 96,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "Our goal is to describe motion of a moving human figure in order to recognize individuals by variation in the characteristics of the motion description. We begin with a short sequence of images of a moving figure, taken by a static camera, and derive dense optical flow data for the sequence. We determine a range of scale-independent features of each how image as a whole, ranging from the motion of the centroid of the moving points (assuming a static background), to the integral of the torque relative to the centroid. We then analyze the periodic structure of these sequences. All elements are multiples of the fundamental period of the gait, but they differ in phase. The phase is time-invariant, since it is independent of the sampling period. We show that there are several regularities in the phase differences of the signals. Moreover, some scalar measures of the signals may be useful in recognition. The representation is model-free, and therefore could be used to characterize the motion of other non-rigid bodies."
            },
            "slug": "Describing-motion-for-recognition-Little-Boyd",
            "title": {
                "fragments": [],
                "text": "Describing motion for recognition"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of International Symposium on Computer Vision - ISCV"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2109825670"
                        ],
                        "name": "A. D. Wilson",
                        "slug": "A.-D.-Wilson",
                        "structuredName": {
                            "firstName": "Ashley",
                            "lastName": "Wilson",
                            "middleNames": [
                                "Danielle"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. D. Wilson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688328"
                        ],
                        "name": "A. Bobick",
                        "slug": "A.-Bobick",
                        "structuredName": {
                            "firstName": "Aaron",
                            "lastName": "Bobick",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Bobick"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 71,
                                "start": 67
                            }
                        ],
                        "text": "It is difficult to imagine such techniques could be extended to the blurred sequence of Fig."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 753848,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "024de79de38c386e1bde33055aa38f607feffe6c",
            "isKey": false,
            "numCitedBy": 148,
            "numCiting": 65,
            "paperAbstract": {
                "fragments": [],
                "text": "A state-based method for learning visual behavior from image sequences is presented. The technique is novel for its incorporation of multiple representations into the Hidden Markov Model framework. Independent representations of the instantaneous visual input at each state of the Markov model are estimated concurrently with the learning of the temporal characteristics. Measures of the degree to which each representation describes the input are combined to determine an input's overall membership to a state. We exploit two constraints allowing application of the technique to view-based gesture recognition: gestures are modal in the space of possible human motion, and gestures are viewpoint-dependent. The recovery of the visual behavior of a number of simple gestures with a small number of low resolution image sequences is shown."
            },
            "slug": "Learning-visual-behavior-for-gesture-analysis-Wilson-Bobick",
            "title": {
                "fragments": [],
                "text": "Learning visual behavior for gesture analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 57,
                "text": "A state-based method for learning visual behavior from image sequences that exploits two constraints allowing application of the technique to view-based gesture recognition: gestures are modal in the space of possible human motion, and gestures are viewpoint-dependent."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of International Symposium on Computer Vision - ISCV"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688328"
                        ],
                        "name": "A. Bobick",
                        "slug": "A.-Bobick",
                        "structuredName": {
                            "firstName": "Aaron",
                            "lastName": "Bobick",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Bobick"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2111091821"
                        ],
                        "name": "James W. Davis",
                        "slug": "James-W.-Davis",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Davis",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "James W. Davis"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 44,
                                "start": 41
                            }
                        ],
                        "text": "Bobick [6] considers the range of motion interpretation problems and proposes a taxonomy of approaches."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 68,
                                "start": 65
                            }
                        ],
                        "text": "But recently, the focus of research is less on the measurement of image or camera motion and more on the labeling of the action taking place in the scene."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "These two approaches address the problem of recognizing actions when the precise configuration of the person and environment is known while the methods from the previous section concentrate on the recovery of the object pose."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 64,
                                "start": 61
                            }
                        ],
                        "text": "Shavit and Jepson also take an approach using the gross overall motion of the person."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 70,
                                "start": 67
                            }
                        ],
                        "text": "As for action recognition, Campbell and Bobick [8] used a commercially available system to obtain three-dimensional data of human body limb positions."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14541345,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7468a60f581504a2f7fb524914e54c304c5b8998",
            "isKey": false,
            "numCitedBy": 183,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "A new view-based approach to the representation of action is presented. Our underlying representations are view-based descriptions of the coarse image motion associated with viewing given actions from particular directions. Using these descriptions, we propose an appearance-based action-recognition strategy comprised of two stages: 1) a motion energy image (MEI) is computed that grossly describes the spatial distribution of motion energy for a given view of a given action, and the input MEI is matched against stored models which span the range of views of known actions; 2) any models that plausibly match the input are tested for a coarse, categorical agreement between a stored motion model of the action and a parametrization of the input motion. Using a \"sitting\" action as an example, and using a manually placed stick model, we develop a representation and verification technique that collapses the temporal variations of the motion parameters into a single, low-order vector."
            },
            "slug": "An-appearance-based-representation-of-action-Bobick-Davis",
            "title": {
                "fragments": [],
                "text": "An appearance-based representation of action"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "An appearance-based action-recognition strategy comprised of a representation and verification technique that collapses the temporal variations of the motion parameters into a single, low-order vector is proposed."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of 13th International Conference on Pattern Recognition"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144854796"
                        ],
                        "name": "D. Gavrila",
                        "slug": "D.-Gavrila",
                        "structuredName": {
                            "firstName": "Dariu",
                            "lastName": "Gavrila",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Gavrila"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1693428"
                        ],
                        "name": "L. Davis",
                        "slug": "L.-Davis",
                        "structuredName": {
                            "firstName": "Larry",
                            "lastName": "Davis",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Davis"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 22,
                                "start": 18
                            }
                        ],
                        "text": "Gavrila and Davis [14] also used a full-body model (22 DOF, tapered superquadrics) for tracking human motion against a complex background."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 52,
                                "start": 47
                            }
                        ],
                        "text": "For Black and Yacoob [4] and, also, Yacoob and Davis [28], optical flow measurements are used to help track predefined polygonal patches placed on interest regions (e.g., mouth)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 165,
                                "start": 161
                            }
                        ],
                        "text": "Because of the self-occlusions that frequently occur in articulated objects, some systems employ multiple cameras and restrict the motion to small regions [23], [14] to help with projective model occlusion constraints."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 10,
                                "start": 5
                            }
                        ],
                        "text": "J.W. Davis is with the Computer and Information Science Department, The Ohio State University, 583 Dreese Labs, 2015 Neil Ave., Columbus, OH 43210."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 153,
                                "start": 149
                            }
                        ],
                        "text": "Given the past history of the model configurations, prediction is commonly attained using Kalman filtering [24], [23], [15] and velocity constraints [14]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 125,
                                "start": 120
                            }
                        ],
                        "text": "The Recognition of Human Movement Using Temporal Templates Aaron F. Bobick, Member, IEEE Computer Society, and\nJames W. Davis, Member, IEEE Computer Society\nAbstract\u00d0A new view-based approach to the representation and recognition of human movement is presented."
                    },
                    "intents": []
                }
            ],
            "corpusId": 130705203,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ee1d075126f1fcdf6a49ad9976e84ebee5f00caf",
            "isKey": true,
            "numCitedBy": 90,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a vision system for the 3-0 modelbased tracking of unconstrained human movement. Using image sequences acquzred szmultaneously from multiple views, we recover the 3-0 body pose at each time instant without the use of markers. The poserecovery problem is formulated as a search problem and entails finding the pose parameters of a graphical human model whose synthesized appearance is most similar to the actual appearance of the real human in the multi-view images. The models used for this purpose are acquiredfrom the images. We use a decomposition approach and a best-first technique to search through the high dimensional pose parameter space. A robust variant of chamfer matching is used as a fast similarity measure between synthesized and real edge images. We present initial tracking results from a large new Humans-In-Action (HIA) database containing more than 2500 frames tn each of four orthogonal vzews. They contain subjects involved in a variety of activities, of various degrees of complexity, rangzng from the more simple one-person hand waving to the chailenging two-person close interaction in the Argentine Tango."
            },
            "slug": "el-based-tracking-of-humans-in-action:-Gavrila-Davis",
            "title": {
                "fragments": [],
                "text": "el-based tracking of humans in action:"
            },
            "tldr": {
                "abstractSimilarityScore": 60,
                "text": "A vision system for the 3-0 modelbased tracking of unconstrained human movement and initial tracking results from a large new Humans-In-Action (HIA) database containing more than 2500 frames each of four orthogonal vzews."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49540989"
                        ],
                        "name": "Lee W. Campbell",
                        "slug": "Lee-W.-Campbell",
                        "structuredName": {
                            "firstName": "Lee",
                            "lastName": "Campbell",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lee W. Campbell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688328"
                        ],
                        "name": "A. Bobick",
                        "slug": "A.-Bobick",
                        "structuredName": {
                            "firstName": "Aaron",
                            "lastName": "Bobick",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Bobick"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 3074726,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "32ce6157957a7ecc960a63327efd84de968bc9b5",
            "isKey": false,
            "numCitedBy": 373,
            "numCiting": 40,
            "paperAbstract": {
                "fragments": [],
                "text": "A new method for representing and recognizing human body movements is presented. The basic idea is to identify sets of constraints that are diagnostic of a movement: expressed using body-centered coordinates such as joint angles and in force only during a particular movement. Assuming the availability of Cartesian tracking data, we develop techniques for a representation of movements defined by space curves in subspaces of a \"phase space.\" The phase space has axes of joint angles and torso location and attitude, and the axes of the subspaces are subsets of the axes of the phase space. Using this representation we develop a system for learning new movements from ground truth data by searching for constraints. We then use the learned representation for recognizing movements in unsegmented data. We train and test the system on nine fundamental steps from classical ballet performed by two dancers; the system accurately recognizes the movements in the unsegmented stream of motion.<<ETX>>"
            },
            "slug": "Recognition-of-human-body-motion-using-phase-space-Campbell-Bobick",
            "title": {
                "fragments": [],
                "text": "Recognition of human body motion using phase space constraints"
            },
            "tldr": {
                "abstractSimilarityScore": 90,
                "text": "A new method for representing and recognizing human body movements is presented, to identify sets of constraints that are diagnostic of a movement: expressed using body-centered coordinates such as joint angles only during a particular movement."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IEEE International Conference on Computer Vision"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2652428"
                        ],
                        "name": "R. Polana",
                        "slug": "R.-Polana",
                        "structuredName": {
                            "firstName": "Ramprasad",
                            "lastName": "Polana",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Polana"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2113399896"
                        ],
                        "name": "R. Nelson",
                        "slug": "R.-Nelson",
                        "structuredName": {
                            "firstName": "Randall",
                            "lastName": "Nelson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Nelson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 30,
                                "start": 26
                            }
                        ],
                        "text": "As for action recognition, Campbell and Bobick [8] used a commercially available system to obtain three-dimensional data of human body limb positions."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Acquiring the three-dimensional information from image sequences is currently a complicated process, many times necessitating human intervention or contrived imaging environments."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 200,
                                "start": 196
                            }
                        ],
                        "text": "As expected, the\nsequence sweeps out a particular region of the image; our\nclaim is that the shape of that region (where there is motion)\ncan be used to suggest both the movement occurring and\nthe viewing condition (angle)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 9,
                                "start": 5
                            }
                        ],
                        "text": "The input to his system consisted of line-drawings of a person, table, and ball."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6353138,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "1ee01bf96b5dbd441eabda533fa89da3fa4d916a",
            "isKey": true,
            "numCitedBy": 371,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "The recognition of human movements such as walking, running or climbing has been approached previously by tracking a number of feature points and either classifying the trajectories directly or matching them with a high-level model of the movement. A major difficulty with these methods is acquiring and trading the requisite feature points, which are generally specific joints such as knees or angles. This requires previous recognition and/or part segmentation of the actor. We show that the recognition of walking or any repetitive motion activity can be accomplished on the basis of bottom up processing, which does not require the prior identification of specific parts, or classification of the actor. In particular, we demonstrate that repetitive motion is such a strong cue, that the moving actor can be segmented, normalized spatially and temporally, and recognized by matching against a spatiotemporal template of motion features. We have implemented a real-time system that can recognize and classify repetitive motion activities in normal gray-scale image sequences.<<ETX>>"
            },
            "slug": "Low-level-recognition-of-human-motion-(or-how-to-Polana-Nelson",
            "title": {
                "fragments": [],
                "text": "Low level recognition of human motion (or how to get your man without finding his body parts)"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "It is demonstrated that repetitive motion is such a strong cue, that the moving actor can be segmented, normalized spatially and temporally, and recognized by matching against a spatiotemporal template of motion features."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of 1994 IEEE Workshop on Motion of Non-rigid and Articulated Objects"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1753210"
                        ],
                        "name": "Trevor Darrell",
                        "slug": "Trevor-Darrell",
                        "structuredName": {
                            "firstName": "Trevor",
                            "lastName": "Darrell",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Trevor Darrell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144994682"
                        ],
                        "name": "A. Pentland",
                        "slug": "A.-Pentland",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Pentland",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Pentland"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "In contrast to the three-dimensional reconstruction and recognition approaches, others attempt to use only the twodimensional appearance of the action (e.g., [3], [ 10 ], [9], [29])."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "For example, Cui et al. [9], Darrell and Pentland [ 10 ] and, also, Wilson and Bobick [27] present results using actions (mostly hand gestures), where the actual grayscale images (with no background) are used in the representation for the action."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5344867,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1807058512ae2934b2be0b43f395d8583ef67303",
            "isKey": false,
            "numCitedBy": 442,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "A method for learning, tracking, and recognizing human gestures using a view-based approach to model articulated objects is presented. Objects are represented using sets of view models, rather than single templates. Stereotypical space-time patterns, i.e., gestures, are then matched to stored gesture patterns using dynamic time warping. Real-time performance is achieved by using special purpose correlation hardware and view prediction to prune as much of the search space as possible. Both view models and view predictions are learned from examples. Results showing tracking and recognition of human hand gestures at over 10 Hz are presented.<<ETX>>"
            },
            "slug": "Space-time-gestures-Darrell-Pentland",
            "title": {
                "fragments": [],
                "text": "Space-time gestures"
            },
            "tldr": {
                "abstractSimilarityScore": 74,
                "text": "A method for learning, tracking, and recognizing human gestures using a view-based approach to model articulated objects is presented and results showing tracking and recognition of human hand gestures at over 10 Hz are presented."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688328"
                        ],
                        "name": "A. Bobick",
                        "slug": "A.-Bobick",
                        "structuredName": {
                            "firstName": "Aaron",
                            "lastName": "Bobick",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Bobick"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8554662,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "3d05a60cd101d8833ad1e609d17dd0f4a8703a7f",
            "isKey": false,
            "numCitedBy": 359,
            "numCiting": 69,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents several approaches to the machine perception of motion and discusses the role and levels of knowledge in each. In particular, different techniques of motion understanding as focusing on one of movement, activity or action are described. Movements are the most atomic primitives, requiring no contextual or sequence knowledge to be recognized; movement is often addressed using either view-invariant or view-specific geometric techniques. Activity refers to sequences of movements or states, where the only real knowledge required is the statistics of the sequence; much of the recent work in gesture understanding falls within this category of motion perception. Finally, actions are larger-scale events, which typically include interaction with the environment and causal relationships; action understanding straddles the grey division between perception and cognition, computer vision and artificial intelligence. These levels are illustrated with examples drawn mostly from the group's work in understanding motion in video imagery. It is argued that the utility of such a division is that it makes explicit the representational competencies and manipulations necessary for perception."
            },
            "slug": "Movement,-activity-and-action:-the-role-of-in-the-Bobick",
            "title": {
                "fragments": [],
                "text": "Movement, activity and action: the role of knowledge in the perception of motion."
            },
            "tldr": {
                "abstractSimilarityScore": 95,
                "text": "This paper presents several approaches to the machine perception of motion and discusses the role and levels of knowledge in each, and different techniques of motion understanding as focusing on one of movement, activity or action are described."
            },
            "venue": {
                "fragments": [],
                "text": "Philosophical transactions of the Royal Society of London. Series B, Biological sciences"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1710918"
                        ],
                        "name": "J. Yamato",
                        "slug": "J.-Yamato",
                        "structuredName": {
                            "firstName": "Junji",
                            "lastName": "Yamato",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Yamato"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1708785"
                        ],
                        "name": "J. Ohya",
                        "slug": "J.-Ohya",
                        "structuredName": {
                            "firstName": "Jun",
                            "lastName": "Ohya",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Ohya"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2072192824"
                        ],
                        "name": "K. Ishii",
                        "slug": "K.-Ishii",
                        "structuredName": {
                            "firstName": "Kenichiro",
                            "lastName": "Ishii",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Ishii"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 28489640,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "45336e96c04ea005b203ff3fc84aa4f4159e8cb0",
            "isKey": false,
            "numCitedBy": 1527,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "A human action recognition method based on a hidden Markov model (HMM) is proposed. It is a feature-based bottom-up approach that is characterized by its learning capability and time-scale invariability. To apply HMMs, one set of time-sequential images is transformed into an image feature vector sequence, and the sequence is converted into a symbol sequence by vector quantization. In learning human action categories, the parameters of the HMMs, one per category, are optimized so as to best describe the training sequences from the category. To recognize an observed sequence, the HMM which best matches the sequence is chosen. Experimental results for real time-sequential images of sports scenes show recognition rates higher than 90%. The recognition rate is improved by increasing the number of people used to generate the training data, indicating the possibility of establishing a person-independent action recognizer.<<ETX>>"
            },
            "slug": "Recognizing-human-action-in-time-sequential-images-Yamato-Ohya",
            "title": {
                "fragments": [],
                "text": "Recognizing human action in time-sequential images using hidden Markov model"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The recognition rate is improved by increasing the number of people used to generate the training data, indicating the possibility of establishing a person-independent action recognizer."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145286523"
                        ],
                        "name": "K. Rohr",
                        "slug": "K.-Rohr",
                        "structuredName": {
                            "firstName": "Karl",
                            "lastName": "Rohr",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Rohr"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 43,
                                "start": 39
                            }
                        ],
                        "text": "A single camera is used in [16], [15], [24], but the actions tracked in these works had little deviation in the depth of motion."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 111,
                                "start": 107
                            }
                        ],
                        "text": "Given the past history of the model configurations, prediction is commonly attained using Kalman filtering [24], [23], [15] and velocity constraints [14]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 23,
                                "start": 19
                            }
                        ],
                        "text": "Hogg [16] and Rohr [24] used a full-body cylindrical model for tracking walking humans in natural scenes."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 89,
                                "start": 85
                            }
                        ],
                        "text": "of a person and then recognizing the motion of the model as advocated in [16], [23], [24]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 18,
                                "start": 14
                            }
                        ],
                        "text": "Hogg [16] and Rohr [24] used a full-body cylindrical model for tracking walking\nhumans in natural scenes."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "Rohr incorporates a 1 DOF pose parameter to aid in the model fitting."
                    },
                    "intents": []
                }
            ],
            "corpusId": 122238372,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "92ab4fc76e2f085dde81626794b79b5e9d1d00e0",
            "isKey": true,
            "numCitedBy": 491,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract The interpretation of the movements of articulated bodies in image sequences is one of the most challenging problems in computer vision. In this contribution, we introduce a model-based approach for the recognition of pedestrians. We represent the human body by a 3D-model consisting of cylinders, whereas for modelling the movement of walking we use data from medical motion studies. The estimation of model parameters in consecutive images is done by applying a Kalman filter. Experimental results are shown for synthetic as well as for real image data."
            },
            "slug": "Towards-model-based-recognition-of-human-movements-Rohr",
            "title": {
                "fragments": [],
                "text": "Towards model-based recognition of human movements in image sequences"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A model-based approach for the recognition of pedestrians is introduced and the human body is represented by a 3D-model consisting of cylinders, whereas for modelling the movement of walking the authors use data from medical motion studies."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144854796"
                        ],
                        "name": "D. Gavrila",
                        "slug": "D.-Gavrila",
                        "structuredName": {
                            "firstName": "Dariu",
                            "lastName": "Gavrila",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Gavrila"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1693428"
                        ],
                        "name": "L. Davis",
                        "slug": "L.-Davis",
                        "structuredName": {
                            "firstName": "Larry",
                            "lastName": "Davis",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Davis"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Given the past history of the model configurations, prediction is commonly attained using Kalman filtering [24], [23], [15] and velocity constraints [ 14 ]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Gavrila and Davis [ 14 ] also used a full-body model (22 DOF, tapered superquadrics) for tracking human motion against a complex background."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Because of the self-occlusions that frequently occur in articulated objects, some systems employ multiple cameras and restrict the motion to small regions [23], [ 14 ] to help with projective model occlusion constraints."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5697345,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cc9b263c1af95ea803c4f5c8888ef8e37f0cef80",
            "isKey": true,
            "numCitedBy": 818,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a vision system for the 3-D model-based tracking of unconstrained human movement. Using image sequences acquired simultaneously from multiple views, we recover the 3-D body pose at each time instant without the use of markers. The pose-recovery problem is formulated as a search problem and entails finding the pose parameters of a graphical human model whose synthesized appearance is most similar to the actual appearance of the real human in the multi-view images. The models used for this purpose are acquired from the images. We use a decomposition approach and a best-first technique to search through the high dimensional pose parameter space. A robust variant of chamfer matching is used as a fast similarity measure between synthesized and real edge images. We present initial tracking results from a large new Humans-in-Action (HIA) database containing more than 2500 frames in each of four orthogonal views. They contain subjects involved in a variety of activities, of various degrees of complexity, ranging from the more simple one-person hand waving to the challenging two-person close interaction in the Argentine Tango."
            },
            "slug": "3-D-model-based-tracking-of-humans-in-action:-a-Gavrila-Davis",
            "title": {
                "fragments": [],
                "text": "3-D model-based tracking of humans in action: a multi-view approach"
            },
            "tldr": {
                "abstractSimilarityScore": 60,
                "text": "A vision system for the 3-D model-based tracking of unconstrained human movement and initial tracking results from a large new Humans-in-Action database containing more than 2500 frames in each of four orthogonal views are presented."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings CVPR IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1917469"
                        ],
                        "name": "Shanon X. Ju",
                        "slug": "Shanon-X.-Ju",
                        "structuredName": {
                            "firstName": "Shanon",
                            "lastName": "Ju",
                            "middleNames": [
                                "X."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shanon X. Ju"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2105795"
                        ],
                        "name": "Michael J. Black",
                        "slug": "Michael-J.-Black",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Black",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael J. Black"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1964574"
                        ],
                        "name": "Y. Yacoob",
                        "slug": "Y.-Yacoob",
                        "structuredName": {
                            "firstName": "Yaser",
                            "lastName": "Yacoob",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Yacoob"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "These two approaches address the problem of recognizing actions when the precise configuration of the person and environment is known while the methods from the previous section concentrate on the recovery of the object pose."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5170789,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8e3b20fb94803d71910043059f402554aa5137b2",
            "isKey": false,
            "numCitedBy": 522,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "We extend the work of Black and Yacoob (1995) on the tracking and recognition of human facial expressions using parametrized models of optical flow to deal with the articulated motion of human limbs. We define a \"card-board person model\" in which a person's limbs are represented by a set of connected planar patches. The parametrized image motion of these patches in constrained to enforce articulated motion and is solved for directly using a robust estimation technique. The recovered motion parameters provide a rich and concise description of the activity that can be used for recognition. We propose a method for performing view-based recognition of human activities from the optical flow parameters that extends previous methods to cope with the cyclical nature of human motion. We illustrate the method with examples of tracking human legs of long image sequences."
            },
            "slug": "Cardboard-people:-a-parameterized-model-of-image-Ju-Black",
            "title": {
                "fragments": [],
                "text": "Cardboard people: a parameterized model of articulated image motion"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "A method for performing view-based recognition of human activities from the optical flow parameters that extends previous methods to cope with the cyclical nature of human motion is proposed."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Second International Conference on Automatic Face and Gesture Recognition"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144248008"
                        ],
                        "name": "K. Akita",
                        "slug": "K.-Akita",
                        "structuredName": {
                            "firstName": "Koichiro",
                            "lastName": "Akita",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Akita"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 161,
                                "start": 158
                            }
                        ],
                        "text": "The most common technique for attaining the threedimensional information of movement is to recover the pose of the person or object at each time instant using a three-dimensional model."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 47,
                                "start": 44
                            }
                        ],
                        "text": "All the poses in a walking action are indexed by a single number."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 33099756,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c74c4ee1466a7c083ab70fdccfbb3e4e4226c364",
            "isKey": false,
            "numCitedBy": 207,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Image-sequence-analysis-of-real-world-human-motion-Akita",
            "title": {
                "fragments": [],
                "text": "Image sequence analysis of real world human motion"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit."
            },
            "year": 1984
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1967104"
                        ],
                        "name": "David C. Hogg",
                        "slug": "David-C.-Hogg",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Hogg",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David C. Hogg"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "This capability of the human vision system argues for recognition of movement directly from the motion itself, as opposed to first reconstructing a three-dimensional model of a person and then recognizing the motion of the model as advocated in [ 16 ], [23], [24]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "A single camera is used in [ 16 ], [15], [24], but the actions tracked in these works had little deviation in the depth of motion."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Hogg [ 16 ] and Rohr [24] used a full-body cylindrical model for tracking walking humans in natural scenes."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 34873540,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "92f98b189cec1220d479e3079b942e71b244aa65",
            "isKey": true,
            "numCitedBy": 597,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Model-based-vision:-a-program-to-see-a-walking-Hogg",
            "title": {
                "fragments": [],
                "text": "Model-based vision: a program to see a walking person"
            },
            "venue": {
                "fragments": [],
                "text": "Image Vis. Comput."
            },
            "year": 1983
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1705627"
                        ],
                        "name": "J. Aggarwal",
                        "slug": "J.-Aggarwal",
                        "structuredName": {
                            "firstName": "Jake",
                            "lastName": "Aggarwal",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Aggarwal"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1851641"
                        ],
                        "name": "Q. Cai",
                        "slug": "Q.-Cai",
                        "structuredName": {
                            "firstName": "Quin",
                            "lastName": "Cai",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Q. Cai"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 29,
                                "start": 26
                            }
                        ],
                        "text": "Presented are frames of an extremely low resolution sequence in which a subject is performing a normally trivially recognizable movement."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2857532,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ff748f6647ccb014f1d8e27825ab2f5022bdcbb9",
            "isKey": false,
            "numCitedBy": 1748,
            "numCiting": 121,
            "paperAbstract": {
                "fragments": [],
                "text": "Human motion analysis is receiving increasing attention from computer vision researchers. This interest is motivated by a wide spectrum of applications, such as athletic performance analysis, surveillance, man-machine interfaces, content-based image storage and retrieval, and video conferencing. The paper gives an overview of the various tasks involved in motion analysis of the human body. The authors focus on three major areas related to interpreting human motion: 1) motion analysis involving human body parts, 2) tracking of human motion using single or multiple cameras, and 3) recognizing human activities from image sequences. Motion analysis of human body parts involves the low-level segmentation of the human body into segments connected by joints, and recovers the 3D structure of the human body using its 2D projections over a sequence of images. Tracking human motion using a single or multiple camera focuses on higher-level processing, in which moving humans are tracked without identifying specific parts of the body structure. After successfully matching the moving human image from one frame to another in image sequences, understanding the human movements or activities comes naturally, which leads to a discussion of recognizing human activities. The review is illustrated by examples."
            },
            "slug": "Human-motion-analysis:-a-review-Aggarwal-Cai",
            "title": {
                "fragments": [],
                "text": "Human Motion Analysis: A Review"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The paper gives an overview of the various tasks involved in motion analysis of the human body, and focuses on three major areas related to interpreting human motion: motion analysis involving human body parts, tracking of human motion using single or multiple cameras, and recognizing human activities from image sequences."
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Vis. Image Underst."
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1705627"
                        ],
                        "name": "J. Aggarwal",
                        "slug": "J.-Aggarwal",
                        "structuredName": {
                            "firstName": "Jake",
                            "lastName": "Aggarwal",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Aggarwal"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1851641"
                        ],
                        "name": "Q. Cai",
                        "slug": "Q.-Cai",
                        "structuredName": {
                            "firstName": "Quin",
                            "lastName": "Cai",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Q. Cai"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 62620915,
            "fieldsOfStudy": [
                "Art"
            ],
            "id": "57a3ddac00d371b1ba2b470c372923fb44a0849e",
            "isKey": false,
            "numCitedBy": 450,
            "numCiting": 47,
            "paperAbstract": {
                "fragments": [],
                "text": "Human motion analysis is receiving increasing attention from computer vision researchers. This interest is motivated by a wide spectrum of applications, such as athletic performance analysis, surveillance, man-machine interfaces, content-based image storage and retrieval, and video conferencing. The paper gives an overview of the various tasks involved in motion analysis of the human body. The authors focus on three major areas related to interpreting human motion: 1) motion analysis involving human body parts, 2) tracking of human motion using single or multiple cameras, and 3) recognizing human activities from image sequences. Motion analysis of human body parts involves the low-level segmentation of the human body into segments connected by joints, and recovers the 3D structure of the human body using its 2D projections over a sequence of images. Tracking human motion using a single or multiple camera focuses on higher-level processing, in which moving humans are tracked without identifying specific parts of the body structure. After successfully matching the moving human image from one frame to another in image sequences, understanding the human movements or activities comes naturally, which leads to a discussion of recognizing human activities. The review is illustrated by examples."
            },
            "slug": "Human-motion-analysis:-a-review-Aggarwal-Cai",
            "title": {
                "fragments": [],
                "text": "Human motion analysis: a review"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The paper gives an overview of the various tasks involved in motion analysis of the human body, and focuses on three major areas related to interpreting human motion: motion analysis involving human body parts, tracking of human motion using single or multiple cameras, and recognizing human activities from image sequences."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings IEEE Nonrigid and Articulated Motion Workshop"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1768236"
                        ],
                        "name": "W. Freeman",
                        "slug": "W.-Freeman",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Freeman",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Freeman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2059594591"
                        ],
                        "name": "Michal Roth",
                        "slug": "Michal-Roth",
                        "structuredName": {
                            "firstName": "Michal",
                            "lastName": "Roth",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michal Roth"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 6,
                                "start": 2
                            }
                        ],
                        "text": ", [13]) and interactive environments [21], [5]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 13146480,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2a63c0ae8cb411040a29ad85f2d009a17bf5a9a2",
            "isKey": false,
            "numCitedBy": 614,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a method to recognize hand gestures, based on a pattern recognition technique developed by McConnell [16] employing histograms of local orientation. We use the orientation histogram as a feature vector for gesture class cation and interpolation. This method is simple and fast to compute, and o ers some robustness to scene illumination changes. We have implemented a real-time version, which can distinguish a small vocabulary of about 10 di erent hand gestures. All the computation occurs on a workstation; special hardware is used only to digitize the image. A user can operate a computer graphic crane under hand gesture control, or play a game. We discuss limitations of this method. For moving or \\dynamic gestures\", the histogram of the spatio-temporal gradients of image intensity form the analogous feature vector and may be useful for dynamic gesture recognition. Reprinted from: IEEE Intl. Wkshp. on Automatic Face and Gesture Recognition, Zurich, June,"
            },
            "slug": "Orientation-Histograms-for-Hand-Gesture-Recognition-Freeman-Roth",
            "title": {
                "fragments": [],
                "text": "Orientation Histograms for Hand Gesture Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 73,
                "text": "A method to recognize hand gestures, based on a pattern recognition technique developed by McConnell employing histograms of local orientation, which is simple and fast to compute, and which can distinguish a small vocabulary of about 10 hand gestures."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2105795"
                        ],
                        "name": "Michael J. Black",
                        "slug": "Michael-J.-Black",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Black",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael J. Black"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1964574"
                        ],
                        "name": "Y. Yacoob",
                        "slug": "Y.-Yacoob",
                        "structuredName": {
                            "firstName": "Yaser",
                            "lastName": "Yacoob",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Yacoob"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "Bobick [6] considers the range of motion interpretation problems and proposes a taxonomy of approaches."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 72,
                                "start": 68
                            }
                        ],
                        "text": "The Recognition of Human Movement Using Temporal Templates Aaron F. Bobick, Member, IEEE Computer Society, and\nJames W. Davis, Member, IEEE Computer Society\nAbstract\u00d0A new view-based approach to the representation and recognition of human movement is presented."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "These two approaches address the problem of recognizing actions when the precise configuration of the person and environment is known while the methods from the previous section concentrate on the recovery of the object pose."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 9,
                                "start": 5
                            }
                        ],
                        "text": "A.F. Bobick is with the College of Computing, Georgia Tech, 801 Atlantic Dr., Atlanta, GA 30332."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 47,
                                "start": 44
                            }
                        ],
                        "text": "As for action recognition, Campbell and Bobick [8] used a commercially available system to obtain three-dimensional data of human body limb positions."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 81,
                                "start": 77
                            }
                        ],
                        "text": "For example, Cui et al. [9], Darrell and Pentland [10] and, also, Wilson and Bobick [27] present results using actions (mostly hand gestures), where the actual grayscale images (with no background) are used in the representation for the action."
                    },
                    "intents": []
                }
            ],
            "corpusId": 3175562,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "4ef915fa9e5b2260d4b45927c0033a7ba53bf66e",
            "isKey": true,
            "numCitedBy": 570,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper explores the use of local parametrized models of image motion for recovering and recognizing the non-rigid and articulated motion of human faces. Parametric flow models (for example affine) are popular for estimating motion in rigid scenes. We observe that within local regions in space and time, such models not only accurately model non-rigid facial motions but also provide a concise description of the motion in terms of a small number of parameters. These parameters are intuitively related to the motion of facial features during facial expressions and we show how expressions such as anger, happiness, surprise, fear, disgust and sadness can be recognized from the local parametric motions in the presence of significant head motion. The motion tracking and expression recognition approach performs with high accuracy in extensive laboratory experiments involving 40 subjects as well as in television and movie sequences.<<ETX>>"
            },
            "slug": "Tracking-and-recognizing-rigid-and-non-rigid-facial-Black-Yacoob",
            "title": {
                "fragments": [],
                "text": "Tracking and recognizing rigid and non-rigid facial motions using local parametric models of image motion"
            },
            "tldr": {
                "abstractSimilarityScore": 74,
                "text": "This paper explores the use of local parametrized models of image motion for recovering and recognizing the non-rigid and articulated motion of human faces and shows how expressions can be recognized from the local parametric motions in the presence of significant head motion."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IEEE International Conference on Computer Vision"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "21472040"
                        ],
                        "name": "Irfan Essa",
                        "slug": "Irfan-Essa",
                        "structuredName": {
                            "firstName": "Irfan",
                            "lastName": "Essa",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Irfan Essa"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144994682"
                        ],
                        "name": "A. Pentland",
                        "slug": "A.-Pentland",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Pentland",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Pentland"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 65,
                                "start": 61
                            }
                        ],
                        "text": "As for action recognition, Campbell and Bobick [8] used a commercially available system to obtain three-dimensional data of human body limb positions."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "These two approaches address the problem of recognizing actions when the precise configuration of the person and environment is known while the methods from the previous section concentrate on the recovery of the object pose."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2117401,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "74839c6ded777733519acaf44684d927c5e625bd",
            "isKey": false,
            "numCitedBy": 1053,
            "numCiting": 61,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a computer vision system for observing facial motion by using an optimal estimation optical flow method coupled with geometric, physical and motion-based dynamic models describing the facial structure. Our method produces a reliable parametric representation of the face's independent muscle action groups, as well as an accurate estimate of facial motion. Previous efforts at analysis of facial expression have been based on the facial action coding system (FACS), a representation developed in order to allow human psychologists to code expression from static pictures. To avoid use of this heuristic coding scheme, we have used our computer vision system to probabilistically characterize facial motion and muscle activation in an experimental population, thus deriving a new, more accurate, representation of human facial expressions that we call FACS+. Finally, we show how this method can be used for coding, analysis, interpretation, and recognition of facial expressions."
            },
            "slug": "Coding,-Analysis,-Interpretation,-and-Recognition-Essa-Pentland",
            "title": {
                "fragments": [],
                "text": "Coding, Analysis, Interpretation, and Recognition of Facial Expressions"
            },
            "tldr": {
                "abstractSimilarityScore": 93,
                "text": "A computer vision system for observing facial motion by using an optimal estimation optical flow method coupled with geometric, physical and motion-based dynamic models describing the facial structure produces a reliable parametric representation of the face's independent muscle action groups, as well as an accurate estimate of facial motion."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2115439468"
                        ],
                        "name": "Yuntao Cui",
                        "slug": "Yuntao-Cui",
                        "structuredName": {
                            "firstName": "Yuntao",
                            "lastName": "Cui",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yuntao Cui"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2995060"
                        ],
                        "name": "D. Swets",
                        "slug": "D.-Swets",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Swets",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Swets"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145926447"
                        ],
                        "name": "J. Weng",
                        "slug": "J.-Weng",
                        "structuredName": {
                            "firstName": "Juyang",
                            "lastName": "Weng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Weng"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 172,
                                "start": 169
                            }
                        ],
                        "text": "The most common technique for attaining the threedimensional information of movement is to recover the pose of the person or object at each time instant using a three-dimensional model."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 15056207,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "98c154b8011cbb7725dd2ffda3346649843e5ec5",
            "isKey": false,
            "numCitedBy": 121,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a self-organizing framework called the SHOSLIF-M for learning and recognizing spatiotemporal events (or patterns) from intensity image sequences. The proposed framework consists of a multiclass, multivariate discriminant analysis to automatically select the most discriminating features (MDF), a space partition tree to achieve a logarithmic retrieval time complexity for a database of n items, and a general interpolation scheme to do view inference and generalization in the MDF space based on a small number of training samples. The system is tested to recognize 28 different hand signs. The experimental results show that the learned system can achieve a 96% recognition rate for test sequences that have not been used in the training phase.<<ETX>>"
            },
            "slug": "Learning-based-hand-sign-recognition-using-Cui-Swets",
            "title": {
                "fragments": [],
                "text": "Learning-based hand sign recognition using SHOSLIF-M"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "A multiclass, multivariate discriminant analysis to automatically select the most discriminating features (MDF), a space partition tree to achieve a logarithmic retrieval time complexity for a database of n items, and a general interpolation scheme to do view inference and generalization in the MDF space based on a small number of training samples are presented."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IEEE International Conference on Computer Vision"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144177248"
                        ],
                        "name": "James M. Rehg",
                        "slug": "James-M.-Rehg",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Rehg",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "James M. Rehg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733113"
                        ],
                        "name": "T. Kanade",
                        "slug": "T.-Kanade",
                        "structuredName": {
                            "firstName": "Takeo",
                            "lastName": "Kanade",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kanade"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 62,
                                "start": 58
                            }
                        ],
                        "text": "We divide the prior work into generic model recovery, appearance-based models, and direct motion-based recognition."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Index Terms\u00d0Motion recognition, computer vision.\n\u00e6"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 30,
                                "start": 26
                            }
                        ],
                        "text": "Bobick [6] considers the range of motion interpretation problems and proposes a taxonomy of approaches."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 17009967,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f3740a2ab2936c2d87f6a3d8b742841a383ba502",
            "isKey": false,
            "numCitedBy": 502,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "Computer sensing of hand and limb motion is an important problem for applications in human computer interaction and computer graphics. We describe a framework for local trading of self occluding motion, in which one part of an object obstructs the visibility of another. Our approach uses a kinematic model to predict occlusions and windowed templates to track partially occluded objects. We present offline 3D tracking results for hand motion with significant self occlusion.<<ETX>>"
            },
            "slug": "Model-based-tracking-of-self-occluding-articulated-Rehg-Kanade",
            "title": {
                "fragments": [],
                "text": "Model-based tracking of self-occluding articulated objects"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "This work describes a framework for local trading of self occluding motion, in which one part of an object obstructs the visibility of another, using a kinematic model to predict occlusions and windowed templates to track partially occluded objects."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IEEE International Conference on Computer Vision"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1705627"
                        ],
                        "name": "J. Aggarwal",
                        "slug": "J.-Aggarwal",
                        "structuredName": {
                            "firstName": "Jake",
                            "lastName": "Aggarwal",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Aggarwal"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3023166"
                        ],
                        "name": "N. Nandhakumar",
                        "slug": "N.-Nandhakumar",
                        "structuredName": {
                            "firstName": "Nagaraj",
                            "lastName": "Nandhakumar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Nandhakumar"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 110,
                                "start": 107
                            }
                        ],
                        "text": "The Recognition of Human Movement Using Temporal Templates Aaron F. Bobick, Member, IEEE Computer Society, and\nJames W. Davis, Member, IEEE Computer Society\nAbstract\u00d0A new view-based approach to the representation and recognition of human movement is presented."
                    },
                    "intents": []
                }
            ],
            "corpusId": 53680608,
            "fieldsOfStudy": [
                "Chemistry"
            ],
            "id": "a03c5a0bbe99c87a6fdcb5ea8c37cbc776fde993",
            "isKey": false,
            "numCitedBy": 766,
            "numCiting": 98,
            "paperAbstract": {
                "fragments": [],
                "text": "Recent developments are reviewed in the computation of motion and structure of objects in a scene from a sequence of images. Two distinct paradigms are highlighted: (i) the feature-based approach and (ii) the optical-flow-based approach. The comparative merits/demerits of these approaches are discussed. The current status of research in these areas is reviewed and future research directions are indicated. >"
            },
            "slug": "On-the-computation-of-motion-from-sequences-of-Aggarwal-Nandhakumar",
            "title": {
                "fragments": [],
                "text": "On the computation of motion from sequences of images-A review"
            },
            "tldr": {
                "abstractSimilarityScore": 37,
                "text": "Two distinct paradigms are highlighted: (i) the feature- based approach and (ii) the optical-flow-based approach: the comparative merits/demerits of these approaches are discussed."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1772763"
                        ],
                        "name": "E. Bernardo",
                        "slug": "E.-Bernardo",
                        "structuredName": {
                            "firstName": "Enrico",
                            "lastName": "Bernardo",
                            "middleNames": [
                                "Di"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Bernardo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2149680415"
                        ],
                        "name": "L. Goncalves",
                        "slug": "L.-Goncalves",
                        "structuredName": {
                            "firstName": "Luis",
                            "lastName": "Goncalves",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Goncalves"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46614172"
                        ],
                        "name": "Enrico Ursella",
                        "slug": "Enrico-Ursella",
                        "structuredName": {
                            "firstName": "Enrico",
                            "lastName": "Ursella",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Enrico Ursella"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1690922"
                        ],
                        "name": "P. Perona",
                        "slug": "P.-Perona",
                        "structuredName": {
                            "firstName": "Pietro",
                            "lastName": "Perona",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Perona"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "We divide the prior work into generic model recovery, appearance-based models, and direct motion-based recognition."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 19164875,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "7d91d26d47289d5633693cb6e91cb23b26195486",
            "isKey": false,
            "numCitedBy": 266,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "We address the problem of estimating the position and motion of a human arm in 3D without any constraints on its behavior and without the use of special markers. We model the arm as two truncated right-circular cones connected with spherical joints. We propose to use a recursive estimator for arm position, and to provide the estimator with error signals obtained by comparing the projected estimated arm position with that of the actual arm in the image. The system is demonstrated and tested on a real image sequence.<<ETX>>"
            },
            "slug": "Monocular-tracking-of-the-human-arm-in-3D-Bernardo-Goncalves",
            "title": {
                "fragments": [],
                "text": "Monocular tracking of the human arm in 3D"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This work proposes to use a recursive estimator for arm position, and to provide the estimator with error signals obtained by comparing the projected estimated arm position with that of the actual arm in the image."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IEEE International Conference on Computer Vision"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1964574"
                        ],
                        "name": "Y. Yacoob",
                        "slug": "Y.-Yacoob",
                        "structuredName": {
                            "firstName": "Yaser",
                            "lastName": "Yacoob",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Yacoob"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1693428"
                        ],
                        "name": "L. Davis",
                        "slug": "L.-Davis",
                        "structuredName": {
                            "firstName": "Larry",
                            "lastName": "Davis",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Davis"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 17,
                                "start": 12
                            }
                        ],
                        "text": "Gavrila and Davis [14] also used a full-body model (22 DOF, tapered superquadrics) for tracking human motion against a complex background."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 52,
                                "start": 36
                            }
                        ],
                        "text": "For Black and Yacoob [4] and, also, Yacoob and Davis [28], optical flow measurements are used to help track predefined polygonal patches placed on interest regions (e.g., mouth)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 99,
                                "start": 95
                            }
                        ],
                        "text": ", characteristic motion of the mouth, eyes, and eyebrows) using region-based motion properties [28], [4], [12]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 57,
                                "start": 53
                            }
                        ],
                        "text": "For Black and Yacoob [4] and, also, Yacoob and Davis [28], optical flow measurements are used to help track predefined polygonal patches placed on interest regions (e."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 10,
                                "start": 5
                            }
                        ],
                        "text": "J.W. Davis is with the Computer and Information Science Department, The Ohio State University, 583 Dreese Labs, 2015 Neil Ave., Columbus, OH 43210."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 53,
                                "start": 49
                            }
                        ],
                        "text": "Direct motion recognition [22], [25], [20], [4], [28], [26], [12], [7] approaches attempt to characterize the motion itself without reference to the underlying static poses of the body."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 125,
                                "start": 120
                            }
                        ],
                        "text": "The Recognition of Human Movement Using Temporal Templates Aaron F. Bobick, Member, IEEE Computer Society, and\nJames W. Davis, Member, IEEE Computer Society\nAbstract\u00d0A new view-based approach to the representation and recognition of human movement is presented."
                    },
                    "intents": []
                }
            ],
            "corpusId": 18445032,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ac1854f0603f2130c334ae4c2c28f260c3e5cd63",
            "isKey": true,
            "numCitedBy": 77,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "An approach to the analysis and representation of facial dynamics for recognition of facial expressions from image sequences is proposed. The algorithms we develop utilize optical ow computation to identify the directions of rigid and non-rigid motions that are caused by human facial expressions. A mid-level symbolic representation motivated by linguistic and psychological considerations is developed. Recognition of six facial expressions, as well as eye blinking, is demonstrated on a large set of image sequences."
            },
            "slug": "Recognizing-Human-FACIAL-EXPRESSION-Yacoob-Davis",
            "title": {
                "fragments": [],
                "text": "Recognizing Human FACIAL EXPRESSION"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "The algorithms developed utilize optical ow computation to identify the directions of rigid and non-rigid motions that are caused by human facial expressions and a mid-level symbolic representation motivated by linguistic and psychological considerations is developed."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144677513"
                        ],
                        "name": "David G. Jones",
                        "slug": "David-G.-Jones",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Jones",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David G. Jones"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143751119"
                        ],
                        "name": "Jitendra Malik",
                        "slug": "Jitendra-Malik",
                        "structuredName": {
                            "firstName": "Jitendra",
                            "lastName": "Malik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jitendra Malik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 24,
                                "start": 20
                            }
                        ],
                        "text": "Let I x; y; t be an image sequence and let D x; y; t be a binary image sequence indicating regions of motion; for many applications image-\ndifferencing is adequate to generate D."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 359416,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1ff22944d8a76831867d902570ed85a7e0e3cac6",
            "isKey": false,
            "numCitedBy": 174,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a computational framework for stereopsis based on the outputs of linear spatial filters tuned to a range of orientations and scales. This approach goes beyond edge-based and area-based approaches by using a richer image description and incorporating several stereo cues that previously have been neglected in the computer vision literature. A technique based on using the pseudo-inverse is presented for characterizing the information present in a vector of filter responses. We show how in our framework viewing geometry can be recovered to determine the locations of epipolar lines. An assumption that visible surfaces in the scene are piecewise smooth leads to differential treatment of image regions corresponding to binocularly visible surfaces, surface boundaries, and occluded regions that are only monocularly visible. The constraints imposed by viewing geometry and piecewise smoothness are incorporated into an iterative algorithm that gives good results on random-dot stereograms, artificially generated scenes, and natural grey-level images."
            },
            "slug": "A-Computational-Framework-for-Determining-Stereo-a-Jones-Malik",
            "title": {
                "fragments": [],
                "text": "A Computational Framework for Determining Stereo Correspondence from a Set of Linear Spatial Filters"
            },
            "tldr": {
                "abstractSimilarityScore": 71,
                "text": "A computational framework for stereopsis based on the outputs of linear spatial filters tuned to a range of orientations and scales is presented and a technique based on using the pseudo-inverse is presented for characterizing the information present in a vector of filter responses."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "97129855"
                        ],
                        "name": "M. Hu",
                        "slug": "M.-Hu",
                        "structuredName": {
                            "firstName": "Ming-Kuei",
                            "lastName": "Hu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Hu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 28,
                                "start": 24
                            }
                        ],
                        "text": "We will show examples of how the two images together provide better discrimination than either alone."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6431165,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ce1e3528047cd01937f6a8aa760640f6b3c8d531",
            "isKey": false,
            "numCitedBy": 8012,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper a theory of two-dimensional moment invariants for planar geometric figures is presented. A fundamental theorem is established to relate such moment invariants to the well-known algebraic invariants. Complete systems of moment invariants under translation, similitude and orthogonal transformations are derived. Some moment invariants under general two-dimensional linear transformations are also included. Both theoretical formulation and practical models of visual pattern recognition based upon these moment invariants are discussed. A simple simulation program together with its performance are also presented. It is shown that recognition of geometrical patterns and alphabetical characters independently of position, size and orientation can be accomplished. It is also indicated that generalization is possible to include invariance with parallel projection."
            },
            "slug": "Visual-pattern-recognition-by-moment-invariants-Hu",
            "title": {
                "fragments": [],
                "text": "Visual pattern recognition by moment invariants"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "It is shown that recognition of geometrical patterns and alphabetical characters independently of position, size and orientation can be accomplished and it is indicated that generalization is possible to include invariance with parallel projection."
            },
            "venue": {
                "fragments": [],
                "text": "IRE Trans. Inf. Theory"
            },
            "year": 1962
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688328"
                        ],
                        "name": "A. Bobick",
                        "slug": "A.-Bobick",
                        "structuredName": {
                            "firstName": "Aaron",
                            "lastName": "Bobick",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Bobick"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1705903"
                        ],
                        "name": "S. Intille",
                        "slug": "S.-Intille",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Intille",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Intille"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2111091821"
                        ],
                        "name": "James W. Davis",
                        "slug": "James-W.-Davis",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Davis",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "James W. Davis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34968010"
                        ],
                        "name": "F. Baird",
                        "slug": "F.-Baird",
                        "structuredName": {
                            "firstName": "Freedom",
                            "lastName": "Baird",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Baird"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1766240"
                        ],
                        "name": "Claudio S. Pinhanez",
                        "slug": "Claudio-S.-Pinhanez",
                        "structuredName": {
                            "firstName": "Claudio",
                            "lastName": "Pinhanez",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Claudio S. Pinhanez"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49540989"
                        ],
                        "name": "Lee W. Campbell",
                        "slug": "Lee-W.-Campbell",
                        "structuredName": {
                            "firstName": "Lee",
                            "lastName": "Campbell",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lee W. Campbell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32511979"
                        ],
                        "name": "Y. Ivanov",
                        "slug": "Y.-Ivanov",
                        "structuredName": {
                            "firstName": "Yuri",
                            "lastName": "Ivanov",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Ivanov"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32294506"
                        ],
                        "name": "A. Sch\u00fctte",
                        "slug": "A.-Sch\u00fctte",
                        "structuredName": {
                            "firstName": "Arjan",
                            "lastName": "Sch\u00fctte",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Sch\u00fctte"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145771244"
                        ],
                        "name": "Andrew D. Wilson",
                        "slug": "Andrew-D.-Wilson",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Wilson",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew D. Wilson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 212,
                                "start": 211
                            }
                        ],
                        "text": "The basis of the representation is a temporal template\u00d0a static vector-image where the vector value at each point is a function of the motion properties at the corresponding spatial location in an image sequence."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1980573,
            "fieldsOfStudy": [
                "Art"
            ],
            "id": "e4424412084e742339d1f4f5ea756322bc8396b6",
            "isKey": false,
            "numCitedBy": 433,
            "numCiting": 80,
            "paperAbstract": {
                "fragments": [],
                "text": "The KidsRoom is a perceptually-based, interactive, narrative playspace for children. Images, music, narration, light, and sound effects are used to transform a normal child's bedroom into a fantasy land where children are guided through a reactive adventure story. The fully automated system was designed with the following goals: (1) to keep the focus of user action and interaction in the physical and not virtual space; (2) to permit multiple, collaborating people to simultaneously engage in an interactive experience combining both real and virtual objects; (3) to use computer-vision algorithms to identify activity in the space without requiring the participants to wear any special clothing or devices; (4) to use narrative to constrain the perceptual recognition, and to use perceptual recognition to allow participants to drive the narrative; and (5) to create a truly immersive and interactive room environment. We believe the KidsRoom is the first multi-person, fully-automated, interactive, narrative environment ever constructed using non-encumbering sensors. This paper describes the KidsRoom, the technology that makes it work, and the issues that were raised during the system's development.1 A demonstration of the project, which complements the material presented here and includes videos, images, and sounds from each part of the story is available at ."
            },
            "slug": "The-KidsRoom:-A-Perceptually-Based-Interactive-and-Bobick-Intille",
            "title": {
                "fragments": [],
                "text": "The KidsRoom: A Perceptually-Based Interactive and Immersive Story Environment"
            },
            "tldr": {
                "abstractSimilarityScore": 51,
                "text": "It is believed that the KidsRoom is the first multi-person, fully-automated, interactive, narrative environment ever constructed using non-encumbering sensors."
            },
            "venue": {
                "fragments": [],
                "text": "Presence"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144677513"
                        ],
                        "name": "David G. Jones",
                        "slug": "David-G.-Jones",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Jones",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David G. Jones"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143751119"
                        ],
                        "name": "Jitendra Malik",
                        "slug": "Jitendra-Malik",
                        "structuredName": {
                            "firstName": "Jitendra",
                            "lastName": "Malik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jitendra Malik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "The vector-image template is similar in spirit to the vector-image based on orientation and edges used by Jones and Malik [ 18 ] for robust stereo matching."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 13573519,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ef4da68443bd6fa826b05196f4fccdb62588a426",
            "isKey": false,
            "numCitedBy": 200,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Computational-framework-for-determining-stereo-from-Jones-Malik",
            "title": {
                "fragments": [],
                "text": "Computational framework for determining stereo correspondence from a set of linear spatial filters"
            },
            "venue": {
                "fragments": [],
                "text": "Image Vis. Comput."
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 17,
                                "start": 0
                            }
                        ],
                        "text": "Polana and Nelson use repetitive motion as a strong cue to recognize cyclic walking motions."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 94,
                                "start": 90
                            }
                        ],
                        "text": "This understanding generally requires previous recognition and segmentation of the person [22]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 30,
                                "start": 26
                            }
                        ],
                        "text": "Direct motion recognition [22], [25], [20], [4], [28], [26], [12], [7] approaches attempt to characterize the motion itself without reference to the underlying static poses of the body."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 69,
                                "start": 65
                            }
                        ],
                        "text": "Of the ablob-analysiso approaches, the work of Polana and Nelson [22], Shavit and Jepson [25] and, also, Little and Boyd [20] are most applicable."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 216,
                                "start": 212
                            }
                        ],
                        "text": ", ain this pixel there has been a large amount of motion in the down direction during the integrating time windowo) or the spatially localized periodicity of motion (a pixel by pixel version of Polana and Nelson [22])."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 323,
                                "start": 306
                            }
                        ],
                        "text": "Other possible components of the\ntemporal templates include power in directional motion integrated over time (e.g., \u00aain this pixel there has been a large amount of motion in the down direction during the integrating time window\u00ba) or the spatially localized periodicity of motion (a pixel by pixel version of Polana and Nelson [22])."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 62,
                                "start": 45
                            }
                        ],
                        "text": "Of the \u00aablob-analysis\u00ba approaches, the work of Polana and Nelson [22], Shavit and Jepson [25] and, also, Little and Boyd [20] are most applicable."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aLow Level Recognition of Human Motion,o"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. IEEE Workshop Non-Rigid and Articulated Motion,"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1964574"
                        ],
                        "name": "Y. Yacoob",
                        "slug": "Y.-Yacoob",
                        "structuredName": {
                            "firstName": "Yaser",
                            "lastName": "Yacoob",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Yacoob"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1693428"
                        ],
                        "name": "L. Davis",
                        "slug": "L.-Davis",
                        "structuredName": {
                            "firstName": "Larry",
                            "lastName": "Davis",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Davis"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 53,
                                "start": 49
                            }
                        ],
                        "text": "As for action recognition, Campbell and Bobick [8] used a commercially available system to obtain three-dimensional data of human body limb positions."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "These two approaches address the problem of recognizing actions when the precise configuration of the person and environment is known while the methods from the previous section concentrate on the recovery of the object pose."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 30279848,
            "fieldsOfStudy": [
                "Chemistry"
            ],
            "id": "5d426fa7f03803e1b3588c601f3a06c2d062fb2a",
            "isKey": false,
            "numCitedBy": 490,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "Low-oil-content, fully lubricated leather is produced by (1) treatment of leather with water emulsions of mixtures of alkanolamine soaps, oils, surfactants having HLB values between 2 and 6, and coupling solvents; and (2) acidification of the leather."
            },
            "slug": "Recognizing-Human-Facial-Expressions-From-Long-Flow-Yacoob-Davis",
            "title": {
                "fragments": [],
                "text": "Recognizing Human Facial Expressions From Long Image Sequences Using Optical Flow"
            },
            "tldr": {
                "abstractSimilarityScore": 99,
                "text": "Low-oil-content, fully lubricated leather is produced by treatment of leather with water emulsions of mixtures of alkanolamine soaps, oils, surfactants having HLB values between 2 and 6, and coupling solvents."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 17,
                                "start": 0
                            }
                        ],
                        "text": "Polana and Nelson use repetitive motion as a strong cue to recognize cyclic walking motions."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 94,
                                "start": 90
                            }
                        ],
                        "text": "This understanding generally requires previous recognition and segmentation of the person [22]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 30,
                                "start": 26
                            }
                        ],
                        "text": "Direct motion recognition [22], [25], [20], [4], [28], [26], [12], [7] approaches attempt to characterize the motion itself without reference to the underlying static poses of the body."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 69,
                                "start": 65
                            }
                        ],
                        "text": "Of the ablob-analysiso approaches, the work of Polana and Nelson [22], Shavit and Jepson [25] and, also, Little and Boyd [20] are most applicable."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 216,
                                "start": 212
                            }
                        ],
                        "text": ", ain this pixel there has been a large amount of motion in the down direction during the integrating time windowo) or the spatially localized periodicity of motion (a pixel by pixel version of Polana and Nelson [22])."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 323,
                                "start": 306
                            }
                        ],
                        "text": "Other possible components of the\ntemporal templates include power in directional motion integrated over time (e.g., \u00aain this pixel there has been a large amount of motion in the down direction during the integrating time window\u00ba) or the spatially localized periodicity of motion (a pixel by pixel version of Polana and Nelson [22])."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 62,
                                "start": 45
                            }
                        ],
                        "text": "Of the \u00aablob-analysis\u00ba approaches, the work of Polana and Nelson [22], Shavit and Jepson [25] and, also, Little and Boyd [20] are most applicable."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aLow Level Recognition of Human Motion,o"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. IEEE Workshop Non-Rigid and Articulated Motion,"
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 8,
                                "start": 3
                            }
                        ],
                        "text": "In Akita's work [3], the use of edges and some simple two-dimensional body configuration knowledge (e.g., the arm is a protrusion out from the torso) are used to determine the body parts in a hierarchical manner (first, find legs, then head, arms, trunk) based on stability."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 45,
                                "start": 42
                            }
                        ],
                        "text": "[29] examines body silhouettes, and Akita [3] employs body contours/edges."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 108,
                                "start": 103
                            }
                        ],
                        "text": "As opposed to using the actual raw gray-scale image, Yamato et al. [29] examines body silhouettes, and Akita [3] employs body contours/edges."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 19,
                                "start": 16
                            }
                        ],
                        "text": "In Akita's work [3], the use of edges and some simple two-dimensional body configuration knowledge (e."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aImage Sequence Analysis of Real World Human Motion,o"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognition,"
            },
            "year": 1984
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 180,
                                "start": 177
                            }
                        ],
                        "text": "1 illustrates the motivation for the work described here and for earlier work, which attempted to exploit similar motion information through a different computational mechanism [7]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 70,
                                "start": 67
                            }
                        ],
                        "text": "Direct motion recognition [22], [25], [20], [4], [28], [26], [12], [7] approaches attempt to characterize the motion itself without reference to the underlying static poses of the body."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 6,
                                "start": 3
                            }
                        ],
                        "text": "In [7], we exploited the smooth variation of motion over angle to compress the entire view circle into a low-order representation."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 6,
                                "start": 3
                            }
                        ],
                        "text": "In [7], we first proposed a representation and recognition theory that decomposed motion-based recognition into first describing where there is motion (the spatial pattern) and then describing how the"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 27,
                                "start": 24
                            }
                        ],
                        "text": "The approach we took in [7] for recognizing whole body movements was an attempt to generalize the face patch tracking technique."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aAn Appearance-Based Representation of Action,o"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. Int'l Conf. Pattern Recognition,"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 28,
                                "start": 13
                            }
                        ],
                        "text": "For example, Rehg and Kanade [23] used a 27 degree-offreedom (DOF) model of a human hand in their system called \u00aaDigiteyes.\u00ba Local image-based trackers are employed to align the projected model lines to the finger edges against a solid background."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 159,
                                "start": 155
                            }
                        ],
                        "text": "Because of the self-occlusions that frequently occur in articulated objects, some systems employ multiple cameras and restrict the motion to small regions [23], [14] to help with projective model occlusion constraints."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 33,
                                "start": 29
                            }
                        ],
                        "text": "For example, Rehg and Kanade [23] used a 27 degree-of-"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 117,
                                "start": 113
                            }
                        ],
                        "text": "Given the past history of the model configurations, prediction is commonly attained using Kalman filtering [24], [23], [15] and velocity constraints [14]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 83,
                                "start": 79
                            }
                        ],
                        "text": "of a person and then recognizing the motion of the model as advocated in [16], [23], [24]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aModel-Based Tracking of Self-Occluding Articulated Objects,o"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. Int'l Conf. Computer Vision,"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 110,
                                "start": 106
                            }
                        ],
                        "text": ", characteristic motion of the mouth, eyes, and eyebrows) using region-based motion properties [28], [4], [12]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 69,
                                "start": 65
                            }
                        ],
                        "text": "Optical flow, rather than patches, was used by Essa and Pentland [12] to estimate muscle activation on a detailed, physically-based model of the face."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 65,
                                "start": 61
                            }
                        ],
                        "text": "Direct motion recognition [22], [25], [20], [4], [28], [26], [12], [7] approaches attempt to characterize the motion itself without reference to the underlying static poses of the body."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 49,
                                "start": 41
                            }
                        ],
                        "text": "For example, Cui et al. [9], Darrell and Pentland [10] and, also, Wilson and Bobick [27] present results using actions (mostly hand gestures), where the actual grayscale images (with no background) are used in the representation for the action."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aCoding, Analysis, Interpretation, and Recognition of Facial Expressions,o"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Analysis and Machine Intelligence,"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 36,
                                "start": 32
                            }
                        ],
                        "text": "Direct motion recognition [22], [25], [20], [4], [28], [26], [12], [7] approaches attempt to characterize the motion itself without reference to the underlying static poses of the body."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 93,
                                "start": 89
                            }
                        ],
                        "text": "Of the ablob-analysiso approaches, the work of Polana and Nelson [22], Shavit and Jepson [25] and, also, Little and Boyd [20] are most applicable."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 86,
                                "start": 69
                            }
                        ],
                        "text": "Of the \u00aablob-analysis\u00ba approaches, the work of Polana and Nelson [22], Shavit and Jepson [25] and, also, Little and Boyd [20] are most applicable."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 17,
                                "start": 0
                            }
                        ],
                        "text": "Shavit and Jepson also take an approach using the gross overall motion of the person."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aMotion Understanding Using Phase Portraits,o"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. IJCAI Workshop: Looking at People,"
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 64,
                                "start": 60
                            }
                        ],
                        "text": "[9], Darrell and Pentland [10] and, also, Wilson and Bobick [27] present results using actions (mostly hand gestures), where the actual grayscale images (with no background) are used in the representation for the action."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 6,
                                "start": 0
                            }
                        ],
                        "text": "Bobick [6] considers the range of motion interpretation problems and proposes a taxonomy of approaches."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 74,
                                "start": 68
                            }
                        ],
                        "text": "The Recognition of Human Movement Using Temporal Templates Aaron F. Bobick, Member, IEEE Computer Society, and\nJames W. Davis, Member, IEEE Computer Society\nAbstract\u00d0A new view-based approach to the representation and recognition of human movement is presented."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 11,
                                "start": 5
                            }
                        ],
                        "text": "A.F. Bobick is with the College of Computing, Georgia Tech, 801 Atlantic Dr., Atlanta, GA 30332."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 46,
                                "start": 40
                            }
                        ],
                        "text": "As for action recognition, Campbell and Bobick [8] used a commercially available system to obtain three-dimensional data of human body limb positions."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 83,
                                "start": 66
                            }
                        ],
                        "text": "For example, Cui et al. [9], Darrell and Pentland [10] and, also, Wilson and Bobick [27] present results using actions (mostly hand gestures), where the actual grayscale images (with no background) are used in the representation for the action."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aLearning Visual Behavior for Gesture Analysis,o"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. IEEE Int'l. Symp. Computer Vision,"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 6,
                                "start": 0
                            }
                        ],
                        "text": "Bobick [6] considers the range of motion interpretation problems and proposes a taxonomy of approaches."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 74,
                                "start": 68
                            }
                        ],
                        "text": "The Recognition of Human Movement Using Temporal Templates Aaron F. Bobick, Member, IEEE Computer Society, and\nJames W. Davis, Member, IEEE Computer Society\nAbstract\u00d0A new view-based approach to the representation and recognition of human movement is presented."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 11,
                                "start": 5
                            }
                        ],
                        "text": "A.F. Bobick is with the College of Computing, Georgia Tech, 801 Atlantic Dr., Atlanta, GA 30332."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 50,
                                "start": 47
                            }
                        ],
                        "text": "As for action recognition, Campbell and Bobick [8] used a commercially available system to obtain three-dimensional data of human body limb positions."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 83,
                                "start": 77
                            }
                        ],
                        "text": "For example, Cui et al. [9], Darrell and Pentland [10] and, also, Wilson and Bobick [27] present results using actions (mostly hand gestures), where the actual grayscale images (with no background) are used in the representation for the action."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aRecognition of Human Body Motion Using Phase Space Constraints,o"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. Int'l Conf. Computer Vision,"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 42,
                                "start": 38
                            }
                        ],
                        "text": "As for action recognition, Campbell and Bobick [8] used a commercially available system to obtain three-dimensional data of human body limb positions."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 65,
                                "start": 61
                            }
                        ],
                        "text": "The input to his system consisted of line-drawings of a person, table, and ball."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "\u00aaDescribing Motion for Recognition,\u00ba Int'l Symp. Computer Vision"
            },
            "venue": {
                "fragments": [],
                "text": "\u00aaDescribing Motion for Recognition,\u00ba Int'l Symp. Computer Vision"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "We divide the prior work into generic model recovery, appearance-based models, and direct motion-based recognition."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 24,
                                "start": 20
                            }
                        ],
                        "text": "Bobick [6] considers the range of motion interpretation problems and proposes a taxonomy of approaches."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "\u00aaModel-Based Vision: A Paradigm to See a Walking Person"
            },
            "venue": {
                "fragments": [],
                "text": "Image and Vision Computing"
            },
            "year": 1983
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 243,
                                "start": 240
                            }
                        ],
                        "text": "Using aerobics exercises as a test domain, we explore the representational power of a simple, two component version of the templates: The first value is a binary value indicating the presence of motion and the second value is a function of the recency of motion in a sequence."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The Role of Knowledge in the Perception of Motion,\u00ba Philosophical Trans"
            },
            "venue": {
                "fragments": [],
                "text": "The Role of Knowledge in the Perception of Motion,\u00ba Philosophical Trans"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 36,
                                "start": 32
                            }
                        ],
                        "text": "As for action recognition, Campbell and Bobick [8] used a commercially available system to obtain three-dimensional data of human body limb positions."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 33,
                                "start": 29
                            }
                        ],
                        "text": "The input to his system consisted of line-drawings of a person, table, and ball."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "\u00aaMotion Understanding Using Phase Portraits"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. IJCAI Workshop: Looking at People"
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[19] have extended this work with faces to include tracking the legs of a person walking."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aCardboard People: A Parameterized Model of Articulated image Motion,o"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. Second Int'l Conf. Automatic Face and Gesture Recognition,"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 167,
                                "start": 163
                            }
                        ],
                        "text": "The most common technique for attaining the threedimensional information of movement is to recover the pose of the person or object at each time instant using a three-dimensional model."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Proc. Computer Vision and Pattern Recognition"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. Computer Vision and Pattern Recognition"
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 41,
                                "start": 37
                            }
                        ],
                        "text": ", [13]) and interactive environments [21], [5]."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aThe ALIVE System: Wireless, Full-Body Interaction with Autonomous Agents,o"
            },
            "venue": {
                "fragments": [],
                "text": "ACM Multimedia Systems,"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[15] promoted three-dimensional tracking of the human arm against a uniform background using a two cone arm"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 37,
                                "start": 33
                            }
                        ],
                        "text": "A single camera is used in [16], [15], [24], but the actions tracked in these works had little deviation in the depth of motion."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 123,
                                "start": 119
                            }
                        ],
                        "text": "Given the past history of the model configurations, prediction is commonly attained using Kalman filtering [24], [23], [15] and velocity constraints [14]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aMonocular Tracking of the Human Arm in 3D,o"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. Int'l Conf. Computer Vision,"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "a 3 D Model - Based Tracking of Humans in Action : A Multiview Approach"
            },
            "venue": {
                "fragments": [],
                "text": "o Proc . Computer Vision and Pattern Recognition"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 10,
                                "start": 7
                            }
                        ],
                        "text": "Bobick [6] considers the range of motion interpretation"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aMovement, Activity, and Action: The Role of Knowledge in the Perception of Motion,o"
            },
            "venue": {
                "fragments": [],
                "text": "Philosophical Trans. Royal Soc. London,"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 83,
                                "start": 80
                            }
                        ],
                        "text": "The application was titled The KidsRoom, an interactive play-space for children [5]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 46,
                                "start": 43
                            }
                        ],
                        "text": ", [13]) and interactive environments [21], [5]."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aThe Kids- Room: A Perceptually-Based Interactive and Immersive Story Environment,o"
            },
            "venue": {
                "fragments": [],
                "text": "Presence, vol. 8,"
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 50,
                                "start": 47
                            }
                        ],
                        "text": "survey on the machine analysis of human motion [2]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aHuman Motion Analysis: A Review,o"
            },
            "venue": {
                "fragments": [],
                "text": "Computer Vision and Image Understanding,"
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 77,
                                "start": 73
                            }
                        ],
                        "text": "of a person and then recognizing the motion of the model as advocated in [16], [23], [24]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 9,
                                "start": 5
                            }
                        ],
                        "text": "Hogg [16] and Rohr [24] used a full-body cylindrical model for tracking walking humans in natural scenes."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 31,
                                "start": 27
                            }
                        ],
                        "text": "A single camera is used in [16], [15], [24], but the actions tracked in these works had little deviation in the depth of motion."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aModel-Based Vision: A Paradigm to See a Walking Person,o"
            },
            "venue": {
                "fragments": [],
                "text": "Image and Vision Computing,"
            },
            "year": 1983
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 3,
                                "start": 0
                            }
                        ],
                        "text": "[9], Darrell and Pentland [10] and, also, Wilson and Bobick [27] present results using actions (mostly hand gestures), where the actual grayscale images (with no background) are used in the representation for the action."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aLearning-Based Hand Sign Recognition Using Shoslif-m,o"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. Int'l Conf. Computer Vision,"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 174,
                                "start": 170
                            }
                        ],
                        "text": "The basis of the representation is a temporal template\u00d0a static vector-image where the vector value at each point is a function of the motion properties at the corresponding spatial location in an image sequence."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "\u00aaOrientation Histogram for Hand Gesture Recognition"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. Int'l Workshop Automatic Face and Gesture Recognition"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "a Orientation Histogram for Hand Gesture Recognition"
            },
            "venue": {
                "fragments": [],
                "text": "o IEEE Trans . Pattern Analysis and Machine Intelligence"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "We divide the prior work into generic model recovery, appearance-based models, and direct motion-based recognition."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 36,
                                "start": 32
                            }
                        ],
                        "text": "Bobick [6] considers the range of motion interpretation problems and proposes a taxonomy of approaches."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "\u00aaTowards Model-Based Recognition of Human Movements in Image Sequences,\u00ba CVGIP, Image Understanding"
            },
            "venue": {
                "fragments": [],
                "text": "\u00aaTowards Model-Based Recognition of Human Movements in Image Sequences,\u00ba CVGIP, Image Understanding"
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "a Low Level Recognition of Human Motion"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "We divide the prior work into generic model recovery, appearance-based models, and direct motion-based recognition."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "\u00aa3D Model-Based Tracking of Humans in Action: A Multiview Approach"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. Computer Vision and Pattern Recognition"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 39,
                                "start": 35
                            }
                        ],
                        "text": "Our current choice is 7 Hu moments [17] which are known to yield reasonable shape discrimination in a translation- and scale-invariant manner (See Appendix)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aVisual Pattern Recognition by Moment Invariants,o"
            },
            "venue": {
                "fragments": [],
                "text": "IRE Trans. Information Theory,"
            },
            "year": 1962
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 109,
                                "start": 106
                            }
                        ],
                        "text": "THERE is a rich tradition in computer vision of studying image sequences, an early survey can be found in [1]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aOn the Computation of Motion of Sequences of Images\u00d0A Review,o"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. IEEE,"
            },
            "year": 1988
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 41,
            "methodology": 31,
            "result": 1
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 60,
        "totalPages": 6
    },
    "page_url": "https://www.semanticscholar.org/paper/The-Recognition-of-Human-Movement-Using-Temporal-Bobick-Davis/886431a362bfdbcc6dd518f844eb374950b9de86?sort=total-citations"
}