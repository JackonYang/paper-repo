{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2189557"
                        ],
                        "name": "Step\u00e1n Obdrz\u00e1lek",
                        "slug": "Step\u00e1n-Obdrz\u00e1lek",
                        "structuredName": {
                            "firstName": "Step\u00e1n",
                            "lastName": "Obdrz\u00e1lek",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Step\u00e1n Obdrz\u00e1lek"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145564537"
                        ],
                        "name": "Jiri Matas",
                        "slug": "Jiri-Matas",
                        "structuredName": {
                            "firstName": "Jiri",
                            "lastName": "Matas",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jiri Matas"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 88,
                                "start": 84
                            }
                        ],
                        "text": "Affine covariance of the center of gravity and of the covariance matrix is shown in [16]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 858096,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2519f659dddabfd8f688e6c7dd348c5460a303c1",
            "isKey": false,
            "numCitedBy": 29,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "A novel approach to content-based image retrieval is presented. The method supports recognition of objects under a very wide range of viewing and illumination conditions and is robust to occlusion and background clutter. Starting from robustly detected 'distinguished regions' of data dependent shape, local affine frames are established by affine-invariant constructions exploiting invariant properties of the second moment matrix and bi-tangent points. Direct comparison of photometrically normalised colour intensities in normalised frames facilitates robust, affine and illumination invariant, but still very selective matching. The potential of the proposed approach is experimentally verified on FOCUS -- a publicly available image database - using a standard set of query images. The results obtained are superior to the state of the art. The method operates successfully on images with complex background, where the sought object covers only a fraction (around 2%) of the database image. Examples of precise localisation of the query objects in an image are shown too."
            },
            "slug": "Local-Affine-Frames-for-Image-Retrieval-Obdrz\u00e1lek-Matas",
            "title": {
                "fragments": [],
                "text": "Local Affine Frames for Image Retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 91,
                "text": "A novel approach to content-based image retrieval that supports recognition of objects under a very wide range of viewing and illumination conditions and is robust to occlusion and background clutter is presented."
            },
            "venue": {
                "fragments": [],
                "text": "CIVR"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1704728"
                        ],
                        "name": "T. Tuytelaars",
                        "slug": "T.-Tuytelaars",
                        "structuredName": {
                            "firstName": "Tinne",
                            "lastName": "Tuytelaars",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Tuytelaars"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1681236"
                        ],
                        "name": "L. Gool",
                        "slug": "L.-Gool",
                        "structuredName": {
                            "firstName": "Luc",
                            "lastName": "Gool",
                            "middleNames": [
                                "Van"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Gool"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Robustness to severe occlusions is demonstrated by only a moderate decrease of recognition performance in an experiment where half of each test image is erased."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 552096,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9ad20e6f6f89631caf6960516bb9939b9430bba0",
            "isKey": false,
            "numCitedBy": 568,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "\u2018Invariant regions\u2019 are image patches that automatically deform with changing viewpoint as to keep on covering identical physical parts of a scene. Such regions are then described by a set of invariant features, which makes it relatively easy to match them between views and under changing illumination. In previous work, we have presented invariant regions that are based on a combination of corners and edges. The application discussed then was image database retrieval. Here, an alternative method for extracting (affinely) invariant regions is given, that does not depend on the presence of edges or corners in the image but is purely intensity-based. Also, we demonstrate the use of such regions for another application, which is wide baseline stereo matching. As a matter of fact, the goal is to build an opportunistic system that exploits several types of invariant regions as it sees fit. This yields more correspondences and a system that can deal with a wider range of images. To increase the robustness of the system even further, two semi-local constraints on combinations of region correspondences are derived (one geometric, the other photometric). They allow to test the consistency of correspondences and hence to reject falsely matched regions."
            },
            "slug": "Wide-Baseline-Stereo-Matching-based-on-Local,-Tuytelaars-Gool",
            "title": {
                "fragments": [],
                "text": "Wide Baseline Stereo Matching based on Local, Affinely Invariant Regions"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This work presents an alternative method for extracting invariant regions that does not depend on the presence of edges or corners in the image but is purely intensity-based, and demonstrates the use of such regions for another application, which is wide baseline stereo matching."
            },
            "venue": {
                "fragments": [],
                "text": "BMVC"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712041"
                        ],
                        "name": "K. Mikolajczyk",
                        "slug": "K.-Mikolajczyk",
                        "structuredName": {
                            "firstName": "Krystian",
                            "lastName": "Mikolajczyk",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Mikolajczyk"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2462253"
                        ],
                        "name": "C. Schmid",
                        "slug": "C.-Schmid",
                        "structuredName": {
                            "firstName": "Cordelia",
                            "lastName": "Schmid",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Schmid"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Robustness to severe occlusions is demonstrated by only a moderate decrease of recognition performance in an experiment where half of each test image is erased."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2326264,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "6647f56413722e812cb084fbb3597ba18ceada36",
            "isKey": false,
            "numCitedBy": 759,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a new method for detecting scale invariant interest points. The method is based on two recent results on scale space: (1) Interest points can be adapted to scale and give repeatable results (geometrically stable). (2) Local extrema over scale of normalized derivatives indicate the presence of characteristic local structures. Our method first computes a multi-scale representation for the Harris interest point detector. We then select points at which a local measure (the Laplacian) is maximal over scales. This allows a selection of distinctive points for which the characteristic scale is known. These points are invariant to scale, rotation and translation as well as robust to illumination changes and limited changes of viewpoint. For indexing, the image is characterized by a set of scale invariant points; the scale associated with each point allows the computation of a scale invariant descriptor. Our descriptors are, in addition, invariant to image rotation, of affine illumination changes and robust to small perspective deformations. Experimental results for indexing show an excellent performance up to a scale factor of 4 for a database with more than 5000 images."
            },
            "slug": "Indexing-based-on-scale-invariant-interest-points-Mikolajczyk-Schmid",
            "title": {
                "fragments": [],
                "text": "Indexing Based on Scale Invariant Interest Points"
            },
            "tldr": {
                "abstractSimilarityScore": 96,
                "text": "This paper presents a new method for detecting scale invariant interest points based on two recent results on scale space: 1) Interest points can be adapted to scale and give repeatable results (geometrically stable); 2) local extrema over scale of normalized derivatives indicate the presence of characteristic local structures."
            },
            "venue": {
                "fragments": [],
                "text": "ICCV"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1715634"
                        ],
                        "name": "Ming-Hsuan Yang",
                        "slug": "Ming-Hsuan-Yang",
                        "structuredName": {
                            "firstName": "Ming-Hsuan",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ming-Hsuan Yang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144590225"
                        ],
                        "name": "D. Roth",
                        "slug": "D.-Roth",
                        "structuredName": {
                            "firstName": "Dan",
                            "lastName": "Roth",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Roth"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145237406"
                        ],
                        "name": "N. Ahuja",
                        "slug": "N.-Ahuja",
                        "structuredName": {
                            "firstName": "Narendra",
                            "lastName": "Ahuja",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Ahuja"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "LAFs 99.9% 99.4% 94.7% 87.8% 76.0% SNoW / edges [17] 94.1% 89.2% 88.3% - -SNoW / intensity [17] 92.3% 85.1% 81.5% - -Linear SVM [17] 91.3% 84.8% 78.5% - -Spin-Glass MRF [3] 96.8% 88.2% 69.4% 57.6% 49.9% Nearest Neighbour [ 17 ] 87.5% 79.5% 74.6% - -"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "LAFs 99.9% 99.4% 94.7% 87.8% 76.0% SNoW / edges [ 17 ] 94.1% 89.2% 88.3% - -SNoW / intensity [17] 92.3% 85.1% 81.5% - -Linear SVM [17] 91.3% 84.8% 78.5% - -Spin-Glass MRF [3] 96.8% 88.2% 69.4% 57.6% 49.9% Nearest Neighbour [17] 87.5% 79.5% 74.6% - -"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "LAFs 99.9% 99.4% 94.7% 87.8% 76.0% SNoW / edges [17] 94.1% 89.2% 88.3% - -SNoW / intensity [ 17 ] 92.3% 85.1% 81.5% - -Linear SVM [17] 91.3% 84.8% 78.5% - -Spin-Glass MRF [3] 96.8% 88.2% 69.4% 57.6% 49.9% Nearest Neighbour [17] 87.5% 79.5% 74.6% - -"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "LAFs 99.9% 99.4% 94.7% 87.8% 76.0% SNoW / edges [17] 94.1% 89.2% 88.3% - -SNoW / intensity [17] 92.3% 85.1% 81.5% - -Linear SVM [ 17 ] 91.3% 84.8% 78.5% - -Spin-Glass MRF [3] 96.8% 88.2% 69.4% 57.6% 49.9% Nearest Neighbour [17] 87.5% 79.5% 74.6% - -"
                    },
                    "intents": []
                }
            ],
            "corpusId": 8260003,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "734a76e9328110455669cd029fe82bc1ddb43972",
            "isKey": true,
            "numCitedBy": 66,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes a novel view-based learning algorithm for 3D object recognition from 2D images using a network of linear units. The SNoW learning architecture is a sparse network of linear functions over a pre-defined or incrementally learned feature space and is specifically tailored for learning in the presence of a very large number of features. We use pixel-based and edge-based representations in large scale object recognition experiments in which the performance of SNoW is compared with that of Support Vector Machines (SVMs) and nearest neighbor using the 100 objects in the Columbia Image Object Database (COIL-100). Experimental results show that the SNoW-based method outperforms the SVM-based system in terms of recognition rate and the computational cost involved in learning. Most importantly, SNoW's performance degrades more gracefully when the training data contains fewer views. The empirical results also provide insight into practical and theoretical considerations on view-based methods for 3D object recognition."
            },
            "slug": "Learning-to-Recognize-3D-Objects-with-SNoW-Yang-Roth",
            "title": {
                "fragments": [],
                "text": "Learning to Recognize 3D Objects with SNoW"
            },
            "tldr": {
                "abstractSimilarityScore": 69,
                "text": "A novel view-based learning algorithm for 3D object recognition from 2D images using a network of linear units that outperforms the SVM-based system in terms of recognition rate and the computational cost involved in learning."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2869141"
                        ],
                        "name": "F. Ennesser",
                        "slug": "F.-Ennesser",
                        "structuredName": {
                            "firstName": "Fran\u00e7ois",
                            "lastName": "Ennesser",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Ennesser"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3463966"
                        ],
                        "name": "G. Medioni",
                        "slug": "G.-Medioni",
                        "structuredName": {
                            "firstName": "G\u00e9rard",
                            "lastName": "Medioni",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Medioni"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Robustness to severe occlusions is demonstrated by only a moderate decrease of recognition performance in an experiment where half of each test image is erased."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 9688224,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c7cb3b96aba81b123278627d03c1f60eafa0bed0",
            "isKey": false,
            "numCitedBy": 105,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "A method is presented to locate an object in a color image, or more precisely, to select a set of likely locations for the object. The model is assumed to be of known color, which permits the use of color-space processing. A new method is presented, which exploits more information than the previous backprojection algorithm of Swain and Ballard at a competitive complexity. The new algorithm is based on matching local histograms with the model, instead of directly replacing pixels with a confidence that they belong to the object. It is proved that a simple version of this algorithm degenerates into backprojection in the worst case. The authors show how to estimate the scale of the model. The use of co-occurrence histograms is proposed to deal with cases where important color variations can be expected.<<ETX>>"
            },
            "slug": "Finding-Waldo,-or-focus-of-attention-using-local-Ennesser-Medioni",
            "title": {
                "fragments": [],
                "text": "Finding Waldo, or focus of attention using local color information"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "A new method is presented, which exploits more information than the previous backprojection algorithm of Swain and Ballard at a competitive complexity, based on matching local histograms with the model, instead of directly replacing pixels with a confidence that they belong to the object."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145801638"
                        ],
                        "name": "J. Kittler",
                        "slug": "J.-Kittler",
                        "structuredName": {
                            "firstName": "Josef",
                            "lastName": "Kittler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Kittler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1784741"
                        ],
                        "name": "A. Ahmadyfard",
                        "slug": "A.-Ahmadyfard",
                        "structuredName": {
                            "firstName": "Alireza",
                            "lastName": "Ahmadyfard",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Ahmadyfard"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 130,
                                "start": 127
                            }
                        ],
                        "text": "using the same subset of 24 box-like objects, using one training view per object, and test view angles differing up to 45\u25e6 (in [5] referred as views 6\u201315)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 70,
                                "start": 67
                            }
                        ],
                        "text": "Table 3: SOIL-47: Recognition rate, in comparison to other methods [5]"
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 49,
                                "start": 46
                            }
                        ],
                        "text": "We have used identical experiment setup as in [5], i."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 39864620,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "dbd44830e16476ef401d78473ee153a546ec4678",
            "isKey": true,
            "numCitedBy": 6,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "An experimental comparative study of three matching methods for the recognition of 3D objects from a 2D view is carried out. The methods include graph matching, geometric hashing and the alignment technique. The same source of information is made available to each method to ensure that the comparison is meaningful. The experiments are designed to measure the performance of the methods in different imaging conditions. We show that matching by geometric hashing and alignment is very sensitive to clutter and measurement errors. Thus in realistic scenarios graph matching is superior to the other methods in terms of both recognition accuracy and computational complexity."
            },
            "slug": "On-Matching-Algorithms-for-the-Recognition-of-in-Kittler-Ahmadyfard",
            "title": {
                "fragments": [],
                "text": "On Matching Algorithms for the Recognition of Objects in Cluttered Background"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "It is shown that matching by geometric hashing and alignment is very sensitive to clutter and measurement errors and in realistic scenarios graph matching is superior to the other methods in terms of both recognition accuracy and computational complexity."
            },
            "venue": {
                "fragments": [],
                "text": "IWVF"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3096453"
                        ],
                        "name": "Y. Lamdan",
                        "slug": "Y.-Lamdan",
                        "structuredName": {
                            "firstName": "Yehezkel",
                            "lastName": "Lamdan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Lamdan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1756534"
                        ],
                        "name": "H. Wolfson",
                        "slug": "H.-Wolfson",
                        "structuredName": {
                            "firstName": "Haim",
                            "lastName": "Wolfson",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Wolfson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Common approaches include geometric hashing exploiting geometric configuration of local image features [6], PCA analysis over local image areas (eigenwindows) [10], matching local colour histograms [13, 4], matching gaussian derivatives in neighbourhoods of scaleinvariant interest points [11, 8], or matching moment invariants in local affine-invariant regions [15, 14]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 20693764,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ce5271110e0b1ef852fd3bd3ed57b1932e08642e",
            "isKey": false,
            "numCitedBy": 966,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "A general method for model-based object recognition in occluded scenes is presented. It is based on geometric hashing. The method stands out for its efficiency. We describe the general framework of the method and illustrate its applications for various recogni- tion problems both in 3-D and 2-D. Special attention is given to the recognition of 3-D objects in occluded scenes from 2-D gray scale images. New experimental results are included for this important case."
            },
            "slug": "Geometric-Hashing:-A-General-And-Efficient-Scheme-Lamdan-Wolfson",
            "title": {
                "fragments": [],
                "text": "Geometric Hashing: A General And Efficient Model-based Recognition Scheme"
            },
            "tldr": {
                "abstractSimilarityScore": 85,
                "text": "A general method for model-based object recognition in occluded scenes is presented based on geometric hashing, which stands out for its efficiency and applications both in 3-D and 2-D."
            },
            "venue": {
                "fragments": [],
                "text": "[1988 Proceedings] Second International Conference on Computer Vision"
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2987811"
                        ],
                        "name": "M. Swain",
                        "slug": "M.-Swain",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Swain",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Swain"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1691804"
                        ],
                        "name": "D. Ballard",
                        "slug": "D.-Ballard",
                        "structuredName": {
                            "firstName": "Dana",
                            "lastName": "Ballard",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Ballard"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Robustness to severe occlusions is demonstrated by only a moderate decrease of recognition performance in an experiment where half of each test image is erased."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 8167136,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5b1e1696564e5a3021ac3a501c9deeb6c0fbc637",
            "isKey": false,
            "numCitedBy": 5039,
            "numCiting": 40,
            "paperAbstract": {
                "fragments": [],
                "text": "Computer vision is embracing a new research focus in which the aim is to develop visual skills for robots that allow them to interact with a dynamic, realistic environment. To achieve this aim, new kinds of vision algorithms need to be developed which run in real time and subserve the robot's goals. Two fundamental goals are determining the location of a known object. Color can be successfully used for both tasks.This article demonstrates that color histograms of multicolored objects provide a robust, efficient cue for indexing into a large database of models. It shows that color histograms are stable object representations in the presence of occlusion and over change in view, and that they can differentiate among a large number of objects. For solving the identification problem, it introduces a technique calledHistogram Intersection, which matches model and image histograms and a fast incremental version of Histogram Intersection, which allows real-time indexing into a large database of stored models. For solving the location problem it introduces an algorithm calledHistogram Backprojection, which performs this task efficiently in crowded scenes."
            },
            "slug": "Color-indexing-Swain-Ballard",
            "title": {
                "fragments": [],
                "text": "Color indexing"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "It is demonstrated that color histograms of multicolored objects provide a robust, efficient cue for indexing into a large database of models and that they can differentiate among a large number of objects."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2462253"
                        ],
                        "name": "C. Schmid",
                        "slug": "C.-Schmid",
                        "structuredName": {
                            "firstName": "Cordelia",
                            "lastName": "Schmid",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Schmid"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145299933"
                        ],
                        "name": "R. Mohr",
                        "slug": "R.-Mohr",
                        "structuredName": {
                            "firstName": "Roger",
                            "lastName": "Mohr",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Mohr"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Robustness to severe occlusions is demonstrated by only a moderate decrease of recognition performance in an experiment where half of each test image is erased."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 325871,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "49fcd806450d947e56c82ef2b438ad9c484069dc",
            "isKey": false,
            "numCitedBy": 1792,
            "numCiting": 61,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper addresses the problem of retrieving images from large image databases. The method is based on local grayvalue invariants which are computed at automatically detected interest points. A voting algorithm and semilocal constraints make retrieval possible. Indexing allows for efficient retrieval from a database of more than 1,000 images. Experimental results show correct retrieval in the case of partial visibility, similarity transformations, extraneous features, and small perspective deformations."
            },
            "slug": "Local-Grayvalue-Invariants-for-Image-Retrieval-Schmid-Mohr",
            "title": {
                "fragments": [],
                "text": "Local Grayvalue Invariants for Image Retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 82,
                "text": "This paper addresses the problem of retrieving images from large image databases with a method based on local grayvalue invariants which are computed at automatically detected interest points and allows for efficient retrieval from a database of more than 1,000 images."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2890846"
                        ],
                        "name": "T. Suk",
                        "slug": "T.-Suk",
                        "structuredName": {
                            "firstName": "Tom\u00e1\u0161",
                            "lastName": "Suk",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Suk"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1749525"
                        ],
                        "name": "J. Flusser",
                        "slug": "J.-Flusser",
                        "structuredName": {
                            "firstName": "Jan",
                            "lastName": "Flusser",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Flusser"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 148,
                                "start": 141
                            }
                        ],
                        "text": "The invariance of the bi-tangents is a consequence of the affine invariance (and even projective invariance) of the convex hull construction [12, 9]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 18576879,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "bbdd7a3b3397b1fdeff21883281936ba0a5a228e",
            "isKey": false,
            "numCitedBy": 13,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "A new more effcient algorithm for recognition of projectively deformed point sets is presented. It supposes the type of projective transformation, where the orientation of a triangle is preserved. \n \nFirst, convex layers of two compared sets are computed and left-tangents are found. If their structures are different, then an advanced algorithm is used. It creates the new structure of one set according to the other set. If the numbers of the points in the convex layers differ from each other, then the suitable points are moved to other layers, and if the left-tangents do not link the corresponding points, then their structure is corrected. The suitable combination of optimal structure correction criteria was investigated by a numerical experiment, the angle criteria were found as the best. \n \nFinally, five-point cross ratios of sequences of the points from both sets are computed and compared."
            },
            "slug": "Convex-Layers:-A-New-Tool-for-Recognition-of-Point-Suk-Flusser",
            "title": {
                "fragments": [],
                "text": "Convex Layers: A New Tool for Recognition of Projectively Deformed Point Sets"
            },
            "tldr": {
                "abstractSimilarityScore": 98,
                "text": "A new more effcient algorithm for recognition of projectively deformed point sets is presented, which supposes the type of projective transformation, where the orientation of a triangle is preserved."
            },
            "venue": {
                "fragments": [],
                "text": "CAIP"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1893913"
                        ],
                        "name": "K. Ohba",
                        "slug": "K.-Ohba",
                        "structuredName": {
                            "firstName": "Kohtaro",
                            "lastName": "Ohba",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Ohba"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1739452"
                        ],
                        "name": "K. Ikeuchi",
                        "slug": "K.-Ikeuchi",
                        "structuredName": {
                            "firstName": "Katsushi",
                            "lastName": "Ikeuchi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Ikeuchi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Robustness to severe occlusions is demonstrated by only a moderate decrease of recognition performance in an experiment where half of each test image is erased."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 18197465,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3a44777759b979a6d1ded7d312cdb055f1d31ef8",
            "isKey": false,
            "numCitedBy": 194,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes a method for recognizing partially occluded objects for bin-picking tasks using eigenspace analysis, referred to as the \"eigen window\" method, that stores multiple partial appearances of an object in an eigenspace. Such partial appearances require a large amount of memory space. Three measurements, detectability, uniqueness, and reliability, on windows are developed to eliminate redundant windows and thereby reduce memory requirements. Using a pose clustering technique, the method determines the pose of an object and the object type itself. We have implemented the method and verified its validity."
            },
            "slug": "Detectability,-Uniqueness,-and-Reliability-of-Eigen-Ohba-Ikeuchi",
            "title": {
                "fragments": [],
                "text": "Detectability, Uniqueness, and Reliability of Eigen Windows for Stable Verification of Partially Occluded Objects"
            },
            "tldr": {
                "abstractSimilarityScore": 89,
                "text": "A method for recognizing partially occluded objects for bin-picking tasks using eigenspace analysis, referred to as the \"eigen window\" method, that stores multiple partial appearances of an object in an eIGenspace to reduce memory requirements."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3033284"
                        ],
                        "name": "B. Caputo",
                        "slug": "B.-Caputo",
                        "structuredName": {
                            "firstName": "Barbara",
                            "lastName": "Caputo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Caputo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1713907"
                        ],
                        "name": "J. Hornegger",
                        "slug": "J.-Hornegger",
                        "structuredName": {
                            "firstName": "Joachim",
                            "lastName": "Hornegger",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Hornegger"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153543875"
                        ],
                        "name": "D. Paulus",
                        "slug": "D.-Paulus",
                        "structuredName": {
                            "firstName": "Dietrich",
                            "lastName": "Paulus",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Paulus"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144290244"
                        ],
                        "name": "H. Niemann",
                        "slug": "H.-Niemann",
                        "structuredName": {
                            "firstName": "Heinrich",
                            "lastName": "Niemann",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Niemann"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 13895625,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d12a64cced38cb82a4ad21f2796fdac31384b95c",
            "isKey": false,
            "numCitedBy": 14,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we present a new energy function for MRF which is inspired by models of physics of disordered systems. This energy function presents two ma in advantages: it can be very easily applied to problems modeled by irregular sites becau se it considers the neighborhood system as fully connected; it does not require an algorithm f or searching the absolute minima because those and their analytical properties are given by t heory. We performed experiments on appearance-based object recognition, using the COIL 100 da tabase; we achieve a recognition rate of 98.78%."
            },
            "slug": "A-Spin-Glass-Markov-Random-Field-for-3-D-Object-Caputo-Hornegger",
            "title": {
                "fragments": [],
                "text": "A Spin-Glass Markov Random Field for 3-D Object Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 68,
                "text": "A new energy function for MRF which is inspired by models of physics of disordered systems, which can be very easily applied to problems modeled by irregular sites and does not require an algorithm or searching the absolute minima."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1750195"
                        ],
                        "name": "E. Trucco",
                        "slug": "E.-Trucco",
                        "structuredName": {
                            "firstName": "Emanuele",
                            "lastName": "Trucco",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Trucco"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 148,
                                "start": 141
                            }
                        ],
                        "text": "The invariance of the bi-tangents is a consequence of the affine invariance (and even projective invariance) of the convex hull construction [12, 9]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 61003302,
            "fieldsOfStudy": [
                "Art"
            ],
            "id": "2fdf3b848d2dded13caa0351376dae861a31f640",
            "isKey": false,
            "numCitedBy": 414,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Geometric Invariance in Computer Vision, edited by Joseph L. Mundy and Andrew Zisserman, the MIT Press, 1992, $70.95 in Europe."
            },
            "slug": "Geometric-Invariance-in-Computer-Vision-Trucco",
            "title": {
                "fragments": [],
                "text": "Geometric Invariance in Computer Vision"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "Geometric Invariance in Computer Vision, edited by Joseph L. Mundy and Andrew Zisserman, the MIT Press, 1992, $70.95 in Europe."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Distinguished regions for widebaseline stereo"
            },
            "venue": {
                "fragments": [],
                "text": "Research Report CTU \u2013 CMP \u2013"
            },
            "year": 2001
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Surrey object image library"
            },
            "venue": {
                "fragments": [],
                "text": "Surrey object image library"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 64,
                                "start": 61
                            }
                        ],
                        "text": "We do not describe the MSERs here; the reader is referred to [7] which includes a formal definition of the MSERs and a detailed description of the extraction algorithm."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 77,
                                "start": 74
                            }
                        ],
                        "text": "In this work we exploit a new type of distinguished regions introduced in [7], the Maximally Stable Extremal Regions (MSERs)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Distinguished regions for widebaseline stereo. Research Report CTU\u2013CMP\u20132001\u201333, Center for Machine Perception, K333"
            },
            "venue": {
                "fragments": [],
                "text": "FEE Czech Technical University,"
            },
            "year": 2001
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Robustness to severe occlusions is demonstrated by only a moderate decrease of recognition performance in an experiment where half of each test image is erased."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Invariant Features for Registration and Recognition"
            },
            "venue": {
                "fragments": [],
                "text": "Kardinaal Mercierlaan"
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 24,
                                "start": 21
                            }
                        ],
                        "text": "As an attempt to combine advantages of both approaches, methods based on the matching of local features have been proposed."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 9,
                                "start": 6
                            }
                        ],
                        "text": "While model-based methods try to analytically model the relation between the object and its projection to the image, appearance-based methods recognise objects by visual similarity, without attempting high-level image analysis."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Distinguished regions for widebaseline stereo Center for Machine Perception"
            },
            "venue": {
                "fragments": [],
                "text": "Research Report"
            },
            "year": 2001
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 370,
                                "start": 362
                            }
                        ],
                        "text": "Common approaches include geometric hashing exploiting geometric configuration of local image features [6], PCA analysis over local image areas (eigenwindows) [10], matching local colour histograms [13, 4], matching gaussian derivatives in neighbourhoods of scaleinvariant interest points [11, 8], or matching moment invariants in local affine-invariant regions [15, 14]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 56,
                                "start": 52
                            }
                        ],
                        "text": "The most closely related work is that of Tuytelaars [14], where local regions were also affine-invariantly found, but these regions were used to determine the image area over which moment invariants were computed."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 10,
                                "start": 0
                            }
                        ],
                        "text": "Tuytelaars also proposed to establish correspondences using normalised correlation over the shape-normalised regions, but since the regions were determined up to an unknown rotation, a computationally expensive maximisation of the correlation was used."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Invariant Features for Registration and Recognition"
            },
            "venue": {
                "fragments": [],
                "text": "PhD thesis, University of Leuven, Kardinaal Mercierlaan 94,"
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 370,
                                "start": 362
                            }
                        ],
                        "text": "Common approaches include geometric hashing exploiting geometric configuration of local image features [6], PCA analysis over local image areas (eigenwindows) [10], matching local colour histograms [13, 4], matching gaussian derivatives in neighbourhoods of scaleinvariant interest points [11, 8], or matching moment invariants in local affine-invariant regions [15, 14]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 56,
                                "start": 52
                            }
                        ],
                        "text": "The most closely related work is that of Tuytelaars [14], where local regions were also affine-invariantly found, but these regions were used to determine the image area over which moment invariants were computed."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 10,
                                "start": 0
                            }
                        ],
                        "text": "Tuytelaars also proposed to establish correspondences using normalised correlation over the shape-normalised regions, but since the regions were determined up to an unknown rotation, a computationally expensive maximisation of the correlation was used."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Local, Invariant Features for Registration and Recognition"
            },
            "venue": {
                "fragments": [],
                "text": "PhD thesis, University of Leuven, Kardinaal Mercierlaan 94,"
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Columbia object image library"
            },
            "venue": {
                "fragments": [],
                "text": "Columbia object image library"
            }
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 11,
            "methodology": 3,
            "result": 1
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 21,
        "totalPages": 3
    },
    "page_url": "https://www.semanticscholar.org/paper/Object-Recognition-using-Local-Affine-Frames-on-Obdrz\u00e1lek-Matas/16cf7026acfdbcef00a6524c72dc7ee5a0660ef8?sort=total-citations"
}