{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2512508"
                        ],
                        "name": "Andrew K. Halberstadt",
                        "slug": "Andrew-K.-Halberstadt",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Halberstadt",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew K. Halberstadt"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145898106"
                        ],
                        "name": "James R. Glass",
                        "slug": "James-R.-Glass",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Glass",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "James R. Glass"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 57,
                                "start": 54
                            }
                        ],
                        "text": "An implementation of the hierarchical classifier from [5] was added as a ninth member to the previously 8-member segmental measurements committee."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 24,
                                "start": 21
                            }
                        ],
                        "text": "In our previous work [5], we reported on hierarchical techniques for combining classifiers."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 6,
                                "start": 3
                            }
                        ],
                        "text": "In [5], we presented a MAP hierarchical approach to combining multiple classifiers."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 50,
                                "start": 47
                            }
                        ],
                        "text": "We implemented a hierarchical classifier as in [5], which uses different measurements for different % Error Methods Dev core"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2515764,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "46c62f33560642d9a051c94eeb7ebb6bc7fed24e",
            "isKey": false,
            "numCitedBy": 109,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we describe our recent efforts to improve acousticphonetic modeling by developing sets of heterogeneous, phoneclass-specific measurements, and combining these diverse measurements into a probabilistic classification framework. We first describe a baseline classifier using homogeneous measurements. After comparing selected sub-tasks to known human performance, we define sets of phone-class-specific measurements which improve within-class classification performance. Subsequently, we combine these heterogeneous measurements into an overall context-independent classification framework. We report on a series of phonetic classification experiments using the TIMIT acoustic-phonetic corpus. Our overall framework achieves 79.0% accuracy on the NIST core test set."
            },
            "slug": "HETEROGENEOUS-ACOUSTIC-MEASUREMENTS-FOR-PHONETIC-Halberstadt-Glass",
            "title": {
                "fragments": [],
                "text": "HETEROGENEOUS ACOUSTIC MEASUREMENTS FOR PHONETIC CLASSIFICATION"
            },
            "tldr": {
                "abstractSimilarityScore": 54,
                "text": "This paper describes a baseline classifier using homogeneous measurements, and defines sets of phone-class-specific measurements which improve within-class classification performance, and combines these heterogeneous measurements into an overall context-independent classification framework."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144157305"
                        ],
                        "name": "S. Zahorian",
                        "slug": "S.-Zahorian",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Zahorian",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Zahorian"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3350697"
                        ],
                        "name": "P. Silsbee",
                        "slug": "P.-Silsbee",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Silsbee",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Silsbee"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108030390"
                        ],
                        "name": "Xihong Wang",
                        "slug": "Xihong-Wang",
                        "structuredName": {
                            "firstName": "Xihong",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xihong Wang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 12258165,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ce254353245326fe2f5a660e7bceda40e2333fbb",
            "isKey": false,
            "numCitedBy": 55,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents methods and experimental results for phonetic classification using 39 phone classes and the NIST recommended training and test sets for NTIMIT and TIMIT. Spectral/temporal features which represent the smoothed trajectory of FFT derived speech spectra over 300 ms intervals are used for the analysis. Classification tests are made with both a binary-pair partitioned (BPP) neural network system (one neural network for each of the 741 pairs of phones) and a single large neural network. The classification accuracy is very similar for the two types of networks, but the BPP method has the advantage of a much shorter training time. The best results obtained (77% for TIMIT and 67.4% for NTIMIT) compare favorably to the best results reported in the literature for this task."
            },
            "slug": "Phone-classification-with-segmental-features-and-a-Zahorian-Silsbee",
            "title": {
                "fragments": [],
                "text": "Phone classification with segmental features and a binary-pair partitioned neural network classifier"
            },
            "tldr": {
                "abstractSimilarityScore": 80,
                "text": "The methods and experimental results for phonetic classification using 39 phone classes and the NIST recommended training and test sets for NTIMIT and TIMIT compare favorably to the best results reported in the literature for this task."
            },
            "venue": {
                "fragments": [],
                "text": "1997 IEEE International Conference on Acoustics, Speech, and Signal Processing"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145898106"
                        ],
                        "name": "James R. Glass",
                        "slug": "James-R.-Glass",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Glass",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "James R. Glass"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143847857"
                        ],
                        "name": "Jane W. Chang",
                        "slug": "Jane-W.-Chang",
                        "structuredName": {
                            "firstName": "Jane",
                            "lastName": "Chang",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jane W. Chang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3001667"
                        ],
                        "name": "M. McCandless",
                        "slug": "M.-McCandless",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "McCandless",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. McCandless"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 29,
                                "start": 26
                            }
                        ],
                        "text": "Either antiphone modeling [3] or 1-state near-miss modeling [1, 2] was used with segment models in order to account for both on-path and off-path segments in the segment network."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 162,
                                "start": 159
                            }
                        ],
                        "text": "For the boundary measurements, the \u201c8 avg\u201d basis consists of symmetric, non-overlapping averages over 5, 10, 20, and 40 milliseconds (indicated by 5 10 20 40) [3], for a total extension of 75 ms to either side of the boundary."
                    },
                    "intents": []
                }
            ],
            "corpusId": 1207578,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "33f3f567911bb4c7958a6783b8cffc87957d5213",
            "isKey": false,
            "numCitedBy": 167,
            "numCiting": 42,
            "paperAbstract": {
                "fragments": [],
                "text": "Most current speech recognizers use an observation space which is based on a temporal sequence of \"frames\" (e.g. Mel-cepstra). There is another class of recognizer which further processes these frames to produce a segment-based network, and represents each segment by fixed-dimensional \"features\". In such feature-based recognizers, the observation space takes the form of a temporal network of feature vectors, so that a single segmentation of an utterance uses a subset of all possible feature vectors. In this paper, we examine a maximum a-posteriori decoding strategy for feature-based recognizers and develop a normalization criterion that is useful for a segment-based Viterbi or A* search. We report experimental results for the task of phonetic recognition on the TIMIT corpus, where we achieved context-independent and context-dependent (using diphones) results on the core test set of 64.1% and 69.5% respectively."
            },
            "slug": "A-probabilistic-framework-for-feature-based-speech-Glass-Chang",
            "title": {
                "fragments": [],
                "text": "A probabilistic framework for feature-based speech recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This paper examines a maximum a-posteriori decoding strategy for feature-based recognizers and develops a normalization criterion that is useful for a segment-based Viterbi or A* search."
            },
            "venue": {
                "fragments": [],
                "text": "Proceeding of Fourth International Conference on Spoken Language Processing. ICSLP '96"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1798550"
                        ],
                        "name": "Timothy J. Hazen",
                        "slug": "Timothy-J.-Hazen",
                        "structuredName": {
                            "firstName": "Timothy",
                            "lastName": "Hazen",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Timothy J. Hazen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2512508"
                        ],
                        "name": "Andrew K. Halberstadt",
                        "slug": "Andrew-K.-Halberstadt",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Halberstadt",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew K. Halberstadt"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2748120,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d483c4bd8451c117180e03d010ba4d89ef6210cc",
            "isKey": false,
            "numCitedBy": 30,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper investigates the use of aggregation as a means of improving the performance and robustness of mixture Gaussian models. This technique produces models that are more accurate and more robust to different test sets than traditional cross-validation using a development set. A theoretical justification for this technique is presented along with experimental results in phonetic classification, phonetic recognition, and word recognition tasks on the TIMIT and Resource Management corpora. In speech classification and recognition tasks error rate reductions of up to 12% were observed using this technique. A method for utilizing tree-structured density functions for the purpose of pruning the aggregated models is also presented."
            },
            "slug": "Using-aggregation-to-improve-the-performance-of-Hazen-Halberstadt",
            "title": {
                "fragments": [],
                "text": "Using aggregation to improve the performance of mixture Gaussian acoustic models"
            },
            "tldr": {
                "abstractSimilarityScore": 95,
                "text": "This paper investigates the use of aggregation as a means of improving the performance and robustness of mixture Gaussian models and produces models that are more accurate and more robust to different test sets than traditional cross-validation using a development set."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 1998 IEEE International Conference on Acoustics, Speech and Signal Processing, ICASSP '98 (Cat. No.98CH36181)"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144990248"
                        ],
                        "name": "R. Lippmann",
                        "slug": "R.-Lippmann",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Lippmann",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Lippmann"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 176,
                                "start": 172
                            }
                        ],
                        "text": "There is still a large gap between human and machine speech recognition ability, and current speech recognition systems rely more heavily on language models than humans do [11]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14283618,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "387e7349b8e31e316c2a7380603d1b6c0b1417c8",
            "isKey": false,
            "numCitedBy": 650,
            "numCiting": 52,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Speech-recognition-by-machines-and-humans-Lippmann",
            "title": {
                "fragments": [],
                "text": "Speech recognition by machines and humans"
            },
            "venue": {
                "fragments": [],
                "text": "Speech Commun."
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145204681"
                        ],
                        "name": "L. Lamel",
                        "slug": "L.-Lamel",
                        "structuredName": {
                            "firstName": "Lori",
                            "lastName": "Lamel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Lamel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685010"
                        ],
                        "name": "J. Gauvain",
                        "slug": "J.-Gauvain",
                        "structuredName": {
                            "firstName": "Jean-Luc",
                            "lastName": "Gauvain",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Gauvain"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 251250,
            "fieldsOfStudy": [
                "Physics",
                "Computer Science"
            ],
            "id": "b250c7238711b5203f2ab9a5e5693d097e38b027",
            "isKey": false,
            "numCitedBy": 116,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we report high phone accuracies on three corpora: WSJ0, BREF and TIMIT. The main characteristics of the phone recognizerare: high dimensional feature vector (48), contextand genderdependent phone models with duration distribution, continuous density HMM with Gaussian mixtures, and n-gram probabilities for the phonotatic constraints. These models are trained on speech data that have either phonetic or orthographic transcriptions using maximum likelihood and maximum a posteriori estimation techniques. On the WSJ0 corpus with a 46 phone set we obtain phone accuraciesof 72.4% and 74.4% using 500 and 1600 CD phone units, respectively. Accuracy on BREF with 35 phones is as high as 78.7% with only 428 CD phone units. On TIMIT using the 61 phone symbols and only 500 CD phone units, we obtain a phone accuracyof 67.2% which correspond to 73.4% when the recognizer output is mapped to the commonly used 39 phone set. Making reference to our work on large vocabulary CSR, we show that it is worthwhile to perform phone recognition experiments as opposed to only focusing attention on word recognition results."
            },
            "slug": "High-performance-speaker-independent-phone-using-Lamel-Gauvain",
            "title": {
                "fragments": [],
                "text": "High performance speaker-independent phone recognition using CDHMM"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "It is shown that it is worthwhile to perform phone recognition experiments as opposed to only focusing attention on word recognition results, and high phone accuracies on three corpora: WSJ0, BREF and TIMIT are reported."
            },
            "venue": {
                "fragments": [],
                "text": "EUROSPEECH"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "102429215"
                        ],
                        "name": "Kai-Fu Lee",
                        "slug": "Kai-Fu-Lee",
                        "structuredName": {
                            "firstName": "Kai-Fu",
                            "lastName": "Lee",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kai-Fu Lee"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145058181"
                        ],
                        "name": "H. Hon",
                        "slug": "H.-Hon",
                        "structuredName": {
                            "firstName": "Hsiao-Wuen",
                            "lastName": "Hon",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Hon"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 37373402,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3034afcd45fc190ed71982828b77f6e4154bdc5c",
            "isKey": false,
            "numCitedBy": 1044,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "Hidden Markov modeling is extended to speaker-independent phone recognition. Using multiple codebooks of various linear-predictive-coding (LPC) parameters and discrete hidden Markov models (HMMs) the authors obtain a speaker-independent phone recognition accuracy of 58.8-73.8% on the TIMIT database, depending on the type of acoustic and language models used. In comparison, the performance of expert spectrogram readers is only 69% without use of higher level knowledge. The authors introduce the co-occurrence smoothing algorithm, which enables accurate recognition even with very limited training data. Since the results were evaluated on a standard database, they can be used as benchmarks to evaluate future systems. >"
            },
            "slug": "Speaker-independent-phone-recognition-using-hidden-Lee-Hon",
            "title": {
                "fragments": [],
                "text": "Speaker-independent phone recognition using hidden Markov models"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "The authors introduce the co-occurrence smoothing algorithm, which enables accurate recognition even with very limited training data, and can be used as benchmarks to evaluate future systems."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Acoust. Speech Signal Process."
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143847857"
                        ],
                        "name": "Jane W. Chang",
                        "slug": "Jane-W.-Chang",
                        "structuredName": {
                            "firstName": "Jane",
                            "lastName": "Chang",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jane W. Chang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145898106"
                        ],
                        "name": "James R. Glass",
                        "slug": "James-R.-Glass",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Glass",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "James R. Glass"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 66,
                                "start": 60
                            }
                        ],
                        "text": "Either antiphone modeling [3] or 1-state near-miss modeling [1, 2] was used with segment models in order to account for both on-path and off-path segments in the segment network."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 62,
                                "start": 52
                            }
                        ],
                        "text": "We refer to this step as probabilistic segmentation [1, 2, 10]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 3116225,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f4fb4a0c71480cda4b8b4fa51d7a58c90e89945e",
            "isKey": false,
            "numCitedBy": 44,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "Recently, we have developed a probabilistic framework for segmentbased speech recognition that represents the speech signal as a network of segments and associated feature vectors [2]. Although in general, each path through the network does not traverse all segments, we argued that each path must account for all feature vectors in the network. We then demonstrated an efficient search algorithm that uses a single additional model to account for segments that are not traversed. In this paper, we present two new extensions to our framework. First, we replace our acoustic segmentation algorithm with \u201csegmentation by recognition,\u201d a probabilistic algorithm that can combine multiple contextual constraints towards hypothesizing only the most likely segments. Second, we generalize our framework to \u201cnear-miss modeling\u201d and describe a search algorithm that can efficiently use multiple models to enforce contextual constraints across all segments in a network. We report experiments in phonetic recognition on the TIMIT corpus in which we achieve a diphone context-dependent error rate of 26.6% on the NIST core test set over 39 classes. This is a 12.8% reduction in error rate from our best previously reported result."
            },
            "slug": "Segmentation-and-modeling-in-segment-based-Chang-Glass",
            "title": {
                "fragments": [],
                "text": "Segmentation and modeling in segment-based recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The acoustic segmentation algorithm is replaced with \u201csegmentation by recognition,\u201d a probabilistic algorithm that can combine multiple contextual constraints towards hypothesizing only the most likely segments and an efficient search algorithm is described that can efficiently use multiple models to enforce contextual constraints across all segments in a network."
            },
            "venue": {
                "fragments": [],
                "text": "EUROSPEECH"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144620965"
                        ],
                        "name": "J. Ming",
                        "slug": "J.-Ming",
                        "structuredName": {
                            "firstName": "Ji",
                            "lastName": "Ming",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Ming"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145894070"
                        ],
                        "name": "F. Smith",
                        "slug": "F.-Smith",
                        "structuredName": {
                            "firstName": "Francis",
                            "lastName": "Smith",
                            "middleNames": [
                                "Jack"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Smith"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 17872406,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d6248fce7299e2b2871e78dcd506743ab86c7d27",
            "isKey": false,
            "numCitedBy": 55,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "A crucial issue in triphone based continuous speech recognition is the large number of models to be estimated against the limited availability of training data. This problem can be relieved by composing a triphone model from less context-dependent models. This paper introduces a new statistical framework, derived from the Bayesian principle, to perform such a composition. The potential power of this new framework is explored, both algorithmically and experimentally, by an implementation with hidden Markov modeling techniques. This implementation is applied to the recognition of the 39-phone set on the TIMIT database. The new model achieves 74.4% and 75.6% accuracy, respectively, on the core and complete test sets."
            },
            "slug": "Improved-phone-recognition-using-Bayesian-triphone-Ming-Smith",
            "title": {
                "fragments": [],
                "text": "Improved phone recognition using Bayesian triphone models"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A new statistical framework, derived from the Bayesian principle, is introduced to perform a triphone model from less context-dependent models, and the potential power of this new framework is explored, both algorithmically and experimentally, by an implementation with hidden Markov modeling techniques."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 1998 IEEE International Conference on Acoustics, Speech and Signal Processing, ICASSP '98 (Cat. No.98CH36181)"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145898106"
                        ],
                        "name": "James R. Glass",
                        "slug": "James-R.-Glass",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Glass",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "James R. Glass"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1798550"
                        ],
                        "name": "Timothy J. Hazen",
                        "slug": "Timothy-J.-Hazen",
                        "structuredName": {
                            "firstName": "Timothy",
                            "lastName": "Hazen",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Timothy J. Hazen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 104,
                                "start": 101
                            }
                        ],
                        "text": "Word recognition experiments were performed using theJUPITERtelephone-based weather information task [4]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 176,
                                "start": 173
                            }
                        ],
                        "text": "Finally, in order to verify that these techniques generalize to word recognition, we performed experiments using the telephone-based JUPITER weather information server task [4]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 5368113,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6293480445a3cd8cb7e6625d1aca10755364272d",
            "isKey": false,
            "numCitedBy": 41,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes our experiences with developing a telephone-based speech recognizer as part of a conversational system in the weather information domain. This system has been used to collect spontaneous speech data which has proven to be extremely valuable for research in a number of different areas. After describing the corpus we have collected, we describe the development of the recognizer vocabulary, pronunciations, language and acoustic models for this system, and report on the current performance of the recognizer under several different conditions."
            },
            "slug": "Telephone-based-conversational-speech-recognition-Glass-Hazen",
            "title": {
                "fragments": [],
                "text": "Telephone-based conversational speech recognition in the JUPITER domain"
            },
            "tldr": {
                "abstractSimilarityScore": 70,
                "text": "The experiences with developing a telephone-based speech recognizer as part of a conversational system in the weather information domain and the development of the recognizer vocabulary, pronunciations, language and acoustic models are described."
            },
            "venue": {
                "fragments": [],
                "text": "ICSLP"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143847857"
                        ],
                        "name": "Jane W. Chang",
                        "slug": "Jane-W.-Chang",
                        "structuredName": {
                            "firstName": "Jane",
                            "lastName": "Chang",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jane W. Chang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 66,
                                "start": 60
                            }
                        ],
                        "text": "Either antiphone modeling [3] or 1-state near-miss modeling [1, 2] was used with segment models in order to account for both on-path and off-path segments in the segment network."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 62,
                                "start": 52
                            }
                        ],
                        "text": "We refer to this step as probabilistic segmentation [1, 2, 10]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1597965,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "78b8d6afee6a1a46ed3b89ccfc76cdc4a2fdbff6",
            "isKey": false,
            "numCitedBy": 26,
            "numCiting": 81,
            "paperAbstract": {
                "fragments": [],
                "text": "Currently, most approaches to speech recognition are frame-based in that they represent speech as a temporal sequence of feature vectors. Although these approaches have been successful, they cannot easily incorporate complex modeling strategies that may further improve speech recognition performance. In contrast, segment-based approaches represent speech as a temporal graph of feature vectors and facilitate the incorporation of a wide range of modeling strategies. However, difficulties in segmentbased recognition have impeded the realization of potential advantages in modeling. This thesis describes an approach called near-miss modeling that addresses the major difficulties in segment-based recognition. Probabilistically, each path should account for the entire graph including the segments that are off the path as well as the segments that are on the path. Near-miss modeling is based on the idea that an off-path segment can be modeled as a \"near-miss\" of an on-path segment. Each segment is associated with a near-miss subset of segments that contains the on-path segment as well as zero or more off-path segments such that the near-miss subsets that are associated with any path account for the entire graph. Computationally, the graph should contain only a small number of segments without introducing a large number of segmentation errors. Near-miss modeling runs a recognizer and produces a graph that contains only the segments on paths that score within a threshold of the best scoring path. A near-miss recognizer using context-independent segment-based acoustic models, diphone context-dependent frame-based models, and a phone bigram language model achieves a 25.5% error rate on the TIMIT core test set over 39 classes. This is a 16% reduction in error rate from our best previously reported result and, to our knowledge, is the lowest error rate that has been reported under comparable conditions. Additional experiments using the ATIS corpus verify that these improvements generalize to word recognition. Thesis Supervisor: James R. Glass Title: Principal Research Scientist"
            },
            "slug": "Near-miss-modeling:-a-segment-based-approach-to-Chang",
            "title": {
                "fragments": [],
                "text": "Near-miss modeling: a segment-based approach to speech recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This thesis describes an approach called near-miss modeling that addresses the major difficulties in segment-based recognition and runs a recognizer and produces a graph that contains only the segments on paths that score within a threshold of the best scoring path."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108322421"
                        ],
                        "name": "Steven C. Lee",
                        "slug": "Steven-C.-Lee",
                        "structuredName": {
                            "firstName": "Steven",
                            "lastName": "Lee",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Steven C. Lee"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 62,
                                "start": 52
                            }
                        ],
                        "text": "We refer to this step as probabilistic segmentation [1, 2, 10]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 6816098,
            "fieldsOfStudy": [
                "Computer Science",
                "Engineering"
            ],
            "id": "026e00b8d5e90e466628971c2fb1c123fe218594",
            "isKey": false,
            "numCitedBy": 19,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "Speech Recognition by Steven C. Lee S.B., Massachusetts Institute of Technology, 1997 Submitted to the Department of Electrical Engineering and Computer Science in partial ful llment of the requirements for the degree of Master of Engineering in Electrical Engineering and Computer Science at the MASSACHUSETTS INSTITUTE OF TECHNOLOGY May 1998 c Massachusetts Institute of Technology 1998. All rights reserved."
            },
            "slug": "Probabilistic-segmentation-for-segment-based-speech-Lee",
            "title": {
                "fragments": [],
                "text": "Probabilistic segmentation for segment-based speech recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 94,
                "text": "Speech Recognition by Steven C.C.B., Massachusetts Institute of Technology, 1997."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 111,
                                "start": 108
                            }
                        ],
                        "text": "Phonetic classification and recognition experiments were conducted using the TIMIT acoustic-phonetic corpus [8]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Speech database development: Design and analysis of the acoustic-phonetic corpus,"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. of the DARPA Speech Recognition"
            },
            "year": 1986
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "An application of recurrent neural nets to phone probability estimation"
            },
            "venue": {
                "fragments": [],
                "text": "Transactions on Neural Networks"
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "An application of recurrent neural nets to phone probability estimation,\u201dTransactions on"
            },
            "venue": {
                "fragments": [],
                "text": "Neural Networks  ,"
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "An application of recurrent neural nets to phone probability estimation"
            },
            "venue": {
                "fragments": [],
                "text": "Transactions on Neural Networks"
            },
            "year": 1998
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 1,
            "methodology": 7
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 16,
        "totalPages": 2
    },
    "page_url": "https://www.semanticscholar.org/paper/Heterogeneous-measurements-and-multiple-classifiers-Halberstadt-Glass/182c9ba291d97dc8d7482533044416869cb15f23?sort=total-citations"
}