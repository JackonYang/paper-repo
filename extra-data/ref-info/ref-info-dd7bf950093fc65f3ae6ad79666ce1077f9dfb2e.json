{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2821129"
                        ],
                        "name": "M. Ashikhmin",
                        "slug": "M.-Ashikhmin",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Ashikhmin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Ashikhmin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 103,
                                "start": 93
                            }
                        ],
                        "text": "The idea of texture transfer based on variations of [6] has been proposed by several authors [9, 1, 11] (in particular, see the elegant paper by Hertzmann et."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 178,
                                "start": 175
                            }
                        ],
                        "text": "Several researchers have proposed optimizations to the basic method including Wei and Levoy [20] (based on earlier work by Popat and Picard [16]), Harrison [9], and Ashikhmin [1]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 403573,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fdc959a9403c92bf99247f482713e795cc4ebd42",
            "isKey": false,
            "numCitedBy": 865,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a simple texture synthesis algorithm that is well-suited for a specific class of naturally occurring textures. This class includes quasi-repeating patterns consisting of small objects of familiar but irregular size, such as flower fields, pebbles, forest undergrowth, bushes and tree branches. The algorithm starts from a sample image and generates a new image of arbitrary size the appearance of which is similar to that of the original image. This new image does not change the basic spatial frequencies the original image; instead it creates an image that is a visually similar, and is of a size set by the user. This method is fast and its implementation is straightforward. We extend the algorithm to allow direct user input for interactive control over the texture synthesis process. This allows the user to indicate large-scale properties of the texture appearance using a standard painting-style interface, and to choose among various candidate textures the algorithm can create by performing different number of iterations."
            },
            "slug": "Synthesizing-natural-textures-Ashikhmin",
            "title": {
                "fragments": [],
                "text": "Synthesizing natural textures"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "The algorithm is extended to allow direct user input for interactive control over the texture synthesis process, which allows the user to indicate large-scale properties of the texture appearance using a standard painting-style interface, and to choose among various candidate textures the algorithm can create by performing different number of iterations."
            },
            "venue": {
                "fragments": [],
                "text": "I3D '01"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2360881"
                        ],
                        "name": "D. Heeger",
                        "slug": "D.-Heeger",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Heeger",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Heeger"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "116003860"
                        ],
                        "name": "J. Bergen",
                        "slug": "J.-Bergen",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Bergen",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Bergen"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 116,
                                "start": 112
                            }
                        ],
                        "text": "Motivated by psychophysical and computational models of human texture discrimination [2, 14], Heeger and Bergen [10] proposed to analyze texture in terms of histograms of filter responses at multiple scales and orientations."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 47266338,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "38850b393d7132dc14141f7d643aca4cb9c321da",
            "isKey": false,
            "numCitedBy": 844,
            "numCiting": 58,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes a method for synthesizing images that match the texture appearance of a given digitized sample. This synthesis is completely automatic and requires only the \"target\" texture as input. It allows generation of as much texture as desired so that any object can be covered. The approach is based on a model of human texture perception, and has potential to be a practically useful tool for image processing and graphics applications."
            },
            "slug": "Pyramid-based-texture-analysis/synthesis-Heeger-Bergen",
            "title": {
                "fragments": [],
                "text": "Pyramid-based texture analysis/synthesis"
            },
            "tldr": {
                "abstractSimilarityScore": 67,
                "text": "This paper describes a method for synthesizing images that match the texture appearance of a given digitized sample that is based on a model of human texture perception, and has potential to be a practically useful tool for image processing and graphics applications."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings., International Conference on Image Processing"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2142595748"
                        ],
                        "name": "Paul Harrison",
                        "slug": "Paul-Harrison",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Harrison",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Paul Harrison"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 103,
                                "start": 93
                            }
                        ],
                        "text": "The idea of texture transfer based on variations of [6] has been proposed by several authors [9, 1, 11] (in particular, see the elegant paper by Hertzmann et."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 159,
                                "start": 156
                            }
                        ],
                        "text": "Several researchers have proposed optimizations to the basic method including Wei and Levoy [20] (based on earlier work by Popat and Picard [16]), Harrison [9], and Ashikhmin [1]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 11708679,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e21811d69201a433094519ba38ee0dc756396295",
            "isKey": false,
            "numCitedBy": 203,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "A procedure is described for synthesizing an image with the same texture as a given input image. \nTo achieve this, the output image is built up by successively adding pixels selected from the input \nimage. Pixels are chosen by searching the input image for patches that closely match pixels already \npresent in the output image. It is shown that the accurate reproduction of features in the input \ntexture depends on the order in which pixels are added to the output image. A procedure for \nselecting an ordering which transfers large complex features of the input to the output image is \ndescribed. This procedure is capable of reproducing large features even if only the interactions of \nnearby pixels are considered. The procedure can be altered to allow speci cation of the placement \nof particular features in the output texture. Several applications of this are described."
            },
            "slug": "A-Non-Hierarchical-Procedure-for-Re-Synthesis-of-Harrison",
            "title": {
                "fragments": [],
                "text": "A Non-Hierarchical Procedure for Re-Synthesis of Complex Textures"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "It is shown that the accurate reproduction of features in the input texture depends on the order in which pixels are added to the output image, which is capable of reproducing large features even if only the interactions of nearby pixels are considered."
            },
            "venue": {
                "fragments": [],
                "text": "WSCG"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34437150"
                        ],
                        "name": "Li-yi Wei",
                        "slug": "Li-yi-Wei",
                        "structuredName": {
                            "firstName": "Li-yi",
                            "lastName": "Wei",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Li-yi Wei"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1801789"
                        ],
                        "name": "M. Levoy",
                        "slug": "M.-Levoy",
                        "structuredName": {
                            "firstName": "Marc",
                            "lastName": "Levoy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Levoy"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 96,
                                "start": 92
                            }
                        ],
                        "text": "Several researchers have proposed optimizations to the basic method including Wei and Levoy [20] (based on earlier work by Popat and Picard [16]), Harrison [9], and Ashikhmin [1]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 3131710,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e1e1a39534aed2cf4894896de75d0ba1fa75ab6a",
            "isKey": false,
            "numCitedBy": 1601,
            "numCiting": 73,
            "paperAbstract": {
                "fragments": [],
                "text": "Texture synthesis is important for many applications in computer graphics, vision, and image processing. However, it remains difficult to design an algorithm that is both efficient and capable of generating high quality results. In this paper, we present an efficient algorithm for realistic texture synthesis. The algorithm is easy to use and requires only a sample texture as input. It generates textures with perceived quality equal to or better than those produced by previous techniques, but runs two orders of magnitude faster. This permits us to apply texture synthesis to problems where it has traditionally been considered impractical. In particular, we have applied it to constrained synthesis for image editing and temporal texture generation. Our algorithm is derived from Markov Random Field texture models and generates textures through a deterministic searching process. We accelerate this synthesis process using tree-structured vector quantization."
            },
            "slug": "Fast-texture-synthesis-using-tree-structured-vector-Wei-Levoy",
            "title": {
                "fragments": [],
                "text": "Fast texture synthesis using tree-structured vector quantization"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This paper presents an efficient algorithm for realistic texture synthesis derived from Markov Random Field texture models and generates textures through a deterministic searching process that accelerates this synthesis process using tree-structured vector quantization."
            },
            "venue": {
                "fragments": [],
                "text": "SIGGRAPH"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1763086"
                        ],
                        "name": "Alexei A. Efros",
                        "slug": "Alexei-A.-Efros",
                        "structuredName": {
                            "firstName": "Alexei",
                            "lastName": "Efros",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alexei A. Efros"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145266088"
                        ],
                        "name": "T. Leung",
                        "slug": "T.-Leung",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Leung",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Leung"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 209,
                                "start": 206
                            }
                        ],
                        "text": "However, all these improvements still operate within the greedy single-pixel-at-a-time paradigm and as such are susceptible to falling into the wrong part of the search space and starting to \u201cgrow garbage\u201d [6]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 19,
                                "start": 16
                            }
                        ],
                        "text": "Efros and Leung [6] developed a simple method of \u201cgrowing\u201d texture using non-parametric sampling."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 55,
                                "start": 52
                            }
                        ],
                        "text": "Our results are virtually the same as Efros & Leung [6] (not shown) but at a much smaller computational cost."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 158,
                                "start": 153
                            }
                        ],
                        "text": "Despite its simplicity, this method works remarkably well when applied to texture synthesis, producing results that are equal or better than the Efros & Leung family of algorithms but with improved stability (less chance of \u201cgrowing garbage\u201d) and at a fraction of the computational cost."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 91,
                                "start": 88
                            }
                        ],
                        "text": "One curious fact about one-pixel-at-a-time synthesis algorithms such as Efros and Leung [6] is that for most complex textures very few pixels actually have a choice of values that can be assigned to them."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 55,
                                "start": 52
                            }
                        ],
                        "text": "The idea of texture transfer based on variations of [6] has been proposed by several authors [9, 1, 11] (in particular, see the elegant paper by Hertzmann et."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 221583955,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bba3264d6794538381687ad6e151a7f42f3872a9",
            "isKey": false,
            "numCitedBy": 1649,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "A non-parametric method for texture synthesis is proposed. The texture synthesis process grows a new image outward from an initial seed, one pixel at a time. A Markov random field model is assumed, and the conditional distribution of a pixel given all its neighbors synthesized so far is estimated by querying the sample image and finding all similar neighborhoods. The degree of randomness is controlled by a single perceptually intuitive parameter. The method aims at preserving as much local structure as possible and produces good results for a wide variety of synthetic and real-world textures."
            },
            "slug": "Texture-synthesis-by-non-parametric-sampling-Efros-Leung",
            "title": {
                "fragments": [],
                "text": "Texture synthesis by non-parametric sampling"
            },
            "tldr": {
                "abstractSimilarityScore": 54,
                "text": "A non-parametric method for texture synthesis that aims at preserving as much local structure as possible and produces good results for a wide variety of synthetic and real-world textures."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Seventh IEEE International Conference on Computer Vision"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2155276610"
                        ],
                        "name": "Lin Liang",
                        "slug": "Lin-Liang",
                        "structuredName": {
                            "firstName": "Lin",
                            "lastName": "Liang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lin Liang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1681442"
                        ],
                        "name": "Ce Liu",
                        "slug": "Ce-Liu",
                        "structuredName": {
                            "firstName": "Ce",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ce Liu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1742571"
                        ],
                        "name": "Ying-Qing Xu",
                        "slug": "Ying-Qing-Xu",
                        "structuredName": {
                            "firstName": "Ying-Qing",
                            "lastName": "Xu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ying-Qing Xu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143632999"
                        ],
                        "name": "B. Guo",
                        "slug": "B.-Guo",
                        "structuredName": {
                            "firstName": "Baining",
                            "lastName": "Guo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Guo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144154486"
                        ],
                        "name": "H. Shum",
                        "slug": "H.-Shum",
                        "structuredName": {
                            "firstName": "Harry",
                            "lastName": "Shum",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Shum"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[13] who report real-time performance using a very similar approach)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[13] propose a realtime patch-based texture synthesis method very similar to ours."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 15448589,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e02295601663f95d8df87adbe159cbd39b685543",
            "isKey": false,
            "numCitedBy": 718,
            "numCiting": 43,
            "paperAbstract": {
                "fragments": [],
                "text": "We present an algorithm for synthesizing textures from an input sample. This patch-based sampling algorithm is fast and it makes high-quality texture synthesis a real-time process. For generating textures of the same size and comparable quality, patch-based sampling is orders of magnitude faster than existing algorithms. The patch-based sampling algorithm works well for a wide variety of textures ranging from regular to stochastic. By sampling patches according to a nonparametric estimation of the local conditional MRF density function, we avoid mismatching features across patch boundaries. We also experimented with documented cases for which pixel-based nonparametric sampling algorithms cease to be effective but our algorithm continues to work well."
            },
            "slug": "Real-time-texture-synthesis-by-patch-based-sampling-Liang-Liu",
            "title": {
                "fragments": [],
                "text": "Real-time texture synthesis by patch-based sampling"
            },
            "tldr": {
                "abstractSimilarityScore": 57,
                "text": "An algorithm for synthesizing textures from an input sample by sampling patches according to a nonparametric estimation of the local conditional MRF density function, to avoid mismatching features across patch boundaries."
            },
            "venue": {
                "fragments": [],
                "text": "TOGS"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1722325"
                        ],
                        "name": "J. Bonet",
                        "slug": "J.-Bonet",
                        "structuredName": {
                            "firstName": "Jeremy",
                            "lastName": "Bonet",
                            "middleNames": [
                                "S.",
                                "De"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Bonet"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 158,
                                "start": 155
                            }
                        ],
                        "text": "Furthermore, it would be useful to be able to transfer texture from one object to anther (e.g. the ability to cut and paste material properties on arbitrary objects)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1908692,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "18bc39207b4d24eabf9d98649db53563d9c2e3fd",
            "isKey": false,
            "numCitedBy": 726,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper outlines a technique for treating input texture images as probability density estimators from which new textures, with similar appearance and structural properties, can be sampled. In a two-phase process, the input texture is first analyzed by measuring the joint occurrence of texture discrimination features at multiple resolutions. In the second phase, a new texture is synthesized by sampling successive spatial frequency bands from the input texture, conditioned on the similar joint occurrence of features at lower spatial frequencies. Textures synthesized with this method more successfully capture the characteristics of input textures than do previous techniques."
            },
            "slug": "Multiresolution-sampling-procedure-for-analysis-and-Bonet",
            "title": {
                "fragments": [],
                "text": "Multiresolution sampling procedure for analysis and synthesis of texture images"
            },
            "tldr": {
                "abstractSimilarityScore": 77,
                "text": "A technique for treating input texture images as probability density estimators from which new textures, with similar appearance and structural properties, can be sampled, which more successfully capture the characteristics of input textures than do previous techniques."
            },
            "venue": {
                "fragments": [],
                "text": "SIGGRAPH"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2072103224"
                        ],
                        "name": "Michael Salisbury",
                        "slug": "Michael-Salisbury",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Salisbury",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael Salisbury"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "112967255"
                        ],
                        "name": "M. Wong",
                        "slug": "M.-Wong",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Wong",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Wong"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1399419990"
                        ],
                        "name": "J. Hughes",
                        "slug": "J.-Hughes",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Hughes",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Hughes"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1745260"
                        ],
                        "name": "D. Salesin",
                        "slug": "D.-Salesin",
                        "structuredName": {
                            "firstName": "D.",
                            "lastName": "Salesin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Salesin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 29,
                                "start": 25
                            }
                        ],
                        "text": "Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5091350,
            "fieldsOfStudy": [
                "Art"
            ],
            "id": "680bb58093261b4cc8f58f9b575549d6260833dd",
            "isKey": false,
            "numCitedBy": 389,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "We present an interactive system for creating pen-and-ink-style line drawings from greyscale images in which the strokes of the rendered illustration follow the features of the original image. The user, via new interaction techniques for editing a direction field, specifies an orientation for each region of the image; the computer draws oriented strokes, based on a user-specified set of example strokes, that achieve the same tone as the image via a new algorithm that compares an adaptively-blurred version of the current illustration to the target tone image. By aligning the direction field with surface orientations of the objects in the image, the user can create textures that appear attached to those objects instead of merely conveying their darkness. The result is a more compelling pen-and-ink illustration than was previously possible from 2D reference imagery. CR"
            },
            "slug": "Orientable-textures-for-image-based-pen-and-ink-Salisbury-Wong",
            "title": {
                "fragments": [],
                "text": "Orientable textures for image-based pen-and-ink illustration"
            },
            "tldr": {
                "abstractSimilarityScore": 94,
                "text": "An interactive system for creating pen-and-ink-style line drawings from greyscale images in which the strokes of the rendered illustration follow the features of the original image."
            },
            "venue": {
                "fragments": [],
                "text": "SIGGRAPH"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1747779"
                        ],
                        "name": "Aaron Hertzmann",
                        "slug": "Aaron-Hertzmann",
                        "structuredName": {
                            "firstName": "Aaron",
                            "lastName": "Hertzmann",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Aaron Hertzmann"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "10251113"
                        ],
                        "name": "C. Jacobs",
                        "slug": "C.-Jacobs",
                        "structuredName": {
                            "firstName": "Charles",
                            "lastName": "Jacobs",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Jacobs"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2060131244"
                        ],
                        "name": "Nuria Oliver",
                        "slug": "Nuria-Oliver",
                        "structuredName": {
                            "firstName": "Nuria",
                            "lastName": "Oliver",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nuria Oliver"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143800609"
                        ],
                        "name": "B. Curless",
                        "slug": "B.-Curless",
                        "structuredName": {
                            "firstName": "Brian",
                            "lastName": "Curless",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Curless"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1745260"
                        ],
                        "name": "D. Salesin",
                        "slug": "D.-Salesin",
                        "structuredName": {
                            "firstName": "D.",
                            "lastName": "Salesin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Salesin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 103,
                                "start": 93
                            }
                        ],
                        "text": "The idea of texture transfer based on variations of [6] has been proposed by several authors [9, 1, 11] (in particular, see the elegant paper by Hertzmann et."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2201072,
            "fieldsOfStudy": [
                "Art"
            ],
            "id": "923562d216386a88947d40da310d94bbb1376a41",
            "isKey": false,
            "numCitedBy": 1640,
            "numCiting": 67,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes a new framework for processing images by example, called \u201cimage analogies.\u201d The framework involves two stages: a design phase, in which a pair of images, with one image purported to be a \u201cfiltered\u201d version of the other, is presented as \u201ctraining data\u201d; and an application phase, in which the learned filter is applied to some new target image in order to create an \u201canalogous\u201d filtered result. Image analogies are based on a simple multi-scale autoregression, inspired primarily by recent results in texture synthesis. By choosing different types of source image pairs as input, the framework supports a wide variety of \u201cimage filter\u201d effects, including traditional image filters, such as blurring or embossing; improved texture synthesis, in which some textures are synthesized with higher quality than by previous approaches; super-resolution, in which a higher-resolution image is inferred from a low-resolution source; texture transfer, in which images are \u201ctexturized\u201d with some arbitrary source texture; artistic filters, in which various drawing and painting styles are synthesized based on scanned real-world examples; and texture-by-numbers, in which realistic scenes, composed of a variety of textures, are created using a simple painting interface."
            },
            "slug": "Image-analogies-Hertzmann-Jacobs",
            "title": {
                "fragments": [],
                "text": "Image analogies"
            },
            "tldr": {
                "abstractSimilarityScore": 67,
                "text": "This paper describes a new framework for processing images by example, called \u201cimage analogies,\u201d based on a simple multi-scale autoregression, inspired primarily by recent results in texture synthesis."
            },
            "venue": {
                "fragments": [],
                "text": "SIGGRAPH"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2807811"
                        ],
                        "name": "Emil Praun",
                        "slug": "Emil-Praun",
                        "structuredName": {
                            "firstName": "Emil",
                            "lastName": "Praun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Emil Praun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "37737599"
                        ],
                        "name": "A. Finkelstein",
                        "slug": "A.-Finkelstein",
                        "structuredName": {
                            "firstName": "Adam",
                            "lastName": "Finkelstein",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Finkelstein"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144201188"
                        ],
                        "name": "Hugues Hoppe",
                        "slug": "Hugues-Hoppe",
                        "structuredName": {
                            "firstName": "Hugues",
                            "lastName": "Hoppe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hugues Hoppe"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 179,
                                "start": 171
                            }
                        ],
                        "text": "The result shown on Figure 2(a) already looks somewhat reasonable and for some textures will perform no worse than many previous complicated algorithms as demonstrated by [21, 18]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[18] for semiautomatic texturing of non-developable objects."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 145,
                                "start": 137
                            }
                        ],
                        "text": "Square blocks from the input texture are patched together to synthesize a new texture sample: (a) blocks are chosen randomly (similar to [21, 18]), (b) the blocks overlap and each new block is chosen so as to \u201cagree\u201d with its neighbors in the region of overlap, (c) to reduce blockiness the boundary between blocks is computed as a minimum cost path through the error surface at the overlap."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 7150663,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "060e1d10b0b00c7ae819531e353544cea10fa501",
            "isKey": true,
            "numCitedBy": 400,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "We present for creating texture over an surface mesh using an example 2D texture. The approach is to identify interesting regions (texture patches) in the 2D example, and to repeatedly paste them onto the surface until it is completely covered. We call such a collection of overlapping patches a lapped texture. It is rendered using compositing operations, either into a traditional global texture map during a preprocess, or directly with the surface at runtime. The runtime compositing approach avoids resampling artifacts and drastically reduces texture memory requirements. Through a simple interface, the user specifies a tangential vector field over the surface, providing local control over the texture scale, and for anisotropic textures, the orientation. To paste a texture patch onto the surface, a surface patch is grown and parametrized over texture space. Specifically, we optimize the parametrization of each surface patch such that the tangential vector field aligns everywhere with the standard frame of the texture patch. We show that this optimization is solved efficiently as a sparse linear system."
            },
            "slug": "Lapped-textures-Praun-Finkelstein",
            "title": {
                "fragments": [],
                "text": "Lapped textures"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This work optimize the parametrization of each surface patch such that the tangential vector field aligns everywhere with the standard frame of the texture patch, and shows that this optimization is solved efficiently as a sparse linear system."
            },
            "venue": {
                "fragments": [],
                "text": "SIGGRAPH"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "71345575"
                        ],
                        "name": "D. D. Garber",
                        "slug": "D.-D.-Garber",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Garber",
                            "middleNames": [
                                "Donovan"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. D. Garber"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "(We have recently learned that a nearly identical algorithm was proposed in 1981 by Garber [ 7 ] but discarded due to its then computational intractability.) The algorithm produces good results for a wide range of textures, but is excruciatingly slow (a full search of the input image is required to synthesize every pixel!)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 56552388,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9fc404b13aa4d33b014e77ba8c72f7a6584babde",
            "isKey": false,
            "numCitedBy": 49,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Numerous computational methods for generating and simulating binary and grey-level natural digital-image textures are proposed using a variety of stochastic models. Pictorial results of each method are given and various aspects of each approach are discussed. The quality of the natural texture simulations depends on the computation time for data collection, computation time for generation, and storage used in each process. In most cases, as computation time and data storage increase, the visual match between the texture simulation and the parent texture improves. Many textures are adequately simulated using simple models thus providing a potentially great information compression for many applications. \nIn most of the texture synthesis methods presented in this thesis, pixel values are generated one-at-a-time according to both the given model and the values of pixels previously generated in the synthesis until the image space is completely filled. Nth-order joint density functions estimated from a natural texture sample were used for this purpose in one method. The results are excellent but the storage required, even for binary textures, is large. Therefore, a much simpler first-order linear, autoregressive model was applied to the texture synthesis problem. Using this model on both binary and continuous-tone textures, each pixel is generated as a linear combination of previously generated pixels plus stationary noise. The results indicate that many textures are satisfactorily simulated using this approach. \nBy adding cross-product terms, the first-order linear model is extended to a second-order linear model. The simulation results improve slightly but the number of computations required for the statistics collection process increases drastically. Non-stationary noise was then used in the synthesis process and further improvements in the quality of the simulations are achieved at the cost of increased storage. \nMethods of texture simulation using more than one model are studied in this thesis. These multiple-models are useful for many textures, especially those with macro-structure. They also improve the fit of the model when applied to the parent texture data and therefore may produce improved simulations. \nA final model, called the best-fit model, generates texture simulations directly from the parent texture itself. Each pixel in the synthesis image is generated based on the similarity of its previously-generated, neighboring pixel values to pixel values in all similarly-shaped neighborhoods in the parent texture. The measures of similarity at all points in the parent texture, along with a random variable, are used to generate the next pixel value in the synthesized image. The synthesis results using the model are excellent but the synthesis process is very computationally demanding. \nAlthough the success of texture synthesis is highly dependent on the texture itself and the modeling method chosen, general conclusions regarding the performance of various techniques are given. Methods of texture segmentation and identification based on texture synthesis results are also presented."
            },
            "slug": "Computational-models-for-texture-analysis-and-Garber",
            "title": {
                "fragments": [],
                "text": "Computational models for texture analysis and texture synthesis"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "Although the success of texture synthesis is highly dependent on the texture itself and the modeling method chosen, general conclusions regarding the performance of various techniques are given."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1981
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2111092372"
                        ],
                        "name": "James Davis",
                        "slug": "James-Davis",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Davis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "James Davis"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 91,
                                "start": 88
                            }
                        ],
                        "text": "This can easily be done with dynamic programming (Dijkstra\u2019s algorithm can also be used [5])."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 16145112,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7f4a6d9806b1329706756634d082cb56348b44b7",
            "isKey": false,
            "numCitedBy": 367,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "Image mosaics are useful for a variety of tasks in vision and computer graphics. A particularly convenient way to generate mosaics is by 'stitching' together many ordinary photographs. Existing algorithms focus on capturing static scenes. This paper presents a complete system for creating visually pleasing mosaics in the presence of moving objects. There are three primary contributions. The first component of our system is a registration method that remains unbiased by movement-the Mellin transform is extended to register images related by a projective transform. Second an efficient method for finding a globally consistent registration of all images is developed. By solving a linear system of equations, derived from many pairwise registration matrices, we find an optimal global registration. Lastly, a new method of compositing images is presented. Blurred areas due to moving objects are avoided by segmenting the mosaic into disjoint regions and sampling pixels in each region from a single source image."
            },
            "slug": "Mosaics-of-scenes-with-moving-objects-Davis",
            "title": {
                "fragments": [],
                "text": "Mosaics of scenes with moving objects"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A complete system for creating visually pleasing mosaics in the presence of moving objects by solving a linear system of equations derived from many pairwise registration matrices and finding an optimal global registration is presented."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings. 1998 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.98CB36231)"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143632999"
                        ],
                        "name": "B. Guo",
                        "slug": "B.-Guo",
                        "structuredName": {
                            "firstName": "Baining",
                            "lastName": "Guo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Guo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "93596028"
                        ],
                        "name": "H. Shum",
                        "slug": "H.-Shum",
                        "structuredName": {
                            "firstName": "Heung-yeung",
                            "lastName": "Shum",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Shum"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1742571"
                        ],
                        "name": "Ying-Qing Xu",
                        "slug": "Ying-Qing-Xu",
                        "structuredName": {
                            "firstName": "Ying-Qing",
                            "lastName": "Xu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ying-Qing Xu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14980760,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bfc75d79183f6f3b4640a63ff7bb5a63b3e19796",
            "isKey": false,
            "numCitedBy": 187,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a procedural method for synthesizing large textures from an input texture sample. The basis of our algorithm is the chaos mosaic, a technique for synthesizing textures with an even and visually stochastic distribution of the local features of the input sample. The chaos mosaic is fast. For synthesizing textures of the same size and comparable quality, our algorithm is orders of magnitude faster than existing algorithms. On a PC we can synthesize a 512 512 texture from a 64 64 sample in just 0.03 second. More importantly, the chaos mosaic facilitates memory efficient texture rendering through procedural texturing. Like traditional solid texture techniques, the chaos mosaic allows us to synthesize and render synthetic textures that, if stored explicitly as textures, would require prohibitively large amount of storage. As an example, we demonstrate that an 100k 100k synthetic texture can be interactively visualized on a modest PC without suffering from latency. Finally, the chaos mosaic can drastically reduce the bandwidth for interactive 3D graphics delivered across the internet."
            },
            "slug": "Chaos-Mosaic:-Fast-and-Memory-Efficient-Texture-Guo-Shum",
            "title": {
                "fragments": [],
                "text": "Chaos Mosaic: Fast and Memory Efficient Texture Synthesis"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The chaos mosaic allows us to synthesize and render synthetic textures that, if stored explicitly as textures, would require prohibitively large amount of storage and drastically reduce the bandwidth for interactive 3D graphics delivered across the internet."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1768122"
                        ],
                        "name": "V. Ostromoukhov",
                        "slug": "V.-Ostromoukhov",
                        "structuredName": {
                            "firstName": "Victor",
                            "lastName": "Ostromoukhov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Ostromoukhov"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1740303"
                        ],
                        "name": "R. Hersch",
                        "slug": "R.-Hersch",
                        "structuredName": {
                            "firstName": "Roger",
                            "lastName": "Hersch",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Hersch"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 34,
                                "start": 30
                            }
                        ],
                        "text": "Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 13173951,
            "fieldsOfStudy": [
                "Art"
            ],
            "id": "63342cae35aa96a95072b9764b4f4784185a9711",
            "isKey": false,
            "numCitedBy": 66,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "A multi-color dithering algorithm is proposed, which converts a barycentric combination of color intensities into a multi-color non-overlapping surface coverage. Multi-color dithering is a generalization of standard bi-level dithering. Combined with tetrahedral color separation, multi-color dithering makes it possible to print images made of a set of non-standard inks. In contrast to most previous color halftoning methods, multi-color dithering ensures by construction that the different selected basic colors are printed side by side. Multi-color dithering is applied to generate color images whose screen dots are made of artistic shapes (letters, symbols, ornaments, etc.). Two dither matrix postprocessing techniques are developed, one for enhancing the visibility of screen motives and one for the local equilibration of large dither matrices. The dither matrix equilibration process corrects disturbing local intensity variations by taking dot gain and the human visual system transfer function into account. Thanks to the combination of the presented techniques, high quality images can be produced, which incorporate at the micro level the desired artistic screens and at the macro level the full color image. Applications include designs for advertisements and posters as well as security printing. Multi-color dithering also offers new perspectives for printing with special inks, such as fluorescent and metallic inks."
            },
            "slug": "Multi-color-and-artistic-dithering-Ostromoukhov-Hersch",
            "title": {
                "fragments": [],
                "text": "Multi-color and artistic dithering"
            },
            "tldr": {
                "abstractSimilarityScore": 71,
                "text": "A multi-color dithering algorithm is proposed, which converts a barycentric combination of color intensities into a multi- color non-overlapping surface coverage and two dither matrix postprocessing techniques are developed, one for enhancing the visibility of screen motives and one for the local equilibration of large dither matrices."
            },
            "venue": {
                "fragments": [],
                "text": "SIGGRAPH '99"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "116003860"
                        ],
                        "name": "J. Bergen",
                        "slug": "J.-Bergen",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Bergen",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Bergen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145358192"
                        ],
                        "name": "E. Adelson",
                        "slug": "E.-Adelson",
                        "structuredName": {
                            "firstName": "Edward",
                            "lastName": "Adelson",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Adelson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 92,
                                "start": 85
                            }
                        ],
                        "text": "Motivated by psychophysical and computational models of human texture discrimination [2, 14], Heeger and Bergen [10] proposed to analyze texture in terms of histograms of filter responses at multiple scales and orientations."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 4288650,
            "fieldsOfStudy": [
                "Environmental Science"
            ],
            "id": "7ef6d7f96721edd46297524e80fbd8d65a57ecc7",
            "isKey": false,
            "numCitedBy": 362,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "Texture perception has frequently been studied using textures constructed by repeated placement of micropatterns or texture elements. Theories have been developed to explain the discrimina-bility of such textures in terms of specific features within the micropatterns themselves. For example, Beck1,2 observed that a region filled with vertical Ts is readily distinguished from one filled with tilted Ts but not from one filled with vertical Ls. He attributed this to the different distribution of oriented line segments present in the former case but not in the latter. However, Bergen and Julesz3 found that a region of randomly oriented Xs segregated from one filled with randomly oriented Ls, in spite of the identical distribution of oriented line segments in the two cases. They suggested that this discrimination might be based on the density of such features as terminators, corners, and intersections within the patterns. We note here that simpler, lower-level mechanisms tuned for size may be sufficient to explain this discrimination. We tested this by varying the relative sizes of the Xs and the Ls; when they produce equal responses in size-tuned mechanisms they are hard to discriminate, and when they produce different size-tuned responses they are easy to discriminate."
            },
            "slug": "Early-vision-and-texture-perception-Bergen-Adelson",
            "title": {
                "fragments": [],
                "text": "Early vision and texture perception"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "It is noted here that simpler, lower-level mechanisms tuned for size may be sufficient to explain this discrimination of micropatterns based on the density of such features as terminators, corners, and intersections within the patterns."
            },
            "venue": {
                "fragments": [],
                "text": "Nature"
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2065554001"
                        ],
                        "name": "J. Malik",
                        "slug": "J.-Malik",
                        "structuredName": {
                            "firstName": "J",
                            "lastName": "Malik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Malik"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1690922"
                        ],
                        "name": "P. Perona",
                        "slug": "P.-Perona",
                        "structuredName": {
                            "firstName": "Pietro",
                            "lastName": "Perona",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Perona"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5601682,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "29cb9c230d999a2175c31969f0d90fcae3fb4efe",
            "isKey": false,
            "numCitedBy": 1083,
            "numCiting": 69,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a model of human preattentive texture perception. This model consists of three stages: (1) convolution of the image with a bank of even-symmetric linear filters followed by half-wave rectification to give a set of responses modeling outputs of V1 simple cells, (2) inhibition, localized in space, within and among the neural-response profiles that results in the suppression of weak responses when there are strong responses at the same or nearby locations, and (3) texture-boundary detection by using wide odd-symmetric mechanisms. Our model can predict the salience of texture boundaries in any arbitrary gray-scale image. A computer implementation of this model has been tested on many of the classic stimuli from psychophysical literature. Quantitative predictions of the degree of discriminability of different texture pairs match well with experimental measurements of discriminability in human observers."
            },
            "slug": "Preattentive-texture-discrimination-with-early-Malik-Perona",
            "title": {
                "fragments": [],
                "text": "Preattentive texture discrimination with early vision mechanisms."
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "A model of human preattentive texture perception that can predict the salience of texture boundaries in any arbitrary gray-scale image and Quantitative predictions of the degree of discriminability of different texture pairs match well with experimental measurements of discriminateability in human observers."
            },
            "venue": {
                "fragments": [],
                "text": "Journal of the Optical Society of America. A, Optics and image science"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2054252"
                        ],
                        "name": "Ashok Popat",
                        "slug": "Ashok-Popat",
                        "structuredName": {
                            "firstName": "Ashok",
                            "lastName": "Popat",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ashok Popat"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1719389"
                        ],
                        "name": "Rosalind W. Picard",
                        "slug": "Rosalind-W.-Picard",
                        "structuredName": {
                            "firstName": "Rosalind",
                            "lastName": "Picard",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Rosalind W. Picard"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 144,
                                "start": 140
                            }
                        ],
                        "text": "Several researchers have proposed optimizations to the basic method including Wei and Levoy [20] (based on earlier work by Popat and Picard [16]), Harrison [9], and Ashikhmin [1]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 15358489,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "dc036b337d2f063e1cf953821acfa4b9eb610f0c",
            "isKey": false,
            "numCitedBy": 173,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a new probabilistic modeling technique for high-dimensional vector sources, and consider its application to the problems of texture synthesis, classification, and compression. Our model combines kernel estimation with clustering, to obtain a semiparametric probability mass function estimate which summarizes -- rather than contains -- the training data. Because the model is cluster based, it is inferable from a limited set of training data, despite the model's high dimensionality. Moreover, its functional form allows recursive implementation that avoids exponential growth in required memory as the number of dimensions increases. Experimental results are presented for each of the three applications considered."
            },
            "slug": "Novel-cluster-based-probability-model-for-texture-Popat-Picard",
            "title": {
                "fragments": [],
                "text": "Novel cluster-based probability model for texture synthesis, classification, and compression"
            },
            "tldr": {
                "abstractSimilarityScore": 88,
                "text": "A new probabilistic modeling technique for high-dimensional vector sources is presented, and its application to the problems of texture synthesis, classification, and compression is considered."
            },
            "venue": {
                "fragments": [],
                "text": "Other Conferences"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1987164"
                        ],
                        "name": "Cassidy J. Curtis",
                        "slug": "Cassidy-J.-Curtis",
                        "structuredName": {
                            "firstName": "Cassidy",
                            "lastName": "Curtis",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Cassidy J. Curtis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2997797"
                        ],
                        "name": "Sean E. Anderson",
                        "slug": "Sean-E.-Anderson",
                        "structuredName": {
                            "firstName": "Sean",
                            "lastName": "Anderson",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sean E. Anderson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2739862"
                        ],
                        "name": "Joshua E. Seims",
                        "slug": "Joshua-E.-Seims",
                        "structuredName": {
                            "firstName": "Joshua",
                            "lastName": "Seims",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Joshua E. Seims"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "4564909"
                        ],
                        "name": "K. Fleischer",
                        "slug": "K.-Fleischer",
                        "structuredName": {
                            "firstName": "Kurt",
                            "lastName": "Fleischer",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Fleischer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1745260"
                        ],
                        "name": "D. Salesin",
                        "slug": "D.-Salesin",
                        "structuredName": {
                            "firstName": "D.",
                            "lastName": "Salesin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Salesin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Our goal is like that of work in non-photorealistic rendering (e.g. [ 4 , 19, 15])."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 3051452,
            "fieldsOfStudy": [
                "Art"
            ],
            "id": "41e32ac0fd2be3c72402ac060410be042d96ef0e",
            "isKey": false,
            "numCitedBy": 538,
            "numCiting": 73,
            "paperAbstract": {
                "fragments": [],
                "text": "A watercolor model based on an ordered set of translucent glazes, which are created independently usinig a shallow water fluid simulation. A Kubelka-Munk compositing model is used for simulating the optical effect of the superimposed glazes. The computer generated watercolor model is used as part of an interactive watercolor paint system, or as a method for automatic image \u201cwatercolorization.\u201d"
            },
            "slug": "Computer-generated-watercolor-Curtis-Anderson",
            "title": {
                "fragments": [],
                "text": "Computer-generated watercolor"
            },
            "tldr": {
                "abstractSimilarityScore": 99,
                "text": "A watercolor model based on an ordered set of translucent glazes, which are created independently usinig a shallow water fluid simulation, and a Kubelka-Munk compositing model is used for simulating the optical effect of the superimposed glazes."
            },
            "venue": {
                "fragments": [],
                "text": "SIGGRAPH"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3326400"
                        ],
                        "name": "B. Julesz",
                        "slug": "B.-Julesz",
                        "structuredName": {
                            "firstName": "B\u00e9la",
                            "lastName": "Julesz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Julesz"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 156,
                                "start": 152
                            }
                        ],
                        "text": "In 1950 Gibson pointed out the importance of texture for visual perception [8], but it was the pioneering work of Bela Julesz on texture discrimination [12] that paved the way for the development of the field."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 29648250,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "4754bfb45726057d98ad47499481e8c172233e20",
            "isKey": false,
            "numCitedBy": 895,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "Visual discrimination experiments were conducted using unfamiliar displays generated by a digital computer. The displays contained two side-by-side fields with different statistical, topological or heuristic properties. Discrimination was defined as that spontaneous visual process which gives the immediate impression of two distinct fields. The condition for such discrimination was found to be based primarily on clusters or lines formed by proximate points of uniform brightness. A similar rule of connectivity with hue replacing brightness was obtained by using varicolored dots of equal subjective brightness. The limitations in discriminating complex line structures were also investigated."
            },
            "slug": "Visual-Pattern-Discrimination-Julesz",
            "title": {
                "fragments": [],
                "text": "Visual Pattern Discrimination"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "The condition for discrimination was found to be based primarily on clusters or lines formed by proximate points of uniform brightness, and a similar rule of connectivity with hue replacing brightness was obtained by using varicolored dots of equal subjective brightness."
            },
            "venue": {
                "fragments": [],
                "text": "IRE Trans. Inf. Theory"
            },
            "year": 1962
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40393949"
                        ],
                        "name": "R. Hetherington",
                        "slug": "R.-Hetherington",
                        "structuredName": {
                            "firstName": "Ralph",
                            "lastName": "Hetherington",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Hetherington"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 78,
                                "start": 75
                            }
                        ],
                        "text": "In 1950 Gibson pointed out the importance of texture for visual perception [8], but it was the pioneering work of Bela Julesz on texture discrimination [12] that paved the way for the development of the field."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 140748236,
            "fieldsOfStudy": [
                "Education"
            ],
            "id": "bf47f891e889c39edd799eb1802a033bf7445412",
            "isKey": false,
            "numCitedBy": 2633,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Let's read! We will often find out this sentence everywhere. When still being a kid, mom used to order us to always read, so did the teacher. Some books are fully read in a week and we need the obligation to support reading. What about now? Do you still love reading? Is reading only for you who have obligation? Absolutely not! We here offer you a new book enPDFd the perception of the visual world to read."
            },
            "slug": "The-Perception-of-the-Visual-World-Hetherington",
            "title": {
                "fragments": [],
                "text": "The Perception of the Visual World"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1952
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "114114112"
                        ],
                        "name": "A. Erfos",
                        "slug": "A.-Erfos",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Erfos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Erfos"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2053571265"
                        ],
                        "name": "W. Freeman",
                        "slug": "W.-Freeman",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Freeman",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Freeman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 63,
                                "start": 60
                            }
                        ],
                        "text": "Impact and Future Work: Despite its simplicity, this method [2] works amazingly well when applied to texture synthesis, producing results that are equal or better than the state-of-the-art [3] but at a fraction of the computational cost."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 18024979,
            "fieldsOfStudy": [
                "Chemistry"
            ],
            "id": "b51c2dec05933ac14c1adc1796445805f8f1b38d",
            "isKey": false,
            "numCitedBy": 14,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "Compositions are provided which protect keratinous material such as skin and hair from the deleterious effects of detergents and adverse climatic conditions. Said compositions contain a modified protein and a surface active agent."
            },
            "slug": "Quilting-for-Texture-Synthesis-and-Transfer-Erfos-Freeman",
            "title": {
                "fragments": [],
                "text": "Quilting for Texture Synthesis and Transfer"
            },
            "tldr": {
                "abstractSimilarityScore": 89,
                "text": "Compositions provided which protect keratinous material such as skin and hair from the deleterious effects of detergents and adverse climatic conditions contain a modified protein and a surface active agent."
            },
            "venue": {
                "fragments": [],
                "text": "SIGGRAPH 2001"
            },
            "year": 2001
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "and James R . Bergen . Pyramid - based texture analysis / synthesis"
            },
            "venue": {
                "fragments": [],
                "text": "In SIGGRAPH"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 92,
                                "start": 85
                            }
                        ],
                        "text": "Motivated by psychophysical and computational models of human texture discrimination [2, 14], Heeger and Bergen [10] proposed to analyze texture in terms of histograms of filter responses at multiple scales and orientations."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Preattentive texture discrimination with early vision mechanism.JOSA-A"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1990
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Hersch . Multi - color and artistic dithering"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1990
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Kurt W"
            },
            "venue": {
                "fragments": [],
                "text": "Fleisher, and D. H. Salsin. Computer-generated watercolor. In  SIGGRAPH 97  , pages 421\u2013430"
            },
            "year": 1997
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 13,
            "methodology": 11,
            "result": 1
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 25,
        "totalPages": 3
    },
    "page_url": "https://www.semanticscholar.org/paper/Image-quilting-for-texture-synthesis-and-transfer-Efros-Freeman/dd7bf950093fc65f3ae6ad79666ce1077f9dfb2e?sort=total-citations"
}