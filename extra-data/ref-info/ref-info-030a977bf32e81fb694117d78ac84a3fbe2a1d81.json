{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40338812"
                        ],
                        "name": "R. Burton",
                        "slug": "R.-Burton",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Burton",
                            "middleNames": [
                                "M."
                            ],
                            "suffix": "Jr."
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Burton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2395481"
                        ],
                        "name": "G. Mpitsos",
                        "slug": "G.-Mpitsos",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Mpitsos",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Mpitsos"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 20594741,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f43df1827cf1cbe61f9a779b963f92a57df9a4be",
            "isKey": false,
            "numCitedBy": 56,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Event-dependent-control-of-noise-enhances-learning-Burton-Mpitsos",
            "title": {
                "fragments": [],
                "text": "Event-dependent control of noise enhances learning in neural networks"
            },
            "venue": {
                "fragments": [],
                "text": "Neural Networks"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1799764"
                        ],
                        "name": "Lasse Holmstr\u00f6m",
                        "slug": "Lasse-Holmstr\u00f6m",
                        "structuredName": {
                            "firstName": "Lasse",
                            "lastName": "Holmstr\u00f6m",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lasse Holmstr\u00f6m"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38071249"
                        ],
                        "name": "P. Koistinen",
                        "slug": "P.-Koistinen",
                        "structuredName": {
                            "firstName": "Petri",
                            "lastName": "Koistinen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Koistinen"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 601336,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "11823e4fd9aa67ff429c6a63d99495187547c093",
            "isKey": false,
            "numCitedBy": 350,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "The possibility of improving the generalization capability of a neural network by introducing additive noise to the training samples is discussed. The network considered is a feedforward layered neural network trained with the back-propagation algorithm. Back-propagation training is viewed as nonlinear least-squares regression and the additive noise is interpreted as generating a kernel estimate of the probability density that describes the training vector distribution. Two specific application types are considered: pattern classifier networks and estimation of a nonstochastic mapping from data corrupted by measurement errors. It is not proved that the introduction of additive noise to the training vectors always improves network generalization. However, the analysis suggests mathematically justified rules for choosing the characteristics of noise if additive noise is used in training. Results of mathematical statistics are used to establish various asymptotic consistency results for the proposed method. Numerical simulations support the applicability of the training method."
            },
            "slug": "Using-additive-noise-in-back-propagation-training-Holmstr\u00f6m-Koistinen",
            "title": {
                "fragments": [],
                "text": "Using additive noise in back-propagation training"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "It is not proved that the introduction of additive noise to the training vectors always improves network generalization, but the analysis suggests mathematically justified rules for choosing the characteristics of noise if additive noise is used in training."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Neural Networks"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1727849"
                        ],
                        "name": "S. Hanson",
                        "slug": "S.-Hanson",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Hanson",
                            "middleNames": [
                                "Jose"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Hanson"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 63581491,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7826ff60d2dfb24d2af18c5bc565c357ef9db4c1",
            "isKey": false,
            "numCitedBy": 56,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-stochastic-version-of-the-delta-rule-Hanson",
            "title": {
                "fragments": [],
                "text": "A stochastic version of the delta rule"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1792884"
                        ],
                        "name": "Charles M. Bishop",
                        "slug": "Charles-M.-Bishop",
                        "structuredName": {
                            "firstName": "Charles",
                            "lastName": "Bishop",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Charles M. Bishop"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 16096318,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "c3ecd8e19e016d15670c8953b4b9afaa5186b0f3",
            "isKey": false,
            "numCitedBy": 993,
            "numCiting": 42,
            "paperAbstract": {
                "fragments": [],
                "text": "It is well known that the addition of noise to the input data of a neural network during training can, in some circumstances, lead to significant improvements in generalization performance. Previous work has shown that such training with noise is equivalent to a form of regularization in which an extra term is added to the error function. However, the regularization term, which involves second derivatives of the error function, is not bounded below, and so can lead to difficulties if used directly in a learning algorithm based on error minimization. In this paper we show that for the purposes of network training, the regularization term can be reduced to a positive semi-definite form that involves only first derivatives of the network mapping. For a sum-of-squares error function, the regularization term belongs to the class of generalized Tikhonov regularizers. Direct minimization of the regularized error function provides a practical alternative to training with noise."
            },
            "slug": "Training-with-Noise-is-Equivalent-to-Tikhonov-Bishop",
            "title": {
                "fragments": [],
                "text": "Training with Noise is Equivalent to Tikhonov Regularization"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "This paper shows that for the purposes of network training, the regularization term can be reduced to a positive semi-definite form that involves only first derivatives of the network mapping."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145157784"
                        ],
                        "name": "C. Lee Giles",
                        "slug": "C.-Lee-Giles",
                        "structuredName": {
                            "firstName": "C.",
                            "lastName": "Giles",
                            "middleNames": [
                                "Lee"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Lee Giles"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1740471"
                        ],
                        "name": "C. Omlin",
                        "slug": "C.-Omlin",
                        "structuredName": {
                            "firstName": "Christian",
                            "lastName": "Omlin",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Omlin"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 18813536,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "21ab69ccabe99e70f36062677cd63bca55a3c181",
            "isKey": false,
            "numCitedBy": 103,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "The experimental results in this paper demonstrate that a simple pruning/retraining method effectively improves the generalization performance of recurrent neural networks trained to recognize regular languages. The technique also permits the extraction of symbolic knowledge in the form of deterministic finite-state automata (DFA) which are more consistent with the rules to be learned. Weight decay has also been shown to improve a network's generalization performance. Simulations with two small DFA (/spl les/10 states) and a large finite-memory machine (64 states) demonstrate that the performance improvement due to pruning/retraining is generally superior to the improvement due to training with weight decay. In addition, there is no need to guess a 'good' decay rate.<<ETX>>"
            },
            "slug": "Pruning-recurrent-neural-networks-for-improved-Giles-Omlin",
            "title": {
                "fragments": [],
                "text": "Pruning recurrent neural networks for improved generalization performance"
            },
            "tldr": {
                "abstractSimilarityScore": 84,
                "text": "It is demonstrated that a simple pruning/retraining method effectively improves the generalization performance of recurrent neural networks trained to recognize regular languages and permits the extraction of symbolic knowledge in the form of deterministic finite-state automata which are more consistent with the rules to be learned."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Neural Networks"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2075413715"
                        ],
                        "name": "Zheng Zeng",
                        "slug": "Zheng-Zeng",
                        "structuredName": {
                            "firstName": "Zheng",
                            "lastName": "Zeng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zheng Zeng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145135018"
                        ],
                        "name": "R. Goodman",
                        "slug": "R.-Goodman",
                        "structuredName": {
                            "firstName": "Rodney",
                            "lastName": "Goodman",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Goodman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50860274"
                        ],
                        "name": "Padhraic Smyth",
                        "slug": "Padhraic-Smyth",
                        "structuredName": {
                            "firstName": "Padhraic",
                            "lastName": "Smyth",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Padhraic Smyth"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 159635,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0d3b51f94a5934fdda8f1e728f1b56c9bfeb1cb6",
            "isKey": false,
            "numCitedBy": 139,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "Recent work has shown that recurrent neural networks have the ability to learn finite state automata from examples. In particular, networks using second-order units have been successful at this task. In studying the performance and learning behavior of such networks we have found that the second-order network model attempts to form clusters in activation space as its internal representation of states. However, these learned states become unstable as longer and longer test input strings are presented to the network. In essence, the network forgets where the individual states are in activation space. In this paper we propose a new method to force such a network to learn stable states by introducing discretization into the network and using a pseudo-gradient learning rule to perform training. The essence of the learning rule is that in doing gradient descent, it makes use of the gradient of a sigmoid function as a heuristic hint in place of that of the hard-limiting function, while still using the discretized value in the feedback update path. The new structure uses isolated points in activation space instead of vague clusters as its internal representation of states. It is shown to have similar capabilities in learning finite state automata as the original network, but without the instability problem. The proposed pseudo-gradient learning rule may also be used as a basis for training other types of networks that have hard-limiting threshold activation functions."
            },
            "slug": "Learning-Finite-State-Machines-With-Self-Clustering-Zeng-Goodman",
            "title": {
                "fragments": [],
                "text": "Learning Finite State Machines With Self-Clustering Recurrent Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "This paper proposes a new method to force a recurrent neural network to learn stable states by introducing discretization into the network and using a pseudo-gradient learning rule to perform training, which has similar capabilities in learning finite state automata as the original network, but without the instability problem."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46486898"
                        ],
                        "name": "A. Krogh",
                        "slug": "A.-Krogh",
                        "structuredName": {
                            "firstName": "Anders",
                            "lastName": "Krogh",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Krogh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2363971"
                        ],
                        "name": "J. Hertz",
                        "slug": "J.-Hertz",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Hertz",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Hertz"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 10137788,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "48e1de7d085808004d5f0493d486669a3d2930b5",
            "isKey": false,
            "numCitedBy": 1364,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "It has been observed in numerical simulations that a weight decay can improve generalization in a feed-forward neural network. This paper explains why. It is proven that a weight decay has two effects in a linear network. First, it suppresses any irrelevant components of the weight vector by choosing the smallest vector that solves the learning problem. Second, if the size is chosen right, a weight decay can suppress some of the effects of static noise on the targets, which improves generalization quite a lot. It is then shown how to extend these results to networks with hidden layers and non-linear units. Finally the theory is confirmed by some numerical simulations using the data from NetTalk."
            },
            "slug": "A-Simple-Weight-Decay-Can-Improve-Generalization-Krogh-Hertz",
            "title": {
                "fragments": [],
                "text": "A Simple Weight Decay Can Improve Generalization"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "It is proven that a weight decay has two effects in a linear network, and it is shown how to extend these results to networks with hidden layers and non-linear units."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153170210"
                        ],
                        "name": "Clifford B. Miller",
                        "slug": "Clifford-B.-Miller",
                        "structuredName": {
                            "firstName": "Clifford",
                            "lastName": "Miller",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Clifford B. Miller"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145157784"
                        ],
                        "name": "C. Lee Giles",
                        "slug": "C.-Lee-Giles",
                        "structuredName": {
                            "firstName": "C.",
                            "lastName": "Giles",
                            "middleNames": [
                                "Lee"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Lee Giles"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6095811,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "34f8c5769899dfd9450bb13c3f52c18c88444515",
            "isKey": false,
            "numCitedBy": 64,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "There has been much interest in increasing the computational power of neural networks. In addition there has been much interest in \u201cdesigning\u201d neural networks better suited to particular problems. Increasing the \u201corder\u201d of the connectivity of a neural network permits both. Though order has played a significant role in feedforward neural networks, its role in dynamically driven recurrent networks is still being understood. This work explores the effect of order in learning grammars. We present an experimental comparison of first order and second order recurrent neural networks, as applied to the task of grammatical inference. We show that for the small grammars studied these two neural net architectures have comparable learning and generalization power, and that both are reasonably capable of extracting the correct finite state automata for the language in question. However, for a larger randomly-generated ten-state grammar, second order networks significantly outperformed the first order networks, both in convergence time and generalization capability. We show that these networks learn faster the more neurons they have (our experiments used up to 10 hidden neurons), but that the solutions found by smaller networks are usually of better quality (in terms of generalization performance after training). Second order nets have the advantage that they converge more quickly to a solution and can find it more reliably than first order nets, but that the second order solutions tend to be of poorer quality than those of the first order if both architectures are trained to the same error tolerance. Despite this, second order nets can more successfully extract finite state machines using heuristic clustering techniques applied to the internal state representations. We speculate that this may be due to restrictions on the ability of first order architecture to fully make use of its internal state representation power and that this may have implications for the performance of the two architectures when scaled up to larger problems."
            },
            "slug": "Experimental-Comparison-of-the-Effect-of-Order-in-Miller-Giles",
            "title": {
                "fragments": [],
                "text": "Experimental Comparison of the Effect of Order in Recurrent Neural Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This work presents an experimental comparison of first order and second order recurrent neural networks, as applied to the task of grammatical inference and shows that for the small grammars studied these two neural net architectures have comparable learning and generalization power, and that both are reasonably capable of extracting the correct finite state automata for the language in question."
            },
            "venue": {
                "fragments": [],
                "text": "Int. J. Pattern Recognit. Artif. Intell."
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1682548"
                        ],
                        "name": "J. Buhmann",
                        "slug": "J.-Buhmann",
                        "structuredName": {
                            "firstName": "Joachim",
                            "lastName": "Buhmann",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Buhmann"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144340430"
                        ],
                        "name": "K. Schulten",
                        "slug": "K.-Schulten",
                        "structuredName": {
                            "firstName": "Klaus",
                            "lastName": "Schulten",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Schulten"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 27,
                                "start": 21
                            }
                        ],
                        "text": "Buhmann and Schulten [6, 7] showed that noise on the membrane potentials of an associative memory model which closely mimics physiological neural systems enables the network to store and adaptively lter weak receptor inputs that would otherwise be neglected."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 60662275,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "1bd674b2a1512034b6eda126c0868321aca2b74d",
            "isKey": false,
            "numCitedBy": 10,
            "numCiting": 1,
            "paperAbstract": {
                "fragments": [],
                "text": "Recently, we simulated the activity and function of neural networks with neuronal units modelled after their physiological counterparts. Neuronal potentials, single neural spikes and their effect on postsynaptic neurons were taken into account. The neural network studied was endowed with plastic synapses. The synaptic modifications were assumed to follow Hebbian rules, i.e. the synaptic strengths increase if the pre\u2010 and postsynaptic cells fire a spike synchronously and decrease if there exists no synchronicity between pre\u2010 and postsynaptic spikes. The time scale of the synaptic plasticity was that of mental processes, i.e. a tenth of a second as proposed by v.d. Malsburg. In this contribution we extend our previous study and include random fluctuations of the neural potentials as observed in electrophysiological recordings. We will dmonstrate that random fluctuations of the membrane potentials raise the sensitivity and performance of the neural network. The fluctuations enable the network to react to wea..."
            },
            "slug": "Influence-of-noise-on-the-behavior-of-an-neural-Buhmann-Schulten",
            "title": {
                "fragments": [],
                "text": "Influence of noise on the behavior of an autoassociative neural network"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "Random fluctuations of the membrane potentials raise the sensitivity and performance of the neural network and enable the network to react to shocks as observed in electrophysiological recordings."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144423965"
                        ],
                        "name": "A. Murray",
                        "slug": "A.-Murray",
                        "structuredName": {
                            "firstName": "Alan",
                            "lastName": "Murray",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Murray"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2053507626"
                        ],
                        "name": "P. J. Edwards",
                        "slug": "P.-J.-Edwards",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Edwards",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. J. Edwards"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 8666351,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "60e66781bf17f8103bbc57fc5daeb6fbc5e4b910",
            "isKey": false,
            "numCitedBy": 190,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "We analyze the effects of analog noise on the synaptic arithmetic during multilayer perceptron training, by expanding the cost function to include noise-mediated terms. Predictions are made in the light of these calculations that suggest that fault tolerance, training quality and training trajectory should be improved by such noise-injection. Extensive simulation experiments on two distinct classification problems substantiate the claims. The results appear to be perfectly general for all training schemes where weights are adjusted incrementally, and have wide-ranging implications for all applications, particularly those involving \"inaccurate\" analog neural VLSI."
            },
            "slug": "Enhanced-MLP-performance-and-fault-tolerance-from-Murray-Edwards",
            "title": {
                "fragments": [],
                "text": "Enhanced MLP performance and fault tolerance resulting from synaptic weight noise during training"
            },
            "tldr": {
                "abstractSimilarityScore": 81,
                "text": "The effects of analog noise on the synaptic arithmetic during multilayer perceptron training is analyzed, by expanding the cost function to include noise-mediated terms, and predictions are made that fault tolerance, training quality and training trajectory should be improved by such noise-injection."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Neural Networks"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145157784"
                        ],
                        "name": "C. Lee Giles",
                        "slug": "C.-Lee-Giles",
                        "structuredName": {
                            "firstName": "C.",
                            "lastName": "Giles",
                            "middleNames": [
                                "Lee"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Lee Giles"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153170210"
                        ],
                        "name": "Clifford B. Miller",
                        "slug": "Clifford-B.-Miller",
                        "structuredName": {
                            "firstName": "Clifford",
                            "lastName": "Miller",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Clifford B. Miller"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2158193072"
                        ],
                        "name": "Dong Chen",
                        "slug": "Dong-Chen",
                        "structuredName": {
                            "firstName": "Dong",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dong Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2115401300"
                        ],
                        "name": "Hsing-Hen Chen",
                        "slug": "Hsing-Hen-Chen",
                        "structuredName": {
                            "firstName": "Hsing-Hen",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hsing-Hen Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34922532"
                        ],
                        "name": "Guo-Zheng Sun",
                        "slug": "Guo-Zheng-Sun",
                        "structuredName": {
                            "firstName": "Guo-Zheng",
                            "lastName": "Sun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Guo-Zheng Sun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2552960"
                        ],
                        "name": "Yee-Chun Lee",
                        "slug": "Yee-Chun-Lee",
                        "structuredName": {
                            "firstName": "Yee-Chun",
                            "lastName": "Lee",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yee-Chun Lee"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 19666035,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "872cdc269f3cb59f8a227818f35041415091545f",
            "isKey": false,
            "numCitedBy": 489,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "We show that a recurrent, second-order neural network using a real-time, forward training algorithm readily learns to infer small regular grammars from positive and negative string training samples. We present simulations that show the effect of initial conditions, training set size and order, and neural network architecture. All simulations were performed with random initial weight strengths and usually converge after approximately a hundred epochs of training. We discuss a quantization algorithm for dynamically extracting finite state automata during and after training. For a well-trained neural net, the extracted automata constitute an equivalence class of state machines that are reducible to the minimal machine of the inferred grammar. We then show through simulations that many of the neural net state machines are dynamically stable, that is, they correctly classify many long unseen strings. In addition, some of these extracted automata actually outperform the trained neural network for classification of unseen strings."
            },
            "slug": "Learning-and-Extracting-Finite-State-Automata-with-Giles-Miller",
            "title": {
                "fragments": [],
                "text": "Learning and Extracting Finite State Automata with Second-Order Recurrent Neural Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 74,
                "text": "It is shown that a recurrent, second-order neural network using a real-time, forward training algorithm readily learns to infer small regular grammars from positive and negative string training samples, and many of the neural net state machines are dynamically stable, that is, they correctly classify many long unseen strings."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144932833"
                        ],
                        "name": "J. S. Judd",
                        "slug": "J.-S.-Judd",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Judd",
                            "middleNames": [
                                "Stephen"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. S. Judd"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2094648"
                        ],
                        "name": "P. Munro",
                        "slug": "P.-Munro",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Munro",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Munro"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14561926,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7dca33aeafc63d0a682bb7eb420b56d809e06cbe",
            "isKey": false,
            "numCitedBy": 21,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "In a multi-layered neural network, any one of the hidden layers can be viewed as computing a distributed representation of the input. Several \"encoder\" experiments have shown that when the representation space is small it can be fully used. But computing with such a representation requires completely dependable nodes. In the case where the hidden nodes are noisy and unreliable, we find that error correcting schemes emerge simply by using noisy units during training; random errors injected during backpropagation result in spreading representations apart. Average and minimum distances increase with misfire probability, as predicted by coding-theoretic considerations. Furthermore, the effect of this noise is to protect the machine against permanent node failure, thereby potentially extending the useful lifetime of the machine."
            },
            "slug": "Nets-with-Unreliable-Hidden-Nodes-Learn-Codes-Judd-Munro",
            "title": {
                "fragments": [],
                "text": "Nets with Unreliable Hidden Nodes Learn Error-Correcting Codes"
            },
            "tldr": {
                "abstractSimilarityScore": 73,
                "text": "In a multi-layered neural network, any one of the hidden layers can be viewed as computing a distributed representation of the input, but computing with such a representation requires completely dependable nodes that are noisy and unreliable."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3175576"
                        ],
                        "name": "B. Flower",
                        "slug": "B.-Flower",
                        "structuredName": {
                            "firstName": "Barry",
                            "lastName": "Flower",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Flower"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1887191"
                        ],
                        "name": "M. Jabri",
                        "slug": "M.-Jabri",
                        "structuredName": {
                            "firstName": "Marwan",
                            "lastName": "Jabri",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Jabri"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 16972514,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "73e7fe0268843ff899e763eceec4a614e8fdb005",
            "isKey": false,
            "numCitedBy": 51,
            "numCiting": 3,
            "paperAbstract": {
                "fragments": [],
                "text": "The algorithm presented performs gradient descent on the weight space of an Artificial Neural Network (ANN), using a finite difference to approximate the gradient. The method is novel in that it achieves a computational complexity similar to that of Node Perturbation, O(N3), but does not require access to the activity of hidden or internal neurons. This is possible due to a stochastic relation between perturbations at the weights and the neurons of an ANN. The algorithm is also similar to Weight Perturbation in that it is optimal in terms of hardware requirements when used for the training of VLSI implementations of ANN's."
            },
            "slug": "Summed-Weight-Neuron-Perturbation:-An-O(N)-Over-Flower-Jabri",
            "title": {
                "fragments": [],
                "text": "Summed Weight Neuron Perturbation: An O(N) Improvement Over Weight Perturbation"
            },
            "tldr": {
                "abstractSimilarityScore": 88,
                "text": "The algorithm presented performs gradient descent on the weight space of an Artificial Neural Network, using a finite difference to approximate the gradient, which achieves a computational complexity similar to that of Node Perturbation, O(N3)."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2403454"
                        ],
                        "name": "E. Baum",
                        "slug": "E.-Baum",
                        "structuredName": {
                            "firstName": "Eric",
                            "lastName": "Baum",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Baum"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733689"
                        ],
                        "name": "D. Haussler",
                        "slug": "D.-Haussler",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Haussler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Haussler"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15659829,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "id": "25406e6733a698bfc4ac836f8e74f458e75dad4f",
            "isKey": false,
            "numCitedBy": 1696,
            "numCiting": 50,
            "paperAbstract": {
                "fragments": [],
                "text": "We address the question of when a network can be expected to generalize from m random training examples chosen from some arbitrary probability distribution, assuming that future test examples are drawn from the same distribution. Among our results are the following bounds on appropriate sample vs. network size. Assume 0 < \u220a 1/8. We show that if m O(W/\u220a log N/\u220a) random examples can be loaded on a feedforward network of linear threshold functions with N nodes and W weights, so that at least a fraction 1 \u220a/2 of the examples are correctly classified, then one has confidence approaching certainty that the network will correctly classify a fraction 1 \u220a of future test examples drawn from the same distribution. Conversely, for fully-connected feedforward nets with one hidden layer, any learning algorithm using fewer than (W/\u220a) random training examples will, for some distributions of examples consistent with an appropriate weight choice, fail at least some fixed fraction of the time to find a weight choice that will correctly classify more than a 1 \u220a fraction of the future test examples."
            },
            "slug": "What-Size-Net-Gives-Valid-Generalization-Baum-Haussler",
            "title": {
                "fragments": [],
                "text": "What Size Net Gives Valid Generalization?"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "It is shown that if m O(W/ \u220a log N/\u220a) random examples can be loaded on a feedforward network of linear threshold functions with N nodes and W weights, so that at least a fraction 1 \u220a/2 of the examples are correctly classified, then one has confidence approaching certainty that the network will correctly classify a fraction 2 \u220a of future test examples drawn from the same distribution."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2702388"
                        ],
                        "name": "G. Cauwenberghs",
                        "slug": "G.-Cauwenberghs",
                        "structuredName": {
                            "firstName": "Gert",
                            "lastName": "Cauwenberghs",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Cauwenberghs"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1964981,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "556789184cb2e401ae2938acfa66dcd624331662",
            "isKey": false,
            "numCitedBy": 166,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "A parallel stochastic algorithm is investigated for error-descent learning and optimization in deterministic networks of arbitrary topology. No explicit information about internal network structure is needed. The method is based on the model-free distributed learning mechanism of Dembo and Kailath. A modified parameter update rule is proposed by which each individual parameter vector perturbation contributes a decrease in error. A substantially faster learning speed is hence allowed. Furthermore, the modified algorithm supports learning time-varying features in dynamical networks. We analyze the convergence and scaling properties of the algorithm, and present simulation results for dynamic trajectory learning in recurrent networks."
            },
            "slug": "A-Fast-Stochastic-Error-Descent-Algorithm-for-and-Cauwenberghs",
            "title": {
                "fragments": [],
                "text": "A Fast Stochastic Error-Descent Algorithm for Supervised Learning and Optimization"
            },
            "tldr": {
                "abstractSimilarityScore": 72,
                "text": "A parallel stochastic algorithm is investigated for error-descent learning and optimization in deterministic networks of arbitrary topology based on the model-free distributed learning mechanism of Dembo and Kailath and supported by a modified parameter update rule."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31748754"
                        ],
                        "name": "J. Minnix",
                        "slug": "J.-Minnix",
                        "structuredName": {
                            "firstName": "Jay",
                            "lastName": "Minnix",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Minnix"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 62640537,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2dee0d447f09470983a9d058f69e1e08af85b020",
            "isKey": false,
            "numCitedBy": 37,
            "numCiting": 2,
            "paperAbstract": {
                "fragments": [],
                "text": "Preliminary results of a study to determine the effect of noisy training sets on fault tolerance are presented. Backpropagation was used to train three networks on 7*7 numeral patterns. One network was the control and used noiseless inputs and the other two used two different noisy cases. After learning was complete, the networks were tested for their fault tolerance to stuck-at-1 and stuck-at-0 element faults, as well as weight connection faults. The networks trained on noisy inputs had substantially better fault tolerance than the network trained on noiseless inputs.<<ETX>>"
            },
            "slug": "Fault-tolerance-of-the-backpropagation-neural-on-Minnix",
            "title": {
                "fragments": [],
                "text": "Fault tolerance of the backpropagation neural network trained on noisy inputs"
            },
            "tldr": {
                "abstractSimilarityScore": 74,
                "text": "Preliminary results of a study to determine the effect of noisy training sets on fault tolerance are presented, showing the networks trained on noisy inputs had substantially better fault tolerance than the network trained on noiseless inputs."
            },
            "venue": {
                "fragments": [],
                "text": "[Proceedings 1992] IJCNN International Joint Conference on Neural Networks"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "71764160"
                        ],
                        "name": "W. Omlin",
                        "slug": "W.-Omlin",
                        "structuredName": {
                            "firstName": "W.",
                            "lastName": "Omlin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Omlin"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 17504105,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e466a22d29f6434ac905288e621ed2888934e71f",
            "isKey": false,
            "numCitedBy": 4,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "Recently, we have proven that the dynamics of any deterministic nite-state automata (DFA) with n states and m input symbols can be implemented in a sparse second-order recurrent neural network (SORNN) with n + 1 state neurons and O(mn) second-order weights and sigmoidal discriminant functions 5]. We investigate how that constructive algorithm can be extended to fault-tolerant neural DFA implementations where faults in an analog implementation of neurons or weights do not aaect the desired network performance. We show that tolerance to weight perturbation can be achieved easily; tolerance to weight and/or neuron stuck-at-zero faults, however, requires duplication of the network resources. This result has an impact on the construction of neural DFAs with a dense internal representation of DFA states."
            },
            "slug": "Fault-tolerant-Implementation-of-Finite-state-in-Omlin",
            "title": {
                "fragments": [],
                "text": "Fault-tolerant Implementation of Finite-state Automata in Recurrent Neural Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "It is shown thatolerance to weight perturbation can be achieved easily; tolerance to weight and/or neuron stuck-at-zero faults, however, requires duplication of the network resources."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1887191"
                        ],
                        "name": "M. Jabri",
                        "slug": "M.-Jabri",
                        "structuredName": {
                            "firstName": "Marwan",
                            "lastName": "Jabri",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Jabri"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3175576"
                        ],
                        "name": "B. Flower",
                        "slug": "B.-Flower",
                        "structuredName": {
                            "firstName": "Barry",
                            "lastName": "Flower",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Flower"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 22090214,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2bb63bd162d7bea204454381db9e98c7fa069553",
            "isKey": false,
            "numCitedBy": 270,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "Previous work on analog VLSI implementation of multilayer perceptrons with on-chip learning has mainly targeted the implementation of algorithms such as back-propagation. Although back-propagation is efficient, its implementation in analog VLSI requires excessive computational hardware. It is shown that using gradient descent with direct approximation of the gradient instead of back-propagation is more economical for parallel analog implementations. It is shown that this technique (which is called ;weight perturbation') is suitable for multilayer recurrent networks as well. A discrete level analog implementation showing the training of an XOR network as an example is presented."
            },
            "slug": "Weight-Perturbation:-An-Optimal-Architecture-and-Jabri-Flower",
            "title": {
                "fragments": [],
                "text": "Weight Perturbation: An Optimal Architecture and Learning Technique for Analog VLSI Feedforward and Recurrent Multilayer Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "It is shown that using gradient descent with direct approximation of the gradient instead of back-propagation is more economical for parallel analog implementations and is suitable for multilayer recurrent networks as well."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Comput."
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145505167"
                        ],
                        "name": "C. S\u00e9quin",
                        "slug": "C.-S\u00e9quin",
                        "structuredName": {
                            "firstName": "Carlo",
                            "lastName": "S\u00e9quin",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. S\u00e9quin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "150273742"
                        ],
                        "name": "R. D. Clay",
                        "slug": "R.-D.-Clay",
                        "structuredName": {
                            "firstName": "R.",
                            "lastName": "Clay",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. D. Clay"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 28412432,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8e5812c5acf2cf9b95d9f82bb80081aa3051e208",
            "isKey": false,
            "numCitedBy": 127,
            "numCiting": 2,
            "paperAbstract": {
                "fragments": [],
                "text": "Different strategies for overcoming hardware failures in artificial neural networks are presented. The failure of one or more units in the hidden layer of layered feedforward networks is especially addressed. Different types of retraining techniques are investigated, and required retraining efforts are correlated with the internal representations for specific classification tasks. Subsequently, a practical technique is introduced to achieve true fault tolerance, i.e., to have the network continue to function correctly after failure of one or more hidden units. To achieve this fault-tolerant behavior, hidden units are randomly disabled for some pattern presentations during a standard backpropagation training phase. Prolonged training in this mode can achieve fault tolerance even with respect to fault patterns for which the network is not specifically trained"
            },
            "slug": "Fault-tolerance-in-artificial-neural-networks-S\u00e9quin-Clay",
            "title": {
                "fragments": [],
                "text": "Fault tolerance in artificial neural networks"
            },
            "tldr": {
                "abstractSimilarityScore": 62,
                "text": "Different strategies for overcoming hardware failures in artificial neural networks are presented and a practical technique is introduced to achieve true fault tolerance, i.e., to have the network continue to function correctly after failure of one or more hidden units."
            },
            "venue": {
                "fragments": [],
                "text": "1990 IJCNN International Joint Conference on Neural Networks"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688882"
                        ],
                        "name": "Yann LeCun",
                        "slug": "Yann-LeCun",
                        "structuredName": {
                            "firstName": "Yann",
                            "lastName": "LeCun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yann LeCun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1747317"
                        ],
                        "name": "J. Denker",
                        "slug": "J.-Denker",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Denker",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Denker"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1759839"
                        ],
                        "name": "S. Solla",
                        "slug": "S.-Solla",
                        "structuredName": {
                            "firstName": "Sara",
                            "lastName": "Solla",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Solla"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7785881,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e7297db245c3feb1897720b173a59fe7e36babb7",
            "isKey": false,
            "numCitedBy": 3490,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "We have used information-theoretic ideas to derive a class of practical and nearly optimal schemes for adapting the size of a neural network. By removing unimportant weights from a network, several improvements can be expected: better generalization, fewer training examples required, and improved speed of learning and/or classification. The basic idea is to use second-derivative information to make a tradeoff between network complexity and training set error. Experiments confirm the usefulness of the methods on a real-world application."
            },
            "slug": "Optimal-Brain-Damage-LeCun-Denker",
            "title": {
                "fragments": [],
                "text": "Optimal Brain Damage"
            },
            "tldr": {
                "abstractSimilarityScore": 60,
                "text": "A class of practical and nearly optimal schemes for adapting the size of a neural network by using second-derivative information to make a tradeoff between network complexity and training set error is derived."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3308302"
                        ],
                        "name": "D. Ackley",
                        "slug": "D.-Ackley",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Ackley",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Ackley"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1714528"
                        ],
                        "name": "T. Sejnowski",
                        "slug": "T.-Sejnowski",
                        "structuredName": {
                            "firstName": "Terrence",
                            "lastName": "Sejnowski",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Sejnowski"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 12174018,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a0d16f0e99f7ce5e6fb70b1a68c685e9ad610657",
            "isKey": false,
            "numCitedBy": 3393,
            "numCiting": 44,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-Learning-Algorithm-for-Boltzmann-Machines-Ackley-Hinton",
            "title": {
                "fragments": [],
                "text": "A Learning Algorithm for Boltzmann Machines"
            },
            "venue": {
                "fragments": [],
                "text": "Cogn. Sci."
            },
            "year": 1985
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1682548"
                        ],
                        "name": "J. Buhmann",
                        "slug": "J.-Buhmann",
                        "structuredName": {
                            "firstName": "Joachim",
                            "lastName": "Buhmann",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Buhmann"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144340430"
                        ],
                        "name": "K. Schulten",
                        "slug": "K.-Schulten",
                        "structuredName": {
                            "firstName": "Klaus",
                            "lastName": "Schulten",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Schulten"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 260,
                                "start": 254
                            }
                        ],
                        "text": "Buhmann and Schulten also showed that a network of spinlike neurons with stochastic spike response can store temporal patterns without resorting to time{dependent synapses nor to synapses with delay, which may not serve for temporal storage in the brain [8, 9]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 122450649,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "072e9fe0e47aaf601fd0746223667a57f79472ac",
            "isKey": false,
            "numCitedBy": 14,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "A network of spin-like neurons with asymmetric exchange interactions and stochastic spike response is proposed. The network can store and recall time sequences of regular and random biased patterns. The patterns can overlap. The performance of the suggested network is described by Monte Carlo simulation, in terms of a Fokker-Planck equation and, for a very large number N of neurons, in terms of a Liouville equation. We provide analytical expressions for the timing of the recall and analyze the scatter of the recall around the limit of precise recall N \u2192 \u221e."
            },
            "slug": "Storing-sequences-of-biased-patterns-in-neural-with-Buhmann-Schulten",
            "title": {
                "fragments": [],
                "text": "Storing sequences of biased patterns in neural networks with stochastic dynamics"
            },
            "tldr": {
                "abstractSimilarityScore": 94,
                "text": "A network of spin-like neurons with asymmetric exchange interactions and stochastic spike response is proposed, which can store and recall time sequences of regular and random biased patterns."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2052130521"
                        ],
                        "name": "Russell Reed",
                        "slug": "Russell-Reed",
                        "structuredName": {
                            "firstName": "Russell",
                            "lastName": "Reed",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Russell Reed"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 35912477,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0d82c68980943718a306df67c3ed95f782e9f93a",
            "isKey": false,
            "numCitedBy": 1660,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "A rule of thumb for obtaining good generalization in systems trained by examples is that one should use the smallest system that will fit the data. Unfortunately, it usually is not obvious what size is best; a system that is too small will not be able to learn the data while one that is just big enough may learn very slowly and be very sensitive to initial conditions and learning parameters. This paper is a survey of neural network pruning algorithms. The approach taken by the methods described here is to train a network that is larger than necessary and then remove the parts that are not needed."
            },
            "slug": "Pruning-algorithms-a-survey-Reed",
            "title": {
                "fragments": [],
                "text": "Pruning algorithms-a survey"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "The approach taken by the methods described here is to train a network that is larger than necessary and then remove the parts that are not needed."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Neural Networks"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1682548"
                        ],
                        "name": "J. Buhmann",
                        "slug": "J.-Buhmann",
                        "structuredName": {
                            "firstName": "Joachim",
                            "lastName": "Buhmann",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Buhmann"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144340430"
                        ],
                        "name": "K. Schulten",
                        "slug": "K.-Schulten",
                        "structuredName": {
                            "firstName": "Klaus",
                            "lastName": "Schulten",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Schulten"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 260,
                                "start": 254
                            }
                        ],
                        "text": "Buhmann and Schulten also showed that a network of spinlike neurons with stochastic spike response can store temporal patterns without resorting to time{dependent synapses nor to synapses with delay, which may not serve for temporal storage in the brain [8, 9]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 121040416,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "c9c2d400a91676679be99d00e31e5f7a5b12da33",
            "isKey": false,
            "numCitedBy": 82,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "A network of spinlike neurons with asymmetric exchange interactions and stochastic spike response which can learn and recall time sequences of biased patterns is proposed. Noise makes synapses with delayed response or with time-dependent strength, previously proposed for storage of time sequences, superfluous. An accurate timing of pattern sequences requires a sufficient number N of neurons. The performance of the suggested network is described by Monte Carlo simulation, in terms of a Fokker-Planck equation and, for N \u2192 \u221e, in terms of a Liouville equation."
            },
            "slug": "Noise-driven-temporal-association-in-neural-Buhmann-Schulten",
            "title": {
                "fragments": [],
                "text": "Noise-driven temporal association in neural networks"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "A network of spinlike neurons with asymmetric exchange interactions and stochastic spike response which can learn and recall time sequences of biased patterns is proposed."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1768934"
                        ],
                        "name": "A. Dembo",
                        "slug": "A.-Dembo",
                        "structuredName": {
                            "firstName": "Amir",
                            "lastName": "Dembo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Dembo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1720911"
                        ],
                        "name": "T. Kailath",
                        "slug": "T.-Kailath",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Kailath",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kailath"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 24993858,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "96aadfd877f5e7ef1cecde1abd7a4ccc7d1f1df1",
            "isKey": false,
            "numCitedBy": 62,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "Model-free learning for synchronous and asynchronous quasi-static networks is presented. The network weights are continuously perturbed, while the time-varying performance index is measured and correlated with the perturbation signals; the correlation output determines the changes in the weights. The perturbation may be either via noise sources or orthogonal signals. The invariance to detailed network structure mitigates large variability between supposedly identical networks as well as implementation defects. This local, regular, and completely distributed mechanism requires no central control and involves only a few global signals. Thus, it allows for integrated, on-chip learning in large analog and optical networks."
            },
            "slug": "Model-free-distributed-learning-Dembo-Kailath",
            "title": {
                "fragments": [],
                "text": "Model-free distributed learning"
            },
            "tldr": {
                "abstractSimilarityScore": 70,
                "text": "Model-free learning for synchronous and asynchronous quasi-static networks is presented, which allows for integrated, on-chip learning in large analog and optical networks."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Neural Networks"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1822055"
                        ],
                        "name": "Raymond L. Watrous",
                        "slug": "Raymond-L.-Watrous",
                        "structuredName": {
                            "firstName": "Raymond",
                            "lastName": "Watrous",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Raymond L. Watrous"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2091434"
                        ],
                        "name": "G. Kuhn",
                        "slug": "G.-Kuhn",
                        "structuredName": {
                            "firstName": "Gary",
                            "lastName": "Kuhn",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Kuhn"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 32480997,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a64ca771a733d58dcbf8f7a3fe65a09310424bf8",
            "isKey": false,
            "numCitedBy": 215,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "Second-order recurrent networks that recognize simple finite state languages over {0,1}* are induced from positive and negative examples. Using the complete gradient of the recurrent network and sufficient training examples to constrain the definition of the language to be induced, solutions are obtained that correctly recognize strings of arbitrary length."
            },
            "slug": "Induction-of-Finite-State-Languages-Using-Recurrent-Watrous-Kuhn",
            "title": {
                "fragments": [],
                "text": "Induction of Finite-State Languages Using Second-Order Recurrent Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 80,
                "text": "Second-order recurrent networks that recognize simple finite state languages over {0,1}* are induced from positive and negative examples to obtain solutions that correctly recognize strings of arbitrary length."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145847131"
                        ],
                        "name": "S. Kirkpatrick",
                        "slug": "S.-Kirkpatrick",
                        "structuredName": {
                            "firstName": "Scott",
                            "lastName": "Kirkpatrick",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Kirkpatrick"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "5882723"
                        ],
                        "name": "C. D. Gelatt",
                        "slug": "C.-D.-Gelatt",
                        "structuredName": {
                            "firstName": "Charles",
                            "lastName": "Gelatt",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. D. Gelatt"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "88645967"
                        ],
                        "name": "M. Vecchi",
                        "slug": "M.-Vecchi",
                        "structuredName": {
                            "firstName": "Michelle",
                            "lastName": "Vecchi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Vecchi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 205939,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "dd5061631a4d11fa394f4421700ebf7e78dcbc59",
            "isKey": false,
            "numCitedBy": 39631,
            "numCiting": 79,
            "paperAbstract": {
                "fragments": [],
                "text": "There is a deep and useful connection between statistical mechanics (the behavior of systems with many degrees of freedom in thermal equilibrium at a finite temperature) and multivariate or combinatorial optimization (finding the minimum of a given function depending on many parameters). A detailed analogy with annealing in solids provides a framework for optimization of the properties of very large and complex systems. This connection to statistical mechanics exposes new information and provides an unfamiliar perspective on traditional optimization problems and methods."
            },
            "slug": "Optimization-by-Simulated-Annealing-Kirkpatrick-Gelatt",
            "title": {
                "fragments": [],
                "text": "Optimization by Simulated Annealing"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "A detailed analogy with annealing in solids provides a framework for optimization of the properties of very large and complex systems."
            },
            "venue": {
                "fragments": [],
                "text": "Science"
            },
            "year": 1983
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2035591"
                        ],
                        "name": "H. Bremermann",
                        "slug": "H.-Bremermann",
                        "structuredName": {
                            "firstName": "Hans",
                            "lastName": "Bremermann",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Bremermann"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34827289"
                        ],
                        "name": "Russell W. Anderson",
                        "slug": "Russell-W.-Anderson",
                        "structuredName": {
                            "firstName": "Russell",
                            "lastName": "Anderson",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Russell W. Anderson"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 27944177,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "8b57afc2f26866b1b3dc87a86ccc67e4b6654692",
            "isKey": false,
            "numCitedBy": 37,
            "numCiting": 76,
            "paperAbstract": {
                "fragments": [],
                "text": "The notion that the synapse is the site of lasting change in memory and learning has had wide acceptance for decades. Hebb [46] postulated that when one neuron repeatedly excites another, the synaptic knobs are strengthened. Verification has taken time, but there is now ample evidence that Hebbian type long term potentiation (with some modifications of the original hypothesis) does indeed occur [61]."
            },
            "slug": "How-the-Brain-Adjusts-Synapses-Maybe-Bremermann-Anderson",
            "title": {
                "fragments": [],
                "text": "How the Brain Adjusts Synapses - Maybe"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "Verification has taken time, but there is now ample evidence that Hebbian type long term potentiation (with some modifications of the original hypothesis) does indeed occur."
            },
            "venue": {
                "fragments": [],
                "text": "Automated Reasoning: Essays in Honor of Woody Bledsoe"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1714528"
                        ],
                        "name": "T. Sejnowski",
                        "slug": "T.-Sejnowski",
                        "structuredName": {
                            "firstName": "Terrence",
                            "lastName": "Sejnowski",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Sejnowski"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 58779360,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8592e46a5435d18bba70557846f47290b34c1aa5",
            "isKey": false,
            "numCitedBy": 1338,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "This chapter contains sections titled: Relaxation Searches, Easy and Hard Learning, The Boltzmann Machine Learning Algorithm, An Example of Hard Learning, Achieving Reliable Computation with Unreliable Hardware, An Example of the Effects of Damage, Conclusion, Acknowledgments, Appendix: Derivation of the Learning Algorithm, References"
            },
            "slug": "Learning-and-relearning-in-Boltzmann-machines-Hinton-Sejnowski",
            "title": {
                "fragments": [],
                "text": "Learning and relearning in Boltzmann machines"
            },
            "tldr": {
                "abstractSimilarityScore": 99,
                "text": "This chapter contains sections titled: Relaxation Searches, Easy and Hard learning, The Boltzmann Machine Learning Algorithm, An Example of Hard Learning, Achieving Reliable Computation with Unreliable Hardware, and an Example of the Effects of Damage."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144289854"
                        ],
                        "name": "W. Bledsoe",
                        "slug": "W.-Bledsoe",
                        "structuredName": {
                            "firstName": "W.",
                            "lastName": "Bledsoe",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Bledsoe"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2404260"
                        ],
                        "name": "R. Boyer",
                        "slug": "R.-Boyer",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Boyer",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Boyer"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 42921737,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e7bb0f1588f5e373a7ffb196d707fdab52681098",
            "isKey": false,
            "numCitedBy": 112,
            "numCiting": 83,
            "paperAbstract": {
                "fragments": [],
                "text": "Netherlands. No part of the material protected by this copyright notice may be reproduced or utilized in any form or by any means, electronic or mechanical including photocopying, recording or by any information storage and retrieval system, without written permission from the copyright owner. 297 Contributors 347 Index 349 Preface These essays have been written to honor W. W. Bledsoe, a scientist who has contributed to such diverse elds as mathematics, systems analysis, pattern recognition, biology, artiicial intelligence, and automated reasoning. The rst essay provides a sketch of his life, emphasizing his scientiic contributions. The diversity of the elds to which Bledsoe has contributed is reeected in the range of the other essays, which are original scientiic contributions by some of his many friends and colleagues. Bledsoe is a founding father of the eld of automated reasoning, and a majority of the essays are on that topic. These essays are collected together here not only to acknowledge Bledsoe's manifold and substantial scientiic contributions but also to express our appreciation for the great care and energy that he has devoted to nurturing many of the scientists working in those scientiic elds he has helped found."
            },
            "slug": "Automated-Reasoning:-Essays-in-Honor-of-Woody-Bledsoe-Boyer",
            "title": {
                "fragments": [],
                "text": "Automated Reasoning: Essays in Honor of Woody Bledsoe"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "These essays have been written to honor W. W. Bledsoe, a scientist who has contributed to such diverse elds as mathematics, systems analysis, pattern recognition, biology, artiicial intelligence, and automated reasoning, and a founding father of the eld of automated reasoning."
            },
            "venue": {
                "fragments": [],
                "text": "Automated Reasoning"
            },
            "year": 1991
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 30,
                                "start": 24
                            }
                        ],
                        "text": "Bremermann and Anderson [4, 5] introduced a biased random walk in weight space (the \"chemotaxis algorithm\") as a biologically plausible learning rule, and Kilis and Ackerman [19] introduced a stochastic neuron model which uses Monte Carlo techniques to stochastically bias the ring decision of neurons."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 23,
                                "start": 0
                            }
                        ],
                        "text": "Bremermann and Anderson [4, 5] introduced a biased random walk in weight space (the \"chemotaxis algo-rithm\") as a biologically plausible learning rule, and Kilis and Ackerman [19] introduced a stochastic neuronmodel which uses Monte Carlo techniques to stochastically bias the ring decision of neurons."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 39,
                                "start": 31
                            }
                        ],
                        "text": "[5] H. J. Bremermann and R. W. Anderson."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 39,
                                "start": 31
                            }
                        ],
                        "text": "[4] H. J. Bremermann and R. W. Anderson."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "An alternative to back-propagation: A simple rule of synaptic  modi cation for neural net training and memory"
            },
            "venue": {
                "fragments": [],
                "text": "Technical Report PAM{483, U. C. Berkeley Center  for Pure and Applied Mathematics,"
            },
            "year": 1989
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 47,
                                "start": 43
                            }
                        ],
                        "text": "For example, Hinton, Sejnowski, and Ackley [15] compared noise temperature in the Boltzmann machine to the addition of Gaussian noise at neuronal membrane potentials."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 66,
                                "start": 60
                            }
                        ],
                        "text": "[15] Geo rey E. Hinton, Terrence J. Sejnowski, and David H. Ackley."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 17,
                                "start": 11
                            }
                        ],
                        "text": "Similarly, Ackley, et.al. and Hinton and Sejnowski [1, 14] used noise in Boltzmann machines toescape from local minima."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 310,
                                "start": 304
                            }
                        ],
                        "text": "Applying this equality here, X and Y are independent noise values, a = 1, b = 1, Cov(X;Y ) = 0, and thefollowing is obtained: V ar(nM) = V ar( 0) + V ar( 1) + + V ar( M): (41)Thus, the noise values for training samples presented later within the batch will observe greater variance.30\nReferences[1] D.H. Ackley, G.E. Hinton, and T.J. Sejnowski."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 42,
                                "start": 13
                            }
                        ],
                        "text": "For example, Hinton, Sejnowski, and Ackley [15] compared noisetemperature in the Boltzmann machine to the addition of Gaussian noise at neuronal membrane potentials."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Boltzmann machines: Constraint  satisfaction networks that learn"
            },
            "venue": {
                "fragments": [],
                "text": "Technical Report CMU-CS-84-119,"
            },
            "year": 1984
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 24,
                                "start": 20
                            }
                        ],
                        "text": "S equin and Reed D. Clay."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 32,
                                "start": 28
                            }
                        ],
                        "text": "Similarly, S equin and Clay [28] showed that randomly disabling hidden nodes (i."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 27,
                                "start": 23
                            }
                        ],
                        "text": "Similarly, S equin and Clay [28] showed that randomly disabling hidden nodes(i.e. clamp to zero) during the training phase increases the tolerance of multilayer perceptrons to nodefailures."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Fault tolerance in arti cial neural networks"
            },
            "venue": {
                "fragments": [],
                "text": "In Proc. of IJCNN,  volume I, pages I{703{708,"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2116648700"
                        ],
                        "name": "Ronald J. Williams",
                        "slug": "Ronald-J.-Williams",
                        "structuredName": {
                            "firstName": "Ronald",
                            "lastName": "Williams",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ronald J. Williams"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1895771"
                        ],
                        "name": "D. Zipser",
                        "slug": "D.-Zipser",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Zipser",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Zipser"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 14792754,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "10dae7fca6b65b61d155a622f0c6ca2bc3922251",
            "isKey": false,
            "numCitedBy": 567,
            "numCiting": 57,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Gradient-based-learning-algorithms-for-recurrent-Williams-Zipser",
            "title": {
                "fragments": [],
                "text": "Gradient-based learning algorithms for recurrent networks and their computational complexity"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "An alternative to back-propagation: A simple rule of synaptic modiication for neural net training and memory"
            },
            "venue": {
                "fragments": [],
                "text": "An alternative to back-propagation: A simple rule of synaptic modiication for neural net training and memory"
            },
            "year": 1989
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A stochastic neuron model for pattern recognition"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the International Joint Conference on Neural Networks"
            },
            "year": 1990
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 322,
                                "start": 310
                            }
                        ],
                        "text": "1 Noiseless Recurrent Network Architecture and Training In this paper we restrict ourselves to second-order, fully-connected, discrete-time recurrent networks since such networks have demonstrated good performance on the types of problems we discuss in this paper, namely, that of learning nite state grammars [11, 22, 29]."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Experimental comparison of the e ect of order in recurrent neural networks"
            },
            "venue": {
                "fragments": [],
                "text": "Journal of Pattern Recognition and Arti cal Intelligence,"
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Experimental comparison of the eeect of order in recurrent neural networks"
            },
            "venue": {
                "fragments": [],
                "text": "849{872, 1993. Special Issue on Neural Networks and Pattern Recognition"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Fault tolerance in artiicial neural networks"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. of IJCNN, volume I"
            },
            "year": 1990
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Boltzmann machines: Constraint satisfaction networks that learn"
            },
            "venue": {
                "fragments": [],
                "text": "Boltzmann machines: Constraint satisfaction networks that learn"
            },
            "year": 1984
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 5,
            "methodology": 1
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 40,
        "totalPages": 4
    },
    "page_url": "https://www.semanticscholar.org/paper/An-analysis-of-noise-in-recurrent-neural-networks:-Jim-Giles/030a977bf32e81fb694117d78ac84a3fbe2a1d81?sort=total-citations"
}