{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143629707"
                        ],
                        "name": "Amr Ahmed",
                        "slug": "Amr-Ahmed",
                        "structuredName": {
                            "firstName": "Amr",
                            "lastName": "Ahmed",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Amr Ahmed"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1898417"
                        ],
                        "name": "N. Shervashidze",
                        "slug": "N.-Shervashidze",
                        "structuredName": {
                            "firstName": "Nino",
                            "lastName": "Shervashidze",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Shervashidze"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3005102"
                        ],
                        "name": "Shravan M. Narayanamurthy",
                        "slug": "Shravan-M.-Narayanamurthy",
                        "structuredName": {
                            "firstName": "Shravan",
                            "lastName": "Narayanamurthy",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shravan M. Narayanamurthy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1679460"
                        ],
                        "name": "V. Josifovski",
                        "slug": "V.-Josifovski",
                        "structuredName": {
                            "firstName": "Vanja",
                            "lastName": "Josifovski",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Josifovski"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46234526"
                        ],
                        "name": "Alex Smola",
                        "slug": "Alex-Smola",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Smola",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alex Smola"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 78,
                                "start": 75
                            }
                        ],
                        "text": "Among the most recent literature is a technique called graph factorization [1]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 5,
                                "start": 2
                            }
                        ],
                        "text": ", [1]) or lack a clear objective function tailored for network embedding (e."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 11955698,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "952bc3bc999be86d4b03a9c4af94c555c822aa11",
            "isKey": false,
            "numCitedBy": 498,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "Natural graphs, such as social networks, email graphs, or instant messaging patterns, have become pervasive through the internet. These graphs are massive, often containing hundreds of millions of nodes and billions of edges. While some theoretical models have been proposed to study such graphs, their analysis is still difficult due to the scale and nature of the data. We propose a framework for large-scale graph decomposition and inference. To resolve the scale, our framework is distributed so that the data are partitioned over a shared-nothing set of machines. We propose a novel factorization technique that relies on partitioning a graph so as to minimize the number of neighboring vertices rather than edges across partitions. Our decomposition is based on a streaming algorithm. It is network-aware as it adapts to the network topology of the underlying computational hardware. We use local copies of the variables and an efficient asynchronous communication protocol to synchronize the replicated values in order to perform most of the computation without having to incur the cost of network communication. On a graph of 200 million vertices and 10 billion edges, derived from an email communication network, our algorithm retains convergence properties while allowing for almost linear scalability in the number of computers."
            },
            "slug": "Distributed-large-scale-natural-graph-factorization-Ahmed-Shervashidze",
            "title": {
                "fragments": [],
                "text": "Distributed large-scale natural graph factorization"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This work proposes a novel factorization technique that relies on partitioning a graph so as to minimize the number of neighboring vertices rather than edges across partitions, and decomposition is based on a streaming algorithm."
            },
            "venue": {
                "fragments": [],
                "text": "WWW"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50362385"
                        ],
                        "name": "Seth A. Myers",
                        "slug": "Seth-A.-Myers",
                        "structuredName": {
                            "firstName": "Seth",
                            "lastName": "Myers",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Seth A. Myers"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2109669217"
                        ],
                        "name": "Aneesh Sharma",
                        "slug": "Aneesh-Sharma",
                        "structuredName": {
                            "firstName": "Aneesh",
                            "lastName": "Sharma",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Aneesh Sharma"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46479974"
                        ],
                        "name": "Pankaj Gupta",
                        "slug": "Pankaj-Gupta",
                        "structuredName": {
                            "firstName": "Pankaj",
                            "lastName": "Gupta",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Pankaj Gupta"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145580839"
                        ],
                        "name": "Jimmy J. Lin",
                        "slug": "Jimmy-J.-Lin",
                        "structuredName": {
                            "firstName": "Jimmy",
                            "lastName": "Lin",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jimmy J. Lin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 129,
                                "start": 125
                            }
                        ],
                        "text": "For example, the Twitter followee-follower network contains 175 million active users and around twenty billion edges in 2012 [14]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1676889,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d055b02f7511ccf22ce6a00f3569d0a84278f5bd",
            "isKey": false,
            "numCitedBy": 284,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we provide a characterization of the topological features of the Twitter follow graph, analyzing properties such as degree distributions, connected components, shortest path lengths, clustering coefficients, and degree assortativity. For each of these properties, we compare and contrast with available data from other social networks. These analyses provide a set of authoritative statistics that the community can reference. In addition, we use these data to investigate an often-posed question: Is Twitter a social network or an information network? The \"follow\" relationship in Twitter is primarily about information consumption, yet many follows are built on social ties. Not surprisingly, we find that the Twitter follow graph exhibits structural characteristics of both an information network and a social network. Going beyond descriptive characterizations, we hypothesize that from an individual user's perspective, Twitter starts off more like an information network, but evolves to behave more like a social network. We provide preliminary evidence that may serve as a formal model of how a hybrid network like Twitter evolves."
            },
            "slug": "Information-network-or-social-network:-the-of-the-Myers-Sharma",
            "title": {
                "fragments": [],
                "text": "Information network or social network?: the structure of the twitter follow graph"
            },
            "tldr": {
                "abstractSimilarityScore": 74,
                "text": "A characterization of the topological features of the Twitter follow graph is provided, analyzing properties such as degree distributions, connected components, shortest path lengths, clustering coefficients, and degree assortativity to hypothesize that from an individual user's perspective, Twitter starts off more like an information network, but evolves to behave more like a social network."
            },
            "venue": {
                "fragments": [],
                "text": "WWW"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143653681"
                        ],
                        "name": "Shuicheng Yan",
                        "slug": "Shuicheng-Yan",
                        "structuredName": {
                            "firstName": "Shuicheng",
                            "lastName": "Yan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shuicheng Yan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38188040"
                        ],
                        "name": "Dong Xu",
                        "slug": "Dong-Xu",
                        "structuredName": {
                            "firstName": "Dong",
                            "lastName": "Xu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dong Xu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2158301"
                        ],
                        "name": "Benyu Zhang",
                        "slug": "Benyu-Zhang",
                        "structuredName": {
                            "firstName": "Benyu",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Benyu Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2144973386"
                        ],
                        "name": "HongJiang Zhang",
                        "slug": "HongJiang-Zhang",
                        "structuredName": {
                            "firstName": "HongJiang",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "HongJiang Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152290618"
                        ],
                        "name": "Qiang Yang",
                        "slug": "Qiang-Yang",
                        "structuredName": {
                            "firstName": "Qiang",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Qiang Yang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145676588"
                        ],
                        "name": "Stephen Lin",
                        "slug": "Stephen-Lin",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Lin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Stephen Lin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 78,
                                "start": 74
                            }
                        ],
                        "text": ", the K-nearest neighbor graph of data, and then embed the affinity graph [22] into a low dimensional space."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2426049,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "69381b5efd97e7c55f51c2730caccab3d632d4d2",
            "isKey": false,
            "numCitedBy": 2194,
            "numCiting": 40,
            "paperAbstract": {
                "fragments": [],
                "text": "A large family of algorithms - supervised or unsupervised; stemming from statistics or geometry theory - has been designed to provide different solutions to the problem of dimensionality reduction. Despite the different motivations of these algorithms, we present in this paper a general formulation known as graph embedding to unify them within a common framework. In graph embedding, each algorithm can be considered as the direct graph embedding or its linear/kernel/tensor extension of a specific intrinsic graph that describes certain desired statistical or geometric properties of a data set, with constraints from scale normalization or a penalty graph that characterizes a statistical or geometric property that should be avoided. Furthermore, the graph embedding framework can be used as a general platform for developing new dimensionality reduction algorithms. By utilizing this framework as a tool, we propose a new supervised dimensionality reduction algorithm called marginal Fisher analysis in which the intrinsic graph characterizes the intraclass compactness and connects each data point with its neighboring points of the same class, while the penalty graph connects the marginal points and characterizes the interclass separability. We show that MFA effectively overcomes the limitations of the traditional linear discriminant analysis algorithm due to data distribution assumptions and available projection directions. Real face recognition experiments show the superiority of our proposed MFA in comparison to LDA, also for corresponding kernel and tensor extensions"
            },
            "slug": "Graph-Embedding-and-Extensions:-A-General-Framework-Yan-Xu",
            "title": {
                "fragments": [],
                "text": "Graph Embedding and Extensions: A General Framework for Dimensionality Reduction"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A new supervised dimensionality reduction algorithm called marginal Fisher analysis is proposed in which the intrinsic graph characterizes the intraclass compactness and connects each data point with its neighboring points of the same class, while the penalty graph connects the marginal points and characterizing the interclass separability."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46199760"
                        ],
                        "name": "Jie Tang",
                        "slug": "Jie-Tang",
                        "structuredName": {
                            "firstName": "Jie",
                            "lastName": "Tang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jie Tang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1519070643"
                        ],
                        "name": "Jing Zhang",
                        "slug": "Jing-Zhang",
                        "structuredName": {
                            "firstName": "Jing",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jing Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1786422"
                        ],
                        "name": "Limin Yao",
                        "slug": "Limin-Yao",
                        "structuredName": {
                            "firstName": "Limin",
                            "lastName": "Yao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Limin Yao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8549842"
                        ],
                        "name": "Juan-Zi Li",
                        "slug": "Juan-Zi-Li",
                        "structuredName": {
                            "firstName": "Juan-Zi",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Juan-Zi Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153824195"
                        ],
                        "name": "Li Zhang",
                        "slug": "Li-Zhang",
                        "structuredName": {
                            "firstName": "Li",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Li Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145640647"
                        ],
                        "name": "Z. Su",
                        "slug": "Z.-Su",
                        "structuredName": {
                            "firstName": "Zhong",
                            "lastName": "Su",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Z. Su"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 29,
                                "start": 25
                            }
                        ],
                        "text": "We use the DBLP data set [19](3) to construct the citation networks between authors and between papers."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 3348552,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f020b61789112fe7241b871907268f0bdc5c84fa",
            "isKey": false,
            "numCitedBy": 1725,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper addresses several key issues in the ArnetMiner system, which aims at extracting and mining academic social networks. Specifically, the system focuses on: 1) Extracting researcher profiles automatically from the Web; 2) Integrating the publication data into the network from existing digital libraries; 3) Modeling the entire academic network; and 4) Providing search services for the academic network. So far, 448,470 researcher profiles have been extracted using a unified tagging approach. We integrate publications from online Web databases and propose a probabilistic framework to deal with the name ambiguity problem. Furthermore, we propose a unified modeling approach to simultaneously model topical aspects of papers, authors, and publication venues. Search services such as expertise search and people association search have been provided based on the modeling results. In this paper, we describe the architecture and main features of the system. We also present the empirical evaluation of the proposed methods."
            },
            "slug": "ArnetMiner:-extraction-and-mining-of-academic-Tang-Zhang",
            "title": {
                "fragments": [],
                "text": "ArnetMiner: extraction and mining of academic social networks"
            },
            "tldr": {
                "abstractSimilarityScore": 58,
                "text": "The architecture and main features of the ArnetMiner system, which aims at extracting and mining academic social networks, are described and a unified modeling approach to simultaneously model topical aspects of papers, authors, and publication venues is proposed."
            },
            "venue": {
                "fragments": [],
                "text": "KDD"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1803520"
                        ],
                        "name": "L. V. D. Maaten",
                        "slug": "L.-V.-D.-Maaten",
                        "structuredName": {
                            "firstName": "Laurens",
                            "lastName": "Maaten",
                            "middleNames": [
                                "van",
                                "der"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. V. D. Maaten"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 14,
                                "start": 10
                            }
                        ],
                        "text": "An edge-sampling algorithm is proposed that addresses the limitation of the classical stochastic gradient descent and improves both the effectiveness and the efficiency of the inference."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5855042,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1c46943103bd7b7a2c7be86859995a4144d1938b",
            "isKey": false,
            "numCitedBy": 22361,
            "numCiting": 41,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a new technique called \u201ct-SNE\u201d that visualizes high-dimensional data by giving each datapoint a location in a two or three-dimensional map. The technique is a variation of Stochastic Neighbor Embedding (Hinton and Roweis, 2002) that is much easier to optimize, and produces significantly better visualizations by reducing the tendency to crowd points together in the center of the map. t-SNE is better than existing techniques at creating a single map that reveals structure at many different scales. This is particularly important for high-dimensional data that lie on several different, but related, low-dimensional manifolds, such as images of objects from multiple classes seen from multiple viewpoints. For visualizing the structure of very large datasets, we show how t-SNE can use random walks on neighborhood graphs to allow the implicit structure of all of the data to influence the way in which a subset of the data is displayed. We illustrate the performance of t-SNE on a wide variety of datasets and compare it with many other non-parametric visualization techniques, including Sammon mapping, Isomap, and Locally Linear Embedding. The visualizations produced by t-SNE are significantly better than those produced by the other techniques on almost all of the datasets."
            },
            "slug": "Visualizing-Data-using-t-SNE-Maaten-Hinton",
            "title": {
                "fragments": [],
                "text": "Visualizing Data using t-SNE"
            },
            "tldr": {
                "abstractSimilarityScore": 84,
                "text": "A new technique called t-SNE that visualizes high-dimensional data by giving each datapoint a location in a two or three-dimensional map, a variation of Stochastic Neighbor Embedding that is much easier to optimize, and produces significantly better visualizations by reducing the tendency to crowd points together in the center of the map."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1397896615"
                        ],
                        "name": "D. Liben-Nowell",
                        "slug": "D.-Liben-Nowell",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Liben-Nowell",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Liben-Nowell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3371403"
                        ],
                        "name": "J. Kleinberg",
                        "slug": "J.-Kleinberg",
                        "structuredName": {
                            "firstName": "Jon",
                            "lastName": "Kleinberg",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Kleinberg"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "In this section, we present a novel network embedding model called the \u201cLINE,\u201d which satisfies all the three requirements."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 61,
                                "start": 57
                            }
                        ],
                        "text": "An edge-sampling algorithm is proposed that addresses the limitation of the classical stochastic gradient descent and improves both the effectiveness and the efficiency of the inference."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 207557742,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "007f3290e1b5e3061a8b7089037ee775efc47b83",
            "isKey": false,
            "numCitedBy": 857,
            "numCiting": 52,
            "paperAbstract": {
                "fragments": [],
                "text": "Given a snapshot of a social network, can we infer which new interactions among its members are likely to occur in the near future? We formalize this question as the link prediction problem, and develop approaches to link prediction based on measures the \"proximity\" of nodes in a network. Experiments on large co-authorship networks suggest that information about future interactions can be extracted from network topology alone, and that fairly subtle measures for detecting node proximity can outperform more direct measures."
            },
            "slug": "The-link-prediction-problem-for-social-networks-Liben-Nowell-Kleinberg",
            "title": {
                "fragments": [],
                "text": "The link prediction problem for social networks"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "Experiments on large co-authorship networks suggest that information about future interactions can be extracted from network topology alone, and that fairly subtle measures for detecting node proximity can outperform more direct measures."
            },
            "venue": {
                "fragments": [],
                "text": "CIKM '03"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "15644550"
                        ],
                        "name": "Xiao Yu",
                        "slug": "Xiao-Yu",
                        "structuredName": {
                            "firstName": "Xiao",
                            "lastName": "Yu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xiao Yu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1384550891"
                        ],
                        "name": "Xiang Ren",
                        "slug": "Xiang-Ren",
                        "structuredName": {
                            "firstName": "Xiang",
                            "lastName": "Ren",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xiang Ren"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2109461904"
                        ],
                        "name": "Yizhou Sun",
                        "slug": "Yizhou-Sun",
                        "structuredName": {
                            "firstName": "Yizhou",
                            "lastName": "Sun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yizhou Sun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9937103"
                        ],
                        "name": "Quanquan Gu",
                        "slug": "Quanquan-Gu",
                        "structuredName": {
                            "firstName": "Quanquan",
                            "lastName": "Gu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Quanquan Gu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47376509"
                        ],
                        "name": "Bradley Sturt",
                        "slug": "Bradley-Sturt",
                        "structuredName": {
                            "firstName": "Bradley",
                            "lastName": "Sturt",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bradley Sturt"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3030219"
                        ],
                        "name": "Urvashi Khandelwal",
                        "slug": "Urvashi-Khandelwal",
                        "structuredName": {
                            "firstName": "Urvashi",
                            "lastName": "Khandelwal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Urvashi Khandelwal"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2172095"
                        ],
                        "name": "Brandon Norick",
                        "slug": "Brandon-Norick",
                        "structuredName": {
                            "firstName": "Brandon",
                            "lastName": "Norick",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Brandon Norick"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153034701"
                        ],
                        "name": "Jiawei Han",
                        "slug": "Jiawei-Han",
                        "structuredName": {
                            "firstName": "Jiawei",
                            "lastName": "Han",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jiawei Han"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 175,
                                "start": 171
                            }
                        ],
                        "text": "Such a low-dimensional embedding is very useful in a variety of applications such as visualization [21], node classification [3], link prediction [10], and recommendation [23]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 207209998,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "65a442711000fcc1c0309106caa27a949c325566",
            "isKey": false,
            "numCitedBy": 487,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "Among different hybrid recommendation techniques, network-based entity recommendation methods, which utilize user or item relationship information, are beginning to attract increasing attention recently. Most of the previous studies in this category only consider a single relationship type, such as friendships in a social network. In many scenarios, the entity recommendation problem exists in a heterogeneous information network environment. Different types of relationships can be potentially used to improve the recommendation quality. In this paper, we study the entity recommendation problem in heterogeneous information networks. Specifically, we propose to combine heterogeneous relationship information for each user differently and aim to provide high-quality personalized recommendation results using user implicit feedback data and personalized recommendation models. In order to take full advantage of the relationship heterogeneity in information networks, we first introduce meta-path-based latent features to represent the connectivity between users and items along different types of paths. We then define recommendation models at both global and personalized levels and use Bayesian ranking optimization techniques to estimate the proposed models. Empirical studies show that our approaches outperform several widely employed or the state-of-the-art entity recommendation techniques."
            },
            "slug": "Personalized-entity-recommendation:-a-heterogeneous-Yu-Ren",
            "title": {
                "fragments": [],
                "text": "Personalized entity recommendation: a heterogeneous information network approach"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This paper proposes to combine heterogeneous relationship information for each user differently and aim to provide high-quality personalized recommendation results using user implicit feedback data and personalized recommendation models."
            },
            "venue": {
                "fragments": [],
                "text": "WSDM"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2271808"
                        ],
                        "name": "Bryan Perozzi",
                        "slug": "Bryan-Perozzi",
                        "structuredName": {
                            "firstName": "Bryan",
                            "lastName": "Perozzi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bryan Perozzi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1388360943"
                        ],
                        "name": "Rami Al-Rfou",
                        "slug": "Rami-Al-Rfou",
                        "structuredName": {
                            "firstName": "Rami",
                            "lastName": "Al-Rfou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Rami Al-Rfou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1721948"
                        ],
                        "name": "S. Skiena",
                        "slug": "S.-Skiena",
                        "structuredName": {
                            "firstName": "Steven",
                            "lastName": "Skiena",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Skiena"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 55,
                                "start": 51
                            }
                        ],
                        "text": "The most recent work related with ours is DeepWalk [16], which deploys a truncated random walk for social network embedding."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 96,
                                "start": 92
                            }
                        ],
                        "text": "The Flickr network is denser than the Youtube network (the same network as used in DeepWalk [16])."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 75,
                                "start": 71
                            }
                        ],
                        "text": "For other networks, the dimension is set as 128 by default, as used in [16]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 3051291,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fff114cbba4f3ba900f33da574283e3de7f26c83",
            "isKey": true,
            "numCitedBy": 5973,
            "numCiting": 55,
            "paperAbstract": {
                "fragments": [],
                "text": "We present DeepWalk, a novel approach for learning latent representations of vertices in a network. These latent representations encode social relations in a continuous vector space, which is easily exploited by statistical models. DeepWalk generalizes recent advancements in language modeling and unsupervised feature learning (or deep learning) from sequences of words to graphs. DeepWalk uses local information obtained from truncated random walks to learn latent representations by treating walks as the equivalent of sentences. We demonstrate DeepWalk's latent representations on several multi-label network classification tasks for social networks such as BlogCatalog, Flickr, and YouTube. Our results show that DeepWalk outperforms challenging baselines which are allowed a global view of the network, especially in the presence of missing information. DeepWalk's representations can provide F1 scores up to 10% higher than competing methods when labeled data is sparse. In some experiments, DeepWalk's representations are able to outperform all baseline methods while using 60% less training data. DeepWalk is also scalable. It is an online learning algorithm which builds useful incremental results, and is trivially parallelizable. These qualities make it suitable for a broad class of real world applications such as network classification, and anomaly detection."
            },
            "slug": "DeepWalk:-online-learning-of-social-representations-Perozzi-Al-Rfou",
            "title": {
                "fragments": [],
                "text": "DeepWalk: online learning of social representations"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "DeepWalk is an online learning algorithm which builds useful incremental results, and is trivially parallelizable, which make it suitable for a broad class of real world applications such as network classification, and anomaly detection."
            },
            "venue": {
                "fragments": [],
                "text": "KDD"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1738297"
                        ],
                        "name": "Smriti Bhagat",
                        "slug": "Smriti-Bhagat",
                        "structuredName": {
                            "firstName": "Smriti",
                            "lastName": "Bhagat",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Smriti Bhagat"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1709589"
                        ],
                        "name": "Graham Cormode",
                        "slug": "Graham-Cormode",
                        "structuredName": {
                            "firstName": "Graham",
                            "lastName": "Cormode",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Graham Cormode"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144963537"
                        ],
                        "name": "S. Muthukrishnan",
                        "slug": "S.-Muthukrishnan",
                        "structuredName": {
                            "firstName": "S.",
                            "lastName": "Muthukrishnan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Muthukrishnan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 128,
                                "start": 125
                            }
                        ],
                        "text": "Such a low-dimensional embedding is very useful in a variety of applications such as visualization [21], node classification [3], link prediction [10], and recommendation [23]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 100,
                                "start": 94
                            }
                        ],
                        "text": "We categorize the vertices into different groups according to their degrees including (0, 1], [2, 3], [4, 6], [7, 12], [13, 30], [31,+\u221e), and then evaluate the performance of vertices in different groups."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 7490480,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6e45220c1f3a8a8cbf176a2fc722c7e8380d5dd4",
            "isKey": false,
            "numCitedBy": 396,
            "numCiting": 55,
            "paperAbstract": {
                "fragments": [],
                "text": "When dealing with large graphs, such as those that arise in the context of online social networks, a subset of nodes may be labeled. These labels can indicate demographic values, interest, beliefs or other characteristics of the nodes (users). A core problem is to use this information to extend the labeling so that all nodes are assigned a label (or labels)."
            },
            "slug": "Node-Classification-in-Social-Networks-Bhagat-Cormode",
            "title": {
                "fragments": [],
                "text": "Node Classification in Social Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 93,
                "text": "When dealing with large graphs, such as those that arise in the context of online social networks, a subset of nodes may be labeled to indicate demographic values, interest, beliefs or other characteristics of the nodes (users)."
            },
            "venue": {
                "fragments": [],
                "text": "Social Network Data Analytics"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39455775"
                        ],
                        "name": "Omer Levy",
                        "slug": "Omer-Levy",
                        "structuredName": {
                            "firstName": "Omer",
                            "lastName": "Levy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Omer Levy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2089067"
                        ],
                        "name": "Yoav Goldberg",
                        "slug": "Yoav-Goldberg",
                        "structuredName": {
                            "firstName": "Yoav",
                            "lastName": "Goldberg",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoav Goldberg"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 212,
                                "start": 209
                            }
                        ],
                        "text": "We also compare with the state-of-the-art word embedding model SkipGram [12], which learns the word embeddings directly from the original Wikipedia pages and is also implicitly a matrix factorization approach [8]."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                }
            ],
            "corpusId": 1190093,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f4c018bcc8ea707b83247866bdc8ccb87cd9f5da",
            "isKey": false,
            "numCitedBy": 1575,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "We analyze skip-gram with negative-sampling (SGNS), a word embedding method introduced by Mikolov et al., and show that it is implicitly factorizing a word-context matrix, whose cells are the pointwise mutual information (PMI) of the respective word and context pairs, shifted by a global constant. We find that another embedding method, NCE, is implicitly factorizing a similar matrix, where each cell is the (shifted) log conditional probability of a word given its context. We show that using a sparse Shifted Positive PMI word-context matrix to represent words improves results on two word similarity tasks and one of two analogy tasks. When dense low-dimensional vectors are preferred, exact factorization with SVD can achieve solutions that are at least as good as SGNS's solutions for word similarity tasks. On analogy questions SGNS remains superior to SVD. We conjecture that this stems from the weighted nature of SGNS's factorization."
            },
            "slug": "Neural-Word-Embedding-as-Implicit-Matrix-Levy-Goldberg",
            "title": {
                "fragments": [],
                "text": "Neural Word Embedding as Implicit Matrix Factorization"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "It is shown that using a sparse Shifted Positive PMI word-context matrix to represent words improves results on two word similarity tasks and one of two analogy tasks, and conjecture that this stems from the weighted nature of SGNS's factorization."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2827616"
                        ],
                        "name": "Quoc V. Le",
                        "slug": "Quoc-V.-Le",
                        "structuredName": {
                            "firstName": "Quoc",
                            "lastName": "Le",
                            "middleNames": [
                                "V."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Quoc V. Le"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2047446108"
                        ],
                        "name": "Tomas Mikolov",
                        "slug": "Tomas-Mikolov",
                        "structuredName": {
                            "firstName": "Tomas",
                            "lastName": "Mikolov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tomas Mikolov"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 66,
                                "start": 63
                            }
                        ],
                        "text": "The readers can find advanced document embedding approaches in [7]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 117,
                                "start": 110
                            }
                        ],
                        "text": "We categorize the vertices into different groups according to their degrees including (0, 1], [2, 3], [4, 6], [7, 12], [13, 30], [31,+\u221e), and then evaluate the performance of vertices in different groups."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2407601,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f527bcfb09f32e6a4a8afc0b37504941c1ba2cee",
            "isKey": false,
            "numCitedBy": 7045,
            "numCiting": 49,
            "paperAbstract": {
                "fragments": [],
                "text": "Many machine learning algorithms require the input to be represented as a fixed-length feature vector. When it comes to texts, one of the most common fixed-length features is bag-of-words. Despite their popularity, bag-of-words features have two major weaknesses: they lose the ordering of the words and they also ignore semantics of the words. For example, \"powerful,\" \"strong\" and \"Paris\" are equally distant. In this paper, we propose Paragraph Vector, an unsupervised algorithm that learns fixed-length feature representations from variable-length pieces of texts, such as sentences, paragraphs, and documents. Our algorithm represents each document by a dense vector which is trained to predict words in the document. Its construction gives our algorithm the potential to overcome the weaknesses of bag-of-words models. Empirical results show that Paragraph Vectors outperforms bag-of-words models as well as other techniques for text representations. Finally, we achieve new state-of-the-art results on several text classification and sentiment analysis tasks."
            },
            "slug": "Distributed-Representations-of-Sentences-and-Le-Mikolov",
            "title": {
                "fragments": [],
                "text": "Distributed Representations of Sentences and Documents"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "Paragraph Vector is an unsupervised algorithm that learns fixed-length feature representations from variable-length pieces of texts, such as sentences, paragraphs, and documents, and its construction gives the algorithm the potential to overcome the weaknesses of bag-of-words models."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31631336"
                        ],
                        "name": "Aaron Q. Li",
                        "slug": "Aaron-Q.-Li",
                        "structuredName": {
                            "firstName": "Aaron",
                            "lastName": "Li",
                            "middleNames": [
                                "Q."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Aaron Q. Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143629707"
                        ],
                        "name": "Amr Ahmed",
                        "slug": "Amr-Ahmed",
                        "structuredName": {
                            "firstName": "Amr",
                            "lastName": "Ahmed",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Amr Ahmed"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35014893"
                        ],
                        "name": "Sujith Ravi",
                        "slug": "Sujith-Ravi",
                        "structuredName": {
                            "firstName": "Sujith",
                            "lastName": "Ravi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sujith Ravi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46234526"
                        ],
                        "name": "Alex Smola",
                        "slug": "Alex-Smola",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Smola",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alex Smola"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 33,
                                "start": 30
                            }
                        ],
                        "text": "We use the alias table method [9] to draw a sample according to the weights of the edges, which takes only O(1) time when repeatedly drawing samples from the same discrete distribution."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 7156173,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ff698613a241aef1f57715eb5a4dfc12a79d1975",
            "isKey": false,
            "numCitedBy": 199,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "Inference in topic models typically involves a sampling step to associate latent variables with observations. Unfortunately the generative model loses sparsity as the amount of data increases, requiring O(k) operations per word for k topics. In this paper we propose an algorithm which scales linearly with the number of actually instantiated topics kd in the document. For large document collections and in structured hierarchical models kd ll k. This yields an order of magnitude speedup. Our method applies to a wide variety of statistical models such as PDP [16,4] and HDP [19]. At its core is the idea that dense, slowly changing distributions can be approximated efficiently by the combination of a Metropolis-Hastings step, use of sparsity, and amortized constant time sampling via Walker's alias method."
            },
            "slug": "Reducing-the-sampling-complexity-of-topic-models-Li-Ahmed",
            "title": {
                "fragments": [],
                "text": "Reducing the sampling complexity of topic models"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "An algorithm which scales linearly with the number of actually instantiated topics kd in the document, for large document collections and in structured hierarchical models kd ll k, yields an order of magnitude speedup."
            },
            "venue": {
                "fragments": [],
                "text": "KDD"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2047446108"
                        ],
                        "name": "Tomas Mikolov",
                        "slug": "Tomas-Mikolov",
                        "structuredName": {
                            "firstName": "Tomas",
                            "lastName": "Mikolov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tomas Mikolov"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1701686"
                        ],
                        "name": "Ilya Sutskever",
                        "slug": "Ilya-Sutskever",
                        "structuredName": {
                            "firstName": "Ilya",
                            "lastName": "Sutskever",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ilya Sutskever"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2118440152"
                        ],
                        "name": "Kai Chen",
                        "slug": "Kai-Chen",
                        "structuredName": {
                            "firstName": "Kai",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kai Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32131713"
                        ],
                        "name": "G. Corrado",
                        "slug": "G.-Corrado",
                        "structuredName": {
                            "firstName": "Gregory",
                            "lastName": "Corrado",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Corrado"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49959210"
                        ],
                        "name": "J. Dean",
                        "slug": "J.-Dean",
                        "structuredName": {
                            "firstName": "Jeffrey",
                            "lastName": "Dean",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Dean"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 84,
                                "start": 80
                            }
                        ],
                        "text": "To address this problem, we adopt the approach of negative sampling proposed in [13], which samples multiple negative edges according to some noisy distribution for each edge (i, j)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 15,
                                "start": 11
                            }
                        ],
                        "text": "Similar to [13], the learning rate is set with the starting value \u03c10 = 0."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 41,
                                "start": 37
                            }
                        ],
                        "text": "We set Pn(v) \u221d dv 3/4 as proposed in [13], where dv is the out-degree of vertex v."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 128,
                                "start": 124
                            }
                        ],
                        "text": "For fair comparisons, the dimensionality of the embeddings of the language network is set to 200, as used in word embedding [13]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 127,
                                "start": 119
                            }
                        ],
                        "text": "We categorize the vertices into different groups according to their degrees including (0, 1], [2, 3], [4, 6], [7, 12], [13, 30], [31,+\u221e), and then evaluate the performance of vertices in different groups."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 16447573,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "87f40e6f3022adbc1f1905e3e506abad05a9964f",
            "isKey": true,
            "numCitedBy": 26055,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "The recently introduced continuous Skip-gram model is an efficient method for learning high-quality distributed vector representations that capture a large number of precise syntactic and semantic word relationships. In this paper we present several extensions that improve both the quality of the vectors and the training speed. By subsampling of the frequent words we obtain significant speedup and also learn more regular word representations. We also describe a simple alternative to the hierarchical softmax called negative sampling. \n \nAn inherent limitation of word representations is their indifference to word order and their inability to represent idiomatic phrases. For example, the meanings of \"Canada\" and \"Air\" cannot be easily combined to obtain \"Air Canada\". Motivated by this example, we present a simple method for finding phrases in text, and show that learning good vector representations for millions of phrases is possible."
            },
            "slug": "Distributed-Representations-of-Words-and-Phrases-Mikolov-Sutskever",
            "title": {
                "fragments": [],
                "text": "Distributed Representations of Words and Phrases and their Compositionality"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "This paper presents a simple method for finding phrases in text, and shows that learning good vector representations for millions of phrases is possible and describes a simple alternative to the hierarchical softmax called negative sampling."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9330607"
                        ],
                        "name": "S. Roweis",
                        "slug": "S.-Roweis",
                        "structuredName": {
                            "firstName": "Sam",
                            "lastName": "Roweis",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Roweis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1796044"
                        ],
                        "name": "L. Saul",
                        "slug": "L.-Saul",
                        "structuredName": {
                            "firstName": "Lawrence",
                            "lastName": "Saul",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Saul"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 88,
                                "start": 85
                            }
                        ],
                        "text": "Because of this importance, many existing graph embedding algorithms such\nas IsoMap, LLE, Laplacian eigenmap, and graph factorization have the objective to preserve the first-order proximity."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 160,
                                "start": 156
                            }
                        ],
                        "text": "Our work is related to classical methods of graph embedding or dimension reduction in general, such as multidimensional scaling (MDS) [4], IsoMap [20], LLE [18] and Laplacian Eigenmap [2]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 5987139,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "afcd6da7637ddeef6715109aca248da7a24b1c65",
            "isKey": false,
            "numCitedBy": 13980,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "Many areas of science depend on exploratory data analysis and visualization. The need to analyze large amounts of multivariate data raises the fundamental problem of dimensionality reduction: how to discover compact representations of high-dimensional data. Here, we introduce locally linear embedding (LLE), an unsupervised learning algorithm that computes low-dimensional, neighborhood-preserving embeddings of high-dimensional inputs. Unlike clustering methods for local dimensionality reduction, LLE maps its inputs into a single global coordinate system of lower dimensionality, and its optimizations do not involve local minima. By exploiting the local symmetries of linear reconstructions, LLE is able to learn the global structure of nonlinear manifolds, such as those generated by images of faces or documents of text."
            },
            "slug": "Nonlinear-dimensionality-reduction-by-locally-Roweis-Saul",
            "title": {
                "fragments": [],
                "text": "Nonlinear dimensionality reduction by locally linear embedding."
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "Locally linear embedding (LLE) is introduced, an unsupervised learning algorithm that computes low-dimensional, neighborhood-preserving embeddings of high-dimensional inputs that learns the global structure of nonlinear manifolds."
            },
            "venue": {
                "fragments": [],
                "text": "Science"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1763295"
                        ],
                        "name": "J. Tenenbaum",
                        "slug": "J.-Tenenbaum",
                        "structuredName": {
                            "firstName": "Joshua",
                            "lastName": "Tenenbaum",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Tenenbaum"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2094778056"
                        ],
                        "name": "V. De Silva",
                        "slug": "V.-De-Silva",
                        "structuredName": {
                            "firstName": "Vin",
                            "lastName": "De Silva",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. De Silva"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46657367"
                        ],
                        "name": "J. Langford",
                        "slug": "J.-Langford",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Langford",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Langford"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 106,
                                "start": 100
                            }
                        ],
                        "text": "Most existing graph embedding algorithms are designed to preserve this first-order proximity, e.g., IsoMap [20] and Laplacian eigenmap [2], even if they do not scale."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 83,
                                "start": 77
                            }
                        ],
                        "text": "Because of this importance, many existing graph embedding algorithms such\nas IsoMap, LLE, Laplacian eigenmap, and graph factorization have the objective to preserve the first-order proximity."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 101,
                                "start": 97
                            }
                        ],
                        "text": "For example, the time complexity of classical graph embedding algorithms such as MDS [4], IsoMap [20], Laplacian eigenmap [2] are at least quadratic to the number of vertices, which is too expensive for networks with millions of nodes."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 84,
                                "start": 78
                            }
                        ],
                        "text": "We do not compare with some classical graph embedding algorithms such as MDS, IsoMap, and Laplacian eigenmap, as they cannot handle networks of this scale."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 13,
                                "start": 9
                            }
                        ],
                        "text": ", IsoMap [20] and Laplacian eigenmap [2], even if they do not scale."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 150,
                                "start": 146
                            }
                        ],
                        "text": "Our work is related to classical methods of graph embedding or dimension reduction in general, such as multidimensional scaling (MDS) [4], IsoMap [20], LLE [18] and Laplacian Eigenmap [2]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 221338160,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3537fcd0ff99a3b3cb3d279012df826358420556",
            "isKey": true,
            "numCitedBy": 12182,
            "numCiting": 61,
            "paperAbstract": {
                "fragments": [],
                "text": "Scientists working with large volumes of high-dimensional data, such as global climate patterns, stellar spectra, or human gene distributions, regularly confront the problem of dimensionality reduction: finding meaningful low-dimensional structures hidden in their high-dimensional observations. The human brain confronts the same problem in everyday perception, extracting from its high-dimensional sensory inputs-30,000 auditory nerve fibers or 10(6) optic nerve fibers-a manageably small number of perceptually relevant features. Here we describe an approach to solving dimensionality reduction problems that uses easily measured local metric information to learn the underlying global geometry of a data set. Unlike classical techniques such as principal component analysis (PCA) and multidimensional scaling (MDS), our approach is capable of discovering the nonlinear degrees of freedom that underlie complex natural observations, such as human handwriting or images of a face under different viewing conditions. In contrast to previous algorithms for nonlinear dimensionality reduction, ours efficiently computes a globally optimal solution, and, for an important class of data manifolds, is guaranteed to converge asymptotically to the true structure."
            },
            "slug": "A-global-geometric-framework-for-nonlinear-Tenenbaum-Silva",
            "title": {
                "fragments": [],
                "text": "A global geometric framework for nonlinear dimensionality reduction."
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "An approach to solving dimensionality reduction problems that uses easily measured local metric information to learn the underlying global geometry of a data set and efficiently computes a globally optimal solution, and is guaranteed to converge asymptotically to the true structure."
            },
            "venue": {
                "fragments": [],
                "text": "Science"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145520115"
                        ],
                        "name": "Mikhail Belkin",
                        "slug": "Mikhail-Belkin",
                        "structuredName": {
                            "firstName": "Mikhail",
                            "lastName": "Belkin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mikhail Belkin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1770745"
                        ],
                        "name": "P. Niyogi",
                        "slug": "P.-Niyogi",
                        "structuredName": {
                            "firstName": "Partha",
                            "lastName": "Niyogi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Niyogi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 187,
                                "start": 184
                            }
                        ],
                        "text": "Our work is related to classical methods of graph embedding or dimension reduction in general, such as multidimensional scaling (MDS) [4], IsoMap [20], LLE [18] and Laplacian Eigenmap [2]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 40,
                                "start": 37
                            }
                        ],
                        "text": ", IsoMap [20] and Laplacian eigenmap [2], even if they do not scale."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 125,
                                "start": 122
                            }
                        ],
                        "text": "For example, the time complexity of classical graph embedding algorithms such as MDS [4], IsoMap [20], Laplacian eigenmap [2] are at least quadratic to the number of vertices, which is too expensive for networks with millions of nodes."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 100,
                                "start": 94
                            }
                        ],
                        "text": "We categorize the vertices into different groups according to their degrees including (0, 1], [2, 3], [4, 6], [7, 12], [13, 30], [31,+\u221e), and then evaluate the performance of vertices in different groups."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 17572432,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "9d16c547d15a08091e68c86a99731b14366e3f0d",
            "isKey": true,
            "numCitedBy": 4244,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "Drawing on the correspondence between the graph Laplacian, the Laplace-Beltrami operator on a manifold, and the connections to the heat equation, we propose a geometrically motivated algorithm for constructing a representation for data sampled from a low dimensional manifold embedded in a higher dimensional space. The algorithm provides a computationally efficient approach to nonlinear dimensionality reduction that has locality preserving properties and a natural connection to clustering. Several applications are considered."
            },
            "slug": "Laplacian-Eigenmaps-and-Spectral-Techniques-for-and-Belkin-Niyogi",
            "title": {
                "fragments": [],
                "text": "Laplacian Eigenmaps and Spectral Techniques for Embedding and Clustering"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "The algorithm provides a computationally efficient approach to nonlinear dimensionality reduction that has locality preserving properties and a natural connection to clustering."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48479130"
                        ],
                        "name": "Lawrence Page",
                        "slug": "Lawrence-Page",
                        "structuredName": {
                            "firstName": "Lawrence",
                            "lastName": "Page",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lawrence Page"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1786259"
                        ],
                        "name": "S. Brin",
                        "slug": "S.-Brin",
                        "structuredName": {
                            "firstName": "Sergey",
                            "lastName": "Brin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Brin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "84095744"
                        ],
                        "name": "R. Motwani",
                        "slug": "R.-Motwani",
                        "structuredName": {
                            "firstName": "Rajeev",
                            "lastName": "Motwani",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Motwani"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1699245"
                        ],
                        "name": "T. Winograd",
                        "slug": "T.-Winograd",
                        "structuredName": {
                            "firstName": "Terry",
                            "lastName": "Winograd",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Winograd"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 252,
                                "start": 248
                            }
                        ],
                        "text": "As the importance of the vertices in the network may be different, we introduce \u03bbi in the objective function to represent the prestige of vertex i in the network, which can be measured by the degree or estimated through algorithms such as PageRank [15]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 246,
                                "start": 238
                            }
                        ],
                        "text": "As the importance of the vertices in the network may be different, we introduce \u03bbi in the objective function to represent\nthe prestige of vertex i in the network, which can be measured by the degree or estimated through algorithms such as PageRank [15]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 1508503,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "eb82d3035849cd23578096462ba419b53198a556",
            "isKey": false,
            "numCitedBy": 14000,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "The importance of a Web page is an inherently subjective matter, which depends on the readers interests, knowledge and attitudes. But there is still much that can be said objectively about the relative importance of Web pages. This paper describes PageRank, a mathod for rating Web pages objectively and mechanically, effectively measuring the human interest and attention devoted to them. We compare PageRank to an idealized random Web surfer. We show how to efficiently compute PageRank for large numbers of pages. And, we show how to apply PageRank to search and to user navigation."
            },
            "slug": "The-PageRank-Citation-Ranking-:-Bringing-Order-to-Page-Brin",
            "title": {
                "fragments": [],
                "text": "The PageRank Citation Ranking : Bringing Order to the Web"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This paper describes PageRank, a mathod for rating Web pages objectively and mechanically, effectively measuring the human interest and attention devoted to them, and shows how to efficiently compute PageRank for large numbers of pages."
            },
            "venue": {
                "fragments": [],
                "text": "WWW 1999"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "5673974"
                        ],
                        "name": "Mark S. Granovetter",
                        "slug": "Mark-S.-Granovetter",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Granovetter",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mark S. Granovetter"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 108,
                                "start": 102
                            }
                        ],
                        "text": "We categorize the vertices into different groups according to their degrees including (0, 1], [2, 3], [4, 6], [7, 12], [13, 30], [31,+\u221e), and then evaluate the performance of vertices in different groups."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 147,
                                "start": 144
                            }
                        ],
                        "text": "For example, \u201cthe degree of overlap of two people\u2019s friendship networks correlates with the strength of ties between them,\u201d in a social network [6]; and \u201cYou shall know a word by the company it keeps\u201d (Firth, J."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 59578641,
            "fieldsOfStudy": [
                "Sociology"
            ],
            "id": "c9aece346139711b8c65c618da99cdbecb162575",
            "isKey": false,
            "numCitedBy": 36691,
            "numCiting": 77,
            "paperAbstract": {
                "fragments": [],
                "text": "Analysis of social networks is suggested as a tool for linking micro and macro levels of sociological theory. The procedure is illustrated by elaboration of the macro implications of one aspect of small-scale interaction: the strength of dyadic ties. It is argued that the degree of overlap of two individuals' friendship networks varies directly with the strength of their tie to one another. The impact of this principle on diffusion of influence and information, mobility opportunity, and community organization is explored. Stress is laid on the cohesive power of weak ties. Most network models deal, implicitly, with strong ties, thus confining their applicability to small, well-defined groups. Emphasis on weak ties lends itself to discussion of relations between groups and to analysis of segments of social structure not easily defined in terms of primary groups."
            },
            "slug": "The-Strength-of-Weak-Ties-Granovetter",
            "title": {
                "fragments": [],
                "text": "The Strength of Weak Ties"
            },
            "venue": {
                "fragments": [],
                "text": "American Journal of Sociology"
            },
            "year": 1973
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2839864"
                        ],
                        "name": "Michael C. Hout",
                        "slug": "Michael-C.-Hout",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Hout",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael C. Hout"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3928946"
                        ],
                        "name": "Megan H Papesh",
                        "slug": "Megan-H-Papesh",
                        "structuredName": {
                            "firstName": "Megan",
                            "lastName": "Papesh",
                            "middleNames": [
                                "H"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Megan H Papesh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34952963"
                        ],
                        "name": "S. Goldinger",
                        "slug": "S.-Goldinger",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Goldinger",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Goldinger"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 137,
                                "start": 134
                            }
                        ],
                        "text": "Our work is related to classical methods of graph embedding or dimension reduction in general, such as multidimensional scaling (MDS) [4], IsoMap [20], LLE [18] and Laplacian Eigenmap [2]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 76,
                                "start": 73
                            }
                        ],
                        "text": "We do not compare with some classical graph embedding algorithms such as MDS, IsoMap, and Laplacian eigenmap, as they cannot handle networks of this scale."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 88,
                                "start": 85
                            }
                        ],
                        "text": "For example, the time complexity of classical graph embedding algorithms such as MDS [4], IsoMap [20], Laplacian eigenmap [2] are at least quadratic to the number of vertices, which is too expensive for networks with millions of nodes."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 108,
                                "start": 102
                            }
                        ],
                        "text": "We categorize the vertices into different groups according to their degrees including (0, 1], [2, 3], [4, 6], [7, 12], [13, 30], [31,+\u221e), and then evaluate the performance of vertices in different groups."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1015584,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a1fa5b4988666cd9fa7c19267ead83f61231c33d",
            "isKey": true,
            "numCitedBy": 2804,
            "numCiting": 68,
            "paperAbstract": {
                "fragments": [],
                "text": "The concept of similarity, or a sense of 'sameness' among things, is pivotal to theories in the cognitive sciences and beyond. Similarity, however, is a difficult thing to measure. Multidimensional scaling (MDS) is a tool by which researchers can obtain quantitative estimates of similarity among groups of items. More formally, MDS refers to a set of statistical techniques that are used to reduce the complexity of a data set, permitting visual appreciation of the underlying relational structures contained therein. The current paper provides an overview of MDS. We discuss key aspects of performing this technique, such as methods that can be used to collect similarity estimates, analytic techniques for treating proximity data, and various concerns regarding interpretation of the MDS output. MDS analyses of two novel data sets are also included, highlighting in step-by-step fashion how MDS is performed, and key issues that may arise during analysis. WIREs Cogn Sci 2013, 4:93-103. doi: 10.1002/wcs.1203 This article is categorized under: Psychology > Perception and Psychophysics."
            },
            "slug": "Multidimensional-scaling.-Hout-Papesh",
            "title": {
                "fragments": [],
                "text": "Multidimensional scaling."
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "Key aspects of performing MDS are discussed, such as methods that can be used to collect similarity estimates, analytic techniques for treating proximity data, and various concerns regarding interpretation of the MDS output."
            },
            "venue": {
                "fragments": [],
                "text": "Wiley interdisciplinary reviews. Cognitive science"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2047446108"
                        ],
                        "name": "Tomas Mikolov",
                        "slug": "Tomas-Mikolov",
                        "structuredName": {
                            "firstName": "Tomas",
                            "lastName": "Mikolov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tomas Mikolov"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2118440152"
                        ],
                        "name": "Kai Chen",
                        "slug": "Kai-Chen",
                        "structuredName": {
                            "firstName": "Kai",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kai Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32131713"
                        ],
                        "name": "G. Corrado",
                        "slug": "G.-Corrado",
                        "structuredName": {
                            "firstName": "Gregory",
                            "lastName": "Corrado",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Corrado"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49959210"
                        ],
                        "name": "J. Dean",
                        "slug": "J.-Dean",
                        "structuredName": {
                            "firstName": "Jeffrey",
                            "lastName": "Dean",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Dean"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 116,
                                "start": 108
                            }
                        ],
                        "text": "Table 2 reports the results of word analogy using the embeddings of words learned on the Wikipedia corpora (SkipGram) or the Wikipedia word network (all other methods)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 111,
                                "start": 103
                            }
                        ],
                        "text": "We can see that LINE(2nd) outperforms all other methods, including the graph embedding methods and the SkipGram."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 100,
                                "start": 96
                            }
                        ],
                        "text": "Two applications are used to evaluate the effectiveness of the learned embeddings: word analogy [12] and document classification."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 117,
                                "start": 110
                            }
                        ],
                        "text": "We categorize the vertices into different groups according to their degrees including (0, 1], [2, 3], [4, 6], [7, 12], [13, 30], [31,+\u221e), and then evaluate the performance of vertices in different groups."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 76,
                                "start": 72
                            }
                        ],
                        "text": "We also compare with the state-of-the-art word embedding model SkipGram [12], which learns the word embeddings directly from the original Wikipedia pages and is also implicitly a matrix factorization approach [8]."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                }
            ],
            "corpusId": 5959482,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "330da625c15427c6e42ccfa3b747fb29e5835bf0",
            "isKey": true,
            "numCitedBy": 21889,
            "numCiting": 43,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose two novel model architectures for computing continuous vector\nrepresentations of words from very large data sets. The quality of these\nrepresentations is measured in a word similarity task, and the results are\ncompared to the previously best performing techniques based on different types\nof neural networks. We observe large improvements in accuracy at much lower\ncomputational cost, i.e. it takes less than a day to learn high quality word\nvectors from a 1.6 billion words data set. Furthermore, we show that these\nvectors provide state-of-the-art performance on our test set for measuring\nsyntactic and semantic word similarities."
            },
            "slug": "Efficient-Estimation-of-Word-Representations-in-Mikolov-Chen",
            "title": {
                "fragments": [],
                "text": "Efficient Estimation of Word Representations in Vector Space"
            },
            "tldr": {
                "abstractSimilarityScore": 65,
                "text": "Two novel model architectures for computing continuous vector representations of words from very large data sets are proposed and it is shown that these vectors provide state-of-the-art performance on the authors' test set for measuring syntactic and semantic word similarities."
            },
            "venue": {
                "fragments": [],
                "text": "ICLR"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9229182"
                        ],
                        "name": "B. Recht",
                        "slug": "B.-Recht",
                        "structuredName": {
                            "firstName": "Benjamin",
                            "lastName": "Recht",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Recht"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1803218"
                        ],
                        "name": "Christopher R\u00e9",
                        "slug": "Christopher-R\u00e9",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "R\u00e9",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christopher R\u00e9"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144731788"
                        ],
                        "name": "Stephen J. Wright",
                        "slug": "Stephen-J.-Wright",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Wright",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Stephen J. Wright"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47657030"
                        ],
                        "name": "Feng Niu",
                        "slug": "Feng-Niu",
                        "structuredName": {
                            "firstName": "Feng",
                            "lastName": "Niu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Feng Niu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6108215,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "36f49b05d764bf5c10428b082c2d96c13c4203b9",
            "isKey": false,
            "numCitedBy": 2018,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "Stochastic Gradient Descent (SGD) is a popular algorithm that can achieve state-of-the-art performance on a variety of machine learning tasks. Several researchers have recently proposed schemes to parallelize SGD, but all require performance-destroying memory locking and synchronization. This work aims to show using novel theoretical analysis, algorithms, and implementation that SGD can be implemented without any locking. We present an update scheme called HOGWILD! which allows processors access to shared memory with the possibility of overwriting each other's work. We show that when the associated optimization problem is sparse, meaning most gradient updates only modify small parts of the decision variable, then HOGWILD! achieves a nearly optimal rate of convergence. We demonstrate experimentally that HOGWILD! outperforms alternative schemes that use locking by an order of magnitude."
            },
            "slug": "Hogwild:-A-Lock-Free-Approach-to-Parallelizing-Recht-R\u00e9",
            "title": {
                "fragments": [],
                "text": "Hogwild: A Lock-Free Approach to Parallelizing Stochastic Gradient Descent"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This work aims to show using novel theoretical analysis, algorithms, and implementation that SGD can be implemented without any locking, and presents an update scheme called HOGWILD! which allows processors access to shared memory with the possibility of overwriting each other's work."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1803434"
                        ],
                        "name": "R. Larson",
                        "slug": "R.-Larson",
                        "structuredName": {
                            "firstName": "Ray",
                            "lastName": "Larson",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Larson"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 63,
                                "start": 59
                            }
                        ],
                        "text": "We report the classification metrics Micro-F1 and Macro-F1 [11]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 32493971,
            "fieldsOfStudy": [
                "Computer Science",
                "Environmental Science",
                "Psychology"
            ],
            "id": "5f3b50c6c826ad105163b09d53e1eb498a4b3994",
            "isKey": false,
            "numCitedBy": 7737,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Introduction To Information Retrieval Overdrive Digital. Introduction To Information Retrieval. Introduction To Information Retrieval Putao Ufcg. Introduction To Information Retrieval Arbeitsbereiche. Introduction To Information Retrieval. Introduction To Information Retrieval Stanford Nlp Group. Introduction To Information Retrieval Cs Ucr Edu. Introduction To Information Retrieval By Christopher D. Introduction To Information Retrieval Book. Information Retrieval The Mit Press. Introduction Information Retrieval Uvm. Information Retrieval Lmu Munich. Introduction To Information Retrieval Stanford University. Introduction To Information Retrieval. Introduction To Information Retrieval Amp Models Slideshare. Introduction To Information Retrieval Kangwon Ac Kr. Information Retrieval. Introduction To Information Retrieval Assets. Introduction To Information Retrieval. Introduction To Information Retrieval"
            },
            "slug": "Introduction-to-Information-Retrieval-Larson",
            "title": {
                "fragments": [],
                "text": "Introduction to Information Retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 56,
                "text": "This chapter discusses Information Retrieval, the science and technology behind information retrieval and retrieval, and some of the techniques used in the retrieval of information."
            },
            "venue": {
                "fragments": [],
                "text": "J. Assoc. Inf. Sci. Technol."
            },
            "year": 2010
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "corpusId": 208875690,
            "fieldsOfStudy": [
                "Medicine"
            ],
            "id": "8cf24826e5bbe8e9e3161bdb98c0523b3ace5443",
            "isKey": false,
            "numCitedBy": 25208,
            "numCiting": 68,
            "paperAbstract": {
                "fragments": [],
                "text": "11. Brunck W: Die systematische untersuchung des sprachorgans bei angeborenen gaumendefekte. Diss Leipiz 1906 (from Meissner). 12. Commichau G, Oeken FW: Pneumatisationsverhaitnisse bel gaumenspaltentragem. HNO (Bed) 7:73-75, 1958 13. Compere WE, Jr: Tympanic cavity clearance studies. Trans AAOO 62:444-454, 1958 14. Compere WE, Jr: The radiologic evaluation of eustachian tube function. AMA Arch Otolaryngol 7 :386-389, 1960 15. Day KM: Management of deafness: Wherry Memorial Lecture. Trans AAOO 55: 22, 1950 16. Donaldson JA: The role of artificial Eustachian tube in cleft palate patients. Cleft Palate J 61-66, 1966 17. Drettner B: The nasal air way and hearing in patients with cleft palate. Acta Otolaryng 52: 131-142, 1960 18. Duncan RB: Positional otitis media. Arch Otolaryng 72:455-463, 1960"
            },
            "slug": "References",
            "title": {
                "fragments": [],
                "text": "References"
            },
            "tldr": {
                "abstractSimilarityScore": 83,
                "text": "11. Brunck W: Die systematische untersuchung des sprachorgans bei angeborenen gaumendefekte ist wirklich ein wirkliches Problem gegen \u00e2\u201a\u00ac\u201d Pneumatisationsverhaitnisse bel gaumenspaltentragem."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1971
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "ACM 978-1-4503-3469-3/15/05. http://dx.doi.org/10.1145/2736277.2741093."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A synopsis of linguistic theory"
            },
            "venue": {
                "fragments": [],
                "text": "Studies in linguistic analysis"
            },
            "year": 1930
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144191879"
                        ],
                        "name": "J. Firth",
                        "slug": "J.-Firth",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Firth",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Firth"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "1957:11) in text corpora [5]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 208093066,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "88b3959b6f5333e5358eac43970a5fa29b54642c",
            "isKey": false,
            "numCitedBy": 1923,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-Synopsis-of-Linguistic-Theory,-1930-1955-Firth",
            "title": {
                "fragments": [],
                "text": "A Synopsis of Linguistic Theory, 1930-1955"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1957
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A lock - free approach to parallelizing stochastic gradient descent"
            },
            "venue": {
                "fragments": [],
                "text": "Advances in Neural Information Processing Systems"
            },
            "year": 2011
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 12,
            "methodology": 17,
            "result": 2
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 26,
        "totalPages": 3
    },
    "page_url": "https://www.semanticscholar.org/paper/LINE:-Large-scale-Information-Network-Embedding-Tang-Qu/0834e74304b547c9354b6d7da6fa78ef47a48fa8?sort=total-citations"
}