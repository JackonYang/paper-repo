{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34699434"
                        ],
                        "name": "A. Ng",
                        "slug": "A.-Ng",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Ng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Ng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694621"
                        ],
                        "name": "Michael I. Jordan",
                        "slug": "Michael-I.-Jordan",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Jordan",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael I. Jordan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "30400079"
                        ],
                        "name": "Yair Weiss",
                        "slug": "Yair-Weiss",
                        "structuredName": {
                            "firstName": "Yair",
                            "lastName": "Weiss",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yair Weiss"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 18764978,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c02dfd94b11933093c797c362e2f8f6a3b9b8012",
            "isKey": false,
            "numCitedBy": 8412,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "Despite many empirical successes of spectral clustering methods\u2014 algorithms that cluster points using eigenvectors of matrices derived from the data\u2014there are several unresolved issues. First. there are a wide variety of algorithms that use the eigenvectors in slightly different ways. Second, many of these algorithms have no proof that they will actually compute a reasonable clustering. In this paper, we present a simple spectral clustering algorithm that can be implemented using a few lines of Matlab. Using tools from matrix perturbation theory, we analyze the algorithm, and give conditions under which it can be expected to do well. We also show surprisingly good experimental results on a number of challenging clustering problems."
            },
            "slug": "On-Spectral-Clustering:-Analysis-and-an-algorithm-Ng-Jordan",
            "title": {
                "fragments": [],
                "text": "On Spectral Clustering: Analysis and an algorithm"
            },
            "tldr": {
                "abstractSimilarityScore": 50,
                "text": "A simple spectral clustering algorithm that can be implemented using a few lines of Matlab is presented, and tools from matrix perturbation theory are used to analyze the algorithm, and give conditions under which it can be expected to do well."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1728654"
                        ],
                        "name": "U. V. Luxburg",
                        "slug": "U.-V.-Luxburg",
                        "structuredName": {
                            "firstName": "Ulrike",
                            "lastName": "Luxburg",
                            "middleNames": [
                                "von"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "U. V. Luxburg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1698617"
                        ],
                        "name": "O. Bousquet",
                        "slug": "O.-Bousquet",
                        "structuredName": {
                            "firstName": "Olivier",
                            "lastName": "Bousquet",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Bousquet"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145520115"
                        ],
                        "name": "Mikhail Belkin",
                        "slug": "Mikhail-Belkin",
                        "structuredName": {
                            "firstName": "Mikhail",
                            "lastName": "Belkin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mikhail Belkin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 221,
                                "start": 197
                            }
                        ],
                        "text": "It can be proved that unnormalized spectral clustering can fail to converge, or that it can converge to trivial solutions which construct clusters consisting of one single point of the data space (von Luxburg et al., 2005, to appear)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 144,
                                "start": 99
                            }
                        ],
                        "text": "For both normalized spectral clustering algorithms, it can be proved that this is indeed the case (von Luxburg, Bousquet, and Belkin, 2004, 2005; von Luxburg, Belkin, and Bousquet, to appear)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 356393,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "32b21a53f527c8ed00f28006df5285164d830912",
            "isKey": false,
            "numCitedBy": 122,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "An important aspect of clustering algorithms is whether the partitions constructed on finite samples converge to a useful clustering of the whole data space as the sample size increases. This paper investigates this question for normalized and unnormalized versions of the popular spectral clustering algorithm. Surprisingly, the convergence of unnormalized spectral clustering is more difficult to handle than the normalized case. Even though recently some first results on the convergence of normalized spectral clustering have been obtained, for the unnormalized case we have to develop a completely new approach combining tools from numerical integration, spectral and perturbation theory, and probability. It turns out that while in the normalized case, spectral clustering usually converges to a nice partition of the data space, in the unnormalized case the same only holds under strong additional assumptions which are not always satisfied. We conclude that our analysis gives strong evidence for the superiority of normalized spectral clustering. It also provides a basis for future exploration of other Laplacian-based methods."
            },
            "slug": "Limits-of-Spectral-Clustering-Luxburg-Bousquet",
            "title": {
                "fragments": [],
                "text": "Limits of Spectral Clustering"
            },
            "tldr": {
                "abstractSimilarityScore": 66,
                "text": "This paper investigates whether the partitions constructed on finite samples converge to a useful clustering of the whole data space as the sample size increases and concludes that while in the normalized case, spectral clustering usually converges to a nice partition of the data space, in the unnormalized case the same only holds under strong additional assumptions which are not always satisfied."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1728654"
                        ],
                        "name": "U. V. Luxburg",
                        "slug": "U.-V.-Luxburg",
                        "structuredName": {
                            "firstName": "Ulrike",
                            "lastName": "Luxburg",
                            "middleNames": [
                                "von"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "U. V. Luxburg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145520115"
                        ],
                        "name": "Mikhail Belkin",
                        "slug": "Mikhail-Belkin",
                        "structuredName": {
                            "firstName": "Mikhail",
                            "lastName": "Belkin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mikhail Belkin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1698617"
                        ],
                        "name": "O. Bousquet",
                        "slug": "O.-Bousquet",
                        "structuredName": {
                            "firstName": "Olivier",
                            "lastName": "Bousquet",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Bousquet"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 232,
                                "start": 208
                            }
                        ],
                        "text": "That is, if we consider a diffusion process on the data space X , then the partition induced by the eigenvectors of U is such that the diffusion does not transition between the different clusters very often (von Luxburg et al., 2004)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 88517984,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6214fc0672de4ccfce1cef8b2d1875e6ea7a3db7",
            "isKey": false,
            "numCitedBy": 540,
            "numCiting": 56,
            "paperAbstract": {
                "fragments": [],
                "text": "Consistency is a key property of all statistical procedures analyzing randomly sampled data. Surprisingly, despite decades of work, little is known about consistency of most clustering algorithms. In this paper we investigate consistency of the popular family of spectral clustering algorithms, which clusters the data with the help of eigenvectors of graph Laplacian matrices. We develop new methods to establish that, for increasing sample size, those eigenvectors converge to the eigenvectors of certain limit operators. As a result, we can prove that one of the two major classes of spectral clustering (normalized clustering) converges under very general conditions, while the other (unnormalized clustering) is only consistent under strong additional assumptions, which are not always satisfied in real data. We conclude that our analysis provides strong evidence for the superiority of normalized spectral clustering."
            },
            "slug": "Consistency-of-spectral-clustering-Luxburg-Belkin",
            "title": {
                "fragments": [],
                "text": "Consistency of spectral clustering"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "It is proved that one of the two major classes of spectral clustering (normalized clustering) converges under very general conditions, while the other is only consistent under strong additional assumptions, which are not always satisfied in real data."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144570279"
                        ],
                        "name": "F. Bach",
                        "slug": "F.-Bach",
                        "structuredName": {
                            "firstName": "Francis",
                            "lastName": "Bach",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Bach"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694621"
                        ],
                        "name": "Michael I. Jordan",
                        "slug": "Michael-I.-Jordan",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Jordan",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael I. Jordan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 23,
                                "start": 0
                            }
                        ],
                        "text": "Bach and Jordan (2004) use a more advanced post-processing of the eigenvectors."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 89,
                                "start": 76
                            }
                        ],
                        "text": "A more advanced post-processing of the eigenvectors is proposed in Bach and Jordan (2004)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 356,
                                "start": 333
                            }
                        ],
                        "text": "As examples consider spectral clustering applied to the co-clustering problem (Dhillon, 2001), spectral clustering with additional side information (Joachims, 2003) connections between spectral clustering and the weighted k-means algorithm (Dhillon, Guan, and Kulis, 2005), learning similarity functions based on spectral clustering (Bach and Jordan, 2004), an average case analysis of spectral clustering (McSherry, 2001), or spectral clustering in a distributed environment (Kempe and McSherry, 2004)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 215,
                                "start": 203
                            }
                        ],
                        "text": "\u2026(Joachims, 2003) connections between spectral clustering and the weighted kernel-k-means algorithm (Dhillon, Guan, and Kulis, 2005), learning similarity functions based on spectral clustering (Bach and Jordan, 2004), or spectral clustering in a distributed environment (Kempe and McSherry, 2004)."
                    },
                    "intents": []
                }
            ],
            "corpusId": 5178437,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "32fad9f3b7ab236f326d6927c2965a01118e8e93",
            "isKey": true,
            "numCitedBy": 488,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "Spectral clustering refers to a class of techniques which rely on the eigen-structure of a similarity matrix to partition points into disjoint clusters with points in the same cluster having high similarity and points in different clusters having low similarity. In this paper, we derive a new cost function for spectral clustering based on a measure of error between a given partition and a solution of the spectral relaxation of a minimum normalized cut problem. Minimizing this cost function with respect to the partition leads to a new spectral clustering algorithm. Minimizing with respect to the similarity matrix leads to an algorithm for learning the similarity matrix. We develop a tractable approximation of our cost function that is based on the power method of computing eigenvectors."
            },
            "slug": "Learning-Spectral-Clustering-Bach-Jordan",
            "title": {
                "fragments": [],
                "text": "Learning Spectral Clustering"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A new cost function for spectral clustering is derived based on a measure of error between a given partition and a solution of the spectral relaxation of a minimum normalized cut problem."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1728654"
                        ],
                        "name": "U. V. Luxburg",
                        "slug": "U.-V.-Luxburg",
                        "structuredName": {
                            "firstName": "Ulrike",
                            "lastName": "Luxburg",
                            "middleNames": [
                                "von"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "U. V. Luxburg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1698617"
                        ],
                        "name": "O. Bousquet",
                        "slug": "O.-Bousquet",
                        "structuredName": {
                            "firstName": "Olivier",
                            "lastName": "Bousquet",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Bousquet"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145520115"
                        ],
                        "name": "Mikhail Belkin",
                        "slug": "Mikhail-Belkin",
                        "structuredName": {
                            "firstName": "Mikhail",
                            "lastName": "Belkin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mikhail Belkin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 232,
                                "start": 208
                            }
                        ],
                        "text": "That is, if we consider a diffusion process on the data space X , then the partition induced by the eigenvectors of U is such that the diffusion does not transition between the different clusters very often (von Luxburg et al., 2004)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 144,
                                "start": 99
                            }
                        ],
                        "text": "For both normalized spectral clustering algorithms, it can be proved that this is indeed the case (von Luxburg, Bousquet, and Belkin, 2004, 2005; von Luxburg, Belkin, and Bousquet, to appear)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 10728665,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "7c8a8bdaa61e118e4f406a123ee90255ed1e44c2",
            "isKey": false,
            "numCitedBy": 51,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "Given a set of n randomly drawn sample points, spectral clustering in its simplest form uses the second eigenvector of the graph Laplacian matrix, constructed on the similarity graph between the sample points, to obtain a partition of the sample. We are interested in the question how spectral clustering behaves for growing sample size n. In case one uses the normalized graph Laplacian, we show that spectral clustering usually converges to an intuitively appealing limit partition of the data space. We argue that in case of the unnormalized graph Laplacian, equally strong convergence results are difficult to obtain."
            },
            "slug": "On-the-Convergence-of-Spectral-Clustering-on-Random-Luxburg-Bousquet",
            "title": {
                "fragments": [],
                "text": "On the Convergence of Spectral Clustering on Random Samples: The Normalized Case"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "It is shown that spectral clustering usually converges to an intuitively appealing limit partition of the data space and argues that in case of the unnormalized graph Laplacian, equally strong convergence results are difficult to obtain."
            },
            "venue": {
                "fragments": [],
                "text": "COLT"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1783667"
                        ],
                        "name": "I. Dhillon",
                        "slug": "I.-Dhillon",
                        "structuredName": {
                            "firstName": "Inderjit",
                            "lastName": "Dhillon",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Dhillon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1853389"
                        ],
                        "name": "Yuqiang Guan",
                        "slug": "Yuqiang-Guan",
                        "structuredName": {
                            "firstName": "Yuqiang",
                            "lastName": "Guan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yuqiang Guan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1692670"
                        ],
                        "name": "B. Kulis",
                        "slug": "B.-Kulis",
                        "structuredName": {
                            "firstName": "Brian",
                            "lastName": "Kulis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Kulis"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1018454,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8faad7901db9a73cacaf92ecdedbaece87d95f92",
            "isKey": false,
            "numCitedBy": 1194,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "Kernel k-means and spectral clustering have both been used to identify clusters that are non-linearly separable in input space. Despite significant research, these methods have remained only loosely related. In this paper, we give an explicit theoretical connection between them. We show the generality of the weighted kernel k-means objective function, and derive the spectral clustering objective of normalized cut as a special case. Given a positive definite similarity matrix, our results lead to a novel weighted kernel k-means algorithm that monotonically decreases the normalized cut. This has important implications: a) eigenvector-based algorithms, which can be computationally prohibitive, are not essential for minimizing normalized cuts, b) various techniques, such as local search and acceleration schemes, may be used to improve the quality as well as speed of kernel k-means. Finally, we present results on several interesting data sets, including diametrical clustering of large gene-expression matrices and a handwriting recognition data set."
            },
            "slug": "Kernel-k-means:-spectral-clustering-and-normalized-Dhillon-Guan",
            "title": {
                "fragments": [],
                "text": "Kernel k-means: spectral clustering and normalized cuts"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "The generality of the weighted kernel k-means objective function is shown, and the spectral clustering objective of normalized cut is derived as a special case, leading to a novel weightedkernel k-Means algorithm that monotonically decreases the normalized cut."
            },
            "venue": {
                "fragments": [],
                "text": "KDD"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1783667"
                        ],
                        "name": "I. Dhillon",
                        "slug": "I.-Dhillon",
                        "structuredName": {
                            "firstName": "Inderjit",
                            "lastName": "Dhillon",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Dhillon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1853389"
                        ],
                        "name": "Yuqiang Guan",
                        "slug": "Yuqiang-Guan",
                        "structuredName": {
                            "firstName": "Yuqiang",
                            "lastName": "Guan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yuqiang Guan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1692670"
                        ],
                        "name": "B. Kulis",
                        "slug": "B.-Kulis",
                        "structuredName": {
                            "firstName": "Brian",
                            "lastName": "Kulis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Kulis"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 76,
                                "start": 18
                            }
                        ],
                        "text": "For background reading on random walks in general we refer to Norris (1997) and Br\u00e9maud (1999), and for random walks on graphs we recommend Aldous and Fill (in preparation) and Lov\u00e1sz (1993)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 114,
                                "start": 93
                            }
                        ],
                        "text": "A link between spectral clustering and the weighted kernel k-means algorithm is described in Dhillon et al. (2005)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 175,
                                "start": 145
                            }
                        ],
                        "text": "\u2026clustering with additional side information (Joachims, 2003) connections between spectral clustering and the weighted kernel-k-means algorithm (Dhillon, Guan, and Kulis, 2005), learning similarity functions based on spectral clustering (Bach and Jordan, 2004), or spectral clustering in a\u2026"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 116,
                                "start": 63
                            }
                        ],
                        "text": "We state those results for completeness, but for background reading we refer to Section V of Stewart and Sun (1990) and Section VII."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 6317467,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0f28993f09606a3e3f6c5c9b6d17138f27d85069",
            "isKey": true,
            "numCitedBy": 181,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "Recently, a variety of clustering algorithms have been proposed to handle data that is not linearly separable. Spectral clustering and kernel k -means are two such methods that are seemingly quite different. In this paper, we show that a general weighted kernel k -means objective is mathematically equivalent to a weighted graph partitioning objective. Special cases of this graph partitioning objective include ratio cut, normalized cut and ratio association. Our equivalence has important consequences: the weighted kernel k -means algorithm may be used to directly optimize the graph partitioning objectives, and conversely, spectral methods may be used to optimize the weighted kernel k -means objective. Hence, in cases where eigenvector computation is prohibitive, we eliminate the need for any eigenvector computation for graph partitioning. Moreover, we show that the Kernighan-Lin objective can also be incorporated into our framework, leading to an incremental weighted kernel k -means algorithm for local optimization of the objective. We further discuss the issue of convergence of weighted kernel k -means for an arbitrary graph affinity matrix and provide a number of experimental results. These results show that non-spectral methods for graph partitioning are as effective as spectral methods and can be used for problems such as image segmentation in addition to data clustering."
            },
            "slug": "A-Unified-View-of-Kernel-k-means-,-Spectral-and-Dhillon-Guan",
            "title": {
                "fragments": [],
                "text": "A Unified View of Kernel k-means , Spectral Clustering and Graph Cuts"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "Results show that non-spectral methods for graph partitioning are as effective as spectral methods and can be used for problems such as image segmentation in addition to data clustering."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1401829700"
                        ],
                        "name": "Shai Ben-David",
                        "slug": "Shai-Ben-David",
                        "structuredName": {
                            "firstName": "Shai",
                            "lastName": "Ben-David",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shai Ben-David"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1728654"
                        ],
                        "name": "U. V. Luxburg",
                        "slug": "U.-V.-Luxburg",
                        "structuredName": {
                            "firstName": "Ulrike",
                            "lastName": "Luxburg",
                            "middleNames": [
                                "von"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "U. V. Luxburg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2153912"
                        ],
                        "name": "D. P\u00e1l",
                        "slug": "D.-P\u00e1l",
                        "structuredName": {
                            "firstName": "D\u00e1vid",
                            "lastName": "P\u00e1l",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. P\u00e1l"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 12275146,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "95934f766b45e50076015a4283b5e2d4109312b9",
            "isKey": false,
            "numCitedBy": 223,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract. Stability is a common tool to verify the validity of sample based algorithms. In clustering it is widely used to tune the parameters of the algorithm, such as the number k of clusters. In spite of the popularity of stability in practical applications, there has been very little theoretical analysis of this notion. In this paper we provide a formal definition of stability and analyze some of its basic properties. Quite surprisingly, the conclusion of our analysis is that for large sample size, stability is fully determined by the behavior of the objective function which the clustering algorithm is aiming to minimize. If the objective function has a unique global minimizer, the algorithm is stable, otherwise it is unstable. In particular we conclude that stability is not a well-suited tool to determine the number of clusters - it is determined by the symmetries of the data which may be unrelated to clustering parameters. We prove our results for center-based clusterings and for spectral clustering, and support our conclusions by many examples in which the behavior of stability is counter-intuitive."
            },
            "slug": "A-Sober-Look-at-Clustering-Stability-Ben-David-Luxburg",
            "title": {
                "fragments": [],
                "text": "A Sober Look at Clustering Stability"
            },
            "tldr": {
                "abstractSimilarityScore": 50,
                "text": "It is concluded that stability is not a well-suited tool to determine the number of clusters - it is determined by the symmetries of the data which may be unrelated to clustering parameters."
            },
            "venue": {
                "fragments": [],
                "text": "COLT"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2470074"
                        ],
                        "name": "Stephen Guattery",
                        "slug": "Stephen-Guattery",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Guattery",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Stephen Guattery"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144985503"
                        ],
                        "name": "G. Miller",
                        "slug": "G.-Miller",
                        "structuredName": {
                            "firstName": "Gary",
                            "lastName": "Miller",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Miller"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 16871555,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "id": "19a7cbd925c33f3423d3a23fcaf8c02c92ad126f",
            "isKey": false,
            "numCitedBy": 167,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "Computing graph separators is an important step in many graph algorithms. A popular technique for finding separators involves spectral methods. However, there has not been much prior analysis of the quality of the separators produced by this technique; instead it is usually claimed that spectral methods \"work well in practice.\" We present an initial attempt at such an analysis. In particular, we consider two popular spectral separator algorithms and provide counterexamples showing that these algorithms perform poorly on certain graphs. We also consider a generalized definition of spectral methods that allows the use of some specified number of the eigenvectors corresponding to the smallest eigenvalues of the Laplacian matrix of a graph, and we show that if such algorithms use a constant number of eigenvectors, then there are graphs for which they do no better than using only the second smallest eigenvector. Furthermore, using the second smallest eigenvector of these graphs produces partitions that are poor with respect to bounds on the gap between the isoperimetric number and the cut quotient of the spectral separator. Even if a generalized spectral algorithm uses $n^\\epsilon$ for \\mbox{$0 < \\epsilon < \\frac{1}{4}$} eigenvectors, there exist graphs for which the algorithm fails to find a separator with a cut quotient within \\mbox{$n^{\\frac{1}{4} - \\epsilon} - 1$} of the isoperimetric number. We also introduce some facts about the structure of eigenvectors of certain types of Laplacian and symmetric matrices; these facts provide the basis for the analysis of the counterexamples. Finally, we discuss some developments in spectral partitioning that have occurred since these results first appeared."
            },
            "slug": "On-the-Quality-of-Spectral-Separators-Guattery-Miller",
            "title": {
                "fragments": [],
                "text": "On the Quality of Spectral Separators"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This work considers two popular spectral separator algorithms and provides counterexamples showing that these algorithms perform poorly on certain graphs, and introduces some facts about the structure of eigenvectors of certain types of Laplacian and symmetric matrices."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2316129"
                        ],
                        "name": "M. Meil\u0103",
                        "slug": "M.-Meil\u0103",
                        "structuredName": {
                            "firstName": "Marina",
                            "lastName": "Meil\u0103",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Meil\u0103"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46865129"
                        ],
                        "name": "Jianbo Shi",
                        "slug": "Jianbo-Shi",
                        "structuredName": {
                            "firstName": "Jianbo",
                            "lastName": "Shi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jianbo Shi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1378740,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "84a86a69315e994cfd1e0c7debb86d62d7bd1f44",
            "isKey": false,
            "numCitedBy": 734,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a new view of clustering and segmentation by pairwise similarities. We interpret the similarities as edge ows in a Markov random walk and study the eigenvalues and eigenvectors of the walk's transition matrix. This view shows that spectral methods for clustering and segmentation have a probabilistic foundation. We prove that the Normalized Cut method arises naturally from our framework and we provide a complete characterization of the cases when the Normalized Cut algorithm is exact. Then we discuss other spectral segmentation and clustering methods showing that several of them are essentially the same as NCut."
            },
            "slug": "A-Random-Walks-View-of-Spectral-Segmentation-Meil\u0103-Shi",
            "title": {
                "fragments": [],
                "text": "A Random Walks View of Spectral Segmentation"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "It is proved that the Normalized Cut method arises naturally from the framework and a complete characterization of the cases when the Normalization Cut algorithm is exact is provided."
            },
            "venue": {
                "fragments": [],
                "text": "AISTATS"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1783667"
                        ],
                        "name": "I. Dhillon",
                        "slug": "I.-Dhillon",
                        "structuredName": {
                            "firstName": "Inderjit",
                            "lastName": "Dhillon",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Dhillon"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 11847258,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a69a816893573aaba052d2614c97d4a7a056a3aa",
            "isKey": false,
            "numCitedBy": 1756,
            "numCiting": 63,
            "paperAbstract": {
                "fragments": [],
                "text": "Both document clustering and word clustering are well studied problems. Most existing algorithms cluster documents and words separately but not simultaneously. In this paper we present the novel idea of modeling the document collection as a bipartite graph between documents and words, using which the simultaneous clustering problem can be posed as a bipartite graph partitioning problem. To solve the partitioning problem, we use a new spectral co-clustering algorithm that uses the second left and right singular vectors of an appropriately scaled word-document matrix to yield good bipartitionings. The spectral algorithm enjoys some optimality properties; it can be shown that the singular vectors solve a real relaxation to the NP-complete graph bipartitioning problem. We present experimental results to verify that the resulting co-clustering algorithm works well in practice."
            },
            "slug": "Co-clustering-documents-and-words-using-bipartite-Dhillon",
            "title": {
                "fragments": [],
                "text": "Co-clustering documents and words using bipartite spectral graph partitioning"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A new spectral co-clustering algorithm is used that uses the second left and right singular vectors of an appropriately scaled word-document matrix to yield good bipartitionings and it can be shown that the singular vectors solve a real relaxation to the NP-complete graph bipartitionsing problem."
            },
            "venue": {
                "fragments": [],
                "text": "KDD '01"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3137076"
                        ],
                        "name": "Frank McSherry",
                        "slug": "Frank-McSherry",
                        "structuredName": {
                            "firstName": "Frank",
                            "lastName": "McSherry",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Frank McSherry"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 145,
                                "start": 125
                            }
                        ],
                        "text": "Random walks and Ncut\nA formal equivalence between Ncut and transition probabilities of the random walk has been observed in Meila and Shi (2001)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 153,
                                "start": 133
                            }
                        ],
                        "text": "In the machine learning community, spectral clustering has been made popular by the works of Shi and Malik (2000), Ng et al. (2002), Meila and Shi (2001), and Ding (2004)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 10389217,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "085e729f762c2f6271b89bbfa14c4330bf9c2f0d",
            "isKey": false,
            "numCitedBy": 608,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "Problems such as bisection, graph coloring, and clique are generally believed hard in the worst case. However, they can be solved if the input data is drawn randomly from a distribution over graphs containing acceptable solutions. In this paper we show that a simple spectral algorithm can solve all three problems above in the average case, as well as a more general problem of partitioning graphs based on edge density. In nearly all cases our approach meets or exceeds previous parameters, while introducing substantial generality. We apply spectral techniques, using foremost the observation that in all of these problems, the expected adjacency matrix is a low rank matrix wherein the structure of the solution is evident."
            },
            "slug": "Spectral-partitioning-of-random-graphs-McSherry",
            "title": {
                "fragments": [],
                "text": "Spectral partitioning of random graphs"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This paper shows that a simple spectral algorithm can solve all three problems above in the average case, as well as a more general problem of partitioning graphs based on edge density."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings 2001 IEEE International Conference on Cluster Computing"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1786884"
                        ],
                        "name": "B. Nadler",
                        "slug": "B.-Nadler",
                        "structuredName": {
                            "firstName": "Boaz",
                            "lastName": "Nadler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Nadler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "37805393"
                        ],
                        "name": "S. Lafon",
                        "slug": "S.-Lafon",
                        "structuredName": {
                            "firstName": "St\u00e9phane",
                            "lastName": "Lafon",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Lafon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1780112"
                        ],
                        "name": "R. Coifman",
                        "slug": "R.-Coifman",
                        "structuredName": {
                            "firstName": "Ronald",
                            "lastName": "Coifman",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Coifman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3439407"
                        ],
                        "name": "I. Kevrekidis",
                        "slug": "I.-Kevrekidis",
                        "structuredName": {
                            "firstName": "Ioannis",
                            "lastName": "Kevrekidis",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Kevrekidis"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 56,
                                "start": 39
                            }
                        ],
                        "text": "Part (1): By the definition of di,\nf \u2032Lf = f \u2032Df \u2212 f \u2032Wf = n\u2211 i=1 dif 2 i \u2212 n\u2211 i,j=1 fifjwij\n= 1 2  n\u2211 i=1 dif 2 i \u2212 2 n\u2211 i,j=1 fifjwij + n\u2211 j=1 djf 2 j  = 1 2 n\u2211 i,j=1 wij(fi \u2212 fj)2."
                    },
                    "intents": []
                }
            ],
            "corpusId": 1028424,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4054314bd6a736f93431ece1e0203ad5ffe6033d",
            "isKey": false,
            "numCitedBy": 447,
            "numCiting": 55,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a diffusion based probabilistic interpretation of spectral clustering and dimensionality reduction algorithms that use the eigenvectors of the normalized graph Laplacian. Given the pairwise adjacency matrix of all points, we define a diffusion distance between any two data points and show that the low dimensional representation of the data by the first few eigenvectors of the corresponding Markov matrix is optimal under a certain mean squared error criterion. Furthermore, assuming that data points are random samples from a density p(x) = e-U(x) we identify these eigenvectors as discrete approximations of eigenfunctions of a Fokker-Planck operator in a potential 2U(x) with reflecting boundary conditions. Finally, applying known results regarding the eigenvalues and eigenfunctions of the continuous Fokker-Planck operator, we provide a mathematical justification for the success of spectral clustering and dimensional reduction algorithms based on these first few eigenvectors. This analysis elucidates, in terms of the characteristics of diffusion processes, many empirical findings regarding spectral clustering algorithms."
            },
            "slug": "Diffusion-Maps,-Spectral-Clustering-and-of-Nadler-Lafon",
            "title": {
                "fragments": [],
                "text": "Diffusion Maps, Spectral Clustering and Eigenfunctions of Fokker-Planck Operators"
            },
            "tldr": {
                "abstractSimilarityScore": 89,
                "text": "A diffusion based probabilistic interpretation of spectral clustering and dimensionality reduction algorithms that use the eigenvectors of the normalized graph Laplacian is presented."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2356015"
                        ],
                        "name": "Marco Saerens",
                        "slug": "Marco-Saerens",
                        "structuredName": {
                            "firstName": "Marco",
                            "lastName": "Saerens",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Marco Saerens"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2910072"
                        ],
                        "name": "Fran\u00e7ois Fouss",
                        "slug": "Fran\u00e7ois-Fouss",
                        "structuredName": {
                            "firstName": "Fran\u00e7ois",
                            "lastName": "Fouss",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Fran\u00e7ois Fouss"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2819997"
                        ],
                        "name": "Luh Yen",
                        "slug": "Luh-Yen",
                        "structuredName": {
                            "firstName": "Luh",
                            "lastName": "Yen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Luh Yen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144487460"
                        ],
                        "name": "P. Dupont",
                        "slug": "P.-Dupont",
                        "structuredName": {
                            "firstName": "Pierre",
                            "lastName": "Dupont",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Dupont"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 136,
                                "start": 111
                            }
                        ],
                        "text": "Several other papers investigate the quality of the clustering constructed by spectral clustering, for example Spielman and Teng (1996) (for unnormalized spectral clustering) and Kannan et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 93,
                                "start": 72
                            }
                        ],
                        "text": "(2004) interpret the matrix D\u22121/2WD\u22121/2 as kernel matrix, other authors (Saerens et al. 2004) interpret the Moore-Penrose inverses of L or Lsym as kernel matrix."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 5583437,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "bdb7da214aa3e041353f47b868950e2613660c27",
            "isKey": false,
            "numCitedBy": 259,
            "numCiting": 45,
            "paperAbstract": {
                "fragments": [],
                "text": "This work presents a novel procedure for computing (1) distances between nodes of a weighted, undirected, graph, called the Euclidean Commute Time Distance (ECTD), and (2) a subspace projection of the nodes of the graph that preserves as much variance as possible, in terms of the ECTD \u2013 a principal components analysis of the graph. It is based on a Markov-chain model of random walk through the graph. The model assigns transition probabilities to the links between nodes, so that a random walker can jump from node to node. A quantity, called the average commute time, computes the average time taken by a random walker for reaching node j for the first time when starting from node i, and coming back to node i. The square root of this quantity, the ECTD, is a distance measure between any two nodes, and has the nice property of decreasing when the number of paths connecting two nodes increases and when the \"length\" of any path decreases. The ECTD can be computed from the pseudoinverse of the Laplacian matrix of the graph, which is a kernel. We finally define the Principal Components Analysis (PCA) of a graph as the subspace projection that preserves as much variance as possible, in terms of the ECTD. This graph PCA has some interesting links with spectral graph theory, in particular spectral clustering."
            },
            "slug": "The-Principal-Components-Analysis-of-a-Graph,-and-Saerens-Fouss",
            "title": {
                "fragments": [],
                "text": "The Principal Components Analysis of a Graph, and Its Relationships to Spectral Clustering"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The Principal Components Analysis (PCA) of a graph is defined as the subspace projection that preserves as much variance as possible, in terms of the ECTD, a principal components analysis of the graph based on a Markov-chain model of random walk through the graph."
            },
            "venue": {
                "fragments": [],
                "text": "ECML"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1737469"
                        ],
                        "name": "C. Ding",
                        "slug": "C.-Ding",
                        "structuredName": {
                            "firstName": "C.",
                            "lastName": "Ding",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Ding"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143644849"
                        ],
                        "name": "Xiaofeng He",
                        "slug": "Xiaofeng-He",
                        "structuredName": {
                            "firstName": "Xiaofeng",
                            "lastName": "He",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xiaofeng He"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145203884"
                        ],
                        "name": "H. Zha",
                        "slug": "H.-Zha",
                        "structuredName": {
                            "firstName": "Hongyuan",
                            "lastName": "Zha",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Zha"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2053083770"
                        ],
                        "name": "Ming Gu",
                        "slug": "Ming-Gu",
                        "structuredName": {
                            "firstName": "Ming",
                            "lastName": "Gu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ming Gu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35124559"
                        ],
                        "name": "H. Simon",
                        "slug": "H.-Simon",
                        "structuredName": {
                            "firstName": "Horst",
                            "lastName": "Simon",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Simon"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 18520895,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6ebb015ac7f7872ecadd75b837e859621abd0751",
            "isKey": false,
            "numCitedBy": 878,
            "numCiting": 46,
            "paperAbstract": {
                "fragments": [],
                "text": "An important application of graph partitioning is data clustering using a graph model - the pairwise similarities between all data objects form a weighted graph adjacency matrix that contains all necessary information for clustering. In this paper, we propose a new algorithm for graph partitioning with an objective function that follows the min-max clustering principle. The relaxed version of the optimization of the min-max cut objective function leads to the Fiedler vector in spectral graph partitioning. Theoretical analyses of min-max cut indicate that it leads to balanced partitions, and lower bounds are derived. The min-max cut algorithm is tested on newsgroup data sets and is found to out-perform other current popular partitioning/clustering methods. The linkage-based refinements to the algorithm further improve the quality of clustering substantially. We also demonstrate that a linearized search order based on linkage differential is better than that based on the Fiedler vector, providing another effective partitioning method."
            },
            "slug": "A-min-max-cut-algorithm-for-graph-partitioning-and-Ding-He",
            "title": {
                "fragments": [],
                "text": "A min-max cut algorithm for graph partitioning and data clustering"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This paper proposes a new algorithm for graph partitioning with an objective function that follows the min-max clustering principle, and demonstrates that a linearized search order based on linkage differential is better than that based on the Fiedler vector, providing another effective partitioning method."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings 2001 IEEE International Conference on Data Mining"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1765196"
                        ],
                        "name": "D. Kempe",
                        "slug": "D.-Kempe",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Kempe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Kempe"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3137076"
                        ],
                        "name": "Frank McSherry",
                        "slug": "Frank-McSherry",
                        "structuredName": {
                            "firstName": "Frank",
                            "lastName": "McSherry",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Frank McSherry"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 30,
                                "start": 17
                            }
                        ],
                        "text": "distributions by Lafon (2004). Then in Belkin and Niyogi"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 295,
                                "start": 271
                            }
                        ],
                        "text": "\u2026(Joachims, 2003) connections between spectral clustering and the weighted kernel-k-means algorithm (Dhillon, Guan, and Kulis, 2005), learning similarity functions based on spectral clustering (Bach and Jordan, 2004), or spectral clustering in a distributed environment (Kempe and McSherry, 2004)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 167,
                                "start": 142
                            }
                        ],
                        "text": "2005), learning similarity functions based on spectral clustering (Bach and Jordan 2004), or spectral clustering in a distributed environment (Kempe and McSherry 2004)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 13105926,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2de7251c2e486d031f9f5f9ff4092aff6947b4e4",
            "isKey": false,
            "numCitedBy": 175,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "In many large network settings, such as computer networks, social networks, or hyperlinked text documents, much information can be obtained from the network's spectral properties. However, traditional centralized approaches for computing eigenvectors struggle with at least two obstacles: the data may be difficult to obtain (both due to technical reasons and because of privacy concerns), and the sheer size of the networks makes the computation expensive. A decentralized, distributed algorithm addresses both of these obstacles: it utilizes the computational power of all nodes in the network and their ability to communicate, thus speeding up the computation with the network size. And as each node knows its incident edges, the data collection problem is avoided as well.Our main result is a simple decentralized algorithm for computing the top k eigenvectors of a symmetric weighted adjacency matrix, and a proof that it converges essentially in O(\u03c4MIXlog2 n) rounds of communication and computation, where \u03c4MIX is the mixing time of a random walk on the network. An additional contribution of our work is a decentralized way of actually detecting convergence, and diagnosing the current error. Our protocol scales well, in that the amount of computation performed at any node in any one round, and the sizes of messages sent, depend polynomially on k, but not on the (typically much larger) number n of nodes."
            },
            "slug": "A-decentralized-algorithm-for-spectral-analysis-Kempe-McSherry",
            "title": {
                "fragments": [],
                "text": "A decentralized algorithm for spectral analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This work presents a simple decentralized algorithm for computing the top k eigenvectors of a symmetric weighted adjacency matrix, and a proof that it converges essentially in O(\u03c4MIXlog2 n) rounds of communication and computation, where \u03c4MIX is the mixing time of a random walk on the network."
            },
            "venue": {
                "fragments": [],
                "text": "STOC '04"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144632403"
                        ],
                        "name": "R. Kannan",
                        "slug": "R.-Kannan",
                        "structuredName": {
                            "firstName": "Ravi",
                            "lastName": "Kannan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Kannan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1737804"
                        ],
                        "name": "S. Vempala",
                        "slug": "S.-Vempala",
                        "structuredName": {
                            "firstName": "Santosh",
                            "lastName": "Vempala",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Vempala"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1776865"
                        ],
                        "name": "A. Vetta",
                        "slug": "A.-Vetta",
                        "structuredName": {
                            "firstName": "Adrian",
                            "lastName": "Vetta",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Vetta"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 212,
                                "start": 179
                            }
                        ],
                        "text": "Several other papers investigate the quality of the clustering constructed by spectral clustering, for example Spielman and Teng (1996) (for unnormalized spectral clustering) and Kannan, Vempala, and Vetta (2004) (for normalized spectral clustering)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 58,
                                "start": 34
                            }
                        ],
                        "text": "This result has been published by Klein and Randic (1993), where it has been proved by methods of electrical network theory."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 61731027,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f36bfb04f8ff4d10aaa204b5338d2234f05c97d2",
            "isKey": false,
            "numCitedBy": 979,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a new measure for assessing the quality of a clustering. A simple heuristic is shown to give worst-case guarantees under the new measure. Then we present two results regarding the quality of the clustering found by a popular spectral algorithm. One proffers worst case guarantees whilst the other shows that if there exists a \"good\" clustering then the spectral algorithm will find one close to it."
            },
            "slug": "On-clusterings-good,-bad-and-spectral-Kannan-Vempala",
            "title": {
                "fragments": [],
                "text": "On clusterings-good, bad and spectral"
            },
            "tldr": {
                "abstractSimilarityScore": 54,
                "text": "Two results regarding the quality of the clustering found by a popular spectral algorithm are presented, one proffers worst case guarantees whilst the other shows that if there exists a \"good\" clustering then the spectral algorithm will find one close to it."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings 41st Annual Symposium on Foundations of Computer Science"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2910072"
                        ],
                        "name": "Fran\u00e7ois Fouss",
                        "slug": "Fran\u00e7ois-Fouss",
                        "structuredName": {
                            "firstName": "Fran\u00e7ois",
                            "lastName": "Fouss",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Fran\u00e7ois Fouss"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2760169"
                        ],
                        "name": "A. Pirotte",
                        "slug": "A.-Pirotte",
                        "structuredName": {
                            "firstName": "Alain",
                            "lastName": "Pirotte",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Pirotte"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2356015"
                        ],
                        "name": "Marco Saerens",
                        "slug": "Marco-Saerens",
                        "structuredName": {
                            "firstName": "Marco",
                            "lastName": "Saerens",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Marco Saerens"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2822140"
                        ],
                        "name": "J. Renders",
                        "slug": "J.-Renders",
                        "structuredName": {
                            "firstName": "Jean-Michel",
                            "lastName": "Renders",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Renders"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2819997"
                        ],
                        "name": "Luh Yen",
                        "slug": "Luh-Yen",
                        "structuredName": {
                            "firstName": "Luh",
                            "lastName": "Yen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Luh Yen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 62804791,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d94b902ff99e8c36fca57915b99688796aab4cfe",
            "isKey": false,
            "numCitedBy": 22,
            "numCiting": 60,
            "paperAbstract": {
                "fragments": [],
                "text": "This work presents a new perspective on characterizing the similarity between elements of a database or, more generally, nodes of a weighted and undirected graph. It is based on a Markov-chain model of random walk through the database. More precisely, we compute quantities (the average commute time, the pseudoinverse of the Laplacian matrix of the graph, etc) that provide similarities between any pair of nodes, having the nice property of increasing when the number of paths connect- ing those elements increases and when the \u201clength\u201d of paths decreases. It turns out that the square root of the average commute time is a Eu- clidean distance and that the pseudoinverse of the Laplacian matrix is a kernel (its elements are inner products closely related to commute times). A procedure for computing the subspace projection of the node vectors of the graph that preserves as much variance as possible in terms of the commute-time distance \u2013 a principal component analysis (PCA) of the graph \u2013 is also introduced. This graph PCA provides a nice interpreta- tion to the \u201cFiedler vector\u201d, widely used for graph partitioning. The model is evaluated on a collaborative-recommendation task where sug- gestions are made about which movies people should watch based upon what they watched in the past. Experimental results on the MovieLens database show that the Laplacian-based similarities (the pseudoinverse of the Laplacian matrix and the \u201crandom-forest matrix\u201d) perform well in comparison with other methods. The model, which nicely fits into the so-called \u201cstatistical relational learning\u201d framework, could also be usedto compute document or word similarities, and, more generally, it could be applied to machine-learning and pattern-recognition tasks involving a database."
            },
            "slug": "A-novel-way-of-computing-similarities-between-nodes-Fouss-Pirotte",
            "title": {
                "fragments": [],
                "text": "A novel way of computing similarities between nodes of a graph, with application to collaborative filtering and subspace projection of the graph nodes"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "The model, which nicely fits into the so-called \u201cstatistical relational learning\u201d framework, could also be used to compute document or word similarities, and, more generally, it could be applied to machine-learning and pattern-recognition tasks involving a database."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143610806"
                        ],
                        "name": "Matthias Hein",
                        "slug": "Matthias-Hein",
                        "structuredName": {
                            "firstName": "Matthias",
                            "lastName": "Hein",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Matthias Hein"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3015507"
                        ],
                        "name": "Jean-Yves Audibert",
                        "slug": "Jean-Yves-Audibert",
                        "structuredName": {
                            "firstName": "Jean-Yves",
                            "lastName": "Audibert",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jean-Yves Audibert"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1728654"
                        ],
                        "name": "U. V. Luxburg",
                        "slug": "U.-V.-Luxburg",
                        "structuredName": {
                            "firstName": "Ulrike",
                            "lastName": "Luxburg",
                            "middleNames": [
                                "von"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "U. V. Luxburg"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1355782,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "id": "3993b1005796fe45d4423daa973d3fe58ae7f798",
            "isKey": false,
            "numCitedBy": 243,
            "numCiting": 60,
            "paperAbstract": {
                "fragments": [],
                "text": "Given a sample from a probability measure with support on a submanifold in Euclidean space one can construct a neighborhood graph which can be seen as an approximation of the submanifold. The graph Laplacian of such a graph is used in several machine learning methods like semi-supervised learning, dimensionality reduction and clustering. In this paper we determine the pointwise limit of three different graph Laplacians used in the literature as the sample size increases and the neighborhood size approaches zero. We show that for a uniform measure on the submanifold all graph Laplacians have the same limit up to constants. However in the case of a non-uniform measure on the submanifold only the so called random walk graph Laplacian converges to the weighted Laplace-Beltrami operator."
            },
            "slug": "Graph-Laplacians-and-their-Convergence-on-Random-Hein-Audibert",
            "title": {
                "fragments": [],
                "text": "Graph Laplacians and their Convergence on Random Neighborhood Graphs"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "This paper determines the pointwise limit of three different graph Laplacians used in the literature as the sample size increases and the neighborhood size approaches zero and shows that for a uniform measure on the submanifold all graph LaPLacians have the same limit up to constants."
            },
            "venue": {
                "fragments": [],
                "text": "J. Mach. Learn. Res."
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2053956"
                        ],
                        "name": "Susanne Still",
                        "slug": "Susanne-Still",
                        "structuredName": {
                            "firstName": "Susanne",
                            "lastName": "Still",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Susanne Still"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1762240"
                        ],
                        "name": "W. Bialek",
                        "slug": "W.-Bialek",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Bialek",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Bialek"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 165,
                                "start": 143
                            }
                        ],
                        "text": "Examples range from ad-hoc measures such as the ratio of within-cluster and between-cluster similarities, over information-theoretic criteria (Still and Bialek, 2004), the gap statistic (Tibshirani, Walther, and Hastie, 2001), to stability approaches (Ben-Hur, Elisseeff, and Guyon, 2002; Lange,\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1171782,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "dfa32f1f5712582255ff30048ae15f744c4a7531",
            "isKey": false,
            "numCitedBy": 146,
            "numCiting": 57,
            "paperAbstract": {
                "fragments": [],
                "text": "Clustering provides a common means of identifying structure in complex data, and there is renewed interest in clustering as a tool for the analysis of large data sets in many fields. A natural question is how many clusters are appropriate for the description of a given system. Traditional approaches to this problem are based on either a framework in which clusters of a particular shape are assumed as a model of the system or on a two-step procedure in which a clustering criterion determines the optimal assignments for a given number of clusters and a separate criterion measures the goodness of the classification to determine the number of clusters. In a statistical mechanics approach, clustering can be seen as a trade-off between energy- and entropy-like terms, with lower temperature driving the proliferation of clusters to provide a more detailed description of the data. For finite data sets, we expect that there is a limit to the meaningful structure that can be resolved and therefore a minimum temperature beyond which we will capture sampling noise. This suggests that correcting the clustering criterion for the bias that arises due to sampling errors will allow us to find a clustering solution at a temperature that is optimal in the sense that we capture maximal meaningful structurewithout having to define an external criterion for the goodness or stability of the clustering. We show that in a general information-theoretic framework, the finite size of a data set determines an optimal temperature, and we introduce a method for finding the maximal number of clusters that can be resolved from the data in the hard clustering limit."
            },
            "slug": "How-Many-Clusters-An-Information-Theoretic-Still-Bialek",
            "title": {
                "fragments": [],
                "text": "How Many Clusters? An Information-Theoretic Perspective"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "It is shown that in a general information-theoretic framework, the finite size of a data set determines an optimal temperature, and a method for finding the maximal number of clusters that can be resolved from the data in the hard clustering limit is introduced."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "51204489"
                        ],
                        "name": "T. D. Bie",
                        "slug": "T.-D.-Bie",
                        "structuredName": {
                            "firstName": "Tijl",
                            "lastName": "Bie",
                            "middleNames": [
                                "De"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. D. Bie"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685083"
                        ],
                        "name": "N. Cristianini",
                        "slug": "N.-Cristianini",
                        "structuredName": {
                            "firstName": "Nello",
                            "lastName": "Cristianini",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Cristianini"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 126,
                                "start": 100
                            }
                        ],
                        "text": "For example, a completely different relaxation which leads to a semi-definite program is derived in Bie and Cristianini (2006), and there might be many other useful relaxations."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 11441492,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2d8eaad2d960c5f073f464c3e8c7ba8c91458703",
            "isKey": false,
            "numCitedBy": 58,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "The rise of convex programming has changed the face of many research fields in recent years, machine learning being one of the ones that benefitted the most. A very recent developement, the relaxation of combinatorial problems to semi-definite programs (SDP), has gained considerable attention over the last decade (Helmberg, 2000; De Bie and Cristianini, 2004a). Although SDP problems can be solved in polynomial time, for many relaxations the exponent in the polynomial complexity bounds is too high for scaling to large problem sizes. This has hampered their uptake as a powerful new tool in machine learning. \n \nIn this paper, we present a new and fast SDP relaxation of the normalized graph cut problem, and investigate its usefulness in unsupervised and semi-supervised learning. In particular, this provides a convex algorithm for transduction, as well as approaches to clustering. We further propose a whole cascade of fast relaxations that all hold the middle between older spectral relaxations and the new SDP relaxation, allowing one to trade off computational cost versus relaxation accuracy. Finally, we discuss how the methodology developed in this paper can be applied to other combinatorial problems in machine learning, and we treat the max-cut problem as an example."
            },
            "slug": "Fast-SDP-Relaxations-of-Graph-Cut-Clustering,-and-Bie-Cristianini",
            "title": {
                "fragments": [],
                "text": "Fast SDP Relaxations of Graph Cut Clustering, Transduction, and Other Combinatorial Problem"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "A new and fast SDP relaxation of the normalized graph cut problem is presented, and its usefulness in unsupervised and semi-supervised learning is investigated, providing a convex algorithm for transduction, as well as approaches to clustering."
            },
            "venue": {
                "fragments": [],
                "text": "J. Mach. Learn. Res."
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144861798"
                        ],
                        "name": "C. Fraley",
                        "slug": "C.-Fraley",
                        "structuredName": {
                            "firstName": "Chris",
                            "lastName": "Fraley",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Fraley"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1804386"
                        ],
                        "name": "A. Raftery",
                        "slug": "A.-Raftery",
                        "structuredName": {
                            "firstName": "Adrian",
                            "lastName": "Raftery",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Raftery"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 170,
                                "start": 145
                            }
                        ],
                        "text": "Those criteria are usually based on the log-likelihood of the data, which can then be treated in a frequentist or Bayesian way, for examples see Fraley and Raftery (2002)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 171,
                                "start": 145
                            }
                        ],
                        "text": "Those criteria are usually based on the log-likelihood of the data, which can then be treated in a frequentist or Bayesian way, for examples see Fraley and Raftery (2002). In settings where no or few assumptions on the underlying model are made, a large variety of different indices can be used to pick the number of clusters."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14462594,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "114e1354cee7a687ae694f7d8134c7afc87abb47",
            "isKey": false,
            "numCitedBy": 3816,
            "numCiting": 217,
            "paperAbstract": {
                "fragments": [],
                "text": "Cluster analysis is the automated search for groups of related observations in a dataset. Most clustering done in practice is based largely on heuristic but intuitively reasonable procedures, and most clustering methods available in commercial software are also of this type. However, there is little systematic guidance associated with these methods for solving important practical questions that arise in cluster analysis, such as how many clusters are there, which clustering method should be used, and how should outliers be handled. We review a general methodology for model-based clustering that provides a principled statistical approach to these issues. We also show that this can be useful for other problems in multivariate analysis, such as discriminant analysis and multivariate density estimation. We give examples from medical diagnosis, minefield detection, cluster recovery from noisy data, and spatial density estimation. Finally, we mention limitations of the methodology and discuss recent developments in model-based clustering for non-Gaussian data, high-dimensional datasets, large datasets, and Bayesian estimation."
            },
            "slug": "Model-Based-Clustering,-Discriminant-Analysis,-and-Fraley-Raftery",
            "title": {
                "fragments": [],
                "text": "Model-Based Clustering, Discriminant Analysis, and Density Estimation"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This work reviews a general methodology for model-based clustering that provides a principled statistical approach to important practical questions that arise in cluster analysis, such as how many clusters are there, which clustering method should be used, and how should outliers be handled."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49464494"
                        ],
                        "name": "Kevin J. Lang",
                        "slug": "Kevin-J.-Lang",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Lang",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kevin J. Lang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9892200,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d5f0884093d88ab525a9d27a229ae70297ce51c6",
            "isKey": false,
            "numCitedBy": 77,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "We discuss two intrinsic weaknesses of the spectral graph partitioning method, both of which have practical consequences. The first is that spectral embeddings tend to hide the best cuts from the commonly used hyperplane rounding method. Rather than cleaning up the resulting sub-optimal cuts with local search, we recommend the adoption of flow-based rounding. The second weakness is that for many \"power law\" graphs, the spectral method produces cuts that are highly unbalanced, thus decreasing the usefulness of the method for visualization (see figure 4(b)) or as a basis for divide-and-conquer algorithms. These balance problems, which occur even though the spectral method's quotient-style objective function does encourage balance, can be fixed with a stricter balance constraint that turns the spectral mathematical program into an SDP that can be solved for million-node graphs by a method of Burer and Monteiro."
            },
            "slug": "Fixing-two-weaknesses-of-the-Spectral-Method-Lang",
            "title": {
                "fragments": [],
                "text": "Fixing two weaknesses of the Spectral Method"
            },
            "tldr": {
                "abstractSimilarityScore": 66,
                "text": "Two intrinsic weaknesses of the spectral graph partitioning method are discussed, including that spectral embeddings tend to hide the best cuts from the commonly used hyperplane rounding method and that for many \"power law\" graphs, the spectral method produces cuts that are highly unbalanced, thus decreasing the usefulness of the method for visualization."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1679116"
                        ],
                        "name": "B. Mohar",
                        "slug": "B.-Mohar",
                        "structuredName": {
                            "firstName": "Bojan",
                            "lastName": "Mohar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Mohar"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 74,
                                "start": 56
                            }
                        ],
                        "text": "An overview over many of its properties can be found in Mohar (1991, 1997)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "corresponding to the ksmallest eigenvalues. 3 3.1 The unnormalized graph Laplacian The unnormalized graph Laplacian matrix is dened as L= D W: An overview over many of its properties can be found in Mohar (1991, 1997). The following proposition summarizes the most important facts needed for spectral clustering. Proposition 1 (Properties of L) The matrix Lsatises the following properties: 1.For every vector"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 143,
                                "start": 125
                            }
                        ],
                        "text": "The unnormalized graph Laplacian and its eigenvalues and eigenvectors can be used to describe many properties of graphs, see Mohar (1991, 1997)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "ar, self-edges in a graph do not change the corresponding graph Laplacian. The unnormalized graph Laplacian and its eigenvalues and eigenvectors can be used to describe many properties of graphs, see Mohar (1991, 1997). One example which will be important for spectral clustering is the following: Proposition 2 (Number of connected components and the spectrum of L) Let Gbe an undirected graph with non-negativ"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 122755097,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "6f76d209c8fe6d8309b257a315e81952698b29dc",
            "isKey": true,
            "numCitedBy": 1199,
            "numCiting": 48,
            "paperAbstract": {
                "fragments": [],
                "text": "The paper is essentially a survey of known results about the spectrum of the Laplacian matrix of graphs with special emphasis on the second smallest Lapla- cian eigenvalue 2 and its relation to numerous graph invariants, including connectivity, expanding properties, isoperimetric number, maximum cut, independence number, genus, diameter, mean distance, and bandwidth-type parameters of a graph. Some new results and generalizations are added."
            },
            "slug": "THE-LAPLACIAN-SPECTRUM-OF-GRAPHS-y-Mohar",
            "title": {
                "fragments": [],
                "text": "THE LAPLACIAN SPECTRUM OF GRAPHS y"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751762"
                        ],
                        "name": "Yoshua Bengio",
                        "slug": "Yoshua-Bengio",
                        "structuredName": {
                            "firstName": "Yoshua",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoshua Bengio"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2460212"
                        ],
                        "name": "Olivier Delalleau",
                        "slug": "Olivier-Delalleau",
                        "structuredName": {
                            "firstName": "Olivier",
                            "lastName": "Delalleau",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Olivier Delalleau"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7245737"
                        ],
                        "name": "Nicolas Le Roux",
                        "slug": "Nicolas-Le-Roux",
                        "structuredName": {
                            "firstName": "Nicolas",
                            "lastName": "Le Roux",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nicolas Le Roux"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39651651"
                        ],
                        "name": "Jean-Fran\u00e7ois Paiement",
                        "slug": "Jean-Fran\u00e7ois-Paiement",
                        "structuredName": {
                            "firstName": "Jean-Fran\u00e7ois",
                            "lastName": "Paiement",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jean-Fran\u00e7ois Paiement"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145467703"
                        ],
                        "name": "Pascal Vincent",
                        "slug": "Pascal-Vincent",
                        "structuredName": {
                            "firstName": "Pascal",
                            "lastName": "Vincent",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Pascal Vincent"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2120888"
                        ],
                        "name": "M. Ouimet",
                        "slug": "M.-Ouimet",
                        "structuredName": {
                            "firstName": "Marie",
                            "lastName": "Ouimet",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Ouimet"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 182,
                                "start": 147
                            }
                        ],
                        "text": "\u2026over information-theoretic criteria (Still and Bialek, 2004), the gap statistic (Tibshirani, Walther, and Hastie, 2001), to stability approaches (Ben-Hur, Elisseeff, and Guyon, 2002; Lange, Roth,\n10 Histogram of the sample\n10 Histogram of the sample\n6 Histogram of the sample\nBraun, and Buhmann,\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1944221,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cfa15801bf4e7bf610d38dc86da62b83e2ddedcb",
            "isKey": false,
            "numCitedBy": 308,
            "numCiting": 37,
            "paperAbstract": {
                "fragments": [],
                "text": "In this letter, we show a direct relation between spectral embedding methods and kernel principal components analysis and how both are special cases of a more general learning problem: learning the principal eigenfunctions of an operator defined from a kernel and the unknown data-generating density. Whereas spectral embedding methods provided only coordinates for the training points, the analysis justifies a simple extension to out-of-sample examples (the Nystrm formula) for multidimensional scaling (MDS), spectral clustering, Laplacian eigenmaps, locally linear embedding (LLE), and Isomap. The analysis provides, for all such spectral embedding methods, the definition of a loss function, whose empirical average is minimized by the traditional algorithms. The asymptotic expected value of that loss defines a generalization performance and clarifies what these algorithms are trying to learn. Experiments with LLE, Isomap, spectral clustering, and MDS show that this out-of-sample embedding formula generalizes well, with a level of error comparable to the effect of small perturbations of the training set on the embedding."
            },
            "slug": "Learning-Eigenfunctions-Links-Spectral-Embedding-Bengio-Delalleau",
            "title": {
                "fragments": [],
                "text": "Learning Eigenfunctions Links Spectral Embedding and Kernel PCA"
            },
            "tldr": {
                "abstractSimilarityScore": 93,
                "text": "A direct relation is shown between spectral embedding methods and kernel principal components analysis and how both are special cases of a more general learning problem: learning the principal eigenfunctions of an operator defined from a kernel and the unknown data-generating density."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143887341"
                        ],
                        "name": "M. Newman",
                        "slug": "M.-Newman",
                        "structuredName": {
                            "firstName": "M.",
                            "lastName": "Newman",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Newman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6549938,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "b28544a8d4bf5d24e70689730a11ed01feafef3e",
            "isKey": false,
            "numCitedBy": 816,
            "numCiting": 167,
            "paperAbstract": {
                "fragments": [],
                "text": "The paper is essentially a survey of known results about the spectrum of the Laplacian matrix of graphs with special emphasis on the second smallest Laplacian eigenvalue \u03bb2 and its relation to numerous graph invariants, including connectivity, expanding properties, isoperimetric number, maximum cut, independence number, genus, diameter, mean distance, and bandwidth-type parameters of a graph. Some new results and generalizations are added. \u2020 This article appeared in \u201cGraph Theory, Combinatorics, and Applications\u201d, Vol. 2, Ed. Y. Alavi, G. Chartrand, O. R. Oellermann, A. J. Schwenk, Wiley, 1991, pp. 871\u2013898. \u2021 The work supported in part by the Research Council of Slovenia, Yugoslavia. Part of the work was done while the author was a Fulbright Scholar at the Ohio State University, Columbus, Ohio."
            },
            "slug": "The-Laplacian-spectrum-of-graphs-Newman",
            "title": {
                "fragments": [],
                "text": "The Laplacian spectrum of graphs"
            },
            "tldr": {
                "abstractSimilarityScore": 99,
                "text": "This paper is essentially a survey of known results about the spectrum of the Laplacian matrix of graphs with special emphasis on the second smallest LaPLacian eigenvalue \u03bb2 and its relation to numerous graph invariants, including connectivity, expanding properties, isoperimetric number, maximum cut, independence number, genus, diameter, mean distance, and bandwidth-type parameters of a graph."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2910072"
                        ],
                        "name": "Fran\u00e7ois Fouss",
                        "slug": "Fran\u00e7ois-Fouss",
                        "structuredName": {
                            "firstName": "Fran\u00e7ois",
                            "lastName": "Fouss",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Fran\u00e7ois Fouss"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2760169"
                        ],
                        "name": "A. Pirotte",
                        "slug": "A.-Pirotte",
                        "structuredName": {
                            "firstName": "Alain",
                            "lastName": "Pirotte",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Pirotte"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2822140"
                        ],
                        "name": "J. Renders",
                        "slug": "J.-Renders",
                        "structuredName": {
                            "firstName": "Jean-Michel",
                            "lastName": "Renders",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Renders"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2356015"
                        ],
                        "name": "Marco Saerens",
                        "slug": "Marco-Saerens",
                        "structuredName": {
                            "firstName": "Marco",
                            "lastName": "Saerens",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Marco Saerens"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "For a proof using first step analysis for random walks see  Fouss, Pirotte, Renders, and Saerens (2007) ."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 12477253,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "474db64356d6c9c82fe2a8604cd6c13bc17bae78",
            "isKey": false,
            "numCitedBy": 1142,
            "numCiting": 84,
            "paperAbstract": {
                "fragments": [],
                "text": "This work presents a new perspective on characterizing the similarity between elements of a database or, more generally, nodes of a weighted and undirected graph. It is based on a Markov-chain model of random walk through the database. More precisely, we compute quantities (the average commute time, the pseudoinverse of the Laplacian matrix of the graph, etc.) that provide similarities between any pair of nodes, having the nice property of increasing when the number of paths connecting those elements increases and when the \"length\" of paths decreases. It turns out that the square root of the average commute time is a Euclidean distance and that the pseudoinverse of the Laplacian matrix is a kernel matrix (its elements are inner products closely related to commute times). A principal component analysis (PCA) of the graph is introduced for computing the subspace projection of the node vectors in a manner that preserves as much variance as possible in terms of the Euclidean commute-time distance. This graph PCA provides a nice interpretation to the \"Fiedler vector,\" widely used for graph partitioning. The model is evaluated on a collaborative-recommendation task where suggestions are made about which movies people should watch based upon what they watched in the past. Experimental results on the MovieLens database show that the Laplacian-based similarities perform well in comparison with other methods. The model, which nicely fits into the so-called \"statistical relational learning\" framework, could also be used to compute document or word similarities, and, more generally, it could be applied to machine-learning and pattern-recognition tasks involving a relational database"
            },
            "slug": "Random-Walk-Computation-of-Similarities-between-of-Fouss-Pirotte",
            "title": {
                "fragments": [],
                "text": "Random-Walk Computation of Similarities between Nodes of a Graph with Application to Collaborative Recommendation"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "The model, which nicely fits into the so-called \"statistical relational learning\" framework, could also be used to compute document or word similarities, and could be applied to machine-learning and pattern-recognition tasks involving a relational database."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Knowledge and Data Engineering"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145518576"
                        ],
                        "name": "K. Liou",
                        "slug": "K.-Liou",
                        "structuredName": {
                            "firstName": "K",
                            "lastName": "Liou",
                            "middleNames": [
                                "P"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Liou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1753507"
                        ],
                        "name": "A. Pothen",
                        "slug": "A.-Pothen",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Pothen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Pothen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Since then, spectral clustering has been discovered, re-discovered, and extended many times in different communities, see for example  Pothen, Simon, and Liou (1990) , Simon (1991), Bolla (1991), Hagen and Kahng (1992), Hendrickson and Leland (1995), Van Driessche and Roose (1995), Barnard, Pothen, and Simon (1995), Spielman and Teng (1996), Guattery and Miller (1998)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 164,
                                "start": 134
                            }
                        ],
                        "text": "Since then, spectral clustering has been discovered, re-discovered, and extended many times in different communities, see for example Pothen, Simon, and Liou (1990), Simon (1991), Bolla (1991), Hagen and Kahng (1992), Hendrickson and Leland (1995), Van Driessche and Roose (1995), Barnard, Pothen,\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 8978853,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c802c8d48580ebba10a0c65d021758e7238dada3",
            "isKey": false,
            "numCitedBy": 1807,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "The problem ofcomputing a small vertex separator in a graph arises in the context ofcomputing a good ordering for the parallel factorization of sparse, symmetric matrices. An algebraic approach for computing vertex separators is considered in this paper. It is shown that lower bounds on separator sizes can be obtained in terms of the eigenvalues of the Laplacian matrix associated with a graph. The Laplacian eigenvectors of grid graphs can be computed from Kronecker products involving the eigenvectors ofpath graphs, and these eigenvectors can be used to compute good separators in grid graphs. A heuristic algorithm is designed to compute a vertex separator in a general graph by first computing an edge separator in the graph from an eigenvector of the Laplacian matrix, and then using a maximum matching in a subgraph to compute the vertex separator. Results on the quality of the separators computed by the spectral algorithm are presented, and these are compared with separators obtained from other algorithms for computing separators. Finally, the time required to compute the Laplacian eigenvector is reported, and the accuracy with which the eigenvector must be computed to obtain good separators is considered. The spectral algorithm has the advantage that it can be implemented on a mediumsize multiprocessor in a straightforward manner. Key words, graph partitioning, graph spectra, Laplacian matrix, ordering algorithms, parallel orderings, sparse matrix, vertex separator AMS(MOS) subject classifications. 65F50, 65F05, 65F15, 68R10"
            },
            "slug": "PARTITIONING-SPARSE-MATRICES-WITH-EIGENVECTORS-OF-Liou-Pothen",
            "title": {
                "fragments": [],
                "text": "PARTITIONING SPARSE MATRICES WITH EIGENVECTORS OF GRAPHS*"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "It is shown that lower bounds on separator sizes can be obtained in terms of the eigenvalues of the Laplacian matrix associated with a graph, which can be used to compute good separators in grid graphs."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1973
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145520115"
                        ],
                        "name": "Mikhail Belkin",
                        "slug": "Mikhail-Belkin",
                        "structuredName": {
                            "firstName": "Mikhail",
                            "lastName": "Belkin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mikhail Belkin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1770745"
                        ],
                        "name": "P. Niyogi",
                        "slug": "P.-Niyogi",
                        "structuredName": {
                            "firstName": "Partha",
                            "lastName": "Niyogi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Niyogi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14879317,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "88816ae492956f3004daa41357166f1181c0c1bf",
            "isKey": false,
            "numCitedBy": 7047,
            "numCiting": 78,
            "paperAbstract": {
                "fragments": [],
                "text": "One of the central problems in machine learning and pattern recognition is to develop appropriate representations for complex data. We consider the problem of constructing a representation for data lying on a low-dimensional manifold embedded in a high-dimensional space. Drawing on the correspondence between the graph Laplacian, the Laplace Beltrami operator on the manifold, and the connections to the heat equation, we propose a geometrically motivated algorithm for representing the high-dimensional data. The algorithm provides a computationally efficient approach to nonlinear dimensionality reduction that has locality-preserving properties and a natural connection to clustering. Some potential applications and illustrative examples are discussed."
            },
            "slug": "Laplacian-Eigenmaps-for-Dimensionality-Reduction-Belkin-Niyogi",
            "title": {
                "fragments": [],
                "text": "Laplacian Eigenmaps for Dimensionality Reduction and Data Representation"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This work proposes a geometrically motivated algorithm for representing the high-dimensional data that provides a computationally efficient approach to nonlinear dimensionality reduction that has locality-preserving properties and a natural connection to clustering."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1701121"
                        ],
                        "name": "Y. Koren",
                        "slug": "Y.-Koren",
                        "structuredName": {
                            "firstName": "Yehuda",
                            "lastName": "Koren",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Koren"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 57,
                                "start": 34
                            }
                        ],
                        "text": "This result has been published by Klein and Randic (1993), where it has been proved by methods of electrical network theory."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 15735639,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "64d8c8099fef68bdfd7bab4c57b9c5e5f5aa21a6",
            "isKey": false,
            "numCitedBy": 117,
            "numCiting": 48,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Drawing-graphs-by-eigenvectors:-theory-and-practice-Koren",
            "title": {
                "fragments": [],
                "text": "Drawing graphs by eigenvectors: theory and practice"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2210169"
                        ],
                        "name": "S. Barnard",
                        "slug": "S.-Barnard",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Barnard",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Barnard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1753507"
                        ],
                        "name": "A. Pothen",
                        "slug": "A.-Pothen",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Pothen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Pothen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35124559"
                        ],
                        "name": "H. Simon",
                        "slug": "H.-Simon",
                        "structuredName": {
                            "firstName": "Horst",
                            "lastName": "Simon",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Simon"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 243,
                                "start": 210
                            }
                        ],
                        "text": "\u2026extended many times in different communities, see for example Pothen, Simon, and Liou (1990), Simon (1991), Bolla (1991), Hagen and Kahng (1992), Hendrickson and Leland (1995), Van Driessche and Roose (1995), Barnard, Pothen, and Simon (1995), Spielman and Teng (1996), Guattery and Miller (1998)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 987225,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9b8bce515820c8222c0dc2d5c0fdbd69aa3c0edf",
            "isKey": false,
            "numCitedBy": 165,
            "numCiting": 56,
            "paperAbstract": {
                "fragments": [],
                "text": "An algorithm for reducing the envelope of a sparse matrix is presented. This algorithm is based on the computation of eigenvectors of the Laplacian matrix associated with the graph of the sparse matrix. A reordering of the sparse matrix is determined based on the numerical values of the entries of an eigenvector of the Laplacian matrix. Numerical results show that the new reordering algorithm can in some cases reduce the envelope by more than a factor of two over the current standard algorithms such as Gibbs-Poole-Stockmeyer or SPARSPAK's reverse Cuthill-McKee."
            },
            "slug": "A-spectral-algorithm-for-envelope-reduction-of-Barnard-Pothen",
            "title": {
                "fragments": [],
                "text": "A spectral algorithm for envelope reduction of sparse matrices"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "Numerical results show that the new reordering algorithm can in some cases reduce the envelope of a sparse matrix by more than a factor of two over the current standard algorithms such as Gibbs-Poole-Stockmeyer or SPARSPAK's reverse Cuthill-McKee."
            },
            "venue": {
                "fragments": [],
                "text": "Supercomputing '93. Proceedings"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143610806"
                        ],
                        "name": "Matthias Hein",
                        "slug": "Matthias-Hein",
                        "structuredName": {
                            "firstName": "Matthias",
                            "lastName": "Hein",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Matthias Hein"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3015507"
                        ],
                        "name": "Jean-Yves Audibert",
                        "slug": "Jean-Yves-Audibert",
                        "structuredName": {
                            "firstName": "Jean-Yves",
                            "lastName": "Audibert",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jean-Yves Audibert"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1728654"
                        ],
                        "name": "U. V. Luxburg",
                        "slug": "U.-V.-Luxburg",
                        "structuredName": {
                            "firstName": "Ulrike",
                            "lastName": "Luxburg",
                            "middleNames": [
                                "von"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "U. V. Luxburg"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 36,
                                "start": 18
                            }
                        ],
                        "text": "At the same time, Hein et al. (2005) prove more general results, taking into account all different graph Laplacians L, Lrw, and Lsym, more general similarity functions, and manifolds with arbitrary distributions."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                }
            ],
            "corpusId": 2789515,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "7edde67273c2ad09458d73328628f3385d0df837",
            "isKey": false,
            "numCitedBy": 317,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "In the machine learning community it is generally believed that graph Laplacians corresponding to a finite sample of data points converge to a continuous Laplace operator if the sample size increases. Even though this assertion serves as a justification for many Laplacian-based algorithms, so far only some aspects of this claim have been rigorously proved. In this paper we close this gap by establishing the strong pointwise consistency of a family of graph Laplacians with data-dependent weights to some weighted Laplace operator. Our investigation also includes the important case where the data lies on a submanifold of R d ."
            },
            "slug": "From-Graphs-to-Manifolds-Weak-and-Strong-Pointwise-Hein-Audibert",
            "title": {
                "fragments": [],
                "text": "From Graphs to Manifolds - Weak and Strong Pointwise Consistency of Graph Laplacians"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This paper establishes the strong pointwise consistency of a family of graph Laplacians with data-dependent weights to some weighted Laplace operator."
            },
            "venue": {
                "fragments": [],
                "text": "COLT"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1399356737"
                        ],
                        "name": "A. Ben-Hur",
                        "slug": "A.-Ben-Hur",
                        "structuredName": {
                            "firstName": "Asa",
                            "lastName": "Ben-Hur",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Ben-Hur"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1766703"
                        ],
                        "name": "A. Elisseeff",
                        "slug": "A.-Elisseeff",
                        "structuredName": {
                            "firstName": "Andr\u00e9",
                            "lastName": "Elisseeff",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Elisseeff"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1743797"
                        ],
                        "name": "I. Guyon",
                        "slug": "I.-Guyon",
                        "structuredName": {
                            "firstName": "Isabelle",
                            "lastName": "Guyon",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Guyon"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 182,
                                "start": 147
                            }
                        ],
                        "text": "\u2026over information-theoretic criteria (Still and Bialek, 2004), the gap statistic (Tibshirani, Walther, and Hastie, 2001), to stability approaches (Ben-Hur, Elisseeff, and Guyon, 2002; Lange, Roth,\n10 Histogram of the sample\n10 Histogram of the sample\n6 Histogram of the sample\nBraun, and Buhmann,\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 16612326,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "825bf4fc7aacb4a202a1095abd7bc036e91f4b8a",
            "isKey": false,
            "numCitedBy": 614,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a method for visually and quantitatively assessing the presence of structure in clustered data. The method exploits measurements of the stability of clustering solutions obtained by perturbing the data set. Stability is characterized by the distribution of pairwise similarities between clusterings obtained from sub samples of the data. High pairwise similarities indicate a stable clustering pattern. The method can be used with any clustering algorithm; it provides a means of rationally defining an optimum number of clusters, and can also detect the lack of structure in data. We show results on artificial and microarray data using a hierarchical clustering algorithm."
            },
            "slug": "A-Stability-Based-Method-for-Discovering-Structure-Ben-Hur-Elisseeff",
            "title": {
                "fragments": [],
                "text": "A Stability Based Method for Discovering Structure in Clustered Data"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The method can be used with any clustering algorithm and provides a means of rationally defining an optimum number of clusters, and can also detect the lack of structure in data."
            },
            "venue": {
                "fragments": [],
                "text": "Pacific Symposium on Biocomputing"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2417095"
                        ],
                        "name": "D. Spielman",
                        "slug": "D.-Spielman",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Spielman",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Spielman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144461956"
                        ],
                        "name": "S. Teng",
                        "slug": "S.-Teng",
                        "structuredName": {
                            "firstName": "Shang-Hua",
                            "lastName": "Teng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Teng"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "V of Stewart and Sun (1990) and Sect."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14861472,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "3868293dee5b1dff83650bea83054b35c2e2ade8",
            "isKey": false,
            "numCitedBy": 422,
            "numCiting": 129,
            "paperAbstract": {
                "fragments": [],
                "text": "Spectral partitioning methods use the Fiedler vector-the eigenvector of the second-smallest eigenvalue of the Laplacian matrix-to find a small separator of a graph. These methods are important components of many scientific numerical algorithms and have been demonstrated by experiment to work extremely well. In this paper, we show that spectral partitioning methods work well on bounded-degree planar graphs and finite element meshes-the classes of graphs to which they are usually applied. While active spectral bisection does not necessarily work, we prove that spectral partitioning techniques can be used to produce separators whose ratio of vertices removed to edges cut is O(/spl radic/n) for bounded-degree planar graphs and two-dimensional meshes and O(n/sup 1/d/) for well-shaped d-dimensional meshes. The heart of our analysis is an upper bound on the second-smallest eigenvalues of the Laplacian matrices of these graphs: we prove a bound of O(1/n) for bounded-degree planar graphs and O(1/n/sup 2/d/) for well-shaped d-dimensional meshes."
            },
            "slug": "Spectral-partitioning-works:-planar-graphs-and-Spielman-Teng",
            "title": {
                "fragments": [],
                "text": "Spectral partitioning works: planar graphs and finite element meshes"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "It is proved that spectral partitioning techniques can be used to produce separators whose ratio of vertices removed to edges cut is O(/spl radic/n) for bounded-degree planar graphs and two-dimensional meshes and O(n/sup 1/d/) for well-shaped d-dimensional mesh."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of 37th Conference on Foundations of Computer Science"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1679116"
                        ],
                        "name": "B. Mohar",
                        "slug": "B.-Mohar",
                        "structuredName": {
                            "firstName": "Bojan",
                            "lastName": "Mohar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Mohar"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 118166840,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "565ab990edc13b1ec75de7b11b86bf40eb48c974",
            "isKey": false,
            "numCitedBy": 486,
            "numCiting": 85,
            "paperAbstract": {
                "fragments": [],
                "text": "In the last decade important relations between Laplace eigenvalues and eigenvectors of graphs and several other graph parameters were discovered. In these notes we present some of these results and discuss their consequences. Attention is given to the partition and the isoperimetric properties of graphs, the max-cut problem and its relation to semidefinite programming, rapid mixing of Markov chains, and to extensions of the results to infinite graphs."
            },
            "slug": "Some-applications-of-Laplace-eigenvalues-of-graphs-Mohar",
            "title": {
                "fragments": [],
                "text": "Some applications of Laplace eigenvalues of graphs"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2417095"
                        ],
                        "name": "D. Spielman",
                        "slug": "D.-Spielman",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Spielman",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Spielman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144461956"
                        ],
                        "name": "S. Teng",
                        "slug": "S.-Teng",
                        "structuredName": {
                            "firstName": "Shang-Hua",
                            "lastName": "Teng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Teng"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 96,
                                "start": 72
                            }
                        ],
                        "text": "A nice overview over the history of spectral clustering can be found in Spielman and Teng (1996)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 135,
                                "start": 111
                            }
                        ],
                        "text": "Several other papers investigate the quality of the clustering constructed by spectral clustering, for example Spielman and Teng (1996) (for unnormalized spectral clustering) and Kannan, Vempala, and Vetta (2004) (for normalized spectral clustering)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 269,
                                "start": 245
                            }
                        ],
                        "text": "\u2026extended many times in different communities, see for example Pothen, Simon, and Liou (1990), Simon (1991), Bolla (1991), Hagen and Kahng (1992), Hendrickson and Leland (1995), Van Driessche and Roose (1995), Barnard, Pothen, and Simon (1995), Spielman and Teng (1996), Guattery and Miller (1998)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 116,
                                "start": 93
                            }
                        ],
                        "text": "We state those results for completeness, but for background reading we refer to Section V of Stewart and Sun (1990) and Section VII."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 124872677,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "8792d119ad31ead2d574645fc03bc6cea1895653",
            "isKey": true,
            "numCitedBy": 187,
            "numCiting": 72,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Spectral-partitioning-works-:-Planar-graphs-and-Spielman-Teng",
            "title": {
                "fragments": [],
                "text": "Spectral partitioning works : Planar graphs and finite element meshes"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145520115"
                        ],
                        "name": "Mikhail Belkin",
                        "slug": "Mikhail-Belkin",
                        "structuredName": {
                            "firstName": "Mikhail",
                            "lastName": "Belkin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mikhail Belkin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1770745"
                        ],
                        "name": "P. Niyogi",
                        "slug": "P.-Niyogi",
                        "structuredName": {
                            "firstName": "Partha",
                            "lastName": "Niyogi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Niyogi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 32,
                                "start": 8
                            }
                        ],
                        "text": "Then in Belkin and Niyogi (2005), the authors prove pointwise convergence results for the unnormalized graph Laplacian using the Gaussian similarity function on manifolds with uniform distribution."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 184,
                                "start": 160
                            }
                        ],
                        "text": "This intuition has been made precise in the works of Belkin (2003), Lafon (2004), Hein, Audibert, and von Luxburg (2005); M., Audibert, and von Luxburg (2007), Belkin and Niyogi (2005), Hein (2006), Gine\u0301 and Koltchinskii (2005)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 10271267,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "40cd779cb417c9e665ec29fdccc73a6499c5ae5e",
            "isKey": false,
            "numCitedBy": 519,
            "numCiting": 45,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Towards-a-theoretical-foundation-for-manifold-Belkin-Niyogi",
            "title": {
                "fragments": [],
                "text": "Towards a theoretical foundation for Laplacian-based manifold methods"
            },
            "venue": {
                "fragments": [],
                "text": "J. Comput. Syst. Sci."
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46865129"
                        ],
                        "name": "Jianbo Shi",
                        "slug": "Jianbo-Shi",
                        "structuredName": {
                            "firstName": "Jianbo",
                            "lastName": "Shi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jianbo Shi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153652147"
                        ],
                        "name": "J. Malik",
                        "slug": "J.-Malik",
                        "structuredName": {
                            "firstName": "Jitendra",
                            "lastName": "Malik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Malik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14848918,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b94c7ff9532ab26c3aedbee3988ec4c7a237c173",
            "isKey": false,
            "numCitedBy": 12819,
            "numCiting": 55,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a novel approach for solving the perceptual grouping problem in vision. Rather than focusing on local features and their consistencies in the image data, our approach aims at extracting the global impression of an image. We treat image segmentation as a graph partitioning problem and propose a novel global criterion, the normalized cut, for segmenting the graph. The normalized cut criterion measures both the total dissimilarity between the different groups as well as the total similarity within the groups. We show that an efficient computational technique based on a generalized eigenvalue problem can be used to optimize this criterion. We have applied this approach to segmenting static images and found results very encouraging."
            },
            "slug": "Normalized-cuts-and-image-segmentation-Shi-Malik",
            "title": {
                "fragments": [],
                "text": "Normalized cuts and image segmentation"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This work treats image segmentation as a graph partitioning problem and proposes a novel global criterion, the normalized cut, for segmenting the graph, which measures both the total dissimilarity between the different groups as well as the total similarity within the groups."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143610806"
                        ],
                        "name": "Matthias Hein",
                        "slug": "Matthias-Hein",
                        "structuredName": {
                            "firstName": "Matthias",
                            "lastName": "Hein",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Matthias Hein"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 34,
                                "start": 15
                            }
                        ],
                        "text": "the same time, Hein et al. (2005) prove more general results,"
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 11,
                                "start": 0
                            }
                        ],
                        "text": "Hein (2006) studies the convergence of the smoothness functional induced by the graph Laplacians and shows uniform convergence results."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 197,
                                "start": 186
                            }
                        ],
                        "text": "This intuition has been made precise in the works of Belkin (2003), Lafon (2004), Hein, Audibert, and von Luxburg (2005); M., Audibert, and von Luxburg (2007), Belkin and Niyogi (2005), Hein (2006), Gine\u0301 and Koltchinskii (2005)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 609886,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "id": "3e9becc469a46ee11aab257f87384fb9fc1428a6",
            "isKey": false,
            "numCitedBy": 71,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "The regularization functional induced by the graph Laplacian of a random neighborhood graph based on the data is adaptive in two ways. First it adapts to an underlying manifold structure and second to the density of the data-generating probability measure. We identify in this paper the limit of the regularizer and show uniform convergence over the space of Holder functions. As an intermediate step we derive upper bounds on the covering numbers of Holder functions on compact Riemannian manifolds, which are of independent interest for the theoretical analysis of manifold-based learning methods."
            },
            "slug": "Uniform-Convergence-of-Adaptive-Graph-Based-Hein",
            "title": {
                "fragments": [],
                "text": "Uniform Convergence of Adaptive Graph-Based Regularization"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This paper identifies the limit of the regularizer and shows uniform convergence over the space of Holder functions, which are of independent interest for the theoretical analysis of manifold-based learning methods."
            },
            "venue": {
                "fragments": [],
                "text": "COLT"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2960836"
                        ],
                        "name": "M. Stoer",
                        "slug": "M.-Stoer",
                        "structuredName": {
                            "firstName": "Mechthild",
                            "lastName": "Stoer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Stoer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143854501"
                        ],
                        "name": "Frank Wagner",
                        "slug": "Frank-Wagner",
                        "structuredName": {
                            "firstName": "Frank",
                            "lastName": "Wagner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Frank Wagner"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 119,
                                "start": 96
                            }
                        ],
                        "text": "In particular for k = 2, mincut is a relatively easy problem and can be solved efficiently, see Stoer and Wagner (1997) and the discussion therein."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15220291,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fec86cab0f490e94f62bfed00f6895db7296a9a1",
            "isKey": false,
            "numCitedBy": 726,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "We present an algorithm for finding the minimum cut of an undirected edge-weighted graph. It is simple in every respect. It has a short and compact description, is easy to implement, and has a surprisingly simple proof of correctness. Its runtime matches that of the fastest algorithm known. The runtime analysis is straightforward. In contrast to nearly all approaches so far, the algorithm uses no flow techniques. Roughly speaking, the algorithm consists of about |V| nearly identical phases each of which is a maximum adjacency search."
            },
            "slug": "A-simple-min-cut-algorithm-Stoer-Wagner",
            "title": {
                "fragments": [],
                "text": "A simple min-cut algorithm"
            },
            "tldr": {
                "abstractSimilarityScore": 79,
                "text": "An algorithm for finding the minimum cut of an undirected edge-weighted graph that has a short and compact description, is easy to implement, and has a surprisingly simple proof of correctness."
            },
            "venue": {
                "fragments": [],
                "text": "JACM"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2919398"
                        ],
                        "name": "W. Donath",
                        "slug": "W.-Donath",
                        "structuredName": {
                            "firstName": "Wilm",
                            "lastName": "Donath",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Donath"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34699665"
                        ],
                        "name": "A. Hoffman",
                        "slug": "A.-Hoffman",
                        "structuredName": {
                            "firstName": "Alan",
                            "lastName": "Hoffman",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Hoffman"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 58,
                                "start": 33
                            }
                        ],
                        "text": "Spectral clustering goes back to Donath and Hoffman (1973), who first suggested to construct graph partitions based on eigenvectors of the adjacency matrix."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 89,
                                "start": 63
                            }
                        ],
                        "text": "9 Outlook and further reading Spectral clustering goes back to Donath and Hoffman (1973), who first suggested to construct graph partitions based on eigenvectors of the adjacency matrix."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 563,
                                "start": 63
                            }
                        ],
                        "text": "9 Outlook and further reading Spectral clustering goes back to Donath and Hoffman (1973), who first suggested to construct graph partitions based on eigenvectors of the adjacency matrix. In the same year, Fiedler (1973) discovered that bi-partitions of a graph are closely connected with the second eigenvector of the graph Laplacian, and he suggested to use this eigenvector to partition a graph. Since then, spectral clustering has been discovered, re-discovered, and extended many times in different communities, see for example Pothen, Simon, and Liou (1990), Simon (1991), Bolla (1991), Hagen and Kahng (1992), Hendrickson and Leland (1995), Van Driessche and Roose (1995), Barnard, Pothen, and Simon (1995), Spielman and Teng (1996), Guattery and Miller (1998)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 220,
                                "start": 63
                            }
                        ],
                        "text": "9 Outlook and further reading Spectral clustering goes back to Donath and Hoffman (1973), who first suggested to construct graph partitions based on eigenvectors of the adjacency matrix. In the same year, Fiedler (1973) discovered that bi-partitions of a graph are closely connected with the second eigenvector of the graph Laplacian, and he suggested to use this eigenvector to partition a graph."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 122138297,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "c78e2e401b3e2b1f9efdc250a5d82607b659bf5e",
            "isKey": true,
            "numCitedBy": 688,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "Let a k-partition of a graph be a division of the vertices into k disjoint subsets containing m1 \u2265 m2,..., \u2265mk vertices. Let Ec be the number of edges whose two vertices belong to different subsets. Let \u03bb1 \u2265 \u03bb2, ..., \u2265 \u03bbk, be the k largest eigenvalues of a matrix, which is the sum of the adjacency matrix of the graph plus any diagonal matrix U such that the suomf all the elements of the sum matrix is zero. Then Ec \u2265 1/2\u03a3r=1k-mr\u03bbr. \n \nA theorem is given that shows the effect of the maximum degree of any node being limited, and it is also shown that the right-hand side is a concave function of U.C omputational studies are madoef the ratio of upper bound to lower bound for the two-partition of a number of random graphs having up to 100 nodes."
            },
            "slug": "Lower-bounds-for-the-partitioning-of-graphs-Donath-Hoffman",
            "title": {
                "fragments": [],
                "text": "Lower bounds for the partitioning of graphs"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1973
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1680188"
                        ],
                        "name": "T. Joachims",
                        "slug": "T.-Joachims",
                        "structuredName": {
                            "firstName": "Thorsten",
                            "lastName": "Joachims",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Joachims"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 155,
                                "start": 141
                            }
                        ],
                        "text": "\u2026for example spectral clustering applied to the co-clustering problem (Dhillon, 2001), spectral clustering with additional side information (Joachims, 2003) connections between spectral clustering and the weighted kernel-k-means algorithm (Dhillon, Guan, and Kulis, 2005), learning\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 236,
                                "start": 221
                            }
                        ],
                        "text": "Subsequently, spectral clustering has been extended to many non-standard settings, for example spectral clustering applied to the co-clustering problem (Dhillon 2001), spectral clustering with additional side information (Joachims 2003) connections between spectral clustering and the weighted kernel-k-means algorithm (Dhillon et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 6027413,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "49b8dff62cccc26023c876460234bf29084a382f",
            "isKey": false,
            "numCitedBy": 734,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a new method for transductive learning, which can be seen as a transductive version of the k nearest-neighbor classifier. Unlike for many other transductive learning methods, the training problem has a meaningful relaxation that can be solved globally optimally using spectral methods. We propose an algorithm that robustly achieves good generalization performance and that can be trained efficiently. A key advantage of the algorithm is that it does not require additional heuristics to avoid unbalanced splits. Furthermore, we show a connection to transductive Support Vector Machines, and that an effective Co-Training algorithm arises as a special case."
            },
            "slug": "Transductive-Learning-via-Spectral-Graph-Joachims",
            "title": {
                "fragments": [],
                "text": "Transductive Learning via Spectral Graph Partitioning"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This work proposes an algorithm that robustly achieves good generalization performance and that can be trained efficiently, and shows a connection to transductive Support Vector Machines, and that an effective Co-Training algorithm arises as a special case."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1836534"
                        ],
                        "name": "L. Hagen",
                        "slug": "L.-Hagen",
                        "structuredName": {
                            "firstName": "Lars",
                            "lastName": "Hagen",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Hagen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1730778"
                        ],
                        "name": "A. Kahng",
                        "slug": "A.-Kahng",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Kahng",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Kahng"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 90,
                                "start": 69
                            }
                        ],
                        "text": "The two most common objective functions to encode this are RatioCut (Hagen and Kahng, 1992) and the normalized cut Ncut (Shi and Malik, 2000)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 164,
                                "start": 142
                            }
                        ],
                        "text": "\u2026re-discovered, and extended many times in different communities, see for example Pothen, Simon, and Liou (1990), Simon (1991), Bolla (1991), Hagen and Kahng (1992), Hendrickson and Leland (1995), Van Driessche and Roose (1995), Barnard, Pothen, and Simon (1995), Spielman and Teng (1996),\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 60,
                                "start": 38
                            }
                        ],
                        "text": "functions to encode this are RatioCut (Hagen and Kahng 1992) and the normalized cut Ncut (Shi and Malik 2000)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 17757903,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "36278bf6919c6dced7d16dc0c02d725e1ed178f8",
            "isKey": true,
            "numCitedBy": 1153,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "Partitioning of circuit netlists in VLSI design is considered. It is shown that the second smallest eigenvalue of a matrix derived from the netlist gives a provably good approximation of the optimal ratio cut partition cost. It is also demonstrated that fast Lanczos-type methods for the sparse symmetric eigenvalue problem are a robust basis for computing heuristic ratio cuts based on the eigenvector of this second eigenvalue. Effective clustering methods are an immediate by-product of the second eigenvector computation and are very successful on the difficult input classes proposed in the CAD literature. The intersection graph representation of the circuit netlist is considered, as a basis for partitioning, a heuristic based on spectral ratio cut partitioning of the netlist intersection graph is proposed. The partitioning heuristics were tested on industry benchmark suites, and the results were good in terms of both solution quality and runtime. Several types of algorithmic speedups and directions for future work are discussed. >"
            },
            "slug": "New-spectral-methods-for-ratio-cut-partitioning-and-Hagen-Kahng",
            "title": {
                "fragments": [],
                "text": "New spectral methods for ratio cut partitioning and clustering"
            },
            "tldr": {
                "abstractSimilarityScore": 60,
                "text": "It is shown that the second smallest eigenvalue of a matrix derived from the netlist gives a provably good approximation of the optimal ratio cut partition cost."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Comput. Aided Des. Integr. Circuits Syst."
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143660088"
                        ],
                        "name": "B. Hendrickson",
                        "slug": "B.-Hendrickson",
                        "structuredName": {
                            "firstName": "Bruce",
                            "lastName": "Hendrickson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Hendrickson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1764206"
                        ],
                        "name": "R. Leland",
                        "slug": "R.-Leland",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Leland",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Leland"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 81,
                                "start": 68
                            }
                        ],
                        "text": "This intuition has been made precise in the works of Belkin (2003), Lafon (2004), Hein, Audibert, and von Luxburg (2005), Belkin and Niyogi (2005), Hein (2006), Gin\u00e9 and Koltchinskii (2005)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 49,
                                "start": 11
                            }
                        ],
                        "text": "In Nadler, Lafon, Coifman, and Kevrekidis (2006), the authors show that the Euclidean distances between the yi are also related to a more general \u201cdiffusion distance\u201d."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 126,
                                "start": 119
                            }
                        ],
                        "text": "We have seen that the Euclidean distance between the points yi is related to the \u201ccommute distance\u201d on the graph, and in Nadler, Lafon, Coifman, and Kevrekidis (2006) the authors show that the Euclidean distances between the yi are also related to a more general \u201cdiffusion distance\u201d."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 308,
                                "start": 11
                            }
                        ],
                        "text": "In Nadler, Lafon, Coifman, and Kevrekidis (2006), the authors show that the Euclidean distances between the yi are also related to a more general \u201cdiffusion distance\u201d. The spectral embedding also turns out to be a solution of several optimization problems on the graph, for further examples see Bolla (1991) or Belkin and Niyogi (2003)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 21601726,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4e892deef85c4cb62716776657d66dc417574bcc",
            "isKey": true,
            "numCitedBy": 605,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "Efficient use of a distributed memory parallel computer requires that the computational load be balanced across processors in a way that minimizes interprocessor communication. A new domain mapping algorithm is presented that extends recent work in which ideas from spectral graph theory have been applied to this problem. The generalization of spectral graph bisection involves a novel use of multiple eigenvectors to allow for division of a computation into four or eight parts at each stage of a recursive decomposition. The resulting method is suitable for scientific computations like irregular finite elements or differences performed on hypercube or mesh architecture machines. Experimental results confirm that the new method provides better decompositions arrived at more economically and robustly than with previous spectral methods. This algorithm allows for arbitrary nonnegative weights on both vertices and edges to model inhomogeneous computation and communication. A new spectral lower bound for graph bi..."
            },
            "slug": "An-Improved-Spectral-Graph-Partitioning-Algorithm-Hendrickson-Leland",
            "title": {
                "fragments": [],
                "text": "An Improved Spectral Graph Partitioning Algorithm for Mapping Parallel Computations"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "A new domain mapping algorithm is presented that extends recent work in which ideas from spectral graph theory have been applied to this problem and provides better decompositions arrived at more economically and robustly than with previous spectral methods."
            },
            "venue": {
                "fragments": [],
                "text": "SIAM J. Sci. Comput."
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39713260"
                        ],
                        "name": "Tilman Lange",
                        "slug": "Tilman-Lange",
                        "structuredName": {
                            "firstName": "Tilman",
                            "lastName": "Lange",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tilman Lange"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716159"
                        ],
                        "name": "Volker Roth",
                        "slug": "Volker-Roth",
                        "structuredName": {
                            "firstName": "Volker",
                            "lastName": "Roth",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Volker Roth"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2522031"
                        ],
                        "name": "M. Braun",
                        "slug": "M.-Braun",
                        "structuredName": {
                            "firstName": "Mikio",
                            "lastName": "Braun",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Braun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1682548"
                        ],
                        "name": "J. Buhmann",
                        "slug": "J.-Buhmann",
                        "structuredName": {
                            "firstName": "Joachim",
                            "lastName": "Buhmann",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Buhmann"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 132,
                                "start": 115
                            }
                        ],
                        "text": "In the machine learning community, spectral clustering has been made popular by the works of Shi and Malik (2000), Ng et al. (2002), Meila and Shi (2001), and Ding (2004)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2506239,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "890e3eb158d5bdfa3042869962d5838ae81be7fe",
            "isKey": false,
            "numCitedBy": 466,
            "numCiting": 57,
            "paperAbstract": {
                "fragments": [],
                "text": "Data clustering describes a set of frequently employed techniques in exploratory data analysis to extract natural group structure in data. Such groupings need to be validated to separate the signal in the data from spurious structure. In this context, finding an appropriate number of clusters is a particularly important model selection question. We introduce a measure of cluster stability to assess the validity of a cluster model. This stability measure quantifies the reproducibility of clustering solutions on a second sample, and it can be interpreted as a classification risk with regard to class labels produced by a clustering algorithm. The preferred number of clusters is determined by minimizing this classification risk as a function of the number of clusters. Convincing results are achieved on simulated as well as gene expression data sets. Comparisons to other methods demonstrate the competitive performance of our method and its suitability as a general validation tool for clustering solutions in real-world problems."
            },
            "slug": "Stability-Based-Validation-of-Clustering-Solutions-Lange-Roth",
            "title": {
                "fragments": [],
                "text": "Stability-Based Validation of Clustering Solutions"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A measure of cluster stability is introduced to assess the validity of a cluster model and its suitability as a general validation tool for clustering solutions in real-world problems."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "69944961"
                        ],
                        "name": "L. Asz",
                        "slug": "L.-Asz",
                        "structuredName": {
                            "firstName": "L",
                            "lastName": "Asz",
                            "middleNames": [
                                "Lov"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Asz"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 125,
                                "start": 112
                            }
                        ],
                        "text": "For example a method in terms of eigenvectors of the normalized Laplacian Lsym can be found as Corollary 3.2 in Lova\u0301sz (1993), and a method computing the commute distance with the help of determinants of certain sub-matrices of L can be found in Bapat, Gutman, and Xiao (2003)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 190,
                                "start": 177
                            }
                        ],
                        "text": "For background reading on random walks in general we refer to Norris (1997) and Bre\u0301maud (1999), and for random walks on graphs we recommend Aldous and Fill (in preparation) and Lova\u0301sz (1993)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 147,
                                "start": 134
                            }
                        ],
                        "text": "It is well known that many properties of a graph can be expressed in terms of the corresponding random walk transition matrix P , see Lova\u0301sz (1993) for an overview."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 196,
                                "start": 184
                            }
                        ],
                        "text": "The commute distance (also called resistance distance) cij between two vertices vi and vj is the expected time it takes the random walk to travel from vertex vi to vertex vj and back (Lova\u0301sz, 1993; Aldous and Fill, in preparation)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 10655982,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "30fa728cb99afaa43f7f2ed291d6e06a85663cca",
            "isKey": true,
            "numCitedBy": 1345,
            "numCiting": 65,
            "paperAbstract": {
                "fragments": [],
                "text": "Dedicated to the marvelous random walk of Paul Erd} os through universities, c ontinents, and mathematics Various aspects of the theory of random walks on graphs are surveyed. In particular, estimates on the important parameters of access time, commute time, cover time and mixing time are discussed. Connections with the eigenvalues of graphs and with electrical networks, and the use of these connections in the study of random walks is described. We also sketch recent algorithmic applications of random walks, in particular to the problem of sampling. 0. Introduction Given a graph and a starting point, we select a neighbor of it at random, and move to this neighborr then we s e l e c t a n e i g h bor of this point at random, and move to it etc. The (random) sequence of points selected this way i s a random walk on the graph. A random walk is a nite Markov c hain that is time-reversible (see below). In fact, there is not much diierence between the theory of random walks on graphs and the theory of nite Markov c hainss every Markov c hain can be viewed as random walk on a directed graph, if we a l l o w w eighted edges. Similarly, time-reversible Markov c hains can be viewed as random walks on undirected graphs, and symmetric Markov c hains, as random walks on regular symmetric graphs. In this paper we'll formulate the results in terms of random walks, and mostly restrict our attention to the undirected case. 2 L. Lovv asz Random walks arise in many models in mathematics and physics. In fact, this is one of those notions that tend to pop up everywhere once you begin to look for them. For example, consider the shuuing of a deck o f cards. Construct a graph whose nodes are all permutations of the deck, and two of them are adjacent if they come by one shuue move (depending on how y ou shuue). Then repeated shuue moves correspond to a random walk on this graph (see Diaconis 20]). The Brownian motion of a dust particle is random walk in the room. Models in statistical mechanics can be viewed as random walks on the set of states. The classical theory of random walks deals with random walks on simple , but innnite graphs, like grids, and studies their qualitative b \u2026"
            },
            "slug": "Random-Walks-on-Graphs:-a-Survey-Asz",
            "title": {
                "fragments": [],
                "text": "Random Walks on Graphs: a Survey"
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1725557"
                        ],
                        "name": "L. Lov\u00e1sz",
                        "slug": "L.-Lov\u00e1sz",
                        "structuredName": {
                            "firstName": "L\u00e1szl\u00f3",
                            "lastName": "Lov\u00e1sz",
                            "middleNames": [
                                "Mikl\u00f3s"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Lov\u00e1sz"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 125,
                                "start": 112
                            }
                        ],
                        "text": "For example a method in terms of eigenvectors of the normalized Laplacian Lsym can be found as Corollary 3.2 in Lova\u0301sz (1993), and a method computing the commute distance with the help of determinants of certain sub-matrices of L can be found in Bapat, Gutman, and Xiao (2003)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 190,
                                "start": 177
                            }
                        ],
                        "text": "For background reading on random walks in general we refer to Norris (1997) and Bre\u0301maud (1999), and for random walks on graphs we recommend Aldous and Fill (in preparation) and Lova\u0301sz (1993)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 147,
                                "start": 134
                            }
                        ],
                        "text": "It is well known that many properties of a graph can be expressed in terms of the corresponding random walk transition matrix P , see Lova\u0301sz (1993) for an overview."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 196,
                                "start": 184
                            }
                        ],
                        "text": "The commute distance (also called resistance distance) cij between two vertices vi and vj is the expected time it takes the random walk to travel from vertex vi to vertex vj and back (Lova\u0301sz, 1993; Aldous and Fill, in preparation)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15649209,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "86fb6d3152a9849444f2301c91ddce5b97ce611b",
            "isKey": true,
            "numCitedBy": 880,
            "numCiting": 76,
            "paperAbstract": {
                "fragments": [],
                "text": "Various aspects of the theory of random walks on graphs are surveyed. In particular, estimates on the important parameters of access time, commute time, cover time and mixing time are discussed. Connections with the eigenvalues of graphs and with electrical networks, and the use of these connections in the study of random walks is described. We also sketch recent algorithmic applications of random walks, in particular to the problem of sampling."
            },
            "slug": "Random-Walks-on-Graphs:-A-Survey-Lov\u00e1sz",
            "title": {
                "fragments": [],
                "text": "Random Walks on Graphs: A Survey"
            },
            "tldr": {
                "abstractSimilarityScore": 59,
                "text": "Estimates on the important parameters of access time, commute time, cover time and mixing time are discussed and recent algorithmic applications of random walks are sketched, in particular to the problem of sampling."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144228103"
                        ],
                        "name": "I. Gutman",
                        "slug": "I.-Gutman",
                        "structuredName": {
                            "firstName": "Ivan",
                            "lastName": "Gutman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Gutman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3457258"
                        ],
                        "name": "W. Xiao",
                        "slug": "W.-Xiao",
                        "structuredName": {
                            "firstName": "Wenjun",
                            "lastName": "Xiao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Xiao"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 409,
                                "start": 33
                            }
                        ],
                        "text": "For further properties of L\u2020 see Gutman and Xiao (2004). Proposition 6 (Commute distance) Let G = (V,E) a connected, undirected graph. Denote by cij the commute distance between vertex vi and vertex vj, and by L\u2020 = (l \u2020 ij)i,j=1,...,n the generalized inverse of L. Then we have: cij = vol(V )(l \u2020 ii \u2212 2l \u2020 ij + l \u2020 jj) = vol(V )(ei \u2212 ej) L(ei \u2212 ej). This result has been published by Klein and Randic (1993), where it has been proved by methods of electrical network theory."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 579,
                                "start": 33
                            }
                        ],
                        "text": "For further properties of L\u2020 see Gutman and Xiao (2004). Proposition 6 (Commute distance) Let G = (V,E) a connected, undirected graph. Denote by cij the commute distance between vertex vi and vertex vj, and by L\u2020 = (l \u2020 ij)i,j=1,...,n the generalized inverse of L. Then we have: cij = vol(V )(l \u2020 ii \u2212 2l \u2020 ij + l \u2020 jj) = vol(V )(ei \u2212 ej) L(ei \u2212 ej). This result has been published by Klein and Randic (1993), where it has been proved by methods of electrical network theory. For a proof using first step analysis for random walks see Fouss, Pirotte, Renders, and Saerens (2007). There also exist other ways to express the commute distance with the help of graph Laplacians."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 56,
                                "start": 33
                            }
                        ],
                        "text": "For further properties of L\u2020 see Gutman and Xiao (2004). Proposition 6 (Commute distance) Let G = (V,E) a connected, undirected graph."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 54,
                                "start": 32
                            }
                        ],
                        "text": "For further properties of L\u2020 see Gutman and Xiao (2004)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 801,
                                "start": 33
                            }
                        ],
                        "text": "For further properties of L\u2020 see Gutman and Xiao (2004). Proposition 6 (Commute distance) Let G = (V,E) a connected, undirected graph. Denote by cij the commute distance between vertex vi and vertex vj, and by L\u2020 = (l \u2020 ij)i,j=1,...,n the generalized inverse of L. Then we have: cij = vol(V )(l \u2020 ii \u2212 2l \u2020 ij + l \u2020 jj) = vol(V )(ei \u2212 ej) L(ei \u2212 ej). This result has been published by Klein and Randic (1993), where it has been proved by methods of electrical network theory. For a proof using first step analysis for random walks see Fouss, Pirotte, Renders, and Saerens (2007). There also exist other ways to express the commute distance with the help of graph Laplacians. For example a method in terms of eigenvectors of the normalized Laplacian Lsym can be found as Corollary 3.2 in Lov\u00e1sz (1993), and a method computing the commute distance with the help of determinants of certain sub-matrices of L can be found in Bapat, Gutman, and Xiao (2003)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 294235,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "17d8f1624edc2d8f5c3e002377faebf01ca5a639",
            "isKey": true,
            "numCitedBy": 116,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": "The generalized inverse L\u2020 of the Laplacian matrix of a connected graph is examined and some of its properties are established. In some physical and chemical considerations the quantity rij = {L\u2020)ii + (L\u2020)jj \u2014 (L\u2020)ij - (L\u2020)ji is encountered; it is called resistance distance. Based on the results obtained for L\u2020 we prove some previously known and deduce some new properties of the resistance distance. ."
            },
            "slug": "Generalized-inverse-of-the-Laplacian-matrix-and-Gutman-Xiao",
            "title": {
                "fragments": [],
                "text": "Generalized inverse of the Laplacian matrix and some applications"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144591388"
                        ],
                        "name": "M. R. Brito",
                        "slug": "M.-R.-Brito",
                        "structuredName": {
                            "firstName": "M.",
                            "lastName": "Brito",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. R. Brito"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144252965"
                        ],
                        "name": "Edgar Ch\u00e1vez",
                        "slug": "Edgar-Ch\u00e1vez",
                        "structuredName": {
                            "firstName": "Edgar",
                            "lastName": "Ch\u00e1vez",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Edgar Ch\u00e1vez"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46913531"
                        ],
                        "name": "A. Quiroz",
                        "slug": "A.-Quiroz",
                        "structuredName": {
                            "firstName": "Adolfo",
                            "lastName": "Quiroz",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Quiroz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145535366"
                        ],
                        "name": "J. Yukich",
                        "slug": "J.-Yukich",
                        "structuredName": {
                            "firstName": "Joseph",
                            "lastName": "Yukich",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Yukich"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 122382498,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8880c03fa42bd073a5efe6fdd0f500d887886cae",
            "isKey": false,
            "numCitedBy": 225,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Connectivity-of-the-mutual-k-nearest-neighbor-graph-Brito-Ch\u00e1vez",
            "title": {
                "fragments": [],
                "text": "Connectivity of the mutual k-nearest-neighbor graph in clustering and outlier detection"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1770745"
                        ],
                        "name": "P. Niyogi",
                        "slug": "P.-Niyogi",
                        "structuredName": {
                            "firstName": "Partha",
                            "lastName": "Niyogi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Niyogi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145520115"
                        ],
                        "name": "Mikhail Belkin",
                        "slug": "Mikhail-Belkin",
                        "structuredName": {
                            "firstName": "Mikhail",
                            "lastName": "Belkin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mikhail Belkin"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 376,
                                "start": 14
                            }
                        ],
                        "text": "Bolla 1991 or Belkin and Niyogi 2003) show that the Euclidean distance in R is meaningful. Instead of k-means, people also use other techniques to construct he final solution from the real-valued representation. For example, in Lang (2006) the authors use hyperplanes for this purpose. A more advanced post-processing of the eigenvectors is proposed in Bach and Jordan (2004). Here the authors study the subspace spanned by the first k eigenvectors, and try to approximate this subspace as well as possible using piecewise constant vectors."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 240,
                                "start": 14
                            }
                        ],
                        "text": "Bolla 1991 or Belkin and Niyogi 2003) show that the Euclidean distance in R is meaningful. Instead of k-means, people also use other techniques to construct he final solution from the real-valued representation. For example, in Lang (2006) the authors use hyperplanes for this purpose."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 13,
                                "start": 0
                            }
                        ],
                        "text": "Belkin (2003) studied the first important step of the convergence proof, which deals with the convergence of a continuous operator related to discrete graph Laplacians to the Laplace-Beltrami operator."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 66,
                                "start": 53
                            }
                        ],
                        "text": "This intuition has been made precise in the works of Belkin (2003), Lafon (2004), Hein, Audibert, and von Luxburg (2005); M., Audibert, and von Luxburg (2007), Belkin and Niyogi (2005), Hein (2006), Gine\u0301 and Koltchinskii (2005)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 118947079,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "0b74dd2397001588673891771de6c221fb91a894",
            "isKey": true,
            "numCitedBy": 144,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "This thesis discusses the general problem of learning a function on a manifold given by data points. The space of functions on a Riemannian manifold has a family of smoothness functionals and a canonical basis associated to the Laplace-Beltrami operator. Moreover, the Laplace-Beltrami operator can be reconstructed with certain convergence guarantees when the manifold is only known through the sampled data points. This allows the techniques of regularization and Fourier analysis to be applied to functions defined on data. A convergence result is proved for the case when data is sampled from a compact submanifold of R\u2227k . Several applications are considered."
            },
            "slug": "Problems-of-learning-on-manifolds-Niyogi-Belkin",
            "title": {
                "fragments": [],
                "text": "Problems of learning on manifolds"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1730609"
                        ],
                        "name": "O. Chapelle",
                        "slug": "O.-Chapelle",
                        "structuredName": {
                            "firstName": "Olivier",
                            "lastName": "Chapelle",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Chapelle"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "66191239"
                        ],
                        "name": "Bernhard Schlkopf",
                        "slug": "Bernhard-Schlkopf",
                        "structuredName": {
                            "firstName": "Bernhard",
                            "lastName": "Schlkopf",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bernhard Schlkopf"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2281542"
                        ],
                        "name": "A. Zien",
                        "slug": "A.-Zien",
                        "structuredName": {
                            "firstName": "Alexander",
                            "lastName": "Zien",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Zien"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 197,
                                "start": 187
                            }
                        ],
                        "text": "In the field of machine learning, graph Laplacians are not only used for clustering, but also emerge for many other tasks such as semi-supervised learning (e.g., Chapelle, Scho\u0308lkopf, and Zien, 2006 for an overview) or manifold reconstruction (e.g., Belkin and Niyogi, 2003)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 60860751,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5ee8a371fc5adc5469435020a52fb815f3b57a71",
            "isKey": false,
            "numCitedBy": 2539,
            "numCiting": 473,
            "paperAbstract": {
                "fragments": [],
                "text": "In the field of machine learning, semi-supervised learning (SSL) occupies the middle ground, between supervised learning (in which all training examples are labeled) and unsupervised learning (in which no label data are given). Interest in SSL has increased in recent years, particularly because of application domains in which unlabeled data are plentiful, such as images, text, and bioinformatics. This first comprehensive overview of SSL presents state-of-the-art algorithms, a taxonomy of the field, selected applications, benchmark experiments, and perspectives on ongoing and future research. Semi-Supervised Learning first presents the key assumptions and ideas underlying the field: smoothness, cluster or low-density separation, manifold structure, and transduction. The core of the book is the presentation of SSL methods, organized according to algorithmic strategies. After an examination of generative models, the book describes algorithms that implement the low-density separation assumption, graph-based methods, and algorithms that perform two-step learning. The book then discusses SSL applications and offers guidelines for SSL practitioners by analyzing the results of extensive benchmark experiments. Finally, the book looks at interesting directions for SSL research. The book closes with a discussion of the relationship between semi-supervised learning and transduction. Adaptive Computation and Machine Learning series"
            },
            "slug": "Semi-Supervised-Learning-Chapelle-Schlkopf",
            "title": {
                "fragments": [],
                "text": "Semi-Supervised Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "This first comprehensive overview of semi-supervised learning presents state-of-the-art algorithms, a taxonomy of the field, selected applications, benchmark experiments, and perspectives on ongoing and future research."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1761784"
                        ],
                        "name": "R. Tibshirani",
                        "slug": "R.-Tibshirani",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Tibshirani",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Tibshirani"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145069347"
                        ],
                        "name": "G. Walther",
                        "slug": "G.-Walther",
                        "structuredName": {
                            "firstName": "Guenther",
                            "lastName": "Walther",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Walther"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1784682"
                        ],
                        "name": "T. Hastie",
                        "slug": "T.-Hastie",
                        "structuredName": {
                            "firstName": "Trevor",
                            "lastName": "Hastie",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Hastie"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 184,
                                "start": 147
                            }
                        ],
                        "text": "\u2026as the ratio of within-cluster and between-cluster similarities, over information-theoretic criteria (Still and Bialek, 2004), the gap statistic (Tibshirani, Walther, and Hastie, 2001), to stability approaches (Ben-Hur, Elisseeff, and Guyon, 2002; Lange, Roth,\n10 Histogram of the sample\n10\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Choosing the number k of clusters is a general problem for all clustering algorithms, and a variety of more or less successful methods have been devised for this problem, for example the gap statistic in  Tibshirani, Walther, and Hastie (2001)  (note that this gap has nothing to do with the eigengap), or stability approaches, see Ben-Hur, Elisseeff, and Guyon (2002), Lange, Roth, Braun, and Buhmann (2004), but also Ben-David, von Luxburg, ..."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 59738652,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e8020b85160eda580566053404cb5c32ad19c62c",
            "isKey": false,
            "numCitedBy": 4607,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a method (the \u2018gap statistic\u2019) for estimating the number of clusters (groups) in a set of data. The technique uses the output of any clustering algorithm (e.g. K\u2010means or hierarchical), comparing the change in within\u2010cluster dispersion with that expected under an appropriate reference null distribution. Some theory is developed for the proposal and a simulation study shows that the gap statistic usually outperforms other methods that have been proposed in the literature."
            },
            "slug": "Estimating-the-number-of-clusters-in-a-data-set-via-Tibshirani-Walther",
            "title": {
                "fragments": [],
                "text": "Estimating the number of clusters in a data set via the gap statistic"
            },
            "tldr": {
                "abstractSimilarityScore": 59,
                "text": "The gap statistic is proposed for estimating the number of clusters (groups) in a set of data by comparing the change in within\u2010cluster dispersion with that expected under an appropriate reference null distribution."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "66455819"
                        ],
                        "name": "R. V. Driessche",
                        "slug": "R.-V.-Driessche",
                        "structuredName": {
                            "firstName": "Raf",
                            "lastName": "Driessche",
                            "middleNames": [
                                "Van"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. V. Driessche"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145890103"
                        ],
                        "name": "D. Roose",
                        "slug": "D.-Roose",
                        "structuredName": {
                            "firstName": "Dirk",
                            "lastName": "Roose",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Roose"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 208,
                                "start": 178
                            }
                        ],
                        "text": "\u2026extended many times in different communities, see for example Pothen, Simon, and Liou (1990), Simon (1991), Bolla (1991), Hagen and Kahng (1992), Hendrickson and Leland (1995), Van Driessche and Roose (1995), Barnard, Pothen, and Simon (1995), Spielman and Teng (1996), Guattery and Miller (1998)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 33632401,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "be1e3222a563b34856bf6094b8a131657b0b2916",
            "isKey": false,
            "numCitedBy": 111,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "An-Improved-Spectral-Bisection-Algorithm-and-its-to-Driessche-Roose",
            "title": {
                "fragments": [],
                "text": "An Improved Spectral Bisection Algorithm and its Application to Dynamic Load Balancing"
            },
            "venue": {
                "fragments": [],
                "text": "EUROSIM"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1979860"
                        ],
                        "name": "T. N. Bui",
                        "slug": "T.-N.-Bui",
                        "structuredName": {
                            "firstName": "Thang",
                            "lastName": "Bui",
                            "middleNames": [
                                "Nguyen"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. N. Bui"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2109380700"
                        ],
                        "name": "Curt Jones",
                        "slug": "Curt-Jones",
                        "structuredName": {
                            "firstName": "Curt",
                            "lastName": "Jones",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Curt Jones"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 32060994,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "id": "95a8b859d6fdc8d5fbf5bffd5a42717321c31444",
            "isKey": false,
            "numCitedBy": 315,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Finding-Good-Approximate-Vertex-and-Edge-Partitions-Bui-Jones",
            "title": {
                "fragments": [],
                "text": "Finding Good Approximate Vertex and Edge Partitions is NP-Hard"
            },
            "venue": {
                "fragments": [],
                "text": "Inf. Process. Lett."
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144895838"
                        ],
                        "name": "M. Penrose",
                        "slug": "M.-Penrose",
                        "structuredName": {
                            "firstName": "Mathew",
                            "lastName": "Penrose",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Penrose"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 154,
                                "start": 141
                            }
                        ],
                        "text": "Similar arguments show that the parameter \u03b5 in the \u03b5-neighborhood graph has to be chosen as (log(n)/n)d to guarantee connectivity in the limit (Penrose, 1999)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 157,
                                "start": 142
                            }
                        ],
                        "text": "Similar arguments show that the parameter \u03b5 in the \u03b5-neighborhood graph has to be chosen as (log(n)/n) to guarantee connectivity in the limit (Penrose, 1999)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 121526341,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "8ee2aa2195d0d0e7832dd30d8dee9f9a9b972ed8",
            "isKey": false,
            "numCitedBy": 120,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "Suppose X 1 , X 2 , X are independent random points in Rd, d > 2, with common density f, having connected compact support \u03a9 with smooth boundary \u2202\u03a9, with f|\u03a9 continuous. Let M n denote the smallest r such that the union of balls of diameter r centered at the first n points is connected. Let \u03b8 denote the volume of the unit ball. Then as n \u2192 \u221e, n\u03b8M d a /log n \u2192 max((min f) -1 , 2(1 - 1/d)(min f) -1 ), a.s."
            },
            "slug": "A-Strong-Law-for-the-Longest-Edge-of-the-Minimal-Penrose",
            "title": {
                "fragments": [],
                "text": "A Strong Law for the Longest Edge of the Minimal Spanning Tree"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144990404"
                        ],
                        "name": "D. Aldous",
                        "slug": "D.-Aldous",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Aldous",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Aldous"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 118128743,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "fa7e9af14a46e07db867d9d01cd885e02a06fd62",
            "isKey": false,
            "numCitedBy": 956,
            "numCiting": 184,
            "paperAbstract": {
                "fragments": [],
                "text": "For simple random walk on aN-vertex graph, the mean time to cover all vertices is at leastcN log(N), wherec>0 is an absolute constant. This is deduced from a more general result about stationary finite-state reversible Markov chains. Under weak conditions, the covering time for such processes is at leastc times the covering time for the corresponding i.i.d. process."
            },
            "slug": "Lower-bounds-for-covering-times-for-reversible-and-Aldous",
            "title": {
                "fragments": [],
                "text": "Lower bounds for covering times for reversible Markov chains and random walks on graphs"
            },
            "tldr": {
                "abstractSimilarityScore": 97,
                "text": "For simple random walk on aN-vertex graph, the mean time to cover all vertices is at leastcN log(N), wherec>0 is an absolute constant, deduced from a more general result about stationary finite-state reversible Markov chains."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3444394"
                        ],
                        "name": "E. Ziegel",
                        "slug": "E.-Ziegel",
                        "structuredName": {
                            "firstName": "Eric",
                            "lastName": "Ziegel",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Ziegel"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 27,
                                "start": 15
                            }
                        ],
                        "text": "Niyogi (2005), Hein (2006), Gin\u00e9 and Koltchinskii (2005)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 124,
                                "start": 103
                            }
                        ],
                        "text": "Readers not familiar with k-means can read up on this algorithm in numerous text books, for example in Hastie et al. (2001). Before we dive into the theory of spectral clustering, we would like to illustrate its principle on a very simple toy example."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 142,
                                "start": 103
                            }
                        ],
                        "text": "Readers not familiar with k-means can read up on this algorithm in numerous\ntext books, for example in Hastie, Tibshirani, and Friedman (2001)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 46701966,
            "fieldsOfStudy": [
                "Business"
            ],
            "id": "e41ba5dc12c79a64dfa905c0328f95976252ffe0",
            "isKey": true,
            "numCitedBy": 12393,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "Chapter 11 includes more case studies in other areas, ranging from manufacturing to marketing research. Chapter 12 concludes the book with some commentary about the scienti\u008e c contributions of MTS. The Taguchi method for design of experiment has generated considerable controversy in the statistical community over the past few decades. The MTS/MTGS method seems to lead another source of discussions on the methodology it advocates (Montgomery 2003). As pointed out by Woodall et al. (2003), the MTS/MTGS methods are considered ad hoc in the sense that they have not been developed using any underlying statistical theory. Because the \u201cnormal\u201d and \u201cabnormal\u201d groups form the basis of the theory, some sampling restrictions are fundamental to the applications. First, it is essential that the \u201cnormal\u201d sample be uniform, unbiased, and/or complete so that a reliable measurement scale is obtained. Second, the selection of \u201cabnormal\u201d samples is crucial to the success of dimensionality reduction when OAs are used. For example, if each abnormal item is really unique in the medical example, then it is unclear how the statistical distance MD can be guaranteed to give a consistent diagnosis measure of severity on a continuous scale when the larger-the-better type S/N ratio is used. Multivariate diagnosis is not new to Technometrics readers and is now becoming increasingly more popular in statistical analysis and data mining for knowledge discovery. As a promising alternative that assumes no underlying data model, The Mahalanobis\u2013Taguchi Strategy does not provide suf\u008e cient evidence of gains achieved by using the proposed method over existing tools. Readers may be very interested in a detailed comparison with other diagnostic tools, such as logistic regression and tree-based methods. Overall, although the idea of MTS/MTGS is intriguing, this book would be more valuable had it been written in a rigorous fashion as a technical reference. There is some lack of precision even in several mathematical notations. Perhaps a follow-up with additional theoretical justi\u008e cation and careful case studies would answer some of the lingering questions."
            },
            "slug": "The-Elements-of-Statistical-Learning-Ziegel",
            "title": {
                "fragments": [],
                "text": "The Elements of Statistical Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 69,
                "text": "Chapter 11 includes more case studies in other areas, ranging from manufacturing to marketing research, and a detailed comparison with other diagnostic tools, such as logistic regression and tree-based methods."
            },
            "venue": {
                "fragments": [],
                "text": "Technometrics"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1679611"
                        ],
                        "name": "D. Wagner",
                        "slug": "D.-Wagner",
                        "structuredName": {
                            "firstName": "Dorothea",
                            "lastName": "Wagner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Wagner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143854501"
                        ],
                        "name": "Frank Wagner",
                        "slug": "Frank-Wagner",
                        "structuredName": {
                            "firstName": "Frank",
                            "lastName": "Wagner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Frank Wagner"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 144,
                                "start": 120
                            }
                        ],
                        "text": "Unfortunately, introducing balancing conditions makes the previously simple to solve mincut problem\nbecome NP hard, see Wagner and Wagner (1993) for a discussion."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 145,
                                "start": 120
                            }
                        ],
                        "text": "Unfortunately, introducing balancing conditions makes the previously simple to solve mincut problem become NP hard, see Wagner and Wagner (1993) for a discussion."
                    },
                    "intents": []
                }
            ],
            "corpusId": 206637578,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "c4c9f645ca334f03b27d6ca646ba7e32fa323aa3",
            "isKey": false,
            "numCitedBy": 181,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "We investigate a class of graph partitioning problems whose two extreme representatives are the well-known Min Cut and Graph Bisection problems. The former is known to be efficiently solvable by flow techniques, the latter to be NP-complete. The results presented in this paper are \n \n \na monotony result of the type\u201c The more balanced the partition we look for has to be, the harder the problem\u201d. \n \n \na complexity result clarifying the status of a large part of intermediate problems in the class."
            },
            "slug": "Between-Min-Cut-and-Graph-Bisection-Wagner-Wagner",
            "title": {
                "fragments": [],
                "text": "Between Min Cut and Graph Bisection"
            },
            "tldr": {
                "abstractSimilarityScore": 72,
                "text": "A class of graph partitioning problems whose two extreme representatives are the well-known Min Cut and Graph Bisection problems is investigated, finding the more balanced the partition the authors look for has to be, the harder the problem."
            },
            "venue": {
                "fragments": [],
                "text": "MFCS"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35124559"
                        ],
                        "name": "H. Simon",
                        "slug": "H.-Simon",
                        "structuredName": {
                            "firstName": "Horst",
                            "lastName": "Simon",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Simon"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 158,
                                "start": 146
                            }
                        ],
                        "text": "\u2026clustering has been discovered, re-discovered, and extended many times in different communities, see for example Pothen, Simon, and Liou (1990), Simon (1991), Bolla (1991), Hagen and Kahng (1992), Hendrickson and Leland (1995), Van Driessche and Roose (1995), Barnard, Pothen, and Simon (1995),\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 136,
                                "start": 111
                            }
                        ],
                        "text": "Several other papers investigate the quality of the clustering constructed by spectral clustering, for example Spielman and Teng (1996) (for unnormalized spectral clustering) and Kannan, Vempala, and Vetta (2004) (for normalized spectral clustering)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 16197093,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fc801b6119fe0fe3fa3f7e6f79d439949224f7d0",
            "isKey": false,
            "numCitedBy": 902,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Partitioning-of-unstructured-problems-for-parallel-Simon",
            "title": {
                "fragments": [],
                "text": "Partitioning of unstructured problems for parallel processing"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145346999"
                        ],
                        "name": "R. Bapat",
                        "slug": "R.-Bapat",
                        "structuredName": {
                            "firstName": "Ravindra",
                            "lastName": "Bapat",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Bapat"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "91586940"
                        ],
                        "name": "I. Gutmana",
                        "slug": "I.-Gutmana",
                        "structuredName": {
                            "firstName": "Ivan",
                            "lastName": "Gutmana",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Gutmana"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3457258"
                        ],
                        "name": "W. Xiao",
                        "slug": "W.-Xiao",
                        "structuredName": {
                            "firstName": "Wenjun",
                            "lastName": "Xiao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Xiao"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 276,
                                "start": 246
                            }
                        ],
                        "text": "For example a method in terms of eigenvectors of the normalized Laplacian Lsym can be found as Corollary 3.2 in Lova\u0301sz (1993), and a method computing the commute distance with the help of determinants of certain sub-matrices of L can be found in Bapat, Gutman, and Xiao (2003)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 158,
                                "start": 138
                            }
                        ],
                        "text": "2 in Lov\u00e1sz (1993), and a method computing the commute distance with the help of determinants of certain submatrices of L can be found in Bapat et al. (2003). Proposition 6 has an important consequence."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 16314784,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "0958a98a10fd8533121cd2e9a459db6254b129d9",
            "isKey": true,
            "numCitedBy": 93,
            "numCiting": 50,
            "paperAbstract": {
                "fragments": [],
                "text": "The resistance distance ri j between two vertices vi and vj of a (connected, molecular) graph G is equal to the effective resistance between the respective two points of an electrical network, constructed so as to correspond to G, such that the resistance of any edge is unity. We show how rij can be computed from the Laplacian matrix L of the graph G: Let L(i) and L(i, j) be obtained from L by deleting its i-th row and column, and by deleting its i-th and j-th rows and columns, respectively. Then rij = detL(i, j)/detL(i)."
            },
            "slug": "A-Simple-Method-for-Computing-Resistance-Distance-Bapat-Gutmana",
            "title": {
                "fragments": [],
                "text": "A Simple Method for Computing Resistance Distance"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2082836538"
                        ],
                        "name": "Evarist Gin'e",
                        "slug": "Evarist-Gin'e",
                        "structuredName": {
                            "firstName": "Evarist",
                            "lastName": "Gin'e",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Evarist Gin'e"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1784986"
                        ],
                        "name": "V. Koltchinskii",
                        "slug": "V.-Koltchinskii",
                        "structuredName": {
                            "firstName": "Vladimir",
                            "lastName": "Koltchinskii",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Koltchinskii"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 10336721,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "4668cdf5dcf787e37c4bfa02755ac633229c7c8c",
            "isKey": false,
            "numCitedBy": 141,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "Let ${M}$ be a compact Riemannian submanifold of ${{\\bf R}^m}$ of dimension $\\scriptstyle{d}$ and let ${X_1,...,X_n}$ be a sample of i.i.d. points in ${M}$ with uniform distribution. We study the random operators $$ \\Delta_{h_n,n}f(p):=\\frac{1}{nh_n^{d+2}}\\sum_{i=1}^n K(\\frac{p-X_i}{h_n})(f(X_i)-f(p)), p\\in M $$ where ${K(u):={\\frac{1}{(4\\pi)^{d/2}}}e^{-\\|u\\|^2/4}}$ is the Gaussian kernel and ${h_n\\to 0}$ as ${n\\to\\infty.}$ Such operators can be viewed as graph laplacians (for a weighted graph with vertices at data points) and they have been used in the machine learning literature to approximate the Laplace-Beltrami operator of ${M,}$ ${\\Delta_Mf}$ (divided by the Riemannian volume of the manifold). We prove several results on a.s. and distributional convergence of the deviations ${\\Delta_{h_n,n}f(p)-{\\frac{1}{|\\mu|}}\\Delta_Mf(p)}$ for smooth functions ${f}$ both pointwise and uniformly in ${f}$ and ${p}$ (here ${|\\mu|=\\mu(M)}$ and ${\\mu}$ is the Riemannian volume measure). In particular, we show that for any class ${{\\cal F}}$ of three times differentiable functions on ${M}$ with uniformly bounded derivatives $$ \\sup_{p\\in M}\\sup_{f\\in F}\\Big|\\Delta_{h_n,p}f(p)-\\frac{1}{|\\mu|}\\Delta_Mf(p)\\Big|= O\\Big(\\sqrt{\\frac{\\log(1/h_n)}{nh_n^{d+2}}}\\Big) a.s. $$ as soon as $$ nh_n^{d+2}/\\log h_n^{-1}\\to \\infty and nh^{d+4}_n/\\log h_n^{-1}\\to 0, $$ and also prove asymptotic normality of ${\\Delta_{h_n,p}f(p)-{\\frac{1}{|\\mu|}}\\Delta_Mf(p)}$ (functional CLT) for a fixed ${p\\in M}$ and uniformly in ${f}.$"
            },
            "slug": "Empirical-graph-Laplacian-approximation-of-Large-Gin'e-Koltchinskii",
            "title": {
                "fragments": [],
                "text": "Empirical graph Laplacian approximation of Laplace\u2013Beltrami operators: Large sample results"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "70979577"
                        ],
                        "name": "P. Maher",
                        "slug": "P.-Maher",
                        "structuredName": {
                            "firstName": "Philip",
                            "lastName": "Maher",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Maher"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "102985337"
                        ],
                        "name": "Helmut Luthepohl",
                        "slug": "Helmut-Luthepohl",
                        "structuredName": {
                            "firstName": "Helmut",
                            "lastName": "Luthepohl",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Helmut Luthepohl"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 118301937,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "4609192a4e87aed95a0dbb2056e4a298bc37457d",
            "isKey": false,
            "numCitedBy": 430,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Definitions, Notations, Terminology. Rules for Matrix Operations. Matrix Valued Functions of a Matrix. Trace, Determinant and Rank of a Matrix. Eigenvalues and Singular Values. Matrix Decompositions and Canonical Forms. Vectorization Operators. Vector and Matrix Norms. Properties of Special Matrices. Vector and Matrix Derivatives. Polynomials, Power Series and Matrices. Appendix. References. Index."
            },
            "slug": "Handbook-of-Matrices-Maher-Luthepohl",
            "title": {
                "fragments": [],
                "text": "Handbook of Matrices"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "100769860"
                        ],
                        "name": "V. N. Bogaevski",
                        "slug": "V.-N.-Bogaevski",
                        "structuredName": {
                            "firstName": "V.",
                            "lastName": "Bogaevski",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. N. Bogaevski"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "102602535"
                        ],
                        "name": "A. Povzner",
                        "slug": "A.-Povzner",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Povzner",
                            "middleNames": [
                                "Ya."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Povzner"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 120,
                                "start": 96
                            }
                        ],
                        "text": "In particular for k = 2, mincut is a relatively easy problem and can be solved efficiently, see Stoer and Wagner (1997) and the discussion therein."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 115761153,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6c09c25131ac2e7f01fd14ce2a576c209f8ad23e",
            "isKey": false,
            "numCitedBy": 1188,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "$$X = {X_0} + \\varepsilon {X_1} + {\\varepsilon ^2}{X_2} + \\cdots $$ \n \n(1.1.1) \n \nwhich acts in the n-dimensional (complex) vector space R."
            },
            "slug": "Matrix-Perturbation-Theory-Bogaevski-Povzner",
            "title": {
                "fragments": [],
                "text": "Matrix Perturbation Theory"
            },
            "tldr": {
                "abstractSimilarityScore": 54,
                "text": "X is the vector space which acts in the n-dimensional (complex) vector space R.1.1 and is related to Varepsilon by the following inequality."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2053158480"
                        ],
                        "name": "Chris H. Q. Ding",
                        "slug": "Chris-H.-Q.-Ding",
                        "structuredName": {
                            "firstName": "Chris",
                            "lastName": "Ding",
                            "middleNames": [
                                "H.",
                                "Q."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chris H. Q. Ding"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 170,
                                "start": 159
                            }
                        ],
                        "text": "In the machine learning community, spectral clustering has been made popular by the works of Shi and Malik (2000), Ng et al. (2002), Meila and Shi (2001), and Ding (2004)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 159,
                                "start": 140
                            }
                        ],
                        "text": "This can be seen even more explicitly by considering yet another graph cut objective function, namely the MinmaxCut criterion introduced by Ding et al. (2001):"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 182,
                                "start": 171
                            }
                        ],
                        "text": "We will see that relaxing Ncut leads to normalized spectral clustering, while relaxing RatioCut leads to unnormalized spectral clustering (see also the tutorial slides by Ding (2004))."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 59646297,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "dbdb70ce52a3314bad946329ef7d399f0986fc97",
            "isKey": false,
            "numCitedBy": 18,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "A modular support element comprising a generally rectangular sheet of stiff deformable material having a large opening therein, is formed into a generally cylindrical shape in which the two diametrically opposite corners of the sheet are fastened to each other and means are provided for connecting several of the modular structures together along with a base and device for holding objects to form a wide variety of structures having decorative and functional purposes."
            },
            "slug": "A-Tutorial-on-Spectral-Clustering-Ding",
            "title": {
                "fragments": [],
                "text": "A Tutorial on Spectral Clustering"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "A modular support element comprising a generally rectangular sheet of stiff deformable material having a large opening therein, is formed into a generally cylindrical shape in which the two diametrically opposite corners of the sheet are fastened to each other."
            },
            "venue": {
                "fragments": [],
                "text": "ICML 2004"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1398249180"
                        ],
                        "name": "John Odentrantz",
                        "slug": "John-Odentrantz",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Odentrantz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "John Odentrantz"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 205458983,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "86639d68fccf9509d050ada1113adc5287507e8a",
            "isKey": false,
            "numCitedBy": 1567,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "Preface * 1 Probability Review * 2 Discrete Time Markov Models * 3 Recurrence and Ergodicity * 4 Long Run Behavior * 5 Lyapunov Functions and Martingales * 6 Eigenvalues and Nonhomogeneous Markov Chains * 7 Gibbs Fields and Monte Carlo Simulation * 8 Continuous-Time Markov Models 9 Poisson Calculus and Queues * Appendix * Bibliography * Author Index * Subject Index"
            },
            "slug": "Markov-Chains:-Gibbs-Fields,-Monte-Carlo-and-Queues-Odentrantz",
            "title": {
                "fragments": [],
                "text": "Markov Chains: Gibbs Fields, Monte Carlo Simulation, and Queues"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "This book describes the development of Markov models for discrete-time Carlo simulation and some of the models used in this study had problems with regard to consistency and Ergodicity."
            },
            "venue": {
                "fragments": [],
                "text": "Technometrics"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "6463600"
                        ],
                        "name": "G. Dunteman",
                        "slug": "G.-Dunteman",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Dunteman",
                            "middleNames": [
                                "Henry"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Dunteman"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 122217809,
            "fieldsOfStudy": [
                "Mathematics",
                "Geology"
            ],
            "id": "b850d9d1529898ec4013deb1c976d081599c3a95",
            "isKey": false,
            "numCitedBy": 1996,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Introduction Basic Concepts of Principal Components Geometrical Properties of Principal Components Decomposition Properties of Principal Components Principal Components of Patterned Correlation Matrices Rotation of Principal Components Using Principal Components to Select a Subset of Variables Principal Components Versus Factor Analysis Uses of Principal Components in Regression Analysis Using Principal Components to Detect Outlying and Influential Observations Use of Principal Components in Cluster Analysis Use of Principal Components Analysis in Conjunction with Other Multivariate Analysis Procedures Other Techniques Related to Principal Components Summary and Conclusions"
            },
            "slug": "Principal-Components-Analysis-Dunteman",
            "title": {
                "fragments": [],
                "text": "Principal Components Analysis"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49237649"
                        ],
                        "name": "J. A. L\u00f3pez del Val",
                        "slug": "J.-A.-L\u00f3pez-del-Val",
                        "structuredName": {
                            "firstName": "J",
                            "lastName": "L\u00f3pez del Val",
                            "middleNames": [
                                "A"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. A. L\u00f3pez del Val"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "15702634"
                        ],
                        "name": "J. P. Alonso P\u00e9rez de \u00c1greda",
                        "slug": "J.-P.-Alonso-P\u00e9rez-de-\u00c1greda",
                        "structuredName": {
                            "firstName": "Juan",
                            "lastName": "Alonso P\u00e9rez de \u00c1greda",
                            "middleNames": [
                                "Pablo"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. P. Alonso P\u00e9rez de \u00c1greda"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 12726134,
            "fieldsOfStudy": [
                "Medicine"
            ],
            "id": "9de58adc7b0be24ac751ec78c5a0c1adbd91be77",
            "isKey": false,
            "numCitedBy": 1399,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "OBJECTIVE\nThis study wants to identify factors or components latent besides health indicators from Spanish regions, and its graphic output.\n\n\nDESIGN\nObservational study.\n\n\nSETTING\nTwenty eight indicators from regions were used: mortality, morbidity, communicable and no-communicable diseases, diet, dwelling and sanitary resources. Measurement was made between 1980-1988.\n\n\nINTERVENTIONS\nPrincipal component analysis has been applied to the indicators, reducing data dimension.\n\n\nMEASUREMENT AND MAIN RESULTS\nEight factors have been extracted, which explain 90% of the original information. This analysis, as can be seen from communnalities, represents correctly the set of original variables. The factors with more easily interpretation were: shortage sanitary resources, develop diet, mortality, chronic diseases and accidental.\n\n\nCONCLUSIONS\nOnly reduction data dimension could be justify the use of principal component analysis. Behind the agrupation of variables is mostly the socioeconomic background."
            },
            "slug": "[Principal-components-analysis].-Val-\u00c1greda",
            "title": {
                "fragments": [],
                "text": "[Principal components analysis]."
            },
            "tldr": {
                "abstractSimilarityScore": 63,
                "text": "Only reduction data dimension could be justify the use of principal component analysis in identifying factors or components latent besides health indicators from Spanish regions, and its graphic output."
            },
            "venue": {
                "fragments": [],
                "text": "Atencion primaria"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1759227"
                        ],
                        "name": "D. Klein",
                        "slug": "D.-Klein",
                        "structuredName": {
                            "firstName": "Douglas",
                            "lastName": "Klein",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Klein"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145743195"
                        ],
                        "name": "M. Randic",
                        "slug": "M.-Randic",
                        "structuredName": {
                            "firstName": "Milan",
                            "lastName": "Randic",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Randic"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 450,
                                "start": 34
                            }
                        ],
                        "text": "This result has been published by Klein and Randic (1993), where it has been proved by methods of electrical network theory. For a proof using first step analysis for random walks see Fouss, Pirotte, Renders, and Saerens (2007). There also exist other ways to express the commute distance with the help of graph Laplacians. For example a method in terms of eigenvectors of the normalized Laplacian Lsym can be found as Corollary 3.2 in Lov\u00e1sz (1993), and a method computing the commute distance with the help of determinants of certain sub-matrices of L can be found in Bapat, Gutman, and Xiao (2003)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 228,
                                "start": 34
                            }
                        ],
                        "text": "This result has been published by Klein and Randic (1993), where it has been proved by methods of electrical network theory. For a proof using first step analysis for random walks see Fouss, Pirotte, Renders, and Saerens (2007). There also exist other ways to express the commute distance with the help of graph Laplacians."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 57,
                                "start": 34
                            }
                        ],
                        "text": "This result has been published by Klein and Randic (1993), where it has been proved by methods of electrical network theory."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 16382100,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "eac8fb1c9883da002a8a9fb1d514bde116219dc1",
            "isKey": true,
            "numCitedBy": 899,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "The theory of resistive electrical networks is invoked to develop a novel view: if fixed resistors are assigned to each edge of a connected graph, then the effective resistance between pairs of vertices is a graphical distance. Several theorems concerning this novel distance function are established."
            },
            "slug": "Resistance-distance-Klein-Randic",
            "title": {
                "fragments": [],
                "text": "Resistance distance"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2085209273"
                        ],
                        "name": "H. Luetkepohl",
                        "slug": "H.-Luetkepohl",
                        "structuredName": {
                            "firstName": "Helmut",
                            "lastName": "Luetkepohl",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Luetkepohl"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 116854014,
            "fieldsOfStudy": [
                "Materials Science"
            ],
            "id": "bf4e821ed2179fd940b16b6fd3568761df07f870",
            "isKey": false,
            "numCitedBy": 864,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "A device including a unit adapted to hold a book in open condition for reading, and an elongated structure for adjustably supporting the book holding unit and adapted to be connected at a first end to a headboard of a bed or the like, and to carry the book holding unit at an opposite end of the elongated structure, with the structure being adjustable to various conditions between those ends in a manner changing the position and orientation of the book."
            },
            "slug": "The-Handbook-of-Matrices-Luetkepohl",
            "title": {
                "fragments": [],
                "text": "The Handbook of Matrices"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3046863"
                        ],
                        "name": "M. Fiedler",
                        "slug": "M.-Fiedler",
                        "structuredName": {
                            "firstName": "Miroslav",
                            "lastName": "Fiedler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Fiedler"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 301,
                                "start": 59
                            }
                        ],
                        "text": "For a proof using first step analysis for random walks see Fouss et al. (2006). There also exist other ways to express the commute distance with the help of graph Laplacians. For example a method in terms of eigenvectors of the normalized Laplacian Lsym can be found as Corollary 3.2 in Lov\u00e1sz (1993), and a method computing the commute distance with the help of determinants of certain submatrices of L can be found in Bapat et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 79,
                                "start": 59
                            }
                        ],
                        "text": "For a proof using first step analysis for random walks see Fouss et al. (2006). There also exist other ways to express the commute distance with the help of graph Laplacians."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 32,
                                "start": 18
                            }
                        ],
                        "text": "In the same year, Fiedler (1973) discovered that bi-partitions of a graph are closely connected with the second eigenvector of the graph Laplacian, and he suggested to use this eigenvector to partition a graph."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 117770486,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "32b5178547b79d384afad2c7abb6c64f1697617c",
            "isKey": true,
            "numCitedBy": 3541,
            "numCiting": 3,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Algebraic-connectivity-of-graphs-Fiedler",
            "title": {
                "fragments": [],
                "text": "Algebraic connectivity of graphs"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1973
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 19,
                                "start": 5
                            }
                        ],
                        "text": "3 of Bhatia (1997). In perturbation theory, distances between subspaces are usually measured using \u201ccanonical angles\u201d (also called \u201cprincipal angles\u201d)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 153,
                                "start": 140
                            }
                        ],
                        "text": "Canonical angles can also be defined if V1 and V2 do not have the same dimension, see Section V of Stewart and Sun (1990), Section VII.3 of Bhatia (1997), or Section 12.4.3 of Golub and Van Loan (1996)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 717,
                                "start": 5
                            }
                        ],
                        "text": "3 of Bhatia (1997). In perturbation theory, distances between subspaces are usually measured using \u201ccanonical angles\u201d (also called \u201cprincipal angles\u201d). To define principal angles, let V1 and V2 be two p-dimensional subspaces of R, and V1 and V2 two matrices such that their columns form orthonormal systems for V1 and V2, respectively. Then the cosines cos \u0398i of the principal angles \u0398i are the singular values of V \u2032 1V2. For p = 1, the so defined canonical angles coincide with the normal definition of an angle. Canonical angles can also be defined if V1 and V2 do not have the same dimension, see Section V of Stewart and Sun (1990), Section VII.3 of Bhatia (1997), or Section 12.4.3 of Golub and Van Loan (1996). The matrix sin \u0398(V1,V2) will denote the diagonal matrix with the sine of the canonical angles on the diagonal."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 150,
                                "start": 137
                            }
                        ],
                        "text": "We state those results for completeness, but for background reading we refer to Section V of Stewart and Sun (1990) and Section VII.3 of Bhatia (1997)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Matrix Analysis. Springer, New York"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 63,
                                "start": 51
                            }
                        ],
                        "text": "Also, other uses of the spectral embeddings (e.g., Bolla (1991) or Belkin and Niyogi (2003)) show that the Euclidean distance in Rd is meaningful."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 55,
                                "start": 43
                            }
                        ],
                        "text": "For more details on this topic we refer to Bolla (1991), Mohar (1997) and Chung (1997)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 59,
                                "start": 33
                            }
                        ],
                        "text": "Spectral clustering goes back to Donath and Hoffman (1973), who first suggested to construct graph partitions based on eigenvectors of the adjacency matrix."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 190,
                                "start": 33
                            }
                        ],
                        "text": "Spectral clustering goes back to Donath and Hoffman (1973), who first suggested to construct graph partitions based on eigenvectors of the adjacency matrix. In the same year, Fiedler (1973) discovered that bi-partitions of a graph are closely connected with the second eigenvector of the graph Laplacian, and he suggested to use this eigenvector to partition a graph."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 523,
                                "start": 33
                            }
                        ],
                        "text": "Spectral clustering goes back to Donath and Hoffman (1973), who first suggested to construct graph partitions based on eigenvectors of the adjacency matrix. In the same year, Fiedler (1973) discovered that bi-partitions of a graph are closely connected with the second eigenvector of the graph Laplacian, and he suggested to use this eigenvector to partition a graph. Since then, spectral clustering has been discovered, re-discovered, and extended many times in different communities, see for example Pothen et al. (1990), Simon (1991), Bolla (1991), Hagen and Kahng (1992), Hendrickson and Leland (1995), Van Driessche and Roose (1995), Barnard et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 161,
                                "start": 149
                            }
                        ],
                        "text": "\u2026has been discovered, re-discovered, and extended many times in different communities, see for example Pothen, Simon, and Liou (1990), Simon (1991), Bolla (1991), Hagen and Kahng (1992), Hendrickson and Leland (1995), Van Driessche and Roose (1995), Barnard, Pothen, and Simon (1995), Spielman and\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Relations between spectral and classification properties of multigraphs"
            },
            "venue": {
                "fragments": [],
                "text": "Technical Report No. DIMACS-91-27, Center for Discrete Mathematics and Theoretical Computer Science"
            },
            "year": 1991
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 63,
                                "start": 51
                            }
                        ],
                        "text": "Also, other uses of the spectral embeddings (e.g., Bolla (1991) or Belkin and Niyogi (2003)) show that the Euclidean distance in Rd is meaningful."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 55,
                                "start": 43
                            }
                        ],
                        "text": "For more details on this topic we refer to Bolla (1991), Mohar (1997) and Chung (1997)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 369,
                                "start": 180
                            }
                        ],
                        "text": "Since then, spectral clustering has been discovered, re-discovered, and extended many times in different communities, see for example Pothen, Simon, and Liou (1990), Simon (1991), Bolla (1991), Hagen and Kahng (1992), Hendrickson and Leland (1995), Van Driessche and Roose (1995), Barnard, Pothen, and Simon (1995), Spielman and Teng (1996), Guattery and Miller (1998). A nice overview over the history of spectral clustering can be found in Spielman and Teng (1996)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 193,
                                "start": 180
                            }
                        ],
                        "text": "Since then, spectral clustering has been discovered, re-discovered, and extended many times in different communities, see for example Pothen, Simon, and Liou (1990), Simon (1991), Bolla (1991), Hagen and Kahng (1992), Hendrickson and Leland (1995), Van Driessche and Roose (1995), Barnard, Pothen, and Simon (1995), Spielman and Teng (1996), Guattery and Miller (1998)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 161,
                                "start": 149
                            }
                        ],
                        "text": "\u2026has been discovered, re-discovered, and extended many times in different communities, see for example Pothen, Simon, and Liou (1990), Simon (1991), Bolla (1991), Hagen and Kahng (1992), Hendrickson and Leland (1995), Van Driessche and Roose (1995), Barnard, Pothen, and Simon (1995), Spielman and\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Relations between spectral and classification properties of multigraphs (Technical Report No"
            },
            "venue": {
                "fragments": [],
                "text": "DIMACS-91-27). Center for Discrete Mathematics and Theoretical Computer Science."
            },
            "year": 1991
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 63,
                                "start": 51
                            }
                        ],
                        "text": "Also, other uses of the spectral embeddings (e.g., Bolla (1991) or Belkin and Niyogi (2003)) show that the Euclidean distance in Rd is meaningful."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 55,
                                "start": 43
                            }
                        ],
                        "text": "For more details on this topic we refer to Bolla (1991), Mohar (1997) and Chung (1997)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 369,
                                "start": 180
                            }
                        ],
                        "text": "Since then, spectral clustering has been discovered, re-discovered, and extended many times in different communities, see for example Pothen, Simon, and Liou (1990), Simon (1991), Bolla (1991), Hagen and Kahng (1992), Hendrickson and Leland (1995), Van Driessche and Roose (1995), Barnard, Pothen, and Simon (1995), Spielman and Teng (1996), Guattery and Miller (1998). A nice overview over the history of spectral clustering can be found in Spielman and Teng (1996)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 193,
                                "start": 180
                            }
                        ],
                        "text": "Since then, spectral clustering has been discovered, re-discovered, and extended many times in different communities, see for example Pothen, Simon, and Liou (1990), Simon (1991), Bolla (1991), Hagen and Kahng (1992), Hendrickson and Leland (1995), Van Driessche and Roose (1995), Barnard, Pothen, and Simon (1995), Spielman and Teng (1996), Guattery and Miller (1998)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 161,
                                "start": 149
                            }
                        ],
                        "text": "\u2026has been discovered, re-discovered, and extended many times in different communities, see for example Pothen, Simon, and Liou (1990), Simon (1991), Bolla (1991), Hagen and Kahng (1992), Hendrickson and Leland (1995), Van Driessche and Roose (1995), Barnard, Pothen, and Simon (1995), Spielman and\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Relations between spectral and classification properties of multigraphs (Technical Report No. DIMACS-91-27)"
            },
            "venue": {
                "fragments": [],
                "text": "Center for Discrete Mathematics and Theoretical Computer Science"
            },
            "year": 1991
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 76,
                                "start": 18
                            }
                        ],
                        "text": "For background reading on random walks in general we refer to Norris (1997) and Br\u00e9maud (1999), and for random walks on graphs we recommend Aldous and Fill (in preparation) and Lov\u00e1sz (1993)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 114,
                                "start": 93
                            }
                        ],
                        "text": "A link between spectral clustering and the weighted kernel k-means algorithm is described in Dhillon et al. (2005)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 175,
                                "start": 145
                            }
                        ],
                        "text": "\u2026clustering with additional side information (Joachims, 2003) connections between spectral clustering and the weighted kernel-k-means algorithm (Dhillon, Guan, and Kulis, 2005), learning similarity functions based on spectral clustering (Bach and Jordan, 2004), or spectral clustering in a\u2026"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 116,
                                "start": 63
                            }
                        ],
                        "text": "We state those results for completeness, but for background reading we refer to Section V of Stewart and Sun (1990) and Section VII."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A unified view of kernel k-means, spectral clustering, and graph partitioning (Technical Report No"
            },
            "venue": {
                "fragments": [],
                "text": "UTCS TR-04-25). University of Texas at Austin."
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1402288698"
                        ],
                        "name": "D. Vere-Jones",
                        "slug": "D.-Vere-Jones",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Vere-Jones",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Vere-Jones"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 75,
                                "start": 62
                            }
                        ],
                        "text": "For background reading on random walks in general we refer to Norris (1997) and Bre\u0301maud (1999), and for random walks on graphs we recommend Aldous and Fill (in preparation) and Lova\u0301sz (1993)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 4260497,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "4841061c3d110f87247b3423c8eceba903726080",
            "isKey": false,
            "numCitedBy": 2501,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Markov-Chains-Vere-Jones",
            "title": {
                "fragments": [],
                "text": "Markov Chains"
            },
            "venue": {
                "fragments": [],
                "text": "Nature"
            },
            "year": 1972
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "corpusId": 437326,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b37e24915290637f9f9782d3345b044975e8e43e",
            "isKey": false,
            "numCitedBy": 6,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Stability-based-Validation-of-Clustering",
            "title": {
                "fragments": [],
                "text": "Stability-based Validation of Clustering"
            },
            "venue": {
                "fragments": [],
                "text": "Encyclopedia of Database Systems"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "71531172"
                        ],
                        "name": "\u5bae\u6ca2 \u653f\u6e05",
                        "slug": "\u5bae\u6ca2-\u653f\u6e05",
                        "structuredName": {
                            "firstName": "\u5bae\u6ca2",
                            "lastName": "\u653f\u6e05",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "\u5bae\u6ca2 \u653f\u6e05"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 118228210,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "2d844d2b592964e74ffc353e0da35170c96c8eaf",
            "isKey": false,
            "numCitedBy": 185,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "P.-Bremaud-\u8457,-Markov-Chains,-(Gibbs-fields,-Monte-\u5bae\u6ca2",
            "title": {
                "fragments": [],
                "text": "P. Bremaud \u8457, Markov Chains, (Gibbs fields, Monte Carlo simulation and Queues), Springer-Verlag, 1999\u5e74"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Reversible Markov chains and random walks on graphs ( in preparation )"
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 86,
                                "start": 74
                            }
                        ],
                        "text": "For more details on this topic we refer to Bolla (1991), Mohar (1997) and Chung (1997)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 70,
                                "start": 58
                            }
                        ],
                        "text": "The standard reference for normalized graph Laplacians is Chung (1997)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 120,
                                "start": 109
                            }
                        ],
                        "text": "There exists a whole field dedicated to the study of those matrices, called spectral graph theory (e.g., see Chung, 1997)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Spectral graph theory (Vol"
            },
            "venue": {
                "fragments": [],
                "text": "92 of the CBMS Regional Conference Series in Mathematics). Conference Board of the Mathematical Sciences, Washington."
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 232,
                                "start": 212
                            }
                        ],
                        "text": "That is, if we consider a diffusion process on the data space X , then the partition induced by the eigenvectors of U is such that the diffusion does not transition between the different clusters very often (von Luxburg et al., 2004)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Consistency of spectral clustering On the convergence of spectral clustering on random samples: the normalized case Limits of spectral clustering"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 17th Annual Conference on Learning Theory (COLT) Advances in Neural Information Processing Systems (NIPS) 17"
            },
            "year": 2004
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Diffusion maps, spectral clustering"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2006
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 170,
                                "start": 159
                            }
                        ],
                        "text": "In the machine learning community, spectral clustering has been made popular by the works of Shi and Malik (2000), Ng et al. (2002), Meila and Shi (2001), and Ding (2004)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 182,
                                "start": 171
                            }
                        ],
                        "text": "We will see that relaxing Ncut leads to normalized spectral clustering, while relaxing RatioCut leads to unnormalized spectral clustering (see also the tutorial slides by Ding (2004))."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 176,
                                "start": 140
                            }
                        ],
                        "text": "This can be seen even more explicitly by considering yet another graph cut objective function, namely the MinMaxCut criterion introduced by Ding, He, Zha, Gu, and Simon (2001):"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A tutorial on spectral clustering. Talk presented at ICML. (Slides available at http://crd.lbl.gov/\u223ccding/Spectral"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2004
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Reversible Markov Chains and Random Walks on Graphs. online version available at http"
            },
            "venue": {
                "fragments": [],
                "text": "Reversible Markov Chains and Random Walks on Graphs. online version available at http"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 340,
                                "start": 319
                            }
                        ],
                        "text": "Subsequently, spectral clustering has been extended to many non-standard settings, for example spectral clustering applied to the co-clustering problem (Dhillon 2001), spectral clustering with additional side information (Joachims 2003) connections between spectral clustering and the weighted kernel-k-means algorithm (Dhillon et al. 2005), learning similarity functions based on spectral clustering (Bach and Jordan 2004), or spectral clustering in a distributed environment (Kempe and McSherry 2004)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 114,
                                "start": 93
                            }
                        ],
                        "text": "A link between spectral clustering and the weighted kernel k-means algorithm is described in Dhillon et al. (2005)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 175,
                                "start": 145
                            }
                        ],
                        "text": "\u2026clustering with additional side information (Joachims, 2003) connections between spectral clustering and the weighted kernel-k-means algorithm (Dhillon, Guan, and Kulis, 2005), learning similarity functions based on spectral clustering (Bach and Jordan, 2004), or spectral clustering in a\u2026"
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A unified view of kernel k-means, spectral clustering, and graph partitioning"
            },
            "venue": {
                "fragments": [],
                "text": "Technical Report No. UTCS TR-04-25,"
            },
            "year": 2005
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 232,
                                "start": 212
                            }
                        ],
                        "text": "That is, if we consider a diffusion process on the data space X , then the partition induced by the eigenvectors of U is such that the diffusion does not transition between the different clusters very often (von Luxburg et al., 2004)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Consistency of spectral clustering (Technical Report No. 134)"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2004
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 28,
                                "start": 16
                            }
                        ],
                        "text": "For example, in Lang (2006) the authors use hyperplanes for this purpose."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 96,
                                "start": 84
                            }
                        ],
                        "text": "His results were generalized from uniform distributions to general distributions by Lafon (2004)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 80,
                                "start": 68
                            }
                        ],
                        "text": "This intuition has been made precise in the works of Belkin (2003), Lafon (2004), Hein, Audibert, and von Luxburg (2005); M., Audibert, and von Luxburg (2007), Belkin and Niyogi (2005), Hein (2006), Gine\u0301 and Koltchinskii (2005)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Diffusion maps and geometric harmonics"
            },
            "venue": {
                "fragments": [],
                "text": "Ph.D. Thesis, Yale University"
            },
            "year": 2004
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 119,
                                "start": 96
                            }
                        ],
                        "text": "In particular for k = 2, mincut is a relatively easy problem and can be solved efficiently, see Stoer and Wagner (1997) and the discussion therein."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A simple mincut algorithm"
            },
            "venue": {
                "fragments": [],
                "text": "J . ACM"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 197,
                                "start": 162
                            }
                        ],
                        "text": "In the field of machine learning, graph Laplacians are not only used for clustering, but also emerge for many other tasks such as semi-supervised learning (e.g., Chapelle, Scho\u0308lkopf, and Zien, 2006 for an overview) or manifold reconstruction (e.g., Belkin and Niyogi, 2003)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "eds.): Semi-Supervised Learning"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2006
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Connectivity of the mutual knearest - neighbor graph in clustering and outlier detection"
            },
            "venue": {
                "fragments": [],
                "text": "Statistics and Probability Letters"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Connectivity of the mutual knearest - neighbor graph in clustering and outlier detection"
            },
            "venue": {
                "fragments": [],
                "text": "Statistics and Probability Letters"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 86,
                                "start": 74
                            }
                        ],
                        "text": "For more details on this topic we refer to Bolla (1991), Mohar (1997) and Chung (1997)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 70,
                                "start": 58
                            }
                        ],
                        "text": "The standard reference for normalized graph Laplacians is Chung (1997)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 120,
                                "start": 109
                            }
                        ],
                        "text": "There exists a whole field dedicated to the study of those matrices, called spectral graph theory (e.g., see Chung, 1997)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Spectral graph theory (Vol. 92 of the CBMS Regional Conference Series in Mathematics)"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Reversible Markov chains and random walks on graphs (in preparation) Online version available at http://www"
            },
            "venue": {
                "fragments": [],
                "text": "Reversible Markov chains and random walks on graphs (in preparation) Online version available at http://www"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The Laplacian spectrum of graphs. In: Graph Theory, Combinatorics, and Applications"
            },
            "venue": {
                "fragments": [],
                "text": "Kalamazoo, MI,"
            },
            "year": 1988
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 114,
                                "start": 93
                            }
                        ],
                        "text": "A link between spectral clustering and the weighted kernel k-means algorithm is described in Dhillon et al. (2005)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 175,
                                "start": 145
                            }
                        ],
                        "text": "\u2026clustering with additional side information (Joachims, 2003) connections between spectral clustering and the weighted kernel-k-means algorithm (Dhillon, Guan, and Kulis, 2005), learning similarity functions based on spectral clustering (Bach and Jordan, 2004), or spectral clustering in a\u2026"
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A unified view of kernel k-means, spectral clustering, and graph partitioning (Technical Report No. UTCS TR-04-25)"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2005
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 164,
                                "start": 134
                            }
                        ],
                        "text": "Since then, spectral clustering has been discovered, re-discovered, and extended many times in different communities, see for example Pothen, Simon, and Liou (1990), Simon (1991), Bolla (1991), Hagen and Kahng (1992), Hendrickson and Leland (1995), Van Driessche and Roose (1995), Barnard, Pothen,\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Partitioning sparse matrices with eigenvectors"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1990
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 46,
            "methodology": 36,
            "result": 2
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 96,
        "totalPages": 10
    },
    "page_url": "https://www.semanticscholar.org/paper/A-tutorial-on-spectral-clustering-Luxburg/eda90bd43f4256986688e525b45b833a3addab97?sort=total-citations"
}