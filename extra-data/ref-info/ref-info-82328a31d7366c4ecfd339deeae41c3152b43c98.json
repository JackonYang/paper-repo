{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145695526"
                        ],
                        "name": "S. Mao",
                        "slug": "S.-Mao",
                        "structuredName": {
                            "firstName": "Song",
                            "lastName": "Mao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Mao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143626870"
                        ],
                        "name": "T. Kanungo",
                        "slug": "T.-Kanungo",
                        "structuredName": {
                            "firstName": "Tapas",
                            "lastName": "Kanungo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kanungo"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 65,
                                "start": 61
                            }
                        ],
                        "text": "We have reported part of the work presented in this paper in [21], [22], [23]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 17519056,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5ab2791fbd8d39d02eb8ee76b0f03f5d64371309",
            "isKey": false,
            "numCitedBy": 10,
            "numCiting": 52,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract : Document page segmentation is a crucial preprocessing step in Optical Character Recognition (OCR) systems. While numerous page segmentation algorithms have been proposed, there is relatively less literature on comparative evaluation--empirical or theoretical-- of these algorithms. Fore the existing performance evaluation methods, two crucial components are usually missing: 1) automatic training of algorithms with free parameters and 2) statistical and error analysis of experimental results. In this thesis, we use the following five-step methodology to quantitatively compare the performance of page segmentation algorithms: 1) First we create mutually exclusive training and test datasets with groundtruth, 2) we then select a meaningful and computable performance metric, 3) an optimization procedure is then used to search automatically for the optimal parameter values of the segmentation algorithms, 4) the segmentation algorithms are then evaluated on the test dataset, and finally 5) a statistical error analysis is performed to give the statistical significance of the experimental results. The automatic training of algorithms is posed as an optimization problem and a direct search method -- the simplex method -- is sued to search for a set of optimal parameter values. A paired-model statistical analysis and an error analysis are conducted to provide confidence intervals for the experimental results and to interpret the functionalities of algorithms. This methodology is applied to the evaluation of five page segmentation algorithms, of which three are representative research algorithms and the other two are well-known commercial products, on 978 images from the University of Washington III dataset. It is found that the performances of the Voronoi, Docstrum and Caere segmentation algorithms are not significantly different from each other, but they are significantly better than that of ScanSoft's segmentation algorithm, which in turn is significantly better than X-Y cut."
            },
            "slug": "A-Methodology-for-Empirical-Performance-Evaluation-Mao-Kanungo",
            "title": {
                "fragments": [],
                "text": "A Methodology for Empirical Performance Evaluation of Page Segmentation Algorithms"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "Five-step methodology is applied to the evaluation of five page segmentation algorithms, of which three are representative research algorithms and the other two are well-known commercial products, on 978 images from the University of Washington III dataset and it is found that the performances of the Voronoi, Docstrum and Caere segmentations algorithms are not significantly different from each other, but they are significantly better than that of ScanSoft's segmentation algorithm."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145695526"
                        ],
                        "name": "S. Mao",
                        "slug": "S.-Mao",
                        "structuredName": {
                            "firstName": "Song",
                            "lastName": "Mao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Mao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143626870"
                        ],
                        "name": "T. Kanungo",
                        "slug": "T.-Kanungo",
                        "structuredName": {
                            "firstName": "Tapas",
                            "lastName": "Kanungo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kanungo"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "We have reported part of the work presented in this paper in [21], [22], [ 23 ]."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                }
            ],
            "corpusId": 15774044,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "21dc465191fa562fef0a49ed5788f4bf6d5f3ce1",
            "isKey": false,
            "numCitedBy": 13,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "Document page segmentation is a crucial preprocessing step in Optical Character Recognition (OCR) system. While numerous segmentation algorithms have been proposed, there is relatively less literature on comparative evaluation -- empirical or theoretical -- of these algorithms. We use the following five step methodology to quantitatively compare the performance of page segmentation algorithms: (1) First we create mutually exclusive training and test dataset with groundtruth, (2) we then select a meaningful and computable performance metric, (3) an optimization procedure is then used to automatically search for the optimal parameter values of the segmentation algorithms, (4) the segmentation algorithms are then evaluated on the test dataset, and finally (5) a statistical error analysis is performed to give the statistical significance of the experimental results. We apply this methodology to five segmentation algorithms, three of which are representative research algorithms and the rest two are well-known commercial products. The three research algorithms evaluated are: Nagy's X-Y cut, O'Gorman's Docstrum and Kise's Voronoi-diagram-based algorithm. The two commercial products evaluated are: Caere Corporation's segmentation algorithm and ScanSoft Corporation's segmentation algorithm. The evaluations are conducted on 978 images from the University of Washington III dataset. It is found that the performance of the Voronoi-based, Docstrum and Caere's segmentation algorithms are not significantly different from each other, but they are significantly better than ScanSoft's segmentation algorithm, which in turn is significantly better than the performance of the X-Y cut algorithm. Furthermore, we see that the commercial segmentation algorithms and research segmentation algorithms have comparable performances."
            },
            "slug": "Empirical-performance-evaluation-of-page-algorithms-Mao-Kanungo",
            "title": {
                "fragments": [],
                "text": "Empirical performance evaluation of page segmentation algorithms"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "It is found that the performance of the Voronoi-based, Docstrum and Caere's segmentation algorithms are not significantly different from each other, but they are significantly better than ScanSoft's segmentations algorithm, which in turn is significantly better Than Nagy's X-Y cut algorithm."
            },
            "venue": {
                "fragments": [],
                "text": "Electronic Imaging"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145695526"
                        ],
                        "name": "S. Mao",
                        "slug": "S.-Mao",
                        "structuredName": {
                            "firstName": "Song",
                            "lastName": "Mao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Mao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143626870"
                        ],
                        "name": "T. Kanungo",
                        "slug": "T.-Kanungo",
                        "structuredName": {
                            "firstName": "Tapas",
                            "lastName": "Kanungo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kanungo"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "We have reported part of the work presented in this paper in [21], [ 22 ], [23]."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                }
            ],
            "corpusId": 2458952,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "184cbf368348a250d005047e269bb96b7e34a460",
            "isKey": false,
            "numCitedBy": 12,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "Most page segmentation algorithms have user-specifiable free parameters. However, algorithm designers typically do not provide a quantitative/rigorous method for choosing values for these parameters. The free parameter values can affect the segmentation result quite drastically and are very dependent on the particular dataset that the algorithm is being used on. We present an automatic training method for choosing free parameters of page segmentation algorithms. The automatic training problem is posed as a multivariate non-smooth function optimization problem. An efficient direct search method-simplex method-is used to solve this optimization problem. This training method is used applied to the training of Kise's page segmentation algorithm. It is found that a set of optimal parameter values and their corresponding performance index can be found using relatively few function evaluations. The UW III dataset was used for conducting our experiments."
            },
            "slug": "Automatic-training-of-page-segmentation-algorithms:-Mao-Kanungo",
            "title": {
                "fragments": [],
                "text": "Automatic training of page segmentation algorithms: an optimization approach"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "An automatic training method for choosing free parameters of page segmentation algorithms and it is found that a set of optimal parameter values and their corresponding performance index can be found using relatively few function evaluations."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings 15th International Conference on Pattern Recognition. ICPR-2000"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145695526"
                        ],
                        "name": "S. Mao",
                        "slug": "S.-Mao",
                        "structuredName": {
                            "firstName": "Song",
                            "lastName": "Mao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Mao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143626870"
                        ],
                        "name": "T. Kanungo",
                        "slug": "T.-Kanungo",
                        "structuredName": {
                            "firstName": "Tapas",
                            "lastName": "Kanungo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kanungo"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "The software used for generating the results in this paper is described in [ 25 ], [24]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "We used the PSET software package [ 25 ], [24] for training and testing the algorithms."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1725865,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "730af7f2d19d37724119e00f48bc5ae7363fa86a",
            "isKey": false,
            "numCitedBy": 37,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract. Empirical performance evaluation of page segmentation algorithms has become increasingly important due to the numerous algorithms that are being proposed each year. In order to choose between these algorithms for a specific domain it is important to empirically evaluate their performance. To accomplish this task the document image analysis community needs: i) standardized document image datasets with groundtruth; ii) evaluation metrics that are agreed upon by researchers; and iii) freely available software for evaluating new algorithms and replicating other researchers' results. In an earlier paper (IEEE Transactions on Pattern Analysis and Machine Intelligence 2001) we published evaluation results for various popular page segmentation algorithms using the University of Washington dataset. In this paper we describe the software architecture of the PSET evaluation package, which was used to evaluate the segmentation algorithms. The description of the architecture will allow researchers to understand the software better, replicate our results, evaluate new algorithms, experiment with new metrics and datasets, etc. The software is written using the C language on the SUN/UNIX platform and is being made available to researchers at no cost."
            },
            "slug": "Software-architecture-of-PSET:-a-page-segmentation-Mao-Kanungo",
            "title": {
                "fragments": [],
                "text": "Software architecture of PSET: a page segmentation evaluation toolkit"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "The software architecture of the PSET evaluation package, which was used to evaluate the segmentation algorithms, is described to allow researchers to understand the software better, replicate the results, evaluate new algorithms, experiment with new metrics and datasets, etc."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal on Document Analysis and Recognition"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1896610"
                        ],
                        "name": "S. Randriamasy",
                        "slug": "S.-Randriamasy",
                        "structuredName": {
                            "firstName": "Sabine",
                            "lastName": "Randriamasy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Randriamasy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1820595"
                        ],
                        "name": "L. Vincent",
                        "slug": "L.-Vincent",
                        "structuredName": {
                            "firstName": "Luc",
                            "lastName": "Vincent",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Vincent"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1726209"
                        ],
                        "name": "B. Wittner",
                        "slug": "B.-Wittner",
                        "structuredName": {
                            "firstName": "Ben",
                            "lastName": "Wittner",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Wittner"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[35] proposed a bitmap-level region-based metric."
                    },
                    "intents": []
                }
            ],
            "corpusId": 7668022,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "42dbc78252120d60c5671463d7384c3a44c281d0",
            "isKey": false,
            "numCitedBy": 19,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "An automatic bitmap-level, set-based benchmarking scheme for page segmentation, comparing results with predefined `ground truth files' containing all the possible correct solutions, is presented. A successful page segmentation is a necessary precondition for a document recognition process to be successful. The problems addressed here are: design methods to describe all possible correct segmentations for a given page and design methods to compare two segmentations. The proposed segmentation ground truth representation scheme defines ground truth text regions as non-mergeable maximal sets of text lines, merged in a language- dependent direction. It includes the other possible correct segmentations in that authorized cuts in the region are explicitly specified. At this low-level stage, quality criteria for a page segmentation are mainly defined as providing correct input for region ordering and classification. The qualitative and quantitative evaluation method tests the overlap between the two sets of regions. In fact, the regions are defined as being the black pixels contained in the derived polygons."
            },
            "slug": "Automatic-benchmarking-scheme-for-page-segmentation-Randriamasy-Vincent",
            "title": {
                "fragments": [],
                "text": "Automatic benchmarking scheme for page segmentation"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "An automatic bitmap-level, set-based benchmarking scheme for page segmentation, comparing results with predefined `ground truth files' containing all the possible correct solutions, is presented."
            },
            "venue": {
                "fragments": [],
                "text": "Electronic Imaging"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145820949"
                        ],
                        "name": "T. Pavlidis",
                        "slug": "T.-Pavlidis",
                        "structuredName": {
                            "firstName": "Theodosios",
                            "lastName": "Pavlidis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Pavlidis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2461436"
                        ],
                        "name": "Jiangying Zhou",
                        "slug": "Jiangying-Zhou",
                        "structuredName": {
                            "firstName": "Jiangying",
                            "lastName": "Zhou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jiangying Zhou"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "In research segmentation algorithms that have userspecifiable parameters, typically the default parameter values are selected and no training method is explicitly specified [17], [1], [28], [13], [ 30 ], [5]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Pavlidis and Zhou [ 30 ] proposed a hybrid algorithm using a split-and-merge strategy."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 23410608,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "999e76f9115af2741b0cd973d875163ae714d5da",
            "isKey": false,
            "numCitedBy": 281,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Page-segmentation-and-classification-Pavlidis-Zhou",
            "title": {
                "fragments": [],
                "text": "Page segmentation and classification"
            },
            "venue": {
                "fragments": [],
                "text": "CVGIP Graph. Model. Image Process."
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1780258"
                        ],
                        "name": "Jisheng Liang",
                        "slug": "Jisheng-Liang",
                        "structuredName": {
                            "firstName": "Jisheng",
                            "lastName": "Liang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jisheng Liang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1744200"
                        ],
                        "name": "I. T. Phillips",
                        "slug": "I.-T.-Phillips",
                        "structuredName": {
                            "firstName": "Ihsin",
                            "lastName": "Phillips",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. T. Phillips"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1710238"
                        ],
                        "name": "R. Haralick",
                        "slug": "R.-Haralick",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Haralick",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Haralick"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 1365695,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e44015ab8d9ba89ac004421e3c56bcbeecbd0a47",
            "isKey": false,
            "numCitedBy": 31,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "A performance evaluation protocol for the layout analysis is discussed in this paper. In the University of Washington English Document Image Database-III, there are 1600 English document images that come with manually edited ground truth of entity bounding boxes. These bounding boxes enclose text and non-text zones, text-lines, and words. We describe a performance metric for the comparison of the detected entities and the ground truth in terms of their bounding boxes. The Document Attribute Format Specification is used as the standard data representation. The protocol is intended to serve as a model for using the UW-III database to evaluate the document analysis algorithms. A set of layout analysis algorithms which detect different entities have been tested based on the data set and the performance metric. The evaluation results are presented in this paper."
            },
            "slug": "Performance-evaluation-of-document-layout-analysis-Liang-Phillips",
            "title": {
                "fragments": [],
                "text": "Performance evaluation of document layout analysis algorithms on the UW data set"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "A performance metric is described for the comparison of the detected entities and the ground truth in terms of their bounding boxes and the evaluation results are presented."
            },
            "venue": {
                "fragments": [],
                "text": "Electronic Imaging"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143626870"
                        ],
                        "name": "T. Kanungo",
                        "slug": "T.-Kanungo",
                        "structuredName": {
                            "firstName": "Tapas",
                            "lastName": "Kanungo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kanungo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2377715"
                        ],
                        "name": "M. Jaisimha",
                        "slug": "M.-Jaisimha",
                        "structuredName": {
                            "firstName": "Mysore",
                            "lastName": "Jaisimha",
                            "middleNames": [
                                "Y."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Jaisimha"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145993358"
                        ],
                        "name": "J. Palmer",
                        "slug": "J.-Palmer",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Palmer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Palmer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1710238"
                        ],
                        "name": "R. Haralick",
                        "slug": "R.-Haralick",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Haralick",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Haralick"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7381934,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ce675b2ae1442e6064c0b51c095c5530aaeede74",
            "isKey": false,
            "numCitedBy": 82,
            "numCiting": 37,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a methodology for the quantitative performance evaluation of detection algorithms in computer vision. A common method is to generate a variety of input images by varying the image parameters and evaluate the performance of the algorithm, as algorithm parameters vary. Operating curves that relate the probability of misdetection and false alarm are generated for each parameter setting. Such an analysis does not integrate the performance of the numerous operating curves. In this paper, we outline a methodology for summarizing many operating curves into a few performance curves. This methodology is adapted from the human psychophysics literature and is general to any detection algorithm. The central concept is to measure the effect of variables in terms of the equivalent effect of a critical signal variable, which in turn facilitates the determination of the breakdown point of the algorithm. We demonstrate the methodology by comparing the performance of two-line detection algorithms."
            },
            "slug": "A-methodology-for-quantitative-performance-of-Kanungo-Jaisimha",
            "title": {
                "fragments": [],
                "text": "A methodology for quantitative performance evaluation of detection algorithms"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A methodology for summarizing many operating curves into a few performance curves based on the equivalent effect of a critical signal variable is outlined, which facilitates the determination of the breakdown point of the algorithm."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Image Processing"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1723766"
                        ],
                        "name": "H. Baird",
                        "slug": "H.-Baird",
                        "structuredName": {
                            "firstName": "Henry",
                            "lastName": "Baird",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Baird"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2107761635"
                        ],
                        "name": "S. Jones",
                        "slug": "S.-Jones",
                        "structuredName": {
                            "firstName": "S.",
                            "lastName": "Jones",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Jones"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1798254"
                        ],
                        "name": "S. Fortune",
                        "slug": "S.-Fortune",
                        "structuredName": {
                            "firstName": "Steven",
                            "lastName": "Fortune",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Fortune"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 62735730,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fbe0be8a26a0e9d8889f7f09ded38000faa357ba",
            "isKey": false,
            "numCitedBy": 130,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "A technique for image segmentation using shape-directed covers is described and applied to the fully automatic analysis of complex printed-page layouts. The structure of the background (white space) is analyzed, assisted by an enumeration of all maximal white rectangles. For this enumeration, the most computationally expensive step, an algorithm has been developed that, aside from a sort, achieves an expected runtime linear in the number of black connected components. The crucial engineering decision is the specification of a partial order on white rectangles to express domain-specific knowledge of preferred shapes and sizes. This order determines a sequence of partial covers of the background, and thus, a sequence of nested page segmentations. In experimental trials on Manhattan layouts, good segmentations often occur early in this sequence, using a simple and uniform shape-direction rule. This is a global-to-local strategy, which for some tasks is superior to strategies currently emphasized in the literature, including bottom-up and top-down.<<ETX>>"
            },
            "slug": "Image-segmentation-by-shape-directed-covers-Baird-Jones",
            "title": {
                "fragments": [],
                "text": "Image segmentation by shape-directed covers"
            },
            "tldr": {
                "abstractSimilarityScore": 73,
                "text": "A technique for image segmentation using shape-directed covers is described and applied to the fully automatic analysis of complex printed-page layouts, which for some tasks is superior to strategies currently emphasized in the literature, including bottom-up and top-down."
            },
            "venue": {
                "fragments": [],
                "text": "[1990] Proceedings. 10th International Conference on Pattern Recognition"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3277321"
                        ],
                        "name": "K. Kise",
                        "slug": "K.-Kise",
                        "structuredName": {
                            "firstName": "Koichi",
                            "lastName": "Kise",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Kise"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2064863306"
                        ],
                        "name": "A. Sato",
                        "slug": "A.-Sato",
                        "structuredName": {
                            "firstName": "Akinori",
                            "lastName": "Sato",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Sato"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40411993"
                        ],
                        "name": "M. Iwata",
                        "slug": "M.-Iwata",
                        "structuredName": {
                            "firstName": "Motoi",
                            "lastName": "Iwata",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Iwata"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "8.2.3 Voronoi-Diagram-Based Algorithm Parameters The Voronoi diagram-based algorithm has eleven free parameters and is insensitive to seven of them [ 17 ]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Kise et al. [ 17 ] provided us with a C implementation of the Voronoi-based segmentation algorithm."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "The segmentation algorithm in [ 17 ] is also a bottom-up algorithm based on the Voronoi diagram."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "In research segmentation algorithms that have userspecifiable parameters, typically the default parameter values are selected and no training method is explicitly specified [ 17 ], [1], [28], [13], [30], [5]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Kise et al. [ 17 ] provided us with a C implementation of their Voronoi-based algorithm (a bottom-up algorithm)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "The Docstrum algorithm of O\u2019Gorman [28], the Voronoidiagram-based algorithm of Kise et al. [ 17 ], the run-length smearing algorithm of Wahl et al. [37], the segmentation algorithm of Jain and Yu [13], and the text string separation algorithm of Fletcher and Kasturi [5] are typical bottom-up algorithms, while the X-Y cut by Nagy et al. [26] and the shape-directed-covers-based algorithm by Baird et al. [1] are top-down algorithms."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 23399574,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "be80678c0eeedf754647a8b9adccd5d6d9be3e86",
            "isKey": true,
            "numCitedBy": 275,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a method of page segmentation based on the approximated area Voronoi diagram. The characteristics of the proposed method are as follows: (1) The Voronoi diagram enables us to obtain the candidates of boundaries of document components from page images with non-Manhattan layout and a skew. (2) The candidates are utilized to estimate the intercharacter and interline gaps without the use of domain-specific parameters to select the boundaries. From the experimental results for 128 images with non-Manhattan layout and the skew of 0\u00b0~45\u00b0 as well as 98 images with Manhattan layout, we have confirmed that the method is effective for extraction of body text regions, and it is as efficient as other methods based on connected component analysis."
            },
            "slug": "Segmentation-of-Page-Images-Using-the-Area-Voronoi-Kise-Sato",
            "title": {
                "fragments": [],
                "text": "Segmentation of Page Images Using the Area Voronoi Diagram"
            },
            "tldr": {
                "abstractSimilarityScore": 59,
                "text": "It is confirmed that the proposed method of page segmentation based on the approximated area Voronoi diagram is effective for extraction of body text regions, and it is as efficient as other methods based on connected component analysis."
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Vis. Image Underst."
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145295484"
                        ],
                        "name": "Anil K. Jain",
                        "slug": "Anil-K.-Jain",
                        "structuredName": {
                            "firstName": "Anil",
                            "lastName": "Jain",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Anil K. Jain"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2116415943"
                        ],
                        "name": "B. Yu",
                        "slug": "B.-Yu",
                        "structuredName": {
                            "firstName": "Bin",
                            "lastName": "Yu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Yu"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "A survey of OCR and page segmentation algorithms can be found in O\u2019Gorman and Kasturi [29] and Jain and Yu [ 13 ]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "The Docstrum algorithm of O\u2019Gorman [28], the Voronoidiagram-based algorithm of Kise et al. [17], the run-length smearing algorithm of Wahl et al. [37], the segmentation algorithm of Jain and Yu [ 13 ], and the text string separation algorithm of Fletcher and Kasturi [5] are typical bottom-up algorithms, while the X-Y cut by Nagy et al. [26] and the shape-directed-covers-based algorithm by Baird et al. [1] are top-down algorithms."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "In research segmentation algorithms that have userspecifiable parameters, typically the default parameter values are selected and no training method is explicitly specified [17], [1], [28], [ 13 ], [30], [5]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 46138594,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b39beea0f761152e65fac0e498af387821d887f1",
            "isKey": true,
            "numCitedBy": 250,
            "numCiting": 52,
            "paperAbstract": {
                "fragments": [],
                "text": "Transforming a paper document to its electronic version in a form suitable for efficient storage, retrieval, and interpretation continues to be a challenging problem. An efficient representation scheme for document images is necessary to solve this problem. Document representation involves techniques of thresholding, skew detection, geometric layout analysis, and logical layout analysis. The derived representation can then be used in document storage and retrieval. Page segmentation is an important stage in representing document images obtained by scanning journal pages. The performance of a document understanding system greatly depends on the correctness of page segmentation and labeling of different regions such as text, tables, images, drawings, and rulers. We use the traditional bottom-up approach based on the connected component extraction to efficiently implement page segmentation and region identification. A new document model which preserves top-down generation information is proposed based on which a document is logically represented for interactive editing, storage, retrieval, transfer, and logical analysis. Our algorithm has a high accuracy and takes approximately 1.4 seconds on a SGI Indy workstation for model creation, including orientation estimation, segmentation, and labeling (text, table, image, drawing, and ruler) for a 2550/spl times/3300 image of a typical journal page scanned at 300 dpi. This method is applicable to documents from various technical journals and can accommodate moderate amounts of skew and noise."
            },
            "slug": "Document-Representation-and-Its-Application-to-Page-Jain-Yu",
            "title": {
                "fragments": [],
                "text": "Document Representation and Its Application to Page Decomposition"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A new document model which preserves top-down generation information is proposed based on which a document is logically represented for interactive editing, storage, retrieval, transfer, and logical analysis."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2064264135"
                        ],
                        "name": "A. Hoover",
                        "slug": "A.-Hoover",
                        "structuredName": {
                            "firstName": "Adam",
                            "lastName": "Hoover",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Hoover"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1403999652"
                        ],
                        "name": "G. Jean-Baptiste",
                        "slug": "G.-Jean-Baptiste",
                        "structuredName": {
                            "firstName": "Gillian",
                            "lastName": "Jean-Baptiste",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Jean-Baptiste"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "103801794"
                        ],
                        "name": "Xiao-Yue Jiang",
                        "slug": "Xiao-Yue-Jiang",
                        "structuredName": {
                            "firstName": "Xiao-Yue",
                            "lastName": "Jiang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xiao-Yue Jiang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1704876"
                        ],
                        "name": "P. Flynn",
                        "slug": "P.-Flynn",
                        "structuredName": {
                            "firstName": "Patrick",
                            "lastName": "Flynn",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Flynn"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1720945"
                        ],
                        "name": "H. Bunke",
                        "slug": "H.-Bunke",
                        "structuredName": {
                            "firstName": "Horst",
                            "lastName": "Bunke",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Bunke"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1698267"
                        ],
                        "name": "D. Goldgof",
                        "slug": "D.-Goldgof",
                        "structuredName": {
                            "firstName": "Dmitry",
                            "lastName": "Goldgof",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Goldgof"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143759604"
                        ],
                        "name": "K. Bowyer",
                        "slug": "K.-Bowyer",
                        "structuredName": {
                            "firstName": "K.",
                            "lastName": "Bowyer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Bowyer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1996470"
                        ],
                        "name": "D. Eggert",
                        "slug": "D.-Eggert",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Eggert",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Eggert"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47139824"
                        ],
                        "name": "A. Fitzgibbon",
                        "slug": "A.-Fitzgibbon",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Fitzgibbon",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Fitzgibbon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1843592"
                        ],
                        "name": "Robert B. Fisher",
                        "slug": "Robert-B.-Fisher",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Fisher",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Robert B. Fisher"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Similarly, in performance evaluation literature where the algorithm parameters can be set by evaluators, a set of parameter values are usually selected manually in the training procedure [ 12 ], [15], [32]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "For example, Hoover et al. [ 12 ] proposed an experimental framework for quantitative comparison of range image segmentation algorithms and demonstrated the methodology by evaluating four range segmentation algorithms."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 836587,
            "fieldsOfStudy": [
                "Computer Science",
                "Physics"
            ],
            "id": "91d31a1e9619749051761341e6ac110962475fdf",
            "isKey": false,
            "numCitedBy": 919,
            "numCiting": 57,
            "paperAbstract": {
                "fragments": [],
                "text": "A methodology for evaluating range image segmentation algorithms is proposed. This methodology involves (1) a common set of 40 laser range finder images and 40 structured light scanner images that have manually specified ground truth and (2) a set of defined performance metrics for instances of correctly segmented, missed, and noise regions, over- and under-segmentation, and accuracy of the recovered geometry. A tool is used to objectively compare a machine generated segmentation against the specified ground truth. Four research groups have contributed to evaluate their own algorithm for segmenting a range image into planar patches."
            },
            "slug": "An-Experimental-Comparison-of-Range-Image-Hoover-Jean-Baptiste",
            "title": {
                "fragments": [],
                "text": "An Experimental Comparison of Range Image Segmentation Algorithms"
            },
            "tldr": {
                "abstractSimilarityScore": 61,
                "text": "A methodology for evaluating range image segmentation algorithms and four research groups have contributed to evaluate their own algorithm for segmenting a range image into planar patches."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145916951"
                        ],
                        "name": "G. Nagy",
                        "slug": "G.-Nagy",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Nagy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Nagy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145062511"
                        ],
                        "name": "S. Seth",
                        "slug": "S.-Seth",
                        "structuredName": {
                            "firstName": "Sharad",
                            "lastName": "Seth",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Seth"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145266621"
                        ],
                        "name": "M. Viswanathan",
                        "slug": "M.-Viswanathan",
                        "structuredName": {
                            "firstName": "Mahesh",
                            "lastName": "Viswanathan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Viswanathan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "The Docstrum algorithm of O\u2019Gorman [28], the Voronoidiagram-based algorithm of Kise et al. [17], the run-length smearing algorithm of Wahl et al. [37], the segmentation algorithm of Jain and Yu [13], and the text string separation algorithm of Fletcher and Kasturi [5] are typical bottom-up algorithms, while the X-Y cut by Nagy et al. [ 26 ] and the shape-directed-covers-based algorithm by Baird et al. [1] are top-down algorithms."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "8.3 Hardware and Software Environments We implemented the X-Y cut and Docstrum algorithms based on [ 26 ], [28]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "7.1 The X-Y Cut Page Segmentation Algorithm The X-Y cut segmentation algorithm [ 26 ] is a tree-based, top-down algorithm."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "8.2.1 X-Y Cut Algorithm Parameters The X-Y cut algorithm [ 26 ] has four free parameters."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2530196,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "62a53caea5213ea177298d7b2aff292b1386c37a",
            "isKey": true,
            "numCitedBy": 434,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "Gobbledoc, a system providing remote access to stored documents, which is based on syntactic document analysis and optical character recognition (OCR), is discussed. In Gobbledoc, image processing, document analysis, and OCR operations take place in batch mode when the documents are acquired. The document image acquisition process and the knowledge base that must be entered into the system to process a family of page images are described. The process by which the X-Y tree data structure converts a 2-D page-segmentation problem into a series of 1-D string-parsing problems that can be tackled using conventional compiler tools is also described. Syntactic analysis is used in Gobbledoc to divide each page into labeled rectangular blocks. Blocks labeled text are converted by OCR to obtain a secondary (ASCII) document representation. Since such symbolic files are better suited for computerized search than for human access to the document content and because too many visual layout clues are lost in the OCR process (including some special characters), Gobbledoc preserves the original block images for human browsing. Storage, networking, and display issues specific to document images are also discussed.<<ETX>>"
            },
            "slug": "A-prototype-document-image-analysis-system-for-Nagy-Seth",
            "title": {
                "fragments": [],
                "text": "A prototype document image analysis system for technical journals"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "The document image acquisition process and the knowledge base that must be entered into the system to process a family of page images are described, and the process by which the X-Y tree data structure converts a 2-D page-segmentation problem into a series of 1-D string-parsing problems that can be tackled using conventional compiler tools."
            },
            "venue": {
                "fragments": [],
                "text": "Computer"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143626870"
                        ],
                        "name": "T. Kanungo",
                        "slug": "T.-Kanungo",
                        "structuredName": {
                            "firstName": "Tapas",
                            "lastName": "Kanungo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kanungo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38102633"
                        ],
                        "name": "Gregory A. Marton",
                        "slug": "Gregory-A.-Marton",
                        "structuredName": {
                            "firstName": "Gregory",
                            "lastName": "Marton",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Gregory A. Marton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "37060316"
                        ],
                        "name": "Osama Bulbul",
                        "slug": "Osama-Bulbul",
                        "structuredName": {
                            "firstName": "Osama",
                            "lastName": "Bulbul",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Osama Bulbul"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9854590,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "23441d0ca6c6014f49ab2c58317497375aadb154",
            "isKey": false,
            "numCitedBy": 56,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "Characterizing the performance of Optical Character Recognition (OCR) systems is crucial for monitoring technical progress, predicting OCR performance, providing scientific explanations for the system behavior and identifying open problems. While research has been done in the past to compare performances of two or more OCR systems, all assume that the accuracies achieved on individual documents in a dataset are independent when, in fact, they are not. In this paper we show that accuracies reported on any dataset are correlated and invoke the appropriate statistical technique--the paired model--to compare the accuracies of two recognition systems. Theoretically we show that this method provides tighter confidence intervals than methods used in OCR and computer vision literature. We also proposed a new visualization method, which we call the accuracy scatter plot, for providing a visual summary of performance results. This method summarizes the accuracy comparisons on the entire corpus while simultaneously allowing the researcher to visually compare the performances on individual document images. Finally, we report on the accuracy and speed performances as a function of scanning resolution. Contrary to what one might expect, the performance of one of the systems degrades when the image resolution is increased beyond 300 dpi. Furthermore, the average time taken to OCR a document image, after increasing almost linearly as a function of resolution, suddenly becomes a constant beyond 400 dpi. This behavior is most likely because the OCR algorithm samples the images at resolutions 400 dpi and higher to a standard resolution. The two products that we compare are the Arabic OmniPage 2.0 and the Automatic Page Reader 3.01 from Sakhr. The SAIC Arabic dataset was used for the evaluations. The statistical and visualization methods presented in this article are very general and can be used for comparing accuracies of any two recognition systems, not just OCR systems."
            },
            "slug": "OmniPage-vs.-Sakhr:-paired-model-evaluation-of-two-Kanungo-Marton",
            "title": {
                "fragments": [],
                "text": "OmniPage vs. Sakhr: paired model evaluation of two Arabic OCR products"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "It is shown that accuracies reported on any dataset are correlated and invoke the appropriate statistical technique--the paired model--to compare the accuracies of two recognition systems."
            },
            "venue": {
                "fragments": [],
                "text": "Electronic Imaging"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1398550688"
                        ],
                        "name": "L. O'Gorman",
                        "slug": "L.-O'Gorman",
                        "structuredName": {
                            "firstName": "Lawrence",
                            "lastName": "O'Gorman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. O'Gorman"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "8.2.2 Docstrum Algorithm Parameters O\u2019Gorman, in his paper, specified eight parameters for the Docstrum algorithm [ 28 ]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "In research segmentation algorithms that have userspecifiable parameters, typically the default parameter values are selected and no training method is explicitly specified [17], [1], [ 28 ], [13], [30], [5]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "7.2 The Docstrum Page Segmentation Algorithm Docstrum [ 28 ] is a bottom-up page segmentation algorithm that can work on document page images with non-Manhattan layout and arbitrary skew angles."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "The Docstrum algorithm of O\u2019Gorman [ 28 ], the Voronoidiagram-based algorithm of Kise et al. [17], the run-length smearing algorithm of Wahl et al. [37], the segmentation algorithm of Jain and Yu [13], and the text string separation algorithm of Fletcher and Kasturi [5] are typical bottom-up algorithms, while the X-Y cut by Nagy et al. [26] and the shape-directed-covers-based algorithm by Baird et al. [1] are top-down algorithms."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "8.3 Hardware and Software Environments We implemented the X-Y cut and Docstrum algorithms based on [26], [ 28 ]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 22995244,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d85097da36118fbccfeb7802abf89bf4b4c63a3e",
            "isKey": true,
            "numCitedBy": 728,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "Page layout analysis is a document processing technique used to determine the format of a page. This paper describes the document spectrum (or docstrum), which is a method for structural page layout analysis based on bottom-up, nearest-neighbor clustering of page components. The method yields an accurate measure of skew, within-line, and between-line spacings and locates text lines and text blocks. It is advantageous over many other methods in three main ways: independence from skew angle, independence from different text spacings, and the ability to process local regions of different text orientations within the same image. Results of the method shown for several different page formats and for randomly oriented subpages on the same image illustrate the versatility of the method. We also discuss the differences, advantages, and disadvantages of the docstrum with respect to other lay-out methods. >"
            },
            "slug": "The-Document-Spectrum-for-Page-Layout-Analysis-O'Gorman",
            "title": {
                "fragments": [],
                "text": "The Document Spectrum for Page Layout Analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 57,
                "text": "The document spectrum (or docstrum), which is a method for structural page layout analysis based on bottom-up, nearest-neighbor clustering of page components, yields an accurate measure of skew, within-line, and between-line spacings and locates text lines and text blocks."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2294095"
                        ],
                        "name": "M. Powell",
                        "slug": "M.-Powell",
                        "structuredName": {
                            "firstName": "M.",
                            "lastName": "Powell",
                            "middleNames": [
                                "J.",
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Powell"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Direct search algorithms are typically used for solving optimization problems involving this kind of objective function [19], [38], [ 34 ]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 57917027,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c514310fe4550f947f2aaaef88e56610daa5047a",
            "isKey": false,
            "numCitedBy": 478,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "Many different procedures have been proposed for optimization calculations when first derivatives are not available. Further, several researchers have contributed to the subject, including some who wish to prove convergence theorems, and some who wish to make any reduction in the least calculated value of the objective function. There is not even a key idea that can be used as a foundation of a review, except for the problem itself, which is the adjustment of variables so that a function becomes least, where each value of the function is returned by a subroutine for each trial vector of variables. Therefore the paper is a collection of essays on particular strategies and algorithms, in order to consider the advantages, limitations and theory of several techniques. The subjects addressed are line search methods, the restriction of vectors of variables to discrete grids, the use of geometric simplices, conjugate direction procedures, trust region algorithms that form linear or quadratic approximations to the objective function, and simulated annealing. We study the main features of the methods themselves, instead of providing a catalogue of references to published work, because an understanding of these features may be very helpful to future research."
            },
            "slug": "Direct-search-algorithms-for-optimization-Powell",
            "title": {
                "fragments": [],
                "text": "Direct search algorithms for optimization calculations"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "Line search methods, the restriction of vectors of variables to discrete grids, the use of geometric simplices, conjugate direction procedures, trust region algorithms that form linear or quadratic approximations to the objective function, and simulated annealing are addressed."
            },
            "venue": {
                "fragments": [],
                "text": "Acta Numerica"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143759604"
                        ],
                        "name": "K. Bowyer",
                        "slug": "K.-Bowyer",
                        "structuredName": {
                            "firstName": "K.",
                            "lastName": "Bowyer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Bowyer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145691986"
                        ],
                        "name": "P. Phillips",
                        "slug": "P.-Phillips",
                        "structuredName": {
                            "firstName": "P.",
                            "lastName": "Phillips",
                            "middleNames": [
                                "Jonathon"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Phillips"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 59782472,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e27be4b432b98ce75da65653ac8e21518c2a97e1",
            "isKey": false,
            "numCitedBy": 160,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "From the Publisher: \nEmpirical Evaluation Techniques in Computer Vision presents methods that allow comparative assessment of algorithms and the accompanying benefits: places computer vision on solid experimental and scientific grounds, assists the development of engineering solutions to practical problems, allows accurate assessments of computer vision research, provides convincing evidence that computer vision research results in practical solutions. The chapters in this volume cover the three main paradigms for evaluating computer vision algorithms. The paradigms are: (1) evaluations that are independently administered, (2) evaluation of a set of algorithms by one research group, and (3) evaluation methods that feature ground truthing procedures as a major component."
            },
            "slug": "Empirical-evaluation-techniques-in-computer-vision-Bowyer-Phillips",
            "title": {
                "fragments": [],
                "text": "Empirical evaluation techniques in computer vision"
            },
            "tldr": {
                "abstractSimilarityScore": 76,
                "text": "Empirical Evaluation Techniques in Computer Vision presents methods that allow comparative assessment of algorithms and the accompanying benefits and provides convincing evidence that computer vision research results in practical solutions."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47260288"
                        ],
                        "name": "L. Fletcher",
                        "slug": "L.-Fletcher",
                        "structuredName": {
                            "firstName": "Lloyd",
                            "lastName": "Fletcher",
                            "middleNames": [
                                "Alan"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Fletcher"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3110392"
                        ],
                        "name": "R. Kasturi",
                        "slug": "R.-Kasturi",
                        "structuredName": {
                            "firstName": "Rangachar",
                            "lastName": "Kasturi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Kasturi"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "In research segmentation algorithms that have userspecifiable parameters, typically the default parameter values are selected and no training method is explicitly specified [17], [1], [28], [13], [30], [ 5 ]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "The Docstrum algorithm of O\u2019Gorman [28], the Voronoidiagram-based algorithm of Kise et al. [17], the run-length smearing algorithm of Wahl et al. [37], the segmentation algorithm of Jain and Yu [13], and the text string separation algorithm of Fletcher and Kasturi [ 5 ] are typical bottom-up algorithms, while the X-Y cut by Nagy et al. [26] and the shape-directed-covers-based algorithm by Baird et al. [1] are top-down algorithms."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2685456,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b08e547ba4edb60902d1708a5593d71f075aa7f1",
            "isKey": false,
            "numCitedBy": 655,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "The development and implementation of an algorithm for automated text string separation that is relatively independent of changes in text font style and size and of string orientation are described. It is intended for use in an automated system for document analysis. The principal parts of the algorithm are the generation of connected components and the application of the Hough transform in order to group components into logical character strings that can then be separated from the graphics. The algorithm outputs two images, one containing text strings and the other graphics. These images can then be processed by suitable character recognition and graphics recognition systems. The performance of the algorithm, both in terms of its effectiveness and computational efficiency, was evaluated using several test images and showed superior performance compared to other techniques. >"
            },
            "slug": "A-Robust-Algorithm-for-Text-String-Separation-from-Fletcher-Kasturi",
            "title": {
                "fragments": [],
                "text": "A Robust Algorithm for Text String Separation from Mixed Text/Graphics Images"
            },
            "tldr": {
                "abstractSimilarityScore": 85,
                "text": "The development and implementation of an algorithm for automated text string separation that is relatively independent of changes in text font style and size and of string orientation are described and showed superior performance compared to other techniques."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1744200"
                        ],
                        "name": "I. T. Phillips",
                        "slug": "I.-T.-Phillips",
                        "structuredName": {
                            "firstName": "Ihsin",
                            "lastName": "Phillips",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. T. Phillips"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34817063"
                        ],
                        "name": "A. Chhabra",
                        "slug": "A.-Chhabra",
                        "structuredName": {
                            "firstName": "Atul",
                            "lastName": "Chhabra",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Chhabra"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Similarly, in performance evaluation literature where the algorithm parameters can be set by evaluators, a set of parameter values are usually selected manually in the training procedure [12], [15], [ 32 ]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Phillips and Chhabra [ 32 ] presented a methodology for empirically evaluating graphics recognition systems."
                    },
                    "intents": []
                }
            ],
            "corpusId": 31517603,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "34a78626bf0277710cb9ab192ec0c094d2bfb784",
            "isKey": false,
            "numCitedBy": 173,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "Presents a methodology for evaluating graphics recognition systems operating on images that contain straight lines, circles, circular arcs, and text blocks. It enables an empirical comparison of vectorization software packages and uses practical performance evaluation methods that can be applied to complete vectorization systems. The methodology includes a set of matching criteria for pairs of graphical entities, a set of performance evaluation metrics, and a benchmark for the evaluation of graphics recognition systems. The benchmark was tested on three systems. The results are reported and analyzed in the paper."
            },
            "slug": "Empirical-Performance-Evaluation-of-Graphics-Phillips-Chhabra",
            "title": {
                "fragments": [],
                "text": "Empirical Performance Evaluation of Graphics Recognition Systems"
            },
            "tldr": {
                "abstractSimilarityScore": 99,
                "text": "Presents a methodology for evaluating graphics recognition systems operating on images that contain straight lines, circles, circular arcs, and text blocks that enables an empirical comparison of vectorization software packages and uses practical performance evaluation methods that can be applied to complete vectorization systems."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1880661"
                        ],
                        "name": "F. Wahl",
                        "slug": "F.-Wahl",
                        "structuredName": {
                            "firstName": "Friedrich",
                            "lastName": "Wahl",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Wahl"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145470231"
                        ],
                        "name": "Kwan Y. Wong",
                        "slug": "Kwan-Y.-Wong",
                        "structuredName": {
                            "firstName": "Kwan",
                            "lastName": "Wong",
                            "middleNames": [
                                "Y."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kwan Y. Wong"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34896449"
                        ],
                        "name": "R. Casey",
                        "slug": "R.-Casey",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Casey",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Casey"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 41585742,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4947ddbda627747c9b13da81514f0129597e91de",
            "isKey": false,
            "numCitedBy": 173,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Block-segmentation-and-text-extraction-in-mixed-Wahl-Wong",
            "title": {
                "fragments": [],
                "text": "Block segmentation and text extraction in mixed text/image documents"
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Graph. Image Process."
            },
            "year": 1982
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145691986"
                        ],
                        "name": "P. Phillips",
                        "slug": "P.-Phillips",
                        "structuredName": {
                            "firstName": "P.",
                            "lastName": "Phillips",
                            "middleNames": [
                                "Jonathon"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Phillips"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40638847"
                        ],
                        "name": "Hyeonjoon Moon",
                        "slug": "Hyeonjoon-Moon",
                        "structuredName": {
                            "firstName": "Hyeonjoon",
                            "lastName": "Moon",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hyeonjoon Moon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2958806"
                        ],
                        "name": "S. A. Rizvi",
                        "slug": "S.-A.-Rizvi",
                        "structuredName": {
                            "firstName": "Syed",
                            "lastName": "Rizvi",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. A. Rizvi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3313513"
                        ],
                        "name": "Patrick J. Rauss",
                        "slug": "Patrick-J.-Rauss",
                        "structuredName": {
                            "firstName": "Patrick",
                            "lastName": "Rauss",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Patrick J. Rauss"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 497801,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "791e530f6a4098bb39696d1476032821a7a1c569",
            "isKey": false,
            "numCitedBy": 2335,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "Two of the most critical requirements in support of producing reliable face-recognition systems are a large database of facial images and a testing procedure to evaluate systems. The Face Recognition Technology (FERET) program has addressed both issues through the FERET database of facial images and the establishment of the FERET tests. To date, 14,126 images from 1199 individuals are included in the FERET database, which is divided into development and sequestered portions. In September 1996, the FERET program administered the third in a series of FERET face-recognition tests. The primary objectives of the third test were to (1) assess the state of the art, (2) identify future areas of research, and (3) measure algorithm performance on large databases."
            },
            "slug": "The-FERET-evaluation-methodology-for-algorithms-Phillips-Moon",
            "title": {
                "fragments": [],
                "text": "The FERET evaluation methodology for face-recognition algorithms"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "Two of the most critical requirements in support of producing reliable face-recognition systems are a large database of facial images and a testing procedure to evaluate systems."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1710238"
                        ],
                        "name": "R. Haralick",
                        "slug": "R.-Haralick",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Haralick",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Haralick"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35086889"
                        ],
                        "name": "S. Sternberg",
                        "slug": "S.-Sternberg",
                        "structuredName": {
                            "firstName": "Stanley",
                            "lastName": "Sternberg",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Sternberg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145238884"
                        ],
                        "name": "X. Zhuang",
                        "slug": "X.-Zhuang",
                        "structuredName": {
                            "firstName": "Xinhua",
                            "lastName": "Zhuang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "X. Zhuang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "We provide the definitions of our proposed textline-based error measures and metric based on set theory and mathematical morphology [ 10 ]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "We now define two morphological operations: dilation and erosion [ 10 ]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 1493641,
            "fieldsOfStudy": [
                "Materials Science"
            ],
            "id": "d2a25c0836805a90cd3fe3eac2322f24250560f6",
            "isKey": false,
            "numCitedBy": 2463,
            "numCiting": 50,
            "paperAbstract": {
                "fragments": [],
                "text": "For the purposes of object or defect identification required in industrial vision applications, the operations of mathematical morphology are more useful than the convolution operations employed in signal processing because the morphological operators relate directly to shape. The tutorial provided in this paper reviews both binary morphology and gray scale morphology, covering the operations of dilation, erosion, opening, and closing and their relations. Examples are given for each morphological concept and explanations are given for many of their interrelationships."
            },
            "slug": "Image-Analysis-Using-Mathematical-Morphology-Haralick-Sternberg",
            "title": {
                "fragments": [],
                "text": "Image Analysis Using Mathematical Morphology"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "The tutorial provided in this paper reviews both binary morphology and gray scale morphology, covering the operations of dilation, erosion, opening, and closing and their relations."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "27975036"
                        ],
                        "name": "R. Lewis",
                        "slug": "R.-Lewis",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Lewis",
                            "middleNames": [
                                "Michael"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Lewis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2776399"
                        ],
                        "name": "V. Torczon",
                        "slug": "V.-Torczon",
                        "structuredName": {
                            "firstName": "Virginia",
                            "lastName": "Torczon",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Torczon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3142467"
                        ],
                        "name": "M. Trosset",
                        "slug": "M.-Trosset",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Trosset",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Trosset"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Direct search algorithms are typically used for solving optimization problems involving this kind of objective function [ 19 ], [38], [34]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14188673,
            "fieldsOfStudy": [
                "Business"
            ],
            "id": "19e2eeaa867cabe9c2ca592294eb7cb90a10812a",
            "isKey": false,
            "numCitedBy": 69,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "Pattern search methods are a class of direct search methods for nonlinear optimization. Since the introduction of the original pattern search methods in the late 1950s and early 1960s, they have remained popular with users due to their simplicity and the fact that they work well in practice on a variety of problems. More recently, the fact that they are provably convergent has generated renewed interest in the nonlinear programming community. The purpose of this article is to describe what pattern search methods are and why they work."
            },
            "slug": "Why-Pattern-Search-Works-Lewis-Torczon",
            "title": {
                "fragments": [],
                "text": "Why Pattern Search Works"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145323121"
                        ],
                        "name": "J. Nelder",
                        "slug": "J.-Nelder",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Nelder",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Nelder"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144189443"
                        ],
                        "name": "R. Mead",
                        "slug": "R.-Mead",
                        "structuredName": {
                            "firstName": "Roger",
                            "lastName": "Mead",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Mead"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "8.2 Algorithm Training and Testing We fix the parameters that the algorithm is insensitive to and automatically train the ones that the algorithm is sensitive to on the 100-page training data set T . Nelder-Mead simplex optimization procedure [ 27 ] is used to search for the optimal parameter value for each algorithm."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "We chose the simplex search method proposed by Nelder and Mead [ 27 ]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "We choose the simplex search method proposed by Nelder and Mead [ 27 ] to minimize our objective function."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2208295,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "017ddb7e815236defd0566bc46f6ed8401cc6ba6",
            "isKey": true,
            "numCitedBy": 25603,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "A method is described for the minimization of a function of n variables, which depends on the comparison of function values at the (n 41) vertices of a general simplex, followed by the replacement of the vertex with the highest value by another point. The simplex adapts itself to the local landscape, and contracts on to the final minimum. The method is shown to be effective and computationally compact. A procedure is given for the estimation of the Hessian matrix in the neighbourhood of the minimum, needed in statistical estimation problems."
            },
            "slug": "A-Simplex-Method-for-Function-Minimization-Nelder-Mead",
            "title": {
                "fragments": [],
                "text": "A Simplex Method for Function Minimization"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "A method is described for the minimization of a function of n variables, which depends on the comparison of function values at the (n 41) vertices of a general simplex, followed by the replacement of the vertex with the highest value by another point."
            },
            "venue": {
                "fragments": [],
                "text": "Comput. J."
            },
            "year": 1965
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1715339"
                        ],
                        "name": "D. Goldberg",
                        "slug": "D.-Goldberg",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Goldberg",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Goldberg"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "\u201cSimulated annealing\u201d [18] and \u201cgenetic\u201d [ 7 ] algorithms are possible global search algorithms that could have been used instead."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 38613589,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2e62d1345b340d5fda3b092c460264b9543bc4b5",
            "isKey": false,
            "numCitedBy": 58106,
            "numCiting": 1,
            "paperAbstract": {
                "fragments": [],
                "text": "From the Publisher: \nThis book brings together - in an informal and tutorial fashion - the computer techniques, mathematical tools, and research results that will enable both students and practitioners to apply genetic algorithms to problems in many fields. \n \nMajor concepts are illustrated with running examples, and major algorithms are illustrated by Pascal computer programs. No prior knowledge of GAs or genetics is assumed, and only a minimum of computer programming and mathematics background is required."
            },
            "slug": "Genetic-Algorithms-in-Search-Optimization-and-Goldberg",
            "title": {
                "fragments": [],
                "text": "Genetic Algorithms in Search Optimization and Machine Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 72,
                "text": "This book brings together the computer techniques, mathematical tools, and research results that will enable both students and practitioners to apply genetic algorithms to problems in many fields."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1744288"
                        ],
                        "name": "P. Gill",
                        "slug": "P.-Gill",
                        "structuredName": {
                            "firstName": "Philip",
                            "lastName": "Gill",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Gill"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143873253"
                        ],
                        "name": "W. Murray",
                        "slug": "W.-Murray",
                        "structuredName": {
                            "firstName": "Walter",
                            "lastName": "Murray",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Murray"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685738"
                        ],
                        "name": "M. H. Wright",
                        "slug": "M.-H.-Wright",
                        "structuredName": {
                            "firstName": "Margaret",
                            "lastName": "Wright",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. H. Wright"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 82,
                                "start": 79
                            }
                        ],
                        "text": "This objective function can be classified as a multivariate nonsmooth function [6]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 20611582,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b8d9abd1c078573188b13d36c1b1efb7cb2fa865",
            "isKey": false,
            "numCitedBy": 7627,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "Practical Optimization MethodsFree eBook: Practical Aspects of Structural Optimization [1701.01450] Practical optimization for hybrid quantum Practical Optimization | 4e70c9cf5faf796993a61adc9f46f2c5Acces PDF Practical OptimizationPractical Bayesian Optimization of Machine Learning Particle Swarm Optimization (PSO) An Overview Practical Issues Optimization Algorithms in Physics Practical Mathematical Optimization Universit T BremenA Practical Price Optimization Approach for Omnichannel A Gentle Introduction to Stochastic Optimization AlgorithmsApplied Sciences | Free Full-Text | Evolutionary 0387986316 Practical Optimization Methods: with A Lecture on Model Predictive ControlPractical Optimization : Algorithms and Engineering Wiley Series in Discrete Mathematics and Optimization Ser PRACTICAL OPTIMIZATION uCozEvolutionary practical optimization | DeepDyveA Practical Guide To Hyperparameter Optimization.Blood platelet production: a novel approach for practical [PDF] Practical Bilevel Optimization Download and Read Stability and Sample-based Approximations of Composite Practical portfolio optimization in Python (2/3) machine (PDF) Practical Financial Optimization. Decision making A Multiobjective Optimization Model for Prevention and Particle swarm optimization WikipediaPractical Methods Of Optimization|RPractical Portfolio Optimization London Business SchoolBao: Making Learned Query Optimization PracticalApache Spark Core Practical Optimization DatabricksPractical Methods of Optimization by R. FletcherChapter 11 Nonlinear Optimization Examples4.7 Applied Optimization Problems \u2013 Calculus Volume 1Practical bayesian optimization using Goptuna | by Masashi Practical Optimization Methods For 4th Generation Cellular Facility location problems \u2014 Mathematical Optimization Practical optimization (2004 edition) | Open Library[J726.Ebook] PDF Download Practical Optimization of Multi-objective Exploration for Practical Optimization Practical Optimization: a Gentle Introduction has moved!?Practical Rod Pumping Optimization on Apple Books(PDF) Practical Optimization with MATLAB The Free StudyPractical portfolio optimization in Python (3/3) code (PDF) Practical, Fast and Robust Point Cloud Registration Numerical Optimization Stanford UniversityPractical Optimization Methods with Mathematica ApplicationsPractical Optimization | 4e70c9cf5faf796993a61adc9f46f2c5Search Engine Optimization: Practical Marketing TechniquesLagout.orgMeter Placement in Active Distribution System using Manual: Practical guide to optimization for mobiles Unity"
            },
            "slug": "Practical-optimization-Gill-Murray",
            "title": {
                "fragments": [],
                "text": "Practical optimization"
            },
            "tldr": {
                "abstractSimilarityScore": 59,
                "text": "This ebook Practical Optimization by Philip E. Gill is presented in pdf format and the full version of this ebook in DjVu, ePub, doc, txt, PDF forms is presented."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1981
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2499975"
                        ],
                        "name": "J. Kanai",
                        "slug": "J.-Kanai",
                        "structuredName": {
                            "firstName": "Junichi",
                            "lastName": "Kanai",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Kanai"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688357"
                        ],
                        "name": "S. V. Rice",
                        "slug": "S.-V.-Rice",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Rice",
                            "middleNames": [
                                "V."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. V. Rice"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688975"
                        ],
                        "name": "T. Nartker",
                        "slug": "T.-Nartker",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Nartker",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Nartker"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145916951"
                        ],
                        "name": "G. Nagy",
                        "slug": "G.-Nagy",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Nagy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Nagy"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Kanai et al. [ 14 ] proposed a metric that is a weighted sum of the number of edit operations (insertions, deletions, and moves)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 30733052,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5bd99ebf0bbe9a8513350d9eae4f3570c99d559b",
            "isKey": false,
            "numCitedBy": 100,
            "numCiting": 3,
            "paperAbstract": {
                "fragments": [],
                "text": "Many current optical character recognition (OCR) systems attempt to decompose printed pages into a set of zones, each containing a single column of text, before converting the characters into coded form. The authors present a methodology for automatically assessing the accuracy of such decompositions, and demonstrate its use in evaluating six OCR systems. >"
            },
            "slug": "Automated-Evaluation-of-OCR-Zoning-Kanai-Rice",
            "title": {
                "fragments": [],
                "text": "Automated Evaluation of OCR Zoning"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "A methodology for automatically assessing the accuracy of optical character recognition decompositions is presented, and its use in evaluating six OCR systems is demonstrated."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1754659"
                        ],
                        "name": "J. Hollingsworth",
                        "slug": "J.-Hollingsworth",
                        "structuredName": {
                            "firstName": "Jeffrey",
                            "lastName": "Hollingsworth",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Hollingsworth"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "116891359"
                        ],
                        "name": "E. Guven",
                        "slug": "E.-Guven",
                        "structuredName": {
                            "firstName": "Esra",
                            "lastName": "Guven",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Guven"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2899796"
                        ],
                        "name": "C. Akinlar",
                        "slug": "C.-Akinlar",
                        "structuredName": {
                            "firstName": "Cuneyt",
                            "lastName": "Akinlar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Akinlar"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Algorithm timing performance depends on hardware and software factors, such as machine type, operating system, memory size, network protocol [ 11 ], etc."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 17224340,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "73cb5c25982c5bd095e01f5d12f054e16fe695a1",
            "isKey": false,
            "numCitedBy": 8,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "Presents a benchmarking study that compares the performance of a network of four PCs connected by a 100 Mbit/s fast Ethernet running three different system software configurations: TCP/IP on Windows NT, TCP/IP on Linux and a lightweight message-passing protocol (U-Net active messages) on Linux. For each configuration, we report results for communication micro-benchmarks and the NAS (Numerical Aerodynamics Simulation) parallel benchmarks. For the NAS benchmarks, the overall running time using Linux TCP/IP was 12-500% less than the Windows NT TCP/IP configuration. Likewise, the Linux U-Net based message-passing protocol outperformed the Linux TCP/IP version by 5-200%+. We also show that, by using Linux U-Net, we are able to achieve 125 /spl mu/s latency between two processes using PVM. Finally, we report that the default mathematical libraries supplied with NT (for both gcc and Visual C++) are substantially slower than the one supplied with Linux."
            },
            "slug": "Benchmarking-a-network-of-PCs-running-parallel-Hollingsworth-Guven",
            "title": {
                "fragments": [],
                "text": "Benchmarking a network of PCs running parallel applications"
            },
            "tldr": {
                "abstractSimilarityScore": 75,
                "text": "A benchmarking study that compares the performance of a network of four PCs connected by a 100 Mbit/s fast Ethernet running three different system software configurations and a lightweight message-passing protocol (U-Net active messages) on Linux finds that the default mathematical libraries supplied with NT are substantially slower than the one supplied with Linux."
            },
            "venue": {
                "fragments": [],
                "text": "1998 IEEE International Performance, Computing and Communications Conference. Proceedings (Cat. No.98CH36191)"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1604429801"
                        ],
                        "name": "Robert M. Haralock",
                        "slug": "Robert-M.-Haralock",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Haralock",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Robert M. Haralock"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1809809"
                        ],
                        "name": "L. Shapiro",
                        "slug": "L.-Shapiro",
                        "structuredName": {
                            "firstName": "Linda",
                            "lastName": "Shapiro",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Shapiro"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 61087042,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a9eaaecf23f3a4b7822e4bcca924e02cd5b4dc4e",
            "isKey": false,
            "numCitedBy": 3343,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "From the Publisher: \nThis two-volume set is an authoritative, comprehensive, modern work on computer vision that covers all of the different areas of vision with a balanced and unified approach. The discussion in \"Volume I\" focuses on image in, and image out or feature set out. \"Volume II\" covers the higher level techniques of illumination, perspective projection, analytical photogrammetry, motion, image matching, consistent labeling, model matching, and knowledge-based vision systems."
            },
            "slug": "Computer-and-Robot-Vision-Haralock-Shapiro",
            "title": {
                "fragments": [],
                "text": "Computer and Robot Vision"
            },
            "tldr": {
                "abstractSimilarityScore": 89,
                "text": "This two-volume set is an authoritative, comprehensive, modern work on computer vision that covers all of the different areas of vision with a balanced and unified approach."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2799422"
                        ],
                        "name": "P. V. Laarhoven",
                        "slug": "P.-V.-Laarhoven",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Laarhoven",
                            "middleNames": [
                                "J.",
                                "M.",
                                "van"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. V. Laarhoven"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1796770"
                        ],
                        "name": "E. Aarts",
                        "slug": "E.-Aarts",
                        "structuredName": {
                            "firstName": "Emile",
                            "lastName": "Aarts",
                            "middleNames": [
                                "H.",
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Aarts"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 26,
                                "start": 22
                            }
                        ],
                        "text": "aSimulated annealingo [18] and agenetico [7] algorithms are possible global search algorithms that could have been used instead."
                    },
                    "intents": []
                }
            ],
            "corpusId": 61815519,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "29b4cdd84e5b657339749c12028ec25310c79764",
            "isKey": false,
            "numCitedBy": 3594,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "1 Introduction.- 2 Simulated annealing.- 3 Asymptotic convergence results.- 4 The relation with statistical physics.- 5 Towards implementing the algorithm.- 6 Performance of the simulated annealing algorithm.- 7 Applications.- 8 Some miscellaneous topics.- 9 Summary and conclusions."
            },
            "slug": "Simulated-Annealing:-Theory-and-Applications-Laarhoven-Aarts",
            "title": {
                "fragments": [],
                "text": "Simulated Annealing: Theory and Applications"
            },
            "tldr": {
                "abstractSimilarityScore": 58,
                "text": "Performance of the simulated annealing algorithm and the relation with statistical physics and asymptotic convergence results are presented."
            },
            "venue": {
                "fragments": [],
                "text": "Mathematics and Its Applications"
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1750195"
                        ],
                        "name": "E. Trucco",
                        "slug": "E.-Trucco",
                        "structuredName": {
                            "firstName": "Emanuele",
                            "lastName": "Trucco",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Trucco"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 60788031,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0ab81a64aa4f5a9099e2099cd3fffbe21e5bcbb1",
            "isKey": false,
            "numCitedBy": 1741,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Computer and Robot Vision Vol. 1, by R.M. Haralick and Linda G. Shapiro, Addison-Wesley, 1992, ISBN 0-201-10887-1."
            },
            "slug": "Computer-and-Robot-Vision-Trucco",
            "title": {
                "fragments": [],
                "text": "Computer and Robot Vision"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 70,
                                "start": 66
                            }
                        ],
                        "text": "We implemented the X-Y cut and Docstrum algorithms based on [26], [28]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 188,
                                "start": 184
                            }
                        ],
                        "text": "In research segmentation algorithms that have userspecifiable parameters, typically the default parameter values are selected and no training method is explicitly specified [17], [1], [28], [13], [30], [5]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 73,
                                "start": 65
                            }
                        ],
                        "text": "A\nsurvey of OCR and page segmentation algorithms can be found in O'Gorman and Kasturi [29] and Jain and Yu [13]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 39,
                                "start": 35
                            }
                        ],
                        "text": "The Docstrum algorithm of O'Gorman [28], the Voronoidiagram-based algorithm of Kise et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 34,
                                "start": 26
                            }
                        ],
                        "text": "The\nDocstrum algorithm of O'Gorman [28], the Voronoidiagram-based algorithm of Kise et al. [17], the run-length\nsmearing algorithm of Wahl et al. [37], the segmentation algorithm of Jain and Yu [13], and the text string separation\nalgorithm of Fletcher and Kasturi [5] are typical bottom-up\nalgorithms, while the X-Y cut by Nagy et al. [26] and the shape-directed-covers-based algorithm by Baird et al. [1]\nare top-down algorithms."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 13,
                                "start": 9
                            }
                        ],
                        "text": "Docstrum [28] is a bottom-up page segmentation algorithm that can work on document page images with nonManhattan layout and arbitrary skew angles."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 82,
                                "start": 78
                            }
                        ],
                        "text": "O'Gorman, in his paper, specified eight parameters for the Docstrum algorithm [28]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aThe Document Spectrum for Page Layout Analysis,o"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Analysis and Machine Intelligence,"
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 26,
                                "start": 22
                            }
                        ],
                        "text": "The X-Y cut algorithm [26] has four free parameters."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 39,
                                "start": 35
                            }
                        ],
                        "text": "The X-Y cut segmentation algorithm [26] is a tree-based, top-down algorithm."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[26] and the shape-directed-covers-based algorithm by Baird et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 64,
                                "start": 60
                            }
                        ],
                        "text": "We implemented the X-Y cut and Docstrum algorithms based on [26], [28]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "and M"
            },
            "venue": {
                "fragments": [],
                "text": "Viswanathan, aA Prototype Document Image Analysis System for Technical Journals,o Computer, vol. 25, pp. 10-22"
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[17], the run-length smearing algorithm of Wahl et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 177,
                                "start": 173
                            }
                        ],
                        "text": "In research segmentation algorithms that have userspecifiable parameters, typically the default parameter values are selected and no training method is explicitly specified [17], [1], [28], [13], [30], [5]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 103,
                                "start": 99
                            }
                        ],
                        "text": "The Voronoi diagram-based algorithm has eleven free parameters and is insensitive to seven of them [17]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[17] provided us with a C implementation of the Voronoi-based segmentation algorithm."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 34,
                                "start": 30
                            }
                        ],
                        "text": "The segmentation algorithm in [17] is also a bottom-up algorithm based on the Voronoi diagram."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[17] provided us with a C implementation of their Voronoi-based algorithm (a bottom-up algorithm)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "and M"
            },
            "venue": {
                "fragments": [],
                "text": "Iwata, aSegmentation of Page Images Using the Area Voronoi Diagram,o Computer Vision and Image Understanding, vol. 70, pp. 370-382"
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 67,
                                "start": 63
                            }
                        ],
                        "text": "We chose the simplex search method proposed by Nelder and Mead [27]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 68,
                                "start": 64
                            }
                        ],
                        "text": "We choose the simplex search method proposed by Nelder and Mead [27] to minimize our objective function."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 62,
                                "start": 47
                            }
                        ],
                        "text": "We chose the simplex search method\nproposed by Nelder and Mead [27]. \u00aaSimulated annealing\u00ba\n[18] and \u00aagenetic\u00ba [7] algorithms are possible global search\nalgorithms that could have been used instead."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 40,
                                "start": 36
                            }
                        ],
                        "text": "Mead simplex optimization procedure [27] is used to search"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 10,
                                "start": 6
                            }
                        ],
                        "text": "NelderMead simplex optimization procedure [27] is used to search\nfor the optimal parameter value for each algorithm."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 63,
                                "start": 59
                            }
                        ],
                        "text": "For a segmentation algorithm with n parameters, the Nelder-Mead algorithm works, as shown in Fig."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aA Simplex Method for Function Minimization,o"
            },
            "venue": {
                "fragments": [],
                "text": "Computer J.,"
            },
            "year": 1965
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 264,
                                "start": 244
                            }
                        ],
                        "text": "The\nDocstrum algorithm of O'Gorman [28], the Voronoidiagram-based algorithm of Kise et al. [17], the run-length\nsmearing algorithm of Wahl et al. [37], the segmentation algorithm of Jain and Yu [13], and the text string separation\nalgorithm of Fletcher and Kasturi [5] are typical bottom-up\nalgorithms, while the X-Y cut by Nagy et al. [26] and the shape-directed-covers-based algorithm by Baird et al. [1]\nare top-down algorithms."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 85,
                                "start": 78
                            }
                        ],
                        "text": "A\nsurvey of OCR and page segmentation algorithms can be found in O'Gorman and Kasturi [29] and Jain and Yu [13]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 122,
                                "start": 119
                            }
                        ],
                        "text": "[37], the segmentation algorithm of Jain and Yu [13], and the text string separation algorithm of Fletcher and Kasturi [5] are typical bottom-up algorithms, while the X-Y cut by Nagy et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 205,
                                "start": 202
                            }
                        ],
                        "text": "In research segmentation algorithms that have userspecifiable parameters, typically the default parameter values are selected and no training method is explicitly specified [17], [1], [28], [13], [30], [5]."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aA Robust Algorithm for Text String Separation from Mixed Text/Graphics Imageso IEEE Trans"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Analysis and Machine Intelligence, vol. 10, pp. 910-918"
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2060983236"
                        ],
                        "name": "D. E. Goldberg",
                        "slug": "D.-E.-Goldberg",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Goldberg",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. E. Goldberg"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 44,
                                "start": 41
                            }
                        ],
                        "text": "aSimulated annealingo [18] and agenetico [7] algorithms are possible global search algorithms that could have been used instead."
                    },
                    "intents": []
                }
            ],
            "corpusId": 61406969,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fc2806a373aefe9ec9fd02e6369fdf9b6a6ff8e4",
            "isKey": false,
            "numCitedBy": 12628,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Genetic-Algorithms-in-Search-Goldberg",
            "title": {
                "fragments": [],
                "text": "Genetic Algorithms in Search"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1398550688"
                        ],
                        "name": "L. O'Gorman",
                        "slug": "L.-O'Gorman",
                        "structuredName": {
                            "firstName": "Lawrence",
                            "lastName": "O'Gorman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. O'Gorman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3110392"
                        ],
                        "name": "R. Kasturi",
                        "slug": "R.-Kasturi",
                        "structuredName": {
                            "firstName": "Rangachar",
                            "lastName": "Kasturi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Kasturi"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 28806157,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9a86dc89b61aa7466dae342842f79aeb9778320f",
            "isKey": false,
            "numCitedBy": 65,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Document-Image-Analysis-Systems-Guest-Editors'-to-O'Gorman-Kasturi",
            "title": {
                "fragments": [],
                "text": "Document Image Analysis Systems - Guest Editors' Introduction to the Special Issue"
            },
            "venue": {
                "fragments": [],
                "text": "Computer"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1398550688"
                        ],
                        "name": "L. O'Gorman",
                        "slug": "L.-O'Gorman",
                        "structuredName": {
                            "firstName": "Lawrence",
                            "lastName": "O'Gorman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. O'Gorman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3110392"
                        ],
                        "name": "R. Kasturi",
                        "slug": "R.-Kasturi",
                        "structuredName": {
                            "firstName": "Rangachar",
                            "lastName": "Kasturi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Kasturi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 264,
                                "start": 257
                            }
                        ],
                        "text": "The\nDocstrum algorithm of O'Gorman [28], the Voronoidiagram-based algorithm of Kise et al. [17], the run-length\nsmearing algorithm of Wahl et al. [37], the segmentation algorithm of Jain and Yu [13], and the text string separation\nalgorithm of Fletcher and Kasturi [5] are typical bottom-up\nalgorithms, while the X-Y cut by Nagy et al. [26] and the shape-directed-covers-based algorithm by Baird et al. [1]\nare top-down algorithms."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 85,
                                "start": 65
                            }
                        ],
                        "text": "A\nsurvey of OCR and page segmentation algorithms can be found in O'Gorman and Kasturi [29] and Jain and Yu [13]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 90,
                                "start": 86
                            }
                        ],
                        "text": "A survey of OCR and page segmentation algorithms can be found in O'Gorman and Kasturi [29] and Jain and Yu [13]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 6575783,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c43505cc450b647f6f3b4a6f9004ae7d414e2bea",
            "isKey": false,
            "numCitedBy": 340,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Document-Image-Analysis-O'Gorman-Kasturi",
            "title": {
                "fragments": [],
                "text": "Document Image Analysis"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685738"
                        ],
                        "name": "M. H. Wright",
                        "slug": "M.-H.-Wright",
                        "structuredName": {
                            "firstName": "Margaret",
                            "lastName": "Wright",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. H. Wright"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 64988980,
            "fieldsOfStudy": [
                "Medicine"
            ],
            "id": "9e0b30065d83c7a95bd7a8cd2c0a59f06fb8cfd0",
            "isKey": false,
            "numCitedBy": 331,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Direct-search-methods:-Once-scorned,-now-Wright",
            "title": {
                "fragments": [],
                "text": "Direct search methods: Once scorned, now respectable"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 38,
                                "start": 34
                            }
                        ],
                        "text": "We used the PSET software package [25], [24] for training and testing the algorithms."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 79,
                                "start": 75
                            }
                        ],
                        "text": "The software used for generating the results in this paper is described in [25], [24]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aSoftware Architecture of PSET: A Page Segmentation Evaluation Toolkit,o"
            },
            "venue": {
                "fragments": [],
                "text": "Technical Report CAR-TR-955, Univ. of Maryland,"
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Caere Developer's Kit 2000. Caere Co"
            },
            "venue": {
                "fragments": [],
                "text": "Caere Developer's Kit 2000. Caere Co"
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 130,
                                "start": 126
                            }
                        ],
                        "text": "Direct search algorithms are typically used for solving optimization problems involving this kind of objective function [19], [38], [34]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aDirect Search Methods: Once Scorned"
            },
            "venue": {
                "fragments": [],
                "text": "Now Respectable,o Numerical Analysis 1995, pp. 191-208, D.F. Griffiths and G.A. Watson, eds., Addison Wesley, Longman (Harlow)"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Performance versus Methodology in Computer Vision"
            },
            "venue": {
                "fragments": [],
                "text": "Performance versus Methodology in Computer Vision"
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 136,
                                "start": 132
                            }
                        ],
                        "text": "Direct search algorithms are typically used for solving optimization problems involving this kind of objective function [19], [38], [34]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aDirect Search Algorithms for Optimization Calculations,o"
            },
            "venue": {
                "fragments": [],
                "text": "Acta Numerica,"
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[37], the segmentation algorithm of Jain and Yu [13], and the text string separation algorithm of Fletcher and Kasturi [5] are typical bottom-up algorithms, while the X-Y cut by Nagy et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "and R"
            },
            "venue": {
                "fragments": [],
                "text": "Casey, aBlock Segmentation and Text Extraction in Mixed Text/Image Documents,o Graphical Models and Image Processing, vol. 20, pp. 375-390"
            },
            "year": 1982
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 20,
                                "start": 0
                            }
                        ],
                        "text": "Phillips and Chhabra [32] presented a methodol-\nogy for empirically evaluating graphics recognition\nsystems."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 203,
                                "start": 199
                            }
                        ],
                        "text": "Similarly, in performance evaluation literature where the algorithm parameters can be set by evaluators, a set of parameter values are usually selected manually in the training procedure [12], [15], [32]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 25,
                                "start": 21
                            }
                        ],
                        "text": "Phillips and Chhabra [32] presented a methodology for empirically evaluating graphics recognition systems."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aEmpirical Performance Evaluation of Graphics Recognition Systems,o"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Analysis and Machine Intelligence,"
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Experimental Comparison of Range Image Segmentation Algorithms IEEE Trans. Pattern Analysis and Machine Intelligence"
            },
            "venue": {
                "fragments": [],
                "text": "Experimental Comparison of Range Image Segmentation Algorithms IEEE Trans. Pattern Analysis and Machine Intelligence"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[14] proposed a metric that is a weighted sum of the number of edit operations (insertions, deletions, and moves)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "and G"
            },
            "venue": {
                "fragments": [],
                "text": "Nagy, aAutomated Evaluation of OCR Zoning,o IEEE Trans. Pattern Analysis and Machine Intelligence, vol. 17, pp. 86-90"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 44,
                                "start": 40
                            }
                        ],
                        "text": "We used the PSET software package [25], [24] for training and testing the algorithms."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 85,
                                "start": 81
                            }
                        ],
                        "text": "The software used for generating the results in this paper is described in [25], [24]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aPSET: A Page Segmentation Evaluation Toolkit,o"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. Fourth IAPR Int'l Workshop Document Analysis Systems,"
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 182,
                                "start": 179
                            }
                        ],
                        "text": "In research segmentation algorithms that have userspecifiable parameters, typically the default parameter values are selected and no training method is explicitly specified [17], [1], [28], [13], [30], [5]."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Fortune, aImage Segmentation by Shape-Directed Covers,o"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. Int'l Conf. Pattern Recognition,"
            },
            "year": 1990
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 111,
                                "start": 107
                            }
                        ],
                        "text": "A survey of OCR and page segmentation algorithms can be found in O'Gorman and Kasturi [29] and Jain and Yu [13]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 52,
                                "start": 48
                            }
                        ],
                        "text": "[37], the segmentation algorithm of Jain and Yu [13], and the text string separation algorithm of Fletcher and Kasturi [5] are typical bottom-up algorithms, while the X-Y cut by Nagy et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 194,
                                "start": 190
                            }
                        ],
                        "text": "In research segmentation algorithms that have userspecifiable parameters, typically the default parameter values are selected and no training method is explicitly specified [17], [1], [28], [13], [30], [5]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aDocument Representation and Its Application to Page Decomposition,o"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Analysis and Machine Intelligence,"
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[20] described a region-area-based metric."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aPerformance Evaluation of Document Layout Analysis Algorithms on the UW Data Set,o"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. SPIE Conf. Document Recognition IV,"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "\u00aaPage Segmentation and Classification,\u00ba Graphical Models and Image Processing"
            },
            "venue": {
                "fragments": [],
                "text": "\u00aaPage Segmentation and Classification,\u00ba Graphical Models and Image Processing"
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "\u00aaWhy Pattern Search Works,\u00ba OPTIMA"
            },
            "venue": {
                "fragments": [],
                "text": "\u00aaWhy Pattern Search Works,\u00ba OPTIMA"
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[16] for their evaluation of Arabic OCR engines and adapt it to analyze our experimental results."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 31,
                                "start": 27
                            }
                        ],
                        "text": "We employed a paired model [16] to compare the performance index and testing time differences between each possible algorithm pair and then computed their confidence intervals."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aOmniPage vs. Sakhr: Paired Model Evaluation of Two Arabic OCR Products,o"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. SPIE Conf. Document Recognition and Retrieval VI,"
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 145,
                                "start": 141
                            }
                        ],
                        "text": "Algorithm timing performance depends on hardware and software factors, such as machine type, operating system, memory size, network protocol [11], etc."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aBenchmarking a Network of PCs Running Parallel Applications,o"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. Int'l Performance, Computing, and Communications Conf.,"
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 22,
                                "start": 18
                            }
                        ],
                        "text": "Pavlidis and Zhou [30] proposed a hybrid algorithm using a split-and-merge strategy."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 200,
                                "start": 196
                            }
                        ],
                        "text": "In research segmentation algorithms that have userspecifiable parameters, typically the default parameter values are selected and no training method is explicitly specified [17], [1], [28], [13], [30], [5]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aPage Segmentation and Classification,o"
            },
            "venue": {
                "fragments": [],
                "text": "Graphical Models and Image Processing,"
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Analysis Using Mathematical Morphology IEEE Trans. Pattern Analysis and Machine Intelligence"
            },
            "venue": {
                "fragments": [],
                "text": "Analysis Using Mathematical Morphology IEEE Trans. Pattern Analysis and Machine Intelligence"
            },
            "year": 1987
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 54,
                                "start": 50
                            }
                        ],
                        "text": "We selected the University of Washington Data Set [31] for the performance evaluation task since it is the only data set currently available that has textline-level groundtruth for each document page."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 49,
                                "start": 30
                            }
                        ],
                        "text": "We selected the University of Washington Data Set [31] for\nthe performance evaluation task since it is the only data set currently available that has textline-level groundtruth for\neach document page."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "User's Reference Manual, CD-ROM, UW-III Document Image Database-III"
            },
            "venue": {
                "fragments": [],
                "text": "User's Reference Manual, CD-ROM, UW-III Document Image Database-III"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Evaluation of OCR Zoning IEEE Trans. Pattern Analysis and Machine Intelligence"
            },
            "venue": {
                "fragments": [],
                "text": "Evaluation of OCR Zoning IEEE Trans. Pattern Analysis and Machine Intelligence"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Application Programmer's Interface, ScanSoft Co"
            },
            "venue": {
                "fragments": [],
                "text": "Application Programmer's Interface, ScanSoft Co"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 69,
                                "start": 65
                            }
                        ],
                        "text": "We now define two morphological operations: dilation and erosion [10]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "and X"
            },
            "venue": {
                "fragments": [],
                "text": "Zhuang, aImage Analysis Using Mathematical Morphology,o IEEE Trans. Pattern Analysis and Machine Intelligence, vol. 9, pp. 523-550"
            },
            "year": 1987
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 71,
                                "start": 67
                            }
                        ],
                        "text": "We have reported part of the work presented in this paper in [21], [22], [23]."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aAutomatic Training of Page Segmentation Algorithms: An Optimization Approach,o"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. Int'l Conf. Pattern Recognition,"
            },
            "year": 2000
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 10,
            "methodology": 29,
            "result": 2
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 64,
        "totalPages": 7
    },
    "page_url": "https://www.semanticscholar.org/paper/Empirical-Performance-Evaluation-Methodology-and-to-Mao-Kanungo/82328a31d7366c4ecfd339deeae41c3152b43c98?sort=total-citations"
}