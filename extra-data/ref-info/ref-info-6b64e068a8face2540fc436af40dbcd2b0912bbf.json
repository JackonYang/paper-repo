{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1680292"
                        ],
                        "name": "P. Resnik",
                        "slug": "P.-Resnik",
                        "structuredName": {
                            "firstName": "Philip",
                            "lastName": "Resnik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Resnik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 124,
                                "start": 107
                            }
                        ],
                        "text": "One node based approach to determine the conceptual similarity is called the information content approach (Resnik 1992, 1995)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 209,
                                "start": 198
                            }
                        ],
                        "text": "With the recently developed lexical taxonomy WordNet (Miller 1990, Miller et al. 1990), many researches have taken the advantage of this broad-coverage taxonomy to study word/concept relationships (Resnik 1995, Richardson and Smeaton 1995)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 350,
                                "start": 337
                            }
                        ],
                        "text": "To make our experimental results comparable with other previous experiments, we decided to use the same sample of 30 noun pairs that were selected in an experiment when only human subjects were involved (Miller and Charles 1991), and in another more recent experiment when some computational models were constructed and compared as well (Resnik 1995)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 69,
                                "start": 58
                            }
                        ],
                        "text": "It is not sensitive to the problem of varying link types (Resnik 1995)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 29,
                                "start": 16
                            }
                        ],
                        "text": "In fact, in the Resnik (1995) experiment, he replicated hehuman judgements on the same set of word pairs that Miller and Charles did."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 147,
                                "start": 136
                            }
                        ],
                        "text": "To convert the distance measure to a similarity measure, one may simply subtract the path length from the maximum possible path length (Resnik 1995): sim w w d c senw c senw len c c( , ) [ min ( ) ( ) ( , )],max1 2 1 1 2 2 1 22= \u2212 \u2208 \u2208 (10) where dmax is the maximum depth of the taxonomy, and the\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 127,
                                "start": 116
                            }
                        ],
                        "text": "Therefore it avoids potentially spurious results in occasions when only word (not word sense) frequencies are used (Resnik 1995)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 108,
                                "start": 97
                            }
                        ],
                        "text": "The data on human ratings are from the publication of previous results (Miller and Charles 1991, Resnik 1995)."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 121,
                                "start": 108
                            }
                        ],
                        "text": "In our experiment, we compare the proposed model with the node-based Information Content model developed by Resnik (1995) and the basic edge-based edge counting model, in the context of how well these perform against human ratings (i.e. the upper bound)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 298,
                                "start": 287
                            }
                        ],
                        "text": "\u2026er previous experiments, we decided to use the same sample of 30 noun pairs that were selected in an experiment when only human subjects were involved (Miller and Charles 1991), and in another more recent experiment when some computational models were constructed and compared as well (Resnik 1995)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 148,
                                "start": 135
                            }
                        ],
                        "text": "To convert the distance measure to a similarity measure, one may simply subtract the path length from the maximum possible path length (Resnik 1995):"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 101,
                                "start": 88
                            }
                        ],
                        "text": "The results of the experiment confirm that the information content approach proposed by Resnik (1995) provides a significant improvement over the traditional edge counting method."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 204,
                                "start": 191
                            }
                        ],
                        "text": "\u2026root c. Classes(w) is defined as the classes in which the word w is contained; in another word, it is the set of possible senses that the word w has: classes w c w words c( ) { | ( )}.= \u2208 (4) Resnik (1995) defined a simple class/concept frequency formula: freq c freq w w words c ( ) ( ) ( ) = \u2208 \u2211 ."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1752785,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "265be00bf112c6cb2fa3e8176bff8394a114dbde",
            "isKey": true,
            "numCitedBy": 3890,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a new measure of semantic similarity in an IS-A taxonomy, based on the notion of information content. Experimental evaluation suggests that the measure performs encouragingly well (a correlation of r = 0.79 with a benchmark set of human similarity judgments, with an upper bound of r = 0.90 for human subjects performing the same task), and significantly better than the traditional edge counting approach (r = 0.66)."
            },
            "slug": "Using-Information-Content-to-Evaluate-Semantic-in-a-Resnik",
            "title": {
                "fragments": [],
                "text": "Using Information Content to Evaluate Semantic Similarity in a Taxonomy"
            },
            "tldr": {
                "abstractSimilarityScore": 72,
                "text": "This paper presents a new measure of semantic similarity in an IS-A taxonomy, based on the notion of information content, which performs encouragingly well and is significantly better than the traditional edge counting approach."
            },
            "venue": {
                "fragments": [],
                "text": "IJCAI"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1766712"
                        ],
                        "name": "R. Rada",
                        "slug": "R.-Rada",
                        "structuredName": {
                            "firstName": "Roy",
                            "lastName": "Rada",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Rada"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2116204"
                        ],
                        "name": "H. Mili",
                        "slug": "H.-Mili",
                        "structuredName": {
                            "firstName": "Hafedh",
                            "lastName": "Mili",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Mili"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144494841"
                        ],
                        "name": "E. Bicknell",
                        "slug": "E.-Bicknell",
                        "structuredName": {
                            "firstName": "Ellen",
                            "lastName": "Bicknell",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Bicknell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7519237"
                        ],
                        "name": "M. Blettner",
                        "slug": "M.-Blettner",
                        "structuredName": {
                            "firstName": "Maria",
                            "lastName": "Blettner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Blettner"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 68,
                                "start": 50
                            }
                        ],
                        "text": "the minimum number of edges that separate A and B (Rada et al. 1989)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 18,
                                "start": 0
                            }
                        ],
                        "text": "Rada et al. (1989) applied the distance method to a medical domain, and found that the distance function simulated well human assessments of conceptual distance."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 78,
                                "start": 62
                            }
                        ],
                        "text": "Many edge-based models consider only the IS-A link hierarchy (Rada et al. 1989, Lee et al. 1993)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 247,
                                "start": 231
                            }
                        ],
                        "text": "Furthermore, in an IS-A semantic network, the simplest form of determining the distance between two elemental concept nodes, A and B, is the shortest path that links A and B, i.e. the minimum number of edges that separate A and B (Rada et al. 1989)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 47,
                                "start": 29
                            }
                        ],
                        "text": "For a hierarchical taxonomy, Rada et al. (1989) pointed out that the distance should satisfy the properties of a metric, namely: zero property, symmetric property, positive property, and triangular inequality."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 58,
                                "start": 40
                            }
                        ],
                        "text": "In the line of the edge-based approach, Rada et al. (1989) and Lee et al. (1993) derived semantic distance formulas using the edge counting principle, which were then used to support higher level result ranking in document retrieval."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 139,
                                "start": 123
                            }
                        ],
                        "text": "It has been suggested and employed to study a special case of semantic relations \u2014 semantic similarity or semantic distance (Rada et al. 1989)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 18702948,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1e41fe310351f5d2f6ff2f930f9c062ba43cbe0f",
            "isKey": true,
            "numCitedBy": 2033,
            "numCiting": 48,
            "paperAbstract": {
                "fragments": [],
                "text": "Motivated by the properties of spreading activation and conceptual distance, the authors propose a metric, called distance, on the power set of nodes in a semantic net. Distance is the average minimum path length over all pairwise combinations of nodes between two subsets of nodes. Distance can be successfully used to assess the conceptual distance between sets of concepts when used on a semantic net of hierarchical relations. When other kinds of relationships, like 'cause', are used, distance must be amended but then can again be effective. The judgements of distance significantly correlate with the distance judgements that people make and help to determine whether one semantic net is better or worse than another. The authors focus on the mathematical characteristics of distance that presents novel cases and interpretations. Experiments in which distance is applied to pairs of concepts and to sets of concepts in a hierarchical knowledge base show the power of hierarchical relations in representing information about the conceptual distance between concepts. >"
            },
            "slug": "Development-and-application-of-a-metric-on-semantic-Rada-Mili",
            "title": {
                "fragments": [],
                "text": "Development and application of a metric on semantic nets"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "Experiments in which distance is applied to pairs of concepts and to sets of concepts in a hierarchical knowledge base show the power of hierarchical relations in representing information about the conceptual distance between concepts."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Syst. Man Cybern."
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1808353"
                        ],
                        "name": "H. Kozima",
                        "slug": "H.-Kozima",
                        "structuredName": {
                            "firstName": "Hideki",
                            "lastName": "Kozima",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Kozima"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 26,
                                "start": 0
                            }
                        ],
                        "text": "Kozima and Furugori (1993) measured word distance by adaptive scaling of a vector space generated from LDOCE (Longman Dictionary of Contemporary English)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 26,
                                "start": 0
                            }
                        ],
                        "text": "Kozima and Furugori (1993) also proposed a word similarity measure by spreading activation on a semantic net composed by the online dictionary LDOCE."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 813476,
            "fieldsOfStudy": [
                "Linguistics",
                "Computer Science"
            ],
            "id": "d5683ff74477e510c081206a9da8ed28a32bd75a",
            "isKey": false,
            "numCitedBy": 152,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper proposes a method for measuring semantic similarity between words as a new tool for text analysis. The similarity is measured on a semantic network constructed systematically from a subset of the English dictionary, LDOCE (Longman Dictionary of Contemporary English). Spreading activation on the network can directly compute the similarity between any two words in the Longman Defining Vocabulary, and indirectly the similarity of all the other words in LDOCE. The similarity represents the strength of lexical cohesion or semantic relation, and also provides valuable information about similarity and coherence of texts."
            },
            "slug": "Similarity-between-Words-Computed-by-Spreading-on-Kozima",
            "title": {
                "fragments": [],
                "text": "Similarity between Words Computed by Spreading Activation on an English Dictionary"
            },
            "tldr": {
                "abstractSimilarityScore": 79,
                "text": "A method for measuring semantic similarity between words as a new tool for text analysis on a semantic network constructed systematically from a subset of the English dictionary, LDOCE (Longman Dictionary of Contemporary English)."
            },
            "venue": {
                "fragments": [],
                "text": "EACL"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1680292"
                        ],
                        "name": "P. Resnik",
                        "slug": "P.-Resnik",
                        "structuredName": {
                            "firstName": "Philip",
                            "lastName": "Resnik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Resnik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 102,
                                "start": 88
                            }
                        ],
                        "text": "The results of the experiment confirm that the information content approach proposed by Resnik (1995) provides a significant improvement over the traditional edge counting method."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 124,
                                "start": 107
                            }
                        ],
                        "text": "One node based approach to determine the conceptual similarity is called the information content approach (Resnik 1992, 1995)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 17631109,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "297e478f92cef1cd090706fc59fde5ea0836ce80",
            "isKey": false,
            "numCitedBy": 103,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "It has become common in statistical studies of natural language data to use measures of lexical association, such as the information-theoretic measure of mutual information, to extract useful relationships between words (e.g. [Church et al., 1989; Church and Hanks, 1989; Hindle, 1990]). For example, [Hindle, 1990] uses an estimate of mutual information to calculate what nouns a verb can take as its subjects and objects, based on distributions found within a large corpus of naturally occurring text."
            },
            "slug": "WordNet-and-Distributional-Analysis:-A-Class-based-Resnik",
            "title": {
                "fragments": [],
                "text": "WordNet and Distributional Analysis: A Class-based Approach to Lexical Discovery"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "An estimate of mutual information is used to calculate what nouns a verb can take as its subjects and objects, based on distributions found within a large corpus of naturally occurring text."
            },
            "venue": {
                "fragments": [],
                "text": "AAAI 1992"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144096985"
                        ],
                        "name": "G. Miller",
                        "slug": "G.-Miller",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Miller",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Miller"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34729490"
                        ],
                        "name": "W. Charles",
                        "slug": "W.-Charles",
                        "structuredName": {
                            "firstName": "Walter",
                            "lastName": "Charles",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Charles"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 228,
                                "start": 203
                            }
                        ],
                        "text": "To make our experimental results comparable with other previous experiments, we decided to use the same sample of 30 noun pairs that were selected in an experiment when only human subjects were involved (Miller and Charles 1991), and in another more recent experiment when some computational models were constructed and compared as well (Resnik 1995)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 90,
                                "start": 65
                            }
                        ],
                        "text": "When the correlation between his replication and the one done by Miller and Charles (1991) was calculated, a baseline from human ratings was obtained for evaluation, which represents an upper bound that one could expect from a machine computation on the same task."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 95,
                                "start": 72
                            }
                        ],
                        "text": "The data on human ratings are from the publication of previous results (Miller and Charles 1991, Resnik 1995)."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 90,
                                "start": 65
                            }
                        ],
                        "text": "The ratings in the table are sorted in descending order based on Miller and Charles (1991) findings."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 176,
                                "start": 153
                            }
                        ],
                        "text": "\u2026er previous experiments, we decided to use the same sample of 30 noun pairs that were selected in an experiment when only human subjects were involved (Miller and Charles 1991), and in another more recent experiment when some computational models were constructed and compared as well (Resnik 1995)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 145580646,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "402627e4eb8c95e4aae3026fd921aa08cd792006",
            "isKey": true,
            "numCitedBy": 1678,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract The relationship between semantic and contextual similarity is investigated for pairs of nouns that vary from high to low semantic similarity. Semantic similarity is estimated by subjective ratings; contextual similarity is estimated by the method of sorting sentential contexts. The results show an inverse linear relationship between similarity of meaning and the discriminability of contexts. This relation, is obtained for two separate corpora of sentence contexts. It is concluded that, on average, for words in the same language drawn from the same syntactic and semantic categories, the more often two words can be substituted into the same contexts the more similar in meaning they are judged to be."
            },
            "slug": "Contextual-correlates-of-semantic-similarity-Miller-Charles",
            "title": {
                "fragments": [],
                "text": "Contextual correlates of semantic similarity"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733049"
                        ],
                        "name": "Eneko Agirre",
                        "slug": "Eneko-Agirre",
                        "structuredName": {
                            "firstName": "Eneko",
                            "lastName": "Agirre",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Eneko Agirre"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1785173"
                        ],
                        "name": "German Rigau",
                        "slug": "German-Rigau",
                        "structuredName": {
                            "firstName": "German",
                            "lastName": "Rigau",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "German Rigau"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 23,
                                "start": 0
                            }
                        ],
                        "text": "Agirre and Rigau (1995) proposed an interesting conceptual density concept for WSD."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1567907,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6e55023e67ee4681736b0ca5ef516b8abaca0ca0",
            "isKey": false,
            "numCitedBy": 154,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a method for the resolution of lexical ambiguity and its \nautomatic evaluation over the Brown Corpus. The method relies on the use of \nthe wide-coverage noun taxonomy of WordNet and the notion of conceptual \ndistance among concepts, captured by a Conceptual Density formula developed \nfor this purpose. This fully automatic method requires no hand coding of \nlexical entries, hand tagging of text nor any kind of training process. The \nresults of the experiment have been automatically evaluated against SemCor, \nthe sense-tagged version of the Brown Corpus."
            },
            "slug": "A-Proposal-for-Word-Sense-Disambiguation-using-Agirre-Rigau",
            "title": {
                "fragments": [],
                "text": "A Proposal for Word Sense Disambiguation using Conceptual Distance"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "The method relies on the use of the wide-coverage noun taxonomy of WordNet and the notion of conceptual distance among concepts, captured by a Conceptual Density formula developed for this purpose, for the resolution of lexical ambiguity."
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143922219"
                        ],
                        "name": "Raymond Richardson",
                        "slug": "Raymond-Richardson",
                        "structuredName": {
                            "firstName": "Raymond",
                            "lastName": "Richardson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Raymond Richardson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1680223"
                        ],
                        "name": "A. Smeaton",
                        "slug": "A.-Smeaton",
                        "structuredName": {
                            "firstName": "Alan",
                            "lastName": "Smeaton",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Smeaton"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 149,
                                "start": 122
                            }
                        ],
                        "text": "Since the overall semantic mass is of a certain amount for a given node (and its subordinates), the local density effect (Richardson and Smeaton 1995) would suggest hat the greater the density, the closer the distance between the nodes (i. . parent child nodes or sibling nodes)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 238,
                                "start": 211
                            }
                        ],
                        "text": "With the recently developed lexical taxonomy WordNet (Miller 1990, Miller et al. 1990), many researches have taken the advantage of this broad-coverage taxonomy to study word/concept relationships (Resnik 1995, Richardson and Smeaton 1995)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 194,
                                "start": 167
                            }
                        ],
                        "text": "Additionally, in the calculation of information content, polysemous words will have an exaggerated content value if only word (not its sense) frequency data are used (Richardson and Smeaton 1995)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 38,
                                "start": 9
                            }
                        ],
                        "text": "However, Richardson and Smeaton (1995) had concerns that the measure was less accurate than expected when applied to a comparatively broad domain (e.g. WordNet taxonomy)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 58,
                                "start": 29
                            }
                        ],
                        "text": "With the lesson learned from Richardson and Smeaton (1995), when they applied their similarity measure to free text document retrieval, it seems that the IR task would benefit most from the semantic similarity measures when both document and query are relatively short in length (Smeaton and Quigley\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 52,
                                "start": 23
                            }
                        ],
                        "text": "This would support the Richardson and Smeaton (1995) argument about the difficulty of the adjustment of the depth scaling factor."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 29,
                                "start": 0
                            }
                        ],
                        "text": "Richardson and Smeaton (1995) considered the first two and the last factors in their edge weight calculation for each link type."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 33,
                                "start": 4
                            }
                        ],
                        "text": "(5) Richardson and Smeaton (1995) proposed a slightly different calculation by considering the number of word senses factor: freq c freq w classes ww words c ( ) ( ) | ( )"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 59,
                                "start": 29
                            }
                        ],
                        "text": "With the lesson learned from Richardson and Smeaton (1995), when they applied their similarity measure to free text document retrieval, it seems that the IR task would benefit most from the semantic similarity measures when both document and query are relatively short in length (Smeaton and Quigley 1996)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 150,
                                "start": 121
                            }
                        ],
                        "text": "Since the overall semantic mass is of a certain amount for a given node (and its subordinates), the local density effect (Richardson and Smeaton 1995) would suggest that the greater the density, the closer the distance between the nodes (i."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2904992,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "50b9b6b6f38aa724121b95a0d4e608843e7438f6",
            "isKey": true,
            "numCitedBy": 231,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "The application of natural language processing tools and techniques to information retrieval tasks has long since been identified as potentially useful for the quality of information retrieval. Traditionally, IR has been based on matching words or terms in a query with words or terms in a document. In this paper we introduce an approach to IR based on computing a semantic distance measurement between concepts or words and using this word distance to compute a similarity between a query and a document. Two such semantic distance measures are presented in this paper and both are benchmarked on queries and documents from the TREC collection. Although our results in terms of precision and recall are disappointing, we rationalise this in terms of our experimental setup and our results show promise for future work in this area."
            },
            "slug": "Using-WordNet-in-a-Knowledge-Based-Approach-to-Richardson-Smeaton",
            "title": {
                "fragments": [],
                "text": "Using WordNet in a Knowledge-Based Approach to Information Retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "This paper introduces an approach to IR based on computing a semantic distance measurement between concepts or words and using this word distance to compute a similarity between a query and a document."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2148782"
                        ],
                        "name": "Michael Sussna",
                        "slug": "Michael-Sussna",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Sussna",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael Sussna"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 13,
                                "start": 0
                            }
                        ],
                        "text": "Sussna (1993) considered the first three factors in the edge weight determination scheme."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 162,
                                "start": 149
                            }
                        ],
                        "text": "\u2026relation type r respectively, and n xr ( ) is the number of relations of type r leaving node x. Applying this distance formula to a word sense disambiguation task, Sussna (1993) showed an improvement where multiple sense words have been disambiguated by finding the combination of senses from a\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 82,
                                "start": 68
                            }
                        ],
                        "text": "Applying this distance formula to a word sense disambiguation task, Sussna (1993) showed an improvement where multiple sense words have been disambiguated by finding the combination of senses from a set of contiguous terms which minimizes total pairwise distance between senses."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 13,
                                "start": 0
                            }
                        ],
                        "text": "Sussna (1993) defined a similarity measure that takes into account taxonomy structure information."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 17299699,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f6921e3c7219c5246a3f6105156cdcbd708603c7",
            "isKey": true,
            "numCitedBy": 457,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "Semantics-free, word-based information retrieval is thwarted by two complementary problems. First, search for relevant documents returns irrelevant items when all meanings of a search term are used, rather than just the meaning intended. This causes low precision. Second, relevant items are missed when they are indexed not under the actual search terms, but rather under related terms. This causes low recall. With semantics-free approaches there is generally no way to improve both precision and recall at the same time. Word sense disambiguation during document indexing should improve precision. We have investigated using the massive Word Net semantic network for disambigu at ion during indexing. With the unconstrained text of the SMART ret rieval environment, we have had to derive our own content description from the input text, given only part-ofspeech tagging of the input. We employ the notion of semantic distance between network nodes. Input text terms with multiple senses are disambiguated by finding the combination of senses from a set of contiguous terms which minimizes total pairwise dist ante between senses. Results so far have been encouraging. Improvement in disamblguation compared with chance is clear"
            },
            "slug": "Word-sense-disambiguation-for-free-text-indexing-a-Sussna",
            "title": {
                "fragments": [],
                "text": "Word sense disambiguation for free-text indexing using a massive semantic network"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This work investigates using the massive Word Net semantic network for disambiguation during document indexing to improve precision and improvement in disamblguation compared with chance."
            },
            "venue": {
                "fragments": [],
                "text": "CIKM '93"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1746017"
                        ],
                        "name": "G. Grefenstette",
                        "slug": "G.-Grefenstette",
                        "structuredName": {
                            "firstName": "Gregory",
                            "lastName": "Grefenstette",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Grefenstette"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 174,
                                "start": 157
                            }
                        ],
                        "text": "Under the corpus-based approach, word relationships are often derived from their co-occurrence distribution in a corpus (Church and Hanks 1989, Hindle 1990, Grefenstette 1992)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 167,
                                "start": 150
                            }
                        ],
                        "text": "In the area of IR using NLP, approaches have be pursued to take advantage of the statistical term association results (Strzalkowski and Vauthey 1992, Grefenstette 1992)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 16105777,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "36c4c51917b1f53ee85c459f2597e115df53eb05",
            "isKey": false,
            "numCitedBy": 177,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "One aspect of world knowledge essential to information retrieval is knowing when two words are related. Knowing word relatedness allows a system given a user's query terms to retrieve relevant documents not containing those exact terms. Two words can be said to be related if they appear in the same contexts Document co-occurrence gives a measure of word relatedness that has proved to be too rough to be useful. The relatively recent apparition of on-line dictionaries and robust and rapid parsers permits the extraction of finer word contexts from large corpora. In this paper, we will describe such an extraction technique that uses only coarse syntactic analysis and no domain knowledge. This technique produces lists of words related to any work appearing in a corpus. When the closest related terms were used in query expansion of a standard information retrieval testbed, the results were much better than that given by document co-occurence techniques, and slightly better than using unexpanded queries, supporting the contention that semantically similar words were indeed extracted by this technique."
            },
            "slug": "Use-of-syntactic-context-to-produce-term-lists-for-Grefenstette",
            "title": {
                "fragments": [],
                "text": "Use of syntactic context to produce term association lists for text retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "When the closest related terms were used in query expansion of a standard information retrieval testbed, the results were much better than that given by document co-occurence techniques, and slightly better than using unexpanded queries, supporting the contention that semantically similar words were indeed extracted by this technique."
            },
            "venue": {
                "fragments": [],
                "text": "SIGIR '92"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144096985"
                        ],
                        "name": "G. Miller",
                        "slug": "G.-Miller",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Miller",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Miller"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3226331"
                        ],
                        "name": "C. Leacock",
                        "slug": "C.-Leacock",
                        "structuredName": {
                            "firstName": "Claudia",
                            "lastName": "Leacock",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Leacock"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1818801"
                        ],
                        "name": "Randee Tengi",
                        "slug": "Randee-Tengi",
                        "structuredName": {
                            "firstName": "Randee",
                            "lastName": "Tengi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Randee Tengi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144819917"
                        ],
                        "name": "R. Bunker",
                        "slug": "R.-Bunker",
                        "structuredName": {
                            "firstName": "Ross",
                            "lastName": "Bunker",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Bunker"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 130,
                                "start": 112
                            }
                        ],
                        "text": "The frequencies of concepts were estimated using noun frequencies from a universal semantic concordance SemCor (Miller et al. 1993), a semantically tagged text consisting of 100 passages from the Brown Corpus."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 82,
                                "start": 76
                            }
                        ],
                        "text": "The MLE method would\n10\nseem unsuitable for probability estimation from the SemCor corpus."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 32,
                                "start": 26
                            }
                        ],
                        "text": "The downside of using the SemCor data is the relatively small size of the corpus due to the need to manually tag the sense for each word in the corpus."
                    },
                    "intents": []
                }
            ],
            "corpusId": 7231199,
            "fieldsOfStudy": [
                "Linguistics",
                "Computer Science"
            ],
            "id": "f9a25e0dc776857fc24ebc7115c980312f2719b1",
            "isKey": true,
            "numCitedBy": 725,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "A semantic concordance is a textual corpus and a lexicon so combined that every substantive word in the text is linked to its appropriate sense in the lexicon. Thus it can be viewed either as a corpus in which words have been tagged syntactically and semantically, or as a lexicon in which example sentences can be found for many definitions. A semantic concordance is being constructed to use in studies of sense resolution in context (semantic disambiguation). The Brown Corpus is the text and WordNet is the lexicon. Semantic tags (pointers to WordNet synsets) are inserted in the text manually using an interface, ConText, that was designed to facilitate the task. Another interface supports searches of the tagged text. Some practical uses for semantic concordances am proposed."
            },
            "slug": "A-Semantic-Concordance-Miller-Leacock",
            "title": {
                "fragments": [],
                "text": "A Semantic Concordance"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "A semantic concordance is a textual corpus and a lexicon so combined that every substantive word in the text is linked to its appropriate sense in the lexicon."
            },
            "venue": {
                "fragments": [],
                "text": "HLT"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2118077301"
                        ],
                        "name": "Jane Morris",
                        "slug": "Jane-Morris",
                        "structuredName": {
                            "firstName": "Jane",
                            "lastName": "Morris",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jane Morris"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145036961"
                        ],
                        "name": "Graeme Hirst",
                        "slug": "Graeme-Hirst",
                        "structuredName": {
                            "firstName": "Graeme",
                            "lastName": "Hirst",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Graeme Hirst"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 23,
                                "start": 0
                            }
                        ],
                        "text": "Morris and Hirst (1991) used Roget\u2019s thesaurus to detect word semantic relationships."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 50,
                                "start": 28
                            }
                        ],
                        "text": "Using an online dictionary, Niwa and Nitta (1994) built a reference network of words where a word as a node in the network is connected to other words that are its definitional words."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 10970495,
            "fieldsOfStudy": [
                "Linguistics",
                "Computer Science"
            ],
            "id": "ca40dc1300ab085406455894dd42fd02f9cc36f8",
            "isKey": false,
            "numCitedBy": 1091,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "In text, lexical cohesion is the result of chains of related words that contribute to the continuity of lexical meaning. These lexical chains are a direct result of units of text being \"about the same thing,\" and finding text structure involves finding units of text that are about the same thing. Hence, computing the chains is useful, since they will have a correspondence to the structure of the text. Determining the structure of text is an essential step in determining the deep meaning of the text. In this paper, a thesaurus is used as the major knowledge base for computing lexical chains. Correspondences between lexical chains and structural elements are shown to exist. Since the lexical chains are computable, and exist in non-domain-specific text, they provide a valuable indicator of text structure. The lexical chains also provide a semantic context for interpreting words, concepts, and sentences."
            },
            "slug": "Lexical-Cohesion-Computed-by-Thesaural-Relations-as-Morris-Hirst",
            "title": {
                "fragments": [],
                "text": "Lexical Cohesion Computed by Thesaural Relations as an Indicator of the Structure of Text"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "Since the lexical chains are computable, and exist in non-domain-specific text, they provide a valuable indicator of text structure, and provide a semantic context for interpreting words, concepts, and sentences."
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Linguistics"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2244184"
                        ],
                        "name": "Kenneth Ward Church",
                        "slug": "Kenneth-Ward-Church",
                        "structuredName": {
                            "firstName": "Kenneth",
                            "lastName": "Church",
                            "middleNames": [
                                "Ward"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kenneth Ward Church"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145165877"
                        ],
                        "name": "P. Hanks",
                        "slug": "P.-Hanks",
                        "structuredName": {
                            "firstName": "Patrick",
                            "lastName": "Hanks",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Hanks"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 142,
                                "start": 121
                            }
                        ],
                        "text": "Under the corpus-based approach, word relationships are often derived from their co-occurrence distribution in a corpus (Church and Hanks 1989, Hindle 1990, Grefenstette 1992)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 424,
                                "start": 121
                            }
                        ],
                        "text": "Under the corpus-based approach, word relationships are often derived from their co-occurrence distribution in a corpus (Church and Hanks 1989, Hindle 1990, Grefenstette 1992). With the introduction of machine readable dictionaries, lexicons, thesauri, and taxonomies, these manually built pseudo-knowledge bases provide a natural framework for organising words or concepts into a semantic space. Kozima and Furugori (1993) measured word distance by adaptive scaling of a vector space generated from LDOCE (Longman Dictionary of Contemporary English)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 576,
                                "start": 121
                            }
                        ],
                        "text": "Under the corpus-based approach, word relationships are often derived from their co-occurrence distribution in a corpus (Church and Hanks 1989, Hindle 1990, Grefenstette 1992). With the introduction of machine readable dictionaries, lexicons, thesauri, and taxonomies, these manually built pseudo-knowledge bases provide a natural framework for organising words or concepts into a semantic space. Kozima and Furugori (1993) measured word distance by adaptive scaling of a vector space generated from LDOCE (Longman Dictionary of Contemporary English). Morris and Hirst (1991) used Roget\u2019s thesaurus to detect word semantic relationships."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 9558665,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "9e2caa39ac534744a180972a30a320ad0ae41ea3",
            "isKey": false,
            "numCitedBy": 4363,
            "numCiting": 44,
            "paperAbstract": {
                "fragments": [],
                "text": "The term word association is used in a very particular sense in the psycholinguistic literature. (Generally speaking, subjects respond quicker than normal to the word nurse if it follows a highly associated word such as doctor. ) We will extend the term to provide the basis for a statistical description of a variety of interesting linguistic phenomena, ranging from semantic relations of the doctor/nurse type (content word/content word) to lexico-syntactic co-occurrence constraints between verbs and prepositions (content word/function word). This paper will propose an objective measure based on the information theoretic notion of mutual information, for estimating word association norms from computer readable corpora. (The standard method of obtaining word association norms, testing a few thousand subjects on a few hundred words, is both costly and unreliable.) The proposed measure, the association ratio, estimates word association norms directly from computer readable corpora, making it possible to estimate norms for tens of thousands of words."
            },
            "slug": "Word-Association-Norms,-Mutual-Information-and-Church-Hanks",
            "title": {
                "fragments": [],
                "text": "Word Association Norms, Mutual Information and Lexicography"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "The proposed measure, the association ratio, estimates word association norms directly from computer readable corpora, making it possible to estimate norms for tens of thousands of words."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2325236"
                        ],
                        "name": "Y. Niwa",
                        "slug": "Y.-Niwa",
                        "structuredName": {
                            "firstName": "Yoshiki",
                            "lastName": "Niwa",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Niwa"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1806193"
                        ],
                        "name": "Y. Nitta",
                        "slug": "Y.-Nitta",
                        "structuredName": {
                            "firstName": "Yoshihiko",
                            "lastName": "Nitta",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Nitta"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 49,
                                "start": 28
                            }
                        ],
                        "text": "Using an online dictionary, Niwa and Nitta (1994) built a reference network of words where a word as a node in the network is connected to other words that are its definitional words."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 59,
                                "start": 40
                            }
                        ],
                        "text": "In the line of the edge-based approach, Rada et al. (1989) and Lee et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2646329,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c989e8aa08b24345419e4528198fe5ea17cc0160",
            "isKey": false,
            "numCitedBy": 140,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "A comparison was made of vectors derived by using ordinary co-occurrence statistics from large text corpora and of vectors derived by measuring the interword distances in dictionary definitions. The precision of word sense disambiguation by using co-occurrence vectors from the 1987 Wall Street Journal (20M total words) was higher than that by using distance vectors from the Collins English Dictionary (60K head words + 1.6M definition words). However, other experimental results suggest that distance vectors contain some different semantic information from co-occurrence vectors."
            },
            "slug": "Co-Occurrence-Vectors-From-Corpora-vs.-Distance-Niwa-Nitta",
            "title": {
                "fragments": [],
                "text": "Co-Occurrence Vectors From Corpora vs. Distance Vectors From Dictionaries"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "Experimental results suggest that distance vectors contain some different semantic information from co-occurrence vectors, compared with other experimental results, which suggest that word sense disambiguation is affected by distance vectors."
            },
            "venue": {
                "fragments": [],
                "text": "COLING"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1680223"
                        ],
                        "name": "A. Smeaton",
                        "slug": "A.-Smeaton",
                        "structuredName": {
                            "firstName": "Alan",
                            "lastName": "Smeaton",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Smeaton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2065293029"
                        ],
                        "name": "Ian Quigley",
                        "slug": "Ian-Quigley",
                        "structuredName": {
                            "firstName": "Ian",
                            "lastName": "Quigley",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ian Quigley"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 78,
                                "start": 52
                            }
                        ],
                        "text": "Most recently, Richardson and Smeaton\n13\n(1995) and Smeaton and Quigley (1996) worked on a combined approach that is very similar to ours."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 296,
                                "start": 272
                            }
                        ],
                        "text": "\u2026lesson learned from Richardson and Smeaton (1995), when they applied their similarity measure to free text document retrieval, it seems that the IR task would benefit most from the semantic similarity measures when both document and query are relatively short in length (Smeaton and Quigley 1996)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 41,
                                "start": 14
                            }
                        ],
                        "text": "13 (1995) and Smeaton and Quigley (1996) worked on a combined approach that is very similar to ours."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 305,
                                "start": 279
                            }
                        ],
                        "text": "With the lesson learned from Richardson and Smeaton (1995), when they applied their similarity measure to free text document retrieval, it seems that the IR task would benefit most from the semantic similarity measures when both document and query are relatively short in length (Smeaton and Quigley 1996)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 15244044,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0087596505d98fbb8ed80453dedd5728f30b6d6b",
            "isKey": true,
            "numCitedBy": 221,
            "numCiting": 37,
            "paperAbstract": {
                "fragments": [],
                "text": "Traditional approaches to information retrieval are based upon representing a user\u2019s query as a bag of query terms and a document as a bag of index terms and computing a degree of similarity between the two based on the overlap or number of query terms in common between them. Our long-term approach to IR applications is based upon precomputing semantically-based word-word similarities, work which is described elsewhere, and using these as part of the document-query similarity measure. A basic premise of our word-to-word similarity measure is that the input to this computation is the correct or intended word sense but in information retrieval applications, automatic and accurate word sense dkambiguation remains an unsolved problem. In this paper we describe our first successful application of these ideas to an information retrieval application, specifically the indexing and retrieval of captions describing the content of images. We have hand-captioned 2714 images and to circumvent, for the time being, the problems raised by word sense disambiguation, we manually disambiguated polysemous words in captions. We have also built a Collection of 60 queries and for each, determined relevance assessments. Using this environment we were able to run experiments in which we varied how the query-caption similarity measure used our pre-computed word-word semantic distances. Our experiments, reported in the paper, show significant improvement for this environment over the more traditional approaches to information retrieval."
            },
            "slug": "Experiments-on-using-semantic-distances-between-in-Smeaton-Quigley",
            "title": {
                "fragments": [],
                "text": "Experiments on using semantic distances between words in image caption retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This paper describes the first successful application of semantically-based word-word similarities, work described elsewhere, to an information retrieval application, specifically the indexing and retrieval of captions describing the content of images."
            },
            "venue": {
                "fragments": [],
                "text": "SIGIR '96"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2116657970"
                        ],
                        "name": "J. Lee",
                        "slug": "J.-Lee",
                        "structuredName": {
                            "firstName": "Joon",
                            "lastName": "Lee",
                            "middleNames": [
                                "Ho"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Lee"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1714259"
                        ],
                        "name": "Myoung-Ho Kim",
                        "slug": "Myoung-Ho-Kim",
                        "structuredName": {
                            "firstName": "Myoung-Ho",
                            "lastName": "Kim",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Myoung-Ho Kim"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2110392249"
                        ],
                        "name": "Yoon-Joon Lee",
                        "slug": "Yoon-Joon-Lee",
                        "structuredName": {
                            "firstName": "Yoon-Joon",
                            "lastName": "Lee",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoon-Joon Lee"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 29,
                                "start": 11
                            }
                        ],
                        "text": "(1989) and Lee et al. (1993) derived semantic distance formulas using the edge counting principle, which were then used to support higher level result ranking in document retrieval."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 95,
                                "start": 80
                            }
                        ],
                        "text": "Many edge-based models consider only the IS-A link hierarchy (Rada et al. 1989, Lee et al. 1993)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 196,
                                "start": 11
                            }
                        ],
                        "text": "(1989) and Lee et al. (1993) derived semantic distance formulas using the edge counting principle, which were then used to support higher level result ranking in document retrieval. Sussna (1993) defined a similarity measure that takes into account taxonomy structure information."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 80,
                                "start": 63
                            }
                        ],
                        "text": "In the line of the edge-based approach, Rada et al. (1989) and Lee et al. (1993) derived semantic distance formulas using the edge counting principle, which were then used to support higher level result ranking in document retrieval."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 297,
                                "start": 11
                            }
                        ],
                        "text": "(1989) and Lee et al. (1993) derived semantic distance formulas using the edge counting principle, which were then used to support higher level result ranking in document retrieval. Sussna (1993) defined a similarity measure that takes into account taxonomy structure information. Resnik\u2019s (1995) information content measure is a typical representative of the node-based approach."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 20403380,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "604ea32f139a36631d8cc9f79e678baa4b38db08",
            "isKey": true,
            "numCitedBy": 337,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "There have been several document ranking methods to calculate the conceptual distance or closeness between a Boolean query and a document. Though they provide good retrieval effectiveness in many cases, they do not support effective weighting schemes for queries and documents and also have several problems resulting from inappropriate evaluation of Boolean operators. We propose a new method called Knowledge\u2010Based Extended Boolean Model (kb\u2010ebm) in which Salton's extended Boolean model is incorporated. kb\u2010ebm evaluates weighted queries and documents effectively, and avoids the problems of the previous methods. kb\u2010ebm provides high quality document rankings by using term dependence information from is\u2010a hierarchies The performance experiments show that the proposed method closely simulates human behaviour."
            },
            "slug": "Information-Retrieval-Based-on-Conceptual-Distance-Lee-Kim",
            "title": {
                "fragments": [],
                "text": "Information Retrieval Based on Conceptual Distance in is-a Hierarchies"
            },
            "venue": {
                "fragments": [],
                "text": "J. Documentation"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "21169546"
                        ],
                        "name": "Donald Hindle",
                        "slug": "Donald-Hindle",
                        "structuredName": {
                            "firstName": "Donald",
                            "lastName": "Hindle",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Donald Hindle"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 155,
                                "start": 144
                            }
                        ],
                        "text": "Under the corpus-based approach, word relationships are often derived from their co-occurrence distribution in a corpus (Church and Hanks 1989, Hindle 1990, Grefenstette 1992)."
                    },
                    "intents": []
                }
            ],
            "corpusId": 15862538,
            "fieldsOfStudy": [
                "Linguistics",
                "Computer Science"
            ],
            "id": "f3f3dcfcaa960ec201e0381f4d026e57e64bea76",
            "isKey": false,
            "numCitedBy": 689,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "A method of determining the similarity of nouns on the basis of a metric derived from the distribution of subject, verb and object in a large text corpus is described. The resulting quasi-semantic classification of nouns demonstrates the plausibility of the distributional hypothesis, and has potential application to a variety of tasks, including automatic indexing, resolving nominal compounds, and determining the scope of modification."
            },
            "slug": "Noun-Classification-from-Predicate-Argument-Hindle",
            "title": {
                "fragments": [],
                "text": "Noun Classification from Predicate-Argument Structures"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "The resulting quasi-semantic classification of nouns demonstrates the plausibility of the distributional hypothesis, and has potential application to a variety of tasks, including automatic indexing, resolving nominal compounds, and determining the scope of modification."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144096985"
                        ],
                        "name": "G. Miller",
                        "slug": "G.-Miller",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Miller",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Miller"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "66511259"
                        ],
                        "name": "R. Beckwith",
                        "slug": "R.-Beckwith",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Beckwith",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Beckwith"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1721801"
                        ],
                        "name": "C. Fellbaum",
                        "slug": "C.-Fellbaum",
                        "structuredName": {
                            "firstName": "Christiane",
                            "lastName": "Fellbaum",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Fellbaum"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145386345"
                        ],
                        "name": "Derek Gross",
                        "slug": "Derek-Gross",
                        "structuredName": {
                            "firstName": "Derek",
                            "lastName": "Gross",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Derek Gross"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2113623689"
                        ],
                        "name": "K. Miller",
                        "slug": "K.-Miller",
                        "structuredName": {
                            "firstName": "Katherine",
                            "lastName": "Miller",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Miller"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "With the recently developed lexical taxonomy WordNet (Miller 1990,  Miller et al. 1990 ), many researches have taken the advantage of this broad-coverage taxonomy to study word/concept relationships (Resnik 1995, Richardson and Smeaton 1995)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 85,
                                "start": 67
                            }
                        ],
                        "text": "With the recently developed lexical taxonomy WordNet (Miller 1990, Miller et al. 1990), many researches have taken the advantage of this broad-coverage taxonomy to study word/concept relationships (Resnik 1995, Richardson and Smeaton 1995)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2146137,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "4bd970a37c59c97804ff93cbb2c108e081de3a37",
            "isKey": false,
            "numCitedBy": 5335,
            "numCiting": 133,
            "paperAbstract": {
                "fragments": [],
                "text": "Standard alphabetical procedures for organizing lexical information put together words that are spelled alike and scatter words with similar or related meanings haphazardly through the list. Unfortunately, there is no obvious alternative, no other simple way for lexicographers to keep track of what has been done or for readers to find the word they are looking for. But a frequent objection to this solution is that finding things on an alphabetical list can be tedious and time-consuming. Many people who would like to refer to a dictionary decide not to bother with it because finding the information would interrupt their work and break their train of thought."
            },
            "slug": "Introduction-to-WordNet:-An-On-line-Lexical-Miller-Beckwith",
            "title": {
                "fragments": [],
                "text": "Introduction to WordNet: An On-line Lexical Database"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "Standard alphabetical procedures for organizing lexical information put together words that are spelled alike and scatter words with similar or related meanings haphazardly through the list."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1791072"
                        ],
                        "name": "T. Strzalkowski",
                        "slug": "T.-Strzalkowski",
                        "structuredName": {
                            "firstName": "Tomek",
                            "lastName": "Strzalkowski",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Strzalkowski"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2159567"
                        ],
                        "name": "Barbara Vauthey",
                        "slug": "Barbara-Vauthey",
                        "structuredName": {
                            "firstName": "Barbara",
                            "lastName": "Vauthey",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Barbara Vauthey"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 148,
                                "start": 119
                            }
                        ],
                        "text": "In the area of IR using NLP, approaches have be pursued to take advantage of the statistical term association results (Strzalkowski and Vauthey 1992, Grefenstette 1992)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 3035418,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3970c8e88cda4e56995c290bd9da586fbd15448a",
            "isKey": false,
            "numCitedBy": 54,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "We developed a fully automated Information Retrieval System which uses advanced natural language processing techniques to enhance the effectiveness of traditional key-word based document retrieval. In early experiments with the standard CACM-3204 collection of abstracts, the augmented system has displayed capabilities that made it clearly superior to the purely statistical base system."
            },
            "slug": "Information-Retrieval-Using-Robust-Natural-Language-Strzalkowski-Vauthey",
            "title": {
                "fragments": [],
                "text": "Information Retrieval Using Robust Natural Language Processing"
            },
            "tldr": {
                "abstractSimilarityScore": 93,
                "text": "A fully automated Information Retrieval System which uses advanced natural language processing techniques to enhance the effectiveness of traditional key-word based document retrieval."
            },
            "venue": {
                "fragments": [],
                "text": "HLT"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144096985"
                        ],
                        "name": "G. Miller",
                        "slug": "G.-Miller",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Miller",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Miller"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 55,
                                "start": 48
                            }
                        ],
                        "text": "The noun portion of the latest version (1.5) of WordNet was selected as the taxonomy to compute the similarity between concepts."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 37,
                                "start": 30
                            }
                        ],
                        "text": "Figure 2 depicts a portion of WordNet hierarchy that includes all the senses of these two words."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 17,
                                "start": 10
                            }
                        ],
                        "text": "Given the WordNet as the structured hierarchical network, the conceptual density for a sense of a word is proportional to the number of contextual words that appear on a sub-hierarchy of the WordNet where that particular sense exists."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 65,
                                "start": 54
                            }
                        ],
                        "text": "With the recently developed lexical taxonomy WordNet (Miller 1990, Miller et al. 1990), many researches have taken the advantage of this broad-coverage taxonomy to study word/concept relationships (Resnik 1995, Richardson and Smeaton 1995)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 24,
                                "start": 17
                            }
                        ],
                        "text": "Fragments of the WordNet noun taxonomy\n5"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 875,
                                "start": 204
                            }
                        ],
                        "text": "To make our experimental results comparable with other previous experiments, we decided to use the same sample of 30 noun pairs that were selected in an experiment when only human subjects were involved (Miller and Charles 1991), and in another more recent experiment when some computational models were constructed and compared as well (Resnik 1995). In fact, in the Resnik (1995) experiment, he replicated the human judgements on the same set of word pairs that Miller and Charles did. When the correlation between his replication and the one done by Miller and Charles (1991) was calculated, a baseline from human ratings was obtained for evaluation, which represents an upper bound that one could expect from a machine computation on the same task. In our experiment, we compare the proposed model with the node-based Information Content model developed by Resnik (1995) and the basic edge-based edge counting model, in the context of how well these perform against human ratings (i."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 159,
                                "start": 152
                            }
                        ],
                        "text": "However, Richardson and Smeaton (1995) had concerns that the measure was less accurate than expected when applied to a comparatively broad domain (e.g. WordNet taxonomy)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 91,
                                "start": 65
                            }
                        ],
                        "text": "The ratings in the table are sorted in descending order based on Miller and Charles (1991) findings."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 162,
                                "start": 155
                            }
                        ],
                        "text": "Notice that two values in Resnik\u2019s replication are not available, as he dropped two noun pairs in his experiment since the word woodland was not yet in the WordNet taxonomy at that time."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 50,
                                "start": 43
                            }
                        ],
                        "text": "For example, in the plant/flora section of WordNet the hierarchy is very dense."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 32,
                                "start": 25
                            }
                        ],
                        "text": "Slightly over 25% of the WordNet noun senses actually appeared in the corpus."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 49,
                                "start": 42
                            }
                        ],
                        "text": "Since the tagging scheme was based on the WordNet word sense definition, this enables us to obtain a precise frequency distribution for each node (synset) in the taxonomy."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 382,
                                "start": 204
                            }
                        ],
                        "text": "To make our experimental results comparable with other previous experiments, we decided to use the same sample of 30 noun pairs that were selected in an experiment when only human subjects were involved (Miller and Charles 1991), and in another more recent experiment when some computational models were constructed and compared as well (Resnik 1995). In fact, in the Resnik (1995) experiment, he replicated the human judgements on the same set of word pairs that Miller and Charles did."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 55,
                                "start": 48
                            }
                        ],
                        "text": "Since the original purpose of the design of the WordNet was not for similarity computation purpose, some local network layer constructions may not be suitable for the direct distance manipulation."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 44,
                                "start": 37
                            }
                        ],
                        "text": "Figure 1 depicts the fragment of the WordNet (Version 1.5) noun hierarchy that contains these classes."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 579,
                                "start": 204
                            }
                        ],
                        "text": "To make our experimental results comparable with other previous experiments, we decided to use the same sample of 30 noun pairs that were selected in an experiment when only human subjects were involved (Miller and Charles 1991), and in another more recent experiment when some computational models were constructed and compared as well (Resnik 1995). In fact, in the Resnik (1995) experiment, he replicated the human judgements on the same set of word pairs that Miller and Charles did. When the correlation between his replication and the one done by Miller and Charles (1991) was calculated, a baseline from human ratings was obtained for evaluation, which represents an upper bound that one could expect from a machine computation on the same task."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 56,
                                "start": 49
                            }
                        ],
                        "text": "A further look at their\n12\nclassification in the WordNet hierarchy seems to provide an explanation."
                    },
                    "intents": []
                }
            ],
            "corpusId": 62525727,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "7e16e2d914720f363f6dc4da3d24791747ee5491",
            "isKey": true,
            "numCitedBy": 314,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Nouns-in-WordNet:-A-Lexical-Inheritance-System-Miller",
            "title": {
                "fragments": [],
                "text": "Nouns in WordNet: A Lexical Inheritance System"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1990
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 124,
                                "start": 107
                            }
                        ],
                        "text": "One node based approach to determine the conceptual similarity is called the information content approach (Resnik 1992, 1995)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 349,
                                "start": 336
                            }
                        ],
                        "text": "To make our experimental results comparable with o er previous experiments, we decided to use the same sample of 30 noun pairs that were selected in an experiment when only human subjects were involved (Miller and Charles 1991), and in another more recent experiment when some computational models were constructed and compared as well (Resnik 1995)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 209,
                                "start": 198
                            }
                        ],
                        "text": "With the recently developed lexical taxonomy WordNet (Miller 1990, Miller et al. 1990), many researches have taken the advantage of this broad-coverage taxonomy to study word/concept relationships (Resnik 1995, Richardson and Smeaton 1995)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 69,
                                "start": 58
                            }
                        ],
                        "text": "It is not sensitive to the problem of varying link types (Resnik 1995)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 29,
                                "start": 16
                            }
                        ],
                        "text": "In fact, in the Resnik (1995) experiment, he replicated hehuman judgements on the same set of word pairs that Miller and Charles did."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 147,
                                "start": 136
                            }
                        ],
                        "text": "To convert the distance measure to a similarity measure, one may simply subtract the path length from the maximum possible path length (Resnik 1995): sim w w d c senw c senw len c c( , ) [ min ( ) ( ) ( , )],max1 2 1 1 2 2 1 22= \u2212 \u2208 \u2208 (10) where dmax is the maximum depth of the taxonomy, and the\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 127,
                                "start": 116
                            }
                        ],
                        "text": "Therefore it avoids potentially spurious results in occasions when only word (not word sense) frequencies are used (Resnik 1995)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 108,
                                "start": 97
                            }
                        ],
                        "text": "The data on human ratings are from the publication of previous results (Miller and Charles 1991, Resnik 1995)."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 16,
                                "start": 0
                            }
                        ],
                        "text": "Resnik\u2019s (1995) information content measure is a typical representative of the node-based approach."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 121,
                                "start": 108
                            }
                        ],
                        "text": "In our experiment, we compare the proposed model with the node-based Information Content model developed by Resnik (1995) and the basic edge-based edge counting model, in the context of how well these perform against human ratings (i.e. the upper bound)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 298,
                                "start": 287
                            }
                        ],
                        "text": "\u2026er previous experiments, we decided to use the same sample of 30 noun pairs that were selected in an experiment when only human subjects were involved (Miller and Charles 1991), and in another more recent experiment when some computational models were constructed and compared as well (Resnik 1995)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 148,
                                "start": 135
                            }
                        ],
                        "text": "To convert the distance measure to a similarity measure, one may simply subtract the path length from the maximum possible path length (Resnik 1995):"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 101,
                                "start": 88
                            }
                        ],
                        "text": "The results of the experiment confirm that the information content approach proposed by Resnik (1995) provides a significant improvement over the traditional edge counting method."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 204,
                                "start": 191
                            }
                        ],
                        "text": "\u2026root c. Classes(w) is defined as the classes in which the word w is contained; in another word, it is the set of possible senses that the word w has: classes w c w words c( ) { | ( )}.= \u2208 (4) Resnik (1995) defined a simple class/concept frequency formula: freq c freq w w words c ( ) ( ) ( ) = \u2208 \u2211 ."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Using Information Content to Evaluate"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 148,
                                "start": 136
                            }
                        ],
                        "text": "In the area of IR using NLP, approaches have be pursued to take advantage of the statistical term association results (Strzalkowski and Vauthey 1992, Grefenstette 1992)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Information Retrieval Using Robust"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 85,
                                "start": 67
                            }
                        ],
                        "text": "With the recently developed lexical taxonomy WordNet (Miller 1990, Miller et al. 1990), many researches have taken the advantage of this broad-coverage taxonomy to study word/concept relationships (Resnik 1995, Richardson and Smeaton 1995)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Introduction to WordNet: An Online Lexical Database"
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Lexicography,"
            },
            "year": 1990
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 12,
            "methodology": 18,
            "result": 4
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 22,
        "totalPages": 3
    },
    "page_url": "https://www.semanticscholar.org/paper/Semantic-Similarity-Based-on-Corpus-Statistics-and-Jiang-Conrath/6b64e068a8face2540fc436af40dbcd2b0912bbf?sort=total-citations"
}