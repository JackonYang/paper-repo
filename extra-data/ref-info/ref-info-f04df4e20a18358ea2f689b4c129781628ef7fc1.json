{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3461596"
                        ],
                        "name": "Johan Bos",
                        "slug": "Johan-Bos",
                        "structuredName": {
                            "firstName": "Johan",
                            "lastName": "Bos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Johan Bos"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1686341"
                        ],
                        "name": "K. Markert",
                        "slug": "K.-Markert",
                        "structuredName": {
                            "firstName": "Katja",
                            "lastName": "Markert",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Markert"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 228,
                                "start": 107
                            }
                        ],
                        "text": "Thus, natural language inference (NLI) \u2014 characterizing and using these relations in computational systems (Fyodorov et al., 2000; Condoravdi et al., 2003; Bos and Markert, 2005; Dagan et al., 2006; MacCartney and Manning, 2009) \u2014 is essential in tasks ranging from information retrieval to semantic parsing to commonsense reasoning."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 10202504,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ea2563467c1c472a346d165b7f97c86317d63ca4",
            "isKey": false,
            "numCitedBy": 253,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "We use logical inference techniques for recognising textual entailment. As the performance of theorem proving turns out to be highly dependent on not readily available background knowledge, we incorporate model building, a technique borrowed from automated reasoning, and show that it is a useful robust method to approximate entailment. Finally, we use machine learning to combine these deep semantic analysis techniques with simple shallow word overlap; the resulting hybrid model achieves high accuracy on the RTE testset, given the state of the art. Our results also show that the different techniques that we employ perform very differently on some of the subsets of the RTE corpus and as a result, it is useful to use the nature of the dataset as a feature."
            },
            "slug": "Recognising-Textual-Entailment-with-Logical-Bos-Markert",
            "title": {
                "fragments": [],
                "text": "Recognising Textual Entailment with Logical Inference"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This work incorporates model building, a technique borrowed from automated reasoning, and shows that it is a useful robust method to approximate entailment, and uses machine learning to combine these deep semantic analysis techniques with simple shallow word overlap."
            },
            "venue": {
                "fragments": [],
                "text": "HLT"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3257930"
                        ],
                        "name": "Bill MacCartney",
                        "slug": "Bill-MacCartney",
                        "structuredName": {
                            "firstName": "Bill",
                            "lastName": "MacCartney",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bill MacCartney"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144783904"
                        ],
                        "name": "Christopher D. Manning",
                        "slug": "Christopher-D.-Manning",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Manning",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christopher D. Manning"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 228,
                                "start": 107
                            }
                        ],
                        "text": "Thus, natural language inference (NLI) \u2014 characterizing and using these relations in computational systems (Fyodorov et al., 2000; Condoravdi et al., 2003; Bos and Markert, 2005; Dagan et al., 2006; MacCartney and Manning, 2009) \u2014 is essential in tasks ranging from information retrieval to semantic parsing to commonsense reasoning."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6561519,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5feb2c61b04532869e44d1ca4e48c7108aee5fd3",
            "isKey": false,
            "numCitedBy": 178,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a model of natural language inference which identifies valid inferences by their lexical and syntactic features, without full semantic interpretation. We extend past work in natural logic, which has focused on semantic containment and monotonicity, by incorporating both semantic exclusion and implicativity. Our model decomposes an inference problem into a sequence of atomic edits linking premise to hypothesis; predicts a lexical semantic relation for each edit; propagates these relations upward through a semantic composition tree according to properties of intermediate nodes; and joins the resulting semantic relations across the edit sequence. A computational implementation of the model achieves 70% accuracy and 89% precision on the FraCaS test suite. Moreover, including this model as a component in an existing system yields significant performance gains on the Recognizing Textual Entailment challenge."
            },
            "slug": "An-extended-model-of-natural-logic-MacCartney-Manning",
            "title": {
                "fragments": [],
                "text": "An extended model of natural logic"
            },
            "tldr": {
                "abstractSimilarityScore": 82,
                "text": "A model of natural language inference which identifies valid inferences by their lexical and syntactic features, without full semantic interpretation is proposed, extending past work in natural logic by incorporating both semantic exclusion and implicativity."
            },
            "venue": {
                "fragments": [],
                "text": "IWCS"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1708581"
                        ],
                        "name": "Sebastian Pad\u00f3",
                        "slug": "Sebastian-Pad\u00f3",
                        "structuredName": {
                            "firstName": "Sebastian",
                            "lastName": "Pad\u00f3",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sebastian Pad\u00f3"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3104237"
                        ],
                        "name": "Tae-Gil Noh",
                        "slug": "Tae-Gil-Noh",
                        "structuredName": {
                            "firstName": "Tae-Gil",
                            "lastName": "Noh",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tae-Gil Noh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32590708"
                        ],
                        "name": "Asher Stern",
                        "slug": "Asher-Stern",
                        "structuredName": {
                            "firstName": "Asher",
                            "lastName": "Stern",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Asher Stern"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2151036793"
                        ],
                        "name": "Rui Wang",
                        "slug": "Rui-Wang",
                        "structuredName": {
                            "firstName": "Rui",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Rui Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "36024018"
                        ],
                        "name": "Roberto Zanoli",
                        "slug": "Roberto-Zanoli",
                        "structuredName": {
                            "firstName": "Roberto",
                            "lastName": "Zanoli",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Roberto Zanoli"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 85,
                                "start": 69
                            }
                        ],
                        "text": "We gratefully acknowledge support from a Google Faculty Research Award, a gift from Bloomberg L.P., the Defense Advanced Research Projects Agency (DARPA) Deep Exploration and Filtering of Text (DEFT) Program under Air Force Research Laboratory (AFRL) contract no."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 85,
                                "start": 69
                            }
                        ],
                        "text": "The first class of models is from the Excitement Open Platform (EOP, Pado\u0301 et al. 2014; Magnini et al. 2014)\u2014an open source platform for RTE research."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 9254866,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b5f55466136bde834232f5641619bcc488c070bc",
            "isKey": false,
            "numCitedBy": 36,
            "numCiting": 87,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract A key challenge at the core of many Natural Language Processing (NLP) tasks is the ability to determine which conclusions can be inferred from a given natural language text. This problem, called the Recognition of Textual Entailment (RTE), has initiated the development of a range of algorithms, methods, and technologies. Unfortunately, research on Textual Entailment (TE), like semantics research more generally, is fragmented into studies focussing on various aspects of semantics such as world knowledge, lexical and syntactic relations, or more specialized kinds of inference. This fragmentation has problematic practical consequences. Notably, interoperability among the existing RTE systems is poor, and reuse of resources and algorithms is mostly infeasible. This also makes systematic evaluations very difficult to carry out. Finally, textual entailment presents a wide array of approaches to potential end users with little guidance on which to pick. Our contribution to this situation is the novel EXCITEMENT architecture, which was developed to enable and encourage the consolidation of methods and resources in the textual entailment area. It decomposes RTE into components with strongly typed interfaces. We specify (a) a modular linguistic analysis pipeline and (b) a decomposition of the \u2018core\u2019 RTE methods into top-level algorithms and subcomponents. We identify four major subcomponent types, including knowledge bases and alignment methods. The architecture was developed with a focus on generality, supporting all major approaches to RTE and encouraging language independence. We illustrate the feasibility of the architecture by constructing mappings of major existing systems onto the architecture. The practical implementation of this architecture forms the EXCITEMENT open platform. It is a suite of textual entailment algorithms and components which contains the three systems named above, including linguistic-analysis pipelines for three languages (English, German, and Italian), and comprises a number of linguistic resources. By addressing the problems outlined above, the platform provides a comprehensive and flexible basis for research and experimentation in textual entailment and is available as open source software under the GNU General Public License."
            },
            "slug": "Design-and-realization-of-a-modular-architecture-Pad\u00f3-Noh",
            "title": {
                "fragments": [],
                "text": "Design and realization of a modular architecture for textual entailment"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The novel EXCITEMENT architecture, which was developed to enable and encourage the consolidation of methods and resources in the textual entailment area, decomposes RTE into components with strongly typed interfaces, and is available as open source software under the GNU General Public License."
            },
            "venue": {
                "fragments": [],
                "text": "Natural Language Engineering"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48188880"
                        ],
                        "name": "M. Marelli",
                        "slug": "M.-Marelli",
                        "structuredName": {
                            "firstName": "Marco",
                            "lastName": "Marelli",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Marelli"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2644577"
                        ],
                        "name": "S. Menini",
                        "slug": "S.-Menini",
                        "structuredName": {
                            "firstName": "Stefano",
                            "lastName": "Menini",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Menini"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145283199"
                        ],
                        "name": "Marco Baroni",
                        "slug": "Marco-Baroni",
                        "structuredName": {
                            "firstName": "Marco",
                            "lastName": "Baroni",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Marco Baroni"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2486762"
                        ],
                        "name": "L. Bentivogli",
                        "slug": "L.-Bentivogli",
                        "structuredName": {
                            "firstName": "Luisa",
                            "lastName": "Bentivogli",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Bentivogli"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145040726"
                        ],
                        "name": "R. Bernardi",
                        "slug": "R.-Bernardi",
                        "structuredName": {
                            "firstName": "Raffaella",
                            "lastName": "Bernardi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Bernardi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2713535"
                        ],
                        "name": "Roberto Zamparelli",
                        "slug": "Roberto-Zamparelli",
                        "structuredName": {
                            "firstName": "Roberto",
                            "lastName": "Zamparelli",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Roberto Zamparelli"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 268,
                                "start": 248
                            }
                        ],
                        "text": "The data for the SemEval 2014 task called Sentences Involving Compositional Knowledge (SICK) is a step up in terms of size, but only to 4,500 training examples, and its partly automatic construction introduced some spurious patterns into the data (Marelli et al. 2014a, \u00a76)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 285,
                                "start": 265
                            }
                        ],
                        "text": "Existing resources suffer from a subtler issue that impacts even projects using only humanprovided annotations: indeterminacies of event and entity coreference lead to insurmountable indeterminacy concerning the correct semantic label (de Marneffe et al. 2008 \u00a74.3; Marelli et al. 2014b)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 195,
                                "start": 174
                            }
                        ],
                        "text": "In a SemEval 2014 task aimed at evaluating distributed representations for NLI, the best-performing systems relied heavily on additional features and reasoning capabilities (Marelli et al., 2014a)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 762228,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c333778104f648c385b4631f7b4a859787e9d3d3",
            "isKey": true,
            "numCitedBy": 496,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "Shared and internationally recognized benchmarks are fundamental for the development of any computational system. We aim to help the research community working on compositional distributional semantic models (CDSMs) by providing SICK (Sentences Involving Compositional Knowldedge), a large size English benchmark tailored for them. SICK consists of about 10,000 English sentence pairs that include many examples of the lexical, syntactic and semantic phenomena that CDSMs are expected to account for, but do not require dealing with other aspects of existing sentential data sets (idiomatic multiword expressions, named entities, telegraphic language) that are not within the scope of CDSMs. By means of crowdsourcing techniques, each pair was annotated for two crucial semantic tasks: relatedness in meaning (with a 5-point rating scale as gold score) and entailment relation between the two elements (with three possible gold labels: entailment, contradiction, and neutral). The SICK data set was used in SemEval-2014 Task 1, and it freely available for research purposes."
            },
            "slug": "A-SICK-cure-for-the-evaluation-of-compositional-Marelli-Menini",
            "title": {
                "fragments": [],
                "text": "A SICK cure for the evaluation of compositional distributional semantic models"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "This work aims to help the research community working on compositional distributional semantic models (CDSMs) by providing SICK (Sentences Involving Compositional Knowldedge), a large size English benchmark tailored for them."
            },
            "venue": {
                "fragments": [],
                "text": "LREC"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2166511"
                        ],
                        "name": "R. Socher",
                        "slug": "R.-Socher",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Socher",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Socher"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "24590005"
                        ],
                        "name": "Alex Perelygin",
                        "slug": "Alex-Perelygin",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Perelygin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alex Perelygin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2110402830"
                        ],
                        "name": "Jean Wu",
                        "slug": "Jean-Wu",
                        "structuredName": {
                            "firstName": "Jean",
                            "lastName": "Wu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jean Wu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1964541"
                        ],
                        "name": "Jason Chuang",
                        "slug": "Jason-Chuang",
                        "structuredName": {
                            "firstName": "Jason",
                            "lastName": "Chuang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jason Chuang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144783904"
                        ],
                        "name": "Christopher D. Manning",
                        "slug": "Christopher-D.-Manning",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Manning",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christopher D. Manning"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34699434"
                        ],
                        "name": "A. Ng",
                        "slug": "A.-Ng",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Ng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Ng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144922861"
                        ],
                        "name": "Christopher Potts",
                        "slug": "Christopher-Potts",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Potts",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christopher Potts"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 163,
                                "start": 145
                            }
                        ],
                        "text": "\u2026at capturing relations based in similarity, and have proven effective at modeling simple dimensions of meaning like evaluative sentiment (e.g., Socher et al. 2013), but it is less clear that they can be trained to support the full range of logical and commonsense inferences required for NLI\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 990233,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "687bac2d3320083eb4530bf18bb8f8f721477600",
            "isKey": false,
            "numCitedBy": 5366,
            "numCiting": 55,
            "paperAbstract": {
                "fragments": [],
                "text": "Semantic word spaces have been very useful but cannot express the meaning of longer phrases in a principled way. Further progress towards understanding compositionality in tasks such as sentiment detection requires richer supervised training and evaluation resources and more powerful models of composition. To remedy this, we introduce a Sentiment Treebank. It includes fine grained sentiment labels for 215,154 phrases in the parse trees of 11,855 sentences and presents new challenges for sentiment compositionality. To address them, we introduce the Recursive Neural Tensor Network. When trained on the new treebank, this model outperforms all previous methods on several metrics. It pushes the state of the art in single sentence positive/negative classification from 80% up to 85.4%. The accuracy of predicting fine-grained sentiment labels for all phrases reaches 80.7%, an improvement of 9.7% over bag of features baselines. Lastly, it is the only model that can accurately capture the effects of negation and its scope at various tree levels for both positive and negative phrases."
            },
            "slug": "Recursive-Deep-Models-for-Semantic-Compositionality-Socher-Perelygin",
            "title": {
                "fragments": [],
                "text": "Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "A Sentiment Treebank that includes fine grained sentiment labels for 215,154 phrases in the parse trees of 11,855 sentences and presents new challenges for sentiment compositionality, and introduces the Recursive Neural Tensor Network."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3644767"
                        ],
                        "name": "Samuel R. Bowman",
                        "slug": "Samuel-R.-Bowman",
                        "structuredName": {
                            "firstName": "Samuel",
                            "lastName": "Bowman",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Samuel R. Bowman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144922861"
                        ],
                        "name": "Christopher Potts",
                        "slug": "Christopher-Potts",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Potts",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christopher Potts"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144783904"
                        ],
                        "name": "Christopher D. Manning",
                        "slug": "Christopher-D.-Manning",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Manning",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christopher D. Manning"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15618372,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7c05a4ffee7e159e34b2efea7e44d994333ec628",
            "isKey": false,
            "numCitedBy": 123,
            "numCiting": 37,
            "paperAbstract": {
                "fragments": [],
                "text": "Tree-structured recursive neural networks (TreeRNNs) for sentence meaning have been successful for many applications, but it remains an open question whether the fixed-length representations that they learn can support tasks as demanding as logical deduction. We pursue this question by evaluating whether two such models---plain TreeRNNs and tree-structured neural tensor networks (TreeRNTNs)---can correctly learn to identify logical relationships such as entailment and contradiction using these representations. In our first set of experiments, we generate artificial data from a logical grammar and use it to evaluate the models' ability to learn to handle basic relational reasoning, recursive structures, and quantification. We then evaluate the models on the more natural SICK challenge data. Both models perform competitively on the SICK data and generalize well in all three experiments on simulated data, suggesting that they can learn suitable representations for logical inference in natural language."
            },
            "slug": "Recursive-Neural-Networks-Can-Learn-Logical-Bowman-Potts",
            "title": {
                "fragments": [],
                "text": "Recursive Neural Networks Can Learn Logical Semantics"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This work generates artificial data from a logical grammar and uses it to evaluate the models' ability to learn to handle basic relational reasoning, recursive structures, and quantification, suggesting that they can learn suitable representations for logical inference in natural language."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145183709"
                        ],
                        "name": "J. Weston",
                        "slug": "J.-Weston",
                        "structuredName": {
                            "firstName": "Jason",
                            "lastName": "Weston",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Weston"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1713934"
                        ],
                        "name": "Antoine Bordes",
                        "slug": "Antoine-Bordes",
                        "structuredName": {
                            "firstName": "Antoine",
                            "lastName": "Bordes",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Antoine Bordes"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3295092"
                        ],
                        "name": "S. Chopra",
                        "slug": "S.-Chopra",
                        "structuredName": {
                            "firstName": "Sumit",
                            "lastName": "Chopra",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Chopra"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2047446108"
                        ],
                        "name": "Tomas Mikolov",
                        "slug": "Tomas-Mikolov",
                        "structuredName": {
                            "firstName": "Tomas",
                            "lastName": "Mikolov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tomas Mikolov"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 3178759,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "abb33d75dc297993fcc3fb75e0f4498f413eb4f6",
            "isKey": false,
            "numCitedBy": 911,
            "numCiting": 50,
            "paperAbstract": {
                "fragments": [],
                "text": "One long-term goal of machine learning research is to produce methods that are applicable to reasoning and natural language, in particular building an intelligent dialogue agent. To measure progress towards that goal, we argue for the usefulness of a set of proxy tasks that evaluate reading comprehension via question answering. Our tasks measure understanding in several ways: whether a system is able to answer questions via chaining facts, simple induction, deduction and many more. The tasks are designed to be prerequisites for any system that aims to be capable of conversing with a human. We believe many existing learning systems can currently not solve them, and hence our aim is to classify these tasks into skill sets, so that researchers can identify (and then rectify) the failings of their systems. We also extend and improve the recently introduced Memory Networks model, and show it is able to solve some, but not all, of the tasks."
            },
            "slug": "Towards-AI-Complete-Question-Answering:-A-Set-of-Weston-Bordes",
            "title": {
                "fragments": [],
                "text": "Towards AI-Complete Question Answering: A Set of Prerequisite Toy Tasks"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This work argues for the usefulness of a set of proxy tasks that evaluate reading comprehension via question answering, and classify these tasks into skill sets so that researchers can identify (and then rectify) the failings of their systems."
            },
            "venue": {
                "fragments": [],
                "text": "ICLR"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145183709"
                        ],
                        "name": "J. Weston",
                        "slug": "J.-Weston",
                        "structuredName": {
                            "firstName": "Jason",
                            "lastName": "Weston",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Weston"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3295092"
                        ],
                        "name": "S. Chopra",
                        "slug": "S.-Chopra",
                        "structuredName": {
                            "firstName": "Sumit",
                            "lastName": "Chopra",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Chopra"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1713934"
                        ],
                        "name": "Antoine Bordes",
                        "slug": "Antoine-Bordes",
                        "structuredName": {
                            "firstName": "Antoine",
                            "lastName": "Bordes",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Antoine Bordes"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 275,
                                "start": 255
                            }
                        ],
                        "text": "\u2026effective at modeling simple dimensions of meaning like evaluative sentiment (e.g., Socher et al. 2013), but it is less clear that they can be trained to support the full range of logical and commonsense inferences required for NLI (Bowman et al., 2015; Weston et al., 2015b; Weston et al., 2015a)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 199,
                                "start": 134
                            }
                        ],
                        "text": "2013), but it is less clear that they can be trained to support the full range of logical and commonsense inferences required for NLI (Bowman et al., 2015; Weston et al., 2015b; Weston et al., 2015a)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2926851,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "71ae756c75ac89e2d731c9c79649562b5768ff39",
            "isKey": false,
            "numCitedBy": 1146,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract: We describe a new class of learning models called memory networks. Memory networks reason with inference components combined with a long-term memory component; they learn how to use these jointly. The long-term memory can be read and written to, with the goal of using it for prediction. We investigate these models in the context of question answering (QA) where the long-term memory effectively acts as a (dynamic) knowledge base, and the output is a textual response. We evaluate them on a large-scale QA task, and a smaller, but more complex, toy task generated from a simulated world. In the latter, we show the reasoning power of such models by chaining multiple supporting sentences to answer questions that require understanding the intension of verbs."
            },
            "slug": "Memory-Networks-Weston-Chopra",
            "title": {
                "fragments": [],
                "text": "Memory Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 87,
                "text": "This work describes a new class of learning models called memory networks, which reason with inference components combined with a long-term memory component; they learn how to use these jointly."
            },
            "venue": {
                "fragments": [],
                "text": "ICLR"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48188880"
                        ],
                        "name": "M. Marelli",
                        "slug": "M.-Marelli",
                        "structuredName": {
                            "firstName": "Marco",
                            "lastName": "Marelli",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Marelli"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2486762"
                        ],
                        "name": "L. Bentivogli",
                        "slug": "L.-Bentivogli",
                        "structuredName": {
                            "firstName": "Luisa",
                            "lastName": "Bentivogli",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Bentivogli"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145283199"
                        ],
                        "name": "Marco Baroni",
                        "slug": "Marco-Baroni",
                        "structuredName": {
                            "firstName": "Marco",
                            "lastName": "Baroni",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Marco Baroni"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145040726"
                        ],
                        "name": "R. Bernardi",
                        "slug": "R.-Bernardi",
                        "structuredName": {
                            "firstName": "Raffaella",
                            "lastName": "Bernardi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Bernardi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2644577"
                        ],
                        "name": "S. Menini",
                        "slug": "S.-Menini",
                        "structuredName": {
                            "firstName": "Stefano",
                            "lastName": "Menini",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Menini"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2713535"
                        ],
                        "name": "Roberto Zamparelli",
                        "slug": "Roberto-Zamparelli",
                        "structuredName": {
                            "firstName": "Roberto",
                            "lastName": "Zamparelli",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Roberto Zamparelli"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 268,
                                "start": 248
                            }
                        ],
                        "text": "The data for the SemEval 2014 task called Sentences Involving Compositional Knowledge (SICK) is a step up in terms of size, but only to 4,500 training examples, and its partly automatic construction introduced some spurious patterns into the data (Marelli et al. 2014a, \u00a76)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 285,
                                "start": 265
                            }
                        ],
                        "text": "Existing resources suffer from a subtler issue that impacts even projects using only humanprovided annotations: indeterminacies of event and entity coreference lead to insurmountable indeterminacy concerning the correct semantic label (de Marneffe et al. 2008 \u00a74.3; Marelli et al. 2014b)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 195,
                                "start": 174
                            }
                        ],
                        "text": "In a SemEval 2014 task aimed at evaluating distributed representations for NLI, the best-performing systems relied heavily on additional features and reasoning capabilities (Marelli et al., 2014a)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 16404002,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "11ec56898a9e7f401a2affe776b5297bd4e25025",
            "isKey": true,
            "numCitedBy": 360,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents the task on the evaluation of Compositional Distributional Semantics Models on full sentences organized for the first time within SemEval2014. Participation was open to systems based on any approach. Systems were presented with pairs of sentences and were evaluated on their ability to predict human judgments on (i) semantic relatedness and (ii) entailment. The task attracted 21 teams, most of which participated in both subtasks. We received 17 submissions in the relatedness subtask (for a total of 66 runs) and 18 in the entailment subtask (65 runs)."
            },
            "slug": "SemEval-2014-Task-1:-Evaluation-of-Compositional-on-Marelli-Bentivogli",
            "title": {
                "fragments": [],
                "text": "SemEval-2014 Task 1: Evaluation of Compositional Distributional Semantic Models on Full Sentences through Semantic Relatedness and Textual Entailment"
            },
            "tldr": {
                "abstractSimilarityScore": 81,
                "text": "This paper presents the task on the evaluation of Compositional Distributional Semantics Models on full sentences organized for the first time within SemEval2014, and attracted 21 teams, most of which participated in both subtasks."
            },
            "venue": {
                "fragments": [],
                "text": "*SEMEVAL"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2241127"
                        ],
                        "name": "Marie-Catherine de Marneffe",
                        "slug": "Marie-Catherine-de-Marneffe",
                        "structuredName": {
                            "firstName": "Marie-Catherine",
                            "lastName": "Marneffe",
                            "middleNames": [
                                "de"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Marie-Catherine de Marneffe"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1875900"
                        ],
                        "name": "Anna N. Rafferty",
                        "slug": "Anna-N.-Rafferty",
                        "structuredName": {
                            "firstName": "Anna",
                            "lastName": "Rafferty",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Anna N. Rafferty"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144783904"
                        ],
                        "name": "Christopher D. Manning",
                        "slug": "Christopher-D.-Manning",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Manning",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christopher D. Manning"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 259,
                                "start": 236
                            }
                        ],
                        "text": "Existing resources suffer from a subtler issue that impacts even projects using only humanprovided annotations: indeterminacies of event and entity coreference lead to insurmountable indeterminacy concerning the correct semantic label (de Marneffe et al. 2008 \u00a74.3; Marelli et al. 2014b)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5555594,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "287d5571dbf255a7ccbdc2bcfe9211fd8f0b2a7c",
            "isKey": false,
            "numCitedBy": 233,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "Detecting conflicting statements is a foundational text understanding task with applications in information analysis. We propose an appropriate definition of contradiction for NLP tasks and develop available corpora, from which we construct a typology of contradictions. We demonstrate that a system for contradiction needs to make more fine-grained distinctions than the common systems for entailment. In particular, we argue for the centrality of event coreference and therefore incorporate such a component based on topicality. We present the first detailed breakdown of performance on this task. Detecting some types of contradiction requires deeper inferential paths than our system is capable of, but we achieve good performance on types arising from negation and antonymy."
            },
            "slug": "Finding-Contradictions-in-Text-Marneffe-Rafferty",
            "title": {
                "fragments": [],
                "text": "Finding Contradictions in Text"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "It is demonstrated that a system for contradiction needs to make more fine-grained distinctions than the common systems for entailment, and is argued for the centrality of event coreference and therefore incorporate such a component based on topicality."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2151036793"
                        ],
                        "name": "Rui Wang",
                        "slug": "Rui-Wang",
                        "structuredName": {
                            "firstName": "Rui",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Rui Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143792905"
                        ],
                        "name": "G. Neumann",
                        "slug": "G.-Neumann",
                        "structuredName": {
                            "firstName": "G\u00fcnter",
                            "lastName": "Neumann",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Neumann"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 300,
                                "start": 276
                            }
                        ],
                        "text": "In addition to the base classifier-based system distributed with the platform, we train a variant which includes information from WordNet (Miller, 1995) and VerbOcean (Chklovski and Pantel, 2004), and makes use of features based on tree patterns and dependency tree skeletons (Wang and Neumann, 2007)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 868993,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "40e7e3d009f83f17b6aa892eeae67d225056c98a",
            "isKey": false,
            "numCitedBy": 63,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a novel approach to RTE that exploits a structure-oriented sentence representation followed by a similarity function. The structural features are automatically acquired from tree skeletons that are extracted and generalized from dependency trees. Our method makes use of a limited size of training data without any external knowledge bases (e.g. WordNet) or handcrafted inference rules. We have achieved an accuracy of 71.1% on the RTE-3 development set performing a 10-fold cross validation and 66.9% on the RTE-3 test data."
            },
            "slug": "Recognizing-Textual-Entailment-Using-Sentence-based-Wang-Neumann",
            "title": {
                "fragments": [],
                "text": "Recognizing Textual Entailment Using Sentence Similarity based on Dependency Tree Skeletons"
            },
            "tldr": {
                "abstractSimilarityScore": 68,
                "text": "A novel approach to RTE that exploits a structure-oriented sentence representation followed by a similarity function that makes use of a limited size of training data without any external knowledge bases or handcrafted inference rules is presented."
            },
            "venue": {
                "fragments": [],
                "text": "ACL-PASCAL@ACL"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39455775"
                        ],
                        "name": "Omer Levy",
                        "slug": "Omer-Levy",
                        "structuredName": {
                            "firstName": "Omer",
                            "lastName": "Levy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Omer Levy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7465342"
                        ],
                        "name": "Ido Dagan",
                        "slug": "Ido-Dagan",
                        "structuredName": {
                            "firstName": "Ido",
                            "lastName": "Dagan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ido Dagan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34508613"
                        ],
                        "name": "J. Goldberger",
                        "slug": "J.-Goldberger",
                        "structuredName": {
                            "firstName": "Jacob",
                            "lastName": "Goldberger",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Goldberger"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7149590,
            "fieldsOfStudy": [
                "Philosophy"
            ],
            "id": "8cef20c98d41018c44c78772424112c5b5679144",
            "isKey": false,
            "numCitedBy": 44,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "Open IE methods extract structured propositions from text. However, these propositions are neither consolidated nor generalized, and querying them may lead to insufficient or redundant information. This work suggests an approach to organize open IE propositions using entailment graphs. The entailment relation unifies equivalent propositions and induces a specific-to-general structure. We create a large dataset of gold-standard proposition entailment graphs, and provide a novel algorithm for automatically constructing them. Our analysis shows that predicate entailment is extremely context-sensitive, and that current lexical-semantic resources do not capture many of the lexical inferences induced by proposition entailment."
            },
            "slug": "Focused-Entailment-Graphs-for-Open-IE-Propositions-Levy-Dagan",
            "title": {
                "fragments": [],
                "text": "Focused Entailment Graphs for Open IE Propositions"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This work creates a large dataset of gold-standard proposition entailment graphs, and provides a novel algorithm for automatically constructing them, and shows that predicate entailment is extremely context-sensitive, and that current lexical-semantic resources do not capture many of the lexical inferences induced by propositions entailment."
            },
            "venue": {
                "fragments": [],
                "text": "CoNLL"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2516953"
                        ],
                        "name": "C. Condoravdi",
                        "slug": "C.-Condoravdi",
                        "structuredName": {
                            "firstName": "Cleo",
                            "lastName": "Condoravdi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Condoravdi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2953252"
                        ],
                        "name": "Dick Crouch",
                        "slug": "Dick-Crouch",
                        "structuredName": {
                            "firstName": "Dick",
                            "lastName": "Crouch",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dick Crouch"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143893075"
                        ],
                        "name": "Valeria C V de Paiva",
                        "slug": "Valeria-C-V-de-Paiva",
                        "structuredName": {
                            "firstName": "Valeria",
                            "lastName": "de Paiva",
                            "middleNames": [
                                "C",
                                "V"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Valeria C V de Paiva"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2097032136"
                        ],
                        "name": "R. Stolle",
                        "slug": "R.-Stolle",
                        "structuredName": {
                            "firstName": "Reinhard",
                            "lastName": "Stolle",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Stolle"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1753394"
                        ],
                        "name": "D. Bobrow",
                        "slug": "D.-Bobrow",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Bobrow",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Bobrow"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 228,
                                "start": 107
                            }
                        ],
                        "text": "Thus, natural language inference (NLI) \u2014 characterizing and using these relations in computational systems (Fyodorov et al., 2000; Condoravdi et al., 2003; Bos and Markert, 2005; Dagan et al., 2006; MacCartney and Manning, 2009) \u2014 is essential in tasks ranging from information retrieval to semantic parsing to commonsense reasoning."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 152,
                                "start": 129
                            }
                        ],
                        "text": "Thus, natural language inference (NLI) \u2014 characterizing and using these relations in computational systems (Fyodorov et al., 2000; Condoravdi et al., 2003; Bos and Markert, 2005; Dagan et al., 2006; MacCartney and Manning, 2009) \u2014 is essential in tasks ranging from information retrieval to semantic\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5471801,
            "fieldsOfStudy": [
                "Philosophy"
            ],
            "id": "5ffa3aea748533186b6638d97eafe80d86b208b2",
            "isKey": false,
            "numCitedBy": 90,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "We argue that the detection of entailment and contradiction relations between texts is a minimal metric for the evaluation of text understanding systems. Intensionality, which is widespread in natural language, raises a number of detection issues that cannot be brushed aside. We describe a contexted clausal representation, derived from approaches in formal semantics, that permits an extended range of intensional entailments and contradictions to be tractably detected."
            },
            "slug": "Entailment,-intensionality-and-text-understanding-Condoravdi-Crouch",
            "title": {
                "fragments": [],
                "text": "Entailment, intensionality and text understanding"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A contexted clausal representation is described, derived from approaches in formal semantics, that permits an extended range of intensional entailments and contradictions to be tractably detected."
            },
            "venue": {
                "fragments": [],
                "text": "HLT-NAACL 2003"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1699245"
                        ],
                        "name": "T. Winograd",
                        "slug": "T.-Winograd",
                        "structuredName": {
                            "firstName": "Terry",
                            "lastName": "Winograd",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Winograd"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 102,
                                "start": 70
                            }
                        ],
                        "text": "Some of these examples have qualities reminiscent of Winograd schemas (Winograd, 1972; Levesque, 2013)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 56798209,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bb20f121c979b535bbeade5ac06676d627d4ad7d",
            "isKey": false,
            "numCitedBy": 2455,
            "numCiting": 46,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract This paper describes a computer system for understanding English. The system answers questions, executes commands, and accepts information in an interactive English dialog. It is based on the belief that in modeling language understanding, we must deal in an integrated way with all of the aspects of language\u2014syntax, semantics, and inference. The system contains a parser, a recognition grammar of English, programs for semantic analysis, and a general problem solving system. We assume that a computer cannot deal reasonably with language unless it can understand the subject it is discussing. Therefore, the program is given a detailed model of a particular domain. In addition, the system has a simple model of its own mentality. It can remember and discuss its plans and actions as well as carrying them out. It enters into a dialog with a person, responding to English sentences with actions and English replies, asking for clarification when its heuristic programs cannot understand a sentence through the use of syntactic, semantic, contextual, and physical knowledge. Knowledge in the system is represented in the form of procedures, rather than tables of rules or lists of patterns. By developing special procedural representations for syntax, semantics, and inference, we gain flexibility and power. Since each piece of knowledge can be a procedure, it can call directly on any other piece of knowledge in the system."
            },
            "slug": "Understanding-natural-language-Winograd",
            "title": {
                "fragments": [],
                "text": "Understanding natural language"
            },
            "tldr": {
                "abstractSimilarityScore": 71,
                "text": "A computer system for understanding English that contains a parser, a recognition grammar of English, programs for semantic analysis, and a general problem solving system based on the belief that in modeling language understanding, it must deal in an integrated way with all of the aspects of language\u2014syntax, semantics, and inference."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1972
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38666915"
                        ],
                        "name": "D. Klein",
                        "slug": "D.-Klein",
                        "structuredName": {
                            "firstName": "Dan",
                            "lastName": "Klein",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Klein"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144783904"
                        ],
                        "name": "Christopher D. Manning",
                        "slug": "Christopher-D.-Manning",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Manning",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christopher D. Manning"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 27,
                                "start": 2
                            }
                        ],
                        "text": "2 (Klein and Manning, 2003), trained on the standard training set as well as on the Brown Corpus (Francis and Kucera 1979), which we found to improve the parse quality of the descriptive sentences and noun phrases found in the descriptions."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 11495042,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a600850ac0120cb09a0b7de7da80bb6a7a76de06",
            "isKey": false,
            "numCitedBy": 3370,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "We demonstrate that an unlexicalized PCFG can parse much more accurately than previously shown, by making use of simple, linguistically motivated state splits, which break down false independence assumptions latent in a vanilla treebank grammar. Indeed, its performance of 86.36% (LP/LR F1) is better than that of early lexicalized PCFG models, and surprisingly close to the current state-of-the-art. This result has potential uses beyond establishing a strong lower bound on the maximum possible accuracy of unlexicalized models: an unlexicalized PCFG is much more compact, easier to replicate, and easier to interpret than more complex lexical models, and the parsing algorithms are simpler, more widely understood, of lower asymptotic complexity, and easier to optimize."
            },
            "slug": "Accurate-Unlexicalized-Parsing-Klein-Manning",
            "title": {
                "fragments": [],
                "text": "Accurate Unlexicalized Parsing"
            },
            "tldr": {
                "abstractSimilarityScore": 98,
                "text": "It is demonstrated that an unlexicalized PCFG can parse much more accurately than previously shown, by making use of simple, linguistically motivated state splits, which break down false independence assumptions latent in a vanilla treebank grammar."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1997146"
                        ],
                        "name": "Yaroslav Fyodorov",
                        "slug": "Yaroslav-Fyodorov",
                        "structuredName": {
                            "firstName": "Yaroslav",
                            "lastName": "Fyodorov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yaroslav Fyodorov"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2104936402"
                        ],
                        "name": "YoadWinter NissimFrancez",
                        "slug": "YoadWinter-NissimFrancez",
                        "structuredName": {
                            "firstName": "YoadWinter",
                            "lastName": "NissimFrancez",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "YoadWinter NissimFrancez"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 228,
                                "start": 107
                            }
                        ],
                        "text": "Thus, natural language inference (NLI) \u2014 characterizing and using these relations in computational systems (Fyodorov et al., 2000; Condoravdi et al., 2003; Bos and Markert, 2005; Dagan et al., 2006; MacCartney and Manning, 2009) \u2014 is essential in tasks ranging from information retrieval to semantic parsing to commonsense reasoning."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 127,
                                "start": 106
                            }
                        ],
                        "text": "Thus, natural language inference (NLI) \u2014 characterizing and using these relations in computational systems (Fyodorov et al., 2000; Condoravdi et al., 2003; Bos and Markert, 2005; Dagan et al., 2006; MacCartney and Manning, 2009) \u2014 is essential in tasks ranging from information retrieval to semantic\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 18306353,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "51a3f127ce3047295d9967ccff19fd006ebc8841",
            "isKey": false,
            "numCitedBy": 22,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper develops a version of Natural Logic \u2013 an inference system that works directly on natural language syntactic representations, with no int ermediate translation to logical formulae. Following work by S\u00e1nchez (1991), we develop a small fragment t ha computes semantic order relations between derivation trees in Categorial Grammar. Unlike pre vious works, the proposed system has the following new characteristics: (i) It uses orderings betwe en derivation trees as purely syntactic units, derivable by a formal calculus. (ii) The system is extended f or conjunctive phenomena like coordination and relative clauses. This allows a simple account of non -m otonic expressions that are reducible to conjunctions of monotonic ones. (iii) A preliminary proof s earch algorithm based on a tree generating regular system is developed for S\u00e1nchez\u2019 smaller fragment of Natural Logic."
            },
            "slug": "A-Natural-Logic-Inference-System-Fyodorov-NissimFrancez",
            "title": {
                "fragments": [],
                "text": "A Natural Logic Inference System"
            },
            "tldr": {
                "abstractSimilarityScore": 86,
                "text": "A version of Natural Logic \u2013 an inference system that works directly on natural language syntactic representations, with no immediate translation to logical formulae is developed."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143845796"
                        ],
                        "name": "Jeffrey Pennington",
                        "slug": "Jeffrey-Pennington",
                        "structuredName": {
                            "firstName": "Jeffrey",
                            "lastName": "Pennington",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jeffrey Pennington"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2166511"
                        ],
                        "name": "R. Socher",
                        "slug": "R.-Socher",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Socher",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Socher"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144783904"
                        ],
                        "name": "Christopher D. Manning",
                        "slug": "Christopher-D.-Manning",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Manning",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christopher D. Manning"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1957433,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f37e1b62a767a307c046404ca96bc140b3e68cb5",
            "isKey": false,
            "numCitedBy": 22536,
            "numCiting": 40,
            "paperAbstract": {
                "fragments": [],
                "text": "Recent methods for learning vector space representations of words have succeeded in capturing fine-grained semantic and syntactic regularities using vector arithmetic, but the origin of these regularities has remained opaque. We analyze and make explicit the model properties needed for such regularities to emerge in word vectors. The result is a new global logbilinear regression model that combines the advantages of the two major model families in the literature: global matrix factorization and local context window methods. Our model efficiently leverages statistical information by training only on the nonzero elements in a word-word cooccurrence matrix, rather than on the entire sparse matrix or on individual context windows in a large corpus. The model produces a vector space with meaningful substructure, as evidenced by its performance of 75% on a recent word analogy task. It also outperforms related models on similarity tasks and named entity recognition."
            },
            "slug": "GloVe:-Global-Vectors-for-Word-Representation-Pennington-Socher",
            "title": {
                "fragments": [],
                "text": "GloVe: Global Vectors for Word Representation"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "A new global logbilinear regression model that combines the advantages of the two major model families in the literature: global matrix factorization and local context window methods and produces a vector space with meaningful substructure."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144096985"
                        ],
                        "name": "G. Miller",
                        "slug": "G.-Miller",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Miller",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Miller"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1671874,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "68c03788224000794d5491ab459be0b2a2c38677",
            "isKey": false,
            "numCitedBy": 13888,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "Because meaningful sentences are composed of meaningful words, any system that hopes to process natural languages as people do must have information about words and their meanings. This information is traditionally provided through dictionaries, and machine-readable dictionaries are now widely available. But dictionary entries evolved for the convenience of human readers, not for machines. WordNet1 provides a more effective combination of traditional lexicographic information and modern computing. WordNet is an online lexical database designed for use under program control. English nouns, verbs, adjectives, and adverbs are organized into sets of synonyms, each representing a lexicalized concept. Semantic relations link the synonym sets [4]."
            },
            "slug": "WordNet:-A-Lexical-Database-for-English-Miller",
            "title": {
                "fragments": [],
                "text": "WordNet: A Lexical Database for English"
            },
            "tldr": {
                "abstractSimilarityScore": 36,
                "text": "WordNet1 provides a more effective combination of traditional lexicographic information and modern computing, and is an online lexical database designed for use under program control."
            },
            "venue": {
                "fragments": [],
                "text": "HLT"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2949185"
                        ],
                        "name": "Ellie Pavlick",
                        "slug": "Ellie-Pavlick",
                        "structuredName": {
                            "firstName": "Ellie",
                            "lastName": "Pavlick",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ellie Pavlick"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2294125"
                        ],
                        "name": "Pushpendre Rastogi",
                        "slug": "Pushpendre-Rastogi",
                        "structuredName": {
                            "firstName": "Pushpendre",
                            "lastName": "Rastogi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Pushpendre Rastogi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2267212"
                        ],
                        "name": "Juri Ganitkevitch",
                        "slug": "Juri-Ganitkevitch",
                        "structuredName": {
                            "firstName": "Juri",
                            "lastName": "Ganitkevitch",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Juri Ganitkevitch"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7536576"
                        ],
                        "name": "Benjamin Van Durme",
                        "slug": "Benjamin-Van-Durme",
                        "structuredName": {
                            "firstName": "Benjamin",
                            "lastName": "Durme",
                            "middleNames": [
                                "Van"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Benjamin Van Durme"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1763608"
                        ],
                        "name": "Chris Callison-Burch",
                        "slug": "Chris-Callison-Burch",
                        "structuredName": {
                            "firstName": "Chris",
                            "lastName": "Callison-Burch",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chris Callison-Burch"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 239,
                                "start": 220
                            }
                        ],
                        "text": "Outside the domain of sentence-level entailment, Levy et al. (2014) introduce a large corpus of semi-automatically annotated entailment examples between subject\u2013verb\u2013 object relation triples, and the second release of the Paraphrase Database (Pavlick et al., 2015) includes automatically generated entailment annotations over a large corpus of pairs of words and short phrases."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 184,
                                "start": 164
                            }
                        ],
                        "text": "\u2026a large corpus of semi-automatically annotated entailment examples between subject\u2013verb\u2013 object relation triples, and the second release of the Paraphrase Database (Pavlick et al., 2015) includes automatically generated entailment annotations over a large corpus of pairs of words and short phrases."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 9711750,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a47a0b0859547f327760d27bf8ce09c6e6f21fa2",
            "isKey": false,
            "numCitedBy": 269,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a new release of the Paraphrase Database. PPDB 2.0 includes a discriminatively re-ranked set of paraphrases that achieve a higher correlation with human judgments than PPDB 1.0\u2019s heuristic rankings. Each paraphrase pair in the database now also includes finegrained entailment relations, word embedding similarities, and style annotations."
            },
            "slug": "PPDB-2.0:-Better-paraphrase-ranking,-fine-grained-Pavlick-Rastogi",
            "title": {
                "fragments": [],
                "text": "PPDB 2.0: Better paraphrase ranking, fine-grained entailment relations, word embeddings, and style classification"
            },
            "tldr": {
                "abstractSimilarityScore": 67,
                "text": "PPDB 2.0 includes a discriminatively re-ranked set of paraphrases that achieve a higher correlation with human judgments than PPDB 1.0's heuristic rankings."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7465342"
                        ],
                        "name": "Ido Dagan",
                        "slug": "Ido-Dagan",
                        "structuredName": {
                            "firstName": "Ido",
                            "lastName": "Dagan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ido Dagan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2807469"
                        ],
                        "name": "Oren Glickman",
                        "slug": "Oren-Glickman",
                        "structuredName": {
                            "firstName": "Oren",
                            "lastName": "Glickman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Oren Glickman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712352"
                        ],
                        "name": "B. Magnini",
                        "slug": "B.-Magnini",
                        "structuredName": {
                            "firstName": "Bernardo",
                            "lastName": "Magnini",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Magnini"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 228,
                                "start": 107
                            }
                        ],
                        "text": "Thus, natural language inference (NLI) \u2014 characterizing and using these relations in computational systems (Fyodorov et al., 2000; Condoravdi et al., 2003; Bos and Markert, 2005; Dagan et al., 2006; MacCartney and Manning, 2009) \u2014 is essential in tasks ranging from information retrieval to semantic parsing to commonsense reasoning."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 163,
                                "start": 145
                            }
                        ],
                        "text": "\u2026(NLI) \u2014 characterizing and using these relations in computational systems (Fyodorov et al., 2000; Condoravdi et al., 2003; Bos and Markert, 2005; Dagan et al., 2006; MacCartney and Manning, 2009) \u2014 is essential in tasks ranging from information retrieval to semantic parsing to commonsense\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 8587959,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "de794d50713ea5f91a7c9da3d72041e2f5ef8452",
            "isKey": false,
            "numCitedBy": 1762,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents the Third PASCAL Recognising Textual Entailment Challenge (RTE-3), providing an overview of the dataset creating methodology and the submitted systems. In creating this year's dataset, a number of longer texts were introduced to make the challenge more oriented to realistic scenarios. Additionally, a pool of resources was offered so that the participants could share common tools. A pilot task was also set up, aimed at differentiating unknown entailments from identified contradictions and providing justifications for overall system decisions. 26 participants submitted 44 runs, using different approaches and generally presenting new entailment models and achieving higher scores than in the previous challenges."
            },
            "slug": "The-PASCAL-Recognising-Textual-Entailment-Challenge-Dagan-Glickman",
            "title": {
                "fragments": [],
                "text": "The PASCAL Recognising Textual Entailment Challenge"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "This paper presents the Third PASCAL Recognising Textual Entailment Challenge (RTE-3), providing an overview of the dataset creating methodology and the submitted systems."
            },
            "venue": {
                "fragments": [],
                "text": "MLCW"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2218418"
                        ],
                        "name": "Timothy Chklovski",
                        "slug": "Timothy-Chklovski",
                        "structuredName": {
                            "firstName": "Timothy",
                            "lastName": "Chklovski",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Timothy Chklovski"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1990190"
                        ],
                        "name": "P. Pantel",
                        "slug": "P.-Pantel",
                        "structuredName": {
                            "firstName": "Patrick",
                            "lastName": "Pantel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Pantel"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 166,
                                "start": 157
                            }
                        ],
                        "text": "In addition to the base classifier-based system distributed with the platform, we train a variant which includes information from WordNet (Miller, 1995) and VerbOcean (Chklovski and Pantel, 2004), and makes use of features based on tree patterns and dependency tree skeletons (Wang and Neumann, 2007)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "We also thank our many excellent Mechanical Turk contributors."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 192,
                                "start": 166
                            }
                        ],
                        "text": "\u2026addition to the base classifier-based system distributed with the platform, we train a variant which includes information from WordNet (Miller, 1995) and VerbOcean (Chklovski and Pantel, 2004), and makes use of features based on tree patterns and dependency tree skeletons (Wang and Neumann, 2007)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 13507979,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0c739b915d633cc3c162e4ef1e57b796c2dc2217",
            "isKey": false,
            "numCitedBy": 497,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "Broad-coverage repositories of semantic relations between verbs could benefit many NLP tasks. We present a semi-automatic method for extracting fine-grained semantic relations between verbs. We detect similarity, strength, antonymy, enablement, and temporal happens-before relations between pairs of strongly associated verbs using lexicosyntactic patterns over the Web. On a set of 29,165 strongly associated verb pairs, our extraction algorithm yielded 65.5% accuracy. Analysis of error types shows that on the relation strength we achieved 75% accuracy. We provide the resource, called VERBOCEAN, for download at http://semantics.isi.edu/ocean/."
            },
            "slug": "VerbOcean:-Mining-the-Web-for-Fine-Grained-Semantic-Chklovski-Pantel",
            "title": {
                "fragments": [],
                "text": "VerbOcean: Mining the Web for Fine-Grained Semantic Verb Relations"
            },
            "tldr": {
                "abstractSimilarityScore": 61,
                "text": "A semi-automatic method for extracting fine-grained semantic relations between verbs using lexicosyntactic patterns over the Web, which detects similarity, strength, antonymy, enablement, and temporal happens-before relations between pairs of strongly associated verbs."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2052690705"
                        ],
                        "name": "Peter Young",
                        "slug": "Peter-Young",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Young",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Peter Young"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2068187980"
                        ],
                        "name": "Alice Lai",
                        "slug": "Alice-Lai",
                        "structuredName": {
                            "firstName": "Alice",
                            "lastName": "Lai",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alice Lai"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2170746"
                        ],
                        "name": "M. Hodosh",
                        "slug": "M.-Hodosh",
                        "structuredName": {
                            "firstName": "Micah",
                            "lastName": "Hodosh",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Hodosh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3118681"
                        ],
                        "name": "J. Hockenmaier",
                        "slug": "J.-Hockenmaier",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Hockenmaier",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Hockenmaier"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 55,
                                "start": 37
                            }
                        ],
                        "text": "The Denotation Graph entailment set (Young et al., 2014) contains millions of examples of entailments between sentences and artificially constructed short phrases, but it was labeled using fully automatic methods, and is noisy enough that it is probably suitable only as a source of\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 56,
                                "start": 36
                            }
                        ],
                        "text": "The Denotation Graph entailment set (Young et al., 2014) contains millions of examples of entailments between sentences and artificially constructed short phrases, but it was labeled using fully automatic methods, and is noisy enough that it is probably suitable only as a source of sup-"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 80,
                                "start": 62
                            }
                        ],
                        "text": "For the premises, we used captions from the Flickr30k corpus (Young et al., 2014), a collection of approximately 160k captions (corresponding to about 30k images) collected in an earlier crowdsourced effort.3 The captions were not authored by the photographers who took the source images, and they\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 81,
                                "start": 61
                            }
                        ],
                        "text": "For the premises, we used captions from the Flickr30k corpus (Young et al., 2014), a collection of approximately 160k captions (corresponding to about 30k images) collected in an earlier crowdsourced effort."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 3104920,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "44040913380206991b1991daf1192942e038fe31",
            "isKey": true,
            "numCitedBy": 1323,
            "numCiting": 40,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose to use the visual denotations of linguistic expressions (i.e. the set of images they describe) to define novel denotational similarity metrics, which we show to be at least as beneficial as distributional similarities for two tasks that require semantic inference. To compute these denotational similarities, we construct a denotation graph, i.e. a subsumption hierarchy over constituents and their denotations, based on a large corpus of 30K images and 150K descriptive captions."
            },
            "slug": "From-image-descriptions-to-visual-denotations:-New-Young-Lai",
            "title": {
                "fragments": [],
                "text": "From image descriptions to visual denotations: New similarity metrics for semantic inference over event descriptions"
            },
            "tldr": {
                "abstractSimilarityScore": 86,
                "text": "This work proposes to use the visual denotations of linguistic expressions to define novel denotational similarity metrics, which are shown to be at least as beneficial as distributional similarities for two tasks that require semantic inference."
            },
            "venue": {
                "fragments": [],
                "text": "TACL"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8729431"
                        ],
                        "name": "Sida I. Wang",
                        "slug": "Sida-I.-Wang",
                        "structuredName": {
                            "firstName": "Sida",
                            "lastName": "Wang",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sida I. Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144783904"
                        ],
                        "name": "Christopher D. Manning",
                        "slug": "Christopher-D.-Manning",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Manning",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christopher D. Manning"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 217537,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "dc0975ae518a5b30e60fde23a41c74bafd7c6f8c",
            "isKey": false,
            "numCitedBy": 1090,
            "numCiting": 49,
            "paperAbstract": {
                "fragments": [],
                "text": "Variants of Naive Bayes (NB) and Support Vector Machines (SVM) are often used as baseline methods for text classification, but their performance varies greatly depending on the model variant, features used and task/dataset. We show that: (i) the inclusion of word bigram features gives consistent gains on sentiment analysis tasks; (ii) for short snippet sentiment tasks, NB actually does better than SVMs (while for longer documents the opposite result holds); (iii) a simple but novel SVM variant using NB log-count ratios as feature values consistently performs well across tasks and datasets. Based on these observations, we identify simple NB and SVM variants which outperform most published results on sentiment analysis datasets, sometimes providing a new state-of-the-art performance level."
            },
            "slug": "Baselines-and-Bigrams:-Simple,-Good-Sentiment-and-Wang-Manning",
            "title": {
                "fragments": [],
                "text": "Baselines and Bigrams: Simple, Good Sentiment and Topic Classification"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "It is shown that the inclusion of word bigram features gives consistent gains on sentiment analysis tasks, and a simple but novel SVM variant using NB log-count ratios as feature values consistently performs well across tasks and datasets."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3308557"
                        ],
                        "name": "S. Hochreiter",
                        "slug": "S.-Hochreiter",
                        "structuredName": {
                            "firstName": "Sepp",
                            "lastName": "Hochreiter",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Hochreiter"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145341374"
                        ],
                        "name": "J. Schmidhuber",
                        "slug": "J.-Schmidhuber",
                        "structuredName": {
                            "firstName": "J\u00fcrgen",
                            "lastName": "Schmidhuber",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Schmidhuber"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 59,
                                "start": 56
                            }
                        ],
                        "text": "To perform transfer, we take the parameters of the LSTM RNN model trained on SNLI and use them to initialize a new model, which is trained from that point only on the training portion of SICK."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 14,
                                "start": 11
                            }
                        ],
                        "text": "Of the two RNN models, the LSTM\u2019s more robust ability to learn long-term dependencies serves it well, giving it a substantial advantage over the plain RNN, and resulting in performance that is essentially equivalent to the lexicalized classifier on the test set (LSTM performance near the stopping iteration varies by up to 0.5% between evaluation steps)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 132,
                                "start": 98
                            }
                        ],
                        "text": "In addition, we experiment with two simple sequence embedding models: a plain RNN and an LSTM RNN (Hochreiter and Schmidhuber, 1997)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1915014,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "44d2abe2175df8153f465f6c39b68b76a0d40ab9",
            "isKey": true,
            "numCitedBy": 51694,
            "numCiting": 68,
            "paperAbstract": {
                "fragments": [],
                "text": "Learning to store information over extended time intervals by recurrent backpropagation takes a very long time, mostly because of insufficient, decaying error backflow. We briefly review Hochreiter's (1991) analysis of this problem, then address it by introducing a novel, efficient, gradient based method called long short-term memory (LSTM). Truncating the gradient where this does not do harm, LSTM can learn to bridge minimal time lags in excess of 1000 discrete-time steps by enforcing constant error flow through constant error carousels within special units. Multiplicative gate units learn to open and close access to the constant error flow. LSTM is local in space and time; its computational complexity per time step and weight is O. 1. Our experiments with artificial data involve local, distributed, real-valued, and noisy pattern representations. In comparisons with real-time recurrent learning, back propagation through time, recurrent cascade correlation, Elman nets, and neural sequence chunking, LSTM leads to many more successful runs, and learns much faster. LSTM also solves complex, artificial long-time-lag tasks that have never been solved by previous recurrent network algorithms."
            },
            "slug": "Long-Short-Term-Memory-Hochreiter-Schmidhuber",
            "title": {
                "fragments": [],
                "text": "Long Short-Term Memory"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "A novel, efficient, gradient based method called long short-term memory (LSTM) is introduced, which can learn to bridge minimal time lags in excess of 1000 discrete-time steps by enforcing constant error flow through constant error carousels within special units."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2897313"
                        ],
                        "name": "Nitish Srivastava",
                        "slug": "Nitish-Srivastava",
                        "structuredName": {
                            "firstName": "Nitish",
                            "lastName": "Srivastava",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nitish Srivastava"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2064160"
                        ],
                        "name": "A. Krizhevsky",
                        "slug": "A.-Krizhevsky",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Krizhevsky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Krizhevsky"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1701686"
                        ],
                        "name": "Ilya Sutskever",
                        "slug": "Ilya-Sutskever",
                        "structuredName": {
                            "firstName": "Ilya",
                            "lastName": "Sutskever",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ilya Sutskever"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145124475"
                        ],
                        "name": "R. Salakhutdinov",
                        "slug": "R.-Salakhutdinov",
                        "structuredName": {
                            "firstName": "Ruslan",
                            "lastName": "Salakhutdinov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Salakhutdinov"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6844431,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "34f25a8704614163c4095b3ee2fc969b60de4698",
            "isKey": false,
            "numCitedBy": 28149,
            "numCiting": 43,
            "paperAbstract": {
                "fragments": [],
                "text": "Deep neural nets with a large number of parameters are very powerful machine learning systems. However, overfitting is a serious problem in such networks. Large networks are also slow to use, making it difficult to deal with overfitting by combining the predictions of many different large neural nets at test time. Dropout is a technique for addressing this problem. The key idea is to randomly drop units (along with their connections) from the neural network during training. This prevents units from co-adapting too much. During training, dropout samples from an exponential number of different \"thinned\" networks. At test time, it is easy to approximate the effect of averaging the predictions of all these thinned networks by simply using a single unthinned network that has smaller weights. This significantly reduces overfitting and gives major improvements over other regularization methods. We show that dropout improves the performance of neural networks on supervised learning tasks in vision, speech recognition, document classification and computational biology, obtaining state-of-the-art results on many benchmark data sets."
            },
            "slug": "Dropout:-a-simple-way-to-prevent-neural-networks-Srivastava-Hinton",
            "title": {
                "fragments": [],
                "text": "Dropout: a simple way to prevent neural networks from overfitting"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "It is shown that dropout improves the performance of neural networks on supervised learning tasks in vision, speech recognition, document classification and computational biology, obtaining state-of-the-art results on many benchmark data sets."
            },
            "venue": {
                "fragments": [],
                "text": "J. Mach. Learn. Res."
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712352"
                        ],
                        "name": "B. Magnini",
                        "slug": "B.-Magnini",
                        "structuredName": {
                            "firstName": "Bernardo",
                            "lastName": "Magnini",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Magnini"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "36024018"
                        ],
                        "name": "Roberto Zanoli",
                        "slug": "Roberto-Zanoli",
                        "structuredName": {
                            "firstName": "Roberto",
                            "lastName": "Zanoli",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Roberto Zanoli"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7465342"
                        ],
                        "name": "Ido Dagan",
                        "slug": "Ido-Dagan",
                        "structuredName": {
                            "firstName": "Ido",
                            "lastName": "Dagan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ido Dagan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153183474"
                        ],
                        "name": "K. Eichler",
                        "slug": "K.-Eichler",
                        "structuredName": {
                            "firstName": "Kathrin",
                            "lastName": "Eichler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Eichler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143792905"
                        ],
                        "name": "G. Neumann",
                        "slug": "G.-Neumann",
                        "structuredName": {
                            "firstName": "G\u00fcnter",
                            "lastName": "Neumann",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Neumann"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3104237"
                        ],
                        "name": "Tae-Gil Noh",
                        "slug": "Tae-Gil-Noh",
                        "structuredName": {
                            "firstName": "Tae-Gil",
                            "lastName": "Noh",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tae-Gil Noh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1708581"
                        ],
                        "name": "Sebastian Pad\u00f3",
                        "slug": "Sebastian-Pad\u00f3",
                        "structuredName": {
                            "firstName": "Sebastian",
                            "lastName": "Pad\u00f3",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sebastian Pad\u00f3"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32590708"
                        ],
                        "name": "Asher Stern",
                        "slug": "Asher-Stern",
                        "structuredName": {
                            "firstName": "Asher",
                            "lastName": "Stern",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Asher Stern"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39455775"
                        ],
                        "name": "Omer Levy",
                        "slug": "Omer-Levy",
                        "structuredName": {
                            "firstName": "Omer",
                            "lastName": "Levy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Omer Levy"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 167,
                                "start": 143
                            }
                        ],
                        "text": "In this section, we explore the performance of three classes of models which could scale readily: (i) models from a well-known NLI system, the Excitement Open Platform; (ii) variants of a strong but simple feature-based classifier model, which makes use of both unlexicalized and lexicalized features, and (iii) distributed representation models, including a baseline model and neural network sequence models."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 107,
                                "start": 63
                            }
                        ],
                        "text": "The first class of models is from the Excitement Open Platform (EOP, Pad\u00f3 et al. 2014; Magnini et al. 2014)\u2014an open source platform for RTE research."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 106,
                                "start": 87
                            }
                        ],
                        "text": "The first class of models is from the Excitement Open Platform (EOP, Pado\u0301 et al. 2014; Magnini et al. 2014)\u2014an open source platform for RTE research."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 17708014,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a53815cf0c9cbb54a23b11f73c7d532910afa750",
            "isKey": false,
            "numCitedBy": 68,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents the Excitement Open Platform (EOP), a generic architecture and a comprehensive implementation for textual inference in multiple languages. The platform includes state-of-art algorithms, a large number of knowledge resources, and facilities for experimenting and testing innovative approaches. The EOP is distributed as an open source software."
            },
            "slug": "The-Excitement-Open-Platform-for-Textual-Inferences-Magnini-Zanoli",
            "title": {
                "fragments": [],
                "text": "The Excitement Open Platform for Textual Inferences"
            },
            "tldr": {
                "abstractSimilarityScore": 88,
                "text": "The Excitement Open Platform is presented, a generic architecture and a comprehensive implementation for textual inference in multiple languages and includes state-of-art algorithms, a large number of knowledge resources, and facilities for experimenting and testing innovative approaches."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143634377"
                        ],
                        "name": "H. Levesque",
                        "slug": "H.-Levesque",
                        "structuredName": {
                            "firstName": "Hector",
                            "lastName": "Levesque",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Levesque"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 102,
                                "start": 70
                            }
                        ],
                        "text": "Some of these examples have qualities reminiscent of Winograd schemas (Winograd, 1972; Levesque, 2013)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 12325453,
            "fieldsOfStudy": [
                "Psychology",
                "Art"
            ],
            "id": "6d334cb557f5addd3fc080134483125eea0b7a90",
            "isKey": false,
            "numCitedBy": 83,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "On-our-best-behaviour-Levesque",
            "title": {
                "fragments": [],
                "text": "On our best behaviour"
            },
            "venue": {
                "fragments": [],
                "text": "Artif. Intell."
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2068187980"
                        ],
                        "name": "Alice Lai",
                        "slug": "Alice-Lai",
                        "structuredName": {
                            "firstName": "Alice",
                            "lastName": "Lai",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alice Lai"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3118681"
                        ],
                        "name": "J. Hockenmaier",
                        "slug": "J.-Hockenmaier",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Hockenmaier",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Hockenmaier"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 30,
                                "start": 3
                            }
                        ],
                        "text": "6% (Lai and Hockenmaier, 2014) and the 84% level of interannotator agreement, which likely represents an approximate performance ceiling."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 10421567,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f529dc492b7f3d1b22db64bc7ad36b1f13641a84",
            "isKey": false,
            "numCitedBy": 123,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes and analyzes our SemEval 2014 Task 1 system. Its features are based on distributional and denotational similarities; word alignment; negation; and hypernym/hyponym, synonym, and antonym relations."
            },
            "slug": "Illinois-LH:-A-Denotational-and-Distributional-to-Lai-Hockenmaier",
            "title": {
                "fragments": [],
                "text": "Illinois-LH: A Denotational and Distributional Approach to Semantics"
            },
            "tldr": {
                "abstractSimilarityScore": 97,
                "text": "This paper describes and analyzes the SemEval 2014 Task 1 system, which features are based on distributional and denotational similarities; word alignment; negation; and hypernym/hyponym, synonym, and antonym relations."
            },
            "venue": {
                "fragments": [],
                "text": "*SEMEVAL"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48799969"
                        ],
                        "name": "Matthew D. Zeiler",
                        "slug": "Matthew-D.-Zeiler",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Zeiler",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Matthew D. Zeiler"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 67,
                                "start": 59
                            }
                        ],
                        "text": "We additionally transfer the accumulators that are used by AdaDelta to set the learning rates."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 109,
                                "start": 97
                            }
                        ],
                        "text": "All of the models are randomly initialized using standard techniques and trained using AdaDelta (Zeiler, 2012) minibatch SGD until performance on the development set stops improving."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 7365802,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8729441d734782c3ed532a7d2d9611b438c0a09a",
            "isKey": false,
            "numCitedBy": 5464,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a novel per-dimension learning rate method for gradient descent called ADADELTA. The method dynamically adapts over time using only first order information and has minimal computational overhead beyond vanilla stochastic gradient descent. The method requires no manual tuning of a learning rate and appears robust to noisy gradient information, different model architecture choices, various data modalities and selection of hyperparameters. We show promising results compared to other methods on the MNIST digit classification task using a single machine and on a large scale voice dataset in a distributed cluster environment."
            },
            "slug": "ADADELTA:-An-Adaptive-Learning-Rate-Method-Zeiler",
            "title": {
                "fragments": [],
                "text": "ADADELTA: An Adaptive Learning Rate Method"
            },
            "tldr": {
                "abstractSimilarityScore": 93,
                "text": "A novel per-dimension learning rate method for gradient descent called ADADELTA that dynamically adapts over time using only first order information and has minimal computational overhead beyond vanilla stochastic gradient descent is presented."
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "98232539"
                        ],
                        "name": "J. Benthem",
                        "slug": "J.-Benthem",
                        "structuredName": {
                            "firstName": "Johan",
                            "lastName": "Benthem",
                            "middleNames": [
                                "van"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Benthem"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 139,
                                "start": 122
                            }
                        ],
                        "text": "The semantic concepts of entailment and contradiction are central to all aspects of natural language meaning (Katz, 1972; van Benthem, 2008), from the lexicon to the content of entire texts."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 73103894,
            "fieldsOfStudy": [
                "Philosophy"
            ],
            "id": "24b391a74ec61209b86a9c4ad37387f9ca261f12",
            "isKey": false,
            "numCitedBy": 62,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper is a brief history of natural logic at the interface of logic, linguistics, and nowadays also other disciplines. It merely summarizes some facts that deserve to be common knowledge."
            },
            "slug": "A-brief-history-of-natural-logic-Benthem",
            "title": {
                "fragments": [],
                "text": "A brief history of natural logic"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145085576"
                        ],
                        "name": "G. Ward",
                        "slug": "G.-Ward",
                        "structuredName": {
                            "firstName": "Gregory",
                            "lastName": "Ward",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Ward"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2001455"
                        ],
                        "name": "B. Birner",
                        "slug": "B.-Birner",
                        "structuredName": {
                            "firstName": "Betty",
                            "lastName": "Birner",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Birner"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 245,
                                "start": 222
                            }
                        ],
                        "text": "For the most part, the original image prompts contained a focal element that the caption writer identified with a syntactic subject, following information structuring conventions associating subjects and topics in English (Ward and Birner, 2004)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 157,
                                "start": 150
                            }
                        ],
                        "text": "To the extent that successfully training a neural network model like our LSTM on SNLI forces that model to encode broadly accurate representations of English scene descriptions and to build an entailment classifier over those relations, we should expect it to be readily possible to adapt the trained model for use on other NLI tasks."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 92,
                                "start": 85
                            }
                        ],
                        "text": "We also find the sentences that we collected to be largely\nfluent, correctly spelled English, with a mix of full sentences and caption-style noun phrase fragments, though punctuation and capitalization are often omitted."
                    },
                    "intents": []
                }
            ],
            "corpusId": 61039193,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "d5b4fbd5d2d6e3083d8fa20b113261a2fc9817f2",
            "isKey": true,
            "numCitedBy": 81,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Information-Structure-and-Non\u2010canonical-Syntax-Ward-Birner",
            "title": {
                "fragments": [],
                "text": "Information Structure and Non\u2010canonical Syntax"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2380885"
                        ],
                        "name": "Danilo Giampiccolo",
                        "slug": "Danilo-Giampiccolo",
                        "structuredName": {
                            "firstName": "Danilo",
                            "lastName": "Giampiccolo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Danilo Giampiccolo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712352"
                        ],
                        "name": "B. Magnini",
                        "slug": "B.-Magnini",
                        "structuredName": {
                            "firstName": "Bernardo",
                            "lastName": "Magnini",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Magnini"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7465342"
                        ],
                        "name": "Ido Dagan",
                        "slug": "Ido-Dagan",
                        "structuredName": {
                            "firstName": "Ido",
                            "lastName": "Dagan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ido Dagan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "83415753"
                        ],
                        "name": "W. Dolan",
                        "slug": "W.-Dolan",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Dolan",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Dolan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 195352006,
            "fieldsOfStudy": [
                "Philosophy"
            ],
            "id": "b2815bc4c9e4260227cd7ca0c9d68d41c4c2f58b",
            "isKey": false,
            "numCitedBy": 474,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "The-Third-PASCAL-Recognizing-Textual-Entailment-Giampiccolo-Magnini",
            "title": {
                "fragments": [],
                "text": "The Third PASCAL Recognizing Textual Entailment Challenge"
            },
            "venue": {
                "fragments": [],
                "text": "ACL-PASCAL@ACL"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3177568"
                        ],
                        "name": "J. Q. Candela",
                        "slug": "J.-Q.-Candela",
                        "structuredName": {
                            "firstName": "Joaquin",
                            "lastName": "Candela",
                            "middleNames": [
                                "Qui\u00f1onero"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Q. Candela"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "69440470"
                        ],
                        "name": "Magnini B Dagan I",
                        "slug": "Magnini-B-Dagan-I",
                        "structuredName": {
                            "firstName": "Magnini",
                            "lastName": "Dagan I",
                            "middleNames": [
                                "B"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Magnini B Dagan I"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "11393449"
                        ],
                        "name": "F. Lauria",
                        "slug": "F.-Lauria",
                        "structuredName": {
                            "firstName": "Francesco",
                            "lastName": "Lauria",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Lauria"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 8564414,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e03d300581e16f6664157d2c1c6ceec33ec528ce",
            "isKey": false,
            "numCitedBy": 209,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Machine-Learning-Challenges.-Evaluating-Predictive-Candela-MagniniBDagan",
            "title": {
                "fragments": [],
                "text": "Machine Learning Challenges. Evaluating Predictive Uncertainty, Visual Object Classification, and Recognising Tectual Entailment"
            },
            "venue": {
                "fragments": [],
                "text": "Lecture Notes in Computer Science"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144442133"
                        ],
                        "name": "L. Pratt",
                        "slug": "L.-Pratt",
                        "structuredName": {
                            "firstName": "Lorien",
                            "lastName": "Pratt",
                            "middleNames": [
                                "Y."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Pratt"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695106"
                        ],
                        "name": "Jack Mostow",
                        "slug": "Jack-Mostow",
                        "structuredName": {
                            "firstName": "Jack",
                            "lastName": "Mostow",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jack Mostow"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1769629"
                        ],
                        "name": "C. Kamm",
                        "slug": "C.-Kamm",
                        "structuredName": {
                            "firstName": "Candace",
                            "lastName": "Kamm",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Kamm"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 30657075,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "052f4d936ceaccbce8d7a3ad2449fb7d7676eb0c",
            "isKey": false,
            "numCitedBy": 180,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "A touted advantage of symbolic representations is the ease of transferring learned information from one intelligent agent to another. This paper investigates an analogous problem: how to use information from one neural network to help a second network learn a related task. Rather than translate such information into symbolic form (in which it may not be readily expressible), we investigate the direct transfer of information encoded as weights. \n \nHere, we focus on how transfer can be used to address the important problem of improving neural network learning speed. First we present an exploratory study of the somewhat surprising effects of pre-setting network weights on subsequent learning. Guided by hypotheses from this study, we sped up back-propagation learning for two speech recognition tasks. By transferring weights from smaller networks trained on subtasks, we achieved speedups of up to an order of magnitude compared with training starting with random weights, even taking into account the time to train the smaller networks. We include results on how transfer scales to a large phoneme recognition problem."
            },
            "slug": "Direct-Transfer-of-Learned-Information-Among-Neural-Pratt-Mostow",
            "title": {
                "fragments": [],
                "text": "Direct Transfer of Learned Information Among Neural Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "By transferring weights from smaller networks trained on subtasks, this paper achieved speedups of up to an order of magnitude compared with training starting with random weights, even taking into account the time to train the smaller networks."
            },
            "venue": {
                "fragments": [],
                "text": "AAAI"
            },
            "year": 1991
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 140,
                                "start": 109
                            }
                        ],
                        "text": "The semantic concepts of entailment and contradiction are central to all aspects of natural language meaning (Katz, 1972; van Benthem, 2008), from the lexicon to the content of entire texts."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Semantic Theory"
            },
            "venue": {
                "fragments": [],
                "text": "Harper & Row, New York."
            },
            "year": 1972
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 163,
                                "start": 145
                            }
                        ],
                        "text": "\u2026(NLI) \u2014 characterizing and using these relations in computational systems (Fyodorov et al., 2000; Condoravdi et al., 2003; Bos and Markert, 2005; Dagan et al., 2006; MacCartney and Manning, 2009) \u2014 is essential in tasks ranging from information retrieval to semantic parsing to commonsense\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "tailment , intensionality and text understanding"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2006
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Ben Van Durme, and Chris Callison-Burch. 2015. PPDB 2.0: Better paraphrase ranking, finegrained entailment relations, word embeddings, and style classification"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. ACL"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Brown corpus manual"
            },
            "venue": {
                "fragments": [],
                "text": "Brown University."
            },
            "year": 1979
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 21,
            "methodology": 9
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 38,
        "totalPages": 4
    },
    "page_url": "https://www.semanticscholar.org/paper/A-large-annotated-corpus-for-learning-natural-Bowman-Angeli/f04df4e20a18358ea2f689b4c129781628ef7fc1?sort=total-citations"
}