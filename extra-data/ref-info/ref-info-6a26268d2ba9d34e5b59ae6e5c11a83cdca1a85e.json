{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145602732"
                        ],
                        "name": "Kobus Barnard",
                        "slug": "Kobus-Barnard",
                        "structuredName": {
                            "firstName": "Kobus",
                            "lastName": "Barnard",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kobus Barnard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2446509"
                        ],
                        "name": "P. D. Sahin",
                        "slug": "P.-D.-Sahin",
                        "structuredName": {
                            "firstName": "Pinar",
                            "lastName": "Sahin",
                            "middleNames": [
                                "Duygulu"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. D. Sahin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144016256"
                        ],
                        "name": "D. Forsyth",
                        "slug": "D.-Forsyth",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Forsyth",
                            "middleNames": [
                                "Alexander"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Forsyth"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 85,
                                "start": 64
                            }
                        ],
                        "text": "This observation led to the alternative model\u2014first described in Barnard et al. (2001)\u2014which is generative."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 91,
                                "start": 70
                            }
                        ],
                        "text": "These include whether the image is a photograph or a sketch and notably the output of a face finder."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 31,
                                "start": 10
                            }
                        ],
                        "text": "Following Barnard et al. (2001) and Barnard and Forsyth (2001), we also experiment with allowing a cluster dependent level structure."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 125,
                                "start": 104
                            }
                        ],
                        "text": "Fitting a probability model with an appropriate structure yields quite useful clusters, as described in Barnard et al. (2001)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 109,
                                "start": 89
                            }
                        ],
                        "text": "Auto-illustration is possible if one can obtain images with high probability given text (Barnard et al., 2001, Barnard and Forsyth, 2001)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 64,
                                "start": 43
                            }
                        ],
                        "text": "Examples of automated annotation appear in Barnard et al. (2001), Barnard and Forsyth (2001) and below."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 86544,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "df70db146b07ce173476be3877a5a3ae3ca06aa5",
            "isKey": false,
            "numCitedBy": 185,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "We extend a recently developed method (K. Barnard and D. Forsyth, 2001) for learning the semantics of image databases using text and pictures. We incorporate statistical natural language processing in order to deal with free text. We demonstrate the current system on a difficult dataset, namely 10000 images of work from the Fine Arts Museum of San Francisco. The images include line drawings, paintings, and pictures of sculpture and ceramics. Many of the images have associated free text which varies greatly from physical description to interpretation and mood. We use WordNet to provide semantic grouping information and to help disambiguate word senses, as well as emphasize the hierarchical nature of semantic relationships. This allows us to impose a natural structure on the image collection that reflects semantics to a considerable degree. Our method produces a joint probability distribution for words and picture elements. We demonstrate that this distribution can be used: (a) to provide illustrations for given captions, and (b) to generate words for images outside the training set. Results from this annotation process yield a quantitative study of our method. Finally, the annotation process can be seen as a form of object recognizer that has been learned through a partially supervised process."
            },
            "slug": "Clustering-art-Barnard-Sahin",
            "title": {
                "fragments": [],
                "text": "Clustering art"
            },
            "tldr": {
                "abstractSimilarityScore": 60,
                "text": "This work extends a recently developed method for learning the semantics of image databases using text and pictures and uses WordNet to provide semantic grouping information and to help disambiguate word senses, as well as emphasize the hierarchical nature of semantic relationships."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 2001 IEEE Computer Society Conference on Computer Vision and Pattern Recognition. CVPR 2001"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2446509"
                        ],
                        "name": "P. D. Sahin",
                        "slug": "P.-D.-Sahin",
                        "structuredName": {
                            "firstName": "Pinar",
                            "lastName": "Sahin",
                            "middleNames": [
                                "Duygulu"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. D. Sahin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145602732"
                        ],
                        "name": "Kobus Barnard",
                        "slug": "Kobus-Barnard",
                        "structuredName": {
                            "firstName": "Kobus",
                            "lastName": "Barnard",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kobus Barnard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2059257793"
                        ],
                        "name": "Jo\u00e3o Freitas",
                        "slug": "Jo\u00e3o-Freitas",
                        "structuredName": {
                            "firstName": "Jo\u00e3o",
                            "lastName": "Freitas",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jo\u00e3o Freitas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144016256"
                        ],
                        "name": "D. Forsyth",
                        "slug": "D.-Forsyth",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Forsyth",
                            "middleNames": [
                                "Alexander"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Forsyth"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 12561212,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6d9f55b445f36578802e7eef4393cfa914b11620",
            "isKey": false,
            "numCitedBy": 1765,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a model of object recognition as machine translation. In this model, recognition is a process of annotating image regions with words. Firstly, images are segmented into regions, which are classified into region types using a variety of features. A mapping between region types and keywords supplied with the images, is then learned, using a method based around EM. This process is analogous with learning a lexicon from an aligned bitext. For the implementation we describe, these words are nouns taken from a large vocabulary. On a large test set, the method can predict numerous words with high accuracy. Simple methods identify words that cannot be predicted well. We show how to cluster words that individually are difficult to predict into clusters that can be predicted well -- for example, we cannot predict the distinction between train and locomotive using the current set of features, but we can predict the underlying concept. The method is trained on a substantial collection of images. Extensive experimental results illustrate the strengths and weaknesses of the approach."
            },
            "slug": "Object-Recognition-as-Machine-Translation:-Learning-Sahin-Barnard",
            "title": {
                "fragments": [],
                "text": "Object Recognition as Machine Translation: Learning a Lexicon for a Fixed Image Vocabulary"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This work shows how to cluster words that individually are difficult to predict into clusters that can be predicted well, and cannot predict the distinction between train and locomotive using the current set of features, but can predict the underlying concept."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2116063254"
                        ],
                        "name": "Francine Chen",
                        "slug": "Francine-Chen",
                        "structuredName": {
                            "firstName": "Francine",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Francine Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2124754"
                        ],
                        "name": "U. Gargi",
                        "slug": "U.-Gargi",
                        "structuredName": {
                            "firstName": "Ullas",
                            "lastName": "Gargi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "U. Gargi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2120460"
                        ],
                        "name": "L. Niles",
                        "slug": "L.-Niles",
                        "structuredName": {
                            "firstName": "Les",
                            "lastName": "Niles",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Niles"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144418438"
                        ],
                        "name": "Hinrich Sch\u00fctze",
                        "slug": "Hinrich-Sch\u00fctze",
                        "structuredName": {
                            "firstName": "Hinrich",
                            "lastName": "Sch\u00fctze",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hinrich Sch\u00fctze"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Others have also experimented with using image features as part of a query refinement process ( Chen et al., 1999;  Chen et al., 2000)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 118,
                                "start": 95
                            }
                        ],
                        "text": "Others have also experimented with using image features as part of a query refinement process (Chen et al., 1999, 2000)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 21239830,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "845336ed2e69fab0999593bf024c896dff1a3305",
            "isKey": false,
            "numCitedBy": 17,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we describe a system for performing browsing and retrieval on a collection of web images and associated text on an HTML page. Browsing is combined with retrieval to help a user locate interesting portions of the corpus, without the need to formulate a query well matched to the corpus. Multi-modal information, in the form of text surrounding an image and some simple image features, is used in this process. Using the system, a user progressively narrows a collection to a small number of elements of interest, similar to the Scatter/Gather system developed for text browsing. We have extended the Scatter/Gather method to use multi-modal features. With the use of multiple features, some collection elements may have unknown or undefined values for some features; we present a method for incorporating these elements into the result set. This method also provides a way to handle the case when a search is narrowed to a part of the space near a boundary between two clusters. A number of examples illustrating our system are provided."
            },
            "slug": "Multimodal-browsing-of-images-in-Web-documents-Chen-Gargi",
            "title": {
                "fragments": [],
                "text": "Multimodal browsing of images in Web documents"
            },
            "tldr": {
                "abstractSimilarityScore": 67,
                "text": "A system for performing browsing and retrieval on a collection of web images and associated text on an HTML page, extended to use multi-modal features, and presents a method for incorporating these elements into the result set."
            },
            "venue": {
                "fragments": [],
                "text": "Electronic Imaging"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145602732"
                        ],
                        "name": "Kobus Barnard",
                        "slug": "Kobus-Barnard",
                        "structuredName": {
                            "firstName": "Kobus",
                            "lastName": "Barnard",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kobus Barnard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144016256"
                        ],
                        "name": "D. Forsyth",
                        "slug": "D.-Forsyth",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Forsyth",
                            "middleNames": [
                                "Alexander"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Forsyth"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 92,
                                "start": 66
                            }
                        ],
                        "text": "Examples of automated annotation appear in Barnard et al. (2001), Barnard and Forsyth (2001) and below."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 136,
                                "start": 111
                            }
                        ],
                        "text": "Auto-illustration is possible if one can obtain images with high probability given text (Barnard et al., 2001, Barnard and Forsyth, 2001)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 62,
                                "start": 36
                            }
                        ],
                        "text": "Following Barnard et al. (2001) and Barnard and Forsyth (2001), we also experiment with allowing a cluster dependent level structure."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 13121800,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4e36d141e2964817c3d926c380793e404a3a3367",
            "isKey": false,
            "numCitedBy": 615,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a statistical model for organizing image collections which integrates semantic information provided by associate text and visual information provided by image features. The model is very promising for information retrieval tasks such as database browsing and searching for images based on text and/or image features. Furthermore, since the model learns relationships between text and image features, it can be used for novel applications such as associating words with pictures, and unsupervised learning for object recognition."
            },
            "slug": "Learning-the-semantics-of-words-and-pictures-Barnard-Forsyth",
            "title": {
                "fragments": [],
                "text": "Learning the semantics of words and pictures"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The model is very promising for information retrieval tasks such as database browsing and searching for images based on text and/or image features, and can be used for novel applications such as associating words with pictures, and unsupervised learning for object recognition."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings Eighth IEEE International Conference on Computer Vision. ICCV 2001"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2969789"
                        ],
                        "name": "C. Carson",
                        "slug": "C.-Carson",
                        "structuredName": {
                            "firstName": "Chad",
                            "lastName": "Carson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Carson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50172592"
                        ],
                        "name": "Serge J. Belongie",
                        "slug": "Serge-J.-Belongie",
                        "structuredName": {
                            "firstName": "Serge",
                            "lastName": "Belongie",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Serge J. Belongie"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143942875"
                        ],
                        "name": "H. Greenspan",
                        "slug": "H.-Greenspan",
                        "structuredName": {
                            "firstName": "Hayit",
                            "lastName": "Greenspan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Greenspan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143751119"
                        ],
                        "name": "Jitendra Malik",
                        "slug": "Jitendra-Malik",
                        "structuredName": {
                            "firstName": "Jitendra",
                            "lastName": "Malik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jitendra Malik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 148,
                                "start": 127
                            }
                        ],
                        "text": "We have yet to experiment with tempering the training as suggested in (Hofmann and Puzicha, 1998) or stochastic versions of EM (Celeux et al., 1995)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 153,
                                "start": 134
                            }
                        ],
                        "text": "We have yet to experiment either with tempering the training as suggested in Hofmann and Puzicha (1998) or stochastic versions of EM (Celeux et al., 1995)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14715074,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fedf7729b620ec2cf4e79705d2898f82e9a2ba66",
            "isKey": false,
            "numCitedBy": 1629,
            "numCiting": 111,
            "paperAbstract": {
                "fragments": [],
                "text": "Retrieving images from large and varied collections using image content as a key is a challenging and important problem. We present a new image representation that provides a transformation from the raw pixel data to a small set of image regions that are coherent in color and texture. This \"Blobworld\" representation is created by clustering pixels in a joint color-texture-position feature space. The segmentation algorithm is fully automatic and has been run on a collection of 10,000 natural images. We describe a system that uses the Blobworld representation to retrieve images from this collection. An important aspect of the system is that the user is allowed to view the internal representation of the submitted image and the query results. Similar systems do not offer the user this view into the workings of the system; consequently, query results from these systems can be inexplicable, despite the availability of knobs for adjusting the similarity metrics. By finding image regions that roughly correspond to objects, we allow querying at the level of objects rather than global image properties. We present results indicating that querying for images using Blobworld produces higher precision than does querying using color and texture histograms of the entire image in cases where the image contains distinctive objects."
            },
            "slug": "Blobworld:-Image-Segmentation-Using-and-Its-to-Carson-Belongie",
            "title": {
                "fragments": [],
                "text": "Blobworld: Image Segmentation Using Expectation-Maximization and Its Application to Image Querying"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "Results indicating that querying for images using Blobworld produces higher precision than does querying using color and texture histograms of the entire image in cases where the image contains distinctive objects are presented."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1748081"
                        ],
                        "name": "R. Srihari",
                        "slug": "R.-Srihari",
                        "structuredName": {
                            "firstName": "Rohini",
                            "lastName": "Srihari",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Srihari"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Srihari and others have used text information to disambiguate image features, particularly in face finding applications ( Srihari, 1991;  Srihari and Burhans, 1994; Srihari et al., 1994)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 60622931,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "697c7f995188ef30b8687e4458c2c7fd33163184",
            "isKey": false,
            "numCitedBy": 32,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "There are many situations where linguistic and pictorial data are jointly presented to communicate information. In the general case, each of these two sources conveys orthogonal information. A computer model for integrating information from the two sources requires an initial interpretation of both the text and the picture followed by consolidation of information. The problem of performing general-purpose vision without apriori knowledge (needed in such a situation) is nearly impossible. However, in some situations, the text describes salient aspects of the picture. In such situations, it is possible to extract visual information from the text, resulting in a conceptualised graph describing the structure of the accompanying picture. This graph can then be used by a computer vision system in the top-down interpretation of the picture. \nIn this dissertation, a computational model for understanding pictures based on information in accompanying captions is presented. The use of SNePS (Semantic Network Processing System) as the common intermediate representation for both linguistic and pictorial information is discussed. Specifically, we present the knowledge representations and interpretations that comprise the model. \nThe focus of this dissertation is on the generation of a conceptualised graph, a SNePS network which reflects a cognitive agent's conceptualisation of a picture based on information contained in a descriptive caption. This representation includes information about objects appearing in the picture and spatial constraints between them, information used in the subsequent task of labelling objects in the picture. A substantial portion of the dissertation is devoted to techniques of extracting such visual information from text. The techniques are based on both syntactic and semantic considerations. We classify linguistic methods of identifying objects in pictures into several broad categories and, for each category, discuss the manner in which visual information can be extracted. The problem of dynamically generating model descriptions for objects (and for entire pictures) is illustrated. A theoretical solution to this problem is presented and illustrated through an example. \nAs a test of the model, we present an implementation, PICTION, whereby information obtained from parsing a caption of a newspaper photograph is used to identify human faces in the photograph. A key component of the system is the utilisation of spatial constraints in order to reduce the number of possible labels that could be associated with a face. These constraints are generated by a natural-language processing system that examines the caption in detail. We report on the extensive testing of the system and discuss the results obtained. The method of evaluating the performance of PICTION can be used by any face-identification system."
            },
            "slug": "Extracting-visual-information-from-text:-using-to-Srihari",
            "title": {
                "fragments": [],
                "text": "Extracting visual information from text: using captions to label faces in newspaper photographs"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A computational model for understanding pictures based on information in accompanying captions, PICTION, whereby information obtained from parsing a caption of a newspaper photograph is used to identify human faces in the photograph."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2333082"
                        ],
                        "name": "Y. Mori",
                        "slug": "Y.-Mori",
                        "structuredName": {
                            "firstName": "Yasuhide",
                            "lastName": "Mori",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Mori"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2079483"
                        ],
                        "name": "Hironobu Takahashi",
                        "slug": "Hironobu-Takahashi",
                        "structuredName": {
                            "firstName": "Hironobu",
                            "lastName": "Takahashi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hironobu Takahashi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1776022"
                        ],
                        "name": "R. Oka",
                        "slug": "R.-Oka",
                        "structuredName": {
                            "firstName": "Ryu-ichi",
                            "lastName": "Oka",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Oka"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 102,
                                "start": 84
                            }
                        ],
                        "text": "Finally, perhaps closest to our work on predicting words for regions is the work of Mori et al. (1999), where co-occurrence statistics are collected for words and image areas defined by a fixed grid."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 19,
                                "start": 0
                            }
                        ],
                        "text": "(Mori et al., 1999), where co-occurrence statistics are collected for words and image areas defined by a fixed grid."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 18574318,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8b29ffb4207435540ddecf4b14a8a32106b33830",
            "isKey": false,
            "numCitedBy": 448,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a method to make a relationship between images and words. We adopt two processes in the method, one is a process to uniformly divide each image into sub-images with key words, and the other is a process to carry out vector quantization of the sub-images. These processes lead to results which show that each sub-image can be correlated to a set of words each of which is selected from words assigned to whole images. Original aspects of the method are, (1) all words assigned to a whole image are inherited to each divided sub-image, (2) the voting probability of each word for a set of divided images is estimated by the result of a vector quantization of the feature vector of sub-images. Some experiments show the e ectiveness of the proposed method."
            },
            "slug": "Image-to-word-transformation-based-on-dividing-Mori-Takahashi",
            "title": {
                "fragments": [],
                "text": "Image-to-word transformation based on dividing"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "All words assigned to a whole image are inherited to each divided sub-image and the voting probability of each word for a set of divided images is estimated by the result of a vector quantization of the feature vector of sub-images."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1748081"
                        ],
                        "name": "R. Srihari",
                        "slug": "R.-Srihari",
                        "structuredName": {
                            "firstName": "Rohini",
                            "lastName": "Srihari",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Srihari"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2011596"
                        ],
                        "name": "D. Burhans",
                        "slug": "D.-Burhans",
                        "structuredName": {
                            "firstName": "Debra",
                            "lastName": "Burhans",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Burhans"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 184,
                                "start": 120
                            }
                        ],
                        "text": "Srihari and others have used text information to disambiguate image features, particularly in face finding applications (Srihari, 1991; Srihari and Burhans, 1994; Srihari et al., 1994)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 183,
                                "start": 158
                            }
                        ],
                        "text": "Srihari and others have used text information to disambiguate image features, particularly in face finding applications (Srihari et al., 1994, Srihari, 1991, Srihari and Burhans, 1994)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1433969,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fabd30916cba34f9711ab9ba18d8868e3df346ae",
            "isKey": false,
            "numCitedBy": 83,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "This research explores the interaction of textual and photographic information in document understanding. The problem of performing general-purpose vision without a priori knowledge is difficult at best. The use of collateral information in scene understanding has been explored in computer vision systems that use scene context in the task of object identification. The work described here extends this notion by defining visual semantics, a theory of systematically extracting picture-specific information from text accompanying a photograph. Specifically, this paper discusses the multi-stage processing of textual captions with the following objectives: (i) predicting which objects (implicitly or explicitly mentioned in the caption) are present in the picture and (ii) generating constraints useful in locating/identifying these objects. The implementation and use of a lexicon specifically designed for the integration of linguistic and visual information is discussed. Finally, the research described here has been successfully incorporated into PICTION, a caption-based face identification system."
            },
            "slug": "Visual-Semantics:-Extracting-Visual-information-Srihari-Burhans",
            "title": {
                "fragments": [],
                "text": "Visual Semantics: Extracting Visual information from Text Accompanying Pictures"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "This paper discusses the multi-stage processing of textual captions with the following objectives: predicting which objects are present in the picture and generating constraints useful in locating/identifying these objects."
            },
            "venue": {
                "fragments": [],
                "text": "AAAI"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1700567"
                        ],
                        "name": "S. Satoh",
                        "slug": "S.-Satoh",
                        "structuredName": {
                            "firstName": "Shin\u2019ichi",
                            "lastName": "Satoh",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Satoh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733113"
                        ],
                        "name": "T. Kanade",
                        "slug": "T.-Kanade",
                        "structuredName": {
                            "firstName": "Takeo",
                            "lastName": "Kanade",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kanade"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 23,
                                "start": 0
                            }
                        ],
                        "text": "Satoh and Kanade (1997) used cooccurrence models for automatically associating faces with names in video."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2304541,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "58942abb806c435d880cc6717eccd4963528dc53",
            "isKey": false,
            "numCitedBy": 152,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper proposes a novel approach to extract meaningful content information from video by collaborative integration of image understanding and natural language processing. As an actual example, we developed a system that associates faces and names in videos, called Name-It, which is given news videos as a knowledge source, then automatically extracts face and name association as content information. The system can infer the name of a given unknown face image, or guess faces which are likely to have the name given to the system. This paper explains the method with several successful matching results which reveal effectiveness in integrating heterogeneous techniques as well as the importance of real content information extraction from video, especially face-name association."
            },
            "slug": "Name-It:-association-of-face-and-name-in-video-Satoh-Kanade",
            "title": {
                "fragments": [],
                "text": "Name-It: association of face and name in video"
            },
            "tldr": {
                "abstractSimilarityScore": 37,
                "text": "A system that associates faces and names in videos, called Name-It, is developed, which is given news videos as a knowledge source, then automatically extracts face and name association as content information."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "114316817"
                        ],
                        "name": "M. La Cascia",
                        "slug": "M.-La-Cascia",
                        "structuredName": {
                            "firstName": "Marco",
                            "lastName": "La Cascia",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. La Cascia"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "120772285"
                        ],
                        "name": "S. Sethi",
                        "slug": "S.-Sethi",
                        "structuredName": {
                            "firstName": "S.",
                            "lastName": "Sethi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Sethi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1749590"
                        ],
                        "name": "S. Sclaroff",
                        "slug": "S.-Sclaroff",
                        "structuredName": {
                            "firstName": "Stan",
                            "lastName": "Sclaroff",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Sclaroff"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 38,
                                "start": 19
                            }
                        ],
                        "text": "These include whether the image is a photograph or a sketch and notably the output of a face finder."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 195,
                                "start": 176
                            }
                        ],
                        "text": "Also see Enser\u2019s work (Armitage and Enser, 1997, Enser, 1993, 1995) on various image archives, which use roughly the same procedure.\ntext and histogram data in the indexing (La Cascia et al., 1998)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6349236,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "78462bcbcd3e8592dc45f41db56e697a2e26209d",
            "isKey": false,
            "numCitedBy": 298,
            "numCiting": 44,
            "paperAbstract": {
                "fragments": [],
                "text": "A system is proposed that combines textual and visual statistics in a single index vector for content-based search of a WWW image database. Textual statistics are captured in vector form using latent semantic indexing (LSI) based on text in the containing HTML document. Visual statistics are captured in vector form using color and orientation histograms. By using an integrated approach, it becomes possible to take advantage of possible statistical couplings between the content of the document (latent semantic content) and the contents of images (visual statistics). The combined approach allows improved performance in conducting content-based search. Search performance experiments are reported for a database containing 100,000 images collected from the WWW."
            },
            "slug": "Combining-textual-and-visual-cues-for-content-based-Cascia-Sethi",
            "title": {
                "fragments": [],
                "text": "Combining textual and visual cues for content-based image retrieval on the World Wide Web"
            },
            "tldr": {
                "abstractSimilarityScore": 81,
                "text": "A system is proposed that combines textual and visual statistics in a single index vector for content- based search of a WWW image database and allows improved performance in conducting content-based search."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings. IEEE Workshop on Content-Based Access of Image and Video Libraries (Cat. No.98EX173)"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2668273"
                        ],
                        "name": "Jau-Yuen Chen",
                        "slug": "Jau-Yuen-Chen",
                        "structuredName": {
                            "firstName": "Jau-Yuen",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jau-Yuen Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1745655"
                        ],
                        "name": "C. Bouman",
                        "slug": "C.-Bouman",
                        "structuredName": {
                            "firstName": "Charles",
                            "lastName": "Bouman",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Bouman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144684111"
                        ],
                        "name": "J. Dalton",
                        "slug": "J.-Dalton",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Dalton",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Dalton"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 118,
                                "start": 95
                            }
                        ],
                        "text": "Others have also experimented with using image features as part of a query refinement process (Chen et al., 1999, 2000)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 5987685,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5617e403c7ce6d88696c13a038041e12b2263ae8",
            "isKey": false,
            "numCitedBy": 168,
            "numCiting": 48,
            "paperAbstract": {
                "fragments": [],
                "text": "The advent of large image databases (>10000) has created a need for tools which can search and organize images automatically by their content. This paper focuses on the use of hierarchical tree-structures to both speed-up search-by-query and organize databases for effective browsing. The first part of this paper develops a fast search algorithm based on best-first branch and bound search. This algorithm is designed so that speed and accuracy may be continuously traded-off through the selection of a parameter lambda. We find that the algorithm is most effective when used to perform an approximate search, where it can typically reduce computation by a factor of 20-40 for accuracies ranging from 80% to 90%. We then present a method for designing a hierarchical browsing environment which we call a similarity pyramid. The similarity pyramid groups similar images together while allowing users to view the database at varying levels of resolution. We show that the similarity pyramid is best constructed using agglomerative (bottom up) clustering methods, and present a fast sparse clustering method which dramatically reduces both memory and computation over conventional methods."
            },
            "slug": "Hierarchical-browsing-and-search-of-large-image-Chen-Bouman",
            "title": {
                "fragments": [],
                "text": "Hierarchical browsing and search of large image databases"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "It is shown that the similarity pyramid is best constructed using agglomerative (bottom up) clustering methods, and a fast sparse clustering method which dramatically reduces both memory and computation over conventional methods is presented."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Image Process."
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144016256"
                        ],
                        "name": "D. Forsyth",
                        "slug": "D.-Forsyth",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Forsyth",
                            "middleNames": [
                                "Alexander"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Forsyth"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 79,
                                "start": 65
                            }
                        ],
                        "text": "The literature is too broad to review here; there are reviews in Forsyth (1999), Forsyth and Ponce (2002)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 58,
                                "start": 45
                            }
                        ],
                        "text": "Typically, images are matched based on features computed from the entire image or from image regions."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 30970545,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bef4b861e087fcf84f6a811714ff2dbe66248610",
            "isKey": false,
            "numCitedBy": 20,
            "numCiting": 60,
            "paperAbstract": {
                "fragments": [],
                "text": "Very large collections of images are now common. Indexing and searching such collections using indexing languages is difficult. Computer vision offers a variety of techniques for searching for pictures in large collections. Appearance methods compare images based on the overall content of the image using such criteria as similarity of color histograms, texture histograms, spatial layout, and filtered representations. Finding methods concentrate on matching subparts of images, defined in a variety of ways, in the hope of finding particular objects. These ideas are illustrated with a variety of examples from the current literature."
            },
            "slug": "Computer-Vision-Tools-for-Finding-Images-and-Video-Forsyth",
            "title": {
                "fragments": [],
                "text": "Computer Vision Tools for Finding Images and Video Sequences"
            },
            "tldr": {
                "abstractSimilarityScore": 50,
                "text": "In this paper, computer vision offers a variety of techniques for searching for pictures in large collections using indexing languages, and finding methods concentrate on matching subparts of images in the hope of finding particular objects."
            },
            "venue": {
                "fragments": [],
                "text": "Libr. Trends"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1735767"
                        ],
                        "name": "Margaret M. Fleck",
                        "slug": "Margaret-M.-Fleck",
                        "structuredName": {
                            "firstName": "Margaret",
                            "lastName": "Fleck",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Margaret M. Fleck"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144016256"
                        ],
                        "name": "D. Forsyth",
                        "slug": "D.-Forsyth",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Forsyth",
                            "middleNames": [
                                "Alexander"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Forsyth"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2428034"
                        ],
                        "name": "C. Bregler",
                        "slug": "C.-Bregler",
                        "structuredName": {
                            "firstName": "Christoph",
                            "lastName": "Bregler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Bregler"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 93,
                                "start": 75
                            }
                        ],
                        "text": "Examples include the Corel data set, most museum image collections (for example, http://www.thinker.org/fam/ thinker.html), the web archive (http://www.archive.org), and most collections of news photographs on the web (which come with captions)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 119,
                                "start": 101
                            }
                        ],
                        "text": "With the exception of systems that can identify faces (Schneiderman and Kanade, 2000), naked people (Fleck et al., 1996), pedestrians (Oren et al., 1997) or cars (Schneiderman and Kanade, 2000), matching is not usually directed toward object semantics."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1979750,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4ccda575c3c3e96bb99522c5a8ab158474a9f2f3",
            "isKey": false,
            "numCitedBy": 552,
            "numCiting": 85,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper demonstrates a content-based retrieval strategy that can tell whether there are naked people present in an image. No manual intervention is required. The approach combines color and texture properties to obtain an effective mask for skin regions. The skin mask is shown to be effective for a wide range of shades and colors of skin. These skin regions are then fed to a specialized grouper, which attempts to group a human figure using geometric constraints on human structure. This approach introduces a new view of object recognition, where an object model is an organized collection of grouping hints obtained from a combination of constraints on geometric properties such as the structure of individual parts, and the relationships between parts, and constraints on color and texture. The system is demonstrated to have 60% precision and 52% recall on a test set of 138 uncontrolled images of naked people, mostly obtained from the internet, and 1401 assorted control images, drawn from a wide collection of sources."
            },
            "slug": "Finding-Naked-People-Fleck-Forsyth",
            "title": {
                "fragments": [],
                "text": "Finding Naked People"
            },
            "tldr": {
                "abstractSimilarityScore": 67,
                "text": "A content-based retrieval strategy that can tell whether there are naked people present in an image and an effective mask for skin regions is demonstrated, which introduces a new view of object recognition."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46865129"
                        ],
                        "name": "Jianbo Shi",
                        "slug": "Jianbo-Shi",
                        "structuredName": {
                            "firstName": "Jianbo",
                            "lastName": "Shi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jianbo Shi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153652147"
                        ],
                        "name": "J. Malik",
                        "slug": "J.-Malik",
                        "structuredName": {
                            "firstName": "Jitendra",
                            "lastName": "Malik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Malik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14848918,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b94c7ff9532ab26c3aedbee3988ec4c7a237c173",
            "isKey": false,
            "numCitedBy": 12809,
            "numCiting": 55,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a novel approach for solving the perceptual grouping problem in vision. Rather than focusing on local features and their consistencies in the image data, our approach aims at extracting the global impression of an image. We treat image segmentation as a graph partitioning problem and propose a novel global criterion, the normalized cut, for segmenting the graph. The normalized cut criterion measures both the total dissimilarity between the different groups as well as the total similarity within the groups. We show that an efficient computational technique based on a generalized eigenvalue problem can be used to optimize this criterion. We have applied this approach to segmenting static images and found results very encouraging."
            },
            "slug": "Normalized-cuts-and-image-segmentation-Shi-Malik",
            "title": {
                "fragments": [],
                "text": "Normalized cuts and image segmentation"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This work treats image segmentation as a graph partitioning problem and proposes a novel global criterion, the normalized cut, for segmenting the graph, which measures both the total dissimilarity between the different groups as well as the total similarity within the groups."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3174044"
                        ],
                        "name": "L. H. Armitage",
                        "slug": "L.-H.-Armitage",
                        "structuredName": {
                            "firstName": "Linda",
                            "lastName": "Armitage",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. H. Armitage"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2137152"
                        ],
                        "name": "P. Enser",
                        "slug": "P.-Enser",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Enser",
                            "middleNames": [
                                "G.",
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Enser"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 45350741,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "316440b3a78715902ebdf9a433867143c70f1b85",
            "isKey": false,
            "numCitedBy": 279,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes a project in which an analysis was undertaken of user queries addressed to seven libraries which manage archives of widely varying still and moving image material. The sampling procedure is described, in which queries obtained from each library were broadly categorised by image content, identification and accessibility. Attention is focused on the image content requests, for which a categorisation based on facet analysis is developed. The analytical tool which is used for this purpose is based on a schema already well established for the analysis of levels of meaning in images. The project demonstrates the possibility of formulating a general categorisation of requests which seek widely different still and moving image material. The paper concludes with observations on the potential value of embedding such a schema within the user interface of unmediated-query visual information retrieval systems."
            },
            "slug": "Analysis-of-user-need-in-image-archives-Armitage-Enser",
            "title": {
                "fragments": [],
                "text": "Analysis of user need in image archives"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "The project demonstrates the possibility of formulating a general categorisation of requests which seek widely different still and moving image material, and the potential value of embedding such a schema within the user interface of unmediated-query visual information retrieval systems."
            },
            "venue": {
                "fragments": [],
                "text": "J. Inf. Sci."
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1796335"
                        ],
                        "name": "D. Blei",
                        "slug": "D.-Blei",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Blei",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Blei"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694621"
                        ],
                        "name": "Michael I. Jordan",
                        "slug": "Michael-I.-Jordan",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Jordan",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael I. Jordan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 49,
                                "start": 27
                            }
                        ],
                        "text": "This issue is described in Blei and Jordan (2002), where the authors derive a LDA-based model of annotated data that is based onpartial exchangeability."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 52,
                                "start": 35
                            }
                        ],
                        "text": "In this approach, image regions are modeled as in the independent model, but the words are not emitted conditioned on the regions."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 207561477,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "473f4b7f8ae2b03dda2593f54b316ff7d55db26b",
            "isKey": false,
            "numCitedBy": 1214,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "We consider the problem of modeling annotated data---data with multiple types where the instance of one type (such as a caption) serves as a description of the other type (such as an image). We describe three hierarchical probabilistic mixture models which aim to describe such data, culminating in correspondence latent Dirichlet allocation, a latent variable model that is effective at modeling the joint distribution of both types and the conditional distribution of the annotation given the primary type. We conduct experiments on the Corel database of images and captions, assessing performance in terms of held-out likelihood, automatic annotation, and text-based image retrieval."
            },
            "slug": "Modeling-annotated-data-Blei-Jordan",
            "title": {
                "fragments": [],
                "text": "Modeling annotated data"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "Three hierarchical probabilistic mixture models which aim to describe annotated data with multiple types, culminating in correspondence latent Dirichlet allocation, a latent variable model that is effective at modeling the joint distribution of both types and the conditional distribution of the annotation given the primary type."
            },
            "venue": {
                "fragments": [],
                "text": "SIGIR"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39955311"
                        ],
                        "name": "M. Markkula",
                        "slug": "M.-Markkula",
                        "structuredName": {
                            "firstName": "Marjo",
                            "lastName": "Markkula",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Markkula"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1991333"
                        ],
                        "name": "Eero Sormunen",
                        "slug": "Eero-Sormunen",
                        "structuredName": {
                            "firstName": "Eero",
                            "lastName": "Sormunen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Eero Sormunen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 75,
                                "start": 47
                            }
                        ],
                        "text": "A typical workflow is described by the work of Markkula and Sormunen (2000), who studied the image archive of a Finnish newspaper.1 A chivists receive pictures and annotate them with words that are likely to be useful keys for retrieving the pictures; journalists then search the collection using\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "\u2022 and that text associated with images is extremely useful in practice\u2014for example, newspaper archivists index largely on captions (Markkula and Sormunen, 2000)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 289,
                                "start": 262
                            }
                        ],
                        "text": "\u2026by what is visible in the picture);\n\u2022 that queries based on image histograms, texture, overall appearance, etc. are vanishingly uncommon;\n\u2022 and that text associated with images is extremely useful in practice\u2014for example, newspaper archivists index largely on captions (Markkula and Sormunen, 2000)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 155,
                                "start": 127
                            }
                        ],
                        "text": "Other user studies include the work of Ornager (1996), who studied practice at a manually operated newspaper photo archive and Markkula and Sormunen (2000), who study practice at a Finnish newspaper\u2019s digital photo archive."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 382080,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d17e528324506eb7dd99a2ed70a9c62119cb2efa",
            "isKey": true,
            "numCitedBy": 212,
            "numCiting": 68,
            "paperAbstract": {
                "fragments": [],
                "text": "Previous research in conceptual indexing methods of images has furnished us with refined theoretical frameworks characterising various aspects of images that could and should be indexed using textual descriptors. The development of digital image processing technologies has bred a brigade of content-based indexing and retrieval methods available for applications. What the users need and in what kinds of environments different indexing and retrieval methods are relevant, has remained an area of less intensive research work.This article presents the results of a field study concentrating on journalists as users of a digital newspaper photo archive. The expressed photo needs, applied selection criteria and observed searching behaviours in journalists' daily work were contrasted with the indexing practices applied by the archivists. The results showed that the journalists achieved satisfactory results when trivial query terms were available, e.g. when photos of named persons were needed. Browsing was the main searching strategy applied by the journalists, but the system did not support browsing well. The access problems faced by the users in particular photo needs are discussed in detail. The paper concludes by discussing the potential approaches in developing both the concept-based and content-based indexing methods as well as the user interfaces in photo retrieval systems."
            },
            "slug": "End-User-Searching-Challenges-Indexing-Practices-in-Markkula-Sormunen",
            "title": {
                "fragments": [],
                "text": "End-User Searching Challenges Indexing Practices in the Digital Newspaper Photo Archive"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The paper concludes by discussing the potential approaches in developing both the concept-based and content-based indexing methods as well as the user interfaces in photo retrieval systems."
            },
            "venue": {
                "fragments": [],
                "text": "Information Retrieval"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143936663"
                        ],
                        "name": "Thomas Hofmann",
                        "slug": "Thomas-Hofmann",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Hofmann",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thomas Hofmann"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2121009"
                        ],
                        "name": "J. Puzicha",
                        "slug": "J.-Puzicha",
                        "structuredName": {
                            "firstName": "Jan",
                            "lastName": "Puzicha",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Puzicha"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 124,
                                "start": 99
                            }
                        ],
                        "text": "Our first model is a multi-modal extension of Hofmann\u2019s hierarchical model for text (Hofmann, 1998, Hofmann and Puzicha, 1998)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Preliminary experiments indicated that there was generally a slight benefit for doing so. We have yet to experiment with tempering the training as suggested in ( Hofmann and Puzicha, 1998 ) or stochastic versions of EM (Celeux et al., 1995) ."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 103,
                                "start": 77
                            }
                        ],
                        "text": "We have yet to experiment either with tempering the training as suggested in Hofmann and Puzicha (1998) or stochastic versions of EM (Celeux et al., 1995)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 105,
                                "start": 79
                            }
                        ],
                        "text": "For model I-0, we estimate the vertical mixing weights for each document as in Hofmann and Puzicha (1998)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Our first model is a multi-modal extension of Hofmann\u2019s hierarchical model for text (Hofmann, 1998;  Hofmann and Puzicha, 1998 ) . This model combines the aspect model with a soft clustering model."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 76,
                                "start": 50
                            }
                        ],
                        "text": "The update equations are very similar to those in Hofmann and Puzicha (1998), except of course, the probability expressions now include parts both for word and region occurrences."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2696305,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4ec00abf9ff66d6f16378978faf907b047834cbb",
            "isKey": true,
            "numCitedBy": 183,
            "numCiting": 96,
            "paperAbstract": {
                "fragments": [],
                "text": "Modeling and predicting co-occurrences of events is a fundamental problem of unsupervised learning. In this contribution we develop a statistical framework for analyzing co-occurrence data in a general setting where elementary observations are joint occurrences of pairs of abstract objects from two finite sets. The main challenge for statistical models in this context is to overcome the inherent data sparseness and to estimate the probabilities for pairs which were rarely observed or even unobserved in a given sample set. Moreover, it is often of considerable interest to extract grouping structure or to find a hierarchical data organization. A novel family of mixture models is proposed which explain the observed data by a finite number of shared aspects or clusters. This provides a common framework for statistical inference and structure discovery and also includes several recently proposed models as special cases. Adopting the maximum likelihood principle, EM algorithms are derived to fit the model parameters. We develop improved versions of EM which largely avoid overfitting problems and overcome the inherent locality of EM--based optimization. Among the broad variety of possible applications, e.g., in information retrieval, natural language processing, data mining, and computer vision, we have chosen document retrieval, the statistical analysis of noun/adjective co-occurrence and the unsupervised segmentation of textured images to test and evaluate the proposed algorithms."
            },
            "slug": "Statistical-Models-for-Co-occurrence-Data-Hofmann-Puzicha",
            "title": {
                "fragments": [],
                "text": "Statistical Models for Co-occurrence Data"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "A statistical framework for analyzing co-occurrence data in a general setting where elementary observations are joint occurrences of pairs of abstract objects from two finite sets is developed and a novel family of mixture models is proposed."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144016256"
                        ],
                        "name": "D. Forsyth",
                        "slug": "D.-Forsyth",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Forsyth",
                            "middleNames": [
                                "Alexander"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Forsyth"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144189388"
                        ],
                        "name": "J. Ponce",
                        "slug": "J.-Ponce",
                        "structuredName": {
                            "firstName": "Jean",
                            "lastName": "Ponce",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Ponce"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 105,
                                "start": 81
                            }
                        ],
                        "text": "The literature is too broad to review here; there are reviews in Forsyth (1999), Forsyth and Ponce (2002)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 73,
                                "start": 49
                            }
                        ],
                        "text": "A detailed review of these strategies appears in Forsyth and Ponce (2002)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 53924538,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "787827850b614135f6b432603afc90b58a8cc665",
            "isKey": false,
            "numCitedBy": 4098,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "From the Publisher: \nThe accessible presentation of this book gives both a general view of the entire computer vision enterprise and also offers sufficient detail to be able to build useful applications. Users learn techniques that have proven to be useful by first-hand experience and a wide range of mathematical methods. A CD-ROM with every copy of the text contains source code for programming practice, color images, and illustrative movies. Comprehensive and up-to-date, this book includes essential topics that either reflect practical significance or are of theoretical importance. Topics are discussed in substantial and increasing depth. Application surveys describe numerous important application areas such as image based rendering and digital libraries. Many important algorithms broken down and illustrated in pseudo code. Appropriate for use by engineers as a comprehensive reference to the computer vision enterprise."
            },
            "slug": "Computer-Vision:-A-Modern-Approach-Forsyth-Ponce",
            "title": {
                "fragments": [],
                "text": "Computer Vision: A Modern Approach"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "Comprehensive and up-to-date, this book includes essential topics that either reflect practical significance or are of theoretical importance and describes numerous important application areas such as image based rendering and digital libraries."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3331580"
                        ],
                        "name": "O. Maron",
                        "slug": "O.-Maron",
                        "structuredName": {
                            "firstName": "Oded",
                            "lastName": "Maron",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Maron"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "In ( Maron, 1998;  Maron and Ratan, 1998), Maron et al. study automatic annotation of images, but work one word at a time, and offer no method of finding the correspondence between words and regions."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 173,
                                "start": 161
                            }
                        ],
                        "text": "\u2026labeled bags of examples\u2014an image is \u201cpositive\u201d if it contains a tiger somewhere amongst all the other stuff and \u201cnegative\u201d if it doesn\u2019t. Maron and Ratan (1998) and Maron (1998) used multiple-instance learning to train classifiers to identify particular keywords from image data using such bags."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14107141,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "30918b62bb8fe863bb145625655c892ce0525d68",
            "isKey": false,
            "numCitedBy": 160,
            "numCiting": 75,
            "paperAbstract": {
                "fragments": [],
                "text": "There are many learning problems for which the examples given by the teacher are ambiguously labeled. In this thesis, we will examine one framework of learning from ambiguous examples known as Multiple-Instance learning. Each example is a bag, consisting of any number of instances. A bag is labeled negative if all instances in it are negative. A bag is labeled positive if at least one instance in it is positive. Because the instances themselves are not labeled, each positive bag is an ambiguous example. We would like to learn a concept which will correctly classify unseen bags. \nWe have developed a measure called Diverse Density and algorithms for learning from multiple-instance examples. We have applied these techniques to problems in drug design, stock prediction, and image database retrieval. These serve as examples of how to translate the ambiguity in the application domain into bags, as well as successful examples of applying Diverse Density techniques. (Copies available exclusively from MIT Libraries, Rm. 14-0551, Cambridge, MA 02139-4307. Ph. 617-253-5668; Fax 617-253-1690.)"
            },
            "slug": "Learning-from-Ambiguity-Maron",
            "title": {
                "fragments": [],
                "text": "Learning from Ambiguity"
            },
            "tldr": {
                "abstractSimilarityScore": 54,
                "text": "This thesis will examine one framework of learning from ambiguous examples known as Multiple-Instance learning, which has developed a measure called Diverse Density and algorithms for learning from multiple-instance examples and applied these techniques to problems in drug design, stock prediction, and image database retrieval."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32538203"
                        ],
                        "name": "P. Brown",
                        "slug": "P.-Brown",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Brown",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Brown"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2714577"
                        ],
                        "name": "S. D. Pietra",
                        "slug": "S.-D.-Pietra",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Pietra",
                            "middleNames": [
                                "Della"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. D. Pietra"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39944066"
                        ],
                        "name": "V. D. Pietra",
                        "slug": "V.-D.-Pietra",
                        "structuredName": {
                            "firstName": "Vincent",
                            "lastName": "Pietra",
                            "middleNames": [
                                "J.",
                                "Della"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. D. Pietra"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2474650"
                        ],
                        "name": "R. Mercer",
                        "slug": "R.-Mercer",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Mercer",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Mercer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 186,
                                "start": 168
                            }
                        ],
                        "text": "Assuming an unknown one-one correspondence between words, coming up with a joint probability distribution linking words in the two languages is a missing data problem (Brown et al., 1993)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 259,
                                "start": 241
                            }
                        ],
                        "text": "This is a traditional solution in the machine translation literature; the tendency of single words in some languages to generate more than one word in others (a property referred to as \u201cfertility\u201d) can be modeled explicitly in this framework (Brown et al., 1993, Melamed, 2001)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 13259913,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ab7b5917515c460b90451e67852171a531671ab8",
            "isKey": false,
            "numCitedBy": 4744,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a series of five statistical models of the translation process and give algorithms for estimating the parameters of these models given a set of pairs of sentences that are translations of one another. We define a concept of word-by-word alignment between such pairs of sentences. For any given pair of such sentences each of our models assigns a probability to each of the possible word-by-word alignments. We give an algorithm for seeking the most probable of these alignments. Although the algorithm is suboptimal, the alignment thus obtained accounts well for the word-by-word relationships in the pair of sentences. We have a great deal of data in French and English from the proceedings of the Canadian Parliament. Accordingly, we have restricted our work to these two languages; but we feel that because our algorithms have minimal linguistic content they would work well on other pairs of languages. We also feel, again because of the minimal linguistic content of our algorithms, that it is reasonable to argue that word-by-word alignments are inherent in any sufficiently large bilingual corpus."
            },
            "slug": "The-Mathematics-of-Statistical-Machine-Translation:-Brown-Pietra",
            "title": {
                "fragments": [],
                "text": "The Mathematics of Statistical Machine Translation: Parameter Estimation"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "It is reasonable to argue that word-by-word alignments are inherent in any sufficiently large bilingual corpus, given a set of pairs of sentences that are translations of one another."
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Linguistics"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2137152"
                        ],
                        "name": "P. Enser",
                        "slug": "P.-Enser",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Enser",
                            "middleNames": [
                                "G.",
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Enser"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 206393711,
            "fieldsOfStudy": [
                "Art"
            ],
            "id": "ef94d01afd7e972fa0ad8401c91e5ccd792e89f2",
            "isKey": false,
            "numCitedBy": 155,
            "numCiting": 128,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper surveys theoretical and practical issues associated with a particular type of information retrieval problem, namely that where the information need is pictorial. The paper is contextualised by the notion of a visually stimulated society, in which the ease of record creation and transmission in the visual medium is contrasted with the difficulty of gaining effective subject access to the world's stores of such records. The technological developments which, in casting the visual image in electronic form, have contributed so significantly to its availability are reviewed briefly, as a prelude to the main thrust of the paper. Concentrating on still and moving pictorial forms of the visual image, the paper dwells on issues related to the subject indexing of pictorial material and discusses four models of pictorial information retrieval corresponding with permutations of the verbal and visual modes for the representation of picture content and of information need."
            },
            "slug": "Progress-in-Documentation-Pictorial-Information-Enser",
            "title": {
                "fragments": [],
                "text": "Progress in Documentation Pictorial Information Retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 70,
                "text": "This paper surveys theoretical and practical issues associated with a particular type of information retrieval problem, namely that where the information need is pictorial, and discusses four models of pictorial information retrieval corresponding with permutations of the verbal and visual modes for the representation of picture content and of information need."
            },
            "venue": {
                "fragments": [],
                "text": "J. Documentation"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1796335"
                        ],
                        "name": "D. Blei",
                        "slug": "D.-Blei",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Blei",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Blei"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34699434"
                        ],
                        "name": "A. Ng",
                        "slug": "A.-Ng",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Ng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Ng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694621"
                        ],
                        "name": "Michael I. Jordan",
                        "slug": "Michael-I.-Jordan",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Jordan",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael I. Jordan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 3177797,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f198043a866e9187925a8d8db9a55e3bfdd47f2c",
            "isKey": false,
            "numCitedBy": 30944,
            "numCiting": 68,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Latent-Dirichlet-Allocation-Blei-Ng",
            "title": {
                "fragments": [],
                "text": "Latent Dirichlet Allocation"
            },
            "venue": {
                "fragments": [],
                "text": "J. Mach. Learn. Res."
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144299912"
                        ],
                        "name": "C. O. Frost",
                        "slug": "C.-O.-Frost",
                        "structuredName": {
                            "firstName": "C.",
                            "lastName": "Frost",
                            "middleNames": [
                                "Olivia"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. O. Frost"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2069536903"
                        ],
                        "name": "Bradley Taylor",
                        "slug": "Bradley-Taylor",
                        "structuredName": {
                            "firstName": "Bradley",
                            "lastName": "Taylor",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bradley Taylor"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2109872"
                        ],
                        "name": "A. Noakes",
                        "slug": "A.-Noakes",
                        "structuredName": {
                            "firstName": "Anna",
                            "lastName": "Noakes",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Noakes"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39817346"
                        ],
                        "name": "S. Markel",
                        "slug": "S.-Markel",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Markel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Markel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2058150725"
                        ],
                        "name": "Deborah Torres",
                        "slug": "Deborah-Torres",
                        "structuredName": {
                            "firstName": "Deborah",
                            "lastName": "Torres",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Deborah Torres"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1719580"
                        ],
                        "name": "K. Drabenstott",
                        "slug": "K.-Drabenstott",
                        "structuredName": {
                            "firstName": "Karen",
                            "lastName": "Drabenstott",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Drabenstott"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 21377428,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "929923c5d16f04004c50c53fa9894f6953417290",
            "isKey": false,
            "numCitedBy": 44,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "A prototype image retrieval system with browse and search capabilities was developed to investigate patterns of searching a collection of digital visual images, as well as factors, such as image size, resolution, and download speed, which affect browsing. The subject populations were art history specialists and non-specialists. Through focus group interviews, a controlled test, post-test interviews and an online survey, data was gathered to compare preferences and actual patterns of use in browsing and searching. While specialists preferred direct search to browsing, and generalists used browsing as their preferred mode, both user groups found each mode to play a role depending on information need, and found value in a system combining both browse and direct search. There were no significant differences in performance among the search modes of browse, search, and combined browse/search models when the quasi-controlled study tested the different modes."
            },
            "slug": "Browse-and-Search-Patterns-in-a-Digital-Image-Frost-Taylor",
            "title": {
                "fragments": [],
                "text": "Browse and Search Patterns in a Digital Image Database"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "A prototype image retrieval system with browse and search capabilities was developed to investigate patterns of searching a collection of digital visual images, as well as factors, such as image size, resolution, and download speed, which affect browsing."
            },
            "venue": {
                "fragments": [],
                "text": "Information Retrieval"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145328018"
                        ],
                        "name": "M. Oren",
                        "slug": "M.-Oren",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Oren",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Oren"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145030811"
                        ],
                        "name": "C. Papageorgiou",
                        "slug": "C.-Papageorgiou",
                        "structuredName": {
                            "firstName": "Constantine",
                            "lastName": "Papageorgiou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Papageorgiou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46597039"
                        ],
                        "name": "P. Sinha",
                        "slug": "P.-Sinha",
                        "structuredName": {
                            "firstName": "Pawan",
                            "lastName": "Sinha",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Sinha"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1781874"
                        ],
                        "name": "E. Osuna",
                        "slug": "E.-Osuna",
                        "structuredName": {
                            "firstName": "Edgar",
                            "lastName": "Osuna",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Osuna"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685292"
                        ],
                        "name": "T. Poggio",
                        "slug": "T.-Poggio",
                        "structuredName": {
                            "firstName": "Tomaso",
                            "lastName": "Poggio",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Poggio"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 152,
                                "start": 135
                            }
                        ],
                        "text": "With the exception of systems that can identify faces (Schneiderman and Kanade, 2000), naked people (Fleck et al., 1996), pedestrians (Oren et al., 1997) or cars (Schneiderman and Kanade, 2000), matching is not usually directed toward object semantics."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7967646,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bd0534a87e09b3d64b7e7462e2684c60c9aca1f5",
            "isKey": false,
            "numCitedBy": 837,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a trainable object detection architecture that is applied to detecting people in static images of cluttered scenes. This problem poses several challenges. People are highly non-rigid objects with a high degree of variability in size, shape, color, and texture. Unlike previous approaches, this system learns from examples and does not rely on any a priori (hand-crafted) models or on motion. The detection technique is based on the novel idea of the wavelet template that defines the shape of an object in terms of a subset of the wavelet coefficients of the image. It is invariant to changes in color and texture and can be used to robustly define a rich and complex class of objects such as people. We show how the invariant properties and computational efficiency of the wavelet template make it an effective tool for object detection."
            },
            "slug": "Pedestrian-detection-using-wavelet-templates-Oren-Papageorgiou",
            "title": {
                "fragments": [],
                "text": "Pedestrian detection using wavelet templates"
            },
            "tldr": {
                "abstractSimilarityScore": 68,
                "text": "This paper presents a trainable object detection architecture that is applied to detecting people in static images of cluttered scenes and shows how the invariant properties and computational efficiency of the wavelet template make it an effective tool for object detection."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1746807"
                        ],
                        "name": "Dan Jurafsky",
                        "slug": "Dan-Jurafsky",
                        "structuredName": {
                            "firstName": "Dan",
                            "lastName": "Jurafsky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dan Jurafsky"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "10796472"
                        ],
                        "name": "James H. Martin",
                        "slug": "James-H.-Martin",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Martin",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "James H. Martin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "We present two classes of models for the joint distribution of text and blobs, and show how they are applied to annotate images."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 139,
                                "start": 114
                            }
                        ],
                        "text": "This is a standard process in the machine translation literature (a good guide is Melamed\u2019s thesis, 2001; see also Jurafsky and Martin, 2000, and Manning and Schu\u0308tze, 1999)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 60691216,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b54bcfca3fddc26b8889739a247a25e445818149",
            "isKey": false,
            "numCitedBy": 3827,
            "numCiting": 263,
            "paperAbstract": {
                "fragments": [],
                "text": "From the Publisher: \nThis book takes an empirical approach to language processing, based on applying statistical and other machine-learning algorithms to large corpora.Methodology boxes are included in each chapter. Each chapter is built around one or more worked examples to demonstrate the main idea of the chapter. Covers the fundamental algorithms of various fields, whether originally proposed for spoken or written language to demonstrate how the same algorithm can be used for speech recognition and word-sense disambiguation. Emphasis on web and other practical applications. Emphasis on scientific evaluation. Useful as a reference for professionals in any of the areas of speech and language processing."
            },
            "slug": "Speech-and-language-processing-an-introduction-to-Jurafsky-Martin",
            "title": {
                "fragments": [],
                "text": "Speech and language processing - an introduction to natural language processing, computational linguistics, and speech recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 73,
                "text": "This book takes an empirical approach to language processing, based on applying statistical and other machine-learning algorithms to large corpora, to demonstrate how the same algorithm can be used for speech recognition and word-sense disambiguation."
            },
            "venue": {
                "fragments": [],
                "text": "Prentice Hall series in artificial intelligence"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "121941586"
                        ],
                        "name": "C. Frankel",
                        "slug": "C.-Frankel",
                        "structuredName": {
                            "firstName": "C.",
                            "lastName": "Frankel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Frankel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2987811"
                        ],
                        "name": "M. Swain",
                        "slug": "M.-Swain",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Swain",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Swain"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1720747"
                        ],
                        "name": "V. Athitsos",
                        "slug": "V.-Athitsos",
                        "structuredName": {
                            "firstName": "Vassilis",
                            "lastName": "Athitsos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Athitsos"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 27,
                                "start": 9
                            }
                        ],
                        "text": "Webseer (Swain et al., 1996) uses similar ideas for query of images on the web, but also indexes the results of a few automatically estimated image features."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 7811959,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "105b158b73511030ff10ac0f0f1cbee65236e4a6",
            "isKey": false,
            "numCitedBy": 378,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "Because of the size of the World Wide Web and its inherent lack of structure, finding what one is looking for can be a challenge. PC-Meters March, 1996, survey found that three of the five most visited Web sites were search engines. However, while Web pages typically contain both text and images, all the currently available search engines only index text. This paper describes WebSeer, a system for locating images on the Web. WebSeer uses image content in addition to associated text to index images, presenting the user with a selection that potentially fits her needs."
            },
            "slug": "WebSeer:-An-Image-Search-Engine-for-the-World-Wide-Frankel-Swain",
            "title": {
                "fragments": [],
                "text": "WebSeer: An Image Search Engine for the World Wide Web"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "WebSeer uses image content in addition to associated text to index images, presenting the user with a selection that potentially fits her needs on the Web."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1806591"
                        ],
                        "name": "G. Celeux",
                        "slug": "G.-Celeux",
                        "structuredName": {
                            "firstName": "Gilles",
                            "lastName": "Celeux",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Celeux"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2811561"
                        ],
                        "name": "D. Chauveau",
                        "slug": "D.-Chauveau",
                        "structuredName": {
                            "firstName": "Didier",
                            "lastName": "Chauveau",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Chauveau"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3045284"
                        ],
                        "name": "J. Diebolt",
                        "slug": "J.-Diebolt",
                        "structuredName": {
                            "firstName": "Jean",
                            "lastName": "Diebolt",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Diebolt"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14925864,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ad2f6d7a96710fcb39472dfeacb9a071bdb354b8",
            "isKey": false,
            "numCitedBy": 173,
            "numCiting": 77,
            "paperAbstract": {
                "fragments": [],
                "text": "We compare three different stochastic versions of the EM algorithm: The SEM algorithm, the SAEM algorithm and the MCEM algorithm. We suggest that the most relevant contribution of the MCEM methodology is what we call the simulated annealing MCEM algorithm, which turns out to be very close to SAEM. We focus particularly on the mixture of distributions problem. In this context, we review the available theoretical results on the convergence of these algorithms and on the behavior of SEM as the sample size tends to infinity. The second part is devoted to intensive Monte Carlo numerical simulations and a real data study. We show that, for some particular mixture situations, the SEM algorithm is almost always preferable to the EM and simulated annealing versions SAEM and MCEM. For some very intricate mixtures, however, none of these algorithms can be confidently used. Then, SEM can be used as an efficient data exploratory tool for locating significant maxima of the likelihood function. In the real data case, we show that the SEM stationary distribution provides a contrasted view of the loglikelihood by emphasizing sensible maxima."
            },
            "slug": "On-Stochastic-Versions-of-the-EM-Algorithm-Celeux-Chauveau",
            "title": {
                "fragments": [],
                "text": "On Stochastic Versions of the EM Algorithm"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "It is shown that, for some particular mixture situations, the SEM algorithm is almost always preferable to the EM and simulated annealing versions SAEM and MCEM, and the SEM stationary distribution provides a contrasted view of the loglikelihood by emphasizing sensible maxima."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144783904"
                        ],
                        "name": "Christopher D. Manning",
                        "slug": "Christopher-D.-Manning",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Manning",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christopher D. Manning"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144418438"
                        ],
                        "name": "Hinrich Sch\u00fctze",
                        "slug": "Hinrich-Sch\u00fctze",
                        "structuredName": {
                            "firstName": "Hinrich",
                            "lastName": "Sch\u00fctze",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hinrich Sch\u00fctze"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "We present two classes of models for the joint distribution of text and blobs, and show how they are applied to annotate images."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 170,
                                "start": 145
                            }
                        ],
                        "text": "This is a standard process in the machine translation literature (a good guide is Melamed\u2019s thesis, 2001; see also Jurafsky and Martin, 2000, and Manning and Schu\u0308tze, 1999)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 52800448,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "084c55d6432265785e3ff86a2e900a49d501c00a",
            "isKey": false,
            "numCitedBy": 7801,
            "numCiting": 294,
            "paperAbstract": {
                "fragments": [],
                "text": "Statistical approaches to processing natural language text have become dominant in recent years. This foundational text is the first comprehensive introduction to statistical natural language processing (NLP) to appear. The book contains all the theory and algorithms needed for building NLP tools. It provides broad but rigorous coverage of mathematical and linguistic foundations, as well as detailed discussion of statistical methods, allowing students and researchers to construct their own implementations. The book covers collocation finding, word sense disambiguation, probabilistic parsing, information retrieval, and other applications."
            },
            "slug": "Foundations-of-statistical-natural-language-Manning-Sch\u00fctze",
            "title": {
                "fragments": [],
                "text": "Foundations of statistical natural language processing"
            },
            "tldr": {
                "abstractSimilarityScore": 53,
                "text": "This foundational text is the first comprehensive introduction to statistical natural language processing (NLP) to appear and provides broad but rigorous coverage of mathematical and linguistic foundations, as well as detailed discussion of statistical methods, allowing students and researchers to construct their own implementations."
            },
            "venue": {
                "fragments": [],
                "text": "SGMD"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143936663"
                        ],
                        "name": "Thomas Hofmann",
                        "slug": "Thomas-Hofmann",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Hofmann",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thomas Hofmann"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 97,
                                "start": 84
                            }
                        ],
                        "text": "Our first model is a multi-modal extension of Hofmann\u2019s hierarchical model for text (Hofmann, 1998, Hofmann and Puzicha, 1998)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 8069201,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7682b0fe481c345ea973ca07d2d979e003fd20a2",
            "isKey": false,
            "numCitedBy": 28,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "ion levels of words document partitioning abstraction levels (a) (b)"
            },
            "slug": "Learning-and-representing-topic-a-hierarchical-for-Hofmann",
            "title": {
                "fragments": [],
                "text": "Learning and representing topic-a hierarchical mixture model for word occurences in document databas"
            },
            "tldr": {
                "abstractSimilarityScore": 55,
                "text": "In this chapter three levels of words document partitioning abstraction levels are calculated using a model based on the model developed in [Bouchut-Boyaval, M3AS, 2013]."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38956799"
                        ],
                        "name": "R. Jonker",
                        "slug": "R.-Jonker",
                        "structuredName": {
                            "firstName": "Roy",
                            "lastName": "Jonker",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Jonker"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1681127"
                        ],
                        "name": "A. Volgenant",
                        "slug": "A.-Volgenant",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Volgenant",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Volgenant"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 79,
                                "start": 53
                            }
                        ],
                        "text": "In this work we report results using graph matching (Jonker and Volgenant, 1987)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 7806079,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ccbe40d7e91e451d10069d1f1b0e7989af528644",
            "isKey": false,
            "numCitedBy": 990,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "We develop a shortest augmenting path algorithm for the linear assignment problem. It contains new initialization routines and a special implementation of Dijkstra's shortest path method. For both dense and sparse problems computational experiments show this algorithm to be uniformly faster than the best algorithms from the literature. A Pascal implementation is presented.ZusammenfassungWir entwickeln einen Algorithmus mit k\u00fcrzesten alternierenden Wegen f\u00fcr das lineare Zuordnungsproblem. Er enth\u00e4lt neue Routinen f\u00fcr die Anfangswerte und eine spezielle Implementierung der K\u00fcrzesten-Wege-Methode von Dijkstra. Sowohl f\u00fcr dichte als auch f\u00fcr d\u00fcnne Probleme zeigen Testl\u00e4ufe, da\u00df unser Algorithmus gleichm\u00e4\u00dfig schneller als die besten Algorithmen aus der Literatur ist. Eine Implementierung in Pascal wird angegeben."
            },
            "slug": "A-shortest-augmenting-path-algorithm-for-dense-and-Jonker-Volgenant",
            "title": {
                "fragments": [],
                "text": "A shortest augmenting path algorithm for dense and sparse linear assignment problems"
            },
            "tldr": {
                "abstractSimilarityScore": 92,
                "text": "A shortest augmenting path algorithm for the linear assignment problem that contains new initialization routines and a special implementation of Dijkstra's shortest path method is developed."
            },
            "venue": {
                "fragments": [],
                "text": "Computing"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35043531"
                        ],
                        "name": "A. Dempster",
                        "slug": "A.-Dempster",
                        "structuredName": {
                            "firstName": "Arthur",
                            "lastName": "Dempster",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Dempster"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7890796"
                        ],
                        "name": "N. Laird",
                        "slug": "N.-Laird",
                        "structuredName": {
                            "firstName": "Nan",
                            "lastName": "Laird",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Laird"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2235217"
                        ],
                        "name": "D. Rubin",
                        "slug": "D.-Rubin",
                        "structuredName": {
                            "firstName": "Donald",
                            "lastName": "Rubin",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Rubin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 4193919,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "d36efb9ad91e00faa334b549ce989bfae7e2907a",
            "isKey": false,
            "numCitedBy": 48403,
            "numCiting": 134,
            "paperAbstract": {
                "fragments": [],
                "text": "Vibratory power unit for vibrating conveyers and screens comprising an asynchronous polyphase motor, at least one pair of associated unbalanced masses disposed on the shaft of said motor, with the first mass of a pair of said unbalanced masses being rigidly fastened to said shaft and with said second mass of said pair being movably arranged relative to said first mass, means for controlling and regulating the conveying rate during conveyer operation by varying the rotational speed of said motor between predetermined minimum and maximum values, said second mass being movably outwardly by centrifugal force against the pressure of spring means, said spring means being prestressed in such a manner that said second mass is, at rotational motor speeds lower than said minimum speed, held in its initial position, and at motor speeds between said lower and upper values in positions which are radially offset with respect to the axis of said motor to an extent depending on the value of said rotational motor speed."
            },
            "slug": "Maximum-likelihood-from-incomplete-data-via-the-EM-Dempster-Laird",
            "title": {
                "fragments": [],
                "text": "Maximum likelihood from incomplete data via the EM - algorithm plus discussions on the paper"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1977
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2084787954"
                        ],
                        "name": "G. Webbe",
                        "slug": "G.-Webbe",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Webbe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Webbe"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 10172,
            "fieldsOfStudy": [
                "Medicine"
            ],
            "id": "96c84e5c8dce13f13d8776a52e189f395b023c5e",
            "isKey": false,
            "numCitedBy": 108,
            "numCiting": 2,
            "paperAbstract": {
                "fragments": [],
                "text": "A.-Potassium citrate is used to make the urine alkaline because citrate is metabolized in the body to produce bicarbonate ions. Sodium bicarbonate would also be effective for this purpose. It is difficult to give exact equivalent doses of potassium citrate and sodium bicarbonate because not all the citrate which is given is converted to bicarbonate. If one were to assume that this were so the equivalent of the 3 g. of potassium citrate contained in a dose of Mist. pot. cit. (N.F.) is about 2.4 g. of sodium bicarbonate. The usual dose of sodium bicarbonate advocated for alkalinization of the urine, however. is 5-10 g. per day. The disadvantages of sodium bicarbonate are that it neutralizes the gastric hydrochloric acid and that a good deal of carbon dioxide is produced in the stomach, so that gastric distension and belching may occur. The nausea produced by pot. cit. is mainly due to the potassium ion, and sodium citrate in a dose of 5-10 g. per day would probably be more pleasant to take and just as effective as potassium citrate. The main dietary factor which controls the pH of the urine in health is the amount of protein eaten. Those who take a mainly vegetarian diet tend to have a more alkaline urine."
            },
            "slug": "Any-Questions-Webbe",
            "title": {
                "fragments": [],
                "text": "Any Questions"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "The main dietary factor which controls the pH of the urine in health is the amount of protein eaten, and those who take a mainly vegetarian diet tend to have a more alkaline urine."
            },
            "venue": {
                "fragments": [],
                "text": "The Indian medical gazette"
            },
            "year": 1946
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 2093,
                                "start": 23
                            }
                        ],
                        "text": ", 1994, Srihari, 1991, Srihari and Burhans, 1994). We are not aware of general probability models that link text and images, however. Such a model would offer the usual benefits of probability models over boolean queries\u2014one doesn\u2019t need to know exactly the right search terms to get useful results\u2014but might offer more. One is that one might predict text given images. There are two ways to do this. Firstly, one might attempt to predict annotations of entire images using all information present. We refer to this task as annotation. Secondly, one might attempt to associate particular words with particular image substructures\u2014that is, to infercorrespondence. Few data sets contain correspondence information, probably because it is difficult to create such data sets. Normally, one has a collection of images, each of which has a collection of associated words. This can be seen as a form of classification problem, where instead of having labeled examples one has labeled bags of examples\u2014an image is \u201cpositive\u201d if it contains a tiger somewhere amongst all the other stuff and \u201cnegative\u201d if it doesn\u2019t. Maron and Ratan (1998) and Maron (1998) used multiple-instance learning to train classifiers to identify particular keywords from image data using such bags. Rather than attempt to sort out all correspondences between image structures and words directly, they build classifiers for each word separately. Satoh and Kanade (1997) used cooccurrence models for automatically associating faces with names in video. Finally, perhaps closest to our work on predicting words for regions is the work of Mori et al. (1999), where co-occurrence statistics are collected for words and image areas defined by a fixed grid. Correspondence is a peculiar feature of object recognition. Current theories of object recognition reason either in terms of geometric correspondence and pose consistency; in terms of template matching via classifiers; or by search to establish the presence of suggestive relations between templates. A detailed review of these strategies appears in Forsyth and Ponce (2002). There has been little work to address object recognition at a broad scale."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 1621,
                                "start": 23
                            }
                        ],
                        "text": ", 1994, Srihari, 1991, Srihari and Burhans, 1994). We are not aware of general probability models that link text and images, however. Such a model would offer the usual benefits of probability models over boolean queries\u2014one doesn\u2019t need to know exactly the right search terms to get useful results\u2014but might offer more. One is that one might predict text given images. There are two ways to do this. Firstly, one might attempt to predict annotations of entire images using all information present. We refer to this task as annotation. Secondly, one might attempt to associate particular words with particular image substructures\u2014that is, to infercorrespondence. Few data sets contain correspondence information, probably because it is difficult to create such data sets. Normally, one has a collection of images, each of which has a collection of associated words. This can be seen as a form of classification problem, where instead of having labeled examples one has labeled bags of examples\u2014an image is \u201cpositive\u201d if it contains a tiger somewhere amongst all the other stuff and \u201cnegative\u201d if it doesn\u2019t. Maron and Ratan (1998) and Maron (1998) used multiple-instance learning to train classifiers to identify particular keywords from image data using such bags. Rather than attempt to sort out all correspondences between image structures and words directly, they build classifiers for each word separately. Satoh and Kanade (1997) used cooccurrence models for automatically associating faces with names in video. Finally, perhaps closest to our work on predicting words for regions is the work of Mori et al. (1999), where co-occurrence statistics are collected for words and image areas defined by a fixed grid."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 1436,
                                "start": 23
                            }
                        ],
                        "text": ", 1994, Srihari, 1991, Srihari and Burhans, 1994). We are not aware of general probability models that link text and images, however. Such a model would offer the usual benefits of probability models over boolean queries\u2014one doesn\u2019t need to know exactly the right search terms to get useful results\u2014but might offer more. One is that one might predict text given images. There are two ways to do this. Firstly, one might attempt to predict annotations of entire images using all information present. We refer to this task as annotation. Secondly, one might attempt to associate particular words with particular image substructures\u2014that is, to infercorrespondence. Few data sets contain correspondence information, probably because it is difficult to create such data sets. Normally, one has a collection of images, each of which has a collection of associated words. This can be seen as a form of classification problem, where instead of having labeled examples one has labeled bags of examples\u2014an image is \u201cpositive\u201d if it contains a tiger somewhere amongst all the other stuff and \u201cnegative\u201d if it doesn\u2019t. Maron and Ratan (1998) and Maron (1998) used multiple-instance learning to train classifiers to identify particular keywords from image data using such bags. Rather than attempt to sort out all correspondences between image structures and words directly, they build classifiers for each word separately. Satoh and Kanade (1997) used cooccurrence models for automatically associating faces with names in video."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 1131,
                                "start": 23
                            }
                        ],
                        "text": ", 1994, Srihari, 1991, Srihari and Burhans, 1994). We are not aware of general probability models that link text and images, however. Such a model would offer the usual benefits of probability models over boolean queries\u2014one doesn\u2019t need to know exactly the right search terms to get useful results\u2014but might offer more. One is that one might predict text given images. There are two ways to do this. Firstly, one might attempt to predict annotations of entire images using all information present. We refer to this task as annotation. Secondly, one might attempt to associate particular words with particular image substructures\u2014that is, to infercorrespondence. Few data sets contain correspondence information, probably because it is difficult to create such data sets. Normally, one has a collection of images, each of which has a collection of associated words. This can be seen as a form of classification problem, where instead of having labeled examples one has labeled bags of examples\u2014an image is \u201cpositive\u201d if it contains a tiger somewhere amongst all the other stuff and \u201cnegative\u201d if it doesn\u2019t. Maron and Ratan (1998) and Maron (1998) used multiple-instance learning to train classifiers to identify particular keywords from image data using such bags."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A statistical approach to 3d object recognition applied to faces"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 85,
                                "start": 64
                            }
                        ],
                        "text": "This observation led to the alternative model\u2014first described in Barnard et al. (2001)\u2014which is generative."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "In this paper, we describe a series of models that link images and text in various ways."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 31,
                                "start": 10
                            }
                        ],
                        "text": "Following Barnard et al. (2001) and Barnard and Forsyth (2001), we also experiment with allowing a cluster dependent level structure."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 72,
                                "start": 52
                            }
                        ],
                        "text": "Because the data set does not provide explicit correspondences, we have a missing data problem which is easily dealt with as an application of EM (see Duygulu et al., 2002 for details)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 125,
                                "start": 104
                            }
                        ],
                        "text": "Fitting a probability model with an appropriate structure yields quite useful clusters, as described in Barnard et al. (2001)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 109,
                                "start": 89
                            }
                        ],
                        "text": "Auto-illustration is possible if one can obtain images with high probability given text (Barnard et al., 2001, Barnard and Forsyth, 2001)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 64,
                                "start": 43
                            }
                        ],
                        "text": "Examples of automated annotation appear in Barnard et al. (2001), Barnard and Forsyth (2001) and below."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Clustering Art, IEEE Conference on Computer Vision and Pattern Recognition, Hawaii"
            },
            "venue": {
                "fragments": [],
                "text": "Clustering Art, IEEE Conference on Computer Vision and Pattern Recognition, Hawaii"
            },
            "year": 2001
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 385,
                                "start": 74
                            }
                        ],
                        "text": "All of these models are fit using the expectation maximization algorithm (Dempster et al. (1977)). The update equations are very similar to those in Hofmann and Puzicha (1998), except of course, the probability expressions now include parts both for word and region occurrences. For model I-0, we estimate the vertical mixing weights for each document as in Hofmann and Puzicha (1998). For model I-1, we estimate the vertical mixing weights for each document giveneachcluster."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 97,
                                "start": 74
                            }
                        ],
                        "text": "All of these models are fit using the expectation maximization algorithm (Dempster et al. (1977))."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 176,
                                "start": 74
                            }
                        ],
                        "text": "All of these models are fit using the expectation maximization algorithm (Dempster et al. (1977)). The update equations are very similar to those in Hofmann and Puzicha (1998), except of course, the probability expressions now include parts both for word and region occurrences."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Maximum likelihood from incomplete data via the EM algorithm.Journal of the Royal Statistical Society"
            },
            "venue": {
                "fragments": [],
                "text": "Series B (Methodological)"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "116312510"
                        ],
                        "name": "M. McCarthy",
                        "slug": "M.-McCarthy",
                        "structuredName": {
                            "firstName": "Mary",
                            "lastName": "McCarthy",
                            "middleNames": [
                                "Dianne"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. McCarthy"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 836,
                                "start": 55
                            }
                        ],
                        "text": "With the exception of systems that can identify faces (Schneiderman and Kanade, 2000), naked people (Fleck et al., 1996), pedestria n (Oren et al., 1997) or cars (Schneiderman and Kanade, 2000), matching is not usually directed t oward object semantics. However, user studies show a large disparity between user needs and wh at tec nology supplies (Armitage and Enser, 1997, Enser, 1993, 1995). This work makes hair-raisi ng reading\u2014an example is a request to a stock photo library for \u201cPretty girl doing something act ive, sporty in a summery setting, beach - not wearing lycra, exercise clothes - more relaxed in tee-s hirt. Feature is about deodorant so girl should look active - not sweaty but happy, healthy, carefree - nothing too posed or set up - nice and natural looking.\u201d Other user studies include the work of Ornager (1996), who st udied practice at a manually operated newspaper photo archive and Markkula and Sormunen (2000), who study practice at a Finnish newspaper\u2019s digital photo archive."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 70631861,
            "fieldsOfStudy": [
                "Medicine"
            ],
            "id": "0ae47348a378307514411560e6db99df8bbf6222",
            "isKey": false,
            "numCitedBy": 248,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "The-statistical-approach-McCarthy",
            "title": {
                "fragments": [],
                "text": "The statistical approach"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1959
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2154295"
                        ],
                        "name": "B. Weinberg",
                        "slug": "B.-Weinberg",
                        "structuredName": {
                            "firstName": "Bella",
                            "lastName": "Weinberg",
                            "middleNames": [
                                "Hass"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Weinberg"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 93,
                                "start": 80
                            }
                        ],
                        "text": "Keister studied requests received by the National Library of Medicine\u2019s Archive (Keister, 1994)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 62228878,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0ddc376b339ee903d548f6d10be43a014c075334",
            "isKey": false,
            "numCitedBy": 22,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Challenges-in-indexing-electronic-text-and-images-Weinberg",
            "title": {
                "fragments": [],
                "text": "Challenges in indexing electronic text and images"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143616144"
                        ],
                        "name": "T. Allen",
                        "slug": "T.-Allen",
                        "structuredName": {
                            "firstName": "Tim",
                            "lastName": "Allen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Allen"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 433860,
            "fieldsOfStudy": [
                "Medicine"
            ],
            "id": "4433cca75c7483f9270f8d05d178ebba55f71e10",
            "isKey": false,
            "numCitedBy": 124,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Thank-you.-Allen",
            "title": {
                "fragments": [],
                "text": "Thank you."
            },
            "venue": {
                "fragments": [],
                "text": "CJEM"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3331580"
                        ],
                        "name": "O. Maron",
                        "slug": "O.-Maron",
                        "structuredName": {
                            "firstName": "Oded",
                            "lastName": "Maron",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Maron"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2578809"
                        ],
                        "name": "A. L. Ratan",
                        "slug": "A.-L.-Ratan",
                        "structuredName": {
                            "firstName": "Aparna",
                            "lastName": "Ratan",
                            "middleNames": [
                                "Lakshmi"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. L. Ratan"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "In (Maron, 1998;  Maron and Ratan, 1998 ), Maron et al. study automatic annotation of images, but work one word at a time, and offer no method of finding the correspondence between words and regions."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 164,
                                "start": 142
                            }
                        ],
                        "text": "\u2026one has labeled bags of examples\u2014an image is \u201cpositive\u201d if it contains a tiger somewhere amongst all the other stuff and \u201cnegative\u201d if it doesn\u2019t. Maron and Ratan (1998) and Maron (1998) used multiple-instance learning to train classifiers to identify particular keywords from image data\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 39240439,
            "fieldsOfStudy": [
                "Education"
            ],
            "id": "6e0616e65727c7ab9c185c92e15ccd405cfc2a0b",
            "isKey": false,
            "numCitedBy": 654,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Multiple-Instance-Learning-for-Natural-Scene-Maron-Ratan",
            "title": {
                "fragments": [],
                "text": "Multiple-Instance Learning for Natural Scene Classification"
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1693993"
                        ],
                        "name": "D. Tufis",
                        "slug": "D.-Tufis",
                        "structuredName": {
                            "firstName": "Dan",
                            "lastName": "Tufis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Tufis"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 75,
                                "start": 62
                            }
                        ],
                        "text": "We used a modest selection of features for each segment, including size, position, color, oriented energy (12 filters), and a few simple shape features."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 205,
                                "start": 192
                            }
                        ],
                        "text": "Instead, we approximate the sum with that obtained by a maximal, or close to maximal match (this approximation is common in the literature on statistical learning of lexicons, see for example Melamed, 2001)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 274,
                                "start": 261
                            }
                        ],
                        "text": "This is a traditional solution in the machine translation literature; the tendency of single words in some languages to generate more than one word in others (a property referred to as \u201cfertility\u201d) can be modeled explicitly in this framework (Brown et al., 1993, Melamed, 2001)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 30926497,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bdf0bc765986f07634326523b49d353625b205f1",
            "isKey": false,
            "numCitedBy": 103,
            "numCiting": 3,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Empirical-Methods-for-Exploiting-Parallel-Texts-Tufis",
            "title": {
                "fragments": [],
                "text": "Empirical Methods for Exploiting Parallel Texts"
            },
            "venue": {
                "fragments": [],
                "text": "Lit. Linguistic Comput."
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2083238819"
                        ],
                        "name": "EstimationPeter",
                        "slug": "EstimationPeter",
                        "structuredName": {
                            "firstName": "",
                            "lastName": "EstimationPeter",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "EstimationPeter"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2071381247"
                        ],
                        "name": "F. Brown",
                        "slug": "F.-Brown",
                        "structuredName": {
                            "firstName": "Frank",
                            "lastName": "Brown",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Brown"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "150294465"
                        ],
                        "name": "Stephen A. Della",
                        "slug": "Stephen-A.-Della",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Della",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Stephen A. Della"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2101944654"
                        ],
                        "name": "PietraVincent",
                        "slug": "PietraVincent",
                        "structuredName": {
                            "firstName": "",
                            "lastName": "PietraVincent",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "PietraVincent"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "15863845"
                        ],
                        "name": "J. Pietra",
                        "slug": "J.-Pietra",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Pietra",
                            "middleNames": [
                                "Della"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Pietra"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "121137016"
                        ],
                        "name": "L. Robert",
                        "slug": "L.-Robert",
                        "structuredName": {
                            "firstName": "L",
                            "lastName": "Robert",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Robert"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2096936222"
                        ],
                        "name": "MercerThe",
                        "slug": "MercerThe",
                        "structuredName": {
                            "firstName": "",
                            "lastName": "MercerThe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "MercerThe"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 33487754,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "56c0b0e834830d415477b69508f230efb38e6716",
            "isKey": false,
            "numCitedBy": 164,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "The-Mathematics-of-Machine-Translation-:-Parameter-EstimationPeter-Brown",
            "title": {
                "fragments": [],
                "text": "The Mathematics of Machine Translation : Parameter"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1748081"
                        ],
                        "name": "R. Srihari",
                        "slug": "R.-Srihari",
                        "structuredName": {
                            "firstName": "Rohini",
                            "lastName": "Srihari",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Srihari"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2099025541"
                        ],
                        "name": "R. Chopra",
                        "slug": "R.-Chopra",
                        "structuredName": {
                            "firstName": "Rajiv",
                            "lastName": "Chopra",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Chopra"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2011596"
                        ],
                        "name": "D. Burhans",
                        "slug": "D.-Burhans",
                        "structuredName": {
                            "firstName": "Debra",
                            "lastName": "Burhans",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Burhans"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "92876288"
                        ],
                        "name": "M. Venkataraman",
                        "slug": "M.-Venkataraman",
                        "structuredName": {
                            "firstName": "Mahesh",
                            "lastName": "Venkataraman",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Venkataraman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1723877"
                        ],
                        "name": "V. Govindaraju",
                        "slug": "V.-Govindaraju",
                        "structuredName": {
                            "firstName": "Venu",
                            "lastName": "Govindaraju",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Govindaraju"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 184,
                                "start": 120
                            }
                        ],
                        "text": "Srihari and others have used text information to disambiguate image features, particularly in face finding applications (Srihari, 1991; Srihari and Burhans, 1994; Srihari et al., 1994)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 141,
                                "start": 121
                            }
                        ],
                        "text": "Srihari and others have used text information to disambiguate image features, particularly in face finding applications (Srihari et al., 1994, Srihari, 1991, Srihari and Burhans, 1994)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 59669097,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1720b6e3e41edd77a86ef45ad5fc49bc73990b80",
            "isKey": false,
            "numCitedBy": 21,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Use-of-Collateral-Text-in-Image-Interpretation-Srihari-Chopra",
            "title": {
                "fragments": [],
                "text": "Use of Collateral Text in Image Interpretation"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Pedestrian detection using wavelet templates. In Computer vision and pattern recognition"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Multiple - instance learning for natur l scene classification"
            },
            "venue": {
                "fragments": [],
                "text": "The Fifteenth International Conference on Machine Learning"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 95,
                                "start": 80
                            }
                        ],
                        "text": "Keister studied requests received by the National Library of Medicine's Archive (Keister, 1994)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 93,
                                "start": 80
                            }
                        ],
                        "text": "Keister studied requests received by the National Library of Medicine\u2019s Archive (Keister, 1994)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "User types and queries: impact on image access systems, Challenges in indexing electronic text and images. Learned Information"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 58,
                                "start": 29
                            }
                        ],
                        "text": "Examples include the Corel data set, most museum image collections (for example, http://www.thinker.org/fam/ thinker.html), the web archive (http://www.archive.org), and most collections of news photographs on the web (which come with captions)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 84,
                                "start": 55
                            }
                        ],
                        "text": "With the exception of systems that can identify faces (Schneiderman and Kanade, 2000), naked people (Fleck et al., 1996), pedestrians (Oren et al., 1997) or cars (Schneiderman and Kanade, 2000), matching is not usually directed toward object semantics."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A statistical approach to 3d object recognition applied to faces and cars"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Normalized Cuts Software Available from http://dlp"
            },
            "venue": {
                "fragments": [],
                "text": "CS.Berkeley.EDU/~doron"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Qing Xia () Matching Words and Pictures March 4, 2008 47 / 54 Annotation Results Annotation results are compared between models"
            },
            "venue": {
                "fragments": [],
                "text": "Measure PR"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Comparison of models using different scores"
            },
            "venue": {
                "fragments": [],
                "text": "Comparison of models using different scores"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Comparison of models using different scores"
            },
            "venue": {
                "fragments": [],
                "text": "Comparison of models using different scores"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 40,
                                "start": 21
                            }
                        ],
                        "text": ", 1996), pedestrians (Oren et al., 1997) or cars (Schneiderman and Kanade, 2000), matching is not usually directed toward object semantics."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 152,
                                "start": 135
                            }
                        ],
                        "text": "With the exception of systems that can identify faces (Schneiderman and Kanade, 2000), naked people (Fleck et al., 1996), pedestrians (Oren et al., 1997) or cars (Schneiderman and Kanade, 2000), matching is not usually directed toward object semantics."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Pedestrian detection using wavelet templates, Computer vision and pattern"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 118,
                                "start": 95
                            }
                        ],
                        "text": "Others have also experimented with using image features as part of a query refinement process (Chen et al., 1999, 2000)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 132,
                                "start": 94
                            }
                        ],
                        "text": "Others have also experimented with using image features as part of a query refinement process (Chen et al., 1999; Chen et al., 2000)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Multi-modal browsing of images in web documents, SPIE Document Recognition and Retrieval"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 152,
                                "start": 135
                            }
                        ],
                        "text": "With the exception of systems that can identify faces (Schneiderman and Kanade, 2000), naked people (Fleck et al., 1996), pedestrians (Oren et al., 1997) or cars (Schneiderman and Kanade, 2000), matching is not usually directed toward object semantics."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Pedestrian detection using wavelet templates, Computer vision and pattern recognition"
            },
            "venue": {
                "fragments": [],
                "text": "Pedestrian detection using wavelet templates, Computer vision and pattern recognition"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 126,
                                "start": 84
                            }
                        ],
                        "text": "Our first model is a multi-modal extension of Hofmann\u2019s hierarchical model for text (Hofmann, 1998; Hofmann and Puzicha, 1998) ."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 97,
                                "start": 84
                            }
                        ],
                        "text": "Our first model is a multi-modal extension of Hofmann\u2019s hierarchical model for text (Hofmann, 1998, Hofmann and Puzicha, 1998)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Learning and representing topic. A hierarchical mixture model for word occurrence in document databases, Workshop on learning from text and the web, CMU"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 137,
                                "start": 120
                            }
                        ],
                        "text": "However, user studies show a large disparity between user needs and what technology supplies (Armitage and Enser, 1997, Enser, 1993, 1995)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 112,
                                "start": 101
                            }
                        ],
                        "text": "Typically, these annotations refer to the content of the annotated image, more or less specifically and more or less comprehensively."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 65,
                                "start": 48
                            }
                        ],
                        "text": "Also see Enser\u2019s work (Armitage and Enser, 1997, Enser, 1993, 1995) on various image archives, which use roughly the same procedure.\ntext and histogram data in the indexing (La Cascia et al., 1998)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Query analysis in a visual information retrieval context"
            },
            "venue": {
                "fragments": [],
                "text": "Journal of Document and Text Management"
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Martin.Speech and Language Processing: An Introduction to Natural Lan"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1987
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Name - it : Association of facend name in video Normalized cuts and image segmentation"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 97,
                                "start": 84
                            }
                        ],
                        "text": "Our first model is a multi-modal extension of Hofmann\u2019s hierarchical model for text (Hofmann, 1998, Hofmann and Puzicha, 1998)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Learning and representing topic. A hierarchical mixture model for word occurrence in document databases, Workshop on learning from text and the web"
            },
            "venue": {
                "fragments": [],
                "text": "Learning and representing topic. A hierarchical mixture model for word occurrence in document databases, Workshop on learning from text and the web"
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Normalized score measure Go from zero to some peak, and then to drop down to zero again. Comparison of models using different scores"
            },
            "venue": {
                "fragments": [],
                "text": "Normalized score measure Go from zero to some peak, and then to drop down to zero again. Comparison of models using different scores"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Normalized score measure"
            },
            "venue": {
                "fragments": [],
                "text": "Normalized score measure"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 150,
                                "start": 137
                            }
                        ],
                        "text": "Feature is about deodorant so girl should look active - not sweaty but happy, healthy, carefree - nothing too posed or set up - nice and natural looking.\u201d"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 53,
                                "start": 39
                            }
                        ],
                        "text": "Other user studies include the work of Ornager (1996), who studied practice at a manually operated newspaper photo archive and Markkula and Sormunen (2000), who study practice at a Finnish newspaper\u2019s digital photo archive."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "View a picture: Theoretical image analysis and empirical user studies on indexing and retrieval"
            },
            "venue": {
                "fragments": [],
                "text": "Swedis Library Research"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 195,
                                "start": 176
                            }
                        ],
                        "text": "Also see Enser\u2019s work (Armitage and Enser, 1997, Enser, 1993, 1995) on various image archives, which use roughly the same procedure.\ntext and histogram data in the indexing (La Cascia et al., 1998)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Combining Textual and Visual Cues for Contentbased Image Retrieval on the World Wide Web, IEEE Workshop on Content-Based Access of Image and Video Libraries"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Normalized score measure Go from zero to some peak, and then to drop down to zero again"
            },
            "venue": {
                "fragments": [],
                "text": "Normalized score measure Go from zero to some peak, and then to drop down to zero again"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Image - toword transformation based on dividing and vector quantizing images with words"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2001
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 93,
                                "start": 80
                            }
                        ],
                        "text": "Keister studied requests received by the National Library of Medicine\u2019s Archive (Keister, 1994)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "In this paper, we describe a series of models that link images and text in various ways."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "User types and queries: impact on image access systems"
            },
            "venue": {
                "fragments": [],
                "text": "Challenges in indexing electronic text and images. Learned Information"
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Keister . User types and queries : impact on image accesssystems"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Latent Dirichlet allocation The mathematics of machine translation : Parameter estimation"
            },
            "venue": {
                "fragments": [],
                "text": "Computational Linguistics"
            },
            "year": 1993
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 32,
            "methodology": 23,
            "result": 2
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 68,
        "totalPages": 7
    },
    "page_url": "https://www.semanticscholar.org/paper/Matching-Words-and-Pictures-Barnard-Sahin/6a26268d2ba9d34e5b59ae6e5c11a83cdca1a85e?sort=total-citations"
}