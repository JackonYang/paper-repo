{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38940652"
                        ],
                        "name": "H. Soltau",
                        "slug": "H.-Soltau",
                        "structuredName": {
                            "firstName": "Hagen",
                            "lastName": "Soltau",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Soltau"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1698208"
                        ],
                        "name": "G. Saon",
                        "slug": "G.-Saon",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Saon",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Saon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144707379"
                        ],
                        "name": "Brian Kingsbury",
                        "slug": "Brian-Kingsbury",
                        "structuredName": {
                            "firstName": "Brian",
                            "lastName": "Kingsbury",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Brian Kingsbury"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 97,
                                "start": 94
                            }
                        ],
                        "text": "For instance, our decoders work with an interface that provides a score for a particular frame and FST input symbol."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7055050,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f66612b7b986169730d4e9c6e473566025a18d85",
            "isKey": false,
            "numCitedBy": 144,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe the design of IBM's Attila speech recognition toolkit. We show how the combination of a highly modular and efficient library of low-level C++ classes with simple interfaces, an interconnection layer implemented in a modern scripting language (Python), and a standardized collection of scripts for system-building produce a flexible and scalable toolkit that is useful both for basic research and for construction of large transcription systems for competitive evaluations."
            },
            "slug": "The-IBM-Attila-speech-recognition-toolkit-Soltau-Saon",
            "title": {
                "fragments": [],
                "text": "The IBM Attila speech recognition toolkit"
            },
            "tldr": {
                "abstractSimilarityScore": 96,
                "text": "The design of IBM's Attila speech recognition toolkit is described, showing how the combination of a highly modular and efficient library of low-level C++ classes with simple interfaces, an interconnection layer implemented in a modern scripting language (Python), and a standardized collection of scripts for system-building produce a flexible and scalable toolkit."
            },
            "venue": {
                "fragments": [],
                "text": "2010 IEEE Spoken Language Technology Workshop"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1743961"
                        ],
                        "name": "David Rybach",
                        "slug": "David-Rybach",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Rybach",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David Rybach"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3165395"
                        ],
                        "name": "Christian Gollan",
                        "slug": "Christian-Gollan",
                        "structuredName": {
                            "firstName": "Christian",
                            "lastName": "Gollan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christian Gollan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2280399"
                        ],
                        "name": "G. Heigold",
                        "slug": "G.-Heigold",
                        "structuredName": {
                            "firstName": "Georg",
                            "lastName": "Heigold",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Heigold"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145878402"
                        ],
                        "name": "Bj\u00f6rn Hoffmeister",
                        "slug": "Bj\u00f6rn-Hoffmeister",
                        "structuredName": {
                            "firstName": "Bj\u00f6rn",
                            "lastName": "Hoffmeister",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bj\u00f6rn Hoffmeister"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2183134"
                        ],
                        "name": "J. L\u00f6\u00f6f",
                        "slug": "J.-L\u00f6\u00f6f",
                        "structuredName": {
                            "firstName": "Jonas",
                            "lastName": "L\u00f6\u00f6f",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. L\u00f6\u00f6f"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144490010"
                        ],
                        "name": "R. Schl\u00fcter",
                        "slug": "R.-Schl\u00fcter",
                        "structuredName": {
                            "firstName": "Ralf",
                            "lastName": "Schl\u00fcter",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Schl\u00fcter"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145322333"
                        ],
                        "name": "H. Ney",
                        "slug": "H.-Ney",
                        "structuredName": {
                            "firstName": "Hermann",
                            "lastName": "Ney",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Ney"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 126,
                                "start": 123
                            }
                        ],
                        "text": "Notable among these are: HTK [1], Julius [2] (both written in C), Sphinx-4 [3] (written in Java), and the RWTH ASR toolkit [4] (written in C++)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 17986018,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "90bbe026fa7acacd817f1962c758e2951f796bd5",
            "isKey": false,
            "numCitedBy": 110,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "We announce the public availability of the RWTH Aachen University speech recognition toolkit. The toolkit includes state of the art speech recognition technology for acoustic model training and decoding. Speaker adaptation, speaker adaptive training, unsupervised training, a finite state automata library, and an efficient tree search decoder are notable components. Comprehensive documentation, example setups for training and recognition, and a tutorial are provided to support newcomers."
            },
            "slug": "The-RWTH-aachen-university-open-source-speech-Rybach-Gollan",
            "title": {
                "fragments": [],
                "text": "The RWTH aachen university open source speech recognition system"
            },
            "tldr": {
                "abstractSimilarityScore": 54,
                "text": "The toolkit includes state of the art speech recognition technology for acoustic model training and decoding, and a finite state automata library, and an efficient tree search decoder are notable components."
            },
            "venue": {
                "fragments": [],
                "text": "INTERSPEECH"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "78659204"
                        ],
                        "name": "M. Mohri",
                        "slug": "M.-Mohri",
                        "structuredName": {
                            "firstName": "Mehryar",
                            "lastName": "Mohri",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Mohri"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145366908"
                        ],
                        "name": "Fernando C Pereira",
                        "slug": "Fernando-C-Pereira",
                        "structuredName": {
                            "firstName": "Fernando",
                            "lastName": "Pereira",
                            "middleNames": [
                                "C"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Fernando C Pereira"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145428168"
                        ],
                        "name": "M. Riley",
                        "slug": "M.-Riley",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Riley",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Riley"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 80,
                                "start": 76
                            }
                        ],
                        "text": "Our decoding-graph construction process is based on the recipe described in [22]; however, there are a number of differences."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 31,
                                "start": 27
                            }
                        ],
                        "text": "In the conventional recipe [22], the input symbols on the decoding graph correspond to context-dependent states (in our toolkit, these symbols are numeric and we call them pdf-ids)."
                    },
                    "intents": []
                }
            ],
            "corpusId": 644936,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a80a452e587bd7f06ece1be101d6775fcee0f7af",
            "isKey": false,
            "numCitedBy": 1040,
            "numCiting": 75,
            "paperAbstract": {
                "fragments": [],
                "text": "We survey the use of weighted finite-state transducers (WFSTs) in speech recognition. We show that WFSTs provide a common and natural representation for hidden Markov models (HMMs), context-dependency, pronunciation dictionaries, grammars, and alternative recognition outputs. Furthermore, general transducer operations combine these representations flexibly and efficiently. Weighted determinization and minimization algorithms optimize their time and space requirements, and a weight pushing algorithm distributes the weights along the paths of a weighted transducer optimally for speech recognition. As an example, we describe a North American Business News (NAB) recognition system built using these techniques that combines the HMMs, full cross-word triphones, a lexicon of 40 000 words, and a large trigram grammar into a single weighted transducer that is only somewhat larger than the trigram word grammar and that runs NAB in real-time on a very simple decoder. In another example, we show that the same techniques can be used to optimize lattices for second-pass recognition. In a third example, we show how general automata operations can be used to assemble lattices from different recognizers to improve recognition performance."
            },
            "slug": "Weighted-finite-state-transducers-in-speech-Mohri-Pereira",
            "title": {
                "fragments": [],
                "text": "Weighted finite-state transducers in speech recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 65,
                "text": "WFSTs provide a common and natural representation for hidden Markov models (HMMs), context-dependency, pronunciation dictionaries, grammars, and alternative recognition outputs, and general transducer operations combine these representations flexibly and efficiently."
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Speech Lang."
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1762744"
                        ],
                        "name": "A. Stolcke",
                        "slug": "A.-Stolcke",
                        "structuredName": {
                            "firstName": "Andreas",
                            "lastName": "Stolcke",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Stolcke"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 157,
                                "start": 153
                            }
                        ],
                        "text": "For building LMs from raw text, users may use the IRSTLM toolkit, for which we provide installation help, or a more fully-featured toolkit such as SRILM [21]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1988103,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "399da68d3b97218b6c80262df7963baa89dcc71b",
            "isKey": false,
            "numCitedBy": 4997,
            "numCiting": 37,
            "paperAbstract": {
                "fragments": [],
                "text": "SRILM is a collection of C++ libraries, executable programs, and helper scripts designed to allow both production of and experimentation with statistical language models for speech recognition and other applications. SRILM is freely available for noncommercial purposes. The toolkit supports creation and evaluation of a variety of language model types based on N-gram statistics, as well as several related tasks, such as statistical tagging and manipulation of N-best lists and word lattices. This paper summarizes the functionality of the toolkit and discusses its design and implementation, highlighting ease of rapid prototyping, reusability, and combinability of tools."
            },
            "slug": "SRILM-an-extensible-language-modeling-toolkit-Stolcke",
            "title": {
                "fragments": [],
                "text": "SRILM - an extensible language modeling toolkit"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "The functionality of the SRILM toolkit is summarized and its design and implementation is discussed, highlighting ease of rapid prototyping, reusability, and combinability of tools."
            },
            "venue": {
                "fragments": [],
                "text": "INTERSPEECH"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "102811815"
                        ],
                        "name": "Marcello Federico",
                        "slug": "Marcello-Federico",
                        "structuredName": {
                            "firstName": "Marcello",
                            "lastName": "Federico",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Marcello Federico"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1895952"
                        ],
                        "name": "N. Bertoldi",
                        "slug": "N.-Bertoldi",
                        "structuredName": {
                            "firstName": "Nicola",
                            "lastName": "Bertoldi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Bertoldi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3077970"
                        ],
                        "name": "M. Cettolo",
                        "slug": "M.-Cettolo",
                        "structuredName": {
                            "firstName": "Mauro",
                            "lastName": "Cettolo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Cettolo"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 52,
                                "start": 48
                            }
                        ],
                        "text": "In our recipes, we have used the IRSTLM toolkit [20] for purposes like LM pruning."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 34745880,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "93f6dd2c761fdeac0af6d2253d57834439d7794f",
            "isKey": false,
            "numCitedBy": 361,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "Research in speech recognition and machine translation is boosting the use of large scale n-gram language models. We present an open source toolkit that permits to efficiently handle language models with billions of n-grams on conventional machines. The IRSTLM toolkit supports distribution of ngram collection and smoothing over a computer cluster, language model compression through probability quantization, lazy-loading of huge language models from disk. IRSTLM has been so far successfully deployed with the Moses toolkit for statistical machine translation and with the FBK-irst speech recognition system. Efficiency of the tool is reported on a speech transcription task of Italian political speeches using a language model of 1.1 billion four-grams."
            },
            "slug": "IRSTLM:-an-open-source-toolkit-for-handling-large-Federico-Bertoldi",
            "title": {
                "fragments": [],
                "text": "IRSTLM: an open source toolkit for handling large scale language models"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "The IRSTLM toolkit supports distribution of ngram collection and smoothing over a computer cluster, language model compression through probability quantization, lazy-loading of huge language models from disk."
            },
            "venue": {
                "fragments": [],
                "text": "INTERSPEECH"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716393"
                        ],
                        "name": "P. Woodland",
                        "slug": "P.-Woodland",
                        "structuredName": {
                            "firstName": "Philip",
                            "lastName": "Woodland",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Woodland"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144687429"
                        ],
                        "name": "J. Odell",
                        "slug": "J.-Odell",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Odell",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Odell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144782065"
                        ],
                        "name": "V. Valtchev",
                        "slug": "V.-Valtchev",
                        "structuredName": {
                            "firstName": "V.",
                            "lastName": "Valtchev",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Valtchev"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145259603"
                        ],
                        "name": "S. Young",
                        "slug": "S.-Young",
                        "structuredName": {
                            "firstName": "Steve",
                            "lastName": "Young",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Young"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 148,
                                "start": 144
                            }
                        ],
                        "text": "The baseline results are reported in [24], which we refer to as \u201cBell\u201d (for Bell Labs, the authors\u2019 affiliation), and a HTK system described in [25]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 46206282,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d8e9bec33ce069e567479a6d1c122363021c4a57",
            "isKey": false,
            "numCitedBy": 295,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "HTK is a portable software toolkit for building speech recognition systems using continuous density hidden Markov models developed by the Cambridge University Speech Group. One particularly successful type of system uses mixture density tied-state triphones. We have used this technique for the 5 k/20 k word ARPA Wall Street Journal (WSJ) task. We have extended our approach from using word-internal gender independent modelling to use decision tree based state clustering, cross-word triphones and gender dependent models. Our current systems can be run with either bigram or trigram language models using a single pass dynamic network decoder. Systems based on these techniques were included in the November 1993 ARPA WSJ evaluation, and gave the lowest error rate reported on the 5 k word bigram, 5 k word trigram and 20 k word bigram \"hub\" tests and the second lowest error rate on the 20 k word trigram \"hub\" test.<<ETX>>"
            },
            "slug": "Large-vocabulary-continuous-speech-recognition-HTK-Woodland-Odell",
            "title": {
                "fragments": [],
                "text": "Large vocabulary continuous speech recognition using HTK"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "This work has extended the approach from using word-internal gender independent modelling to use decision tree based state clustering, cross-word triphones and gender dependent models, and gave the lowest error rate reported on the 5 k/20 k word bigram and 20 k word trigram \"hub\" tests."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of ICASSP '94. IEEE International Conference on Acoustics, Speech and Signal Processing"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145259603"
                        ],
                        "name": "S. Young",
                        "slug": "S.-Young",
                        "structuredName": {
                            "firstName": "Steve",
                            "lastName": "Young",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Young"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144687429"
                        ],
                        "name": "J. Odell",
                        "slug": "J.-Odell",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Odell",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Odell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716393"
                        ],
                        "name": "P. Woodland",
                        "slug": "P.-Woodland",
                        "structuredName": {
                            "firstName": "Philip",
                            "lastName": "Woodland",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Woodland"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 30,
                                "start": 26
                            }
                        ],
                        "text": "The conventional approach [19] is to have a single decision tree for each HMM-state of each phone, or for each phone, and to ask questions about the phones to the left and right; the questions are asked in a greedy way to maximize likelihood given a single-Gaussian model."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[19]), these would be specified by a human based on linguistic knowledge."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 16667309,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "618c54f2ee1ebffdb8dc8fc501166b01f8731496",
            "isKey": false,
            "numCitedBy": 749,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "The key problem to be faced when building a HMM-based continuous speech recogniser is maintaining the balance between model complexity and available training data. For large vocabulary systems requiring cross-word context dependent modelling, this is particularly acute since many such contexts will never occur in the training data. This paper describes a method of creating a tied-state continuous speech recognition system using a phonetic decision tree. This tree-based clustering is shown to lead to similar recognition performance to that obtained using an earlier data-driven approach but to have the additional advantage of providing a mapping for unseen triphones. State-tying is also compared with traditional model-based tying and shown to be clearly superior. Experimental results are presented for both the Resource Management and Wall Street Journal tasks."
            },
            "slug": "Tree-based-state-tying-for-high-accuracy-acoustic-Young-Odell",
            "title": {
                "fragments": [],
                "text": "Tree-based state tying for high accuracy acoustic modelling"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This paper describes a method of creating a tied-state continuous speech recognition system using a phonetic decision tree, which is shown to lead to similar recognition performance to that obtained using an earlier data-driven approach but to have the additional advantage of providing a mapping for unseen triphones."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1792214"
                        ],
                        "name": "Daniel Povey",
                        "slug": "Daniel-Povey",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Povey",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Daniel Povey"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1816892"
                        ],
                        "name": "L. Burget",
                        "slug": "L.-Burget",
                        "structuredName": {
                            "firstName": "Luk\u00e1\u0161",
                            "lastName": "Burget",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Burget"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1776245"
                        ],
                        "name": "Mohit Agarwal",
                        "slug": "Mohit-Agarwal",
                        "structuredName": {
                            "firstName": "Mohit",
                            "lastName": "Agarwal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mohit Agarwal"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2175315"
                        ],
                        "name": "Pinar Akyazi",
                        "slug": "Pinar-Akyazi",
                        "structuredName": {
                            "firstName": "Pinar",
                            "lastName": "Akyazi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Pinar Akyazi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2065586026"
                        ],
                        "name": "Kai Feng",
                        "slug": "Kai-Feng",
                        "structuredName": {
                            "firstName": "Kai",
                            "lastName": "Feng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kai Feng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2268620"
                        ],
                        "name": "Arnab Ghoshal",
                        "slug": "Arnab-Ghoshal",
                        "structuredName": {
                            "firstName": "Arnab",
                            "lastName": "Ghoshal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Arnab Ghoshal"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3075141"
                        ],
                        "name": "O. Glembek",
                        "slug": "O.-Glembek",
                        "structuredName": {
                            "firstName": "Ondrej",
                            "lastName": "Glembek",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Glembek"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46356878"
                        ],
                        "name": "N. Goel",
                        "slug": "N.-Goel",
                        "structuredName": {
                            "firstName": "Nagendra",
                            "lastName": "Goel",
                            "middleNames": [
                                "Kumar"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Goel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2245567"
                        ],
                        "name": "M. Karafi\u00e1t",
                        "slug": "M.-Karafi\u00e1t",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "Karafi\u00e1t",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Karafi\u00e1t"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3070896"
                        ],
                        "name": "A. Rastrow",
                        "slug": "A.-Rastrow",
                        "structuredName": {
                            "firstName": "Ariya",
                            "lastName": "Rastrow",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Rastrow"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1786323"
                        ],
                        "name": "R. Rose",
                        "slug": "R.-Rose",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Rose",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Rose"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35455336"
                        ],
                        "name": "Petr Schwarz",
                        "slug": "Petr-Schwarz",
                        "structuredName": {
                            "firstName": "Petr",
                            "lastName": "Schwarz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Petr Schwarz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152809214"
                        ],
                        "name": "Samuel Thomas",
                        "slug": "Samuel-Thomas",
                        "structuredName": {
                            "firstName": "Samuel",
                            "lastName": "Thomas",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Samuel Thomas"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "in [13]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 7645326,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8d73b5b6bbb93fdfb3974632b72930741cdedf46",
            "isKey": false,
            "numCitedBy": 304,
            "numCiting": 48,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "The-subspace-Gaussian-mixture-model-A-structured-Povey-Burget",
            "title": {
                "fragments": [],
                "text": "The subspace Gaussian mixture model - A structured model for speech recognition"
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Speech Lang."
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1792214"
                        ],
                        "name": "Daniel Povey",
                        "slug": "Daniel-Povey",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Povey",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Daniel Povey"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716393"
                        ],
                        "name": "P. Woodland",
                        "slug": "P.-Woodland",
                        "structuredName": {
                            "firstName": "Philip",
                            "lastName": "Woodland",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Woodland"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6787686,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6a3b8d6aaa38a8cbac71935b03560c79cc89f8c1",
            "isKey": false,
            "numCitedBy": 56,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes the application of a discriminative HMM parameter estimation technique called frame discrimination (FD), to medium and large vocabulary continuous speech recognition. Previous work has shown that FD training can give better results than maximum mutual information (MMI) training for small tasks. The use of FD for much larger tasks required the development of a technique to be able to rapidly find the most likely set of Gaussians for each frame in the system. Experiments on the resource management and North American business tasks show that FD training can give comparable improvements to MMI, but is less computationally intensive."
            },
            "slug": "Frame-discrimination-training-for-HMMs-for-large-Povey-Woodland",
            "title": {
                "fragments": [],
                "text": "Frame discrimination training for HMMs for large vocabulary speech recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "Experiments on the resource management and North American business tasks show that FD training can give comparable improvements to MMI, but is less computationally intensive."
            },
            "venue": {
                "fragments": [],
                "text": "1999 IEEE International Conference on Acoustics, Speech, and Signal Processing. Proceedings. ICASSP99 (Cat. No.99CH36258)"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2053149086"
                        ],
                        "name": "William Walker",
                        "slug": "William-Walker",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Walker",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "William Walker"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2353539"
                        ],
                        "name": "Paul Lamere",
                        "slug": "Paul-Lamere",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Lamere",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Paul Lamere"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "66229880"
                        ],
                        "name": "P. Kwok",
                        "slug": "P.-Kwok",
                        "structuredName": {
                            "firstName": "Philip",
                            "lastName": "Kwok",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Kwok"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1681921"
                        ],
                        "name": "B. Raj",
                        "slug": "B.-Raj",
                        "structuredName": {
                            "firstName": "Bhiksha",
                            "lastName": "Raj",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Raj"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153915824"
                        ],
                        "name": "Rita Singh",
                        "slug": "Rita-Singh",
                        "structuredName": {
                            "firstName": "Rita",
                            "lastName": "Singh",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Rita Singh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2166780"
                        ],
                        "name": "E. Gouv\u00eaa",
                        "slug": "E.-Gouv\u00eaa",
                        "structuredName": {
                            "firstName": "Evandro",
                            "lastName": "Gouv\u00eaa",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Gouv\u00eaa"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2053086761"
                        ],
                        "name": "Peter Wolf",
                        "slug": "Peter-Wolf",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Wolf",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Peter Wolf"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145319774"
                        ],
                        "name": "Joseph Woelfel",
                        "slug": "Joseph-Woelfel",
                        "structuredName": {
                            "firstName": "Joseph",
                            "lastName": "Woelfel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Joseph Woelfel"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 78,
                                "start": 75
                            }
                        ],
                        "text": "Notable among these are: HTK [1], Julius [2] (both written in C), Sphinx-4 [3] (written in Java), and the RWTH ASR toolkit [4] (written in C++)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14177520,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7d060fc04306580d8693e1335caf4c37ad83357b",
            "isKey": false,
            "numCitedBy": 516,
            "numCiting": 45,
            "paperAbstract": {
                "fragments": [],
                "text": "Sphinx-4 is a flexible, modular and pluggable framework to help foster new innovations in the core research of hidden Markov model (HMM) speech recognition systems. The design of Sphinx-4 is based on patterns that have emerged from the design of past systems as well as new requirements based on areas that researchers currently want to explore. To exercise this framework, and to provide researchers with a \"researchready\" system, Sphinx-4 also includes several implementations of both simple and state-of-the-art techniques. The framework and the implementations are all freely available via open source."
            },
            "slug": "Sphinx-4:-a-flexible-open-source-framework-for-Walker-Lamere",
            "title": {
                "fragments": [],
                "text": "Sphinx-4: a flexible open source framework for speech recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 84,
                "text": "Sphinx-4 is a flexible, modular and pluggable framework to help foster new innovations in the core research of hidden Markov model (HMM) speech recognition systems and to provide researchers with a \"researchready\" system."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1740397"
                        ],
                        "name": "M. Gales",
                        "slug": "M.-Gales",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Gales",
                            "middleNames": [
                                "John",
                                "Francis"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Gales"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 9241826,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2109f8f91301abec8497286160cd6b0f2e65ed05",
            "isKey": false,
            "numCitedBy": 1752,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract This paper examines the application of linear transformations for speaker and environmental adaptation in an HMM-based speech recognition system. In particular, transformations that are trained in a maximum likelihood sense on adaptation data are investigated. Only model-based linear transforms are considered, since, for linear transforms, they subsume the appropriate feature\u2013space transforms. The paper compares the two possible forms of model-based transforms: (i) unconstrained, where any combination of mean and variance transform may be used, and (ii) constrained, which requires the variance transform to have the same form as the mean transform. Re-estimation formulae for all appropriate cases of transform are given. This includes a new and efficient full variance transform and the extension of the constrained model\u2013space transform from the simple diagonal case to the full or block\u2013diagonal case. The constrained and unconstrained transforms are evaluated in terms of computational cost, recognition time efficiency, and use for speaker adaptive training. The recognition performance of the two model\u2013space transforms on a large vocabulary speech recognition task using incremental adaptation is investigated. In addition, initial experiments using the constrained model\u2013space transform for speaker adaptive training are detailed."
            },
            "slug": "Maximum-likelihood-linear-transformations-for-Gales",
            "title": {
                "fragments": [],
                "text": "Maximum likelihood linear transformations for HMM-based speech recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "The paper compares the two possible forms of model-based transforms: unconstrained, where any combination of mean and variance transform may be used, and constrained, which requires the variance transform to have the same form as the mean transform."
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Speech Lang."
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1905330"
                        ],
                        "name": "C. Leggetter",
                        "slug": "C.-Leggetter",
                        "structuredName": {
                            "firstName": "Chris",
                            "lastName": "Leggetter",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Leggetter"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716393"
                        ],
                        "name": "P. Woodland",
                        "slug": "P.-Woodland",
                        "structuredName": {
                            "firstName": "Philip",
                            "lastName": "Woodland",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Woodland"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 264,
                                "start": 260
                            }
                        ],
                        "text": "There is a single class AmSgmm that represents a whole collection of pdf\u2019s; unlike the GMM case there is no class that represents a single pdf of the SGMM. Similar to the GMM case, however, separate classes handle model estimation and speaker adaptation using fMLLR.\n4This is currently implemented only for fMLLR."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 13,
                                "start": 9
                            }
                        ],
                        "text": "For both MLLR and fMLLR, multiple transforms can be estimated using a regression tree [16]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 10,
                                "start": 6
                            }
                        ],
                        "text": "Both fMLLR and VTLN can be used for speaker adaptive training (SAT) of the acoustic models."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 349,
                                "start": 345
                            }
                        ],
                        "text": "The best result for conventional GMM system is achieved by a speaker-adaptively trained system that splices 9 frames (4 on each side of the current frame) and uses LDA to project down to 40 dimensions, together with MLLT. Comparable performance is achieved with an SGMM system trained on MFCC features (static +\u2206+\u2206\u2206) that uses speaker vectors and fMLLR adaptation (we have not yet tried the SGMM system on top of the better LDA-based features)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 93,
                                "start": 89
                            }
                        ],
                        "text": "We support both model-space adaptation using maximum likelihood linear regression (MLLR) [14] and feature-space adaptation using feature-space MLLR (fMLLR), also known as constrained MLLR [15]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 19,
                                "start": 15
                            }
                        ],
                        "text": "When a single fMLLR transform is needed, it can be used as an additional processing step in the feature pipeline."
                    },
                    "intents": []
                }
            ],
            "corpusId": 14708613,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ae4614f758dfa344a04b33377c96abc10d5eeda7",
            "isKey": true,
            "numCitedBy": 2593,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract A method of speaker adaptation for continuous density hidden Markov models (HMMs) is presented. An initial speaker-independent system is adapted to improve the modelling of a new speaker by updating the HMM parameters. Statistics are gathered from the available adaptation data and used to calculate a linear regression-based transformation for the mean vectors. The transformation matrices are calculated to maximize the likelihood of the adaptation data and can be implemented using the forward\u2013backward algorithm. By tying the transformations among a number of distributions, adaptation can be performed for distributions which are not represented in the training data. An important feature of the method is that arbitrary adaptation data can be used\u2014no special enrolment sentences are needed. Experiments have been performed on the ARPA RM1 database using an HMM system with cross-word triphones and mixture Gaussian output distributions. Results show that adaptation can be performed using as little as 11 s of adaptation data, and that as more data is used the adaptation performance improves. For example, using 40 adaptation utterances, a 37% reduction in error from the speaker-independent system was achieved with supervised adaptation and a 32% reduction in unsupervised mode."
            },
            "slug": "Maximum-likelihood-linear-regression-for-speaker-of-Leggetter-Woodland",
            "title": {
                "fragments": [],
                "text": "Maximum likelihood linear regression for speaker adaptation of continuous density hidden Markov models"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "An important feature of the method is that arbitrary adaptation data can be used\u2014no special enrolment sentences are needed and that as more data is used the adaptation performance improves."
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Speech Lang."
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1792214"
                        ],
                        "name": "Daniel Povey",
                        "slug": "Daniel-Povey",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Povey",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Daniel Povey"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1681543"
                        ],
                        "name": "G. Zweig",
                        "slug": "G.-Zweig",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Zweig",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Zweig"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1723644"
                        ],
                        "name": "A. Acero",
                        "slug": "A.-Acero",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Acero",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Acero"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 3000061,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "820de1656c2ddd5009e92553bc2c2ca45fc674fb",
            "isKey": false,
            "numCitedBy": 8,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we describe a linear transform that we call an Exponential Transform (ET), which integrates aspects of CMLLR, VTLN and STC/MLLT into a single transform with jointly trained components. Its main advantage is that a very small number of speaker-specific parameters is required, thus enabling effective adaptation with small amounts of speaker specific data. Our formulation shares some characteristics of Vocal Tract Length Normalization (VTLN), and is intended as a substitute for VTLN. The key part of the transform is controlled by a single speaker-specific parameter that is analogous to a VTLN warp factor. The transform has non-speaker-specific parameters that are learned from data, and we find that the axis along which male and female speakers differ is automatically learned. The exponential transform has no explicit notion of frequency warping, which makes it applicable in principle to non-standard features such as those derived from neural nets, or when the key axes may not be male-female. Based on our experiments with standard MFCC features, it appears to perform better than conventional VTLN."
            },
            "slug": "Speaker-adaptation-with-an-Exponential-Transform-Povey-Zweig",
            "title": {
                "fragments": [],
                "text": "Speaker adaptation with an Exponential Transform"
            },
            "tldr": {
                "abstractSimilarityScore": 77,
                "text": "A linear transform that is called an Exponential Transform (ET), which integrates aspects of CMLLR, VTLN and STC/MLLT into a single transform with jointly trained components, and finds that the axis along which male and female speakers differ is automatically learned."
            },
            "venue": {
                "fragments": [],
                "text": "2011 IEEE Workshop on Automatic Speech Recognition & Understanding"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2116962108"
                        ],
                        "name": "Nagendra Kumar",
                        "slug": "Nagendra-Kumar",
                        "structuredName": {
                            "firstName": "Nagendra",
                            "lastName": "Kumar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nagendra Kumar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2730857"
                        ],
                        "name": "A. Andreou",
                        "slug": "A.-Andreou",
                        "structuredName": {
                            "firstName": "Andreas",
                            "lastName": "Andreou",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Andreou"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 274,
                                "start": 270
                            }
                        ],
                        "text": "delta) features of arbitrary order, splicing of arbitrary number of frames to the left or right of the current frame and linear projections of such high-dimensional features using linear discriminant analysis (LDA) or heteroscedastic linear discriminant analysis (HLDA) [11] are supported at the executable layer through simple command line tools."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 324,
                                "start": 320
                            }
                        ],
                        "text": "Cepstral mean and variance normalization, dynamic (i.e. delta) features of arbitrary order, splicing of arbitrary number of frames to the left or right of the current frame and linear projections of such high-dimensional features using linear discriminant analysis (LDA) or heteroscedastic linear discriminant analysis (HLDA) [11] are supported at the executable layer through simple command line tools."
                    },
                    "intents": []
                }
            ],
            "corpusId": 28539506,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3fd4b226ecf0465d952fac3cc7d161a583a7c10c",
            "isKey": false,
            "numCitedBy": 390,
            "numCiting": 44,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Heteroscedastic-discriminant-analysis-and-reduced-Kumar-Andreou",
            "title": {
                "fragments": [],
                "text": "Heteroscedastic discriminant analysis and reduced rank HMMs for improved speech recognition"
            },
            "venue": {
                "fragments": [],
                "text": "Speech Commun."
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1740276"
                        ],
                        "name": "Cyril Allauzen",
                        "slug": "Cyril-Allauzen",
                        "structuredName": {
                            "firstName": "Cyril",
                            "lastName": "Allauzen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Cyril Allauzen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145428168"
                        ],
                        "name": "M. Riley",
                        "slug": "M.-Riley",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Riley",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Riley"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1698491"
                        ],
                        "name": "J. Schalkwyk",
                        "slug": "J.-Schalkwyk",
                        "structuredName": {
                            "firstName": "Johan",
                            "lastName": "Schalkwyk",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Schalkwyk"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1718399"
                        ],
                        "name": "Wojciech Skut",
                        "slug": "Wojciech-Skut",
                        "structuredName": {
                            "firstName": "Wojciech",
                            "lastName": "Skut",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wojciech Skut"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "78659204"
                        ],
                        "name": "M. Mohri",
                        "slug": "M.-Mohri",
                        "structuredName": {
                            "firstName": "Mehryar",
                            "lastName": "Mohri",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Mohri"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 22,
                                "start": 19
                            }
                        ],
                        "text": "Kaldi provides a speech recognition system based on finite-state automata (using the freely available OpenFst), together with detailed documentation and a comprehensive set of scripts for building complete recognition systems."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 10869889,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "31e105cac80aa8f1646dfb22c95d035564ea4998",
            "isKey": false,
            "numCitedBy": 657,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe OpenFst, an open-source library for weighted finite-state transducers (WFSTs). OpenFst consists of a C++ template library with efficient WFST representations and over twenty-five operations for constructing, combining, optimizing, and searching them. At the shell-command level, there are corresponding transducer file representations and programs that operate on them. OpenFst is designed to be both very efficient in time and space and to scale to very large problems. \n \nThis library has key applications speech, image, and natural language processing, pattern and string matching, and machine learning. \n \nWe give an overview of the library, examples of its use, details of its design that allow customizing the labels, states, and weights and the lazy evaluation of many of its operations. \n \nFurther information and a download of the OpenFst library can be obtained from http://www.openfst.org."
            },
            "slug": "OpenFst:-A-General-and-Efficient-Weighted-Library-Allauzen-Riley",
            "title": {
                "fragments": [],
                "text": "OpenFst: A General and Efficient Weighted Finite-State Transducer Library"
            },
            "tldr": {
                "abstractSimilarityScore": 92,
                "text": "OpenFst is an open-source library for weighted finite-state transducers (WFSTs) that consists of a C++ template library with efficient WFST representations and over twenty-five operations for constructing, combining, optimizing, and searching them."
            },
            "venue": {
                "fragments": [],
                "text": "CIAA"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1740397"
                        ],
                        "name": "M. Gales",
                        "slug": "M.-Gales",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Gales",
                            "middleNames": [
                                "John",
                                "Francis"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Gales"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 134,
                                "start": 130
                            }
                        ],
                        "text": "Speaker adaptation and other linear transforms like maximum likelihood linear transform (MLLT) [12] or semi-tied covariance (STC) [13] are implemented by separate classes."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 8255228,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2b899462b71be626c475c5a372a353de7ec07832",
            "isKey": false,
            "numCitedBy": 633,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "There is normally a simple choice made in the form of the covariance matrix to be used with continuous-density HMMs. Either a diagonal covariance matrix is used, with the underlying assumption that elements of the feature vector are independent, or a full or block-diagonal matrix is used, where all or some of the correlations are explicitly modeled. Unfortunately when using full or block-diagonal covariance matrices there tends to be a dramatic increase in the number of parameters per Gaussian component, limiting the number of components which may be robustly estimated. This paper introduces a new form of covariance matrix which allows a few \"full\" covariance matrices to be shared over many distributions, whilst each distribution maintains its own \"diagonal\" covariance matrix. In contrast to other schemes which have hypothesized a similar form, this technique fits within the standard maximum-likelihood criterion used for training HMMs. The new form of covariance matrix is evaluated on a large-vocabulary speech-recognition task. In initial experiments the performance of the standard system was achieved using approximately half the number of parameters. Moreover, a 10% reduction in word error rate compared to a standard system can be achieved with less than a 1% increase in the number of parameters and little increase in recognition time."
            },
            "slug": "Semi-tied-covariance-matrices-for-hidden-Markov-Gales",
            "title": {
                "fragments": [],
                "text": "Semi-tied covariance matrices for hidden Markov models"
            },
            "tldr": {
                "abstractSimilarityScore": 50,
                "text": "A new form of covariance matrix which allows a few \"full\" covariance matrices to be shared over many distributions, whilst each distribution maintains its own \"diagonal\" covariancy matrix is introduced."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Speech Audio Process."
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2579762"
                        ],
                        "name": "W. Reichl",
                        "slug": "W.-Reichl",
                        "structuredName": {
                            "firstName": "Wolfgang",
                            "lastName": "Reichl",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Reichl"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145320076"
                        ],
                        "name": "W. Chou",
                        "slug": "W.-Chou",
                        "structuredName": {
                            "firstName": "Wu",
                            "lastName": "Chou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Chou"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 41,
                                "start": 37
                            }
                        ],
                        "text": "The baseline results are reported in [24], which we refer to as \u201cBell\u201d (for Bell Labs, the authors\u2019 affiliation), and a HTK system described in [25]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 16127534,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "626a71ca59d88964d9a08e40ba0c8e4be2ac3bb9",
            "isKey": false,
            "numCitedBy": 61,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "Methods of improving the robustness and accuracy of acoustic modeling using decision tree based state tying are described. A new two-level segmental clustering approach is devised which combines the decision tree based state tying with agglomerative clustering of rare acoustic phonetic events. In addition, a unified maximum likelihood framework for incorporating both phonetic and nonphonetic features in decision tree based state tying is presented. In contrast to other heuristic data separation methods, which often lead to training data depletion, a tagging scheme is used to attach various features of interest and the selection of these features in the decision tree is data driven. Finally, two methods of using multiple-mixture parameterization to improve the quality of the evaluation function in decision tree state tying are described. One method is based on the approach of k-means fitting and the other method is based on a novel use of a local multilevel optimal subtree. Both methods provide more accurate likelihood evaluation in decision tree clustering and are consistent with the structure of the decision tree. Experimental results on Wall Street Journal corpora demonstrate that the proposed approaches lead to a significant improvement in model quality and recognition performance."
            },
            "slug": "Robust-decision-tree-state-tying-for-continuous-Reichl-Chou",
            "title": {
                "fragments": [],
                "text": "Robust decision tree state tying for continuous speech recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 51,
                "text": "A new two-level segmental clustering approach is devised which combines the decision tree based state tying with agglomerative clustering of rare acoustic phonetic events."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Speech Audio Process."
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2109232944"
                        ],
                        "name": "Do Yeong Kim",
                        "slug": "Do-Yeong-Kim",
                        "structuredName": {
                            "firstName": "Do",
                            "lastName": "Kim",
                            "middleNames": [
                                "Yeong"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Do Yeong Kim"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145788741"
                        ],
                        "name": "S. Umesh",
                        "slug": "S.-Umesh",
                        "structuredName": {
                            "firstName": "Srinivasan",
                            "lastName": "Umesh",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Umesh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1740397"
                        ],
                        "name": "M. Gales",
                        "slug": "M.-Gales",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Gales",
                            "middleNames": [
                                "John",
                                "Francis"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Gales"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2171861"
                        ],
                        "name": "Thomas Hain",
                        "slug": "Thomas-Hain",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Hain",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thomas Hain"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716393"
                        ],
                        "name": "P. Woodland",
                        "slug": "P.-Woodland",
                        "structuredName": {
                            "firstName": "Philip",
                            "lastName": "Woodland",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Woodland"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 101,
                                "start": 97
                            }
                        ],
                        "text": "The toolkit also supports speaker normalization using a linear approximation to VTLN, similar to [17], or conventional feature-level VTLN, or a more generic approach for gender normalization which we call the \u201cexponential transform\u201d [18]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 10425838,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6bb862f92e222ad7b1bf03a14a1c564ba0f2e76b",
            "isKey": false,
            "numCitedBy": 48,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "Vocal tract length normalisation (VTLN) is a commonly used speaker normalisation approach. It is attractive compared to many normalisation schemes as it is typically dependent on only a single parameter, allowing the warp factors to be robustly calculated on little data. However, the scheme normally requires explicitly coding the data at multiple warp factors. Furthermore, it is only possible to approximate the Jacobian associated with the VTLN transformation. A new, simple, linear approximation to VTLN is described in this paper. This linear approximation allows the Jacobian to be exactly computed. It can also be highly efficient in terms of warp factor estimation and application of the warp factors. Both the linear and standard CUED VTLN schemes were evaluated in the 2003 BNE evaluation framework and found to yield similar performance. When used in system combination both VTLN schemes yielded slight gains over the baseline system."
            },
            "slug": "Using-VTLN-for-broadcast-news-transcription-Kim-Umesh",
            "title": {
                "fragments": [],
                "text": "Using VTLN for broadcast news transcription"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A new, simple, linear approximation to VTLN allows the Jacobian to be exactly computed and can be highly efficient in terms of warp factor estimation and application of the warp factors."
            },
            "venue": {
                "fragments": [],
                "text": "INTERSPEECH"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1687020"
                        ],
                        "name": "R. Gopinath",
                        "slug": "R.-Gopinath",
                        "structuredName": {
                            "firstName": "Ramesh",
                            "lastName": "Gopinath",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Gopinath"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 99,
                                "start": 95
                            }
                        ],
                        "text": "Speaker adaptation and other linear transforms like maximum likelihood linear transform (MLLT) [12] or semi-tied covariance (STC) [13] are implemented by separate classes."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 220,
                                "start": 216
                            }
                        ],
                        "text": "The best result for conventional GMM system is achieved by a speaker-adaptively trained system that splices 9 frames (4 on each side of the current frame) and uses LDA to project down to 40 dimensions, together with MLLT. Comparable performance is achieved with an SGMM system trained on MFCC features (static +\u2206+\u2206\u2206) that uses speaker vectors and fMLLR adaptation (we have not yet tried the SGMM system on top of the better LDA-based features)."
                    },
                    "intents": []
                }
            ],
            "corpusId": 2238572,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "df7614d47ab852439bed5d790f8b8e45b476aaeb",
            "isKey": false,
            "numCitedBy": 321,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "Maximum likelihood (ML) modeling of multiclass data for classification often suffers from the following problems: (a) data insufficiency implying overtrained or unreliable models, (b) large storage requirement, (c) large computational requirement and/or (d) the ML is not discriminating between classes. Sharing parameters across classes (or constraining the parameters) clearly tends to alleviate the first three problems. We show that in some cases it can also lead to better discrimination (as evidenced by reduced misclassification error). The parameters considered are the means and variances of the Gaussians and linear transformations of the feature space (or equivalently the Gaussian means). Some constraints on the parameters are shown to lead to linear discrimination analysis (a well-known result) while others are shown to lead to optimal feature spaces (a relatively new result). Applications of some of these ideas to the speech recognition problem are also given."
            },
            "slug": "Maximum-likelihood-modeling-with-Gaussian-for-Gopinath",
            "title": {
                "fragments": [],
                "text": "Maximum likelihood modeling with Gaussian distributions for classification"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "It is shown that in some cases sharing parameters across classes can also lead to better discrimination (as evidenced by reduced misclassification error), and some constraints on the parameters are shown to lead to linear discrimination analysis."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 1998 IEEE International Conference on Acoustics, Speech and Signal Processing, ICASSP '98 (Cat. No.98CH36181)"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48174548"
                        ],
                        "name": "Akinobu Lee",
                        "slug": "Akinobu-Lee",
                        "structuredName": {
                            "firstName": "Akinobu",
                            "lastName": "Lee",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Akinobu Lee"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1717105"
                        ],
                        "name": "Tatsuya Kawahara",
                        "slug": "Tatsuya-Kawahara",
                        "structuredName": {
                            "firstName": "Tatsuya",
                            "lastName": "Kawahara",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tatsuya Kawahara"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9243990"
                        ],
                        "name": "K. Shikano",
                        "slug": "K.-Shikano",
                        "structuredName": {
                            "firstName": "Kiyohiro",
                            "lastName": "Shikano",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Shikano"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 44,
                                "start": 41
                            }
                        ],
                        "text": "Notable among these are: HTK [1], Julius [2] (both written in C), Sphinx-4 [3] (written in Java), and the RWTH ASR toolkit [4] (written in C++)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1617469,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "eefd065ae942b03f5ff7199fce46d3392a136048",
            "isKey": false,
            "numCitedBy": 634,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "EUROSPEECH2001: the 7th European Conference on Speech Communication and Technology, September 3-7, 2001, Aalborg, Denmark."
            },
            "slug": "Julius-an-open-source-real-time-large-vocabulary-Lee-Kawahara",
            "title": {
                "fragments": [],
                "text": "Julius - an open source real-time large vocabulary recognition engine"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "EUROSPEECH2001: the 7th European Conference on Speech Communication and Technology, September 3-7, 2001, Aalborg, Denmark."
            },
            "venue": {
                "fragments": [],
                "text": "INTERSPEECH"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1704103"
                        ],
                        "name": "H. Malvar",
                        "slug": "H.-Malvar",
                        "structuredName": {
                            "firstName": "Henrique",
                            "lastName": "Malvar",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Malvar"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 27,
                                "start": 23
                            }
                        ],
                        "text": "Our FFT implementation [10] works for window lengths that are not powers of 2, and we also provide an implementation of split-radix FFT for 0-padded windows whose lengths are powers of 2."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 60927588,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "09e33003ba16184f1206810932c4eb0eeffe7601",
            "isKey": false,
            "numCitedBy": 1049,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Applications of transforms in signal processing signal processing in subbands lapped orthogonal transforms the modulated lapped transform heirarchical lapped transforms applications of lapped transforms."
            },
            "slug": "Signal-processing-with-lapped-transforms-Malvar",
            "title": {
                "fragments": [],
                "text": "Signal processing with lapped transforms"
            },
            "tldr": {
                "abstractSimilarityScore": 99,
                "text": "Applications of transforms in signal processing signal processing in subbands lapped orthogonal transforms the modulated lapped transform heirarchical lapped transforms applications of lapping transforms."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145259603"
                        ],
                        "name": "S. Young",
                        "slug": "S.-Young",
                        "structuredName": {
                            "firstName": "Steve",
                            "lastName": "Young",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Young"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1713807"
                        ],
                        "name": "Gunnar Evermann",
                        "slug": "Gunnar-Evermann",
                        "structuredName": {
                            "firstName": "Gunnar",
                            "lastName": "Evermann",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Gunnar Evermann"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1740397"
                        ],
                        "name": "M. Gales",
                        "slug": "M.-Gales",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Gales",
                            "middleNames": [
                                "John",
                                "Francis"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Gales"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2171861"
                        ],
                        "name": "Thomas Hain",
                        "slug": "Thomas-Hain",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Hain",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thomas Hain"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2066474202"
                        ],
                        "name": "Dan J. Kershaw",
                        "slug": "Dan-J.-Kershaw",
                        "structuredName": {
                            "firstName": "Dan",
                            "lastName": "Kershaw",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dan J. Kershaw"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1938928"
                        ],
                        "name": "G. Moore",
                        "slug": "G.-Moore",
                        "structuredName": {
                            "firstName": "Gareth",
                            "lastName": "Moore",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Moore"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144687429"
                        ],
                        "name": "J. Odell",
                        "slug": "J.-Odell",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Odell",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Odell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2965187"
                        ],
                        "name": "D. Ollason",
                        "slug": "D.-Ollason",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Ollason",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Ollason"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1792214"
                        ],
                        "name": "Daniel Povey",
                        "slug": "Daniel-Povey",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Povey",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Daniel Povey"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "69013545"
                        ],
                        "name": "Valtchev",
                        "slug": "Valtchev",
                        "structuredName": {
                            "firstName": "",
                            "lastName": "Valtchev",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Valtchev"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716393"
                        ],
                        "name": "P. Woodland",
                        "slug": "P.-Woodland",
                        "structuredName": {
                            "firstName": "Philip",
                            "lastName": "Woodland",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Woodland"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 32,
                                "start": 29
                            }
                        ],
                        "text": "Notable among these are: HTK [1], Julius [2] (both written in C), Sphinx-4 [3] (written in Java), and the RWTH ASR toolkit [4] (written in C++)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 86,
                                "start": 83
                            }
                        ],
                        "text": "Additionally, we support reading and writing of features in the format used by HTK [1]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 108,
                                "start": 105
                            }
                        ],
                        "text": "Table I shows the results of a context-dependent triphone system with mixture-of-Gaussian densities; the HTK baseline numbers are taken from [23] and the systems use essentially the same algorithms."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 88,
                                "start": 85
                            }
                        ],
                        "text": "While this is similar to the traditional approach followed in several toolkits (e.g. HTK), the Kaldi approach differs fundamentally in how we view the tools."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 17,
                                "start": 14
                            }
                        ],
                        "text": "Note that the HTK baseline is gender dependent while ours is not, so the comparison may not be entirely fair; we have other algorithms, such as VTLN to handle gender dependency, and chose not to build this type of gender-dependent system."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 120,
                                "start": 117
                            }
                        ],
                        "text": "The baseline results are reported in [24], which we refer to as \u201cBell\u201d (for Bell Labs, the authors\u2019 affiliation), and a HTK system described in [25]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 76,
                                "start": 73
                            }
                        ],
                        "text": "Our results are slightly better than the Bell Labs results, and although HTK\u2019s are better than ours, this difference can be attributed to the gender dependency."
                    },
                    "intents": []
                }
            ],
            "corpusId": 60164858,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "135328a4e2a33e17949b495ccd5fbdc87b2a7e3d",
            "isKey": false,
            "numCitedBy": 1071,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "The-HTK-book-version-3.4-Young-Evermann",
            "title": {
                "fragments": [],
                "text": "The HTK book version 3.4"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1740397"
                        ],
                        "name": "M. Gales",
                        "slug": "M.-Gales",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Gales",
                            "middleNames": [
                                "John",
                                "Francis"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Gales"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 90,
                                "start": 86
                            }
                        ],
                        "text": "For both MLLR and fMLLR, multiple transforms can be estimated using a regression tree [10]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 59786167,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "694694267738a1295361294f2631b5f8f0abbbb1",
            "isKey": false,
            "numCitedBy": 143,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "The-generation-and-use-of-regression-class-trees-Gales",
            "title": {
                "fragments": [],
                "text": "The generation and use of regression class trees for MLLR adaptation"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Finally, we provide some benchmarking results in section XI."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "JAMA homepage"
            },
            "venue": {
                "fragments": [],
                "text": "JAMA homepage"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 237,
                                "start": 233
                            }
                        ],
                        "text": "The toolkit also supports speaker normalization using a linear approximation to VTLN, similar to [17], or conventional feature-level VTLN, or a more generic approach for gender normalization which we call the \u201cexponential transform\u201d [18]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The exponential transform as a generic substitute for vtln"
            },
            "venue": {
                "fragments": [],
                "text": "Asru 2011 (submitted)"
            },
            "year": 2011
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Finally, we provide some benchmarking results in section XI."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "ATLAS homepage, http://math-atlas.sourceforge.net"
            },
            "venue": {
                "fragments": [],
                "text": "ATLAS homepage, http://math-atlas.sourceforge.net"
            }
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 9,
            "methodology": 12
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 26,
        "totalPages": 3
    },
    "page_url": "https://www.semanticscholar.org/paper/The-Kaldi-Speech-Recognition-Toolkit-Povey-Ghoshal/3a1a2cff2b70fb84a7ca7d97f8adcc5855851795?sort=total-citations"
}