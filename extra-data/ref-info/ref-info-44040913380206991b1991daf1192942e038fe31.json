{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145592791"
                        ],
                        "name": "Polina Kuznetsova",
                        "slug": "Polina-Kuznetsova",
                        "structuredName": {
                            "firstName": "Polina",
                            "lastName": "Kuznetsova",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Polina Kuznetsova"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2004053"
                        ],
                        "name": "Vicente Ordonez",
                        "slug": "Vicente-Ordonez",
                        "structuredName": {
                            "firstName": "Vicente",
                            "lastName": "Ordonez",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Vicente Ordonez"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39668247"
                        ],
                        "name": "A. Berg",
                        "slug": "A.-Berg",
                        "structuredName": {
                            "firstName": "Alexander",
                            "lastName": "Berg",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Berg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685538"
                        ],
                        "name": "Tamara L. Berg",
                        "slug": "Tamara-L.-Berg",
                        "structuredName": {
                            "firstName": "Tamara",
                            "lastName": "Berg",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tamara L. Berg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1699545"
                        ],
                        "name": "Yejin Choi",
                        "slug": "Yejin-Choi",
                        "structuredName": {
                            "firstName": "Yejin",
                            "lastName": "Choi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yejin Choi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 227,
                                "start": 57
                            }
                        ],
                        "text": "ically associate image with sentences that describe them (Farhadi et al., 2010; Kulkarni et al., 2011; Li et al., 2011; Yang et al., 2011; Mitchell et al., 2012; Kuznetsova et al., 2012; Gupta et al., 2012; Hodosh et al., 2013)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 255,
                                "start": 232
                            }
                        ],
                        "text": "\u2026be of great interest for people who aim to build systems that automatically associate image with sentences that describe them (Farhadi et al., 2010; Kulkarni et al., 2011; Li et al., 2011; Yang et al., 2011; Mitchell et al., 2012; Kuznetsova et al., 2012; Gupta et al., 2012; Hodosh et al., 2013)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 10315654,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2a0d0f6c5a69b264710df0230696f47c5918e2f2",
            "isKey": false,
            "numCitedBy": 319,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a holistic data-driven approach to image description generation, exploiting the vast amount of (noisy) parallel image data and associated natural language descriptions available on the web. More specifically, given a query image, we retrieve existing human-composed phrases used to describe visually similar images, then selectively combine those phrases to generate a novel description for the query image. We cast the generation process as constraint optimization problems, collectively incorporating multiple interconnected aspects of language composition for content planning, surface realization and discourse structure. Evaluation by human annotators indicates that our final system generates more semantically correct and linguistically appealing descriptions than two nontrivial baselines."
            },
            "slug": "Collective-Generation-of-Natural-Image-Descriptions-Kuznetsova-Ordonez",
            "title": {
                "fragments": [],
                "text": "Collective Generation of Natural Image Descriptions"
            },
            "tldr": {
                "abstractSimilarityScore": 88,
                "text": "A holistic data-driven approach to image description generation, exploiting the vast amount of (noisy) parallel image data and associated natural language descriptions available on the web to generate novel descriptions for query images."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2170746"
                        ],
                        "name": "M. Hodosh",
                        "slug": "M.-Hodosh",
                        "structuredName": {
                            "firstName": "Micah",
                            "lastName": "Hodosh",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Hodosh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2052690705"
                        ],
                        "name": "Peter Young",
                        "slug": "Peter-Young",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Young",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Peter Young"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3125805"
                        ],
                        "name": "Cyrus Rashtchian",
                        "slug": "Cyrus-Rashtchian",
                        "structuredName": {
                            "firstName": "Cyrus",
                            "lastName": "Rashtchian",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Cyrus Rashtchian"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3118681"
                        ],
                        "name": "J. Hockenmaier",
                        "slug": "J.-Hockenmaier",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Hockenmaier",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Hockenmaier"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "To do this, we use the heuristic cross-caption coreference algorithm of Hodosh et al. (2010) to identify coreferent NP chunks among the original five captions of each image."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "It contains and extends Hodosh et al. (2013)\u2019s corpus of 8,092 images."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 92,
                                "start": 72
                            }
                        ],
                        "text": "To do this, we use the heuristic cross-caption coreference algorithm of Hodosh et al. (2010) to identify coreferent NP chunks among the original five captions of each image.2 For each ambiguous head noun, we consider every non-singleton coreference chains it appears in, and reduce its synsets to\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 3196382,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "01915181692c821cc5a0a703047bd5b07c1f9af5",
            "isKey": false,
            "numCitedBy": 14,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "Recent work in computer vision has aimed to associate image regions with keywords describing the depicted entities, but actual image 'understanding' would also require identifying their attributes, relations and activities. Since this information cannot be conveyed by simple keywords, we have collected a corpus of \"action\" photos each associated with five descriptive captions. In order to obtain a consistent semantic representation for each image, we need to first identify which NPs refer to the same entities. We present three hierarchical Bayesian models for cross-caption coreference resolution. We have also created a simple ontology of entity classes that appear in images and evaluate how well these can be recovered."
            },
            "slug": "Cross-Caption-Coreference-Resolution-for-Automatic-Hodosh-Young",
            "title": {
                "fragments": [],
                "text": "Cross-Caption Coreference Resolution for Automatic Image Understanding"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A corpus of \"action\" photos each associated with five descriptive captions is collected and a simple ontology of entity classes that appear in images is created to evaluate how well these can be recovered."
            },
            "venue": {
                "fragments": [],
                "text": "CoNLL"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2110759501"
                        ],
                        "name": "Ankush Gupta",
                        "slug": "Ankush-Gupta",
                        "structuredName": {
                            "firstName": "Ankush",
                            "lastName": "Gupta",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ankush Gupta"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2169614"
                        ],
                        "name": "Yashaswi Verma",
                        "slug": "Yashaswi-Verma",
                        "structuredName": {
                            "firstName": "Yashaswi",
                            "lastName": "Verma",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yashaswi Verma"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694502"
                        ],
                        "name": "C. Jawahar",
                        "slug": "C.-Jawahar",
                        "structuredName": {
                            "firstName": "C.",
                            "lastName": "Jawahar",
                            "middleNames": [
                                "V."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Jawahar"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 227,
                                "start": 57
                            }
                        ],
                        "text": "ically associate image with sentences that describe them (Farhadi et al., 2010; Kulkarni et al., 2011; Li et al., 2011; Yang et al., 2011; Mitchell et al., 2012; Kuznetsova et al., 2012; Gupta et al., 2012; Hodosh et al., 2013)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 275,
                                "start": 257
                            }
                        ],
                        "text": "\u2026be of great interest for people who aim to build systems that automatically associate image with sentences that describe them (Farhadi et al., 2010; Kulkarni et al., 2011; Li et al., 2011; Yang et al., 2011; Mitchell et al., 2012; Kuznetsova et al., 2012; Gupta et al., 2012; Hodosh et al., 2013)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 16610834,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0ba87571341beaf6a5c9a30e049be7b1fc9a4c60",
            "isKey": false,
            "numCitedBy": 96,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "\n \n In this paper, we address the problem of automatically generating human-like descriptions for unseen images, given a collection of images and their corresponding human-generated descriptions. Previous attempts for this task mostly rely on visual clues and corpus statistics, but do not take much advantage of the semantic information inherent in the available image descriptions. Here, we present a generic method which benefits from all these three sources (i.e. visual clues, corpus statistics and available descriptions) simultaneously, and is capable of constructing novel descriptions. Our approach works on syntactically and linguistically motivated phrases extracted from the human descriptions. Experimental evaluations demonstrate that our formulation mostly generates lucid and semantically correct descriptions, and significantly outperforms the previous methods on automatic evaluation metrics. One of the significant advantages of our approach is that we can generate multiple interesting descriptions for an image. Unlike any previous work, we also test the applicability of our method on a large dataset containing complex images with rich descriptions.\n \n"
            },
            "slug": "Choosing-Linguistics-over-Vision-to-Describe-Images-Gupta-Verma",
            "title": {
                "fragments": [],
                "text": "Choosing Linguistics over Vision to Describe Images"
            },
            "tldr": {
                "abstractSimilarityScore": 74,
                "text": "This paper addresses the problem of automatically generating human-like descriptions for unseen images, given a collection of images and their corresponding human-generated descriptions, and presents a generic method which benefits from all three sources simultaneously, and is capable of constructing novel descriptions."
            },
            "venue": {
                "fragments": [],
                "text": "AAAI"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2170746"
                        ],
                        "name": "M. Hodosh",
                        "slug": "M.-Hodosh",
                        "structuredName": {
                            "firstName": "Micah",
                            "lastName": "Hodosh",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Hodosh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2052690705"
                        ],
                        "name": "Peter Young",
                        "slug": "Peter-Young",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Young",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Peter Young"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3118681"
                        ],
                        "name": "J. Hockenmaier",
                        "slug": "J.-Hockenmaier",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Hockenmaier",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Hockenmaier"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 296,
                                "start": 277
                            }
                        ],
                        "text": "\u2026be of great interest for people who aim to build systems that automatically associate image with sentences that describe them (Farhadi et al., 2010; Kulkarni et al., 2011; Li et al., 2011; Yang et al., 2011; Mitchell et al., 2012; Kuznetsova et al., 2012; Gupta et al., 2012; Hodosh et al., 2013)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 44,
                                "start": 24
                            }
                        ],
                        "text": "It contains and extends Hodosh et al. (2013)\u2019s corpus of 8,092 images."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 79,
                                "start": 59
                            }
                        ],
                        "text": "Almost all of the images that we add to those collected by Hodosh et al. (2013) have been made available under a Creative Commons license."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 227,
                                "start": 57
                            }
                        ],
                        "text": "ically associate image with sentences that describe them (Farhadi et al., 2010; Kulkarni et al., 2011; Li et al., 2011; Yang et al., 2011; Mitchell et al., 2012; Kuznetsova et al., 2012; Gupta et al., 2012; Hodosh et al., 2013)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 32,
                                "start": 12
                            }
                        ],
                        "text": "We followed Hodosh et al. (2013)\u2019s approach to collect images."
                    },
                    "intents": []
                }
            ],
            "corpusId": 928608,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9814df8bd00ba999c4d1e305a7e9bca579dc7c75",
            "isKey": false,
            "numCitedBy": 924,
            "numCiting": 102,
            "paperAbstract": {
                "fragments": [],
                "text": "The ability to associate images with natural language sentences that describe what is depicted in them is a hallmark of image understanding, and a prerequisite for applications such as sentence-based image search. In analogy to image search, we propose to frame sentence-based image annotation as the task of ranking a given pool of captions. We introduce a new benchmark collection for sentence-based image description and search, consisting of 8,000 images that are each paired with five different captions which provide clear descriptions of the salient entities and events. We introduce a number of systems that perform quite well on this task, even though they are only based on features that can be obtained with minimal supervision. Our results clearly indicate the importance of training on multiple captions per image, and of capturing syntactic (word order-based) and semantic features of these captions. We also perform an in-depth comparison of human and automatic evaluation metrics for this task, and propose strategies for collecting human judgments cheaply and on a very large scale, allowing us to augment our collection with additional relevance judgments of which captions describe which image. Our analysis shows that metrics that consider the ranked list of results for each query image or sentence are significantly more robust than metrics that are based on a single response per query. Moreover, our study suggests that the evaluation of ranking-based image description systems may be fully automated."
            },
            "slug": "Framing-Image-Description-as-a-Ranking-Task:-Data,-Hodosh-Young",
            "title": {
                "fragments": [],
                "text": "Framing Image Description as a Ranking Task: Data, Models and Evaluation Metrics (Extended Abstract)"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This work proposes to frame sentence-based image annotation as the task of ranking a given pool of captions, and introduces a new benchmark collection, consisting of 8,000 images that are each paired with five different captions which provide clear descriptions of the salient entities and events."
            },
            "venue": {
                "fragments": [],
                "text": "IJCAI"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145564333"
                        ],
                        "name": "Girish Kulkarni",
                        "slug": "Girish-Kulkarni",
                        "structuredName": {
                            "firstName": "Girish",
                            "lastName": "Kulkarni",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Girish Kulkarni"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3128210"
                        ],
                        "name": "Visruth Premraj",
                        "slug": "Visruth-Premraj",
                        "structuredName": {
                            "firstName": "Visruth",
                            "lastName": "Premraj",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Visruth Premraj"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2985883"
                        ],
                        "name": "S. Dhar",
                        "slug": "S.-Dhar",
                        "structuredName": {
                            "firstName": "Sagnik",
                            "lastName": "Dhar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Dhar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50341924"
                        ],
                        "name": "Siming Li",
                        "slug": "Siming-Li",
                        "structuredName": {
                            "firstName": "Siming",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Siming Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1699545"
                        ],
                        "name": "Yejin Choi",
                        "slug": "Yejin-Choi",
                        "structuredName": {
                            "firstName": "Yejin",
                            "lastName": "Choi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yejin Choi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39668247"
                        ],
                        "name": "A. Berg",
                        "slug": "A.-Berg",
                        "structuredName": {
                            "firstName": "Alexander",
                            "lastName": "Berg",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Berg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685538"
                        ],
                        "name": "Tamara L. Berg",
                        "slug": "Tamara-L.-Berg",
                        "structuredName": {
                            "firstName": "Tamara",
                            "lastName": "Berg",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tamara L. Berg"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 227,
                                "start": 57
                            }
                        ],
                        "text": "ically associate image with sentences that describe them (Farhadi et al., 2010; Kulkarni et al., 2011; Li et al., 2011; Yang et al., 2011; Mitchell et al., 2012; Kuznetsova et al., 2012; Gupta et al., 2012; Hodosh et al., 2013)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 171,
                                "start": 150
                            }
                        ],
                        "text": "\u2026be of great interest for people who aim to build systems that automatically associate image with sentences that describe them (Farhadi et al., 2010; Kulkarni et al., 2011; Li et al., 2011; Yang et al., 2011; Mitchell et al., 2012; Kuznetsova et al., 2012; Gupta et al., 2012; Hodosh et al., 2013)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 10116609,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "169b847e69c35cfd475eb4dcc561a24de11762ca",
            "isKey": false,
            "numCitedBy": 483,
            "numCiting": 56,
            "paperAbstract": {
                "fragments": [],
                "text": "We posit that visually descriptive language offers computer vision researchers both information about the world, and information about how people describe the world. The potential benefit from this source is made more significant due to the enormous amount of language data easily available today. We present a system to automatically generate natural language descriptions from images that exploits both statistics gleaned from parsing large quantities of text data and recognition algorithms from computer vision. The system is very effective at producing relevant sentences for images. It also generates descriptions that are notably more true to the specific image content than previous work."
            },
            "slug": "Baby-talk:-Understanding-and-generating-simple-Kulkarni-Premraj",
            "title": {
                "fragments": [],
                "text": "Baby talk: Understanding and generating simple image descriptions"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A system to automatically generate natural language descriptions from images that exploits both statistics gleaned from parsing large quantities of text data and recognition algorithms from computer vision that is very effective at producing relevant sentences for images."
            },
            "venue": {
                "fragments": [],
                "text": "CVPR 2011"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143787583"
                        ],
                        "name": "Ali Farhadi",
                        "slug": "Ali-Farhadi",
                        "structuredName": {
                            "firstName": "Ali",
                            "lastName": "Farhadi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ali Farhadi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1888731"
                        ],
                        "name": "Mohsen Hejrati",
                        "slug": "Mohsen-Hejrati",
                        "structuredName": {
                            "firstName": "Mohsen",
                            "lastName": "Hejrati",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mohsen Hejrati"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "21160985"
                        ],
                        "name": "M. Sadeghi",
                        "slug": "M.-Sadeghi",
                        "structuredName": {
                            "firstName": "Mohammad",
                            "lastName": "Sadeghi",
                            "middleNames": [
                                "Amin"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Sadeghi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2052690705"
                        ],
                        "name": "Peter Young",
                        "slug": "Peter-Young",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Young",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Peter Young"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3125805"
                        ],
                        "name": "Cyrus Rashtchian",
                        "slug": "Cyrus-Rashtchian",
                        "structuredName": {
                            "firstName": "Cyrus",
                            "lastName": "Rashtchian",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Cyrus Rashtchian"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3118681"
                        ],
                        "name": "J. Hockenmaier",
                        "slug": "J.-Hockenmaier",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Hockenmaier",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Hockenmaier"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144016256"
                        ],
                        "name": "D. Forsyth",
                        "slug": "D.-Forsyth",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Forsyth",
                            "middleNames": [
                                "Alexander"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Forsyth"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 227,
                                "start": 57
                            }
                        ],
                        "text": "ically associate image with sentences that describe them (Farhadi et al., 2010; Kulkarni et al., 2011; Li et al., 2011; Yang et al., 2011; Mitchell et al., 2012; Kuznetsova et al., 2012; Gupta et al., 2012; Hodosh et al., 2013)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 170,
                                "start": 150
                            }
                        ],
                        "text": "\u2026that they should also be of great interest for people who aim to build systems that automatically associate image with sentences that describe them (Farhadi et al., 2010; Kulkarni et al., 2011; Li et al., 2011; Yang et al., 2011; Mitchell et al., 2012; Kuznetsova et al., 2012; Gupta et al., 2012;\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 13272863,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "eaaed23a2d94feb2f1c3ff22a25777c7a78f3141",
            "isKey": false,
            "numCitedBy": 986,
            "numCiting": 40,
            "paperAbstract": {
                "fragments": [],
                "text": "Humans can prepare concise descriptions of pictures, focusing on what they find important. We demonstrate that automatic methods can do so too. We describe a system that can compute a score linking an image to a sentence. This score can be used to attach a descriptive sentence to a given image, or to obtain images that illustrate a given sentence. The score is obtained by comparing an estimate of meaning obtained from the image to one obtained from the sentence. Each estimate of meaning comes from a discriminative procedure that is learned us-ingdata. We evaluate on a novel dataset consisting of human-annotated images. While our underlying estimate of meaning is impoverished, it is sufficient to produce very good quantitative results, evaluated with a novel score that can account for synecdoche."
            },
            "slug": "Every-Picture-Tells-a-Story:-Generating-Sentences-Farhadi-Hejrati",
            "title": {
                "fragments": [],
                "text": "Every Picture Tells a Story: Generating Sentences from Images"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "A system that can compute a score linking an image to a sentence, which can be used to attach a descriptive sentence to a given image, or to obtain images that illustrate a given sentence."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49501003"
                        ],
                        "name": "Margaret Mitchell",
                        "slug": "Margaret-Mitchell",
                        "structuredName": {
                            "firstName": "Margaret",
                            "lastName": "Mitchell",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Margaret Mitchell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34176020"
                        ],
                        "name": "Jesse Dodge",
                        "slug": "Jesse-Dodge",
                        "structuredName": {
                            "firstName": "Jesse",
                            "lastName": "Dodge",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jesse Dodge"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46479604"
                        ],
                        "name": "Amit Goyal",
                        "slug": "Amit-Goyal",
                        "structuredName": {
                            "firstName": "Amit",
                            "lastName": "Goyal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Amit Goyal"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1721910"
                        ],
                        "name": "Kota Yamaguchi",
                        "slug": "Kota-Yamaguchi",
                        "structuredName": {
                            "firstName": "Kota",
                            "lastName": "Yamaguchi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kota Yamaguchi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1714215"
                        ],
                        "name": "K. Stratos",
                        "slug": "K.-Stratos",
                        "structuredName": {
                            "firstName": "Karl",
                            "lastName": "Stratos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Stratos"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1682965"
                        ],
                        "name": "Xufeng Han",
                        "slug": "Xufeng-Han",
                        "structuredName": {
                            "firstName": "Xufeng",
                            "lastName": "Han",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xufeng Han"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40614240"
                        ],
                        "name": "Alyssa C. Mensch",
                        "slug": "Alyssa-C.-Mensch",
                        "structuredName": {
                            "firstName": "Alyssa",
                            "lastName": "Mensch",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alyssa C. Mensch"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39668247"
                        ],
                        "name": "A. Berg",
                        "slug": "A.-Berg",
                        "structuredName": {
                            "firstName": "Alexander",
                            "lastName": "Berg",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Berg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685538"
                        ],
                        "name": "Tamara L. Berg",
                        "slug": "Tamara-L.-Berg",
                        "structuredName": {
                            "firstName": "Tamara",
                            "lastName": "Berg",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tamara L. Berg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1722360"
                        ],
                        "name": "Hal Daum\u00e9",
                        "slug": "Hal-Daum\u00e9",
                        "structuredName": {
                            "firstName": "Hal",
                            "lastName": "Daum\u00e9",
                            "middleNames": [],
                            "suffix": "III"
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hal Daum\u00e9"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 227,
                                "start": 57
                            }
                        ],
                        "text": "ically associate image with sentences that describe them (Farhadi et al., 2010; Kulkarni et al., 2011; Li et al., 2011; Yang et al., 2011; Mitchell et al., 2012; Kuznetsova et al., 2012; Gupta et al., 2012; Hodosh et al., 2013)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 230,
                                "start": 209
                            }
                        ],
                        "text": "\u2026be of great interest for people who aim to build systems that automatically associate image with sentences that describe them (Farhadi et al., 2010; Kulkarni et al., 2011; Li et al., 2011; Yang et al., 2011; Mitchell et al., 2012; Kuznetsova et al., 2012; Gupta et al., 2012; Hodosh et al., 2013)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2972357,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "355de7460120ddc1150d9ce3756f9848983f7ff4",
            "isKey": false,
            "numCitedBy": 383,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper introduces a novel generation system that composes humanlike descriptions of images from computer vision detections. By leveraging syntactically informed word co-occurrence statistics, the generator filters and constrains the noisy detections output from a vision system to generate syntactic trees that detail what the computer vision system sees. Results show that the generation system outperforms state-of-the-art systems, automatically generating some of the most natural image descriptions to date."
            },
            "slug": "Midge:-Generating-Image-Descriptions-From-Computer-Mitchell-Dodge",
            "title": {
                "fragments": [],
                "text": "Midge: Generating Image Descriptions From Computer Vision Detections"
            },
            "tldr": {
                "abstractSimilarityScore": 81,
                "text": "A novel generation system that composes humanlike descriptions of images from computer vision detections by leveraging syntactically informed word co-occurrence statistics and automatically generating some of the most natural image descriptions to date."
            },
            "venue": {
                "fragments": [],
                "text": "EACL"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50341924"
                        ],
                        "name": "Siming Li",
                        "slug": "Siming-Li",
                        "structuredName": {
                            "firstName": "Siming",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Siming Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145564333"
                        ],
                        "name": "Girish Kulkarni",
                        "slug": "Girish-Kulkarni",
                        "structuredName": {
                            "firstName": "Girish",
                            "lastName": "Kulkarni",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Girish Kulkarni"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685538"
                        ],
                        "name": "Tamara L. Berg",
                        "slug": "Tamara-L.-Berg",
                        "structuredName": {
                            "firstName": "Tamara",
                            "lastName": "Berg",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tamara L. Berg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39668247"
                        ],
                        "name": "A. Berg",
                        "slug": "A.-Berg",
                        "structuredName": {
                            "firstName": "Alexander",
                            "lastName": "Berg",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Berg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1699545"
                        ],
                        "name": "Yejin Choi",
                        "slug": "Yejin-Choi",
                        "structuredName": {
                            "firstName": "Yejin",
                            "lastName": "Choi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yejin Choi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 227,
                                "start": 57
                            }
                        ],
                        "text": "ically associate image with sentences that describe them (Farhadi et al., 2010; Kulkarni et al., 2011; Li et al., 2011; Yang et al., 2011; Mitchell et al., 2012; Kuznetsova et al., 2012; Gupta et al., 2012; Hodosh et al., 2013)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 188,
                                "start": 173
                            }
                        ],
                        "text": "\u2026be of great interest for people who aim to build systems that automatically associate image with sentences that describe them (Farhadi et al., 2010; Kulkarni et al., 2011; Li et al., 2011; Yang et al., 2011; Mitchell et al., 2012; Kuznetsova et al., 2012; Gupta et al., 2012; Hodosh et al., 2013)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 10702193,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fbdbe747c6aa8b35b981d21e475ff1506a1bae66",
            "isKey": false,
            "numCitedBy": 319,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "Studying natural language, and especially how people describe the world around them can help us better understand the visual world. In turn, it can also help us in the quest to generate natural language that describes this world in a human manner. We present a simple yet effective approach to automatically compose image descriptions given computer vision based inputs and using web-scale n-grams. Unlike most previous work that summarizes or retrieves pre-existing text relevant to an image, our method composes sentences entirely from scratch. Experimental results indicate that it is viable to generate simple textual descriptions that are pertinent to the specific content of an image, while permitting creativity in the description -- making for more human-like annotations than previous approaches."
            },
            "slug": "Composing-Simple-Image-Descriptions-using-Web-scale-Li-Kulkarni",
            "title": {
                "fragments": [],
                "text": "Composing Simple Image Descriptions using Web-scale N-grams"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A simple yet effective approach to automatically compose image descriptions given computer vision based inputs and using web-scale n-grams, which indicates that it is viable to generate simple textual descriptions that are pertinent to the specific content of an image, while permitting creativity in the description -- making for more human-like annotations than previous approaches."
            },
            "venue": {
                "fragments": [],
                "text": "CoNLL"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1680292"
                        ],
                        "name": "P. Resnik",
                        "slug": "P.-Resnik",
                        "structuredName": {
                            "firstName": "Philip",
                            "lastName": "Resnik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Resnik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1752785,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "265be00bf112c6cb2fa3e8176bff8394a114dbde",
            "isKey": false,
            "numCitedBy": 3889,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a new measure of semantic similarity in an IS-A taxonomy, based on the notion of information content. Experimental evaluation suggests that the measure performs encouragingly well (a correlation of r = 0.79 with a benchmark set of human similarity judgments, with an upper bound of r = 0.90 for human subjects performing the same task), and significantly better than the traditional edge counting approach (r = 0.66)."
            },
            "slug": "Using-Information-Content-to-Evaluate-Semantic-in-a-Resnik",
            "title": {
                "fragments": [],
                "text": "Using Information Content to Evaluate Semantic Similarity in a Taxonomy"
            },
            "tldr": {
                "abstractSimilarityScore": 72,
                "text": "This paper presents a new measure of semantic similarity in an IS-A taxonomy, based on the notion of information content, which performs encouragingly well and is significantly better than the traditional edge counting approach."
            },
            "venue": {
                "fragments": [],
                "text": "IJCAI"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32914745"
                        ],
                        "name": "Daoud Clarke",
                        "slug": "Daoud-Clarke",
                        "structuredName": {
                            "firstName": "Daoud",
                            "lastName": "Clarke",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Daoud Clarke"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 209,
                                "start": 123
                            }
                        ],
                        "text": "More recently, asymmetric similarities have been proposed as more suitable for semantic inference tasks such as entailment (Weeds and Weir, 2003; Szpektor and Dagan, 2008; Clarke, 2009; Kotlerman et al., 2010)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7634844,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "38c5a728c57baa59907ee0890137b75a5269f4a7",
            "isKey": false,
            "numCitedBy": 79,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "We present the context-theoretic framework, which provides a set of rules for the nature of composition of meaning based on the philosophy of meaning as context. Principally, in the framework the composition of the meaning of words can be represented as multiplication of their representative vectors, where multiplication is distributive with respect to the vector space. \n \nWe discuss the applicability of the framework to a range of techniques in natural language processing, including subsequence matching, the lexical entailment model of Dagan et al. (2005), vector-based representations of taxonomies, statistical parsing and the representation of uncertainty in logical semantics."
            },
            "slug": "Context-theoretic-Semantics-for-Natural-Language:-Clarke",
            "title": {
                "fragments": [],
                "text": "Context-theoretic Semantics for Natural Language: an Overview"
            },
            "tldr": {
                "abstractSimilarityScore": 76,
                "text": "The context-theoretic framework is presented, which provides a set of rules for the nature of composition of meaning based on the philosophy of meaning as context, which can be represented as multiplication of their representative vectors, where multiplication is distributive with respect to the vector space."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34902160"
                        ],
                        "name": "Jeff Mitchell",
                        "slug": "Jeff-Mitchell",
                        "structuredName": {
                            "firstName": "Jeff",
                            "lastName": "Mitchell",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jeff Mitchell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1747893"
                        ],
                        "name": "Mirella Lapata",
                        "slug": "Mirella-Lapata",
                        "structuredName": {
                            "firstName": "Mirella",
                            "lastName": "Lapata",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mirella Lapata"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 129,
                                "start": 102
                            }
                        ],
                        "text": "Distributional word vectors can also be used to define the compositional similarity of longer strings (Mitchell and Lapata, 2010)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 26901423,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "745d86adca56ec50761591733e157f84cfb19671",
            "isKey": false,
            "numCitedBy": 930,
            "numCiting": 253,
            "paperAbstract": {
                "fragments": [],
                "text": "Vector-based models of word meaning have become increasingly popular in cognitive science. The appeal of these models lies in their ability to represent meaning simply by using distributional information under the assumption that words occurring within similar contexts are semantically similar. Despite their widespread use, vector-based models are typically directed at representing words in isolation, and methods for constructing representations for phrases or sentences have received little attention in the literature. This is in marked contrast to experimental evidence (e.g., in sentential priming) suggesting that semantic similarity is more complex than simply a relation between isolated words. This article proposes a framework for representing the meaning of word combinations in vector space. Central to our approach is vector composition, which we operationalize in terms of additive and multiplicative functions. Under this framework, we introduce a wide range of composition models that we evaluate empirically on a phrase similarity task."
            },
            "slug": "Composition-in-Distributional-Models-of-Semantics-Mitchell-Lapata",
            "title": {
                "fragments": [],
                "text": "Composition in Distributional Models of Semantics"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This article proposes a framework for representing the meaning of word combinations in vector space in terms of additive and multiplicative functions, and introduces a wide range of composition models that are evaluated empirically on a phrase similarity task."
            },
            "venue": {
                "fragments": [],
                "text": "Cogn. Sci."
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1718798"
                        ],
                        "name": "E. Gabrilovich",
                        "slug": "E.-Gabrilovich",
                        "structuredName": {
                            "firstName": "Evgeniy",
                            "lastName": "Gabrilovich",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Gabrilovich"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2309269"
                        ],
                        "name": "Shaul Markovitch",
                        "slug": "Shaul-Markovitch",
                        "structuredName": {
                            "firstName": "Shaul",
                            "lastName": "Markovitch",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shaul Markovitch"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5291693,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a9fee459ed211f53bfadef22e3ab774d0e927358",
            "isKey": false,
            "numCitedBy": 2319,
            "numCiting": 51,
            "paperAbstract": {
                "fragments": [],
                "text": "Computing semantic relatedness of natural language texts requires access to vast amounts of common-sense and domain-specific world knowledge. We propose Explicit Semantic Analysis (ESA), a novel method that represents the meaning of texts in a high-dimensional space of concepts derived from Wikipedia. We use machine learning techniques to explicitly represent the meaning of any text as a weighted vector of Wikipedia-based concepts. Assessing the relatedness of texts in this space amounts to comparing the corresponding vectors using conventional metrics (e.g., cosine). Compared with the previous state of the art, using ESA results in substantial improvements in correlation of computed relatedness scores with human judgments: from r = 0.56 to 0.75 for individual words and from r = 0.60 to 0.72 for texts. Importantly, due to the use of natural concepts, the ESA model is easy to explain to human users."
            },
            "slug": "Computing-Semantic-Relatedness-Using-Explicit-Gabrilovich-Markovitch",
            "title": {
                "fragments": [],
                "text": "Computing Semantic Relatedness Using Wikipedia-based Explicit Semantic Analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 50,
                "text": "This work proposes Explicit Semantic Analysis (ESA), a novel method that represents the meaning of texts in a high-dimensional space of concepts derived from Wikipedia that results in substantial improvements in correlation of computed relatedness scores with human judgments."
            },
            "venue": {
                "fragments": [],
                "text": "IJCAI"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2020379"
                        ],
                        "name": "Lili Kotlerman",
                        "slug": "Lili-Kotlerman",
                        "structuredName": {
                            "firstName": "Lili",
                            "lastName": "Kotlerman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lili Kotlerman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7465342"
                        ],
                        "name": "Ido Dagan",
                        "slug": "Ido-Dagan",
                        "structuredName": {
                            "firstName": "Ido",
                            "lastName": "Dagan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ido Dagan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1711977"
                        ],
                        "name": "Idan Szpektor",
                        "slug": "Idan-Szpektor",
                        "structuredName": {
                            "firstName": "Idan",
                            "lastName": "Szpektor",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Idan Szpektor"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1402141228"
                        ],
                        "name": "M. Zhitomirsky-Geffet",
                        "slug": "M.-Zhitomirsky-Geffet",
                        "structuredName": {
                            "firstName": "Maayan",
                            "lastName": "Zhitomirsky-Geffet",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Zhitomirsky-Geffet"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 208,
                                "start": 186
                            }
                        ],
                        "text": "More recently, asymmetric similarities have been proposed as more suitable for semantic inference tasks such as entailment (Weeds and Weir, 2003; Szpektor and Dagan, 2008; Clarke, 2009; Kotlerman et al., 2010)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 172,
                                "start": 149
                            }
                        ],
                        "text": "\u2026min(w(i),w \u2032(i))\n\u2211 i w(i)\nBal(w | w\u2032) = \u221a W(w | w\u2032)\u00d7 Lin(w,w\u2032)\nW(w | w\u2032) = \u2211\ni:w(i)>0\u2227w\u2032(i)>0 w(i)\u2211 i w(i)\nWe also use two publicly available resources that provide precomputed similarities, Kotlerman et al. (2010)\u2019s DIRECT noun and verb rules and Chklovski and Pantel (2004)\u2019s VERBOCEAN rules."
                    },
                    "intents": []
                }
            ],
            "corpusId": 7187022,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "daa9afe2865446b553c95c14ebc241288e7a87cb",
            "isKey": false,
            "numCitedBy": 233,
            "numCiting": 81,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract Distributional word similarity is most commonly perceived as a symmetric relation. Yet, directional relations are abundant in lexical semantics and in many Natural Language Processing (NLP) settings that require lexical inference, making symmetric similarity measures less suitable for their identification. This paper investigates the nature of directional (asymmetric) similarity measures that aim to quantify distributional feature inclusion. We identify desired properties of such measures for lexical inference, specify a particular measure based on Average Precision that addresses these properties, and demonstrate the empirical benefit of directional measures for two different NLP datasets."
            },
            "slug": "Directional-distributional-similarity-for-lexical-Kotlerman-Dagan",
            "title": {
                "fragments": [],
                "text": "Directional distributional similarity for lexical inference"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "This paper investigates the nature of directional (asymmetric) similarity measures that aim to quantify distributional feature inclusion, identifies desired properties of such measures for lexical inference, specifies a particular measure based on Average Precision that addresses these properties, and demonstrates the empirical benefit of directional measures for two different NLP datasets."
            },
            "venue": {
                "fragments": [],
                "text": "Natural Language Engineering"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8963527"
                        ],
                        "name": "Shachar Mirkin",
                        "slug": "Shachar-Mirkin",
                        "structuredName": {
                            "firstName": "Shachar",
                            "lastName": "Mirkin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shachar Mirkin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7465342"
                        ],
                        "name": "Ido Dagan",
                        "slug": "Ido-Dagan",
                        "structuredName": {
                            "firstName": "Ido",
                            "lastName": "Dagan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ido Dagan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1734246"
                        ],
                        "name": "Eyal Shnarch",
                        "slug": "Eyal-Shnarch",
                        "structuredName": {
                            "firstName": "Eyal",
                            "lastName": "Shnarch",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Eyal Shnarch"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 211,
                                "start": 192
                            }
                        ],
                        "text": "\u2026to lexical similarity (Section 2.1) are very effective at identifying which words are related to the same topic, and can provide useful features for systems that perform semantic inferences (Mirkin et al., 2009), but are not suited to capture precise entailments between complex expressions."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 149,
                                "start": 128
                            }
                        ],
                        "text": "tifying which words are related to the same topic, and can provide useful features for systems that perform semantic inferences (Mirkin et al., 2009), but are not suited to capture precise entailments between complex expressions."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2122915,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e5efcfe5b138f0380ae9796b7aedc393426d0ccc",
            "isKey": true,
            "numCitedBy": 30,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "Lexical-semantic resources are used extensively for applied semantic inference, yet a clear quantitative picture of their current utility and limitations is largely missing. We propose system- and application-independent evaluation and analysis methodologies for resources' performance, and systematically apply them to seven prominent resources. Our findings identify the currently limited recall of available resources, and indicate the potential to improve performance by examining non-standard relation types and by distilling the output of distributional methods. Further, our results stress the need to include auxiliary information regarding the lexical and logical contexts in which a lexical inference is valid, as well as its prior validity likelihood."
            },
            "slug": "Evaluating-the-Inferential-Utility-of-Resources-Mirkin-Dagan",
            "title": {
                "fragments": [],
                "text": "Evaluating the Inferential Utility of Lexical-Semantic Resources"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "The findings identify the currently limited recall of available resources, and indicate the potential to improve performance by examining non-standard relation types and by distilling the output of distributional methods."
            },
            "venue": {
                "fragments": [],
                "text": "EACL"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1750652"
                        ],
                        "name": "Jonathan Berant",
                        "slug": "Jonathan-Berant",
                        "structuredName": {
                            "firstName": "Jonathan",
                            "lastName": "Berant",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jonathan Berant"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7465342"
                        ],
                        "name": "Ido Dagan",
                        "slug": "Ido-Dagan",
                        "structuredName": {
                            "firstName": "Ido",
                            "lastName": "Dagan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ido Dagan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34508613"
                        ],
                        "name": "J. Goldberger",
                        "slug": "J.-Goldberger",
                        "structuredName": {
                            "firstName": "Jacob",
                            "lastName": "Goldberger",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Goldberger"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 55,
                                "start": 35
                            }
                        ],
                        "text": "The denotation graph is similar to Berant et al. (2012)\u2019s \u2018entailment graph\u2019, but differs from it in two ways: first, entailment relations in the denotation graph are defined extensionally in terms of the images described by the expressions at each node, and second, nodes in Berant et al.\u2019s\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "The denotation graph is similar to Berant et al. (2012)\u2019s \u2018entailment graph\u2019, but differs from it in two ways: first, entailment relations in the denotation graph"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 6890477,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "527921b29af545af6967715694244a232605c132",
            "isKey": false,
            "numCitedBy": 42,
            "numCiting": 68,
            "paperAbstract": {
                "fragments": [],
                "text": "Identifying entailment relations between predicates is an important part of applied semantic inference. In this article we propose a global inference algorithm that learns such entailment rules. First, we define a graph structure over predicates that represents entailment relations as directed edges. Then, we use a global transitivity constraint on the graph to learn the optimal set of edges, formulating the optimization problem as an Integer Linear Program. The algorithm is applied in a setting where, given a target concept, the algorithm learns on the fly all entailment rules between predicates that co-occur with this concept. Results show that our global algorithm improves performance over baseline algorithms by more than 10%."
            },
            "slug": "Learning-Entailment-Relations-by-Global-Graph-Berant-Dagan",
            "title": {
                "fragments": [],
                "text": "Learning Entailment Relations by Global Graph Structure Optimization"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "A global inference algorithm is proposed that learns on the fly all entailment rules between predicates that co-occur with this concept, and uses a global transitivity constraint on the graph to learn the optimal set of edges."
            },
            "venue": {
                "fragments": [],
                "text": "CL"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7607499"
                        ],
                        "name": "Yezhou Yang",
                        "slug": "Yezhou-Yang",
                        "structuredName": {
                            "firstName": "Yezhou",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yezhou Yang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1756655"
                        ],
                        "name": "C. L. Teo",
                        "slug": "C.-L.-Teo",
                        "structuredName": {
                            "firstName": "Ching",
                            "lastName": "Teo",
                            "middleNames": [
                                "Lik"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. L. Teo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1722360"
                        ],
                        "name": "Hal Daum\u00e9",
                        "slug": "Hal-Daum\u00e9",
                        "structuredName": {
                            "firstName": "Hal",
                            "lastName": "Daum\u00e9",
                            "middleNames": [],
                            "suffix": "III"
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hal Daum\u00e9"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1697493"
                        ],
                        "name": "Y. Aloimonos",
                        "slug": "Y.-Aloimonos",
                        "structuredName": {
                            "firstName": "Yiannis",
                            "lastName": "Aloimonos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Aloimonos"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 227,
                                "start": 57
                            }
                        ],
                        "text": "ically associate image with sentences that describe them (Farhadi et al., 2010; Kulkarni et al., 2011; Li et al., 2011; Yang et al., 2011; Mitchell et al., 2012; Kuznetsova et al., 2012; Gupta et al., 2012; Hodosh et al., 2013)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 207,
                                "start": 190
                            }
                        ],
                        "text": "\u2026be of great interest for people who aim to build systems that automatically associate image with sentences that describe them (Farhadi et al., 2010; Kulkarni et al., 2011; Li et al., 2011; Yang et al., 2011; Mitchell et al., 2012; Kuznetsova et al., 2012; Gupta et al., 2012; Hodosh et al., 2013)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1539668,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "76a1dca3a9c2b0229c1b12c95752dcf40dc95a11",
            "isKey": false,
            "numCitedBy": 356,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a sentence generation strategy that describes images by predicting the most likely nouns, verbs, scenes and prepositions that make up the core sentence structure. The input are initial noisy estimates of the objects and scenes detected in the image using state of the art trained detectors. As predicting actions from still images directly is unreliable, we use a language model trained from the English Gigaword corpus to obtain their estimates; together with probabilities of co-located nouns, scenes and prepositions. We use these estimates as parameters on a HMM that models the sentence generation process, with hidden nodes as sentence components and image detections as the emissions. Experimental results show that our strategy of combining vision and language produces readable and descriptive sentences compared to naive strategies that use vision alone."
            },
            "slug": "Corpus-Guided-Sentence-Generation-of-Natural-Images-Yang-Teo",
            "title": {
                "fragments": [],
                "text": "Corpus-Guided Sentence Generation of Natural Images"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "Experimental results show that the strategy of combining vision and language produces readable and descriptive sentences compared to naive strategies that use vision alone."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3257930"
                        ],
                        "name": "Bill MacCartney",
                        "slug": "Bill-MacCartney",
                        "structuredName": {
                            "firstName": "Bill",
                            "lastName": "MacCartney",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bill MacCartney"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144783904"
                        ],
                        "name": "Christopher D. Manning",
                        "slug": "Christopher-D.-Manning",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Manning",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christopher D. Manning"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "its of MacCartney and Manning (2008)\u2019s NatLog system, and allow us to construct large subsumption hierarchies over image descriptions, which we call denotation graphs."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5617715,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "523f420cb55d8070f565c87a50099a9a5b0b9206",
            "isKey": false,
            "numCitedBy": 142,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose an approach to natural language inference based on a model of natural logic, which identifies valid inferences by their lexical and syntactic features, without full semantic interpretation. We greatly extend past work in natural logic, which has focused solely on semantic containment and monotonicity, to incorporate both semantic exclusion and implicativity. Our system decomposes an inference problem into a sequence of atomic edits linking premise to hypothesis; predicts a lexical entailment relation for each edit using a statistical classifier; propagates these relations upward through a syntax tree according to semantic properties of intermediate nodes; and composes the resulting entailment relations across the edit sequence. We evaluate our system on the FraCaS test suite, and achieve a 27% reduction in error from previous work. We also show that hybridizing an existing RTE system with our natural logic system yields significant gains on the RTE3 test suite."
            },
            "slug": "Modeling-Semantic-Containment-and-Exclusion-in-MacCartney-Manning",
            "title": {
                "fragments": [],
                "text": "Modeling Semantic Containment and Exclusion in Natural Language Inference"
            },
            "tldr": {
                "abstractSimilarityScore": 81,
                "text": "This work proposes an approach to natural language inference based on a model of natural logic, which identifies valid inferences by their lexical and syntactic features, without full semantic interpretation, to incorporate both semantic exclusion and implicativity."
            },
            "venue": {
                "fragments": [],
                "text": "COLING"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2759903"
                        ],
                        "name": "F. Saric",
                        "slug": "F.-Saric",
                        "structuredName": {
                            "firstName": "Frane",
                            "lastName": "Saric",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Saric"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2472657"
                        ],
                        "name": "Goran Glavas",
                        "slug": "Goran-Glavas",
                        "structuredName": {
                            "firstName": "Goran",
                            "lastName": "Glavas",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Goran Glavas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2065433122"
                        ],
                        "name": "Mladen Karan",
                        "slug": "Mladen-Karan",
                        "structuredName": {
                            "firstName": "Mladen",
                            "lastName": "Karan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mladen Karan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143809437"
                        ],
                        "name": "J. \u0160najder",
                        "slug": "J.-\u0160najder",
                        "structuredName": {
                            "firstName": "Jan",
                            "lastName": "\u0160najder",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. \u0160najder"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1747163"
                        ],
                        "name": "B. D. Basic",
                        "slug": "B.-D.-Basic",
                        "structuredName": {
                            "firstName": "Bojana",
                            "lastName": "Basic",
                            "middleNames": [
                                "Dalbelo"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. D. Basic"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 12233462,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bfc214ce7ab5b101425e5cabd631176bb427adff",
            "isKey": false,
            "numCitedBy": 224,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes the two systems for determining the semantic similarity of short texts submitted to the SemEval 2012 Task 6. Most of the research on semantic similarity of textual content focuses on large documents. However, a fair amount of information is condensed into short text snippets such as social media posts, image captions, and scientific abstracts. We predict the human ratings of sentence similarity using a support vector regression model with multiple features measuring word-overlap similarity and syntax similarity. Out of 89 systems submitted, our two systems ranked in the top 5, for the three overall evaluation metrics used (overall Pearson -- 2nd and 3rd, normalized Pearson -- 1st and 3rd, weighted mean -- 2nd and 5th)."
            },
            "slug": "TakeLab:-Systems-for-Measuring-Semantic-Text-Saric-Glavas",
            "title": {
                "fragments": [],
                "text": "TakeLab: Systems for Measuring Semantic Text Similarity"
            },
            "tldr": {
                "abstractSimilarityScore": 74,
                "text": "The two systems for determining the semantic similarity of short texts submitted to the SemEval 2012 Task 6 ranked in the top 5, for the three overall evaluation metrics used."
            },
            "venue": {
                "fragments": [],
                "text": "*SEMEVAL"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2500077"
                        ],
                        "name": "Julie Weeds",
                        "slug": "Julie-Weeds",
                        "structuredName": {
                            "firstName": "Julie",
                            "lastName": "Weeds",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Julie Weeds"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35258592"
                        ],
                        "name": "David J. Weir",
                        "slug": "David-J.-Weir",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Weir",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David J. Weir"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 209,
                                "start": 123
                            }
                        ],
                        "text": "More recently, asymmetric similarities have been proposed as more suitable for semantic inference tasks such as entailment (Weeds and Weir, 2003; Szpektor and Dagan, 2008; Clarke, 2009; Kotlerman et al., 2010)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15205002,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d0f6af15c46a8f834f2d30ce21330cbf0b4a0397",
            "isKey": false,
            "numCitedBy": 143,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a general framework for distributional similarity based on the concepts of precision and recall. Different parameter settings within this framework approximate different existing similarity measures as well as many more which have, until now, been unexplored. We show that optimal parameter settings outperform two existing state-of-the-art similarity measures on two evaluation tasks for high and low frequency nouns."
            },
            "slug": "A-General-Framework-for-Distributional-Similarity-Weeds-Weir",
            "title": {
                "fragments": [],
                "text": "A General Framework for Distributional Similarity"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "It is shown that optimal parameter settings outperform two existing state-of-the-art similarity measures on two evaluation tasks for high and low frequency nouns."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2004053"
                        ],
                        "name": "Vicente Ordonez",
                        "slug": "Vicente-Ordonez",
                        "structuredName": {
                            "firstName": "Vicente",
                            "lastName": "Ordonez",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Vicente Ordonez"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145564333"
                        ],
                        "name": "Girish Kulkarni",
                        "slug": "Girish-Kulkarni",
                        "structuredName": {
                            "firstName": "Girish",
                            "lastName": "Kulkarni",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Girish Kulkarni"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685538"
                        ],
                        "name": "Tamara L. Berg",
                        "slug": "Tamara-L.-Berg",
                        "structuredName": {
                            "firstName": "Tamara",
                            "lastName": "Berg",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tamara L. Berg"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Coreference resolution has also been used for word sense disambiguation by Preiss (2001) and Hu and Liu (2011)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 21,
                                "start": 0
                            }
                        ],
                        "text": "Ordonez et al. (2011) harvested 1 million images and their user-generated captions from Flickr to create the SBU Captioned Photo Dataset."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14579301,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8e080b98efbe65c02a116439205ca2344b9f7cd4",
            "isKey": false,
            "numCitedBy": 734,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "We develop and demonstrate automatic image description methods using a large captioned photo collection. One contribution is our technique for the automatic collection of this new dataset \u2013 performing a huge number of Flickr queries and then filtering the noisy results down to 1 million images with associated visually relevant captions. Such a collection allows us to approach the extremely challenging problem of description generation using relatively simple non-parametric methods and produces surprisingly effective results. We also develop methods incorporating many state of the art, but fairly noisy, estimates of image content to produce even more pleasing results. Finally we introduce a new objective performance measure for image captioning."
            },
            "slug": "Im2Text:-Describing-Images-Using-1-Million-Ordonez-Kulkarni",
            "title": {
                "fragments": [],
                "text": "Im2Text: Describing Images Using 1 Million Captioned Photographs"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A new objective performance measure for image captioning is introduced and methods incorporating many state of the art, but fairly noisy, estimates of image content are developed to produce even more pleasing results."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153642390"
                        ],
                        "name": "David L. Chen",
                        "slug": "David-L.-Chen",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Chen",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David L. Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "83415753"
                        ],
                        "name": "W. Dolan",
                        "slug": "W.-Dolan",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Dolan",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Dolan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 169,
                                "start": 141
                            }
                        ],
                        "text": "To assess how the denotational similarities perform on a more established task and domain, we apply them to the 1500 sentence pairs from the MSR Video Description Corpus (Chen and Dolan, 2011) that were annotated for the SemEval 2012 Semantic Textual Similarity (STS) task (Agirre et al., 2012)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 192,
                                "start": 170
                            }
                        ],
                        "text": "To assess how the denotational similarities perform on a more established task and domain, we apply them to the 1500 sentence pairs from the MSR Video Description Corpus (Chen and Dolan, 2011) that were annotated for the SemEval 2012 Semantic Textual Similarity (STS) task (Agirre et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 51,
                                "start": 23
                            }
                        ],
                        "text": "Chen and Dolan (2011)\u2019s MSR Video Description Corpus (of which the STS data is a subset) is most similar to ours, but its curated part is significantly smaller."
                    },
                    "intents": []
                }
            ],
            "corpusId": 215717103,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "554a31ce91189cf6022ac677413ef2f8b9b40ca7",
            "isKey": false,
            "numCitedBy": 650,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "A lack of standard datasets and evaluation metrics has prevented the field of paraphrasing from making the kind of rapid progress enjoyed by the machine translation community over the last 15 years. We address both problems by presenting a novel data collection framework that produces highly parallel text data relatively inexpensively and on a large scale. The highly parallel nature of this data allows us to use simple n-gram comparisons to measure both the semantic adequacy and lexical dissimilarity of paraphrase candidates. In addition to being simple and efficient to compute, experiments show that these metrics correlate highly with human judgments."
            },
            "slug": "Collecting-Highly-Parallel-Data-for-Paraphrase-Chen-Dolan",
            "title": {
                "fragments": [],
                "text": "Collecting Highly Parallel Data for Paraphrase Evaluation"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A novel data collection framework is presented that produces highly parallel text data relatively inexpensively and on a large scale that allows for simple n-gram comparisons to measure both the semantic adequacy and lexical dissimilarity of paraphrase candidates."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2218418"
                        ],
                        "name": "Timothy Chklovski",
                        "slug": "Timothy-Chklovski",
                        "structuredName": {
                            "firstName": "Timothy",
                            "lastName": "Chklovski",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Timothy Chklovski"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1990190"
                        ],
                        "name": "P. Pantel",
                        "slug": "P.-Pantel",
                        "structuredName": {
                            "firstName": "Patrick",
                            "lastName": "Pantel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Pantel"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "(2010)\u2019s DIRECT noun and verb rules and Chklovski and Pantel (2004)\u2019s VERBOCEAN rules."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 13507979,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0c739b915d633cc3c162e4ef1e57b796c2dc2217",
            "isKey": false,
            "numCitedBy": 497,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "Broad-coverage repositories of semantic relations between verbs could benefit many NLP tasks. We present a semi-automatic method for extracting fine-grained semantic relations between verbs. We detect similarity, strength, antonymy, enablement, and temporal happens-before relations between pairs of strongly associated verbs using lexicosyntactic patterns over the Web. On a set of 29,165 strongly associated verb pairs, our extraction algorithm yielded 65.5% accuracy. Analysis of error types shows that on the relation strength we achieved 75% accuracy. We provide the resource, called VERBOCEAN, for download at http://semantics.isi.edu/ocean/."
            },
            "slug": "VerbOcean:-Mining-the-Web-for-Fine-Grained-Semantic-Chklovski-Pantel",
            "title": {
                "fragments": [],
                "text": "VerbOcean: Mining the Web for Fine-Grained Semantic Verb Relations"
            },
            "tldr": {
                "abstractSimilarityScore": 61,
                "text": "A semi-automatic method for extracting fine-grained semantic relations between verbs using lexicosyntactic patterns over the Web, which detects similarity, strength, antonymy, enablement, and temporal happens-before relations between pairs of strongly associated verbs."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35400286"
                        ],
                        "name": "Z. Harris",
                        "slug": "Z.-Harris",
                        "structuredName": {
                            "firstName": "Zellig",
                            "lastName": "Harris",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Z. Harris"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "similar meaning (Harris, 1954)."
                    },
                    "intents": []
                }
            ],
            "corpusId": 86680084,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "decd9bc0385612bdf936928206d83730718e737e",
            "isKey": false,
            "numCitedBy": 2640,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": "For the purposes of the present discussion, the term structure will be used in the following non-rigorous sense: A set of phonemes or a set of data is structured in respect to some feature, to the extent that we can form in terms of that feature some organized system of statements which describes the members of the set and their interrelations (at least up to some limit of complexity). In this sense, language can be structured in respect to various independent features. And whether it is structured (to more than a trivial extent) in respect to, say, regular historical change, social intercourse, meaning, or distribution - or to what extent it is structured in any of these respects - is a matter decidable by investigation. Here we will discuss how each language can be described in terms of a distributional structure, i.e. in terms of the occurrence of parts (ultimately sounds) relative to other parts, and how this description is complete without intrusion of other features such as history or meaning. It goes without saying that other studies of language - historical, psychological, etc.-are also possible, both in relation to distributional structure and independently of it."
            },
            "slug": "Distributional-Structure-Harris",
            "title": {
                "fragments": [],
                "text": "Distributional Structure"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This discussion will discuss how each language can be described in terms of a distributional structure, i.e. in Terms of the occurrence of parts relative to other parts, and how this description is complete without intrusion of other features such as history or meaning."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1981
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "37582951"
                        ],
                        "name": "Judita Preiss",
                        "slug": "Judita-Preiss",
                        "structuredName": {
                            "firstName": "Judita",
                            "lastName": "Preiss",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Judita Preiss"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 11684037,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "99b639deb392587f6619f5a0013486ca51729f3b",
            "isKey": false,
            "numCitedBy": 6,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a simple word sense disambiguation system equipped with the Kennedy and Boguraev (1996) anaphora resolution algorithm, evaluated on the Senseval-2 English all-words task. The system relies on the structure of the WordNet hierarchy to pick optimal senses for nouns in the text. Since anaphoric references are known to indicate the topic of the text (Boguraev et al., 1998), they may aid disambiguation."
            },
            "slug": "Anaphora-Resolution-with-Word-Sense-Disambiguation-Preiss",
            "title": {
                "fragments": [],
                "text": "Anaphora Resolution with Word Sense Disambiguation"
            },
            "tldr": {
                "abstractSimilarityScore": 93,
                "text": "A simple word sense disambiguation system equipped with the Kennedy and Boguraev (1996) anaphora resolution algorithm, evaluated on the Senseval-2 English all-words task."
            },
            "venue": {
                "fragments": [],
                "text": "*SEMEVAL"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1690956"
                        ],
                        "name": "Dekang Lin",
                        "slug": "Dekang-Lin",
                        "structuredName": {
                            "firstName": "Dekang",
                            "lastName": "Lin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dekang Lin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 126,
                                "start": 115
                            }
                        ],
                        "text": "lexical similarities of words, either via the cosine of the angle between them, or via other, more complex metrics (Lin, 1998)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5659557,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cc0c3033ea7d4e19e1f5ac71934759507e126162",
            "isKey": false,
            "numCitedBy": 4466,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "Similarity is an important and widely used concept. Previous definitions of similarity are tied to a particular application or a form of knowledge representation. We present an informationtheoretic definition of similarity that is applicable as long as there is a probabilistic model. We demonstrate how our definition can be used to measure the similarity in a number of different domains."
            },
            "slug": "An-Information-Theoretic-Definition-of-Similarity-Lin",
            "title": {
                "fragments": [],
                "text": "An Information-Theoretic Definition of Similarity"
            },
            "tldr": {
                "abstractSimilarityScore": 50,
                "text": "This work presents an informationtheoretic definition of similarity that is applicable as long as there is a probabilistic model and demonstrates how this definition can be used to measure the similarity in a number of different domains."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733049"
                        ],
                        "name": "Eneko Agirre",
                        "slug": "Eneko-Agirre",
                        "structuredName": {
                            "firstName": "Eneko",
                            "lastName": "Agirre",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Eneko Agirre"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46724030"
                        ],
                        "name": "Daniel Matthew Cer",
                        "slug": "Daniel-Matthew-Cer",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Cer",
                            "middleNames": [
                                "Matthew"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Daniel Matthew Cer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1700007"
                        ],
                        "name": "Mona T. Diab",
                        "slug": "Mona-T.-Diab",
                        "structuredName": {
                            "firstName": "Mona",
                            "lastName": "Diab",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mona T. Diab"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1403836100"
                        ],
                        "name": "A. Gonzalez-Agirre",
                        "slug": "A.-Gonzalez-Agirre",
                        "structuredName": {
                            "firstName": "Aitor",
                            "lastName": "Gonzalez-Agirre",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Gonzalez-Agirre"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 212,
                                "start": 193
                            }
                        ],
                        "text": "\u2026goal is to decide whether the hypothesis (a brief image caption) refers to the same image as the premises (four longer captions), and the recently introduced Semantic Textual Similarity task (Agirre et al., 2012), which can be viewed as a graded (rather than binary) version of paraphrase detection."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 293,
                                "start": 274
                            }
                        ],
                        "text": "To assess how the denotational similarities perform on a more established task and domain, we apply them to the 1500 sentence pairs from the MSR Video Description Corpus (Chen and Dolan, 2011) that were annotated for the SemEval 2012 Semantic Textual Similarity (STS) task (Agirre et al., 2012)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 248,
                                "start": 227
                            }
                        ],
                        "text": "tion task for our domain, where the goal is to decide whether the hypothesis (a brief image caption) refers to the same image as the premises (four longer captions), and the recently introduced Semantic Textual Similarity task (Agirre et al., 2012), which can be"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 12549805,
            "fieldsOfStudy": [
                "Computer Science",
                "Psychology"
            ],
            "id": "528fa9bb03644ba752fb9491be49b9dd1bce1d52",
            "isKey": false,
            "numCitedBy": 655,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "Semantic Textual Similarity (STS) measures the degree of semantic equivalence between two texts. This paper presents the results of the STS pilot task in Semeval. The training data contained 2000 sentence pairs from previously existing paraphrase datasets and machine translation evaluation resources. The test data also comprised 2000 sentences pairs for those datasets, plus two surprise datasets with 400 pairs from a different machine translation evaluation corpus and 750 pairs from a lexical resource mapping exercise. The similarity of pairs of sentences was rated on a 0-5 scale (low to high similarity) by human judges using Amazon Mechanical Turk, with high Pearson correlation scores, around 90%. 35 teams participated in the task, submitting 88 runs. The best results scored a Pearson correlation >80%, well above a simple lexical baseline that only scored a 31% correlation. This pilot task opens an exciting way ahead, although there are still open issues, specially the evaluation metric."
            },
            "slug": "SemEval-2012-Task-6:-A-Pilot-on-Semantic-Textual-Agirre-Cer",
            "title": {
                "fragments": [],
                "text": "SemEval-2012 Task 6: A Pilot on Semantic Textual Similarity"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "The results of the STS pilot task in Semeval open an exciting way ahead, although there are still open issues, specially the evaluation metric."
            },
            "venue": {
                "fragments": [],
                "text": "*SEMEVAL"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2122826660"
                        ],
                        "name": "Shangfeng Hu",
                        "slug": "Shangfeng-Hu",
                        "structuredName": {
                            "firstName": "Shangfeng",
                            "lastName": "Hu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shangfeng Hu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1706734"
                        ],
                        "name": "C. Liu",
                        "slug": "C.-Liu",
                        "structuredName": {
                            "firstName": "Chengfei",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Liu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Coreference resolution has also been used for word sense disambiguation by Preiss (2001) and Hu and Liu (2011). ating the denotation graph."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 9540743,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8806f821880da42c4dbf35e9c4c27a747ac99650",
            "isKey": false,
            "numCitedBy": 1,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "Word sense disambiguation (WSD) and coreference resolution are two fundamental tasks for natural language processing. Unfortunately, they are seldom studied together. In this paper, we propose to incorporate the coreference resolution technique into a word sense disambiguation system for improving disambiguation precision. Our work is based on the existing instance knowledge network (IKN) based approach for WSD. With the help of coreference resolution, we are able to connect related candidate dependency graphs at the candidate level and similarly the related instance graph patterns at the instance level in IKN together. Consequently, the contexts which can be considered for WSD are expanded and precision for WSD is improved. Based on Senseval-3 all-words task, we run extensive experiments by following the same experimental approach as the IKN based WSD. It turns out that each combined algorithm between the extended IKN WSD algorithm and one of the best five existing algorithms consistently outperforms the corresponding combined algorithm between the IKN WSD algorithm and the existing algorithm."
            },
            "slug": "Incorporating-Coreference-Resolution-into-Word-Hu-Liu",
            "title": {
                "fragments": [],
                "text": "Incorporating Coreference Resolution into Word Sense Disambiguation"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This work is based on the existing instance knowledge network (IKN) based approach for WSD and is able to connect related candidate dependency graphs at the candidate level and similarly the related instance graph patterns at the instance level in IKN together with the help of coreference resolution."
            },
            "venue": {
                "fragments": [],
                "text": "CICLing"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145507021"
                        ],
                        "name": "Daniel B\u00e4r",
                        "slug": "Daniel-B\u00e4r",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "B\u00e4r",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Daniel B\u00e4r"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1780779"
                        ],
                        "name": "Torsten Zesch",
                        "slug": "Torsten-Zesch",
                        "structuredName": {
                            "firstName": "Torsten",
                            "lastName": "Zesch",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Torsten Zesch"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1730400"
                        ],
                        "name": "Iryna Gurevych",
                        "slug": "Iryna-Gurevych",
                        "structuredName": {
                            "firstName": "Iryna",
                            "lastName": "Gurevych",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Iryna Gurevych"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 119,
                                "start": 101
                            }
                        ],
                        "text": "Table 5 shows experimental results for four models: DKPro is the off-the-shelf DKProSimilarity model (B\u00e4r et al., 2013)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 75,
                                "start": 58
                            }
                        ],
                        "text": "Baseline and Compositional Features Our starting point is Ba\u0308r et al. (2013)\u2019s DKPro Similarity, one of the top-performing models from the 2012 STS shared task, which is available and easily modified."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 118,
                                "start": 102
                            }
                        ],
                        "text": "Table 5 shows experimental results for four models: DKPro is the off-the-shelf DKProSimilarity model (Ba\u0308r et al., 2013)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 69,
                                "start": 51
                            }
                        ],
                        "text": "Table 5: Performance on the STS MSRvid task: DKPro (B\u00e4r et al., 2013) plus compositional (\u03a3,\u03a0) and/or denotational similarities (nPMI JK) from our corpus"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 8635289,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1448096699653d0dbd34edc352c07366e80c4f59",
            "isKey": true,
            "numCitedBy": 88,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "We present DKPro Similarity, an open source framework for text similarity. Our goal is to provide a comprehensive repository of text similarity measures which are implemented using standardized interfaces. DKPro Similarity comprises a wide variety of measures ranging from ones based on simple n-grams and common subsequences to high-dimensional vector comparisons and structural, stylistic, and phonetic measures. In order to promote the reproducibility of experimental results and to provide reliable, permanent experimental conditions for future studies, DKPro Similarity additionally comes with a set of full-featured experimental setups which can be run out-of-the-box and be used for future systems to built upon."
            },
            "slug": "DKPro-Similarity:-An-Open-Source-Framework-for-Text-B\u00e4r-Zesch",
            "title": {
                "fragments": [],
                "text": "DKPro Similarity: An Open Source Framework for Text Similarity"
            },
            "tldr": {
                "abstractSimilarityScore": 63,
                "text": "The goal is to provide a comprehensive repository of text similarity measures which are implemented using standardized interfaces and come with a set of full-featured experimental setups which can be run out-of-the-box and be used for future systems to built upon."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1711977"
                        ],
                        "name": "Idan Szpektor",
                        "slug": "Idan-Szpektor",
                        "structuredName": {
                            "firstName": "Idan",
                            "lastName": "Szpektor",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Idan Szpektor"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7465342"
                        ],
                        "name": "Ido Dagan",
                        "slug": "Ido-Dagan",
                        "structuredName": {
                            "firstName": "Ido",
                            "lastName": "Dagan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ido Dagan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 209,
                                "start": 123
                            }
                        ],
                        "text": "More recently, asymmetric similarities have been proposed as more suitable for semantic inference tasks such as entailment (Weeds and Weir, 2003; Szpektor and Dagan, 2008; Clarke, 2009; Kotlerman et al., 2010)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5522668,
            "fieldsOfStudy": [
                "Computer Science",
                "Business"
            ],
            "id": "d470bc09a6beb526e363ab994287a6bb80935520",
            "isKey": false,
            "numCitedBy": 122,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "Most work on unsupervised entailment rule acquisition focused on rules between templates with two variables, ignoring unary rules - entailment rules between templates with a single variable. In this paper we investigate two approaches for unsupervised learning of such rules and compare the proposed methods with a binary rule learning method. The results show that the learned unary rule-sets outperform the binary rule-set. In addition, a novel directional similarity measure for learning entailment, termed Balanced-Inclusion, is the best performing measure."
            },
            "slug": "Learning-Entailment-Rules-for-Unary-Templates-Szpektor-Dagan",
            "title": {
                "fragments": [],
                "text": "Learning Entailment Rules for Unary Templates"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The results show that the learned unary rule-sets outperform the binary rule-set and a novel directional similarity measure for learning entailment, termed Balanced-Inclusion, is the best performing measure."
            },
            "venue": {
                "fragments": [],
                "text": "COLING"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7465342"
                        ],
                        "name": "Ido Dagan",
                        "slug": "Ido-Dagan",
                        "structuredName": {
                            "firstName": "Ido",
                            "lastName": "Dagan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ido Dagan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2807469"
                        ],
                        "name": "Oren Glickman",
                        "slug": "Oren-Glickman",
                        "structuredName": {
                            "firstName": "Oren",
                            "lastName": "Glickman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Oren Glickman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712352"
                        ],
                        "name": "B. Magnini",
                        "slug": "B.-Magnini",
                        "structuredName": {
                            "firstName": "Bernardo",
                            "lastName": "Magnini",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Magnini"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 161,
                                "start": 143
                            }
                        ],
                        "text": "\u2026these inferences, we apply them to an approximate entailment task, which is loosely modeled after the Recognizing Textual Entailment problem (Dagan et al., 2006), and consists of deciding whether a brief caption h (the hypothesis) can describe the same image as a set of captions P = {p1,\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 153,
                                "start": 133
                            }
                        ],
                        "text": "ferences, we apply them to an approximate entailment task, which is loosely modeled after the Recognizing Textual Entailment problem (Dagan et al., 2006), and consists of deciding whether a brief caption h (the hypothesis) can describe the same image as a set of captions P = {p1, ."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 8587959,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "de794d50713ea5f91a7c9da3d72041e2f5ef8452",
            "isKey": false,
            "numCitedBy": 1762,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents the Third PASCAL Recognising Textual Entailment Challenge (RTE-3), providing an overview of the dataset creating methodology and the submitted systems. In creating this year's dataset, a number of longer texts were introduced to make the challenge more oriented to realistic scenarios. Additionally, a pool of resources was offered so that the participants could share common tools. A pilot task was also set up, aimed at differentiating unknown entailments from identified contradictions and providing justifications for overall system decisions. 26 participants submitted 44 runs, using different approaches and generally presenting new entailment models and achieving higher scores than in the previous challenges."
            },
            "slug": "The-PASCAL-Recognising-Textual-Entailment-Challenge-Dagan-Glickman",
            "title": {
                "fragments": [],
                "text": "The PASCAL Recognising Textual Entailment Challenge"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "This paper presents the Third PASCAL Recognising Textual Entailment Challenge (RTE-3), providing an overview of the dataset creating methodology and the submitted systems."
            },
            "venue": {
                "fragments": [],
                "text": "MLCW"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2426894"
                        ],
                        "name": "Michael Grubinger",
                        "slug": "Michael-Grubinger",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Grubinger",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael Grubinger"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1704149"
                        ],
                        "name": "Paul D. Clough",
                        "slug": "Paul-D.-Clough",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Clough",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Paul D. Clough"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2151194032"
                        ],
                        "name": "H. M\u00fcller",
                        "slug": "H.-M\u00fcller",
                        "structuredName": {
                            "firstName": "Henning",
                            "lastName": "M\u00fcller",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. M\u00fcller"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1879646"
                        ],
                        "name": "Thomas Deselaers",
                        "slug": "Thomas-Deselaers",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Deselaers",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thomas Deselaers"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 64,
                                "start": 41
                            }
                        ],
                        "text": "Instead of several independent captions, Grubinger et al. (2006)\u2019s IAPR TC-12 data set contains longer descriptions."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 18883184,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "381929a8187010f6db940a23d78731c8e694c56c",
            "isKey": false,
            "numCitedBy": 388,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we describe an image collection created for the CLEF cross-language image retrieval track (ImageCLEF). This image retrieval benchmark (referred to as the IAPR TC-12 Benchmark) has developed from an initiative started by the Technical Committee 12 (TC-12) of the International Association of Pattern Recognition (IAPR). The collection consists of 20,000 images from a private photographic image collection. The construction and composition of the IAPR TC-12 Benchmark is described, including its associated text captions which are expressed in multiple languages, making the collection well-suited for evaluating the effectiveness of both textbased and visual retrieval methods. We also discuss the current and expected uses of the collection, including its use to benchmark and compare different image retrieval systems in ImageCLEF 2006."
            },
            "slug": "The-IAPR-TC-12-Benchmark:-A-New-Evaluation-Resource-Grubinger-Clough",
            "title": {
                "fragments": [],
                "text": "The IAPR TC-12 Benchmark: A New Evaluation Resource for Visual Information Systems"
            },
            "tldr": {
                "abstractSimilarityScore": 56,
                "text": "An image collection created for the CLEF cross-language image retrieval track (ImageCLEF), including its associated text captions which are expressed in multiple languages, making the collection well-suited for evaluating the effectiveness of both textbased and visual retrieval methods."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2244184"
                        ],
                        "name": "Kenneth Ward Church",
                        "slug": "Kenneth-Ward-Church",
                        "structuredName": {
                            "firstName": "Kenneth",
                            "lastName": "Church",
                            "middleNames": [
                                "Ward"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kenneth Ward Church"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145165877"
                        ],
                        "name": "P. Hanks",
                        "slug": "P.-Hanks",
                        "structuredName": {
                            "firstName": "Patrick",
                            "lastName": "Hanks",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Hanks"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 186,
                                "start": 175
                            }
                        ],
                        "text": "In our domain of descriptive sentences, we can obtain more generic descriptions by simple syntactic and lexical operations \u03c9 \u2208 O \u2282 S \u00d7 S that preserve upward entailment, so that if \u03c9(s) = s\u2032, JsK \u2286 Js\u2032K."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 9558665,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "9e2caa39ac534744a180972a30a320ad0ae41ea3",
            "isKey": false,
            "numCitedBy": 4363,
            "numCiting": 44,
            "paperAbstract": {
                "fragments": [],
                "text": "The term word association is used in a very particular sense in the psycholinguistic literature. (Generally speaking, subjects respond quicker than normal to the word nurse if it follows a highly associated word such as doctor. ) We will extend the term to provide the basis for a statistical description of a variety of interesting linguistic phenomena, ranging from semantic relations of the doctor/nurse type (content word/content word) to lexico-syntactic co-occurrence constraints between verbs and prepositions (content word/function word). This paper will propose an objective measure based on the information theoretic notion of mutual information, for estimating word association norms from computer readable corpora. (The standard method of obtaining word association norms, testing a few thousand subjects on a few hundred words, is both costly and unreliable.) The proposed measure, the association ratio, estimates word association norms directly from computer readable corpora, making it possible to estimate norms for tens of thousands of words."
            },
            "slug": "Word-Association-Norms,-Mutual-Information-and-Church-Hanks",
            "title": {
                "fragments": [],
                "text": "Word Association Norms, Mutual Information and Lexicography"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "The proposed measure, the association ratio, estimates word association norms directly from computer readable corpora, making it possible to estimate norms for tens of thousands of words."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "52287177"
                        ],
                        "name": "David R. Dowty",
                        "slug": "David-R.-Dowty",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Dowty",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David R. Dowty"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40383053"
                        ],
                        "name": "R. Wall",
                        "slug": "R.-Wall",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Wall",
                            "middleNames": [
                                "E."
                            ],
                            "suffix": "Jr."
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Wall"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145840346"
                        ],
                        "name": "S. Peters",
                        "slug": "S.-Peters",
                        "structuredName": {
                            "firstName": "Stanley",
                            "lastName": "Peters",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Peters"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 241,
                                "start": 223
                            }
                        ],
                        "text": "Our approach is inspired by truth-conditional semantic theories in which the denotation of a declarative sentence is assumed to be the set of all situations or possible worlds in which the sentence is true (Montague, 1974; Dowty et al., 1981; Barwise and Perry, 1980)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 61127848,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "03380e7083807d3264472871dc0582036cf79479",
            "isKey": false,
            "numCitedBy": 884,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "1. Introduction.- 2. The Syntax and Semantics of Two Simple Languages.- I. The Language L0.- 1. Syntax of L0.- 2. Semantics of L0.- II. The Language L0E.- 1. Syntax of L0E.- 2. Semantics of L0E.- 3. Alternative Formulations of L0E and L0.- III. A Synopsis of Truth-Conditional Semantics.- IV. The Notion of Truth Relative to a Model.- V. Validity and Entailment Defined in Terms of Possible Models.- VI. Model Theory and Deductive Systems.- Exercises.- Note.- 3. First-Order Predicate Logic.- I. The Language L1.- 1. Syntax of L1.- 2. Semantics of L1.- II. The Language L1E.- 1. Syntax of L1E.- 2. Semantics of L1E.- Exercises.- Notes.- 4. A Higher-Order Type-Theoretic Language.- I. A Notational Variant of L1.- II. The Language Ltype.- 1. Syntax of Ltype.- 2. Semantics of Ltype.- III. Lambda Abstraction and the Language L?.- Exercises.- Notes.- 5. Tense and Modal Operators.- I. Tense Operators and Their Interpretation.- II. The Other Varieties of Modal Logic the Operators ? and ?.- III. Languages Containing Both Tense and Modal Operators: Coordinate Semantics.- Exercises.- Notes.- 6. Montague's Intensional Logic.- I. Compositionality and the Intension-Extension Distinction.- II. The Intensional Logic of PTQ.- 1. Syntax of IL.- 2. Semantics of IL.- III. Examples of 'Oblique Contexts' as Represented in IL.- IV. Some Unresolved Issues with Possible Worlds Semantics and Propositional Attitudes.- Notes.- 7. The Grammar of PTQ.- I. The Overall Organization of the PTQ Grammar.- 1. The Syntactic Categories of English in the PTQ Grammar.- 2. The Correspondence Between Categories of English and Types of IL.- II. Subject-Predicate and Determiner-Noun Rules.- III. Conjoined Sentences, Verb Phrases, and Term Phrases.- IV. Anaphoric Pronouns as Bound Variables Scope Ambiguities and Relative Clauses.- V. Be, Transitive Verbs, Meaning Postulates, and Non-Specific Readings.- VI. Adverbs and Infinitive Complement Verbs.- VII. De dicto Pronouns and Some Pronoun Problems.- VIII. Prepositions, Tenses, and Negation.- Exercises.- Notes.- 8. Montague's General Semiotic Program.- 9. An Annotated Bibliography of Further Work in Montague Semantics.- Appendix I: Index of Symbols.- Appendix II: Variable Type Conventions for Chapter 7.- Notes.- References.- Answers to Selected Problems and Exercises."
            },
            "slug": "Introduction-to-Montague-semantics-Dowty-Wall",
            "title": {
                "fragments": [],
                "text": "Introduction to Montague semantics"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This book discusses Montague's Intensional Logic, a Higher-Order Type-Theoretic Language, and some Unresolved Issues with Possible Worlds Semantics and Propositional Attitudes."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1980
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1720988"
                        ],
                        "name": "Joakim Nivre",
                        "slug": "Joakim-Nivre",
                        "structuredName": {
                            "firstName": "Joakim",
                            "lastName": "Nivre",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Joakim Nivre"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712813"
                        ],
                        "name": "Johan Hall",
                        "slug": "Johan-Hall",
                        "structuredName": {
                            "firstName": "Johan",
                            "lastName": "Hall",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Johan Hall"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145446170"
                        ],
                        "name": "Jens Nilsson",
                        "slug": "Jens-Nilsson",
                        "structuredName": {
                            "firstName": "Jens",
                            "lastName": "Nilsson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jens Nilsson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 185,
                                "start": 167
                            }
                        ],
                        "text": "Preprocessing and Linguistic Analysis We use the Linux spell checker, the OpenNLP tokenizer, POS tagger and chunker (http://opennlp. apache.org), and the Malt parser (Nivre et al., 2006) to analyze the captions."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 52,
                                "start": 32
                            }
                        ],
                        "text": "Although we use the Malt parser (Nivre et al., 2006) to identify subject-"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 51,
                                "start": 33
                            }
                        ],
                        "text": "Although we use the Malt parser (Nivre et al., 2006) to identify subjectverb-object dependencies, we have found it more accurate to develop deterministic heuristics and lexi-\ncal rules to identify the boundaries of complex (e.g. conjoined) NPs, allowing us to treat \u201ca man with red shoes and a white\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 46,
                                "start": 26
                            }
                        ],
                        "text": "org), and the Malt parser (Nivre et al., 2006) to analyze the captions."
                    },
                    "intents": []
                }
            ],
            "corpusId": 15430366,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ecf3a4cd2b2d721e823fd06b5c467c64e0fde5a8",
            "isKey": true,
            "numCitedBy": 613,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce MaltParser, a data-driven parser generator for dependency parsing. Given a treebank in dependency format, MaltParser can be used to induce a parser for the language of the treebank. Ma ..."
            },
            "slug": "MaltParser:-A-Data-Driven-Parser-Generator-for-Nivre-Hall",
            "title": {
                "fragments": [],
                "text": "MaltParser: A Data-Driven Parser-Generator for Dependency Parsing"
            },
            "tldr": {
                "abstractSimilarityScore": 87,
                "text": "MaltParser is introduced, a data-driven parser generator for dependency parsing given a treebank in dependency format and can be used to induce a parser for the language of the treebank."
            },
            "venue": {
                "fragments": [],
                "text": "LREC"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2697557"
                        ],
                        "name": "N. Cocchiarella",
                        "slug": "N.-Cocchiarella",
                        "structuredName": {
                            "firstName": "Nino",
                            "lastName": "Cocchiarella",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Cocchiarella"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152219342"
                        ],
                        "name": "J. Barwise",
                        "slug": "J.-Barwise",
                        "structuredName": {
                            "firstName": "Jon",
                            "lastName": "Barwise",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Barwise"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145386435"
                        ],
                        "name": "J. Perry",
                        "slug": "J.-Perry",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Perry",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Perry"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 124893762,
            "fieldsOfStudy": [
                "Philosophy",
                "Linguistics"
            ],
            "id": "319baebb5894d843d63a913647ec9a52801ba1b5",
            "isKey": false,
            "numCitedBy": 2195,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "In this provocative book, Barwise and Perry tackle the slippery subject of \"meaning, \" a subject that has long vexed linguists, language philosophers, and logicians."
            },
            "slug": "Situations-and-Attitudes.-Cocchiarella-Barwise",
            "title": {
                "fragments": [],
                "text": "Situations and Attitudes."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1983
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "118645635"
                        ],
                        "name": "R. Jorna",
                        "slug": "R.-Jorna",
                        "structuredName": {
                            "firstName": "Ren\u00e9",
                            "lastName": "Jorna",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Jorna"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "98076419"
                        ],
                        "name": "Van Engelen",
                        "slug": "Van-Engelen",
                        "structuredName": {
                            "firstName": "Van",
                            "lastName": "Engelen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Van Engelen"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 103,
                                "start": 90
                            }
                        ],
                        "text": "Restricting our attention to visually descriptive sentences, i.e. non-negative, episodic (Carlson, 2005) sentences that can be used to describe an image (Figure 1), we propose to instantiate the abstract notions of possible worlds or situations with concrete sets of images."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 23,
                                "start": 10
                            }
                        ],
                        "text": "This has led to the definition of vector-based distributional similarities, which represent each word w as a vector w derived from counts of w\u2019s co-occurrence with other words."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 63513789,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "84772baec268555a565c133b8de28cb1abbd0f48",
            "isKey": false,
            "numCitedBy": 11,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "The-encyclopedia-of-language-and-linguistics-Jorna-Engelen",
            "title": {
                "fragments": [],
                "text": "The encyclopedia of language and linguistics"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2005
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "corpusId": 47390681,
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Word Association Norms, Mutual Information, and Lexicography"
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 1989
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 93,
                                "start": 77
                            }
                        ],
                        "text": "Models All of our models are binary MaxEnt classifiers, trained using MALLET (McCallum, 2002)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Mallet: A machine learning for language toolkit"
            },
            "venue": {
                "fragments": [],
                "text": "http://www.cs.umass.edu/ mccallum/mallet."
            },
            "year": 2002
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "From image descriptions to visual denotations: New similarity metrics for semantic inference over event descriptions. To appear in TACL"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2014
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Formal philosophy: papers of Richard Montague"
            },
            "venue": {
                "fragments": [],
                "text": "Yale University Press, New Haven. Edited by Richmond H. Thomason."
            },
            "year": 1974
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 22,
            "methodology": 13
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 40,
        "totalPages": 4
    },
    "page_url": "https://www.semanticscholar.org/paper/From-image-descriptions-to-visual-denotations:-New-Young-Lai/44040913380206991b1991daf1192942e038fe31?sort=total-citations"
}