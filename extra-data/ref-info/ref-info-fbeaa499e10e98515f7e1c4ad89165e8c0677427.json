{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8218398"
                        ],
                        "name": "V. Lee",
                        "slug": "V.-Lee",
                        "structuredName": {
                            "firstName": "Victor",
                            "lastName": "Lee",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Lee"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7297702"
                        ],
                        "name": "Changkyu Kim",
                        "slug": "Changkyu-Kim",
                        "structuredName": {
                            "firstName": "Changkyu",
                            "lastName": "Kim",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Changkyu Kim"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1727275"
                        ],
                        "name": "J. Chhugani",
                        "slug": "J.-Chhugani",
                        "structuredName": {
                            "firstName": "Jatin",
                            "lastName": "Chhugani",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Chhugani"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1907053"
                        ],
                        "name": "M. Deisher",
                        "slug": "M.-Deisher",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Deisher",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Deisher"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2111926329"
                        ],
                        "name": "Daehyun Kim",
                        "slug": "Daehyun-Kim",
                        "structuredName": {
                            "firstName": "Daehyun",
                            "lastName": "Kim",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Daehyun Kim"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32661398"
                        ],
                        "name": "A. Nguyen",
                        "slug": "A.-Nguyen",
                        "structuredName": {
                            "firstName": "Anthony",
                            "lastName": "Nguyen",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Nguyen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143758120"
                        ],
                        "name": "N. Satish",
                        "slug": "N.-Satish",
                        "structuredName": {
                            "firstName": "Nadathur",
                            "lastName": "Satish",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Satish"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1711231"
                        ],
                        "name": "M. Smelyanskiy",
                        "slug": "M.-Smelyanskiy",
                        "structuredName": {
                            "firstName": "Mikhail",
                            "lastName": "Smelyanskiy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Smelyanskiy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3066815"
                        ],
                        "name": "Srinivas Chennupaty",
                        "slug": "Srinivas-Chennupaty",
                        "structuredName": {
                            "firstName": "Srinivas",
                            "lastName": "Chennupaty",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Srinivas Chennupaty"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3258280"
                        ],
                        "name": "Per Hammarlund",
                        "slug": "Per-Hammarlund",
                        "structuredName": {
                            "firstName": "Per",
                            "lastName": "Hammarlund",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Per Hammarlund"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50101920"
                        ],
                        "name": "Ronak Singhal",
                        "slug": "Ronak-Singhal",
                        "structuredName": {
                            "firstName": "Ronak",
                            "lastName": "Singhal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ronak Singhal"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145126868"
                        ],
                        "name": "P. Dubey",
                        "slug": "P.-Dubey",
                        "structuredName": {
                            "firstName": "Pradeep",
                            "lastName": "Dubey",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Dubey"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 10039635,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "94fd94b7ebcdd80e47706376aa0540cbeb009262",
            "isKey": false,
            "numCitedBy": 820,
            "numCiting": 75,
            "paperAbstract": {
                "fragments": [],
                "text": "Recent advances in computing have led to an explosion in the amount of data being generated. Processing the ever-growing data in a timely manner has made throughput computing an important aspect for emerging applications. Our analysis of a set of important throughput computing kernels shows that there is an ample amount of parallelism in these kernels which makes them suitable for today's multi-core CPUs and GPUs. In the past few years there have been many studies claiming GPUs deliver substantial speedups (between 10X and 1000X) over multi-core CPUs on these kernels. To understand where such large performance difference comes from, we perform a rigorous performance analysis and find that after applying optimizations appropriate for both CPUs and GPUs the performance gap between an Nvidia GTX280 processor and the Intel Core i7-960 processor narrows to only 2.5x on average. In this paper, we discuss optimization techniques for both CPU and GPU, analyze what architecture features contributed to performance differences between the two architectures, and recommend a set of architectural features which provide significant improvement in architectural efficiency for throughput kernels."
            },
            "slug": "Debunking-the-100X-GPU-vs.-CPU-myth:-an-evaluation-Lee-Kim",
            "title": {
                "fragments": [],
                "text": "Debunking the 100X GPU vs. CPU myth: an evaluation of throughput computing on CPU and GPU"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This paper discusses optimization techniques for both CPU and GPU, analyzes what architecture features contributed to performance differences between the two architectures, and recommends a set of architectural features which provide significant improvement in architectural efficiency for throughput kernels."
            },
            "venue": {
                "fragments": [],
                "text": "ISCA"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153589279"
                        ],
                        "name": "Honghoon Jang",
                        "slug": "Honghoon-Jang",
                        "structuredName": {
                            "firstName": "Honghoon",
                            "lastName": "Jang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Honghoon Jang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3250641"
                        ],
                        "name": "Anjin Park",
                        "slug": "Anjin-Park",
                        "structuredName": {
                            "firstName": "Anjin",
                            "lastName": "Park",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Anjin Park"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "37872761"
                        ],
                        "name": "K. Jung",
                        "slug": "K.-Jung",
                        "structuredName": {
                            "firstName": "Keechul",
                            "lastName": "Jung",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Jung"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 17999732,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fa5cf89c59b834ec7573673657c99c77f53f7add",
            "isKey": false,
            "numCitedBy": 142,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "Many algorithms for image processing and pattern recognition have recently been implemented on GPU (graphic processing unit) for faster computational times. However, the implementation using GPU encounters two problems. First, the programmer should master the fundamentals of the graphics shading languages that require the prior knowledge on computer graphics. Second, in a job which needs much cooperation between CPU and GPU, which is usual in image processings and pattern recognitions contrary to the graphics area, CPU should generate raw feature data for GPU processing as much as possible to effectively utilize GPU performance. This paper proposes more quick and efficient implementation of neural networks on both GPU and multi-core CPU. We use CUDA (compute unified device architecture) that can be easily programmed due to its simple C language-like style instead of GPU to solve the first problem. Moreover, OpenMP (Open Multi-Processing) is used to concurrently process multiple data with single instruction on multi-core CPU, which results ineffectively utilizing the memories of GPU. In the experiments, we implemented neural networks-based text detection system using the proposed architecture, and the computational times showed about 15 times faster than implementation using CPU and about 4 times faster than implementation on only GPU without OpenMP."
            },
            "slug": "Neural-Network-Implementation-Using-CUDA-and-OpenMP-Jang-Park",
            "title": {
                "fragments": [],
                "text": "Neural Network Implementation Using CUDA and OpenMP"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This paper proposes more quick and efficient implementation of neural networks on both GPU and multi-core CPU and uses CUDA (compute unified device architecture) that can be easily programmed due to its simple C language-like style instead of GPU to solve the first problem."
            },
            "venue": {
                "fragments": [],
                "text": "2008 Digital Image Computing: Techniques and Applications"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2979876"
                        ],
                        "name": "R. Raina",
                        "slug": "R.-Raina",
                        "structuredName": {
                            "firstName": "Rajat",
                            "lastName": "Raina",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Raina"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2070938295"
                        ],
                        "name": "Anand Madhavan",
                        "slug": "Anand-Madhavan",
                        "structuredName": {
                            "firstName": "Anand",
                            "lastName": "Madhavan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Anand Madhavan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34699434"
                        ],
                        "name": "A. Ng",
                        "slug": "A.-Ng",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Ng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Ng"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 392458,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e337c5e4c23999c36f64bcb33ebe6b284e1bcbf1",
            "isKey": false,
            "numCitedBy": 640,
            "numCiting": 42,
            "paperAbstract": {
                "fragments": [],
                "text": "The promise of unsupervised learning methods lies in their potential to use vast amounts of unlabeled data to learn complex, highly nonlinear models with millions of free parameters. We consider two well-known unsupervised learning models, deep belief networks (DBNs) and sparse coding, that have recently been applied to a flurry of machine learning applications (Hinton & Salakhutdinov, 2006; Raina et al., 2007). Unfortunately, current learning algorithms for both models are too slow for large-scale applications, forcing researchers to focus on smaller-scale models, or to use fewer training examples.\n In this paper, we suggest massively parallel methods to help resolve these problems. We argue that modern graphics processors far surpass the computational capabilities of multicore CPUs, and have the potential to revolutionize the applicability of deep unsupervised learning methods. We develop general principles for massively parallelizing unsupervised learning tasks using graphics processors. We show that these principles can be applied to successfully scaling up learning algorithms for both DBNs and sparse coding. Our implementation of DBN learning is up to 70 times faster than a dual-core CPU implementation for large models. For example, we are able to reduce the time required to learn a four-layer DBN with 100 million free parameters from several weeks to around a single day. For sparse coding, we develop a simple, inherently parallel algorithm, that leads to a 5 to 15-fold speedup over previous methods."
            },
            "slug": "Large-scale-deep-unsupervised-learning-using-Raina-Madhavan",
            "title": {
                "fragments": [],
                "text": "Large-scale deep unsupervised learning using graphics processors"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "It is argued that modern graphics processors far surpass the computational capabilities of multicore CPUs, and have the potential to revolutionize the applicability of deep unsupervised learning methods."
            },
            "venue": {
                "fragments": [],
                "text": "ICML '09"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1736801"
                        ],
                        "name": "Kyoungsu Oh",
                        "slug": "Kyoungsu-Oh",
                        "structuredName": {
                            "firstName": "Kyoungsu",
                            "lastName": "Oh",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kyoungsu Oh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "37872761"
                        ],
                        "name": "K. Jung",
                        "slug": "K.-Jung",
                        "structuredName": {
                            "firstName": "Keechul",
                            "lastName": "Jung",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Jung"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 12600784,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "80664dab16a1f18ce1998e38a03f080c5e98363a",
            "isKey": false,
            "numCitedBy": 358,
            "numCiting": 2,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "GPU-implementation-of-neural-networks-Oh-Jung",
            "title": {
                "fragments": [],
                "text": "GPU implementation of neural networks"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit."
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3111912"
                        ],
                        "name": "Navdeep Jaitly",
                        "slug": "Navdeep-Jaitly",
                        "structuredName": {
                            "firstName": "Navdeep",
                            "lastName": "Jaitly",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Navdeep Jaitly"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "14902530"
                        ],
                        "name": "P. Nguyen",
                        "slug": "P.-Nguyen",
                        "structuredName": {
                            "firstName": "Patrick",
                            "lastName": "Nguyen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Nguyen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "33666044"
                        ],
                        "name": "A. Senior",
                        "slug": "A.-Senior",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Senior",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Senior"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2657155"
                        ],
                        "name": "Vincent Vanhoucke",
                        "slug": "Vincent-Vanhoucke",
                        "structuredName": {
                            "firstName": "Vincent",
                            "lastName": "Vanhoucke",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Vincent Vanhoucke"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 78,
                                "start": 75
                            }
                        ],
                        "text": "The question then becomes whether to invest in GPU resources, or whether traditional CPUs can be made to perform fast enough that, using distributed computing, they will yield similar or superior scalability and performance."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 13521651,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a4eb9f4fad5c5a1935c6d0532e2c765ee29b0b37",
            "isKey": false,
            "numCitedBy": 239,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "The use of Deep Belief Networks (DBN) to pretrain Neural Networks has recently led to a resurgence in the use of Artificial Neural Network Hidden Markov Model (ANN/HMM) hybrid systems for Automatic Speech Recognition (ASR). In this paper we report results of a DBN-pretrained context-dependent ANN/HMM system trained on two datasets that are much larger than any reported previously with DBN-pretrained ANN/HMM systems 5870 hours of Voice Search and 1400 hours of YouTube data. On the first dataset, the pretrained ANN/HMM system outperforms the best Gaussian Mixture Model Hidden Markov Model (GMM/HMM) baseline, built with a much larger dataset by 3.7% absolute WER, while on the second dataset, it outperforms the GMM/HMM baseline by 4.7% absolute. Maximum Mutual Information (MMI) fine tuning and model combination using Segmental Conditional Random Fields (SCARF) give additional gains of 0.1% and 0.4% on the first dataset and 0.5% and 0.9% absolute on the second dataset."
            },
            "slug": "Application-of-Pretrained-Deep-Neural-Networks-to-Jaitly-Nguyen",
            "title": {
                "fragments": [],
                "text": "Application of Pretrained Deep Neural Networks to Large Vocabulary Speech Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This paper reports results of a DBN-pretrained context-dependent ANN/HMM system trained on two datasets that are much larger than any reported previously, and outperforms the best Gaussian Mixture Model Hidden Markov Model baseline."
            },
            "venue": {
                "fragments": [],
                "text": "INTERSPEECH"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2541509"
                        ],
                        "name": "N. Fujimoto",
                        "slug": "N.-Fujimoto",
                        "structuredName": {
                            "firstName": "Noriyuki",
                            "lastName": "Fujimoto",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Fujimoto"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7652286,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0409187ebfce03de95677aaeb499e8f1953bdbaf",
            "isKey": false,
            "numCitedBy": 69,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "Recently a GPU has acquired programmability to perform general purpose computation fast by running ten thousands of threads concurrently. This paper presents a new algorithm for dense matrix-vector multiplication on NVIDIA CUDA architecture. The experimental results on GeForce 8800GTX show that the proposed algorithm runs maximum 15.69 (resp., 32.88) times faster than the sgemv routine in NVIDIA's BIAS library CUBLAS 1.1 (resp., Intel Math Kernel Library 9.1 on one-core of 2.0 GHz Intel Xeon E5335 CPU with SSE3 SIMD instructions) for matrices with order 16 to 12800. The performance, including the data transfer between CPU and GPU, of Jacobi's iterative method for solving linear equations shows that the proposed algorithm is practical for some real applications."
            },
            "slug": "Faster-matrix-vector-multiplication-on-GeForce-Fujimoto",
            "title": {
                "fragments": [],
                "text": "Faster matrix-vector multiplication on GeForce 8800GTX"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The performance, including the data transfer between CPU and GPU, of Jacobi's iterative method for solving linear equations shows that the proposed algorithm is practical for some real applications."
            },
            "venue": {
                "fragments": [],
                "text": "2008 IEEE International Symposium on Parallel and Distributed Processing"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3255983"
                        ],
                        "name": "Volodymyr Mnih",
                        "slug": "Volodymyr-Mnih",
                        "structuredName": {
                            "firstName": "Volodymyr",
                            "lastName": "Mnih",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Volodymyr Mnih"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 58732357,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0ea90fac0958d84bcf4a2875c2b169478358b480",
            "isKey": false,
            "numCitedBy": 83,
            "numCiting": 1,
            "paperAbstract": {
                "fragments": [],
                "text": "CUDAMat is an open source software package that provides a CUDA-based matrix class for Python. The primary goal of CUDAMat is to make it easy to implement algorithms that are easily expressed in terms of dense matrix operations on a GPU. At present, the feature set of CUDAMat is biased towards providing functionality useful for implementing standard machine learning algorithms, however, it is general enough to be useful in other elds. We have used CUDAMat to implement several common machine learning algorithms on GPUs oering speedups of up to 50x over numpy and MATLAB implementations."
            },
            "slug": "CUDAMat:-a-CUDA-based-matrix-class-for-Python-Mnih",
            "title": {
                "fragments": [],
                "text": "CUDAMat: a CUDA-based matrix class for Python"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The feature set of CUDAMat is biased towards providing functionality useful for implementing standard machine learning algorithms, however, it is general enough to be useful in other elds."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145962472"
                        ],
                        "name": "K. Knill",
                        "slug": "K.-Knill",
                        "structuredName": {
                            "firstName": "Kate",
                            "lastName": "Knill",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Knill"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1740397"
                        ],
                        "name": "M. Gales",
                        "slug": "M.-Gales",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Gales",
                            "middleNames": [
                                "John",
                                "Francis"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Gales"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145259603"
                        ],
                        "name": "S. Young",
                        "slug": "S.-Young",
                        "structuredName": {
                            "firstName": "Steve",
                            "lastName": "Young",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Young"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1675187,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9226b20bf8fb7467b0dac0acf0f0e39e6c3cff23",
            "isKey": false,
            "numCitedBy": 68,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper investigates the use of Gaussian Selection (GS) to reduce the state likelihood computation in HMM-based systems. These likelihood calculations contribute significantly (30 to 70%) to the computational load. Previously, it has been reported that when GS is used on large systems the recognition accuracy tends to degrade above a /spl times/3 reduction in likelihood computation. To explain this degradation, this paper investigates the trade-offs necessary between achieving good state likelihoods and low computation. In addition, the problem of unseen states in a cluster is examined. It is shown that further improvements are possible. For example, using a different assignment measure, with a constraint on the number of components per state per cluster enabled the recognition accuracy on a 5k speaker-independent task to be maintained up to a /spl times/5 reduction in likelihood computation."
            },
            "slug": "Use-of-Gaussian-selection-in-large-vocabulary-using-Knill-Gales",
            "title": {
                "fragments": [],
                "text": "Use of Gaussian selection in large vocabulary continuous speech recognition using HMMS"
            },
            "tldr": {
                "abstractSimilarityScore": 70,
                "text": "This paper investigates the use of Gaussian Selection to reduce the state likelihood computation in HMM-based systems and investigates the trade-offs necessary between achieving good state likelihoods and low computation."
            },
            "venue": {
                "fragments": [],
                "text": "Proceeding of Fourth International Conference on Spoken Language Processing. ICSLP '96"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144657062"
                        ],
                        "name": "J. Fritsch",
                        "slug": "J.-Fritsch",
                        "structuredName": {
                            "firstName": "J\u00fcrgen",
                            "lastName": "Fritsch",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Fritsch"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3281101"
                        ],
                        "name": "I. Rogina",
                        "slug": "I.-Rogina",
                        "structuredName": {
                            "firstName": "Ivica",
                            "lastName": "Rogina",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Rogina"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 3088788,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8a0a14d8f84fcd8003cc0417cb97b2455dac3eee",
            "isKey": false,
            "numCitedBy": 49,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "Today, most of the state-of-the-art speech recognizers are based on hidden Markov modeling. Using semi-continuous or continuous density hidden Markov models, the computation of emission probabilities requires the evaluation of mixture Gaussian probability density functions. Since it is very expensive to evaluate all the Gaussians of the mixture density codebook, many recognizers only compute the M most significant Gaussians (M=1,...,8). This paper presents an alternative approach to approximate mixture Gaussians with diagonal covariance matrices, based on a binary feature space partitioning tree. The proposed algorithm is experimentally evaluated in the context of large vocabulary, speaker independent, spontaneous speech recognition using the JANUS-2 speech recognizer. In the case of mixtures with 50 Gaussians, we achieve a speedup of 2-5 in the computation of HMM emission probabilities, without affecting the accuracy of the system."
            },
            "slug": "The-bucket-box-intersection-(BBI)-algorithm-for-of-Fritsch-Rogina",
            "title": {
                "fragments": [],
                "text": "The bucket box intersection (BBI) algorithm for fast approximative evaluation of diagonal mixture Gaussians"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "This paper presents an alternative approach to approximate mixture Gaussians with diagonal covariance matrices, based on a binary feature space partitioning tree, which achieves a speedup of 2-5 in the computation of HMM emission probabilities, without affecting the accuracy of the system."
            },
            "venue": {
                "fragments": [],
                "text": "1996 IEEE International Conference on Acoustics, Speech, and Signal Processing Conference Proceedings"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3111912"
                        ],
                        "name": "Navdeep Jaitly",
                        "slug": "Navdeep-Jaitly",
                        "structuredName": {
                            "firstName": "Navdeep",
                            "lastName": "Jaitly",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Navdeep Jaitly"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "14902530"
                        ],
                        "name": "P. Nguyen",
                        "slug": "P.-Nguyen",
                        "structuredName": {
                            "firstName": "Patrick",
                            "lastName": "Nguyen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Nguyen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "33666044"
                        ],
                        "name": "A. Senior",
                        "slug": "A.-Senior",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Senior",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Senior"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2657155"
                        ],
                        "name": "Vincent Vanhoucke",
                        "slug": "Vincent-Vanhoucke",
                        "structuredName": {
                            "firstName": "Vincent",
                            "lastName": "Vanhoucke",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Vincent Vanhoucke"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 64175775,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d779f5c56a7121bdb62d73c1894a1ab0d182cbc2",
            "isKey": false,
            "numCitedBy": 33,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Application-of-Pretrained-Deep-Neural-Networks-to-Jaitly-Nguyen",
            "title": {
                "fragments": [],
                "text": "Application of Pretrained Deep Neural Networks to Large Vocabulary Conversational Speech Recognition"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2012
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "GPU implementation of neural networks Pattern Recognition"
            },
            "venue": {
                "fragments": [],
                "text": "GPU implementation of neural networks Pattern Recognition"
            },
            "year": 2004
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 230,
                                "start": 225
                            }
                        ],
                        "text": "The recent resurgence of interest in neural networks owes a certain debt to the availability of affordable, powerful GPUs which routinely speed up common operations such as large matrix computations by factors from 5\u00d7 to 50\u00d7 [1-3]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 35,
                                "start": 32
                            }
                        ],
                        "text": "// c[0] = saturate(u[0]*s[0] + u[1]*s[1]) ."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Debunking the 100\u00d7 GPU vs. CPU myth: an evaluation of throughput computing on CPU and GPU"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 37th annual international symposium on Computer architecture,"
            },
            "year": 2010
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Debunking the 100\u00d7 GPU vs. CPU myth: an evaluation of throughput computing on CPU and GPU"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 37th annual international symposium on Computer architecture, ISCA'10"
            },
            "year": 2010
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "OpenFst Library"
            },
            "venue": {
                "fragments": [],
                "text": "OpenFst Library"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Eigen, a C++ template library for linear algebra"
            },
            "venue": {
                "fragments": [],
                "text": "Eigen, a C++ template library for linear algebra"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "GPU implementation of neural networks Pattern Recognition, 37(6):1311-1314"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2004
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 2
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 16,
        "totalPages": 2
    },
    "page_url": "https://www.semanticscholar.org/paper/Improving-the-speed-of-neural-networks-on-CPUs-Vanhoucke-Senior/fbeaa499e10e98515f7e1c4ad89165e8c0677427?sort=total-citations"
}