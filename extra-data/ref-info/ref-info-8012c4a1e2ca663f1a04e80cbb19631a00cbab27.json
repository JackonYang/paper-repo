{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49649079"
                        ],
                        "name": "D. Field",
                        "slug": "D.-Field",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Field",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Field"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1600874,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "aeb37769d72999bcbfb0582b73607fd8d23f4545",
            "isKey": false,
            "numCitedBy": 3273,
            "numCiting": 57,
            "paperAbstract": {
                "fragments": [],
                "text": "The relative efficiency of any particular image-coding scheme should be defined only in relation to the class of images that the code is likely to encounter. To understand the representation of images by the mammalian visual system, it might therefore be useful to consider the statistics of images from the natural environment (i.e., images with trees, rocks, bushes, etc). In this study, various coding schemes are compared in relation to how they represent the information in such natural images. The coefficients of such codes are represented by arrays of mechanisms that respond to local regions of space, spatial frequency, and orientation (Gabor-like transforms). For many classes of image, such codes will not be an efficient means of representing information. However, the results obtained with six natural images suggest that the orientation and the spatial-frequency tuning of mammalian simple cells are well suited for coding the information in such images if the goal of the code is to convert higher-order redundancy (e.g., correlation between the intensities of neighboring pixels) into first-order redundancy (i.e., the response distribution of the coefficients). Such coding produces a relatively high signal-to-noise ratio and permits information to be transmitted with only a subset of the total number of cells. These results support Barlow's theory that the goal of natural vision is to represent the information in the natural environment with minimal redundancy."
            },
            "slug": "Relations-between-the-statistics-of-natural-images-Field",
            "title": {
                "fragments": [],
                "text": "Relations between the statistics of natural images and the response properties of cortical cells."
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The results obtained with six natural images suggest that the orientation and the spatial-frequency tuning of mammalian simple cells are well suited for coding the information in such images if the goal of the code is to convert higher-order redundancy into first- order redundancy."
            },
            "venue": {
                "fragments": [],
                "text": "Journal of the Optical Society of America. A, Optics and image science"
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1781325"
                        ],
                        "name": "J. Daugman",
                        "slug": "J.-Daugman",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Daugman",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Daugman"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 20021288,
            "fieldsOfStudy": [
                "Computer Science",
                "Biology"
            ],
            "id": "da9cee8647743711c1f8b4f61185bfbece0ad284",
            "isKey": false,
            "numCitedBy": 171,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "In biological visual systems, it is not obvious whether coding efficiency as measured by mutual information among the neurons is a factor that explains any of their properties. The center/surround receptive field profiles of neurons in the retina and geniculate are far from an orthogonal set, but a given neuron can still be regarded as a decorrelator of the incoming signal in the sense that it responds primarily to changes in the image. At the level of the brain's visual cortex, the introduction of the new variable of orientation selectivity can be regarded not only as a means for providing orientation labels for image structure, but also more basically as an effective decorrelator of the neural representation. The present image coding simulations, based on quantitative neurobiological data about the code primitives, provide measures of the bit-rate efficiency of such oriented, quadrature, neural codes. Demonstrations of data compression to below 1 bit/pixel in cortically-based, quadrature self-similar wavelet image codes are also provided.<<ETX>>"
            },
            "slug": "Entropy-reduction-and-decorrelation-in-visual-by-Daugman",
            "title": {
                "fragments": [],
                "text": "Entropy reduction and decorrelation in visual coding by oriented neural receptive fields"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "The present image coding simulations, based on quantitative neurobiological data about the code primitives, provide measures of the bit-rate efficiency of such oriented, quadrature, neural codes."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Biomedical Engineering"
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49649079"
                        ],
                        "name": "D. Field",
                        "slug": "D.-Field",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Field",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Field"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 1650980,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ff1152582155acaa0e9d0ccbc900a4641504256d",
            "isKey": false,
            "numCitedBy": 1344,
            "numCiting": 85,
            "paperAbstract": {
                "fragments": [],
                "text": "A number of recent attempts have been made to describe early sensory coding in terms of a general information processing strategy. In this paper, two strategies are contrasted. Both strategies take advantage of the redundancy in the environment to produce more effective representations. The first is described as a compact coding scheme. A compact code performs a transform that allows the input to be represented with a reduced number of vectors (cells) with minimal RMS error. This approach has recently become popular in the neural network literature and is related to a process called Principal Components Analysis (PCA). A number of recent papers have suggested that the optimal compact code for representing natural scenes will have units with receptive field profiles much like those found in the retina and primary visual cortex. However, in this paper, it is proposed that compact coding schemes are insufficient to account for the receptive field properties of cells in the mammalian visual pathway. In contrast, it is proposed that the visual system is near to optimal in representing natural scenes only if optimality is defined in terms of sparse distributed coding. In a sparse distributed code, all cells in the code have an equal response probability across the class of images but have a low response probability for any single image. In such a code, the dimensionality is not reduced. Rather, the redundancy of the input is transformed into the redundancy of the firing pattern of cells. It is proposed that the signature for a sparse code is found in the fourth moment of the response distribution (i.e., the kurtosis). In measurements with 55 calibrated natural scenes, the kurtosis was found to peak when the bandwidths of the visual code matched those of cells in the mammalian visual cortex. Codes resembling wavelet transforms are proposed to be effective because the response histograms of such codes are sparse (i.e., show high kurtosis) when presented with natural scenes. It is proposed that the structure of the image that allows sparse coding is found in the phase spectrum of the image. It is suggested that natural scenes, to a first approximation, can be considered as a sum of self-similar local functions (the inverse of a wavelet). Possible reasons for why sensory systems would evolve toward sparse coding are presented."
            },
            "slug": "What-Is-the-Goal-of-Sensory-Coding-Field",
            "title": {
                "fragments": [],
                "text": "What Is the Goal of Sensory Coding?"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "It is proposed that compact coding schemes are insufficient to account for the receptive field properties of cells in the mammalian visual pathway and suggested that natural scenes, to a first approximation, can be considered as a sum of self-similar local functions (the inverse of a wavelet)."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2107584303"
                        ],
                        "name": "J. P. Jones",
                        "slug": "J.-P.-Jones",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Jones",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. P. Jones"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3459632"
                        ],
                        "name": "L. Palmer",
                        "slug": "L.-Palmer",
                        "structuredName": {
                            "firstName": "Larry",
                            "lastName": "Palmer",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Palmer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 16809045,
            "fieldsOfStudy": [
                "Environmental Science"
            ],
            "id": "0dbf797d5b34f40d16eeadfa7a5b4543c2af2c11",
            "isKey": false,
            "numCitedBy": 1709,
            "numCiting": 48,
            "paperAbstract": {
                "fragments": [],
                "text": "1. Using the two-dimensional (2D) spatial and spectral response profiles described in the previous two reports, we test Daugman's generalization of Marcelja's hypothesis that simple receptive fields belong to a class of linear spatial filters analogous to those described by Gabor and referred to here as 2D Gabor filters. 2. In the space domain, we found 2D Gabor filters that fit the 2D spatial response profile of each simple cell in the least-squared error sense (with a simplex algorithm), and we show that the residual error is devoid of spatial structure and statistically indistinguishable from random error. 3. Although a rigorous statistical approach was not possible with our spectral data, we also found a Gabor function that fit the 2D spectral response profile of each simple cell and observed that the residual errors are everywhere small and unstructured. 4. As an assay of spatial linearity in two dimensions, on which the applicability of Gabor theory is dependent, we compare the filter parameters estimated from the independent 2D spatial and spectral measurements described above. Estimates of most parameters from the two domains are highly correlated, indicating that assumptions about spatial linearity are valid. 5. Finally, we show that the functional form of the 2D Gabor filter provides a concise mathematical expression, which incorporates the important spatial characteristics of simple receptive fields demonstrated in the previous two reports. Prominent here are 1) Cartesian separable spatial response profiles, 2) spatial receptive fields with staggered subregion placement, 3) Cartesian separable spectral response profiles, 4) spectral response profiles with axes of symmetry not including the origin, and 5) the uniform distribution of spatial phase angles. 6. We conclude that the Gabor function provides a useful and reasonably accurate description of most spatial aspects of simple receptive fields. Thus it seems that an optimal strategy has evolved for sampling images simultaneously in the 2D spatial and spatial frequency domains."
            },
            "slug": "An-evaluation-of-the-two-dimensional-Gabor-filter-Jones-Palmer",
            "title": {
                "fragments": [],
                "text": "An evaluation of the two-dimensional Gabor filter model of simple receptive fields in cat striate cortex."
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "It seems that an optimal strategy has evolved for sampling images simultaneously in the 2D spatial and spatial frequency domains and the Gabor function provides a useful and reasonably accurate description of most spatial aspects of simple receptive fields."
            },
            "venue": {
                "fragments": [],
                "text": "Journal of neurophysiology"
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1742997"
                        ],
                        "name": "C. Fyfe",
                        "slug": "C.-Fyfe",
                        "structuredName": {
                            "firstName": "Colin",
                            "lastName": "Fyfe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Fyfe"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34931109"
                        ],
                        "name": "R. Baddeley",
                        "slug": "R.-Baddeley",
                        "structuredName": {
                            "firstName": "Roland",
                            "lastName": "Baddeley",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Baddeley"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 8604471,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e5ae37805bc9e0291c4c2c64cb2435f91849de74",
            "isKey": false,
            "numCitedBy": 60,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "Some recent work has investigated the dichotomy between compact coding using dimensionality reduction and sparse-distributed coding in the context of understanding biological information processing. We introduce an artificial neural network which self-organizes on the basis of simple Hebbian learning and negative feedback of activation and show that it is capable both of forming compact codings of data distributions and of identifying filters most sensitive to sparse-distributed codes. The network is extremely simple and its biological relevance is investigated via its response to a set of images which are typical of everyday life. However, an analysis of the network's identification of the filter for sparse coding reveals that this coding may not be globally optimal and that there exists an innate limiting factor which cannot be transcended."
            },
            "slug": "Finding-compact-and-sparse-distributed-of-visual-Fyfe-Baddeley",
            "title": {
                "fragments": [],
                "text": "Finding compact and sparse-distributed representations of visual images"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "An artificial neural network which self-organizes on the basis of simple Hebbian learning and negative feedback of activation is introduced and it is shown that it is capable both of forming compact codings of data distributions and of identifying filters most sensitive to sparse-distributed codes."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39409429"
                        ],
                        "name": "R. L. Valois",
                        "slug": "R.-L.-Valois",
                        "structuredName": {
                            "firstName": "Russell",
                            "lastName": "Valois",
                            "middleNames": [
                                "L.",
                                "de"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. L. Valois"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2129244"
                        ],
                        "name": "D. G. Albrecht",
                        "slug": "D.-G.-Albrecht",
                        "structuredName": {
                            "firstName": "Duane",
                            "lastName": "Albrecht",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. G. Albrecht"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40471674"
                        ],
                        "name": "Lisa G. Thorell",
                        "slug": "Lisa-G.-Thorell",
                        "structuredName": {
                            "firstName": "Lisa",
                            "lastName": "Thorell",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lisa G. Thorell"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 16496844,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "e2f74bec30cc4e471919de4dfd27c45dbc7b4b9d",
            "isKey": false,
            "numCitedBy": 1118,
            "numCiting": 53,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Spatial-frequency-selectivity-of-cells-in-macaque-Valois-Albrecht",
            "title": {
                "fragments": [],
                "text": "Spatial frequency selectivity of cells in macaque visual cortex"
            },
            "venue": {
                "fragments": [],
                "text": "Vision Research"
            },
            "year": 1982
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2064184853"
                        ],
                        "name": "C. C. Law",
                        "slug": "C.-C.-Law",
                        "structuredName": {
                            "firstName": "C.",
                            "lastName": "Law",
                            "middleNames": [
                                "Charles"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. C. Law"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8884630"
                        ],
                        "name": "L. Cooper",
                        "slug": "L.-Cooper",
                        "structuredName": {
                            "firstName": "Leon",
                            "lastName": "Cooper",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Cooper"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 25243472,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "486babc6bea3568bf1ef0ae8ef5d469c212bcb41",
            "isKey": false,
            "numCitedBy": 81,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "The Bienenstock, Cooper, and Munro (BCM) theory of synaptic plasticity has successfully reproduced the development of orientation selectivity and ocular dominance in kitten visual cortex in normal, as well as deprived, visual environments. To better compare the consequences of this theory with experiment, previous abstractions of the visual environment are replaced in this work by real visual images with retinal processing. The visual environment is represented by 24 gray-scale natural images that are shifted across retinal fields. In this environment, the BCM neuron develops receptive fields similar to the fields of simple cells found in kitten striate cortex. These fields display adjacent excitatory and inhibitory bands when tested with spot stimuli, orientation selectivity when tested with bar stimuli, and spatial-frequency selectivity when tested with sinusoidal gratings. In addition, their development in various deprived visual environments agrees with experimental results."
            },
            "slug": "Formation-of-receptive-fields-in-realistic-visual-Law-Cooper",
            "title": {
                "fragments": [],
                "text": "Formation of receptive fields in realistic visual environments according to the Bienenstock, Cooper, and Munro (BCM) theory."
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "The Bienenstock, Cooper, and Munro (BCM) theory of synaptic plasticity has successfully reproduced the development of orientation selectivity and ocular dominance in kitten visual cortex in normal, as well as deprived, visual environments."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the National Academy of Sciences of the United States of America"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2577641"
                        ],
                        "name": "R. Linsker",
                        "slug": "R.-Linsker",
                        "structuredName": {
                            "firstName": "Ralph",
                            "lastName": "Linsker",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Linsker"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1527671,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "16d70e8af45ca0ae2c1bb73f3be6628518d40b8f",
            "isKey": false,
            "numCitedBy": 1417,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "The emergence of a feature-analyzing function from the development rules of simple, multilayered networks is explored. It is shown that even a single developing cell of a layered network exhibits a remarkable set of optimization properties that are closely related to issues in statistics, theoretical physics, adaptive signal processing, the formation of knowledge representation in artificial intelligence, and information theory. The network studied is based on the visual system. These results are used to infer an information-theoretic principle that can be applied to the network as a whole, rather than a single cell. The organizing principle proposed is that the network connections develop in such a way as to maximize the amount of information that is preserved when signals are transformed at each processing stage, subject to certain constraints. The operation of this principle is illustrated for some simple cases.<<ETX>>"
            },
            "slug": "Self-organization-in-a-perceptual-network-Linsker",
            "title": {
                "fragments": [],
                "text": "Self-organization in a perceptual network"
            },
            "tldr": {
                "abstractSimilarityScore": 62,
                "text": "It is shown that even a single developing cell of a layered network exhibits a remarkable set of optimization properties that are closely related to issues in statistics, theoretical physics, adaptive signal processing, the formation of knowledge representation in artificial intelligence, and information theory."
            },
            "venue": {
                "fragments": [],
                "text": "Computer"
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2474176"
                        ],
                        "name": "J. H. Hateren",
                        "slug": "J.-H.-Hateren",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Hateren",
                            "middleNames": [
                                "H.",
                                "van"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. H. Hateren"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 207845327,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "b7b0b0847e2edc22020956b42196705eac18986a",
            "isKey": false,
            "numCitedBy": 98,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "IT has been suggested1\u20133 that the first steps in visual processing strive to compress as much information as possible about the outside world into the limited dynamic range of the visual channels. Here I compare measured neural images with theoretical calculations based on maximizing information, taking into account the statistical structure of natural images. Neural images were obtained by scanning an image while recording from a second-order neuron in the fly visual system. Over a 5.5-log-units-wide range of mean intensities, experiment and theory correspond well. At high mean intensities, redundancy in the image is reduced by spatial and temporal antagonism. At low mean intensities, spatial and temporal low-pass filtering combat noise and increase signal reliability."
            },
            "slug": "Real-and-optimal-neural-images-in-early-vision-Hateren",
            "title": {
                "fragments": [],
                "text": "Real and optimal neural images in early vision"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "Compared neural images obtained by scanning an image while recording from a second-order neuron in the fly visual system are compared with theoretical calculations based on maximizing information, taking into account the statistical structure of natural images."
            },
            "venue": {
                "fragments": [],
                "text": "Nature"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1735689"
                        ],
                        "name": "A. Parker",
                        "slug": "A.-Parker",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Parker",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Parker"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2480424"
                        ],
                        "name": "M. Hawken",
                        "slug": "M.-Hawken",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Hawken",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Hawken"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 20372548,
            "fieldsOfStudy": [
                "Biology",
                "Psychology"
            ],
            "id": "11a437b768ff54b6af01b5568087b38d97942f00",
            "isKey": false,
            "numCitedBy": 109,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "Measurements of the spatial contrast sensitivity function and orientation selectivity of visual neurons in the foveal striate cortex (V1) of primates were interpreted within the context of a model of the two-dimensional spatial structure of their receptive fields. Estimates of the spatial dimensions of the receptive fields along the axis of preferred orientation were derived from the application of the model and were compared with estimates of the smallest spatial subunit in the dimension orthogonal to the preferred orientation. Some measure of agreement was found with corresponding estimates of parameters for psychophysical channels in human foveal vision."
            },
            "slug": "Two-dimensional-spatial-structure-of-receptive-in-Parker-Hawken",
            "title": {
                "fragments": [],
                "text": "Two-dimensional spatial structure of receptive fields in monkey striate cortex."
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "Measurements of the spatial contrast sensitivity function and orientation selectivity of visual neurons in the foveal striate cortex (V1) of primates were interpreted within the context of a model of the two-dimensional spatial structure of their receptive fields."
            },
            "venue": {
                "fragments": [],
                "text": "Journal of the Optical Society of America. A, Optics and image science"
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1829021"
                        ],
                        "name": "D. Ruderman",
                        "slug": "D.-Ruderman",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Ruderman",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Ruderman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2793971,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "13206b6ba3711a14a56cf1599ecb08c16f49061e",
            "isKey": false,
            "numCitedBy": 912,
            "numCiting": 144,
            "paperAbstract": {
                "fragments": [],
                "text": "Recently there has been a resurgence of interest in the properties of natural images. Their statistics are important not only in image compression but also for the study of sensory processing in biology, which can be viewed as satisfying certain \u2018design criteria\u2019. This review summarizes previous work on image statistics and presents our own data. Perhaps the most notable property of natural images is an invariance to scale. We present data to support this claim as well as evidence for a hierarchical invariance in natural scenes. These symmetries provide a powerful description of natural images as they greatly restrict the class of allowed distributions."
            },
            "slug": "The-statistics-of-natural-images-Ruderman",
            "title": {
                "fragments": [],
                "text": "The statistics of natural images"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2334226"
                        ],
                        "name": "D. Hubel",
                        "slug": "D.-Hubel",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Hubel",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Hubel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2629471"
                        ],
                        "name": "T. Wiesel",
                        "slug": "T.-Wiesel",
                        "structuredName": {
                            "firstName": "Torsten",
                            "lastName": "Wiesel",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Wiesel"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7136759,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "c5f5311fa1f34159ab3a0a1d58da51cd0340a640",
            "isKey": false,
            "numCitedBy": 6319,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": "1. The striate cortex was studied in lightly anaesthetized macaque and spider monkeys by recording extracellularly from single units and stimulating the retinas with spots or patterns of light. Most cells can be categorized as simple, complex, or hypercomplex, with response properties very similar to those previously described in the cat. On the average, however, receptive fields are smaller, and there is a greater sensitivity to changes in stimulus orientation. A small proportion of the cells are colour coded."
            },
            "slug": "Receptive-fields-and-functional-architecture-of-Hubel-Wiesel",
            "title": {
                "fragments": [],
                "text": "Receptive fields and functional architecture of monkey striate cortex"
            },
            "tldr": {
                "abstractSimilarityScore": 82,
                "text": "The striate cortex was studied in lightly anaesthetized macaque and spider monkeys by recording extracellularly from single units and stimulating the retinas with spots or patterns of light, with response properties very similar to those previously described in the cat."
            },
            "venue": {
                "fragments": [],
                "text": "The Journal of physiology"
            },
            "year": 1968
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144187218"
                        ],
                        "name": "A. J. Bell",
                        "slug": "A.-J.-Bell",
                        "structuredName": {
                            "firstName": "Anthony",
                            "lastName": "Bell",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. J. Bell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1714528"
                        ],
                        "name": "T. Sejnowski",
                        "slug": "T.-Sejnowski",
                        "structuredName": {
                            "firstName": "Terrence",
                            "lastName": "Sejnowski",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Sejnowski"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1701422,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1d7d0e8c4791700defd4b0df82a26b50055346e0",
            "isKey": false,
            "numCitedBy": 8754,
            "numCiting": 121,
            "paperAbstract": {
                "fragments": [],
                "text": "We derive a new self-organizing learning algorithm that maximizes the information transferred in a network of nonlinear units. The algorithm does not assume any knowledge of the input distributions, and is defined here for the zero-noise limit. Under these conditions, information maximization has extra properties not found in the linear case (Linsker 1989). The nonlinearities in the transfer function are able to pick up higher-order moments of the input distributions and perform something akin to true redundancy reduction between units in the output representation. This enables the network to separate statistically independent components in the inputs: a higher-order generalization of principal components analysis. We apply the network to the source separation (or cocktail party) problem, successfully separating unknown mixtures of up to 10 speakers. We also show that a variant on the network architecture is able to perform blind deconvolution (cancellation of unknown echoes and reverberation in a speech signal). Finally, we derive dependencies of information transfer on time delays. We suggest that information maximization provides a unifying framework for problems in \"blind\" signal processing."
            },
            "slug": "An-Information-Maximization-Approach-to-Blind-and-Bell-Sejnowski",
            "title": {
                "fragments": [],
                "text": "An Information-Maximization Approach to Blind Separation and Blind Deconvolution"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "It is suggested that information maximization provides a unifying framework for problems in \"blind\" signal processing and dependencies of information transfer on time delays are derived."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8909922"
                        ],
                        "name": "N. Intrator",
                        "slug": "N.-Intrator",
                        "structuredName": {
                            "firstName": "Nathan",
                            "lastName": "Intrator",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Intrator"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15475544,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "136fc611e49e5f3676265a288b78e473a752783b",
            "isKey": false,
            "numCitedBy": 78,
            "numCiting": 67,
            "paperAbstract": {
                "fragments": [],
                "text": "A novel unsupervised neural network for dimensionality reduction that seeks directions emphasizing multimodality is presented, and its connection to exploratory projection pursuit methods is discussed. This leads to a new statistical insight into the synaptic modification equations governing learning in Bienenstock, Cooper, and Munro (BCM) neurons (1982). The importance of a dimensionality reduction principle based solely on distinguishing features is demonstrated using a phoneme recognition experiment. The extracted features are compared with features extracted using a backpropagation network."
            },
            "slug": "Feature-Extraction-Using-an-Unsupervised-Neural-Intrator",
            "title": {
                "fragments": [],
                "text": "Feature Extraction Using an Unsupervised Neural Network"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "A novel unsupervised neural network for dimensionality reduction that seeks directions emphasizing multimodality is presented, and its connection to exploratory projection pursuit methods is discussed."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145160279"
                        ],
                        "name": "P. Hancock",
                        "slug": "P.-Hancock",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Hancock",
                            "middleNames": [
                                "J.",
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Hancock"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34931109"
                        ],
                        "name": "R. Baddeley",
                        "slug": "R.-Baddeley",
                        "structuredName": {
                            "firstName": "Roland",
                            "lastName": "Baddeley",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Baddeley"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144708497"
                        ],
                        "name": "Leslie S. Smith",
                        "slug": "Leslie-S.-Smith",
                        "structuredName": {
                            "firstName": "Leslie",
                            "lastName": "Smith",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Leslie S. Smith"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 9967699,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "7dcfa42cfe3b59becb441844b72558b361693608",
            "isKey": false,
            "numCitedBy": 280,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "A neural net was used to analyse samples of natural images and text. For the natural images, components resemble derivatives of Gaussian operators, similar to those found in visual cortex and inferred from psychophysics. While the results from natural images do not depend on scale, those from text images are highly scale dependent. Convolution of one of the text components with an original image shows that it is sensitive to inter-word gaps."
            },
            "slug": "The-principal-components-of-natural-images-Hancock-Baddeley",
            "title": {
                "fragments": [],
                "text": "The principal components of natural images"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1763321"
                        ],
                        "name": "E. Saund",
                        "slug": "E.-Saund",
                        "structuredName": {
                            "firstName": "Eric",
                            "lastName": "Saund",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Saund"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 18231498,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fd7d7767129ed180db39d38be28c1ae389481d2f",
            "isKey": false,
            "numCitedBy": 143,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a formulation for unsupervised learning of clusters reflecting multiple causal structure in binary data. Unlike the hard k-means clustering algorithm and the soft mixture model, each of which assumes that a single hidden event generates each data point, a multiple cause model accounts for observed data by combining assertions from many hidden causes, each of which can pertain to varying degree to any subset of the observable dimensions. We employ an objective function and iterative gradient descent learning algorithm resembling the conventional mixture model. A crucial issue is the mixing function for combining beliefs from different cluster centers in order to generate data predictions whose errors are minimized both during recognition and learning. The mixing function constitutes a prior assumption about underlying structural regularities of the data domain; we demonstrate a weakness inherent to the popular weighted sum followed by sigmoid squashing, and offer alternative forms of the nonlinearity for two types of data domain. Results are presented demonstrating the algorithm's ability successfully to discover coherent multiple causal representations in several experimental data sets."
            },
            "slug": "A-Multiple-Cause-Mixture-Model-for-Unsupervised-Saund",
            "title": {
                "fragments": [],
                "text": "A Multiple Cause Mixture Model for Unsupervised Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 60,
                "text": "A formulation for unsupervised learning of clusters reflecting multiple causal structure in binary data, which employs an objective function and iterative gradient descent learning algorithm resembling the conventional mixture model and demonstrates its ability to discover coherent multiple causal representations in several experimental data sets."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145341374"
                        ],
                        "name": "J. Schmidhuber",
                        "slug": "J.-Schmidhuber",
                        "structuredName": {
                            "firstName": "J\u00fcrgen",
                            "lastName": "Schmidhuber",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Schmidhuber"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1983976"
                        ],
                        "name": "M. Eldracher",
                        "slug": "M.-Eldracher",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "Eldracher",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Eldracher"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "51073406"
                        ],
                        "name": "Bernhard Foltin",
                        "slug": "Bernhard-Foltin",
                        "structuredName": {
                            "firstName": "Bernhard",
                            "lastName": "Foltin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bernhard Foltin"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 16154391,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6bf2479e607ff547012b54dab3f35dc01613ef86",
            "isKey": false,
            "numCitedBy": 56,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "Predictability minimization (PMSchmidhuber 1992) exhibits various intuitive and theoretical advantages over many other methods for unsupervised redundancy reduction. So far, however, there have not been any serious practical applications of PM. In this paper, we apply semilinear PM to static real world images and find that without a teacher and without any significant preprocessing, the system automatically learns to generate distributed representations based on well-known feature detectors, such as orientation-sensitive edge detectors and off-centeron-surround detectors, thus extracting simple features related to those considered useful for image preprocessing and compression."
            },
            "slug": "Semilinear-Predictability-Minimization-Produces-Schmidhuber-Eldracher",
            "title": {
                "fragments": [],
                "text": "Semilinear Predictability Minimization Produces Well-Known Feature Detectors"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This paper applies semilinear PM to static real world images and finds that without a teacher and without any significant preprocessing, the system automatically learns to generate distributed representations based on well-known feature detectors, thus extracting simple features related to those considered useful for image preprocessing and compression."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46831169"
                        ],
                        "name": "G. Hinton",
                        "slug": "G.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Hinton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1790646"
                        ],
                        "name": "P. Dayan",
                        "slug": "P.-Dayan",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Dayan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Dayan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1749650"
                        ],
                        "name": "B. Frey",
                        "slug": "B.-Frey",
                        "structuredName": {
                            "firstName": "Brendan",
                            "lastName": "Frey",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Frey"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145572884"
                        ],
                        "name": "R. Neal",
                        "slug": "R.-Neal",
                        "structuredName": {
                            "firstName": "R",
                            "lastName": "Neal",
                            "middleNames": [
                                "M"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Neal"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 871473,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6dd01cd9c17d1491ead8c9f97597fbc61dead8ea",
            "isKey": false,
            "numCitedBy": 1001,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "An unsupervised learning algorithm for a multilayer network of stochastic neurons is described. Bottom-up \"recognition\" connections convert the input into representations in successive hidden layers, and top-down \"generative\" connections reconstruct the representation in one layer from the representation in the layer above. In the \"wake\" phase, neurons are driven by recognition connections, and generative connections are adapted to increase the probability that they would reconstruct the correct activity vector in the layer below. In the \"sleep\" phase, neurons are driven by generative connections, and recognition connections are adapted to increase the probability that they would produce the correct activity vector in the layer above."
            },
            "slug": "The-\"wake-sleep\"-algorithm-for-unsupervised-neural-Hinton-Dayan",
            "title": {
                "fragments": [],
                "text": "The \"wake-sleep\" algorithm for unsupervised neural networks."
            },
            "tldr": {
                "abstractSimilarityScore": 98,
                "text": "An unsupervised learning algorithm for a multilayer network of stochastic neurons is described, where bottom-up \"recognition\" connections convert the input into representations in successive hidden layers, and top-down \"generative\" connections reconstruct the representation in one layer from the representations in the layer above."
            },
            "venue": {
                "fragments": [],
                "text": "Science"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1772264"
                        ],
                        "name": "E. Schwartz",
                        "slug": "E.-Schwartz",
                        "structuredName": {
                            "firstName": "Eric",
                            "lastName": "Schwartz",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Schwartz"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 86849023,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "91fad4dbf1ba6b952a48413437a323f70bf2e4ca",
            "isKey": false,
            "numCitedBy": 723,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Computational-neuroscience-Schwartz",
            "title": {
                "fragments": [],
                "text": "Computational neuroscience"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1993
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {},
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 19,
        "totalPages": 2
    },
    "page_url": "https://www.semanticscholar.org/paper/Emergence-of-simple-cell-receptive-field-properties-Olshausen-Field/8012c4a1e2ca663f1a04e80cbb19631a00cbab27?sort=total-citations"
}