{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50785579"
                        ],
                        "name": "N. Friedman",
                        "slug": "N.-Friedman",
                        "structuredName": {
                            "firstName": "Nir",
                            "lastName": "Friedman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Friedman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145107462"
                        ],
                        "name": "Stuart J. Russell",
                        "slug": "Stuart-J.-Russell",
                        "structuredName": {
                            "firstName": "Stuart",
                            "lastName": "Russell",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Stuart J. Russell"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1041214,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6dfc312ebd656faf7c01018f5cd53345818d0e1c",
            "isKey": false,
            "numCitedBy": 1017,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "\"Background subtraction\" is an old technique for finding moving objects in a video sequence--for example, cars driving on a freeway. The idea is that subtracting the current image from a time-averaged background image will leave only nonstationary objects. It is, however, a crude approximation to the task of classifying each pixel of the current image; it fails with slow-moving objects and does not distinguish shadows from moving objects. The basic idea of this paper is that we can classify each pixel using a model of how that pixel looks when it is part of different classes. We learn a mixture-of-Gaussians classification model for each pixel using an unsupervised technique--an efficient, incremental version of EM. Unlike the standard image-averaging approach, this automatically updates the mixture component for each class according to likelihood of membership; hence slow-moving objects are handled perfectly. Our approach also identifies and eliminates shadows much more effectively than other techniques such as thresholding. Application of this method as part of the Roadwatch traffic surveillance project is expected to result in significant improvements in vehicle identification and tracking."
            },
            "slug": "Image-Segmentation-in-Video-Sequences:-A-Approach-Friedman-Russell",
            "title": {
                "fragments": [],
                "text": "Image Segmentation in Video Sequences: A Probabilistic Approach"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "A mixture-of-Gaussians classification model for each pixel is learned using an unsupervised technique--an efficient, incremental version of EM, which identifies and eliminates shadows much more effectively than other techniques such as thresholding."
            },
            "venue": {
                "fragments": [],
                "text": "UAI"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2074042871"
                        ],
                        "name": "Christof Ridder",
                        "slug": "Christof-Ridder",
                        "structuredName": {
                            "firstName": "Christof",
                            "lastName": "Ridder",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christof Ridder"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1956188"
                        ],
                        "name": "O. Munkelt",
                        "slug": "O.-Munkelt",
                        "structuredName": {
                            "firstName": "Olaf",
                            "lastName": "Munkelt",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Munkelt"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2069179220"
                        ],
                        "name": "H. Kirchner",
                        "slug": "H.-Kirchner",
                        "structuredName": {
                            "firstName": "H.",
                            "lastName": "Kirchner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Kirchner"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 274,
                                "start": 271
                            }
                        ],
                        "text": "It should be capable of dealing with movement through cluttered areas, objects overlap-\nping in the visual field, shadows, lighting changes, effects of moving elements of the scene (e.g. swaying trees), slow-moving objects, and objects being introduced or removed from the scene."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 16234680,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "f680e7e609ce0729c8a594336e0cf8f447b3ef13",
            "isKey": false,
            "numCitedBy": 341,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "In image sequence processing kalman filtering is used for an adaptive background estimation, in order to separate the foreground from the background. The presented work is an approach which takes into account that changing illumination should be considered in the background estimation, and should not be detected as foreground. The new approach assumes a stationary CCD cameras with fixed focal length and considers non-rigid objects moving non-continuously like human bodies. Furthermore, statistic based methods are used to overcome the problems caused by shadow borders and the adaptation, when the background is covered by the foreground."
            },
            "slug": "Adaptive-Background-Estimation-and-Foreground-using-Ridder-Munkelt",
            "title": {
                "fragments": [],
                "text": "Adaptive Background Estimation and Foreground Detection using Kalman-Filtering"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "An approach which takes into account that changing illumination should be considered in the background estimation, and should not be detected as foreground is presented, which assumes a stationary CCD cameras with fixed focal length and considers non-rigid objects moving non-continuously like human bodies."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1736370"
                        ],
                        "name": "D. Koller",
                        "slug": "D.-Koller",
                        "structuredName": {
                            "firstName": "Daphne",
                            "lastName": "Koller",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Koller"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145774177"
                        ],
                        "name": "J. Weber",
                        "slug": "J.-Weber",
                        "structuredName": {
                            "firstName": "Joseph",
                            "lastName": "Weber",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Weber"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "30434770"
                        ],
                        "name": "Timothy Huang",
                        "slug": "Timothy-Huang",
                        "structuredName": {
                            "firstName": "Timothy",
                            "lastName": "Huang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Timothy Huang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143751119"
                        ],
                        "name": "Jitendra Malik",
                        "slug": "Jitendra-Malik",
                        "structuredName": {
                            "firstName": "Jitendra",
                            "lastName": "Malik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jitendra Malik"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31430928"
                        ],
                        "name": "G. Ogasawara",
                        "slug": "G.-Ogasawara",
                        "structuredName": {
                            "firstName": "Gary",
                            "lastName": "Ogasawara",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Ogasawara"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145107462"
                        ],
                        "name": "Stuart J. Russell",
                        "slug": "Stuart-J.-Russell",
                        "structuredName": {
                            "firstName": "Stuart",
                            "lastName": "Russell",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Stuart J. Russell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2140497935"
                        ],
                        "name": "B. Rao",
                        "slug": "B.-Rao",
                        "structuredName": {
                            "firstName": "Bobby",
                            "lastName": "Rao",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Rao"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 18343101,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "45fa86ed9255bb35829c2356444fbbfc39f7b5bb",
            "isKey": false,
            "numCitedBy": 329,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "Automatic symbolic traffic scene analysis is essential to many areas of IVHS (Intelligent Vehicle Highway Systems). Traffic scene information can be used to optimize traffic flow during busy periods, identify stalled vehicles and accidents, and aid the decision-making of an autonomous vehicle controller. Improvements in technologies for machine vision-based surveillance and high-level symbolic reasoning have enabled the authors to develop a system for detailed, reliable traffic scene analysis. The machine vision component of the system employs a contour tracker and an affine motion model based on Kalman filters to extract vehicle trajectories over a sequence of traffic scene images. The symbolic reasoning component uses a dynamic belief network to make inferences about traffic events such as vehicle lane changes and stalls. In this paper, the authors discuss the key tasks of the vision and reasoning components as well as their integration into a working prototype. Preliminary results of an implementation on special purpose hardware using C-40 Digital Signal Processors show that near real-time performance can be achieved without further improvements."
            },
            "slug": "Towards-robust-automatic-traffic-scene-analysis-in-Koller-Weber",
            "title": {
                "fragments": [],
                "text": "Towards robust automatic traffic scene analysis in real-time"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "Improvements in technologies for machine vision-based surveillance and high-level symbolic reasoning have enabled the authors to develop a system for detailed, reliable traffic scene analysis and preliminary results show that near real-time performance can be achieved without further improvements."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of 12th International Conference on Pattern Recognition"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1719838"
                        ],
                        "name": "W. Grimson",
                        "slug": "W.-Grimson",
                        "structuredName": {
                            "firstName": "W.",
                            "lastName": "Grimson",
                            "middleNames": [
                                "Eric",
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Grimson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34712076"
                        ],
                        "name": "C. Stauffer",
                        "slug": "C.-Stauffer",
                        "structuredName": {
                            "firstName": "C.",
                            "lastName": "Stauffer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Stauffer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2801291"
                        ],
                        "name": "R. Romano",
                        "slug": "R.-Romano",
                        "structuredName": {
                            "firstName": "Raquel",
                            "lastName": "Romano",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Romano"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2107410732"
                        ],
                        "name": "L. Lee",
                        "slug": "L.-Lee",
                        "structuredName": {
                            "firstName": "L.",
                            "lastName": "Lee",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Lee"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 107,
                                "start": 104
                            }
                        ],
                        "text": "Our tracking system has been effectively storing tracking information for five scenes for over 16 months[6]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 107,
                                "start": 104
                            }
                        ],
                        "text": "We are working on activity classification and object classification using literally millions of examples[6]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 17957171,
            "fieldsOfStudy": [
                "Computer Science",
                "Environmental Science"
            ],
            "id": "7c05eb1563da0a3f8fa31363f4d8ecae40b7e3ce",
            "isKey": false,
            "numCitedBy": 667,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a vision system that monitors activity in a site over extended periods of time. The system uses a distributed set of sensors to cover the site, and an adaptive tracker detects multiple moving objects in the sensors. Our hypothesis is that motion tracking is sufficient to support a range of computations about site activities. We demonstrate using the tracked motion data to calibrate the distributed sensors, to construct rough site models, to classify detected objects, to learn common patterns of activity for different object classes, and to detect unusual activities."
            },
            "slug": "Using-adaptive-tracking-to-classify-and-monitor-in-Grimson-Stauffer",
            "title": {
                "fragments": [],
                "text": "Using adaptive tracking to classify and monitor activities in a site"
            },
            "tldr": {
                "abstractSimilarityScore": 57,
                "text": "A vision system that monitors activity in a site over extended periods of time using tracked motion data to calibrate the distributed sensors, to construct rough site models, to classify detected objects, to learn common patterns of activity for different object classes, and to detect unusual activities."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings. 1998 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.98CB36231)"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34751187"
                        ],
                        "name": "C. R. Wren",
                        "slug": "C.-R.-Wren",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Wren",
                            "middleNames": [
                                "Richard"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. R. Wren"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145271456"
                        ],
                        "name": "A. Azarbayejani",
                        "slug": "A.-Azarbayejani",
                        "structuredName": {
                            "firstName": "Ali",
                            "lastName": "Azarbayejani",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Azarbayejani"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1753210"
                        ],
                        "name": "Trevor Darrell",
                        "slug": "Trevor-Darrell",
                        "structuredName": {
                            "firstName": "Trevor",
                            "lastName": "Darrell",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Trevor Darrell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144994682"
                        ],
                        "name": "A. Pentland",
                        "slug": "A.-Pentland",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Pentland",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Pentland"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9458767,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "69b7efd02ea06e6aa372b5c1a46167e6a5366bfd",
            "isKey": false,
            "numCitedBy": 3549,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "Pfinder is a real-time system for tracking and interpretation of people. It runs on a standard SGI Indy computer, and has performed reliably on thousands of people in many different physical locations. The system uses a multi-class statistical model of color and shape to obtain a 2-D representation of head and hands in a wide range of viewing conditions. These representations are useful for applications such as wireless interfaces, video databases, and low-bandwidth coding, without cumbersome wires or attached sensors."
            },
            "slug": "Pfinder:-real-time-tracking-of-the-human-body-Wren-Azarbayejani",
            "title": {
                "fragments": [],
                "text": "Pfinder: Real-Time Tracking of the Human Body"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "Pfinder uses a multi-class statistical model of color and shape to obtain a 2-D representation of head and hands in a wide range of viewing conditions, useful for applications such as wireless interfaces, video databases, and low-bandwidth coding."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2448449"
                        ],
                        "name": "Y. J. Tejwani",
                        "slug": "Y.-J.-Tejwani",
                        "structuredName": {
                            "firstName": "Yogendra",
                            "lastName": "Tejwani",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. J. Tejwani"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 116,
                                "start": 113
                            }
                        ],
                        "text": "These labeled foreground pixels can then be segmented into regions by a two-pass, connected components algorithm [3]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 713769,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "3e5ad6a48fe0b8e97825e9ec1e831d18eeb5605a",
            "isKey": false,
            "numCitedBy": 2456,
            "numCiting": 1,
            "paperAbstract": {
                "fragments": [],
                "text": "A scheme is developed for classifying the types of motion perceived by a humanlike robot. It is assumed that the robot receives visual images of the scene using a perspective system model. Equations, theorems, concepts, clues, etc., relating the objects, their positions, and their motion to their images on the focal plane are presented.<<ETX>>"
            },
            "slug": "Robot-vision-Tejwani",
            "title": {
                "fragments": [],
                "text": "Robot vision"
            },
            "tldr": {
                "abstractSimilarityScore": 65,
                "text": "A scheme is developed for classifying the types of motion perceived by a humanlike robot and equations, theorems, concepts, clues, etc., relating the objects, their positions, and their motion to their images on the focal plane are presented."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE International Symposium on Circuits and Systems,"
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35043531"
                        ],
                        "name": "A. Dempster",
                        "slug": "A.-Dempster",
                        "structuredName": {
                            "firstName": "Arthur",
                            "lastName": "Dempster",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Dempster"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7890796"
                        ],
                        "name": "N. Laird",
                        "slug": "N.-Laird",
                        "structuredName": {
                            "firstName": "Nan",
                            "lastName": "Laird",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Laird"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2235217"
                        ],
                        "name": "D. Rubin",
                        "slug": "D.-Rubin",
                        "structuredName": {
                            "firstName": "Donald",
                            "lastName": "Rubin",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Rubin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 4193919,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "d36efb9ad91e00faa334b549ce989bfae7e2907a",
            "isKey": false,
            "numCitedBy": 48406,
            "numCiting": 134,
            "paperAbstract": {
                "fragments": [],
                "text": "Vibratory power unit for vibrating conveyers and screens comprising an asynchronous polyphase motor, at least one pair of associated unbalanced masses disposed on the shaft of said motor, with the first mass of a pair of said unbalanced masses being rigidly fastened to said shaft and with said second mass of said pair being movably arranged relative to said first mass, means for controlling and regulating the conveying rate during conveyer operation by varying the rotational speed of said motor between predetermined minimum and maximum values, said second mass being movably outwardly by centrifugal force against the pressure of spring means, said spring means being prestressed in such a manner that said second mass is, at rotational motor speeds lower than said minimum speed, held in its initial position, and at motor speeds between said lower and upper values in positions which are radially offset with respect to the axis of said motor to an extent depending on the value of said rotational motor speed."
            },
            "slug": "Maximum-likelihood-from-incomplete-data-via-the-EM-Dempster-Laird",
            "title": {
                "fragments": [],
                "text": "Maximum likelihood from incomplete data via the EM - algorithm plus discussions on the paper"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1977
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "My Background subtraction implementation using GMM at OpenCV"
            },
            "venue": {
                "fragments": [],
                "text": "My Background subtraction implementation using GMM at OpenCV"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "IEEE"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE"
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "My Results Let's go to the video tape"
            },
            "venue": {
                "fragments": [],
                "text": "My Results Let's go to the video tape"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Adaptive background mixture models for real-time tracking"
            },
            "venue": {
                "fragments": [],
                "text": "In Computer Vision and Pattern Recognition,"
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "W.E.L., \"Adaptive background mixture models for real-time tracking,"
            },
            "venue": {
                "fragments": [],
                "text": "Computer Vision and Pattern Recognition,"
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "You @BULLET Questions? 21 Background subtraction implementation using GMM at OpenCV References @BULLET Reading \u25ab StaufferAdaptive background mixture models for real-time tracking"
            },
            "venue": {
                "fragments": [],
                "text": "Computer Vision and Pattern Recognition"
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "You @BULLET Questions?"
            },
            "venue": {
                "fragments": [],
                "text": "You @BULLET Questions?"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Robot Vision, pp"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1986
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 162,
                                "start": 159
                            }
                        ],
                        "text": "If the pixel process could be considered a stationary process, a standard method for maximizing the likelihood of the observed data is expectation maximization[1]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "and D"
            },
            "venue": {
                "fragments": [],
                "text": "Rubin. \u201cMaximum likelihood from incomplete data via the EM algorithm,\u201d Journal of the Royal Statistical Society, 39 (Series B):1-38"
            },
            "year": 1977
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "@BULLET Background Subtraction Datasets \u25ab https://sites.google.com/site/backgroundsubtraction/ test-sequences"
            },
            "venue": {
                "fragments": [],
                "text": "@BULLET Background Subtraction Datasets \u25ab https://sites.google.com/site/backgroundsubtraction/ test-sequences"
            }
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 1,
            "methodology": 3
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 17,
        "totalPages": 2
    },
    "page_url": "https://www.semanticscholar.org/paper/Adaptive-background-mixture-models-for-real-time-Stauffer-Grimson/eac7287d7ef69252358c1fbddedf123e11012370?sort=total-citations"
}