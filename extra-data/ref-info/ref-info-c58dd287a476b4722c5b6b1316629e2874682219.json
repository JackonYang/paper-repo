{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145539951"
                        ],
                        "name": "J. Pollack",
                        "slug": "J.-Pollack",
                        "structuredName": {
                            "firstName": "Jordan",
                            "lastName": "Pollack",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Pollack"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 770011,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6a835df43fdc2f79126319f6fa033bb42147c6f6",
            "isKey": false,
            "numCitedBy": 948,
            "numCiting": 62,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Recursive-Distributed-Representations-Pollack",
            "title": {
                "fragments": [],
                "text": "Recursive Distributed Representations"
            },
            "venue": {
                "fragments": [],
                "text": "Artif. Intell."
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1749815"
                        ],
                        "name": "A. Sperduti",
                        "slug": "A.-Sperduti",
                        "structuredName": {
                            "firstName": "Alessandro",
                            "lastName": "Sperduti",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Sperduti"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1678493"
                        ],
                        "name": "A. Starita",
                        "slug": "A.-Starita",
                        "structuredName": {
                            "firstName": "Antonina",
                            "lastName": "Starita",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Starita"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1759124"
                        ],
                        "name": "C. Goller",
                        "slug": "C.-Goller",
                        "structuredName": {
                            "firstName": "Christoph",
                            "lastName": "Goller",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Goller"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8785487,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "14a9a814a54dbab99388fafbd96a1c5fe249e376",
            "isKey": false,
            "numCitedBy": 39,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper is a study on LRAAM-based (Labeling Recursive Auto-Associative Memory)classification of symbolic recursive structures encoding terms. The results reported here have been obtained by combining an LRAAM network with an analog perceptron. The approach used was to interleave the development of representations (unsupervised learning of the LRAAM) with the learning of the classification task. In this way, the representations are optimized with respect to the classification task. The intended applications of the approach described in this paper are hybrid (symbolic/connectionist) systems, where the connectionist part has to solve logic-oriented inductive learning tasks similar to the term-classification problems used in our experiments. These problems range from the detection of a specific subterm to the satisfaction of a specific unification pattern, and they can get a very satisfactory solution by our approach."
            },
            "slug": "Learning-Distributed-Representations-for-the-of-Sperduti-Starita",
            "title": {
                "fragments": [],
                "text": "Learning Distributed Representations for the Classification of Terms"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "The intended applications of the approach described in this paper are hybrid (symbolic/connectionist) systems, where the connectionist part has to solve logic-oriented inductive learning tasks similar to the term-classification problems used in the experiments."
            },
            "venue": {
                "fragments": [],
                "text": "IJCAI"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2624386"
                        ],
                        "name": "L. Chrisman",
                        "slug": "L.-Chrisman",
                        "structuredName": {
                            "firstName": "Lonnie",
                            "lastName": "Chrisman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Chrisman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 60590857,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "26affdaceca32cd4a5fde0db61ffef02a59baa13",
            "isKey": false,
            "numCitedBy": 105,
            "numCiting": 47,
            "paperAbstract": {
                "fragments": [],
                "text": "A number of connectionist models capable of representing data with compositional structure have recently appeared. These new models suggest the intriguing possibility of performing holistic structure-sensitive computations with distributed representations. Two possible forms of holistic inference, transformational inference and confluent inference, are identified and compared. Transformational inference was successfully demonstrated by Chalmers; however, the pure transformational approach does not consider the eventual inference tasks during the process of learning its representations. Confluent inference is introduced as a method for achieving a tight coupling between the distributed representations of a problem and the solution for the given inference task while the net is still learning its representations. A dual-ported RAAM architecture based on Pollack's Recursive Auto-Associative Memory is implemented and demonstrated in the domain of Natural Language translation."
            },
            "slug": "Learning-Recursive-Distributed-Representations-for-Chrisman",
            "title": {
                "fragments": [],
                "text": "Learning Recursive Distributed Representations for Holistic Computation"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "Two possible forms of holistic inference, transformational inference and confluent inference, are identified and compared and a dual-ported RAAM architecture based on Pollack's Recursive Auto-Associative Memory is implemented and demonstrated in the domain of Natural Language translation."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1749815"
                        ],
                        "name": "A. Sperduti",
                        "slug": "A.-Sperduti",
                        "structuredName": {
                            "firstName": "Alessandro",
                            "lastName": "Sperduti",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Sperduti"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1678493"
                        ],
                        "name": "A. Starita",
                        "slug": "A.-Starita",
                        "structuredName": {
                            "firstName": "Antonina",
                            "lastName": "Starita",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Starita"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1759124"
                        ],
                        "name": "C. Goller",
                        "slug": "C.-Goller",
                        "structuredName": {
                            "firstName": "Christoph",
                            "lastName": "Goller",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Goller"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 16117073,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bd210021bf4a559c1849351d90c20ce7fcd34dea",
            "isKey": false,
            "numCitedBy": 9,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper is a study on LRAAM-based (Labeling Recursive Auto-Associative Memory) clas-siication of symbolic recursive structures encoding terms. The results reported here have been obtained by combining an LRAAM network with an analog perceptron. The approach used was to interleave the development of representations (unsupervised learning of the LRAAM) with the learning of the classiica-tion task. In this way, the representations are optimized with respect to the classiica-tion task. The intended applications of our approach are hybrid (symbolic/connectionist) systems, where the connectionist part has to solve logic-oriented inductive learning tasks similar to the term-classiication problems used in our experiments. Speciically, we intend to use the classiication method for terms presented here for learning search control heuris-tics for symbolic reasoning systems."
            },
            "slug": "Distributed-representations-for-terms-in-hybrid-Sperduti-Starita",
            "title": {
                "fragments": [],
                "text": "Distributed representations for terms in hybrid reasoning systems"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "The intended applications of the approach are hybrid (symbolic/connectionist) systems, where the connectionist part has to solve logic-oriented inductive learning tasks similar to the term-classiication problems used in the experiments."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39143967"
                        ],
                        "name": "George Berg",
                        "slug": "George-Berg",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Berg",
                            "middleNames": [],
                            "suffix": ""
                        }
                    },
                    {
                        "fragments": [],
                        "text": "George Berg"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 12549784,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f48d6233238c9da9cf36cbcdc9e5d00cf6e1b4b0",
            "isKey": false,
            "numCitedBy": 52,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "In order to be taken seriously, connectionist natural language processing systems must be able to parse syntactically complex sentences. Current connectionist parsers either ignore structure or impose prior restrictions on the structural complexity of the sentences they can process -- either number of phrases or the \"depth\" of the sentence structure. XERIC networks, presented here, are distributed representation connectionist parsers which can analyze and represent syntactically varied sentences, including ones with recursive phrase structure constructs. No a priori limits are placed on the depth or length of sentences by the architecture. XERIC networks use recurrent networks to read words one at a time. RAAM style reduced descriptions and X-Bar grammar are used to make an economical syntactic representation scheme. This is combined with a training technique which allows XERIC to use multiple, virtual copies of its RAAM decoder network to learn to parse and represent sentence structure using gradient-descent methods. XERIC networks also perform number-person disambiguation and lexical disambiguation. Results show that the networks train to a few percent error for sentences up to a phrase-nesting depth of ten or more and that this performance generalizes well."
            },
            "slug": "A-Connectionist-Parser-with-Recursive-Sentence-and-Berg",
            "title": {
                "fragments": [],
                "text": "A Connectionist Parser with Recursive Sentence Structure and Lexical Disambiguation"
            },
            "tldr": {
                "abstractSimilarityScore": 53,
                "text": "XERIC networks, presented here, are distributed representation connectionist parsers which can analyze and represent syntactically varied sentences, including ones with recursive phrase structure constructs."
            },
            "venue": {
                "fragments": [],
                "text": "AAAI"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47055692"
                        ],
                        "name": "P. Werbos",
                        "slug": "P.-Werbos",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Werbos",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Werbos"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 151,
                                "start": 147
                            }
                        ],
                        "text": "We assume in the following the reader to be familiar with the standardbackpropagation algorithm (BP) and its variant backpropagation through time (BPTT) [10] that is usedto train recurrent network models."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 40,
                                "start": 36
                            }
                        ],
                        "text": "With a similar argument as for BPTT [10] we can see, that the exact gradient is computed."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 206,
                                "start": 202
                            }
                        ],
                        "text": "We present a simple architecture together with a novel supervised learning scheme that we call backpropagation through structure (BPTS) in analogy to backpropagation through time for recurrent networks [10]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 158,
                                "start": 154
                            }
                        ],
                        "text": "We assume in the following the reader to be familiar with the standard backpropagation algorithm (BP) and its variant backpropagation through time (BPTT) [10] that is used to train recurrent network models."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 18470994,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "1a3d22599028a05669e884f3eaf19a342e190a87",
            "isKey": true,
            "numCitedBy": 4036,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "Backpropagation is now the most widely used tool in the field of artificial neural networks. At the core of backpropagation is a method for calculating derivatives exactly and efficiently in any large system made up of elementary subsystems or calculations which are represented by known, differentiable functions; thus, backpropagation has many applications which do not involve neural networks as such. This paper first reviews basic backpropagation, a simple method which is now being widely used in areas like pattern recognition and fault diagnosis. Next, it presents the basic equations for backpropagation through time, and discusses applications to areas like pattern recognition involving dynamic systems, systems identification, and control. Finally, i t describes further extensions of this method, to deal with systems other than neural networks, systems involving simultaneous equations or true recurrent networks, and other practical issues which arise with this method. Pseudocode is provided to clarify the algorithms. The chain rule for ordered derivatives-the theorem which underlies backpropagation-is briefly discussed."
            },
            "slug": "Backpropagation-Through-Time:-What-It-Does-and-How-Werbos",
            "title": {
                "fragments": [],
                "text": "Backpropagation Through Time: What It Does and How to Do It"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This paper first reviews basic backpropagation, a simple method which is now being widely used in areas like pattern recognition and fault diagnosis, and describes further extensions of this method, to deal with systems other than neural networks, systems involving simultaneous equations or true recurrent networks, and other practical issues which arise with this method."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1755154"
                        ],
                        "name": "Douglas S. Blank",
                        "slug": "Douglas-S.-Blank",
                        "structuredName": {
                            "firstName": "Douglas",
                            "lastName": "Blank",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Douglas S. Blank"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3091735"
                        ],
                        "name": "L. Meeden",
                        "slug": "L.-Meeden",
                        "structuredName": {
                            "firstName": "Lisa",
                            "lastName": "Meeden",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Meeden"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1823028"
                        ],
                        "name": "James B. Marshall",
                        "slug": "James-B.-Marshall",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Marshall",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "James B. Marshall"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2852656,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "740ffad1ea3010f5d00ce3b34d8c2c400e9a6a52",
            "isKey": false,
            "numCitedBy": 92,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "It is di cult to clearly de ne the symbolic and subsymbolic paradigms; each is usually described by its tendencies rather than any one de nitive property. Symbolic processing is generally characterized by hard-coded, explicit rules operating on discrete, static tokens, while subsymbolic processing is associated with learned, fuzzy constraints a ecting continuous, distributed representations. In addition, programming languages such as Lisp and mechanisms such as Turing machines are typically associated with the symbolic paradigm, while connectionism is frequently associated with the subsymbolic paradigm. Debates contrasting the two paradigms sometimes center on these mechanisms, for example comparing the capabilities of Turing machines with those of connectionist networks (see Adams, Aizawa, and Fuller in this volume). However, connectionist networks can be proven to be computationally equivalent to the abstract notion of Turing machines [Franklin and Garzon, 1990]. Therefore the computational mechanism is not the crucial issue in separating the symbolic and subsymbolic paradigms. What then is the crucial issue? We believe there are three major issues which distinguish the symbolic paradigm from the subsymbolic paradigm: (1) the type of representations; (2) the style of composition; and (3) the functional characteristics. We have summarized the key elements of these di erences between the two paradigms in Table 1. However, most cognitive science and classical arti cial intelligence (AI) models cannot be completely characterized as either purely symbolic or purely subsymbolic using these criteria. Instead, most models fall somewhere in between the two extremes, or in the so-called \\Gap.\" For this reason, it seems appropriate to view the paradigms as de ning two opposite corners of a three-dimensional continuum as shown in"
            },
            "slug": "Exploring-the-Symbolic/Subsymbolic-Continuum:-A-of-Blank-Meeden",
            "title": {
                "fragments": [],
                "text": "Exploring the Symbolic/Subsymbolic Continuum: A case study of RAAM"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1749815"
                        ],
                        "name": "A. Sperduti",
                        "slug": "A.-Sperduti",
                        "structuredName": {
                            "firstName": "Alessandro",
                            "lastName": "Sperduti",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Sperduti"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5853754,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f03db7ef9cf309561eb02eb317b875deb8817c01",
            "isKey": false,
            "numCitedBy": 41,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we propose an extension to the RAAM by Pollack. This extension, the Labeling RAAM (LRAAM), can encode labeled graphs with cycles by representing pointers explicitly. Data encoded in an LRAAM can be accessed by pointer as well as by content. Direct access by content can be achieved by transforming the encoder network of the LRAAM into an analog Hopfield network with hidden units. Different access procedures can be defined depending on the access key. Sufficient conditions on the asymptotical stability of the associated Hopfield network are briefly introduced."
            },
            "slug": "Encoding-Labeled-Graphs-by-Labeling-RAAM-Sperduti",
            "title": {
                "fragments": [],
                "text": "Encoding Labeled Graphs by Labeling RAAM"
            },
            "tldr": {
                "abstractSimilarityScore": 63,
                "text": "The Labeling RAAM (LRAAM), an extension to the RAAM by Pollack, can encode labeled graphs with cycles by representing pointers explicitly by transforming the encoder network of the LRAAM into an analog Hopfield network with hidden units."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2681887"
                        ],
                        "name": "D. Rumelhart",
                        "slug": "D.-Rumelhart",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Rumelhart",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Rumelhart"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2116648700"
                        ],
                        "name": "Ronald J. Williams",
                        "slug": "Ronald-J.-Williams",
                        "structuredName": {
                            "firstName": "Ronald",
                            "lastName": "Williams",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ronald J. Williams"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 62245742,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "111fd833a4ae576cfdbb27d87d2f8fc0640af355",
            "isKey": false,
            "numCitedBy": 19354,
            "numCiting": 66,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Learning-internal-representations-by-error-Rumelhart-Hinton",
            "title": {
                "fragments": [],
                "text": "Learning internal representations by error propagation"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3224336"
                        ],
                        "name": "L. Niklasson",
                        "slug": "L.-Niklasson",
                        "structuredName": {
                            "firstName": "Lars",
                            "lastName": "Niklasson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Niklasson"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 60666283,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "4add0dd0041403f585cf85b455aae487e37dfd3a",
            "isKey": false,
            "numCitedBy": 17,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Annotation: Published in The Proceedings of the 1993 Connectionist Models Summer School, (Eds) Mozer et al., Lawrence Erlbaum, 1993."
            },
            "slug": "Structure-Sensitivity-in-Connectionist-Models-Niklasson",
            "title": {
                "fragments": [],
                "text": "Structure Sensitivity in Connectionist Models"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "Annotation: Published in The Proceedings of the 1993 Connectionist Models Summer School, (Eds) Mozer et al., Lawrence Erlbaum, 1993."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 76,
                                "start": 71
                            }
                        ],
                        "text": "Labeling RAAMThe architecture we use is inspired by the Labeling RAAM (LRAAM) [8], an extension of the RAAM [7]model that learns xed-width distributed representations for labeled variable-sized recursive data structures."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 20,
                                "start": 15
                            }
                        ],
                        "text": "Obviously, the LRAAMChas to solve the additional task of developing unique representations, i.e. to minimize the encoding-decodingerror ( ) % Dec.-Enc., in Table 2)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 108,
                                "start": 103
                            }
                        ],
                        "text": "Furthermore, as the error from the classi er is not propagated recursively through thestructure in the LRAAMC, the exact gradient is not computed and (in contrast to our approach) therepresentations of subterms are not optimized directly for the classi cation task concerning their parents.5."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 55,
                                "start": 50
                            }
                        ],
                        "text": "The rst two layers occupy the role of thestandard LRAAM encoder part, the hidden units are connected to a simple sigmoid feedforward layer, inour case just one unit for classi cation."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 72,
                                "start": 67
                            }
                        ],
                        "text": "Why is the folding architecture together with BPTS superior to the LRAAMC?"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 44,
                                "start": 39
                            }
                        ],
                        "text": "This would be done in the same way for LRAAM-derived representations."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 13,
                                "start": 8
                            }
                        ],
                        "text": "For the LRAAM training as well as for BPTS (as we will show in the following two sections) the number offorward and backward phases per epoch is linear to the number of nodes in the DAG-representation of thetraining set.\nf f f\na a a a\ng\nf\na a\na\nf f a g f(f(a,a),f(a,a)) g(f(a,a),a) Terms Tree-Representation Dag-RepresentationFig."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 127,
                                "start": 122
                            }
                        ],
                        "text": "Our folding architecture supplied with BPTS leads to nearly the same or slightly better classi cationperformance than the LRAAMC approach."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 33,
                                "start": 28
                            }
                        ],
                        "text": "The general structurefor an LRAAM is that of a three-layer feedforward network (see Figure 1, right).\nm units m units m unitsn units m units\nlabel branch 1 branch 2 branch k\nHidden\nOutput\nInput\n(n+km) units\nEncoder\nClassifier\nm units m units m units m units m units n units n units\nm units\nm units\nlabel branch 1 branch 2 branch k\nHidden\nOutput\nInput\n(n+km) units\nEncoder\nDecoderFig."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 108,
                                "start": 103
                            }
                        ],
                        "text": "The performanceof the folding architecture with BPTS is listed together with the results of a combined LRAAM-classi er2(LRAAMC) architecture () 4) whenever results for the LRAAMC were available [6]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 82,
                                "start": 79
                            }
                        ],
                        "text": "Labeling RAAM The architecture we use is inspired by the Labeling RAAM (LRAAM) [8], an extension of the RAAM [7] model that learns xed-width distributed representations for labeled variable-sized recursive data structures."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 138,
                                "start": 133
                            }
                        ],
                        "text": "In the forward phasethe encoder (Figure 1, left) is used to compute a representation for a given tree in the same way as inthe plain LRAAM."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 188,
                                "start": 183
                            }
                        ],
                        "text": "But this has been achieved by a topology which uses one1We de ne the depth of a term as the maximum number of edges between the root and leaf nodes in the term's LDAG-representation.2LRAAMC uses a special dynamic pattern selection strategy for network training and applies di erent learning parametersto the LRAAM () ) and the classi er () ).\norder of magnitude less hidden units and by a learning procedure which needs more than one order ofmagnitude less training epochs to converge to the same performance."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 62,
                                "start": 57
                            }
                        ],
                        "text": "1: The Folding Architecture (left side) and the standard LRAAM (right side)."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Encoding of Labeled Graphs by Labeling RAAM,\" in NIPS 6"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 146,
                                "start": 140
                            }
                        ],
                        "text": "There have been several publications showing the appropriateness of representations produced by the RAAM for subsequent classi cation tasks [3, 6] and also for more complex tasks even with structured output [2, 4]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 58,
                                "start": 55
                            }
                        ],
                        "text": "The set of problems is an extension of the one used in [6]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 184,
                                "start": 181
                            }
                        ],
                        "text": "We show that all classi cation problems can be solved with smaller networks, less training epochs and better classi cation results than with using the ordinary RAAM learning scheme [6]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Distributed Representations for the Classi cation of  Terms,"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the IJCAI"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1762744"
                        ],
                        "name": "A. Stolcke",
                        "slug": "A.-Stolcke",
                        "structuredName": {
                            "firstName": "Andreas",
                            "lastName": "Stolcke",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Stolcke"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2390150"
                        ],
                        "name": "Dekai Wu",
                        "slug": "Dekai-Wu",
                        "structuredName": {
                            "firstName": "Dekai",
                            "lastName": "Wu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dekai Wu"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 60182639,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e69119c2909dcbbc29a01ee8cd8b3e6577a1968d",
            "isKey": false,
            "numCitedBy": 37,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Tree-matching-with-recursive-distributed-Stolcke-Wu",
            "title": {
                "fragments": [],
                "text": "Tree matching with recursive distributed representations"
            },
            "venue": {
                "fragments": [],
                "text": "AAAI 1992"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2235757"
                        ],
                        "name": "V. Cadoret",
                        "slug": "V.-Cadoret",
                        "structuredName": {
                            "firstName": "Vincent",
                            "lastName": "Cadoret",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Cadoret"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 39999249,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0f67caf90fe8f43845adc67f40d084bef25fbb31",
            "isKey": false,
            "numCitedBy": 6,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Encoding-Syntactical-Trees-with-Labelling-Recursive-Cadoret",
            "title": {
                "fragments": [],
                "text": "Encoding Syntactical Trees with Labelling Recursive Auto-Associative Memory"
            },
            "venue": {
                "fragments": [],
                "text": "ECAI"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39143967"
                        ],
                        "name": "George Berg",
                        "slug": "George-Berg",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Berg",
                            "middleNames": [],
                            "suffix": ""
                        }
                    },
                    {
                        "fragments": [],
                        "text": "George Berg"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9613206,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f100facfc5dff3de578ede2558deeaa17f1e42f8",
            "isKey": false,
            "numCitedBy": 9,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Learning-Recursive-Phrase-Structure:-Combining-the-Berg",
            "title": {
                "fragments": [],
                "text": "Learning Recursive Phrase Structure: Combining the Strengths of PDP and X-Bar Syntax"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1991
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Recursive Distributed Representations. Artiicial Intelligence"
            },
            "venue": {
                "fragments": [],
                "text": "Recursive Distributed Representations. Artiicial Intelligence"
            },
            "year": 1990
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Learning Task-Dependent Distributed Representations by Backpropagation Through Structure,"
            },
            "venue": {
                "fragments": [],
                "text": "AR-report AR-95-02,"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 12,
                                "start": 9
                            }
                        ],
                        "text": "Refer to [5] for a detailed discussion and formal speci cation of the given algorithms."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "uchler, \\Learning Task-Dependent Distributed Representations by Backpropagation  Through Structure,\" AR-report AR-95-02, Institut f\u007f  ur Informatik, Technische Universit\u007f  at M\u007f"
            },
            "venue": {
                "fragments": [],
                "text": "unchen,"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "\\Recursive Distributed Representations Artiicial Intelligence"
            },
            "venue": {
                "fragments": [],
                "text": "\\Recursive Distributed Representations Artiicial Intelligence"
            },
            "year": 1990
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 2,
            "methodology": 3
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 19,
        "totalPages": 2
    },
    "page_url": "https://www.semanticscholar.org/paper/Learning-task-dependent-distributed-representations-Goller-K\u00fcchler/c58dd287a476b4722c5b6b1316629e2874682219?sort=total-citations"
}