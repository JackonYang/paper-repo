{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1885312"
                        ],
                        "name": "Sheikh Faisal Rashid",
                        "slug": "Sheikh-Faisal-Rashid",
                        "structuredName": {
                            "firstName": "Sheikh",
                            "lastName": "Rashid",
                            "middleNames": [
                                "Faisal"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sheikh Faisal Rashid"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "81314270"
                        ],
                        "name": "A. Akmal",
                        "slug": "A.-Akmal",
                        "structuredName": {
                            "firstName": "Ab.",
                            "lastName": "Akmal",
                            "middleNames": [
                                "Razak",
                                "Nurul",
                                "Saidatul"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Akmal"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1739137808"
                        ],
                        "name": "M. Adnan",
                        "slug": "M.-Adnan",
                        "structuredName": {
                            "firstName": "Muhammad",
                            "lastName": "Adnan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Adnan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "33354035"
                        ],
                        "name": "Ali Adnan Aslam",
                        "slug": "Ali-Adnan-Aslam",
                        "structuredName": {
                            "firstName": "Ali",
                            "lastName": "Aslam",
                            "middleNames": [
                                "Adnan"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ali Adnan Aslam"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145279674"
                        ],
                        "name": "A. Dengel",
                        "slug": "A.-Dengel",
                        "structuredName": {
                            "firstName": "Andreas",
                            "lastName": "Dengel",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Dengel"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 193,
                                "start": 189
                            }
                        ],
                        "text": "Table detection and recognition in unconstrained documents is considered a challenging task and recently has received significant attention within the community [2], [7], [11], [16], [19], [22], [24]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 4775097,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4be161e3c9731f0c431ce5d890441c867b872938",
            "isKey": false,
            "numCitedBy": 28,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "Tables are an easy way to represent information in a structural form. Table recognition is important for the extraction of such information from document images. Usually, modern OCR systems provide textual information coming from tables without recognizing actual table structure. However, recognition of table structure is important to get the contextual meaning of the contents. Table structure recognition in heterogeneous documents is challenging due to a variety of table layouts. It becomes harder where no physical rulings are present in a table. This work proposes a novel learning based methodology for the recognition of table contents in heterogeneous document images. Textual contents of documents are classified as table or non-table elements using a pre-trained neural network model. The output of the neural network is further enhanced by applying a contextual post processing on each element to correct the classifications errors if any. The system is trained using a subset of UNLV and UW3 document images and depicted more than 97% accuracy on a test set in detection of table and non-table elements."
            },
            "slug": "Table-Recognition-in-Heterogeneous-Documents-Using-Rashid-Akmal",
            "title": {
                "fragments": [],
                "text": "Table Recognition in Heterogeneous Documents Using Machine Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "This work proposes a novel learning based methodology for the recognition of table contents in heterogeneous document images and depicts more than 97% accuracy on a test set in detection of table and non-table elements."
            },
            "venue": {
                "fragments": [],
                "text": "2017 14th IAPR International Conference on Document Analysis and Recognition (ICDAR)"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1402440928"
                        ],
                        "name": "Azka Gilani",
                        "slug": "Azka-Gilani",
                        "structuredName": {
                            "firstName": "Azka",
                            "lastName": "Gilani",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Azka Gilani"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39404123"
                        ],
                        "name": "S. Qasim",
                        "slug": "S.-Qasim",
                        "structuredName": {
                            "firstName": "Shah",
                            "lastName": "Qasim",
                            "middleNames": [
                                "Rukh"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Qasim"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49012494"
                        ],
                        "name": "M. I. Malik",
                        "slug": "M.-I.-Malik",
                        "structuredName": {
                            "firstName": "Muhammad",
                            "lastName": "Malik",
                            "middleNames": [
                                "Imran"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. I. Malik"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688013"
                        ],
                        "name": "F. Shafait",
                        "slug": "F.-Shafait",
                        "structuredName": {
                            "firstName": "Faisal",
                            "lastName": "Shafait",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Shafait"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 3,
                                "start": 0
                            }
                        ],
                        "text": "[7] proposed a variant of region proposal network where they feed pre-processed document images for detecting tables."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 169,
                                "start": 166
                            }
                        ],
                        "text": "Table detection and recognition in unconstrained documents is considered a challenging task and recently has received significant attention within the community [2], [7], [11], [16], [19], [22], [24]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 206777650,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9d6931dd0ba9e492b0ceab00268ca4be62ef663a",
            "isKey": false,
            "numCitedBy": 91,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "Table detection is a crucial step in many document analysis applications as tables are used for presenting essential information to the reader in a structured manner. It is a hard problem due to varying layouts and encodings of the tables. Researchers have proposed numerous techniques for table detection based on layout analysis of documents. Most of these techniques fail to generalize because they rely on hand engineered features which are not robust to layout variations. In this paper, we have presented a deep learning based method for table detection. In the proposed method, document images are first pre-processed. These images are then fed to a Region Proposal Network followed by a fully connected neural network for table detection. The proposed method works with high precision on document images with varying layouts that include documents, research papers, and magazines. We have done our evaluations on publicly available UNLV dataset where it beats Tesseract's state of the art table detection system by a significant margin."
            },
            "slug": "Table-Detection-Using-Deep-Learning-Gilani-Qasim",
            "title": {
                "fragments": [],
                "text": "Table Detection Using Deep Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The proposed method works with high precision on document images with varying layouts that include documents, research papers, and magazines and beats Tesseract's state of the art table detection system by a significant margin."
            },
            "venue": {
                "fragments": [],
                "text": "2017 14th IAPR International Conference on Document Analysis and Recognition (ICDAR)"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2057440295"
                        ],
                        "name": "Sebastian Schreiber",
                        "slug": "Sebastian-Schreiber",
                        "structuredName": {
                            "firstName": "Sebastian",
                            "lastName": "Schreiber",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sebastian Schreiber"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2582412"
                        ],
                        "name": "S. Agne",
                        "slug": "S.-Agne",
                        "structuredName": {
                            "firstName": "Stefan",
                            "lastName": "Agne",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Agne"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144651288"
                        ],
                        "name": "I. Wolf",
                        "slug": "I.-Wolf",
                        "structuredName": {
                            "firstName": "Ivo",
                            "lastName": "Wolf",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Wolf"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145279674"
                        ],
                        "name": "A. Dengel",
                        "slug": "A.-Dengel",
                        "structuredName": {
                            "firstName": "Andreas",
                            "lastName": "Dengel",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Dengel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1734717217"
                        ],
                        "name": "Sheraz Ahmed",
                        "slug": "Sheraz-Ahmed",
                        "structuredName": {
                            "firstName": "Sheraz",
                            "lastName": "Ahmed",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sheraz Ahmed"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 88,
                                "start": 84
                            }
                        ],
                        "text": "A similar approach based on a region proposal network is also proposed in DeepDeSRT [24] for detecting tables, they further extended it to rows and column detection."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 199,
                                "start": 195
                            }
                        ],
                        "text": "Table detection and recognition in unconstrained documents is considered a challenging task and recently has received significant attention within the community [2], [7], [11], [16], [19], [22], [24]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 10191334,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f8bead3ae810cd3f7427d3004e45b4158da9b744",
            "isKey": false,
            "numCitedBy": 158,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a novel end-to-end system for table understanding in document images called DeepDeSRT. In particular, the contribution of DeepDeSRT is two-fold. First, it presents a deep learning-based solution for table detection in document images. Secondly, it proposes a novel deep learning-based approach for table structure recognition, i.e. identifying rows, columns, and cell positions in the detected tables. In contrast to existing rule-based methods, which rely on heuristics or additional PDF metadata (like, for example, print instructions, character bounding boxes, or line segments), the presented system is data-driven and does not need any heuristics or metadata to detect as well as to recognize tabular structures in document images. Furthermore, in contrast to most existing table detection and structure recognition methods, which are applicable only to PDFs, DeepDeSRT processes document images, which makes it equally suitable for born-digital PDFs (as they can automatically be converted into images) as well as even harder problems, e.g. scanned documents. To gauge the performance of DeepDeSRT, the system is evaluated on the publicly available ICDAR 2013 table competition dataset containing 67 documents with 238 pages overall. Evaluation results reveal that DeepDeSRT outperforms state-of-the-art methods for table detection and structure recognition and achieves F1-measures of 96.77% and 91.44% for table detection and structure recognition, respectively. Additionally, DeepDeSRT is evaluated on a closed dataset from a real use case of a major European aviation company comprising documents which are highly unlike those in ICDAR 2013. Tested on a randomly selected sample from this dataset, DeepDeSRT achieves high detection accuracy for tables which demonstrates the sound generalization capabilities of our system."
            },
            "slug": "DeepDeSRT:-Deep-Learning-for-Detection-and-of-in-Schreiber-Agne",
            "title": {
                "fragments": [],
                "text": "DeepDeSRT: Deep Learning for Detection and Structure Recognition of Tables in Document Images"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "In contrast to most existing table detection and structure recognition methods, which are applicable only to PDFs, DeepDeSRT processes document images, which makes it equally suitable for born-digital PDFs as well as even harder problems, e.g. scanned documents."
            },
            "venue": {
                "fragments": [],
                "text": "2017 14th IAPR International Conference on Document Analysis and Recognition (ICDAR)"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "103233751"
                        ],
                        "name": "D. Lohani",
                        "slug": "D.-Lohani",
                        "structuredName": {
                            "firstName": "D.",
                            "lastName": "Lohani",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Lohani"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2128453"
                        ],
                        "name": "A. Bela\u00efd",
                        "slug": "A.-Bela\u00efd",
                        "structuredName": {
                            "firstName": "Abdel",
                            "lastName": "Bela\u00efd",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Bela\u00efd"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2448729"
                        ],
                        "name": "Y. Bela\u00efd",
                        "slug": "Y.-Bela\u00efd",
                        "structuredName": {
                            "firstName": "Yolande",
                            "lastName": "Bela\u00efd",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Bela\u00efd"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[19] proposed the same GCN-based technique for recognizing different fields in an invoice."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 187,
                                "start": 183
                            }
                        ],
                        "text": "Table detection and recognition in unconstrained documents is considered a challenging task and recently has received significant attention within the community [2], [7], [11], [16], [19], [22], [24]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 195064850,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1c1b85ba3c5b6e78e3c027d792f3afeef08cdac5",
            "isKey": false,
            "numCitedBy": 19,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we present a model-free system for reading digitized invoice images, which highlights the most useful billing entities and does not require any particular parameterization. The power of the system lies in the fact that it generalizes to both seen and unseen layouts of invoice. The system first breaks down the invoice data into various set of entities to extract and then learns structural and semantic information for each entity to extract via a graph structure, which is later generalized to the whole invoice structure. This local neighborhood exploitation is accomplished via a Graph Convolutional Network (GCN). The system digs deep to extract table information and provide complete invoice reading upto 27 entities of interest without any template information or configuration with an excellent overall F-measure score of 0.93."
            },
            "slug": "An-Invoice-Reading-System-Using-a-Graph-Network-Lohani-Bela\u00efd",
            "title": {
                "fragments": [],
                "text": "An Invoice Reading System Using a Graph Convolutional Network"
            },
            "tldr": {
                "abstractSimilarityScore": 81,
                "text": "A model-free system for reading digitized invoice images, which highlights the most useful billing entities and does not require any particular parameterization and generalizes to both seen and unseen layouts of invoice."
            },
            "venue": {
                "fragments": [],
                "text": "ACCV Workshops"
            },
            "year": 2018
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2912641"
                        ],
                        "name": "I. Kavasidis",
                        "slug": "I.-Kavasidis",
                        "structuredName": {
                            "firstName": "Isaak",
                            "lastName": "Kavasidis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Kavasidis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46792082"
                        ],
                        "name": "S. Palazzo",
                        "slug": "S.-Palazzo",
                        "structuredName": {
                            "firstName": "Sergio",
                            "lastName": "Palazzo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Palazzo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2441118"
                        ],
                        "name": "C. Spampinato",
                        "slug": "C.-Spampinato",
                        "structuredName": {
                            "firstName": "Concetto",
                            "lastName": "Spampinato",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Spampinato"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145587660"
                        ],
                        "name": "C. Pino",
                        "slug": "C.-Pino",
                        "structuredName": {
                            "firstName": "Carmelo",
                            "lastName": "Pino",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Pino"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144027622"
                        ],
                        "name": "D. Giordano",
                        "slug": "D.-Giordano",
                        "structuredName": {
                            "firstName": "Daniela",
                            "lastName": "Giordano",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Giordano"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2076542103"
                        ],
                        "name": "D. Giuffrida",
                        "slug": "D.-Giuffrida",
                        "structuredName": {
                            "firstName": "Dario",
                            "lastName": "Giuffrida",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Giuffrida"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "19324186"
                        ],
                        "name": "P. Messina",
                        "slug": "P.-Messina",
                        "structuredName": {
                            "firstName": "Pablo",
                            "lastName": "Messina",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Messina"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 175,
                                "start": 171
                            }
                        ],
                        "text": "Table detection and recognition in unconstrained documents is considered a challenging task and recently has received significant attention within the community [2], [7], [11], [16], [19], [22], [24]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 4899629,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "03672cfa599950f208d424d5298cdc12b72c2492",
            "isKey": false,
            "numCitedBy": 58,
            "numCiting": 60,
            "paperAbstract": {
                "fragments": [],
                "text": "Deep Convolutional Neural Networks (DCNNs) have recently been applied successfully to a variety of vision and multimedia tasks, thus driving development of novel solutions in several application domains. Document analysis is a particularly promising area for DCNNs: indeed, the number of available digital documents has reached unprecedented levels, and humans are no longer able to discover and retrieve all the information contained in these documents without the help of automation. Under this scenario, DCNNs offers a viable solution to automate the information extraction process from digital documents. Within the realm of information extraction from documents, detection of tables and charts is particularly needed as they contain a visual summary of the most valuable information contained in a document. For a complete automation of visual information extraction process from tables and charts, it is necessary to develop techniques that localize them and identify precisely their boundaries. In this paper we aim at solving the table/chart detection task through an approach that combines deep convolutional neural networks, graphical models and saliency concepts. In particular, we propose a saliency-based fully-convolutional neural network performing multi-scale reasoning on visual cues followed by a fully-connected conditional random field (CRF) for localizing tables and charts in digital/digitized documents. Performance analysis carried out on an extended version of ICDAR 2013 (with annotated charts as well as tables) shows that our approach yields promising results, outperforming existing models."
            },
            "slug": "A-Saliency-based-Convolutional-Neural-Network-for-Kavasidis-Palazzo",
            "title": {
                "fragments": [],
                "text": "A Saliency-based Convolutional Neural Network for Table and Chart Detection in Digitized Documents"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "A saliency-based fully-convolutional neural network performing multi-scale reasoning on visual cues followed by a fully-connected conditional random field (CRF) for localizing tables and charts in digital/digitized documents is proposed."
            },
            "venue": {
                "fragments": [],
                "text": "ICIAP"
            },
            "year": 2019
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688013"
                        ],
                        "name": "F. Shafait",
                        "slug": "F.-Shafait",
                        "structuredName": {
                            "firstName": "Faisal",
                            "lastName": "Shafait",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Shafait"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108985360"
                        ],
                        "name": "Raymond W. Smith",
                        "slug": "Raymond-W.-Smith",
                        "structuredName": {
                            "firstName": "Raymond",
                            "lastName": "Smith",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Raymond W. Smith"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 131,
                                "start": 127
                            }
                        ],
                        "text": "As a consequence, most of the methods do not work well on multi-column document images for making some simplifying assumptions [25]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 2534837,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2dea52f04a90dc993d2aa30e75b5a5a535e7ca70",
            "isKey": false,
            "numCitedBy": 96,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "Detecting tables in document images is important since not only do tables contain important information, but also most of the layout analysis methods fail in the presence of tables in the document image. Existing approaches for table detection mainly focus on detecting tables in single columns of text and do not work reliably on documents with varying layouts. This paper presents a practical algorithm for table detection that works with a high accuracy on documents with varying layouts (company reports, newspaper articles, magazine pages, ...). An open source implementation of the algorithm is provided as part of the Tesseract OCR engine. Evaluation of the algorithm on document images from publicly available UNLV dataset shows competitive performance in comparison to the table detection module of a commercial OCR system."
            },
            "slug": "Table-detection-in-heterogeneous-documents-Shafait-Smith",
            "title": {
                "fragments": [],
                "text": "Table detection in heterogeneous documents"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "Evaluation of the algorithm on document images from publicly available UNLV dataset shows competitive performance in comparison to the table detection module of a commercial OCR system."
            },
            "venue": {
                "fragments": [],
                "text": "DAS '10"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3320897"
                        ],
                        "name": "T. Kieninger",
                        "slug": "T.-Kieninger",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Kieninger",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kieninger"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145279674"
                        ],
                        "name": "A. Dengel",
                        "slug": "A.-Dengel",
                        "structuredName": {
                            "firstName": "Andreas",
                            "lastName": "Dengel",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Dengel"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 61,
                                "start": 57
                            }
                        ],
                        "text": "on this topic were mostly bottom-up in nature [1], [12], [13], [27], and they often start by detecting words or parallel lines"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 58220542,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d1fdbf577a1b8d6e78556a509326bbf304af5780",
            "isKey": false,
            "numCitedBy": 20,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "Document organization may be described in different ways. The physical presentation on one hand by means of a nested layout structure representing a \u201cpart-of\u201d-relationship, e.g. of text blocks, text line segments, words, and characters. The composition of meaningful entities, such as title, author, address, or abstract, on the other, in terms of a logical structure. Both views to the contents of a document are complementary. They relate to each other as being explicitely given by publication guidelines where the position and dimensions of logical objects are precisely described. Moreover such \u201cpublication guidelines\u201d more or less hold for various types of documents. Although they are intuitively understandable for human beings, they are hard to formalize explicitly because of the freedom originators and authors of documents have in order to incorporate their own creativity. However, humans use these intrinsic layout features to get first hints towards the logical meaning of document information. This is even obvious when considering the very difficult document examples in Figure 1 where no text is given but it is nevertheless possible to generate hypothesis for logical meaning."
            },
            "slug": "Table-Recognition-and-Labeling-Using-Intrinsic-Kieninger-Dengel",
            "title": {
                "fragments": [],
                "text": "Table Recognition and Labeling Using Intrinsic Layout Features"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "Although intrinsic layout features of documents are intuitively understandable for human beings, they are hard to formalize explicitly because of the freedom originators and authors of documents have in order to incorporate their own creativity."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3320897"
                        ],
                        "name": "T. Kieninger",
                        "slug": "T.-Kieninger",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Kieninger",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kieninger"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145279674"
                        ],
                        "name": "A. Dengel",
                        "slug": "A.-Dengel",
                        "structuredName": {
                            "firstName": "Andreas",
                            "lastName": "Dengel",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Dengel"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 55,
                                "start": 51
                            }
                        ],
                        "text": "on this topic were mostly bottom-up in nature [1], [12], [13], [27], and they often start by detecting words or parallel lines"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 206776168,
            "fieldsOfStudy": [
                "Business"
            ],
            "id": "d25a61cc0cd816eba75864912fe2f6f44be3cecf",
            "isKey": false,
            "numCitedBy": 75,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper summarizes the core idea of the T-Recs table recognition system, an integrated system covering block-segmentation, table location and a model-free structural analysis of tables. T-Recs works on the output of commercial OCR systems that provide the word bounding box geometry together with the text itself (e.g. Xerox ScanWorX). While T-Recs performs well on a number of document categories, business letters still remained a challenging domain because the T-Recs location heuristics are mislead by their header or footer resulting in a low recognition precision. Business letters such as invoices are a very interesting domain for industrial applications due to the large amount of documents to be analyzed and the importance of the data carried within their tables. Hence, we developed a more restrictive approach which is implemented in the T-Recs++ prototype. This paper describes the ideas of the T-Recs++ location and also proposes a quality evaluation measure that reflects the bottom-up strategy of either T-Recs or T-Recs++. Finally, some results comparing both systems on a collection of business letters are given."
            },
            "slug": "Applying-the-T-Recs-table-recognition-system-to-the-Kieninger-Dengel",
            "title": {
                "fragments": [],
                "text": "Applying the T-Recs table recognition system to the business letter domain"
            },
            "tldr": {
                "abstractSimilarityScore": 79,
                "text": "This paper summarizes the core idea of the T-Recs table recognition system, an integrated system covering block-segmentation, table location and a model-free structural analysis of tables, and proposes a quality evaluation measure that reflects the bottom-up strategy of either T-recs or T- Recs++."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of Sixth International Conference on Document Analysis and Recognition"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1757263"
                        ],
                        "name": "Elvis Koci",
                        "slug": "Elvis-Koci",
                        "structuredName": {
                            "firstName": "Elvis",
                            "lastName": "Koci",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Elvis Koci"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2405035"
                        ],
                        "name": "Maik Thiele",
                        "slug": "Maik-Thiele",
                        "structuredName": {
                            "firstName": "Maik",
                            "lastName": "Thiele",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Maik Thiele"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7337091"
                        ],
                        "name": "Wolfgang Lehner",
                        "slug": "Wolfgang-Lehner",
                        "structuredName": {
                            "firstName": "Wolfgang",
                            "lastName": "Lehner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wolfgang Lehner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144149891"
                        ],
                        "name": "Oscar Romero",
                        "slug": "Oscar-Romero",
                        "structuredName": {
                            "firstName": "Oscar",
                            "lastName": "Romero",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Oscar Romero"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[16] proposed another graph-based method, where instead of a GCN, they proposed the remove and conquer algorithm for detecting tables."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 181,
                                "start": 177
                            }
                        ],
                        "text": "Table detection and recognition in unconstrained documents is considered a challenging task and recently has received significant attention within the community [2], [7], [11], [16], [19], [22], [24]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 49419621,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "72babebcd6e61988d6caa1fb2e98a26a642862d3",
            "isKey": false,
            "numCitedBy": 26,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "Spreadsheet software are very popular data management tools. Their ease of use and abundant functionalities equip novices and professionals alike with the means to generate, transform, analyze, and visualize data. As a result, spreadsheets are a great resource of factual and structured information. This accentuates the need to automatically understand and extract their contents. In this paper, we present a novel approach for recognizing tables in spreadsheets. Having inferred the layout role of the individual cells, we build layout regions. We encode the spatial interrelations between these regions using a graph representation. Based on this, we propose Remove and Conquer (RAC), an algorithm for table recognition that implements a list of carefully curated rules. An extensive experimental evaluation shows that our approach is viable. We achieve significant accuracy in a dataset of real spreadsheets from various domains."
            },
            "slug": "Table-Recognition-in-Spreadsheets-via-a-Graph-Koci-Thiele",
            "title": {
                "fragments": [],
                "text": "Table Recognition in Spreadsheets via a Graph Representation"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This paper proposes Remove and Conquer (RAC), an algorithm for table recognition that implements a list of carefully curated rules that achieves significant accuracy in a dataset of real spreadsheets from various domains."
            },
            "venue": {
                "fragments": [],
                "text": "2018 13th IAPR International Workshop on Document Analysis Systems (DAS)"
            },
            "year": 2018
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1768769"
                        ],
                        "name": "F. Cesarini",
                        "slug": "F.-Cesarini",
                        "structuredName": {
                            "firstName": "Francesca",
                            "lastName": "Cesarini",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Cesarini"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3285734"
                        ],
                        "name": "S. Marinai",
                        "slug": "S.-Marinai",
                        "structuredName": {
                            "firstName": "Simone",
                            "lastName": "Marinai",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Marinai"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2608269"
                        ],
                        "name": "L. Sarti",
                        "slug": "L.-Sarti",
                        "structuredName": {
                            "firstName": "Lorenzo",
                            "lastName": "Sarti",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Sarti"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2540925"
                        ],
                        "name": "G. Soda",
                        "slug": "G.-Soda",
                        "structuredName": {
                            "firstName": "Giovanni",
                            "lastName": "Soda",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Soda"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 49,
                                "start": 46
                            }
                        ],
                        "text": "on this topic were mostly bottom-up in nature [1], [12], [13], [27], and they often start by detecting words or parallel lines"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1551166,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "56d3298d06b3eb5d479b33d8d9e59eff774965f4",
            "isKey": false,
            "numCitedBy": 45,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe an approach for table location in document images. The documents are described by means of a hierarchical representation that is based on the MXY tree. The presence of a table is hypothesized by searching parallel lines in the MXY tree of the page. This hypothesis is afterwards verified by locating perpendicular lines or white spaces in the region included between the parallel lines. Lastly, located tables can be merged on the basis of proximity and similarity criteria. The use of an optimization method, that relies on the definition of an appropriate table location index, allows us to identify, the optimal values of thresholds involved in the algorithm. In this way the algorithm can be adapted to recognize tables with different features by maximizing the performance on an appropriate training set. The algorithm has been evaluated on two data-sets containing more than 1500 pages, and comparing its results with the tables identified by two commercial OCRs."
            },
            "slug": "Trainable-table-location-in-document-images-Cesarini-Marinai",
            "title": {
                "fragments": [],
                "text": "Trainable table location in document images"
            },
            "tldr": {
                "abstractSimilarityScore": 70,
                "text": "An approach for table location in document images is described by means of a hierarchical representation that is based on the MXY tree and the use of an optimization method allows us to identify the optimal values of thresholds involved in the algorithm."
            },
            "venue": {
                "fragments": [],
                "text": "Object recognition supported by user interaction for service robots"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47002813"
                        ],
                        "name": "Yujia Li",
                        "slug": "Yujia-Li",
                        "structuredName": {
                            "firstName": "Yujia",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yujia Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1725299"
                        ],
                        "name": "Daniel Tarlow",
                        "slug": "Daniel-Tarlow",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Tarlow",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Daniel Tarlow"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2107692"
                        ],
                        "name": "Marc Brockschmidt",
                        "slug": "Marc-Brockschmidt",
                        "structuredName": {
                            "firstName": "Marc",
                            "lastName": "Brockschmidt",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Marc Brockschmidt"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1804104"
                        ],
                        "name": "R. Zemel",
                        "slug": "R.-Zemel",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Zemel",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Zemel"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 189,
                                "start": 185
                            }
                        ],
                        "text": "Spatial methods extend the idea of Convolutional Neural Networks (CNNs) for images and define a set of operations involving the local neighbourhood to compute a new representation [4], [18]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 8393918,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "492f57ee9ceb61fb5a47ad7aebfec1121887a175",
            "isKey": false,
            "numCitedBy": 1968,
            "numCiting": 42,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract: Graph-structured data appears frequently in domains including chemistry, natural language semantics, social networks, and knowledge bases. In this work, we study feature learning techniques for graph-structured inputs. Our starting point is previous work on Graph Neural Networks (Scarselli et al., 2009), which we modify to use gated recurrent units and modern optimization techniques and then extend to output sequences. The result is a flexible and broadly useful class of neural network models that has favorable inductive biases relative to purely sequence-based models (e.g., LSTMs) when the problem is graph-structured. We demonstrate the capabilities on some simple AI (bAbI) and graph algorithm learning tasks. We then show it achieves state-of-the-art performance on a problem from program verification, in which subgraphs need to be matched to abstract data structures."
            },
            "slug": "Gated-Graph-Sequence-Neural-Networks-Li-Tarlow",
            "title": {
                "fragments": [],
                "text": "Gated Graph Sequence Neural Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This work studies feature learning techniques for graph-structured inputs and achieves state-of-the-art performance on a problem from program verification, in which subgraphs need to be matched to abstract data structures."
            },
            "venue": {
                "fragments": [],
                "text": "ICLR"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34939798"
                        ],
                        "name": "Adam W. Harley",
                        "slug": "Adam-W.-Harley",
                        "structuredName": {
                            "firstName": "Adam",
                            "lastName": "Harley",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Adam W. Harley"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2079687415"
                        ],
                        "name": "Alex Ufkes",
                        "slug": "Alex-Ufkes",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Ufkes",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alex Ufkes"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3150825"
                        ],
                        "name": "K. Derpanis",
                        "slug": "K.-Derpanis",
                        "structuredName": {
                            "firstName": "Konstantinos",
                            "lastName": "Derpanis",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Derpanis"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 92,
                                "start": 84
                            }
                        ],
                        "text": "Additionally, we have contributed to the community a novel dataset derived from the RVL-CDIP invoice data."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 42,
                                "start": 39
                            }
                        ],
                        "text": "RVL-CDIP The original RVL-CDIP dataset [9] contains 400, 000 grayscale images, which are divided in 16 classes with 25, 000 images per class."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 33,
                                "start": 25
                            }
                        ],
                        "text": "Note that in the case of RVL-CDIP, there is a small amount of training data and the variability is much higher, hence, making this the more challenging dataset which is reflected in the results."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 64,
                                "start": 61
                            }
                        ],
                        "text": "(4) A dataset1 consisting of 518 invoice pages from RVL-CDIP [9] dataset augmented with ground truth for table detection and layout analysis has been created and publicly released."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2760893,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bd86b4b551b9d3fb498f62008b037e7599365018",
            "isKey": true,
            "numCitedBy": 174,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a new state-of-the-art for document image classification and retrieval, using features learned by deep convolutional neural networks (CNNs). In object and scene analysis, deep neural nets are capable of learning a hierarchical chain of abstraction from pixel inputs to concise and descriptive representations. The current work explores this capacity in the realm of document analysis, and confirms that this representation strategy is superior to a variety of popular handcrafted alternatives. Extensive experiments show that (i) features extracted from CNNs are robust to compression, (ii) CNNs trained on non-document images transfer well to document analysis tasks, and (iii) enforcing region-specific feature-learning is unnecessary given sufficient training data. This work also makes available a new labelled subset of the IIT-CDIP collection, containing 400,000 document images across 16 categories."
            },
            "slug": "Evaluation-of-deep-convolutional-nets-for-document-Harley-Ufkes",
            "title": {
                "fragments": [],
                "text": "Evaluation of deep convolutional nets for document image classification and retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 69,
                "text": "A new state-of-the-art for document image classification and retrieval, using features learned by deep convolutional neural networks (CNNs), and makes available a new labelled subset of the IIT-CDIP collection, containing 400,000 document images across 16 categories."
            },
            "venue": {
                "fragments": [],
                "text": "2015 13th International Conference on Document Analysis and Recognition (ICDAR)"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2601937"
                        ],
                        "name": "N. Ghanmi",
                        "slug": "N.-Ghanmi",
                        "structuredName": {
                            "firstName": "Nabil",
                            "lastName": "Ghanmi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Ghanmi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2128453"
                        ],
                        "name": "A. Bela\u00efd",
                        "slug": "A.-Bela\u00efd",
                        "structuredName": {
                            "firstName": "Abdel",
                            "lastName": "Bela\u00efd",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Bela\u00efd"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 29,
                                "start": 26
                            }
                        ],
                        "text": "Later, Ghanmi and Bela\u0131\u0308d [6] proposed Conditional Random Field (CRF) to localize tabular components in unconstrained handwritten documents."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 24,
                                "start": 19
                            }
                        ],
                        "text": "[19] D. Lohani, A. Bela\u0131\u0308d, and Y. Bela\u0131\u0308d, \u201cAn invoice reading system using a graph convolutional network,\u201d in IWRR, 2018."
                    },
                    "intents": []
                }
            ],
            "corpusId": 23618951,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "928faf04df18da371063f2b921d8e90f86a777a4",
            "isKey": false,
            "numCitedBy": 12,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we present a new approach using conditional random fields (CRFs) to localize tabular components in an unconstrained handwritten compound document. Given a line-segmented document, the extraction of table is considered as a labeling task that consists in assigning a label to each line: Table Row label for a line which belongs to a table and Line Text label for a line which belongs to a text block. To perform the labeling task, we use a CRF model to combine two classifiers: a local classifier which assigns a label to the line based on local features and a contextual classifier which uses features taking into account the neighborhood. The CRF model gives the global conditional probability of a given labeling of the line considering the outputs of the two classifiers. A set of chemistry documents is used for the evaluation of this approach. The obtained results are around 88% of table lines correctly detected."
            },
            "slug": "Table-Detection-in-Handwritten-Chemistry-Documents-Ghanmi-Bela\u00efd",
            "title": {
                "fragments": [],
                "text": "Table Detection in Handwritten Chemistry Documents Using Conditional Random Fields"
            },
            "tldr": {
                "abstractSimilarityScore": 71,
                "text": "A new approach using conditional random fields (CRFs) to localize tabular components in an unconstrained handwritten compound document and gives the global conditional probability of a given labeling of the line considering the outputs of the two classifiers."
            },
            "venue": {
                "fragments": [],
                "text": "2014 14th International Conference on Frontiers in Handwriting Recognition"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2207074"
                        ],
                        "name": "S. Clinchant",
                        "slug": "S.-Clinchant",
                        "structuredName": {
                            "firstName": "St\u00e9phane",
                            "lastName": "Clinchant",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Clinchant"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2131960"
                        ],
                        "name": "Herv\u00e9 D\u00e9jean",
                        "slug": "Herv\u00e9-D\u00e9jean",
                        "structuredName": {
                            "firstName": "Herv\u00e9",
                            "lastName": "D\u00e9jean",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Herv\u00e9 D\u00e9jean"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2066113788"
                        ],
                        "name": "J. Meunier",
                        "slug": "J.-Meunier",
                        "structuredName": {
                            "firstName": "Jean-Luc",
                            "lastName": "Meunier",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Meunier"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2059294500"
                        ],
                        "name": "E. Lang",
                        "slug": "E.-Lang",
                        "structuredName": {
                            "firstName": "Eva",
                            "lastName": "Lang",
                            "middleNames": [
                                "Maria"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Lang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1729636"
                        ],
                        "name": "Florian Kleber",
                        "slug": "Florian-Kleber",
                        "structuredName": {
                            "firstName": "Florian",
                            "lastName": "Kleber",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Florian Kleber"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 164,
                                "start": 161
                            }
                        ],
                        "text": "Table detection and recognition in unconstrained documents is considered a challenging task and recently has received significant attention within the community [2], [7], [11], [16], [19], [22], [24]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 49407309,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e652226d2f58435d97de6899bb347e0e39de310a",
            "isKey": false,
            "numCitedBy": 22,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "We present in this paper experiments on Table Recognition in hand-written register books. We first explain how the problem of row and column detection is modelled, and then compare two Machine Learning approaches (Conditional Random Field and Graph Convolutional Network) for detecting these table elements. Evaluation was conducted on death records provided by the Archives of the Diocese of Passau. With an F-1 score of 89, both methods provide a quality which allows for Information Extraction. Software and dataset are open source/data."
            },
            "slug": "Comparing-Machine-Learning-Approaches-for-Table-in-Clinchant-D\u00e9jean",
            "title": {
                "fragments": [],
                "text": "Comparing Machine Learning Approaches for Table Recognition in Historical Register Books"
            },
            "tldr": {
                "abstractSimilarityScore": 64,
                "text": "This paper first explains how the problem of row and column detection is modelled, and then compares two Machine Learning approaches (Conditional Random Field and Graph Convolutional Network) for detecting these table elements."
            },
            "venue": {
                "fragments": [],
                "text": "2018 13th IAPR International Workshop on Document Analysis Systems (DAS)"
            },
            "year": 2018
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40420775"
                        ],
                        "name": "Pau Riba",
                        "slug": "Pau-Riba",
                        "structuredName": {
                            "firstName": "Pau",
                            "lastName": "Riba",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Pau Riba"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153745355"
                        ],
                        "name": "Andreas Fischer",
                        "slug": "Andreas-Fischer",
                        "structuredName": {
                            "firstName": "Andreas",
                            "lastName": "Fischer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andreas Fischer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143826881"
                        ],
                        "name": "J. Llad\u00f3s",
                        "slug": "J.-Llad\u00f3s",
                        "structuredName": {
                            "firstName": "Josep",
                            "lastName": "Llad\u00f3s",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Llad\u00f3s"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1686569"
                        ],
                        "name": "A. Forn\u00e9s",
                        "slug": "A.-Forn\u00e9s",
                        "structuredName": {
                            "firstName": "Alicia",
                            "lastName": "Forn\u00e9s",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Forn\u00e9s"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 180,
                                "start": 176
                            }
                        ],
                        "text": "These basic architectures are further extended to new tasks involving graphs, such as variational graph autoencoder [14], learning graph edit distance between a pair of graphs [23], graph matching [29] etc."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 54439486,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fe4f2e1d5fa6b634b039066307b756295dda580f",
            "isKey": false,
            "numCitedBy": 19,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "Graph representations have been widely used in pattern recognition thanks to their powerful representation formalism and rich theoretical background. A number of error-tolerant graph matching algorithms such as graph edit distance have been proposed for computing a distance between two labelled graphs. However, they typically suffer from a high computational complexity, which makes it difficult to apply these matching algorithms in a real scenario. In this paper, we propose an efficient graph distance based on the emerging field of geometric deep learning. Our method employs a message passing neural network to capture the graph structure and learns a metric with a siamese network approach. The performance of the proposed graph distance is validated in two application cases, graph classification and graph retrieval of handwritten words, and shows a promising performance when compared with (approximate) graph edit distance benchmarks."
            },
            "slug": "Learning-Graph-Distances-with-Message-Passing-Riba-Fischer",
            "title": {
                "fragments": [],
                "text": "Learning Graph Distances with Message Passing Neural Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This paper proposes an efficient graph distance based on the emerging field of geometric deep learning that employs a message passing neural network to capture the graph structure and learns a metric with a siamese network approach."
            },
            "venue": {
                "fragments": [],
                "text": "2018 24th International Conference on Pattern Recognition (ICPR)"
            },
            "year": 2018
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "41016725"
                        ],
                        "name": "Thomas Kipf",
                        "slug": "Thomas-Kipf",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Kipf",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thomas Kipf"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1678311"
                        ],
                        "name": "M. Welling",
                        "slug": "M.-Welling",
                        "structuredName": {
                            "firstName": "Max",
                            "lastName": "Welling",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Welling"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 94,
                                "start": 91
                            }
                        ],
                        "text": "At the same time, Koci et al. [16] proposed another graph-based method, where instead of a GCN, they proposed the remove and conquer algorithm for detecting tables."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 172,
                                "start": 168
                            }
                        ],
                        "text": "On other hand, spectral methods take the advantage of spectral graph theory [26] and consider graph Laplacians for defining convolution operations in graph domain [3], [15]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 55,
                                "start": 52
                            }
                        ],
                        "text": "Very recently, Lohani et al. [19] proposed the same GCN-based technique for recognizing different fields in an invoice."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 34,
                                "start": 30
                            }
                        ],
                        "text": "Geometric deep learning2 [3], [15] refers to deep learning algorithms that apply neural networks to non-Euclidean domains, such as graphs and manifolds."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 253,
                                "start": 250
                            }
                        ],
                        "text": "In [2], Clinchant et al. proposed two graph-based methods and compared them for the table detection task, where the first method relies on graph Conditional Random Fields (gCRF) [17], while the second method is based on Graph Convolutional Networks (GCN) [15]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 234,
                                "start": 230
                            }
                        ],
                        "text": "proposed two graph-based methods and compared them for the table detection task, where the first method relies on graph Conditional Random Fields (gCRF) [17], while the second method is based on Graph Convolutional Networks (GCN) [15]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 3144218,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "36eff562f65125511b5dfab68ce7f7a943c27478",
            "isKey": true,
            "numCitedBy": 11719,
            "numCiting": 43,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a scalable approach for semi-supervised learning on graph-structured data that is based on an efficient variant of convolutional neural networks which operate directly on graphs. We motivate the choice of our convolutional architecture via a localized first-order approximation of spectral graph convolutions. Our model scales linearly in the number of graph edges and learns hidden layer representations that encode both local graph structure and features of nodes. In a number of experiments on citation networks and on a knowledge graph dataset we demonstrate that our approach outperforms related methods by a significant margin."
            },
            "slug": "Semi-Supervised-Classification-with-Graph-Networks-Kipf-Welling",
            "title": {
                "fragments": [],
                "text": "Semi-Supervised Classification with Graph Convolutional Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 83,
                "text": "A scalable approach for semi-supervised learning on graph-structured data that is based on an efficient variant of convolutional neural networks which operate directly on graphs which outperforms related methods by a significant margin."
            },
            "venue": {
                "fragments": [],
                "text": "ICLR"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "73240341"
                        ],
                        "name": "Victor Garcia Satorras",
                        "slug": "Victor-Garcia-Satorras",
                        "structuredName": {
                            "firstName": "Victor",
                            "lastName": "Satorras",
                            "middleNames": [
                                "Garcia"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Victor Garcia Satorras"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143627859"
                        ],
                        "name": "Joan Bruna",
                        "slug": "Joan-Bruna",
                        "structuredName": {
                            "firstName": "Joan",
                            "lastName": "Bruna",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Joan Bruna"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 36,
                                "start": 33
                            }
                        ],
                        "text": "Following the idea introduced in [5], we allowed our network to learn the weights of our operators at layer k."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 51,
                                "start": 48
                            }
                        ],
                        "text": "GNN Layer: Following the notation introduced in [5], let us consider an input signal x \u2208 R|V |\u00d7dk on the vertices of the given graph G and a set of graph intrinsic linear operators A(k) both at the k layer of our network."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 3431470,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "572a1f77306e160c3893299c18f3ed862fb5f6d9",
            "isKey": false,
            "numCitedBy": 702,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose to study the problem of few-shot learning with the prism of inference on a partially observed graphical model, constructed from a collection of input images whose label can be either observed or not. By assimilating generic message-passing inference algorithms with their neural-network counterparts, we define a graph neural network architecture that generalizes several of the recently proposed few-shot learning models. Besides providing improved numerical performance, our framework is easily extended to variants of few-shot learning, such as semi-supervised or active learning, demonstrating the ability of graph-based models to operate well on 'relational' tasks."
            },
            "slug": "Few-Shot-Learning-with-Graph-Neural-Networks-Satorras-Bruna",
            "title": {
                "fragments": [],
                "text": "Few-Shot Learning with Graph Neural Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A graph neural network architecture is defined that generalizes several of the recently proposed few-shot learning models and provides improved numerical performance, and is easily extended to variants of few- shot learning, such as semi-supervised or active learning, demonstrating the ability of graph-based models to operate well on 'relational' tasks."
            },
            "venue": {
                "fragments": [],
                "text": "ICLR"
            },
            "year": 2018
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3422350"
                        ],
                        "name": "M. Defferrard",
                        "slug": "M.-Defferrard",
                        "structuredName": {
                            "firstName": "Micha\u00ebl",
                            "lastName": "Defferrard",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Defferrard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2549032"
                        ],
                        "name": "X. Bresson",
                        "slug": "X.-Bresson",
                        "structuredName": {
                            "firstName": "Xavier",
                            "lastName": "Bresson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "X. Bresson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1697397"
                        ],
                        "name": "P. Vandergheynst",
                        "slug": "P.-Vandergheynst",
                        "structuredName": {
                            "firstName": "Pierre",
                            "lastName": "Vandergheynst",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Vandergheynst"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 28,
                                "start": 25
                            }
                        ],
                        "text": "Geometric deep learning2 [3], [15] refers to deep learning algorithms that apply neural networks to non-Euclidean domains, such as graphs and manifolds."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 166,
                                "start": 163
                            }
                        ],
                        "text": "On other hand, spectral methods take the advantage of spectral graph theory [26] and consider graph Laplacians for defining convolution operations in graph domain [3], [15]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 3016223,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c41eb895616e453dcba1a70c9b942c5063cc656c",
            "isKey": false,
            "numCitedBy": 4145,
            "numCiting": 46,
            "paperAbstract": {
                "fragments": [],
                "text": "In this work, we are interested in generalizing convolutional neural networks (CNNs) from low-dimensional regular grids, where image, video and speech are represented, to high-dimensional irregular domains, such as social networks, brain connectomes or words' embedding, represented by graphs. We present a formulation of CNNs in the context of spectral graph theory, which provides the necessary mathematical background and efficient numerical schemes to design fast localized convolutional filters on graphs. Importantly, the proposed technique offers the same linear computational complexity and constant learning complexity as classical CNNs, while being universal to any graph structure. Experiments on MNIST and 20NEWS demonstrate the ability of this novel deep learning system to learn local, stationary, and compositional features on graphs."
            },
            "slug": "Convolutional-Neural-Networks-on-Graphs-with-Fast-Defferrard-Bresson",
            "title": {
                "fragments": [],
                "text": "Convolutional Neural Networks on Graphs with Fast Localized Spectral Filtering"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This work presents a formulation of CNNs in the context of spectral graph theory, which provides the necessary mathematical background and efficient numerical schemes to design fast localized convolutional filters on graphs."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2263107"
                        ],
                        "name": "Andrei Zanfir",
                        "slug": "Andrei-Zanfir",
                        "structuredName": {
                            "firstName": "Andrei",
                            "lastName": "Zanfir",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrei Zanfir"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1781120"
                        ],
                        "name": "C. Sminchisescu",
                        "slug": "C.-Sminchisescu",
                        "structuredName": {
                            "firstName": "Cristian",
                            "lastName": "Sminchisescu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Sminchisescu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 201,
                                "start": 197
                            }
                        ],
                        "text": "These basic architectures are further extended to new tasks involving graphs, such as variational graph autoencoder [14], learning graph edit distance between a pair of graphs [23], graph matching [29] etc."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 52088075,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d6c1e14e8bea932f821352ea9e33928129f7d065",
            "isKey": false,
            "numCitedBy": 131,
            "numCiting": 41,
            "paperAbstract": {
                "fragments": [],
                "text": "The problem of graph matching under node and pairwise constraints is fundamental in areas as diverse as combinatorial optimization, machine learning or computer vision, where representing both the relations between nodes and their neighborhood structure is essential. We present an end-to-end model that makes it possible to learn all parameters of the graph matching process, including the unary and pairwise node neighborhoods, represented as deep feature extraction hierarchies. The challenge is in the formulation of the different matrix computation layers of the model in a way that enables the consistent, efficient propagation of gradients in the complete pipeline from the loss function, through the combinatorial optimization layer solving the matching problem, and the feature extraction hierarchy. Our computer vision experiments and ablation studies on challenging datasets like PASCAL VOC keypoints, Sintel and CUB show that matching models refined end-to-end are superior to counterparts based on feature hierarchies trained for other problems."
            },
            "slug": "Deep-Learning-of-Graph-Matching-Zanfir-Sminchisescu",
            "title": {
                "fragments": [],
                "text": "Deep Learning of Graph Matching"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This work presents an end-to-end model that makes it possible to learn all parameters of the graph matching process, including the unary and pairwise node neighborhoods, represented as deep feature extraction hierarchies."
            },
            "venue": {
                "fragments": [],
                "text": "2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2018
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2115625054"
                        ],
                        "name": "Yalin Wang",
                        "slug": "Yalin-Wang",
                        "structuredName": {
                            "firstName": "Yalin",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yalin Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1710238"
                        ],
                        "name": "R. Haralick",
                        "slug": "R.-Haralick",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Haralick",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Haralick"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1744200"
                        ],
                        "name": "I. T. Phillips",
                        "slug": "I.-T.-Phillips",
                        "structuredName": {
                            "firstName": "Ihsin",
                            "lastName": "Phillips",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. T. Phillips"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 67,
                                "start": 63
                            }
                        ],
                        "text": "on this topic were mostly bottom-up in nature [1], [12], [13], [27], and they often start by detecting words or parallel lines"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 628973,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cd7e243fb7041c582a479116a11126904f2be010",
            "isKey": false,
            "numCitedBy": 61,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "We first describe an automatic table ground truth generation system which can efficiently generate a large amount of accurate table ground truth suitable for the development of table detection algorithms. Then a novel background analysis-based, coarse-to-fine table identification algorithm and an X-Y cut table decomposition algorithm are described. We discuss an experimental protocol to evaluate the table detection algorithms. For a total of 1,125 document pages having 518 table entities and a total of 10,941 cell entities, our table detection algorithm takes line, word segmentation results as input and obtains around 90% cell correct detection rates."
            },
            "slug": "Automatic-table-ground-truth-generation-and-a-table-Wang-Haralick",
            "title": {
                "fragments": [],
                "text": "Automatic table ground truth generation and a background-analysis-based table structure extraction method"
            },
            "tldr": {
                "abstractSimilarityScore": 83,
                "text": "An automatic table groundtruth generation system which can efficiently generate a large amount of accurate table ground truth suitable for the development of table detection algorithms and an X-Y cut table decomposition algorithm are described."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of Sixth International Conference on Document Analysis and Recognition"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39353098"
                        ],
                        "name": "Kaiming He",
                        "slug": "Kaiming-He",
                        "structuredName": {
                            "firstName": "Kaiming",
                            "lastName": "He",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kaiming He"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1771551"
                        ],
                        "name": "X. Zhang",
                        "slug": "X.-Zhang",
                        "structuredName": {
                            "firstName": "X.",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "X. Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3080683"
                        ],
                        "name": "Shaoqing Ren",
                        "slug": "Shaoqing-Ren",
                        "structuredName": {
                            "firstName": "Shaoqing",
                            "lastName": "Ren",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shaoqing Ren"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [],
                        "name": "Jian Sun",
                        "slug": "Jian-Sun",
                        "structuredName": {
                            "firstName": "Jian",
                            "lastName": "Sun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jian Sun"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[10] but replacing the CNN layers by GNN layers."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 206594692,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2c03df8b48bf3fa39054345bafabfeff15bfd11d",
            "isKey": false,
            "numCitedBy": 95318,
            "numCiting": 61,
            "paperAbstract": {
                "fragments": [],
                "text": "Deeper neural networks are more difficult to train. We present a residual learning framework to ease the training of networks that are substantially deeper than those used previously. We explicitly reformulate the layers as learning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We provide comprehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets with a depth of up to 152 layers - 8\u00d7 deeper than VGG nets [40] but still having lower complexity. An ensemble of these residual nets achieves 3.57% error on the ImageNet test set. This result won the 1st place on the ILSVRC 2015 classification task. We also present analysis on CIFAR-10 with 100 and 1000 layers. The depth of representations is of central importance for many visual recognition tasks. Solely due to our extremely deep representations, we obtain a 28% relative improvement on the COCO object detection dataset. Deep residual nets are foundations of our submissions to ILSVRC & COCO 2015 competitions1, where we also won the 1st places on the tasks of ImageNet detection, ImageNet localization, COCO detection, and COCO segmentation."
            },
            "slug": "Deep-Residual-Learning-for-Image-Recognition-He-Zhang",
            "title": {
                "fragments": [],
                "text": "Deep Residual Learning for Image Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 63,
                "text": "This work presents a residual learning framework to ease the training of networks that are substantially deeper than those used previously, and provides comprehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth."
            },
            "venue": {
                "fragments": [],
                "text": "2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50058359"
                        ],
                        "name": "D. Shuman",
                        "slug": "D.-Shuman",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Shuman",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Shuman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1799060"
                        ],
                        "name": "S. K. Narang",
                        "slug": "S.-K.-Narang",
                        "structuredName": {
                            "firstName": "Sunil",
                            "lastName": "Narang",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. K. Narang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1703189"
                        ],
                        "name": "P. Frossard",
                        "slug": "P.-Frossard",
                        "structuredName": {
                            "firstName": "Pascal",
                            "lastName": "Frossard",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Frossard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145029825"
                        ],
                        "name": "Antonio Ortega",
                        "slug": "Antonio-Ortega",
                        "structuredName": {
                            "firstName": "Antonio",
                            "lastName": "Ortega",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Antonio Ortega"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1697397"
                        ],
                        "name": "P. Vandergheynst",
                        "slug": "P.-Vandergheynst",
                        "structuredName": {
                            "firstName": "Pierre",
                            "lastName": "Vandergheynst",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Vandergheynst"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 80,
                                "start": 76
                            }
                        ],
                        "text": "On other hand, spectral methods take the advantage of spectral graph theory [26] and consider graph Laplacians for defining convolution operations in graph domain [3], [15]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 1594725,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "39e223e6b5a6f8727e9f60b8b7c7720dc40a5dbc",
            "isKey": false,
            "numCitedBy": 2723,
            "numCiting": 73,
            "paperAbstract": {
                "fragments": [],
                "text": "In applications such as social, energy, transportation, sensor, and neuronal networks, high-dimensional data naturally reside on the vertices of weighted graphs. The emerging field of signal processing on graphs merges algebraic and spectral graph theoretic concepts with computational harmonic analysis to process such signals on graphs. In this tutorial overview, we outline the main challenges of the area, discuss different ways to define graph spectral domains, which are the analogs to the classical frequency domain, and highlight the importance of incorporating the irregular structures of graph data domains when processing signals on graphs. We then review methods to generalize fundamental operations such as filtering, translation, modulation, dilation, and downsampling to the graph setting and survey the localized, multiscale transforms that have been proposed to efficiently extract information from high-dimensional data on graphs. We conclude with a brief discussion of open issues and possible extensions."
            },
            "slug": "The-emerging-field-of-signal-processing-on-graphs:-Shuman-Narang",
            "title": {
                "fragments": [],
                "text": "The emerging field of signal processing on graphs: Extending high-dimensional data analysis to networks and other irregular domains"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "This tutorial overview outlines the main challenges of the emerging field of signal processing on graphs, discusses different ways to define graph spectral domains, which are the analogs to the classical frequency domain, and highlights the importance of incorporating the irregular structures of graph data domains when processing signals on graphs."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Signal Processing Magazine"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "41016725"
                        ],
                        "name": "Thomas Kipf",
                        "slug": "Thomas-Kipf",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Kipf",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thomas Kipf"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1678311"
                        ],
                        "name": "M. Welling",
                        "slug": "M.-Welling",
                        "structuredName": {
                            "firstName": "Max",
                            "lastName": "Welling",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Welling"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 120,
                                "start": 116
                            }
                        ],
                        "text": "These basic architectures are further extended to new tasks involving graphs, such as variational graph autoencoder [14], learning graph edit distance between a pair of graphs [23], graph matching [29] etc."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14249137,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "54906484f42e871f7c47bbfe784a358b1448231f",
            "isKey": false,
            "numCitedBy": 1355,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce the variational graph auto-encoder (VGAE), a framework for unsupervised learning on graph-structured data based on the variational auto-encoder (VAE). This model makes use of latent variables and is capable of learning interpretable latent representations for undirected graphs. We demonstrate this model using a graph convolutional network (GCN) encoder and a simple inner product decoder. Our model achieves competitive results on a link prediction task in citation networks. In contrast to most existing models for unsupervised learning on graph-structured data and link prediction, our model can naturally incorporate node features, which significantly improves predictive performance on a number of benchmark datasets."
            },
            "slug": "Variational-Graph-Auto-Encoders-Kipf-Welling",
            "title": {
                "fragments": [],
                "text": "Variational Graph Auto-Encoders"
            },
            "tldr": {
                "abstractSimilarityScore": 67,
                "text": "The variational graph auto-encoder (VGAE) is introduced, a framework for unsupervised learning on graph-structured data based on the variational auto- Encoder (VAE) that can naturally incorporate node features, which significantly improves predictive performance on a number of benchmark datasets."
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8314845"
                        ],
                        "name": "Xingwei Yang",
                        "slug": "Xingwei-Yang",
                        "structuredName": {
                            "firstName": "Xingwei",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xingwei Yang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2290812"
                        ],
                        "name": "Lakshman Prasad",
                        "slug": "Lakshman-Prasad",
                        "structuredName": {
                            "firstName": "Lakshman",
                            "lastName": "Prasad",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lakshman Prasad"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1686678"
                        ],
                        "name": "L. Latecki",
                        "slug": "L.-Latecki",
                        "structuredName": {
                            "firstName": "Longin",
                            "lastName": "Latecki",
                            "middleNames": [
                                "Jan"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Latecki"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 188,
                                "start": 184
                            }
                        ],
                        "text": "GNNs offer a solid foundation to achieve this objective by extending the formalism of Convolutional Neural Networks (CNNs) to graph domains, utilizing the principle of graph diffusion [28]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 10153184,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "de97e64f57342cfe2fcdd942a567c12d079b7f4d",
            "isKey": false,
            "numCitedBy": 138,
            "numCiting": 55,
            "paperAbstract": {
                "fragments": [],
                "text": "In many applications, we are given a finite set of data points sampled from a data manifold and represented as a graph with edge weights determined by pairwise similarities of the samples. Often the pairwise similarities (which are also called affinities) are unreliable due to noise or due to intrinsic difficulties in estimating similarity values of the samples. As observed in several recent approaches, more reliable similarities can be obtained if the original similarities are diffused in the context of other data points, where the context of each point is a set of points most similar to it. Compared to the existing methods, our approach differs in two main aspects. First, instead of diffusing the similarity information on the original graph, we propose to utilize the tensor product graph (TPG) obtained by the tensor product of the original graph with itself. Since TPG takes into account higher order information, it is not a surprise that we obtain more reliable similarities. However, it comes at the price of higher order computational complexity and storage requirement. The key contribution of the proposed approach is that the information propagation on TPG can be computed with the same computational complexity and the same amount of storage as the propagation on the original graph. We prove that a graph diffusion process on TPG is equivalent to a novel iterative algorithm on the original graph, which is guaranteed to converge. After its convergence we obtain new edge weights that can be interpreted as new, learned affinities. We stress that the affinities are learned in an unsupervised setting. We illustrate the benefits of the proposed approach for data manifolds composed of shapes, images, and image patches on two very different tasks of image retrieval and image segmentation. With learned affinities, we achieve the bull's eye retrieval score of 99.99 percent on the MPEG-7 shape dataset, which is much higher than the state-of-the-art algorithms. When the data points are image patches, the NCut with the learned affinities not only significantly outperforms the NCut with the original affinities, but it also outperforms state-of-the-art image segmentation methods."
            },
            "slug": "Affinity-Learning-with-Diffusion-on-Tensor-Product-Yang-Prasad",
            "title": {
                "fragments": [],
                "text": "Affinity Learning with Diffusion on Tensor Product Graph"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "It is proved that a graph diffusion process on TPG is equivalent to a novel iterative algorithm on the original graph, which is guaranteed to converge, and new edge weights that can be interpreted as new, learned affinities are obtained."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1739581"
                        ],
                        "name": "J. Lafferty",
                        "slug": "J.-Lafferty",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Lafferty",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Lafferty"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143753639"
                        ],
                        "name": "A. McCallum",
                        "slug": "A.-McCallum",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "McCallum",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. McCallum"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "113414328"
                        ],
                        "name": "Fernando Pereira",
                        "slug": "Fernando-Pereira",
                        "structuredName": {
                            "firstName": "Fernando",
                            "lastName": "Pereira",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Fernando Pereira"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 157,
                                "start": 153
                            }
                        ],
                        "text": "proposed two graph-based methods and compared them for the table detection task, where the first method relies on graph Conditional Random Fields (gCRF) [17], while the second method is based on Graph Convolutional Networks (GCN) [15]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 219683473,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f4ba954b0412773d047dc41231c733de0c1f4926",
            "isKey": false,
            "numCitedBy": 13409,
            "numCiting": 75,
            "paperAbstract": {
                "fragments": [],
                "text": "We present conditional random fields , a framework for building probabilistic models to segment and label sequence data. Conditional random fields offer several advantages over hidden Markov models and stochastic grammars for such tasks, including the ability to relax strong independence assumptions made in those models. Conditional random fields also avoid a fundamental limitation of maximum entropy Markov models (MEMMs) and other discriminative Markov models based on directed graphical models, which can be biased towards states with few successor states. We present iterative parameter estimation algorithms for conditional random fields and compare the performance of the resulting models to HMMs and MEMMs on synthetic and natural-language data."
            },
            "slug": "Conditional-Random-Fields:-Probabilistic-Models-for-Lafferty-McCallum",
            "title": {
                "fragments": [],
                "text": "Conditional Random Fields: Probabilistic Models for Segmenting and Labeling Sequence Data"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This work presents iterative parameter estimation algorithms for conditional random fields and compares the performance of the resulting models to HMMs and MEMMs on synthetic and natural-language data."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2058362"
                        ],
                        "name": "J. Gilmer",
                        "slug": "J.-Gilmer",
                        "structuredName": {
                            "firstName": "Justin",
                            "lastName": "Gilmer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Gilmer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2601641"
                        ],
                        "name": "S. Schoenholz",
                        "slug": "S.-Schoenholz",
                        "structuredName": {
                            "firstName": "Samuel",
                            "lastName": "Schoenholz",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Schoenholz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "119508204"
                        ],
                        "name": "Patrick F. Riley",
                        "slug": "Patrick-F.-Riley",
                        "structuredName": {
                            "firstName": "Patrick",
                            "lastName": "Riley",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Patrick F. Riley"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1689108"
                        ],
                        "name": "Oriol Vinyals",
                        "slug": "Oriol-Vinyals",
                        "structuredName": {
                            "firstName": "Oriol",
                            "lastName": "Vinyals",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Oriol Vinyals"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35188630"
                        ],
                        "name": "George E. Dahl",
                        "slug": "George-E.-Dahl",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Dahl",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "George E. Dahl"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 3,
                                "start": 0
                            }
                        ],
                        "text": "[8] generalized the above two domains of GNN, and defined most of the existing methods in terms of a message passing pipeline."
                    },
                    "intents": []
                }
            ],
            "corpusId": 9665943,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e24cdf73b3e7e590c2fe5ecac9ae8aa983801367",
            "isKey": false,
            "numCitedBy": 3235,
            "numCiting": 43,
            "paperAbstract": {
                "fragments": [],
                "text": "Supervised learning on molecules has incredible potential to be useful in chemistry, drug discovery, and materials science. Luckily, several promising and closely related neural network models invariant to molecular symmetries have already been described in the literature. These models learn a message passing algorithm and aggregation procedure to compute a function of their entire input graph. At this point, the next step is to find a particularly effective variant of this general approach and apply it to chemical prediction benchmarks until we either solve them or reach the limits of the approach. In this paper, we reformulate existing models into a single common framework we call Message Passing Neural Networks (MPNNs) and explore additional novel variations within this framework. Using MPNNs we demonstrate state of the art results on an important molecular property prediction benchmark; these results are strong enough that we believe future work should focus on datasets with larger molecules or more accurate ground truth labels."
            },
            "slug": "Neural-Message-Passing-for-Quantum-Chemistry-Gilmer-Schoenholz",
            "title": {
                "fragments": [],
                "text": "Neural Message Passing for Quantum Chemistry"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "Using MPNNs, state of the art results on an important molecular property prediction benchmark are demonstrated and it is believed future work should focus on datasets with larger molecules or more accurate ground truth labels."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1704657"
                        ],
                        "name": "D. Duvenaud",
                        "slug": "D.-Duvenaud",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Duvenaud",
                            "middleNames": [
                                "Kristjanson"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Duvenaud"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1683298"
                        ],
                        "name": "D. Maclaurin",
                        "slug": "D.-Maclaurin",
                        "structuredName": {
                            "firstName": "Dougal",
                            "lastName": "Maclaurin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Maclaurin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1422175619"
                        ],
                        "name": "J. Aguilera-Iparraguirre",
                        "slug": "J.-Aguilera-Iparraguirre",
                        "structuredName": {
                            "firstName": "Jorge",
                            "lastName": "Aguilera-Iparraguirre",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Aguilera-Iparraguirre"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1398336096"
                        ],
                        "name": "Rafael G\u00f3mez-Bombarelli",
                        "slug": "Rafael-G\u00f3mez-Bombarelli",
                        "structuredName": {
                            "firstName": "Rafael",
                            "lastName": "G\u00f3mez-Bombarelli",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Rafael G\u00f3mez-Bombarelli"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145916942"
                        ],
                        "name": "Timothy D. Hirzel",
                        "slug": "Timothy-D.-Hirzel",
                        "structuredName": {
                            "firstName": "Timothy",
                            "lastName": "Hirzel",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Timothy D. Hirzel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1380248954"
                        ],
                        "name": "Al\u00e1n Aspuru-Guzik",
                        "slug": "Al\u00e1n-Aspuru-Guzik",
                        "structuredName": {
                            "firstName": "Al\u00e1n",
                            "lastName": "Aspuru-Guzik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Al\u00e1n Aspuru-Guzik"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1722180"
                        ],
                        "name": "Ryan P. Adams",
                        "slug": "Ryan-P.-Adams",
                        "structuredName": {
                            "firstName": "Ryan",
                            "lastName": "Adams",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ryan P. Adams"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1690180,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5d1bfeed240709725c78bc72ea40e55410b373dc",
            "isKey": false,
            "numCitedBy": 2232,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce a convolutional neural network that operates directly on graphs. These networks allow end-to-end learning of prediction pipelines whose inputs are graphs of arbitrary size and shape. The architecture we present generalizes standard molecular feature extraction methods based on circular fingerprints. We show that these data-driven features are more interpretable, and have better predictive performance on a variety of tasks."
            },
            "slug": "Convolutional-Networks-on-Graphs-for-Learning-Duvenaud-Maclaurin",
            "title": {
                "fragments": [],
                "text": "Convolutional Networks on Graphs for Learning Molecular Fingerprints"
            },
            "tldr": {
                "abstractSimilarityScore": 87,
                "text": "A convolutional neural network that operates directly on graphs that allows end-to-end learning of prediction pipelines whose inputs are graphs of arbitrary size and shape is introduced."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35238678"
                        ],
                        "name": "D. Lowe",
                        "slug": "D.-Lowe",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Lowe",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Lowe"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 48,
                                "start": 44
                            }
                        ],
                        "text": "The Gestalt principles of visual perception [20] can be applied: table items have a regular arrangement, with a continuity in horizontal and vertical directions."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 60449135,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "27ce5a120a86632dd56f869ee65656b7d7312a3a",
            "isKey": false,
            "numCitedBy": 846,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "A computational model is presented for the visual recognition of three-dimensional objects based upon their spatial correspondence with two-dimensional features in an image. A number of components of this model are developed in further detail and implemented as computer algorithms. At the highest level, a verification process has been developed which can determine exact values of viewpoint and object parameters from hypothesized matches between three-dimensional object features and two-dimensional image features. This provides a reliable quantitative procedure for evaluating the correctness of an interpretation, even in the presence of noise or occlusion. Given a reliable method for final evaluation of correspondence, the remaining components of the system are aimed at reducing the size of the search space which must be covered. Unlike many previous approaches, this recognition process does not assume that it is possible to directly derive depth information from the image. Instead, the primary descriptive component is a process of perceptual organization, in which spatial relations are detected directly among two-dimensional image features. A basic requirement of the recognition process is that perceptual organization should accurately distinguish meaningful groupings from those which arise by accident of viewpoint or position. This requirement is used to derive a number of further constraints which must be satisfied by algorithms for perceptual grouping. A specific algorithm is presented for the problem of segmenting curves into natural descriptions. Methods are also presented for using the viewpoint-invariance properties of the perceptual groupings to infer three-dimensional relations directly from the image. The search process itself is described, both for covering the range of possible viewpoints and the range of possible objects. A method is presented for using evidential reasoning to combine information from multiple sources to determine the most efficient ordering for the search. This use of evidential reasoning allows a system to automatically improve its performance as it gains visual experience. In summary, spatial organization and recognition are shown to be a practical basis for current systems and to provide a promising path for further development of improved visual capabilities."
            },
            "slug": "Perceptual-Organization-and-Visual-Recognition-Lowe",
            "title": {
                "fragments": [],
                "text": "Perceptual Organization and Visual Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "Spatial organization and recognition are shown to be a practical basis for current systems and to provide a promising path for further development of improved visual capabilities."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34961461"
                        ],
                        "name": "Andrew L. Maas",
                        "slug": "Andrew-L.-Maas",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Maas",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew L. Maas"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 93,
                                "start": 89
                            }
                        ],
                        "text": "where \u03b8 B \u2208 Rdk\u00d7dk+1 are trainable parameters and \u03c1(\u00b7) is a Rectified Linear Unit (ReLU) [21]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 16489696,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "367f2c63a6f6a10b3b64b8729d601e69337ee3cc",
            "isKey": false,
            "numCitedBy": 4400,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "Deep neural network acoustic models produce substantial gains in large vocabulary continuous speech recognition systems. Emerging work with rectified linear (ReL) hidden units demonstrates additional gains in final system performance relative to more commonly used sigmoidal nonlinearities. In this work, we explore the use of deep rectifier networks as acoustic models for the 300 hour Switchboard conversational speech recognition task. Using simple training procedures without pretraining, networks with rectifier nonlinearities produce 2% absolute reductions in word error rates over their sigmoidal counterparts. We analyze hidden layer representations to quantify differences in how ReL units encode inputs as compared to sigmoidal units. Finally, we evaluate a variant of the ReL unit with a gradient more amenable to optimization in an attempt to further improve deep rectifier networks."
            },
            "slug": "Rectifier-Nonlinearities-Improve-Neural-Network-Maas",
            "title": {
                "fragments": [],
                "text": "Rectifier Nonlinearities Improve Neural Network Acoustic Models"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "This work explores the use of deep rectifier networks as acoustic models for the 300 hour Switchboard conversational speech recognition task, and analyzes hidden layer representations to quantify differences in how ReL units encode inputs as compared to sigmoidal units."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2013
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "ble recognition in heterogeneous documents using machine learning"
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Perceptual Organization and Visual Recognition. Norwell"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1985
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 20,
            "methodology": 9
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 31,
        "totalPages": 4
    },
    "page_url": "https://www.semanticscholar.org/paper/Table-Detection-in-Invoice-Documents-by-Graph-Riba-Dutta/0e45d822c782fd9e52b4e5abf60b3b7d6d5e3df0?sort=total-citations"
}