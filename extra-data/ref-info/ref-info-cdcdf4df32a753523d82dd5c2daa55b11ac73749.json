{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145461897"
                        ],
                        "name": "S. S. Bukhari",
                        "slug": "S.-S.-Bukhari",
                        "structuredName": {
                            "firstName": "Syed",
                            "lastName": "Bukhari",
                            "middleNames": [
                                "Saqib"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. S. Bukhari"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3290619"
                        ],
                        "name": "M. A. Azawi",
                        "slug": "M.-A.-Azawi",
                        "structuredName": {
                            "firstName": "Mayce",
                            "lastName": "Azawi",
                            "middleNames": [
                                "Ibrahim",
                                "Ali",
                                "Al"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. A. Azawi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688013"
                        ],
                        "name": "F. Shafait",
                        "slug": "F.-Shafait",
                        "structuredName": {
                            "firstName": "Faisal",
                            "lastName": "Shafait",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Shafait"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733858"
                        ],
                        "name": "T. Breuel",
                        "slug": "T.-Breuel",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Breuel",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Breuel"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 325,
                                "start": 315
                            }
                        ],
                        "text": "In literature, many methods have been proposed for document image layout analysis, and according to [11] they can be classified into three different groups: (i) region or block based classification methods [21, 17], (ii) pixel based classification methods [14, 13], (iii) connected component classification methods [6, 20, 1]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 10505962,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "86dc413ef69fb7e77608cca0683b558ab7fda7af",
            "isKey": false,
            "numCitedBy": 74,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "Segmentation of a document image into text and non-text regions is an important preprocessing step for a variety of document image analysis tasks, like improving OCR, document compression etc. Most of the state-of-the-art document image segmentation approaches perform segmentation using pixel-based or zone(block)-based classification. Pixel-based classification approaches are time consuming, whereas block-based methods heavily depend on the accuracy of block segmentation step. In contrast to the state-of-the-art document image segmentation approaches, our segmentation approach introduces connected component based classification, thereby not requiring a block segmentation beforehand. Here we train a self-tunable multi-layer perceptron (MLP) classifier for distinguishing between text and non-text connected components using shape and context information as a feature vector. Experimental results prove the effectiveness of our proposed algorithm. We have evaluated our method on subset of UW-III, ICDAR 2009 page segmentation competition test images and circuit diagrams datasets and compared its results with the state-of-the-art leptonica's page segmentation algorithm."
            },
            "slug": "Document-image-segmentation-using-discriminative-Bukhari-Azawi",
            "title": {
                "fragments": [],
                "text": "Document image segmentation using discriminative learning over connected components"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This work trains a self-tunable multi-layer perceptron (MLP) classifier for distinguishing between text and non-text connected components using shape and context information as a feature vector to introduce connected component based classification."
            },
            "venue": {
                "fragments": [],
                "text": "DAS '10"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "12195028"
                        ],
                        "name": "V. Le",
                        "slug": "V.-Le",
                        "structuredName": {
                            "firstName": "Viet",
                            "lastName": "Le",
                            "middleNames": [
                                "Phuong"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Le"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2170742"
                        ],
                        "name": "Nibal Nayef",
                        "slug": "Nibal-Nayef",
                        "structuredName": {
                            "firstName": "Nibal",
                            "lastName": "Nayef",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nibal Nayef"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1698969"
                        ],
                        "name": "M. Visani",
                        "slug": "M.-Visani",
                        "structuredName": {
                            "firstName": "Muriel",
                            "lastName": "Visani",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Visani"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695766"
                        ],
                        "name": "J. Ogier",
                        "slug": "J.-Ogier",
                        "structuredName": {
                            "firstName": "Jean-Marc",
                            "lastName": "Ogier",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Ogier"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2045917"
                        ],
                        "name": "D. Tran",
                        "slug": "D.-Tran",
                        "structuredName": {
                            "firstName": "De",
                            "lastName": "Tran",
                            "middleNames": [
                                "Cao"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Tran"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 104,
                                "start": 100
                            }
                        ],
                        "text": "In literature, many methods have been proposed for document image layout analysis, and according to [11] they can be classified into three different groups: (i) region or block based classification methods [21, 17], (ii) pixel based classification methods [14, 13], (iii) connected component classification methods [6, 20, 1]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 19307603,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "99032c30c6609889391da4b023096594a0c11ca9",
            "isKey": false,
            "numCitedBy": 32,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "Document image segmentation is crucial to OCR and other digitization processes. In this paper, we present a learning-based approach for text and non-text separation in document images. The training features are extracted at the level of connected components, a mid-level between the slow noise-sensitive pixel level, and the segmentation-dependent zone level. Given all types, shapes and sizes of connected components, we extract a powerful set of features based on size, shape, stroke width and position of each connected component. Adaboosting with Decision trees is used for labeling connected components. Finally, the classification of connected components into text and non-text is corrected based on classification probabilities and size as well as stroke width analysis of the nearest neighbors of a connected component. The performance of our approach has been evaluated on the two standard datasets: UW-III and ICDAR-2009 competition for document layout analysis. Our results demonstrate that the proposed approach achieves competitive performance for segmenting text and non-text in document images of variable content and degradation."
            },
            "slug": "Text-and-non-text-segmentation-based-on-connected-Le-Nayef",
            "title": {
                "fragments": [],
                "text": "Text and non-text segmentation based on connected component features"
            },
            "tldr": {
                "abstractSimilarityScore": 57,
                "text": "This paper presents a learning-based approach for text and non-text separation in document images by extracting a powerful set of features based on size, shape, stroke width and position of each connected component."
            },
            "venue": {
                "fragments": [],
                "text": "2015 13th International Conference on Document Analysis and Recognition (ICDAR)"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34939798"
                        ],
                        "name": "Adam W. Harley",
                        "slug": "Adam-W.-Harley",
                        "structuredName": {
                            "firstName": "Adam",
                            "lastName": "Harley",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Adam W. Harley"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2079687415"
                        ],
                        "name": "Alex Ufkes",
                        "slug": "Alex-Ufkes",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Ufkes",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alex Ufkes"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3150825"
                        ],
                        "name": "K. Derpanis",
                        "slug": "K.-Derpanis",
                        "structuredName": {
                            "firstName": "Konstantinos",
                            "lastName": "Derpanis",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Derpanis"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 187,
                                "start": 181
                            }
                        ],
                        "text": "When it comes to image classification, convolutional neural networks (CNNs) have been widely adopted in many different fields for a variety of purposes, including document analysis [9, 8]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2760893,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bd86b4b551b9d3fb498f62008b037e7599365018",
            "isKey": false,
            "numCitedBy": 174,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a new state-of-the-art for document image classification and retrieval, using features learned by deep convolutional neural networks (CNNs). In object and scene analysis, deep neural nets are capable of learning a hierarchical chain of abstraction from pixel inputs to concise and descriptive representations. The current work explores this capacity in the realm of document analysis, and confirms that this representation strategy is superior to a variety of popular handcrafted alternatives. Extensive experiments show that (i) features extracted from CNNs are robust to compression, (ii) CNNs trained on non-document images transfer well to document analysis tasks, and (iii) enforcing region-specific feature-learning is unnecessary given sufficient training data. This work also makes available a new labelled subset of the IIT-CDIP collection, containing 400,000 document images across 16 categories."
            },
            "slug": "Evaluation-of-deep-convolutional-nets-for-document-Harley-Ufkes",
            "title": {
                "fragments": [],
                "text": "Evaluation of deep convolutional nets for document image classification and retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 69,
                "text": "A new state-of-the-art for document image classification and retrieval, using features learned by deep convolutional neural networks (CNNs), and makes available a new labelled subset of the IIT-CDIP collection, containing 400,000 document images across 16 categories."
            },
            "venue": {
                "fragments": [],
                "text": "2015 13th International Conference on Document Analysis and Recognition (ICDAR)"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2569483"
                        ],
                        "name": "M. S. Erk\u0131l\u0131n\u00e7",
                        "slug": "M.-S.-Erk\u0131l\u0131n\u00e7",
                        "structuredName": {
                            "firstName": "M.",
                            "lastName": "Erk\u0131l\u0131n\u00e7",
                            "middleNames": [
                                "Sezer"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. S. Erk\u0131l\u0131n\u00e7"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40165419"
                        ],
                        "name": "M. Jaber",
                        "slug": "M.-Jaber",
                        "structuredName": {
                            "firstName": "Mustafa",
                            "lastName": "Jaber",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Jaber"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733172"
                        ],
                        "name": "E. Saber",
                        "slug": "E.-Saber",
                        "structuredName": {
                            "firstName": "Eli",
                            "lastName": "Saber",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Saber"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47712094"
                        ],
                        "name": "P\u00e9ter Bauer",
                        "slug": "P\u00e9ter-Bauer",
                        "structuredName": {
                            "firstName": "P\u00e9ter",
                            "lastName": "Bauer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P\u00e9ter Bauer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2785103"
                        ],
                        "name": "Dejan Depalov",
                        "slug": "Dejan-Depalov",
                        "structuredName": {
                            "firstName": "Dejan",
                            "lastName": "Depalov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dejan Depalov"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "[3, 4] proposed methods to reduce the computation burden of document analysis using projections for identifying image blocks but do not benefit from the robustness of CNNs using a one-dimensional convolutional architecture."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 11464716,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cbbf6c76be2ddba0aa89de3e53ab89db052719d7",
            "isKey": false,
            "numCitedBy": 10,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract. We propose a page layout analysis algorithm to classify a scanned document into different regions such as text, photo, or strong lines. The proposed scheme consists of five modules. The first module performs several image preprocessing techniques such as image scaling, filtering, color space conversion, and gamma correction to enhance the scanned image quality and reduce the computation time in later stages. Text detection is applied in the second module wherein wavelet transform and run-length encoding are employed to generate and validate text regions, respectively. The third module uses a Markov random field based block-wise segmentation that employs a basis vector projection technique with maximum a posteriori probability optimization to detect photo regions. In the fourth module, methods for edge detection, edge linking, line-segment fitting, and Hough transform are utilized to detect strong edges and lines. In the last module, the resultant text, photo, and edge maps are combined to generate a page layout map using K-Means clustering. The proposed algorithm has been tested on several hundred documents that contain simple and complex page layout structures and contents such as articles, magazines, business cards, dictionaries, and newsletters, and compared against state-of-the-art page-segmentation techniques with benchmark performance. The results indicate that our methodology achieves an average of \u223c89% classification accuracy in text, photo, and background regions."
            },
            "slug": "Text,-photo,-and-line-extraction-in-scanned-Erk\u0131l\u0131n\u00e7-Jaber",
            "title": {
                "fragments": [],
                "text": "Text, photo, and line extraction in scanned documents"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The proposed algorithm has been tested on several hundred documents that contain simple and complex page layout structures and contents and compared against state-of-the-art page-segmentation techniques with benchmark performance and results indicate that the methodology achieves an average of \u223c89% classification accuracy in text, photo, and background regions."
            },
            "venue": {
                "fragments": [],
                "text": "J. Electronic Imaging"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31742772"
                        ],
                        "name": "Michael A. Moll",
                        "slug": "Michael-A.-Moll",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Moll",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael A. Moll"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1723766"
                        ],
                        "name": "H. Baird",
                        "slug": "H.-Baird",
                        "structuredName": {
                            "firstName": "Henry",
                            "lastName": "Baird",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Baird"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 264,
                                "start": 256
                            }
                        ],
                        "text": "In literature, many methods have been proposed for document image layout analysis, and according to [11] they can be classified into three different groups: (i) region or block based classification methods [21, 17], (ii) pixel based classification methods [14, 13], (iii) connected component classification methods [6, 20, 1]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 7481079,
            "fieldsOfStudy": [
                "Environmental Science"
            ],
            "id": "c08e086d3bbdafe958117f0243b3805002ebf97f",
            "isKey": false,
            "numCitedBy": 17,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a methodology for retrieving document images from large extremely diverse collections. First we perform content extraction, that is the location and measurement of regions containing handwriting, machine-printed text, photographs, blank space, etc, in documents represented as bilevel, greylevel, or color images. Recent experiments have shown that even modest per-pixel content classification accuracies can support usefully high recall and precision rates (of, e.g., 80-90%) for retrieval queries within document collections seeking pages that contain a fraction of a certain type of content. When the distribution of content and error rates are uniform across the entire collection, it is possible to derive IR measures from classification measures and vice versa. Our largest experiments to date, consisting of 80 training images totaling over 416 million pixels, are presented to illustrate these conclusions. This data set is more representative than previous experiments, containing a more balanced distribution of content types. Contained in this data set are also images of text obtained from handheld digital cameras and the success of existing methods (with no modification) in classifying these images with are discussed. Initial experiments in discriminating line art from the four classes mentioned above are also described. We also discuss methodological issues that affect both ground-truthing and evaluation measures."
            },
            "slug": "Segmentation-based-retrieval-of-document-images-Moll-Baird",
            "title": {
                "fragments": [],
                "text": "Segmentation-based retrieval of document images from diverse collections"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "The largest experiments to date, consisting of 80 training images totaling over 416 million pixels, are presented, and it is shown that this data set is more representative than previous experiments, containing a more balanced distribution of content types."
            },
            "venue": {
                "fragments": [],
                "text": "Electronic Imaging"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2569483"
                        ],
                        "name": "M. S. Erk\u0131l\u0131n\u00e7",
                        "slug": "M.-S.-Erk\u0131l\u0131n\u00e7",
                        "structuredName": {
                            "firstName": "M.",
                            "lastName": "Erk\u0131l\u0131n\u00e7",
                            "middleNames": [
                                "Sezer"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. S. Erk\u0131l\u0131n\u00e7"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40165419"
                        ],
                        "name": "M. Jaber",
                        "slug": "M.-Jaber",
                        "structuredName": {
                            "firstName": "Mustafa",
                            "lastName": "Jaber",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Jaber"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733172"
                        ],
                        "name": "E. Saber",
                        "slug": "E.-Saber",
                        "structuredName": {
                            "firstName": "Eli",
                            "lastName": "Saber",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Saber"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47712094"
                        ],
                        "name": "P\u00e9ter Bauer",
                        "slug": "P\u00e9ter-Bauer",
                        "structuredName": {
                            "firstName": "P\u00e9ter",
                            "lastName": "Bauer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P\u00e9ter Bauer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2785103"
                        ],
                        "name": "Dejan Depalov",
                        "slug": "Dejan-Depalov",
                        "structuredName": {
                            "firstName": "Dejan",
                            "lastName": "Depalov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dejan Depalov"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 6,
                                "start": 0
                            }
                        ],
                        "text": "[3, 4] proposed methods to reduce the computation burden of document analysis using projections for identifying image blocks but do not benefit from the robustness of CNNs using a one-dimensional convolutional architecture."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 61446693,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7a590d808c8378343bc994f45fdccfb3271a6805",
            "isKey": false,
            "numCitedBy": 3,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "A framework for region/zone classification in color and gray-scale scanned documents is proposed in this paper. The algorithm includes modules for extracting text, photo, and strong edge/line regions. Firstly, a text detection module which is based on wavelet analysis and Run Length Encoding (RLE) technique is employed. Local and global energy maps in high frequency bands of the wavelet domain are generated and used as initial text maps. Further analysis using RLE yields a final text map. The second module is developed to detect image/photo and pictorial regions in the input document. A block-based classifier using basis vector projections is employed to identify photo candidate regions. Then, a final photo map is obtained by applying probabilistic model based on Markov random field (MRF) based maximum a posteriori (MAP) optimization with iterated conditional mode (ICM). The final module detects lines and strong edges using Hough transform and edge-linkages analysis, respectively. The text, photo, and strong edge/line maps are combined to generate a page layout classification of the scanned target document. Experimental results and objective evaluation show that the proposed technique has a very effective performance on variety of simple and complex scanned document types obtained from MediaTeam Oulu document database. The proposed page layout classifier can be used in systems for efficient document storage, content based document retrieval, optical character recognition, mobile phone imagery, and augmented reality."
            },
            "slug": "Page-layout-analysis-and-classification-for-complex-Erk\u0131l\u0131n\u00e7-Jaber",
            "title": {
                "fragments": [],
                "text": "Page layout analysis and classification for complex scanned documents"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The proposed page layout classifier can be used in systems for efficient document storage, content based document retrieval, optical character recognition, mobile phone imagery, and augmented reality."
            },
            "venue": {
                "fragments": [],
                "text": "Optical Engineering + Applications"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2170742"
                        ],
                        "name": "Nibal Nayef",
                        "slug": "Nibal-Nayef",
                        "structuredName": {
                            "firstName": "Nibal",
                            "lastName": "Nayef",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nibal Nayef"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695766"
                        ],
                        "name": "J. Ogier",
                        "slug": "J.-Ogier",
                        "structuredName": {
                            "firstName": "Jean-Marc",
                            "lastName": "Ogier",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Ogier"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "65 [16] 1."
                    },
                    "intents": []
                }
            ],
            "corpusId": 30457691,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a996b518cb5dcab27713cfda6a29826e49c9df1e",
            "isKey": false,
            "numCitedBy": 3,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "Text zone classification is a vital step in the digitization process, without which OCR systems perform poorly. Prior methods to document zone classification have relied on large sets of hand-crafted features for training zone classifiers. Such features are usually database-dependent, and their computation is time consuming. In this work we propose a novel method for text zone classification that relies on the approach of unsupervised feature learning. Within our method, feature vectors of document zones are automatically learned by patches extraction, encoding and pooling, where feature encoding is based on a codebook of visual words. The training phase of the text classifier takes into consideration the unbalance between text zones and non-text zones of all types. The proposed method has been tested on publicly available standard databases, and achieved competitive or better results compared to state-of-the-art methods. The results show that our approach matches well the task of text classification, and is robust to zone shapes, orientations and size."
            },
            "slug": "Text-zone-classification-using-unsupervised-feature-Nayef-Ogier",
            "title": {
                "fragments": [],
                "text": "Text zone classification using unsupervised feature learning"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The proposed method for text zone classification that relies on the approach of unsupervised feature learning has been tested on publicly available standard databases, and achieved competitive or better results compared to state-of-the-art methods."
            },
            "venue": {
                "fragments": [],
                "text": "2015 13th International Conference on Document Analysis and Recognition (ICDAR)"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145714522"
                        ],
                        "name": "Le Kang",
                        "slug": "Le-Kang",
                        "structuredName": {
                            "firstName": "Le",
                            "lastName": "Kang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Le Kang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143775793"
                        ],
                        "name": "J. Kumar",
                        "slug": "J.-Kumar",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Kumar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Kumar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144449660"
                        ],
                        "name": "Peng Ye",
                        "slug": "Peng-Ye",
                        "structuredName": {
                            "firstName": "Peng",
                            "lastName": "Ye",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Peng Ye"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2153682487"
                        ],
                        "name": "Yi Li",
                        "slug": "Yi-Li",
                        "structuredName": {
                            "firstName": "Yi",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yi Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48471936"
                        ],
                        "name": "D. Doermann",
                        "slug": "D.-Doermann",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Doermann",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Doermann"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 187,
                                "start": 181
                            }
                        ],
                        "text": "When it comes to image classification, convolutional neural networks (CNNs) have been widely adopted in many different fields for a variety of purposes, including document analysis [9, 8]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 16147742,
            "fieldsOfStudy": [
                "Computer Science",
                "Environmental Science"
            ],
            "id": "432bbce9609e62f699a7419ea9b243bd486f9acb",
            "isKey": false,
            "numCitedBy": 106,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a Convolutional Neural Network (CNN) for document image classification. In particular, document image classes are defined by the structural similarity. Previous approaches rely on hand-crafted features for capturing structural information. In contrast, we propose to learn features from raw image pixels using CNN. The use of CNN is motivated by the the hierarchical nature of document layout. Equipped with rectified linear units and trained with dropout, our CNN performs well even when document layouts present large inner-class variations. Experiments on public challenging datasets demonstrate the effectiveness of the proposed approach."
            },
            "slug": "Convolutional-Neural-Networks-for-Document-Image-Kang-Kumar",
            "title": {
                "fragments": [],
                "text": "Convolutional Neural Networks for Document Image Classification"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "Equipped with rectified linear units and trained with dropout, this CNN performs well even when document layouts present large inner-class variations, and experiments on public challenging datasets demonstrate the effectiveness of the proposed approach."
            },
            "venue": {
                "fragments": [],
                "text": "2014 22nd International Conference on Pattern Recognition"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145461897"
                        ],
                        "name": "S. S. Bukhari",
                        "slug": "S.-S.-Bukhari",
                        "structuredName": {
                            "firstName": "Syed",
                            "lastName": "Bukhari",
                            "middleNames": [
                                "Saqib"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. S. Bukhari"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688013"
                        ],
                        "name": "F. Shafait",
                        "slug": "F.-Shafait",
                        "structuredName": {
                            "firstName": "Faisal",
                            "lastName": "Shafait",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Shafait"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733858"
                        ],
                        "name": "T. Breuel",
                        "slug": "T.-Breuel",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Breuel",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Breuel"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "3*UW III [2] 0."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "3*ICDAR 2009 [2] 0."
                    },
                    "intents": []
                }
            ],
            "corpusId": 2551062,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "680691b631baeecb70d31403fc6f9e2560e9f574",
            "isKey": false,
            "numCitedBy": 53,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "Page segmentation into text and non-text elements is an essential preprocessing step before optical character recognition (OCR) operation. In case of poor segmentation, an OCR classification engine produces garbage characters due to the presence of non-text elements. This paper describes modifications to the text/non-text segmentation algorithm presented by Bloomberg,1 which is also available in his open-source Leptonica library.2The modifications result in significant improvements and achieved better segmentation accuracy than the original algorithm for UW-III, UNLV, ICDAR 2009 page segmentation competition test images and circuit diagram datasets."
            },
            "slug": "Improved-document-image-segmentation-algorithm-Bukhari-Shafait",
            "title": {
                "fragments": [],
                "text": "Improved document image segmentation algorithm using multiresolution morphology"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "Modifications to the text/non-text segmentation algorithm presented by Bloomberg are described which result in significant improvements and achieved better segmentation accuracy than the original algorithm for UW-III, UNLV, ICDAR 2009 page segmentation competition test images and circuit diagram datasets."
            },
            "venue": {
                "fragments": [],
                "text": "Electronic Imaging"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3340391"
                        ],
                        "name": "O. Okun",
                        "slug": "O.-Okun",
                        "structuredName": {
                            "firstName": "Oleg",
                            "lastName": "Okun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Okun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48471936"
                        ],
                        "name": "D. Doermann",
                        "slug": "D.-Doermann",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Doermann",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Doermann"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145962204"
                        ],
                        "name": "M. Pietik\u00e4inen",
                        "slug": "M.-Pietik\u00e4inen",
                        "structuredName": {
                            "firstName": "Matti",
                            "lastName": "Pietik\u00e4inen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Pietik\u00e4inen"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 60292304,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "003b0302980c3143bf5941ac3b738bad8f704a28",
            "isKey": false,
            "numCitedBy": 50,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract : Page segmentation and zone classification are key areas of research in document image processing, because they occupy an intermediate position between document preprocessing and higher-level document understanding such as logical page analysis and OCR. Such analysis of the page relies heavily on an appropriate document model and results in a representation of the physical structure of the document. The purpose of this review is to analyze progress made in page segmentation and zone classification and suggest what needs to be done to advance the field."
            },
            "slug": "Page-Segmentation-and-Zone-Classification:-The-of-Okun-Doermann",
            "title": {
                "fragments": [],
                "text": "Page Segmentation and Zone Classification: The State of the Art"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "The purpose of this review is to analyze progress made in page segmentation and zone classification and suggest what needs to be done to advance the field."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108860705"
                        ],
                        "name": "M.-W. Lin",
                        "slug": "M.-W.-Lin",
                        "structuredName": {
                            "firstName": "M.-W.",
                            "lastName": "Lin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M.-W. Lin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3165624"
                        ],
                        "name": "J. Tapamo",
                        "slug": "J.-Tapamo",
                        "structuredName": {
                            "firstName": "Jules-Raymond",
                            "lastName": "Tapamo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Tapamo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2332904"
                        ],
                        "name": "B. Ndovie",
                        "slug": "B.-Ndovie",
                        "structuredName": {
                            "firstName": "B.",
                            "lastName": "Ndovie",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Ndovie"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "3*MediaTeam [12] 8."
                    },
                    "intents": []
                }
            ],
            "corpusId": 17300339,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "33ae0c2ae9e7ad1d6fa3fcc82e1bd5a6c8204eba",
            "isKey": false,
            "numCitedBy": 51,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we present a hybrid approach to segment and classify contents of document images. A Document Image is segmented into three types of regions: Graphics, Text and Space. The image of a document is subdivided into blocks and for each block five GLCM (Grey Level Co-occurrence Matrix) features are extracted. Based on these features, blocks are then clustered into three groups using K-Means algorithm; connected blocks that belong to the same group are merged. The classification of groups is done using pre-learned heuristic rules. Experiments were conducted on scanned newspapers and images from MediaTeam Document Database"
            },
            "slug": "A-texture-based-method-for-document-segmentation-Lin-Tapamo",
            "title": {
                "fragments": [],
                "text": "A texture-based method for document segmentation and classification"
            },
            "tldr": {
                "abstractSimilarityScore": 84,
                "text": "This paper presents a hybrid approach to segment and classify contents of document images, segmented into three types of regions: Graphics, Text and Space."
            },
            "venue": {
                "fragments": [],
                "text": "South Afr. Comput. J."
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34838386"
                        ],
                        "name": "K. Simonyan",
                        "slug": "K.-Simonyan",
                        "structuredName": {
                            "firstName": "Karen",
                            "lastName": "Simonyan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Simonyan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688869"
                        ],
                        "name": "Andrew Zisserman",
                        "slug": "Andrew-Zisserman",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Zisserman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Zisserman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 83,
                                "start": 79
                            }
                        ],
                        "text": "The CNN architectures used in this paper were inspired in the VGG architecture [18] and consists of a number of convolutional layers responsible for computing convolutional features, followed by a number of fully connected layers, which classify the features and generate probabilities for each class of interest."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14124313,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "eb42cf88027de515750f230b23b1a057dc782108",
            "isKey": false,
            "numCitedBy": 62220,
            "numCiting": 58,
            "paperAbstract": {
                "fragments": [],
                "text": "In this work we investigate the effect of the convolutional network depth on its accuracy in the large-scale image recognition setting. Our main contribution is a thorough evaluation of networks of increasing depth using an architecture with very small (3x3) convolution filters, which shows that a significant improvement on the prior-art configurations can be achieved by pushing the depth to 16-19 weight layers. These findings were the basis of our ImageNet Challenge 2014 submission, where our team secured the first and the second places in the localisation and classification tracks respectively. We also show that our representations generalise well to other datasets, where they achieve state-of-the-art results. We have made our two best-performing ConvNet models publicly available to facilitate further research on the use of deep visual representations in computer vision."
            },
            "slug": "Very-Deep-Convolutional-Networks-for-Large-Scale-Simonyan-Zisserman",
            "title": {
                "fragments": [],
                "text": "Very Deep Convolutional Networks for Large-Scale Image Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 73,
                "text": "This work investigates the effect of the convolutional network depth on its accuracy in the large-scale image recognition setting using an architecture with very small convolution filters, which shows that a significant improvement on the prior-art configurations can be achieved by pushing the depth to 16-19 weight layers."
            },
            "venue": {
                "fragments": [],
                "text": "ICLR"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145470231"
                        ],
                        "name": "Kwan Y. Wong",
                        "slug": "Kwan-Y.-Wong",
                        "structuredName": {
                            "firstName": "Kwan",
                            "lastName": "Wong",
                            "middleNames": [
                                "Y."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kwan Y. Wong"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34896449"
                        ],
                        "name": "R. Casey",
                        "slug": "R.-Casey",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Casey",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Casey"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1880661"
                        ],
                        "name": "F. Wahl",
                        "slug": "F.-Wahl",
                        "structuredName": {
                            "firstName": "Friedrich",
                            "lastName": "Wahl",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Wahl"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 135,
                                "start": 131
                            }
                        ],
                        "text": "Single pages are converted into gray-scale images (see Figure 2a), and then processed by the running length algorithm described in [21] to detect regions with high chance of containing information."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 64,
                                "start": 60
                            }
                        ],
                        "text": "b) Binary image resulting from the running length algorithm [21]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 214,
                                "start": 206
                            }
                        ],
                        "text": "In literature, many methods have been proposed for document image layout analysis, and according to [11] they can be classified into three different groups: (i) region or block based classification methods [21, 17], (ii) pixel based classification methods [14, 13], (iii) connected component classification methods [6, 20, 1]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 15921038,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7abca302c74d2f5adfd323a28e26d40b019df2b5",
            "isKey": false,
            "numCitedBy": 594,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper outlines the requirements and components for a proposed Document Analysis System, which assists a user in encoding printed documents for computer processing. Several critical functions have been investigated and the technical approaches are discussed. The first is the segmentation and classification of digitized printed documents into regions of text and images. A nonlinear, run-length smoothing algorithm has been used for this purpose. By using the regular features of text lines, a linear adaptive classification scheme discriminates text regions from others. The second technique studied is an adaptive approach to the recognition of the hundreds of font styles and sizes that can occur on printed documents. A preclassifier is constructed during the input process and used to speed up a well-known pattern-matching method for clustering characters from an arbitrary print source into a small sample of prototypes. Experimental results are included."
            },
            "slug": "Document-Analysis-System-Wong-Casey",
            "title": {
                "fragments": [],
                "text": "Document Analysis System"
            },
            "tldr": {
                "abstractSimilarityScore": 92,
                "text": "The requirements and components for a proposed Document Analysis System, which assists a user in encoding printed documents for computer processing, are outlined and several critical functions have been investigated and the technical approaches are discussed."
            },
            "venue": {
                "fragments": [],
                "text": "IBM J. Res. Dev."
            },
            "year": 1982
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47260288"
                        ],
                        "name": "L. Fletcher",
                        "slug": "L.-Fletcher",
                        "structuredName": {
                            "firstName": "Lloyd",
                            "lastName": "Fletcher",
                            "middleNames": [
                                "Alan"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Fletcher"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3110392"
                        ],
                        "name": "R. Kasturi",
                        "slug": "R.-Kasturi",
                        "structuredName": {
                            "firstName": "Rangachar",
                            "lastName": "Kasturi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Kasturi"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 325,
                                "start": 315
                            }
                        ],
                        "text": "In literature, many methods have been proposed for document image layout analysis, and according to [11] they can be classified into three different groups: (i) region or block based classification methods [21, 17], (ii) pixel based classification methods [14, 13], (iii) connected component classification methods [6, 20, 1]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2685456,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b08e547ba4edb60902d1708a5593d71f075aa7f1",
            "isKey": false,
            "numCitedBy": 655,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "The development and implementation of an algorithm for automated text string separation that is relatively independent of changes in text font style and size and of string orientation are described. It is intended for use in an automated system for document analysis. The principal parts of the algorithm are the generation of connected components and the application of the Hough transform in order to group components into logical character strings that can then be separated from the graphics. The algorithm outputs two images, one containing text strings and the other graphics. These images can then be processed by suitable character recognition and graphics recognition systems. The performance of the algorithm, both in terms of its effectiveness and computational efficiency, was evaluated using several test images and showed superior performance compared to other techniques. >"
            },
            "slug": "A-Robust-Algorithm-for-Text-String-Separation-from-Fletcher-Kasturi",
            "title": {
                "fragments": [],
                "text": "A Robust Algorithm for Text String Separation from Mixed Text/Graphics Images"
            },
            "tldr": {
                "abstractSimilarityScore": 85,
                "text": "The development and implementation of an algorithm for automated text string separation that is relatively independent of changes in text font style and size and of string orientation are described and showed superior performance compared to other techniques."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1795288"
                        ],
                        "name": "K. Tombre",
                        "slug": "K.-Tombre",
                        "structuredName": {
                            "firstName": "Karl",
                            "lastName": "Tombre",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Tombre"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1719344"
                        ],
                        "name": "S. Tabbone",
                        "slug": "S.-Tabbone",
                        "structuredName": {
                            "firstName": "Salvatore",
                            "lastName": "Tabbone",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Tabbone"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31972224"
                        ],
                        "name": "L. P\u00e9lissier",
                        "slug": "L.-P\u00e9lissier",
                        "structuredName": {
                            "firstName": "Lo\u00efc",
                            "lastName": "P\u00e9lissier",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. P\u00e9lissier"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1801759"
                        ],
                        "name": "B. Lamiroy",
                        "slug": "B.-Lamiroy",
                        "structuredName": {
                            "firstName": "Bart",
                            "lastName": "Lamiroy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Lamiroy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2562511"
                        ],
                        "name": "P. Dosch",
                        "slug": "P.-Dosch",
                        "structuredName": {
                            "firstName": "Philippe",
                            "lastName": "Dosch",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Dosch"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 325,
                                "start": 315
                            }
                        ],
                        "text": "In literature, many methods have been proposed for document image layout analysis, and according to [11] they can be classified into three different groups: (i) region or block based classification methods [21, 17], (ii) pixel based classification methods [14, 13], (iii) connected component classification methods [6, 20, 1]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 16384820,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fdd06aef8c129c27ebbec3439c3224024261cfad",
            "isKey": false,
            "numCitedBy": 161,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "Text/graphics separation aims at segmenting the document into two layers: a layer assumed to contain text and a layer containing graphical objects. In this paper, we present a consolidation of a method proposed by Fletcher and Kasturi, with a number of improvements to make it more suitable for graphics-rich documents. We discuss the right choice of thresholds for this method, and their stability. We also propose a post-processing step for retrieving text components touching the graphics, through local segmentation of the distance skeleton."
            },
            "slug": "Text/Graphics-Separation-Revisited-Tombre-Tabbone",
            "title": {
                "fragments": [],
                "text": "Text/Graphics Separation Revisited"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This paper presents a consolidation of a method proposed by Fletcher and Kasturi, with a number of improvements to make it more suitable for graphics-rich documents."
            },
            "venue": {
                "fragments": [],
                "text": "Document Analysis Systems"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2897313"
                        ],
                        "name": "Nitish Srivastava",
                        "slug": "Nitish-Srivastava",
                        "structuredName": {
                            "firstName": "Nitish",
                            "lastName": "Srivastava",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nitish Srivastava"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2064160"
                        ],
                        "name": "A. Krizhevsky",
                        "slug": "A.-Krizhevsky",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Krizhevsky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Krizhevsky"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1701686"
                        ],
                        "name": "Ilya Sutskever",
                        "slug": "Ilya-Sutskever",
                        "structuredName": {
                            "firstName": "Ilya",
                            "lastName": "Sutskever",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ilya Sutskever"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145124475"
                        ],
                        "name": "R. Salakhutdinov",
                        "slug": "R.-Salakhutdinov",
                        "structuredName": {
                            "firstName": "Ruslan",
                            "lastName": "Salakhutdinov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Salakhutdinov"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "1 dropout [19] for regularization."
                    },
                    "intents": []
                }
            ],
            "corpusId": 6844431,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "34f25a8704614163c4095b3ee2fc969b60de4698",
            "isKey": false,
            "numCitedBy": 28147,
            "numCiting": 43,
            "paperAbstract": {
                "fragments": [],
                "text": "Deep neural nets with a large number of parameters are very powerful machine learning systems. However, overfitting is a serious problem in such networks. Large networks are also slow to use, making it difficult to deal with overfitting by combining the predictions of many different large neural nets at test time. Dropout is a technique for addressing this problem. The key idea is to randomly drop units (along with their connections) from the neural network during training. This prevents units from co-adapting too much. During training, dropout samples from an exponential number of different \"thinned\" networks. At test time, it is easy to approximate the effect of averaging the predictions of all these thinned networks by simply using a single unthinned network that has smaller weights. This significantly reduces overfitting and gives major improvements over other regularization methods. We show that dropout improves the performance of neural networks on supervised learning tasks in vision, speech recognition, document classification and computational biology, obtaining state-of-the-art results on many benchmark data sets."
            },
            "slug": "Dropout:-a-simple-way-to-prevent-neural-networks-Srivastava-Hinton",
            "title": {
                "fragments": [],
                "text": "Dropout: a simple way to prevent neural networks from overfitting"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "It is shown that dropout improves the performance of neural networks on supervised learning tasks in vision, speech recognition, document classification and computational biology, obtaining state-of-the-art results on many benchmark data sets."
            },
            "venue": {
                "fragments": [],
                "text": "J. Mach. Learn. Res."
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "33354551"
                        ],
                        "name": "A. Giusti",
                        "slug": "A.-Giusti",
                        "structuredName": {
                            "firstName": "Alessandro",
                            "lastName": "Giusti",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Giusti"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1895356"
                        ],
                        "name": "D. Ciresan",
                        "slug": "D.-Ciresan",
                        "structuredName": {
                            "firstName": "Dan",
                            "lastName": "Ciresan",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Ciresan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2426718"
                        ],
                        "name": "Jonathan Masci",
                        "slug": "Jonathan-Masci",
                        "structuredName": {
                            "firstName": "Jonathan",
                            "lastName": "Masci",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jonathan Masci"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "6803671"
                        ],
                        "name": "L. Gambardella",
                        "slug": "L.-Gambardella",
                        "structuredName": {
                            "firstName": "Luca",
                            "lastName": "Gambardella",
                            "middleNames": [
                                "Maria"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Gambardella"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145341374"
                        ],
                        "name": "J. Schmidhuber",
                        "slug": "J.-Schmidhuber",
                        "structuredName": {
                            "firstName": "J\u00fcrgen",
                            "lastName": "Schmidhuber",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Schmidhuber"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 92,
                                "start": 89
                            }
                        ],
                        "text": "In this model, each bi-dimensional convolutional layer is followed by a MaxPooling layer [7] with 2 pixels kernel and a 0."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 93,
                                "start": 90
                            }
                        ],
                        "text": "In this model, each one-dimensional convolutional layer is followed by a MaxPooling layer [7] with a kernel size of 2 pixels and a 0."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 9237654,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "68299ec9b72e3ac378a1fdc9d86039ebba203deb",
            "isKey": false,
            "numCitedBy": 296,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "Deep Neural Networks now excel at image classification, detection and segmentation. When used to scan images by means of a sliding window, however, their high computational complexity can bring even the most powerful hardware to its knees. We show how dynamic programming can speedup the process by orders of magnitude, even when max-pooling layers are present."
            },
            "slug": "Fast-image-scanning-with-deep-max-pooling-neural-Giusti-Ciresan",
            "title": {
                "fragments": [],
                "text": "Fast image scanning with deep max-pooling convolutional neural networks"
            },
            "tldr": {
                "abstractSimilarityScore": 37,
                "text": "This work shows how dynamic programming can speedup the process by orders of magnitude, even when max-pooling layers are present."
            },
            "venue": {
                "fragments": [],
                "text": "2013 IEEE International Conference on Image Processing"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2073603971"
                        ],
                        "name": "Vinod Nair",
                        "slug": "Vinod-Nair",
                        "structuredName": {
                            "firstName": "Vinod",
                            "lastName": "Nair",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Vinod Nair"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 157,
                                "start": 153
                            }
                        ],
                        "text": "Each projection is processed by an independent convolutional track composed by a sequence of three 1D convolutional layers with 50 filters each and ReLu [15] activation."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 210,
                                "start": 206
                            }
                        ],
                        "text": "For the bi-dimensional baseline we implemented an architecture that receives as input a bi-dimensional image tile and processes it using a sequence of three 2D convolutional layers with 50 filters and ReLu [15] activation; then evaluate the convolutional features using a fully connected layer with 50 nodes connected to a fully connected layer with 3 nodes and softmax activation (for three classes categorical classification)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 205,
                                "start": 201
                            }
                        ],
                        "text": "For the bi-dimensional baseline we implemented an architecture that receives as input a bi-dimensional image tile and processes it using a sequence of three 2D convolutional layers with 50 filters and ReLu [15] activation; then evaluate the convolutional features using a fully connected layer\nwith 50 nodes connected to a fully connected layer with 3 nodes and softmax activation (for three classes categorical classification)."
                    },
                    "intents": []
                }
            ],
            "corpusId": 15539264,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a538b05ebb01a40323997629e171c91aa28b8e2f",
            "isKey": true,
            "numCitedBy": 12807,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "Restricted Boltzmann machines were developed using binary stochastic hidden units. These can be generalized by replacing each binary unit by an infinite number of copies that all have the same weights but have progressively more negative biases. The learning and inference rules for these \"Stepped Sigmoid Units\" are unchanged. They can be approximated efficiently by noisy, rectified linear units. Compared with binary units, these units learn features that are better for object recognition on the NORB dataset and face verification on the Labeled Faces in the Wild dataset. Unlike binary units, rectified linear units preserve information about relative intensities as information travels through multiple layers of feature detectors."
            },
            "slug": "Rectified-Linear-Units-Improve-Restricted-Boltzmann-Nair-Hinton",
            "title": {
                "fragments": [],
                "text": "Rectified Linear Units Improve Restricted Boltzmann Machines"
            },
            "tldr": {
                "abstractSimilarityScore": 62,
                "text": "Restricted Boltzmann machines were developed using binary stochastic hidden units that learn features that are better for object recognition on the NORB dataset and face verification on the Labeled Faces in the Wild dataset."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2010
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 264,
                                "start": 256
                            }
                        ],
                        "text": "In literature, many methods have been proposed for document image layout analysis, and according to [11] they can be classified into three different groups: (i) region or block based classification methods [21, 17], (ii) pixel based classification methods [14, 13], (iii) connected component classification methods [6, 20, 1]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Truthing for pixelaccurate segmentation"
            },
            "venue": {
                "fragments": [],
                "text": "The Eighth IAPR International Workshop on Document Analysis Systems,"
            },
            "year": 2008
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Text / graphics separation revisited Document analysis system"
            },
            "venue": {
                "fragments": [],
                "text": "IBM journal of research and development"
            }
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 2,
            "methodology": 12
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 20,
        "totalPages": 2
    },
    "page_url": "https://www.semanticscholar.org/paper/Fast-CNN-Based-Document-Layout-Analysis-Viana-Oliveira/cdcdf4df32a753523d82dd5c2daa55b11ac73749?sort=total-citations"
}