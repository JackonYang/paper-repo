{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3157053"
                        ],
                        "name": "Nanyun Peng",
                        "slug": "Nanyun-Peng",
                        "structuredName": {
                            "firstName": "Nanyun",
                            "lastName": "Peng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nanyun Peng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1759772"
                        ],
                        "name": "Hoifung Poon",
                        "slug": "Hoifung-Poon",
                        "structuredName": {
                            "firstName": "Hoifung",
                            "lastName": "Poon",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hoifung Poon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2596310"
                        ],
                        "name": "Chris Quirk",
                        "slug": "Chris-Quirk",
                        "structuredName": {
                            "firstName": "Chris",
                            "lastName": "Quirk",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chris Quirk"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3259253"
                        ],
                        "name": "Kristina Toutanova",
                        "slug": "Kristina-Toutanova",
                        "structuredName": {
                            "firstName": "Kristina",
                            "lastName": "Toutanova",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kristina Toutanova"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144105277"
                        ],
                        "name": "Wen-tau Yih",
                        "slug": "Wen-tau-Yih",
                        "structuredName": {
                            "firstName": "Wen-tau",
                            "lastName": "Yih",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wen-tau Yih"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 33,
                                "start": 15
                            }
                        ],
                        "text": "In particular, Peng et al. (2017) make model parameters specific to edge labels."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 44,
                                "start": 26
                            }
                        ],
                        "text": "Their model is similar as Peng et al. (2017) by calculating node states sequentially: for each input graph, a start node and a node sequence are chosen, which determines the order of recurrent state updates."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 70,
                                "start": 52
                            }
                        ],
                        "text": "To calculate a hidden state encoding for each word, Peng et al. (2017) first split the input graph into two directed acyclic graphs (DAGs) by separating left-to-right edges from right-to-left edges (Figure 1 (b))."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 230,
                                "start": 212
                            }
                        ],
                        "text": "\u2026(the Cross column in Table 3), our graph state LSTM model shows the highest test accuracy among all methods, which is 5.9% higher than our baseline.4 The accuracy of our baseline is lower than EMBED and FULL of Peng et al. (2017), which is likely due to the differences mentioned in Section 3.3."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 28,
                                "start": 10
                            }
                        ],
                        "text": "Following Peng et al. (2017), five-fold crossvalidation is used for evaluating the models,3 and the final test accuracy is calculated by averaging the test accuracies over all five folds."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 52,
                                "start": 34
                            }
                        ],
                        "text": "Our final results are better than Peng et al. (2017), despite the fact that we do not use multi-task learning."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 155,
                                "start": 137
                            }
                        ],
                        "text": "Results show that our model outperforms a bidirectional DAG LSTM baseline by 5.9% in accuracy, overtaking the state-of-the-art system of Peng et al. (2017) by 1.2%."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 18,
                                "start": 0
                            }
                        ],
                        "text": "Peng et al. (2017) proposed a graph-structured LSTM for n-ary relation extraction."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 28,
                                "start": 10
                            }
                        ],
                        "text": "We follow Peng et al. (2017) and binarize multi-class labels by grouping all relation classes as \u201cYes\u201d and treat \u201cNone\u201d as \u201cNo\u201d."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 28,
                                "start": 10
                            }
                        ],
                        "text": "We follow Peng et al. (2017) by studying ternary cross-sentence relations."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 153,
                                "start": 135
                            }
                        ],
                        "text": "For fair comparison with DAG LSTMs, we build a graph LSTM by extending Song et al. (2018), which strictly follow the configurations of Peng et al. (2017) such as the source of features and hyper parameter settings."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 169,
                                "start": 151
                            }
                        ],
                        "text": "The state of the graph consists of all word states, and thus can be represented as:\ng = {hj}|vj\u2208V (6) 1For more information please refer Section 3.3 of Peng\net al. (2017)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 269,
                                "start": 252
                            }
                        ],
                        "text": "It has been shown to be useful for detecting explicit facts, such as cause-effect (Hendrickx et al., 2009), and predicting the effectiveness of a medicine on a cancer caused by mutation of a certain gene in the biomedical domain (Quirk and Poon, 2017; Peng et al., 2017)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 168,
                                "start": 151
                            }
                        ],
                        "text": "The performance of forward and backward lag behind concat, which is consistent with the intuition that both forward and backward relations are useful (Peng et al., 2017)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 40,
                                "start": 22
                            }
                        ],
                        "text": "We use the dataset of Peng et al. (2017), which is a biomedical-domain dataset focusing on druggene-mutation ternary relations,2 extracted from PubMed."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 68,
                                "start": 50
                            }
                        ],
                        "text": "For a bi-directional DAG LSTM baseline, we follow Peng et al. (2017), splitting each input graph into two separate DAGs by separating leftto-right edges from right-to-left edges (Figure 1)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 142,
                                "start": 125
                            }
                        ],
                        "text": "This task can be formulated as a binary classification problem of determining whether 1, . . . , N together form a relation (Peng et al., 2017), or a multi-class classification problem of detecting which relation holds for the entity mentions."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 18,
                                "start": 0
                            }
                        ],
                        "text": "Peng et al. (2017) formulate the task as a graphstructured problem in order to adopt rich dependency and discourse features."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 61,
                                "start": 43
                            }
                        ],
                        "text": "Our baseline is computationally similar to Peng et al. (2017), but different on how to utilize edge labels in the gated network."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2797612,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "54b8aadb7c2576665ce26caf59464b6449ac9ccf",
            "isKey": true,
            "numCitedBy": 346,
            "numCiting": 61,
            "paperAbstract": {
                "fragments": [],
                "text": "Past work in relation extraction has focused on binary relations in single sentences. Recent NLP inroads in high-value domains have sparked interest in the more general setting of extracting n-ary relations that span multiple sentences. In this paper, we explore a general relation extraction framework based on graph long short-term memory networks (graph LSTMs) that can be easily extended to cross-sentence n-ary relation extraction. The graph formulation provides a unified way of exploring different LSTM approaches and incorporating various intra-sentential and inter-sentential dependencies, such as sequential, syntactic, and discourse relations. A robust contextual representation is learned for the entities, which serves as input to the relation classifier. This simplifies handling of relations with arbitrary arity, and enables multi-task learning with related relations. We evaluate this framework in two important precision medicine settings, demonstrating its effectiveness with both conventional supervised learning and distant supervision. Cross-sentence extraction produced larger knowledge bases. and multi-task learning significantly improved extraction accuracy. A thorough analysis of various LSTM approaches yielded useful insight the impact of linguistic analysis on extraction accuracy."
            },
            "slug": "Cross-Sentence-N-ary-Relation-Extraction-with-Graph-Peng-Poon",
            "title": {
                "fragments": [],
                "text": "Cross-Sentence N-ary Relation Extraction with Graph LSTMs"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "A general relation extraction framework based on graph long short-term memory networks (graph LSTMs) that can be easily extended to cross-sentence n-ary relation extraction is explored, demonstrating its effectiveness with both conventional supervised learning and distant supervision."
            },
            "venue": {
                "fragments": [],
                "text": "TACL"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1731657"
                        ],
                        "name": "Makoto Miwa",
                        "slug": "Makoto-Miwa",
                        "structuredName": {
                            "firstName": "Makoto",
                            "lastName": "Miwa",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Makoto Miwa"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143977268"
                        ],
                        "name": "Mohit Bansal",
                        "slug": "Mohit-Bansal",
                        "structuredName": {
                            "firstName": "Mohit",
                            "lastName": "Bansal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mohit Bansal"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 261,
                                "start": 62
                            }
                        ],
                        "text": "While most existing work extracts relations within a sentence (Zelenko et al., 2003; Palmer et al., 2005; Zhao and Grishman, 2005; Jiang and Zhai, 2007; Plank and Moschitti, 2013; Li and Ji, 2014; Gormley et al., 2015; Miwa and Bansal, 2016; Zhang et al., 2017), the task of cross-sentence relation extraction has received increasing attention (Gerber and Chai, 2010; Yoshikawa et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 145,
                                "start": 122
                            }
                        ],
                        "text": "The bi-directional DAG LSTM model showed superior performance over several strong baselines, such as tree-structured LSTM (Miwa and Bansal, 2016), on a biomedical-domain benchmark."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2476229,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3899f87a2031f3434f89beb68c11a1ca6428328a",
            "isKey": false,
            "numCitedBy": 796,
            "numCiting": 72,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a novel end-to-end neural model to extract entities and relations between them. Our recurrent neural network based model captures both word sequence and dependency tree substructure information by stacking bidirectional tree-structured LSTM-RNNs on bidirectional sequential LSTM-RNNs. This allows our model to jointly represent both entities and relations with shared parameters in a single model. We further encourage detection of entities during training and use of entity information in relation extraction via entity pretraining and scheduled sampling. Our model improves over the state-of-the-art feature-based model on end-to-end relation extraction, achieving 12.1% and 5.7% relative error reductions in F1-score on ACE2005 and ACE2004, respectively. We also show that our LSTM-RNN based model compares favorably to the state-of-the-art CNN based model (in F1-score) on nominal relation classification (SemEval-2010 Task 8). Finally, we present an extensive ablation analysis of several model components."
            },
            "slug": "End-to-End-Relation-Extraction-using-LSTMs-on-and-Miwa-Bansal",
            "title": {
                "fragments": [],
                "text": "End-to-End Relation Extraction using LSTMs on Sequences and Tree Structures"
            },
            "tldr": {
                "abstractSimilarityScore": 60,
                "text": "A novel end-to-end neural model to extract entities and relations between them and compares favorably to the state-of-the-art CNN based model (in F1-score) on nominal relation classification (SemEval-2010 Task 8)."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2022957"
                        ],
                        "name": "Diego Marcheggiani",
                        "slug": "Diego-Marcheggiani",
                        "structuredName": {
                            "firstName": "Diego",
                            "lastName": "Marcheggiani",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Diego Marcheggiani"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144889265"
                        ],
                        "name": "Ivan Titov",
                        "slug": "Ivan-Titov",
                        "structuredName": {
                            "firstName": "Ivan",
                            "lastName": "Titov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ivan Titov"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 122,
                                "start": 45
                            }
                        ],
                        "text": "Recently, graph convolutional networks (GCN) (Kipf and Welling, 2017; Marcheggiani and Titov, 2017; Bastings et al., 2017) and graph recurrent networks (GRN) (Song et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 41,
                                "start": 38
                            }
                        ],
                        "text": "We leave it to future work to compare GCN and GRN for our task."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 9,
                                "start": 6
                            }
                        ],
                        "text": "While GCNs use CNN for information exchange, GRNs take gated recurrent steps to this end."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 202,
                                "start": 172
                            }
                        ],
                        "text": "Graph convolutional networks (GCNs) and very recently graph recurrent networks (GRNs) have been used to model graph structures in NLP tasks, such as semantic role labeling (Marcheggiani and Titov, 2017), machine translation (Bastings et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 43,
                                "start": 40
                            }
                        ],
                        "text": "Recently, graph convolutional networks (GCN) (Kipf and Welling, 2017; Marcheggiani and Titov, 2017; Bastings et al., 2017) and graph recurrent networks (GRN) (Song et al., 2018; Zhang et al., 2018) have been proposed for representing graph structures for NLP tasks."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 33,
                                "start": 30
                            }
                        ],
                        "text": "Graph convolutional networks (GCNs) and very recently graph recurrent networks (GRNs) have been used to model graph structures in NLP tasks, such as semantic role labeling (Marcheggiani and Titov, 2017), machine translation (Bastings et al., 2017), text generation (Song et al., 2018), text representation (Zhang et al., 2018) and semantic parsing (Xu et al., 2018b,a)."
                    },
                    "intents": []
                }
            ],
            "corpusId": 16839291,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c3a3c163f25b9181f1fb7e71a32482a7393d2088",
            "isKey": true,
            "numCitedBy": 608,
            "numCiting": 58,
            "paperAbstract": {
                "fragments": [],
                "text": "Semantic role labeling (SRL) is the task of identifying the predicate-argument structure of a sentence. It is typically regarded as an important step in the standard NLP pipeline. As the semantic representations are closely related to syntactic ones, we exploit syntactic information in our model. We propose a version of graph convolutional networks (GCNs), a recent class of neural networks operating on graphs, suited to model syntactic dependency graphs. GCNs over syntactic dependency trees are used as sentence encoders, producing latent feature representations of words in a sentence. We observe that GCN layers are complementary to LSTM ones: when we stack both GCN and LSTM layers, we obtain a substantial improvement over an already state-of-the-art LSTM SRL model, resulting in the best reported scores on the standard benchmark (CoNLL-2009) both for Chinese and English."
            },
            "slug": "Encoding-Sentences-with-Graph-Convolutional-for-Marcheggiani-Titov",
            "title": {
                "fragments": [],
                "text": "Encoding Sentences with Graph Convolutional Networks for Semantic Role Labeling"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "A version of graph convolutional networks (GCNs), a recent class of neural networks operating on graphs, suited to model syntactic dependency graphs, is proposed, observing that GCN layers are complementary to LSTM ones."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1748796"
                        ],
                        "name": "Linfeng Song",
                        "slug": "Linfeng-Song",
                        "structuredName": {
                            "firstName": "Linfeng",
                            "lastName": "Song",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Linfeng Song"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48378565"
                        ],
                        "name": "Yue Zhang",
                        "slug": "Yue-Zhang",
                        "structuredName": {
                            "firstName": "Yue",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yue Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40296541"
                        ],
                        "name": "Zhiguo Wang",
                        "slug": "Zhiguo-Wang",
                        "structuredName": {
                            "firstName": "Zhiguo",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zhiguo Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1793218"
                        ],
                        "name": "D. Gildea",
                        "slug": "D.-Gildea",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Gildea",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Gildea"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 44,
                                "start": 25
                            }
                        ],
                        "text": ", 2017), text generation (Song et al., 2018), text representation (Zhang et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 176,
                                "start": 159
                            }
                        ],
                        "text": "Recently, graph convolutional networks (GCN) (Kipf and Welling, 2017; Marcheggiani and Titov, 2017; Bastings et al., 2017) and graph recurrent networks (GRN) (Song et al., 2018; Zhang et al., 2018) have been proposed for representing graph structures for NLP tasks."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 89,
                                "start": 71
                            }
                        ],
                        "text": "For fair comparison with DAG LSTMs, we build a graph LSTM by extending Song et al. (2018), which strictly follow the configurations of Peng et al. (2017) such as the source of features and hyper parameter settings."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 82,
                                "start": 43
                            }
                        ],
                        "text": ", 2017) and graph recurrent networks (GRN) (Song et al., 2018; Zhang et al., 2018) have been proposed for representing graph structures for NLP tasks."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 214,
                                "start": 197
                            }
                        ],
                        "text": "\u2026networks (GRNs) have been used to model graph structures in NLP tasks, such as semantic role labeling (Marcheggiani and Titov, 2017), machine translation (Bastings et al., 2017), text generation (Song et al., 2018), text representation (Zhang et al., 2018) and semantic parsing (Xu et al., 2018b,a)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 45,
                                "start": 27
                            }
                        ],
                        "text": "Following the approches of Song et al. (2018) and Zhang et al. (2018), a recurrent neural network is utilized to model the state transition process."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 177,
                                "start": 159
                            }
                        ],
                        "text": "\u2026and a sentence-level node, showing that the encoder outperforms BiLSTMs and Transformer (Vaswani et al., 2017) on classification and sequence labeling tasks; Song et al. (2018) build a GRN for encoding AMR graphs, showing that the representation is superior compared to BiLSTM on serialized AMR."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                }
            ],
            "corpusId": 25111673,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b4812702a7c1c47e2af34d8752b2103505089fc2",
            "isKey": false,
            "numCitedBy": 190,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "The problem of AMR-to-text generation is to recover a text representing the same meaning as an input AMR graph. The current state-of-the-art method uses a sequence-to-sequence model, leveraging LSTM for encoding a linearized AMR structure. Although being able to model non-local semantic information, a sequence LSTM can lose information from the AMR graph structure, and thus facing challenges with large-graphs, which result in long sequences. We introduce a neural graph-to-sequence model, using a novel LSTM structure for directly encoding graph-level semantics. On a standard benchmark, our model shows superior results to existing methods in the literature."
            },
            "slug": "A-Graph-to-Sequence-Model-for-AMR-to-Text-Song-Zhang",
            "title": {
                "fragments": [],
                "text": "A Graph-to-Sequence Model for AMR-to-Text Generation"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This work introduces a neural graph-to-sequence model, using a novel LSTM structure for directly encoding graph-level semantics, and shows superior results to existing methods in the literature."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2018
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2118912383"
                        ],
                        "name": "Qi Li",
                        "slug": "Qi-Li",
                        "structuredName": {
                            "firstName": "Qi",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Qi Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144016781"
                        ],
                        "name": "Heng Ji",
                        "slug": "Heng-Ji",
                        "structuredName": {
                            "firstName": "Heng",
                            "lastName": "Ji",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Heng Ji"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 261,
                                "start": 62
                            }
                        ],
                        "text": "While most existing work extracts relations within a sentence (Zelenko et al., 2003; Palmer et al., 2005; Zhao and Grishman, 2005; Jiang and Zhai, 2007; Plank and Moschitti, 2013; Li and Ji, 2014; Gormley et al., 2015; Miwa and Bansal, 2016; Zhang et al., 2017), the task of cross-sentence relation extraction has received increasing attention (Gerber and Chai, 2010; Yoshikawa et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 20744,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8b156bdce947783b8c7071f02557b414ab7b5276",
            "isKey": false,
            "numCitedBy": 336,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": "We present an incremental joint framework to simultaneously extract entity mentions and relations using structured perceptron with efficient beam-search. A segment-based decoder based on the idea of semi-Markov chain is adopted to the new framework as opposed to traditional token-based tagging. In addition, by virtue of the inexact search, we developed a number of new and effective global features as soft constraints to capture the interdependency among entity mentions and relations. Experiments on Automatic Content Extraction (ACE) 1 corpora demonstrate that our joint model significantly outperforms a strong pipelined baseline, which attains better performance than the best-reported end-to-end system."
            },
            "slug": "Incremental-Joint-Extraction-of-Entity-Mentions-and-Li-Ji",
            "title": {
                "fragments": [],
                "text": "Incremental Joint Extraction of Entity Mentions and Relations"
            },
            "tldr": {
                "abstractSimilarityScore": 70,
                "text": "An incremental joint framework to simultaneously extract entity mentions and relations using structured perceptron with efficient beam-search is presented, which significantly outperforms a strong pipelined baseline, which attains better performance than the best-reported end-to-end system."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2596310"
                        ],
                        "name": "Chris Quirk",
                        "slug": "Chris-Quirk",
                        "structuredName": {
                            "firstName": "Chris",
                            "lastName": "Quirk",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chris Quirk"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1759772"
                        ],
                        "name": "Hoifung Poon",
                        "slug": "Hoifung-Poon",
                        "structuredName": {
                            "firstName": "Hoifung",
                            "lastName": "Poon",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hoifung Poon"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 171,
                                "start": 130
                            }
                        ],
                        "text": ", 2009), and predicting the effectiveness of a medicine on a cancer caused by mutation of a certain gene in the biomedical domain (Quirk and Poon, 2017; Peng et al., 2017)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15359942,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0bd50cb6e58c09923ecab00ac252dc7e60eb5cc8",
            "isKey": false,
            "numCitedBy": 165,
            "numCiting": 62,
            "paperAbstract": {
                "fragments": [],
                "text": "The growing demand for structured knowledge has led to great interest in relation extraction, especially in cases with limited supervision. However, existing distance supervision approaches only extract relations expressed in single sentences. In general, cross-sentence relation extraction is under-explored, even in the supervised-learning setting. In this paper, we propose the first approach for applying distant supervision to cross-sentence relation extraction. At the core of our approach is a graph representation that can incorporate both standard dependencies and discourse relations, thus providing a unifying way to model relations within and across sentences. We extract features from multiple paths in this graph, increasing accuracy and robustness when confronted with linguistic variation and analysis error. Experiments on an important extraction task for precision medicine show that our approach can learn an accurate cross-sentence extractor, using only a small existing knowledge base and unlabeled text from biomedical research articles. Compared to the existing distant supervision paradigm, our approach extracted twice as many relations at similar precision, thus demonstrating the prevalence of cross-sentence relations and the promise of our approach."
            },
            "slug": "Distant-Supervision-for-Relation-Extraction-beyond-Quirk-Poon",
            "title": {
                "fragments": [],
                "text": "Distant Supervision for Relation Extraction beyond the Sentence Boundary"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "This paper proposes the first approach for applying distant supervision to cross-sentence relation extraction with a graph representation that can incorporate both standard dependencies and discourse relations, thus providing a unifying way to model relations within and across sentences."
            },
            "venue": {
                "fragments": [],
                "text": "EACL"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "151485141"
                        ],
                        "name": "Kun Xu",
                        "slug": "Kun-Xu",
                        "structuredName": {
                            "firstName": "Kun",
                            "lastName": "Xu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kun Xu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3008832"
                        ],
                        "name": "Lingfei Wu",
                        "slug": "Lingfei-Wu",
                        "structuredName": {
                            "firstName": "Lingfei",
                            "lastName": "Wu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lingfei Wu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40296541"
                        ],
                        "name": "Zhiguo Wang",
                        "slug": "Zhiguo-Wang",
                        "structuredName": {
                            "firstName": "Zhiguo",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zhiguo Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2482533"
                        ],
                        "name": "Mo Yu",
                        "slug": "Mo-Yu",
                        "structuredName": {
                            "firstName": "Mo",
                            "lastName": "Yu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mo Yu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47818709"
                        ],
                        "name": "Liwei Chen",
                        "slug": "Liwei-Chen",
                        "structuredName": {
                            "firstName": "Liwei",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Liwei Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1757683"
                        ],
                        "name": "V. Sheinin",
                        "slug": "V.-Sheinin",
                        "structuredName": {
                            "firstName": "Vadim",
                            "lastName": "Sheinin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Sheinin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 296,
                                "start": 280
                            }
                        ],
                        "text": "\u2026networks (GRNs) have been used to model graph structures in NLP tasks, such as semantic role labeling (Marcheggiani and Titov, 2017), machine translation (Bastings et al., 2017), text generation (Song et al., 2018), text representation (Zhang et al., 2018) and semantic parsing (Xu et al., 2018b,a)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 52074926,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "305f8c705c034b6179fc4db19eb6163265432baa",
            "isKey": false,
            "numCitedBy": 54,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "Existing neural semantic parsers mainly utilize a sequence encoder, i.e., a sequential LSTM, to extract word order features while neglecting other valuable syntactic information such as dependency or constituent trees. In this paper, we first propose to use the syntactic graph to represent three types of syntactic information, i.e., word order, dependency and constituency features; then employ a graph-to-sequence model to encode the syntactic graph and decode a logical form. Experimental results on benchmark datasets show that our model is comparable to the state-of-the-art on Jobs640, ATIS, and Geo880. Experimental results on adversarial examples demonstrate the robustness of the model is also improved by encoding more syntactic information."
            },
            "slug": "Exploiting-Rich-Syntactic-Information-for-Semantic-Xu-Wu",
            "title": {
                "fragments": [],
                "text": "Exploiting Rich Syntactic Information for Semantic Parsing with Graph-to-Sequence Model"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This paper first proposes to use the syntactic graph to represent three types of syntactic information, i.e., word order, dependency and constituency features; then employs a graph-to-sequence model to encode the Syntactic graph and decode a logical form."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 2018
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48378565"
                        ],
                        "name": "Yue Zhang",
                        "slug": "Yue-Zhang",
                        "structuredName": {
                            "firstName": "Yue",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yue Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50384171"
                        ],
                        "name": "Qi Liu",
                        "slug": "Qi-Liu",
                        "structuredName": {
                            "firstName": "Qi",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Qi Liu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1748796"
                        ],
                        "name": "Linfeng Song",
                        "slug": "Linfeng-Song",
                        "structuredName": {
                            "firstName": "Linfeng",
                            "lastName": "Song",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Linfeng Song"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 49,
                                "start": 46
                            }
                        ],
                        "text": "We leave it to future work to compare GCN and GRN for our task."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 48,
                                "start": 45
                            }
                        ],
                        "text": "While GCNs use CNN for information exchange, GRNs take gated recurrent steps to this end."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 90,
                                "start": 87
                            }
                        ],
                        "text": "Under the same recurrent framework, we show that modeling the original graphs with one GRN model is more useful than two DAG LSTMs for our relation extraction task."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 45,
                                "start": 42
                            }
                        ],
                        "text": "To our knowledge, we are the first to use GRN for representing dependency and discourse structures."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 34,
                                "start": 15
                            }
                        ],
                        "text": "In particular, Zhang et al. (2018) use GRN to represent raw sentences by building a graph structure of neighboring words and a sentence-level node, showing that the encoder outperforms BiLSTMs and Transformer (Vaswani et al., 2017) on classification and sequence labeling tasks; Song et al. (2018)\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 42,
                                "start": 39
                            }
                        ],
                        "text": "In particular, Zhang et al. (2018) use GRN to represent raw sentences by building a graph structure of neighboring words and a sentence-level node, showing that the encoder outperforms BiLSTMs and Transformer (Vaswani et al., 2017) on classification and sequence labeling tasks; Song et al. (2018) build a GRN for encoding AMR graphs, showing that the representation is superior compared to BiLSTM on serialized AMR."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 196,
                                "start": 178
                            }
                        ],
                        "text": "Recently, graph convolutional networks (GCN) (Kipf and Welling, 2017; Marcheggiani and Titov, 2017; Bastings et al., 2017) and graph recurrent networks (GRN) (Song et al., 2018; Zhang et al., 2018) have been proposed for representing graph structures for NLP tasks."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 13,
                                "start": 10
                            }
                        ],
                        "text": "We choose GRN as our main method because it gives a more fair comparison with DAG LSTM."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 63,
                                "start": 60
                            }
                        ],
                        "text": "Our work is in line with their work in the investigation of GRN on NLP."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 82,
                                "start": 43
                            }
                        ],
                        "text": ", 2017) and graph recurrent networks (GRN) (Song et al., 2018; Zhang et al., 2018) have been proposed for representing graph structures for NLP tasks."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 49,
                                "start": 29
                            }
                        ],
                        "text": ", 2018), text representation (Zhang et al., 2018) and semantic parsing (Xu et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 256,
                                "start": 238
                            }
                        ],
                        "text": "\u2026networks (GRNs) have been used to model graph structures in NLP tasks, such as semantic role labeling (Marcheggiani and Titov, 2017), machine translation (Bastings et al., 2017), text generation (Song et al., 2018), text representation (Zhang et al., 2018) and semantic parsing (Xu et al., 2018b,a)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 69,
                                "start": 50
                            }
                        ],
                        "text": "Following the approches of Song et al. (2018) and Zhang et al. (2018), a recurrent neural network is utilized to model the state transition process."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 83,
                                "start": 80
                            }
                        ],
                        "text": "Graph convolutional networks (GCNs) and very recently graph recurrent networks (GRNs) have been used to model graph structures in NLP tasks, such as semantic role labeling (Marcheggiani and Titov, 2017), machine translation (Bastings et al., 2017), text generation (Song et al., 2018), text representation (Zhang et al., 2018) and semantic parsing (Xu et al., 2018b,a)."
                    },
                    "intents": []
                }
            ],
            "corpusId": 19175261,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3e79a574d776c46bbe6d34f41b1e83b5d0f698f2",
            "isKey": false,
            "numCitedBy": 150,
            "numCiting": 57,
            "paperAbstract": {
                "fragments": [],
                "text": "Bi-directional LSTMs are a powerful tool for text representation. On the other hand, they have been shown to suffer various limitations due to their sequential nature. We investigate an alternative LSTM structure for encoding text, which consists of a parallel state for each word. Recurrent steps are used to perform local and global information exchange between words simultaneously, rather than incremental reading of a sequence of words. Results on various classification and sequence labelling benchmarks show that the proposed model has strong representation power, giving highly competitive performances compared to stacked BiLSTM models with similar parameter numbers."
            },
            "slug": "Sentence-State-LSTM-for-Text-Representation-Zhang-Liu",
            "title": {
                "fragments": [],
                "text": "Sentence-State LSTM for Text Representation"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This work investigates an alternative LSTM structure for encoding text, which consists of a parallel state for each word, and shows that the proposed model has strong representation power, giving highly competitive performances compared to stacked BiLSTM models with similar parameter numbers."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2018
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1762110"
                        ],
                        "name": "Matthew R. Gormley",
                        "slug": "Matthew-R.-Gormley",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Gormley",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Matthew R. Gormley"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2482533"
                        ],
                        "name": "Mo Yu",
                        "slug": "Mo-Yu",
                        "structuredName": {
                            "firstName": "Mo",
                            "lastName": "Yu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mo Yu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1782853"
                        ],
                        "name": "Mark Dredze",
                        "slug": "Mark-Dredze",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Dredze",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mark Dredze"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 167,
                                "start": 147
                            }
                        ],
                        "text": "\u2026a sentence (Zelenko et al., 2003; Palmer et al., 2005; Zhao and Grishman, 2005; Jiang and Zhai, 2007; Plank and Moschitti, 2013; Li and Ji, 2014; Gormley et al., 2015; Miwa and Bansal, 2016; Zhang et al., 2017), the task of cross-sentence relation extraction has received increasing attention\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 261,
                                "start": 62
                            }
                        ],
                        "text": "While most existing work extracts relations within a sentence (Zelenko et al., 2003; Palmer et al., 2005; Zhao and Grishman, 2005; Jiang and Zhai, 2007; Plank and Moschitti, 2013; Li and Ji, 2014; Gormley et al., 2015; Miwa and Bansal, 2016; Zhang et al., 2017), the task of cross-sentence relation extraction has received increasing attention (Gerber and Chai, 2010; Yoshikawa et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 247735,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "30f4599c16223237d5622e2150b59211e641032f",
            "isKey": false,
            "numCitedBy": 128,
            "numCiting": 49,
            "paperAbstract": {
                "fragments": [],
                "text": "Compositional embedding models build a representation (or embedding) for a linguistic structure based on its component word embeddings. We propose a Feature-rich Compositional Embedding Model (FCM) for relation extraction that is expressive, generalizes to new domains, and is easy-to-implement. The key idea is to combine both (unlexicalized) hand-crafted features with learned word embeddings. The model is able to directly tackle the difficulties met by traditional compositional embeddings models, such as handling arbitrary types of sentence annotations and utilizing global information for composition. We test the proposed model on two relation extraction tasks, and demonstrate that our model outperforms both previous compositional models and traditional feature rich models on the ACE 2005 relation extraction task, and the SemEval 2010 relation classification task. The combination of our model and a log-linear classifier with hand-crafted features gives state-of-the-art results."
            },
            "slug": "Improved-Relation-Extraction-with-Feature-Rich-Gormley-Yu",
            "title": {
                "fragments": [],
                "text": "Improved Relation Extraction with Feature-Rich Compositional Embedding Models"
            },
            "tldr": {
                "abstractSimilarityScore": 52,
                "text": "A Feature-rich Compositional Embedding Model (FCM) for relation extraction that is expressive, generalizes to new domains, and is easy-to-implement that outperforms both previous compositional models and traditional feature rich models."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2041815"
                        ],
                        "name": "Kumutha Swampillai",
                        "slug": "Kumutha-Swampillai",
                        "structuredName": {
                            "firstName": "Kumutha",
                            "lastName": "Swampillai",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kumutha Swampillai"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144795097"
                        ],
                        "name": "Mark Stevenson",
                        "slug": "Mark-Stevenson",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Stevenson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mark Stevenson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 136,
                                "start": 85
                            }
                        ],
                        "text": ", 2011), or the assumption that the whole document refers to a single coherent event (Wick et al., 2006; Swampillai and Stevenson, 2011)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14846155,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "efbb63f3cb13cf7b6fc6ec5e6c4129be82c919cc",
            "isKey": false,
            "numCitedBy": 45,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "Previous work on relation extraction has focussed on identifying relationships between entities that occur in the same sentence (intra-sentential relations) rather than between entities in different sentences (inter-sentential relations) despite previous research having shown that intersentential relations commonly occur in information extraction corpora. This paper describes a SVM-based approach to relation extraction that is applied to both types. Adapted features and techniques for counter-acting bias in SVM models are used to deal with specific issues that arise in the inter-sentential case. It was found that the structured features used for intrasentential relation extraction can be easily adapted for the inter-sentential case and provides comparable performance."
            },
            "slug": "Extracting-Relations-Within-and-Across-Sentences-Swampillai-Stevenson",
            "title": {
                "fragments": [],
                "text": "Extracting Relations Within and Across Sentences"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "It was found that the structured features used for intrasentential relation extraction can be easily adapted for the inter-sentential case and provides comparable performance."
            },
            "venue": {
                "fragments": [],
                "text": "RANLP"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8421815"
                        ],
                        "name": "Kai Sheng Tai",
                        "slug": "Kai-Sheng-Tai",
                        "structuredName": {
                            "firstName": "Kai",
                            "lastName": "Tai",
                            "middleNames": [
                                "Sheng"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kai Sheng Tai"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2166511"
                        ],
                        "name": "R. Socher",
                        "slug": "R.-Socher",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Socher",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Socher"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144783904"
                        ],
                        "name": "Christopher D. Manning",
                        "slug": "Christopher-D.-Manning",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Manning",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christopher D. Manning"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 92,
                                "start": 76
                            }
                        ],
                        "text": "Then, two separate gated recurrent neural networks, which extend tree LSTM (Tai et al., 2015), were adopted for each single-directional DAG, respectively."
                    },
                    "intents": []
                }
            ],
            "corpusId": 3033526,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "32de44f01a96d4473d21099d15e25bc2b9f08e2f",
            "isKey": false,
            "numCitedBy": 2501,
            "numCiting": 43,
            "paperAbstract": {
                "fragments": [],
                "text": "Because of their superior ability to preserve sequence information over time, Long Short-Term Memory (LSTM) networks, a type of recurrent neural network with a more complex computational unit, have obtained strong results on a variety of sequence modeling tasks. The only underlying LSTM structure that has been explored so far is a linear chain. However, natural language exhibits syntactic properties that would naturally combine words to phrases. We introduce the Tree-LSTM, a generalization of LSTMs to tree-structured network topologies. Tree-LSTMs outperform all existing systems and strong LSTM baselines on two tasks: predicting the semantic relatedness of two sentences (SemEval 2014, Task 1) and sentiment classification (Stanford Sentiment Treebank)."
            },
            "slug": "Improved-Semantic-Representations-From-Long-Memory-Tai-Socher",
            "title": {
                "fragments": [],
                "text": "Improved Semantic Representations From Tree-Structured Long Short-Term Memory Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The Tree-LSTM is introduced, a generalization of LSTMs to tree-structured network topologies that outperform all existing systems and strong LSTM baselines on two tasks: predicting the semantic relatedness of two sentences and sentiment classification."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40250403"
                        ],
                        "name": "Xiaodan Liang",
                        "slug": "Xiaodan-Liang",
                        "structuredName": {
                            "firstName": "Xiaodan",
                            "lastName": "Liang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xiaodan Liang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1720987"
                        ],
                        "name": "Xiaohui Shen",
                        "slug": "Xiaohui-Shen",
                        "structuredName": {
                            "firstName": "Xiaohui",
                            "lastName": "Shen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xiaohui Shen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "33221685"
                        ],
                        "name": "Jiashi Feng",
                        "slug": "Jiashi-Feng",
                        "structuredName": {
                            "firstName": "Jiashi",
                            "lastName": "Feng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jiashi Feng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1737218"
                        ],
                        "name": "Liang Lin",
                        "slug": "Liang-Lin",
                        "structuredName": {
                            "firstName": "Liang",
                            "lastName": "Lin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Liang Lin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143653681"
                        ],
                        "name": "Shuicheng Yan",
                        "slug": "Shuicheng-Yan",
                        "structuredName": {
                            "firstName": "Shuicheng",
                            "lastName": "Yan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shuicheng Yan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 33,
                                "start": 14
                            }
                        ],
                        "text": "Graph encoder Liang et al. (2016) build a graph LSTM model for semantic object parsing, which aims to segment objects within an image into more fine-grained, semantically meaningful parts."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7886345,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3cea26512e9fd8bcb4081af44286d395004a5433",
            "isKey": false,
            "numCitedBy": 280,
            "numCiting": 58,
            "paperAbstract": {
                "fragments": [],
                "text": "By taking the semantic object parsing task as an exemplar application scenario, we propose the Graph Long Short-Term Memory (Graph LSTM) network, which is the generalization of LSTM from sequential data or multi-dimensional data to general graph-structured data. Particularly, instead of evenly and fixedly dividing an image to pixels or patches in existing multi-dimensional LSTM structures (e.g., Row, Grid and Diagonal LSTMs), we take each arbitrary-shaped superpixel as a semantically consistent node, and adaptively construct an undirected graph for each image, where the spatial relations of the superpixels are naturally used as edges. Constructed on such an adaptive graph topology, the Graph LSTM is more naturally aligned with the visual patterns in the image (e.g., object boundaries or appearance similarities) and provides a more economical information propagation route. Furthermore, for each optimization step over Graph LSTM, we propose to use a confidence-driven scheme to update the hidden and memory states of nodes progressively till all nodes are updated. In addition, for each node, the forgets gates are adaptively learned to capture different degrees of semantic correlation with neighboring nodes. Comprehensive evaluations on four diverse semantic object parsing datasets well demonstrate the significant superiority of our Graph LSTM over other state-of-the-art solutions."
            },
            "slug": "Semantic-Object-Parsing-with-Graph-LSTM-Liang-Shen",
            "title": {
                "fragments": [],
                "text": "Semantic Object Parsing with Graph LSTM"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "The Graph Long Short-Term Memory network is proposed, which is the generalization of LSTM from sequential data or multi-dimensional data to general graph-structured data."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2022124"
                        ],
                        "name": "Barbara Plank",
                        "slug": "Barbara-Plank",
                        "structuredName": {
                            "firstName": "Barbara",
                            "lastName": "Plank",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Barbara Plank"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1719404"
                        ],
                        "name": "Alessandro Moschitti",
                        "slug": "Alessandro-Moschitti",
                        "structuredName": {
                            "firstName": "Alessandro",
                            "lastName": "Moschitti",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alessandro Moschitti"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 261,
                                "start": 62
                            }
                        ],
                        "text": "While most existing work extracts relations within a sentence (Zelenko et al., 2003; Palmer et al., 2005; Zhao and Grishman, 2005; Jiang and Zhai, 2007; Plank and Moschitti, 2013; Li and Ji, 2014; Gormley et al., 2015; Miwa and Bansal, 2016; Zhang et al., 2017), the task of cross-sentence relation extraction has received increasing attention (Gerber and Chai, 2010; Yoshikawa et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 3011134,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9666727600e633617984cbf431ea1495277bd970",
            "isKey": false,
            "numCitedBy": 116,
            "numCiting": 45,
            "paperAbstract": {
                "fragments": [],
                "text": "Relation Extraction (RE) is the task of extracting semantic relationships between entities in text. Recent studies on relation extraction are mostly supervised. The clear drawback of supervised methods is the need of training data: labeled data is expensive to obtain, and there is often a mismatch between the training data and the data the system will be applied to. This is the problem of domain adaptation. In this paper, we propose to combine (i) term generalization approaches such as word clustering and latent semantic analysis (LSA) and (ii) structured kernels to improve the adaptability of relation extractors to new text genres/domains. The empirical evaluation on ACE 2005 domains shows that a suitable combination of syntax and lexical generalization is very promising for domain adaptation."
            },
            "slug": "Embedding-Semantic-Similarity-in-Tree-Kernels-for-Plank-Moschitti",
            "title": {
                "fragments": [],
                "text": "Embedding Semantic Similarity in Tree Kernels for Domain Adaptation of Relation Extraction"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This paper proposes to combine term generalization approaches such as word clustering and latent semantic analysis (LSA) and structured kernels to improve the adaptability of relation extractors to new text genres/domains."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2678094"
                        ],
                        "name": "Meishan Zhang",
                        "slug": "Meishan-Zhang",
                        "structuredName": {
                            "firstName": "Meishan",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Meishan Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48378565"
                        ],
                        "name": "Yue Zhang",
                        "slug": "Yue-Zhang",
                        "structuredName": {
                            "firstName": "Yue",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yue Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2059275"
                        ],
                        "name": "G. Fu",
                        "slug": "G.-Fu",
                        "structuredName": {
                            "firstName": "Guohong",
                            "lastName": "Fu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Fu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 261,
                                "start": 62
                            }
                        ],
                        "text": "While most existing work extracts relations within a sentence (Zelenko et al., 2003; Palmer et al., 2005; Zhao and Grishman, 2005; Jiang and Zhai, 2007; Plank and Moschitti, 2013; Li and Ji, 2014; Gormley et al., 2015; Miwa and Bansal, 2016; Zhang et al., 2017), the task of cross-sentence relation extraction has received increasing attention (Gerber and Chai, 2010; Yoshikawa et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 166,
                                "start": 148
                            }
                        ],
                        "text": "\u2026al., 2005; Zhao and Grishman, 2005; Jiang and Zhai, 2007; Plank and Moschitti, 2013; Li and Ji, 2014; Gormley et al., 2015; Miwa and Bansal, 2016; Zhang et al., 2017), the task of cross-sentence relation extraction has received increasing attention (Gerber and Chai, 2010; Yoshikawa et al., 2011)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2204967,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ee13e1a3c1d5f5f319b0bf62f04974165f7b0a37",
            "isKey": false,
            "numCitedBy": 99,
            "numCiting": 66,
            "paperAbstract": {
                "fragments": [],
                "text": "Neural networks have shown promising results for relation extraction. State-of-the-art models cast the task as an end-to-end problem, solved incrementally using a local classifier. Yet previous work using statistical models have demonstrated that global optimization can achieve better performances compared to local classification. We build a globally optimized neural model for end-to-end relation extraction, proposing novel LSTM features in order to better learn context representations. In addition, we present a novel method to integrate syntactic information to facilitate global learning, yet requiring little background on syntactic grammars thus being easy to extend. Experimental results show that our proposed model is highly effective, achieving the best performances on two standard benchmarks."
            },
            "slug": "End-to-End-Neural-Relation-Extraction-with-Global-Zhang-Zhang",
            "title": {
                "fragments": [],
                "text": "End-to-End Neural Relation Extraction with Global Optimization"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This work builds a globally optimized neural model for end-to-end relation extraction, proposing novel LSTM features in order to better learn context representations, and presents a novel method to integrate syntactic information to facilitate global learning."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2060333"
                        ],
                        "name": "K. Yoshikawa",
                        "slug": "K.-Yoshikawa",
                        "structuredName": {
                            "firstName": "Katsumasa",
                            "lastName": "Yoshikawa",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Yoshikawa"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145941665"
                        ],
                        "name": "S. Riedel",
                        "slug": "S.-Riedel",
                        "structuredName": {
                            "firstName": "Sebastian",
                            "lastName": "Riedel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Riedel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8351786"
                        ],
                        "name": "T. Hirao",
                        "slug": "T.-Hirao",
                        "structuredName": {
                            "firstName": "Tsutomu",
                            "lastName": "Hirao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Hirao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1749558"
                        ],
                        "name": "Masayuki Asahara",
                        "slug": "Masayuki-Asahara",
                        "structuredName": {
                            "firstName": "Masayuki",
                            "lastName": "Asahara",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Masayuki Asahara"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1681502"
                        ],
                        "name": "Yuji Matsumoto",
                        "slug": "Yuji-Matsumoto",
                        "structuredName": {
                            "firstName": "Yuji",
                            "lastName": "Matsumoto",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yuji Matsumoto"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 148,
                                "start": 126
                            }
                        ],
                        "text": "Previous work on cross-sentence relation extraction relies on either explicit co-reference annotation (Gerber and Chai, 2010; Yoshikawa et al., 2011), or the assumption that the whole document refers to a single coherent event (Wick et al., 2006; Swampillai and Stevenson, 2011)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 296,
                                "start": 274
                            }
                        ],
                        "text": "\u2026al., 2005; Zhao and Grishman, 2005; Jiang and Zhai, 2007; Plank and Moschitti, 2013; Li and Ji, 2014; Gormley et al., 2015; Miwa and Bansal, 2016; Zhang et al., 2017), the task of cross-sentence relation extraction has received increasing attention (Gerber and Chai, 2010; Yoshikawa et al., 2011)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 149,
                                "start": 102
                            }
                        ],
                        "text": "Previous work on cross-sentence relation extraction relies on either explicit co-reference annotation (Gerber and Chai, 2010; Yoshikawa et al., 2011), or the assumption that the whole document refers to a single coherent event (Wick et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 137,
                                "start": 90
                            }
                        ],
                        "text": ", 2017), the task of cross-sentence relation extraction has received increasing attention (Gerber and Chai, 2010; Yoshikawa et al., 2011)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 11992031,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "da67c23d8e7d466f0b50e5a69672557b4b3255f8",
            "isKey": true,
            "numCitedBy": 44,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a new approach to exploit coreference information for extracting event-argument (E-A) relations from biomedical documents. This approach has two advantages: (1) it can extract a large number of valuable E-A relations based on the concept of salience in discourse; (2) it enables us to identify E-A relations over sentence boundaries (cross-links) using transitivity of coreference relations. We propose two coreference-based models: a pipeline based on Support Vector Machine (SVM) classifiers, and a joint Markov Logic Network (MLN). We show the effectiveness of these models on a biomedical event corpus. Both models outperform the systems that do not use coreference information. When the two proposed models are compared to each other, joint MLN outperforms pipeline SVM with gold coreference information."
            },
            "slug": "Coreference-based-event-argument-relation-on-text-Yoshikawa-Riedel",
            "title": {
                "fragments": [],
                "text": "Coreference based event-argument relation extraction on biomedical text"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "Two coreference-based models are proposed: a pipeline based on Support Vector Machine (SVM) classifiers, and a joint Markov Logic Network (MLN) that outperform the systems that do not use coreference information."
            },
            "venue": {
                "fragments": [],
                "text": "Semantic Mining in Biomedicine"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2987641"
                        ],
                        "name": "Michael L. Wick",
                        "slug": "Michael-L.-Wick",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Wick",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael L. Wick"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1741453"
                        ],
                        "name": "A. Culotta",
                        "slug": "A.-Culotta",
                        "structuredName": {
                            "firstName": "Aron",
                            "lastName": "Culotta",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Culotta"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143753639"
                        ],
                        "name": "A. McCallum",
                        "slug": "A.-McCallum",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "McCallum",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. McCallum"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 136,
                                "start": 85
                            }
                        ],
                        "text": ", 2011), or the assumption that the whole document refers to a single coherent event (Wick et al., 2006; Swampillai and Stevenson, 2011)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 245,
                                "start": 228
                            }
                        ],
                        "text": "Previous work on cross-sentence relation extraction relies on either explicit co-reference annotation (Gerber and Chai, 2010; Yoshikawa et al., 2011), or the assumption that the whole document refers to a single coherent event (Wick et al., 2006; Swampillai and Stevenson, 2011)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 8692445,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9156d2566881e8b9a933ea2343ba2e3b417ae0b1",
            "isKey": false,
            "numCitedBy": 39,
            "numCiting": 57,
            "paperAbstract": {
                "fragments": [],
                "text": "Named-entity recognition systems extract entities such as people, organizations, and locations from unstructured text. Rather than extract these mentions in isolation, this paper presents a record extraction system that assembles mentions into records (i.e. database tuples). We construct a probabilistic model of the compatibility between field values, then employ graph partitioning algorithms to cluster fields into cohesive records. We also investigate compatibility functions over sets of fields, rather than simply pairs of fields, to examine how higher representational power can impact performance. We apply our techniques to the task of extracting contact records from faculty and student homepages, demonstrating a 53% error reduction over baseline approaches."
            },
            "slug": "Learning-Field-Compatibilities-to-Extract-Database-Wick-Culotta",
            "title": {
                "fragments": [],
                "text": "Learning Field Compatibilities to Extract Database Records from Unstructured Text"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "A record extraction system that assembles mentions into records (i.e. database tuples) is presented, and a probabilistic model of the compatibility between field values is constructed, then graph partitioning algorithms are employed to cluster fields into cohesive records."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3000862"
                        ],
                        "name": "Jasmijn Bastings",
                        "slug": "Jasmijn-Bastings",
                        "structuredName": {
                            "firstName": "Jasmijn",
                            "lastName": "Bastings",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jasmijn Bastings"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144889265"
                        ],
                        "name": "Ivan Titov",
                        "slug": "Ivan-Titov",
                        "structuredName": {
                            "firstName": "Ivan",
                            "lastName": "Titov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ivan Titov"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2782694"
                        ],
                        "name": "Wilker Aziz",
                        "slug": "Wilker-Aziz",
                        "structuredName": {
                            "firstName": "Wilker",
                            "lastName": "Aziz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wilker Aziz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2022957"
                        ],
                        "name": "Diego Marcheggiani",
                        "slug": "Diego-Marcheggiani",
                        "structuredName": {
                            "firstName": "Diego",
                            "lastName": "Marcheggiani",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Diego Marcheggiani"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3540477"
                        ],
                        "name": "K. Sima'an",
                        "slug": "K.-Sima'an",
                        "structuredName": {
                            "firstName": "K.",
                            "lastName": "Sima'an",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Sima'an"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 122,
                                "start": 45
                            }
                        ],
                        "text": "Recently, graph convolutional networks (GCN) (Kipf and Welling, 2017; Marcheggiani and Titov, 2017; Bastings et al., 2017) and graph recurrent networks (GRN) (Song et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 41,
                                "start": 38
                            }
                        ],
                        "text": "We leave it to future work to compare GCN and GRN for our task."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 9,
                                "start": 6
                            }
                        ],
                        "text": "While GCNs use CNN for information exchange, GRNs take gated recurrent steps to this end."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 247,
                                "start": 224
                            }
                        ],
                        "text": "Graph convolutional networks (GCNs) and very recently graph recurrent networks (GRNs) have been used to model graph structures in NLP tasks, such as semantic role labeling (Marcheggiani and Titov, 2017), machine translation (Bastings et al., 2017), text generation (Song et al."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 121,
                                "start": 100
                            }
                        ],
                        "text": "Recently, graph convolutional networks (GCN) (Kipf and Welling, 2017; Marcheggiani and Titov, 2017; Bastings et al., 2017) and graph recurrent networks (GRN) (Song et al., 2018; Zhang et al., 2018) have been proposed for representing graph structures for NLP tasks."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 177,
                                "start": 156
                            }
                        ],
                        "text": "\u2026networks (GRNs) have been used to model graph structures in NLP tasks, such as semantic role labeling (Marcheggiani and Titov, 2017), machine translation (Bastings et al., 2017), text generation (Song et al., 2018), text representation (Zhang et al., 2018) and semantic parsing (Xu et al., 2018b,a)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 33,
                                "start": 30
                            }
                        ],
                        "text": "Graph convolutional networks (GCNs) and very recently graph recurrent networks (GRNs) have been used to model graph structures in NLP tasks, such as semantic role labeling (Marcheggiani and Titov, 2017), machine translation (Bastings et al., 2017), text generation (Song et al., 2018), text representation (Zhang et al., 2018) and semantic parsing (Xu et al., 2018b,a)."
                    },
                    "intents": []
                }
            ],
            "corpusId": 6206777,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2784000e1a3554374662f4d18cb5ad52f59c8de6",
            "isKey": true,
            "numCitedBy": 368,
            "numCiting": 58,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a simple and effective approach to incorporating syntactic structure into neural attention-based encoder-decoder models for machine translation. We rely on graph-convolutional networks (GCNs), a recent class of neural networks developed for modeling graph-structured data. Our GCNs use predicted syntactic dependency trees of source sentences to produce representations of words (i.e. hidden states of the encoder) that are sensitive to their syntactic neighborhoods. GCNs take word representations as input and produce word representations as output, so they can easily be incorporated as layers into standard encoders (e.g., on top of bidirectional RNNs or convolutional neural networks). We evaluate their effectiveness with English-German and English-Czech translation experiments for different types of encoders and observe substantial improvements over their syntax-agnostic versions in all the considered setups."
            },
            "slug": "Graph-Convolutional-Encoders-for-Syntax-aware-Bastings-Titov",
            "title": {
                "fragments": [],
                "text": "Graph Convolutional Encoders for Syntax-aware Neural Machine Translation"
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39776771"
                        ],
                        "name": "Shubin Zhao",
                        "slug": "Shubin-Zhao",
                        "structuredName": {
                            "firstName": "Shubin",
                            "lastName": "Zhao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shubin Zhao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1788050"
                        ],
                        "name": "R. Grishman",
                        "slug": "R.-Grishman",
                        "structuredName": {
                            "firstName": "Ralph",
                            "lastName": "Grishman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Grishman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 261,
                                "start": 62
                            }
                        ],
                        "text": "While most existing work extracts relations within a sentence (Zelenko et al., 2003; Palmer et al., 2005; Zhao and Grishman, 2005; Jiang and Zhai, 2007; Plank and Moschitti, 2013; Li and Ji, 2014; Gormley et al., 2015; Miwa and Bansal, 2016; Zhang et al., 2017), the task of cross-sentence relation extraction has received increasing attention (Gerber and Chai, 2010; Yoshikawa et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5273348,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6f8f3c79d38ffb64f54adfdcfe2b43dd5b59692a",
            "isKey": false,
            "numCitedBy": 350,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "Entity relation detection is a form of information extraction that finds predefined relations between pairs of entities in text. This paper describes a relation detection approach that combines clues from different levels of syntactic processing using kernel methods. Information from three different levels of processing is considered: tokenization, sentence parsing and deep dependency analysis. Each source of information is represented by kernel functions. Then composite kernels are developed to integrate and extend individual kernels so that processing errors occurring at one level can be overcome by information from other levels. We present an evaluation of these methods on the 2004 ACE relation detection task, using Support Vector Machines, and show that each level of syntactic processing contributes useful information for this task. When evaluated on the official test data, our approach produced very competitive ACE value scores. We also compare the SVM with KNN on different kernels."
            },
            "slug": "Extracting-Relations-with-Integrated-Information-Zhao-Grishman",
            "title": {
                "fragments": [],
                "text": "Extracting Relations with Integrated Information Using Kernel Methods"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This paper presents an evaluation of these methods on the 2004 ACE relation detection task, using Support Vector Machines, and shows that each level of syntactic processing contributes useful information for this task."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "151485141"
                        ],
                        "name": "Kun Xu",
                        "slug": "Kun-Xu",
                        "structuredName": {
                            "firstName": "Kun",
                            "lastName": "Xu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kun Xu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3008832"
                        ],
                        "name": "Lingfei Wu",
                        "slug": "Lingfei-Wu",
                        "structuredName": {
                            "firstName": "Lingfei",
                            "lastName": "Wu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lingfei Wu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40296541"
                        ],
                        "name": "Zhiguo Wang",
                        "slug": "Zhiguo-Wang",
                        "structuredName": {
                            "firstName": "Zhiguo",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zhiguo Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1717629"
                        ],
                        "name": "Yansong Feng",
                        "slug": "Yansong-Feng",
                        "structuredName": {
                            "firstName": "Yansong",
                            "lastName": "Feng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yansong Feng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1757683"
                        ],
                        "name": "V. Sheinin",
                        "slug": "V.-Sheinin",
                        "structuredName": {
                            "firstName": "Vadim",
                            "lastName": "Sheinin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Sheinin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 296,
                                "start": 280
                            }
                        ],
                        "text": "\u2026networks (GRNs) have been used to model graph structures in NLP tasks, such as semantic role labeling (Marcheggiani and Titov, 2017), machine translation (Bastings et al., 2017), text generation (Song et al., 2018), text representation (Zhang et al., 2018) and semantic parsing (Xu et al., 2018b,a)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 4590511,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "94eb48c1878efbe2ccff121bd600dd0fd8a75650",
            "isKey": false,
            "numCitedBy": 115,
            "numCiting": 69,
            "paperAbstract": {
                "fragments": [],
                "text": "The celebrated Sequence to Sequence learning (Seq2Seq) technique and its numerous variants achieve excellent performance on many tasks. However, many machine learning tasks have inputs naturally represented as graphs; existing Seq2Seq models face a significant challenge in achieving accurate conversion from graph form to the appropriate sequence. To address this challenge, we introduce a novel general end-to-end graph-to-sequence neural encoder-decoder model that maps an input graph to a sequence of vectors and uses an attention-based LSTM method to decode the target sequence from these vectors. Our method first generates the node and graph embeddings using an improved graph-based neural network with a novel aggregation strategy to incorporate edge direction information in the node embeddings. We further introduce an attention mechanism that aligns node embeddings and the decoding sequence to better cope with large graphs. Experimental results on bAbI, Shortest Path, and Natural Language Generation tasks demonstrate that our model achieves state-of-the-art performance and significantly outperforms existing graph neural networks, Seq2Seq, and Tree2Seq models; using the proposed bi-directional node embedding aggregation strategy, the model can converge rapidly to the optimal performance."
            },
            "slug": "Graph2Seq:-Graph-to-Sequence-Learning-with-Neural-Xu-Wu",
            "title": {
                "fragments": [],
                "text": "Graph2Seq: Graph to Sequence Learning with Attention-based Neural Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This work introduces a novel general end-to-end graph- to-sequence neural encoder-decoder model that maps an input graph to a sequence of vectors and uses an attention-based LSTM method to decode the target sequence from these vectors."
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 2018
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2118239775"
                        ],
                        "name": "Jing Jiang",
                        "slug": "Jing-Jiang",
                        "structuredName": {
                            "firstName": "Jing",
                            "lastName": "Jiang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jing Jiang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1736467"
                        ],
                        "name": "ChengXiang Zhai",
                        "slug": "ChengXiang-Zhai",
                        "structuredName": {
                            "firstName": "ChengXiang",
                            "lastName": "Zhai",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "ChengXiang Zhai"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 261,
                                "start": 62
                            }
                        ],
                        "text": "While most existing work extracts relations within a sentence (Zelenko et al., 2003; Palmer et al., 2005; Zhao and Grishman, 2005; Jiang and Zhai, 2007; Plank and Moschitti, 2013; Li and Ji, 2014; Gormley et al., 2015; Miwa and Bansal, 2016; Zhang et al., 2017), the task of cross-sentence relation extraction has received increasing attention (Gerber and Chai, 2010; Yoshikawa et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 17069935,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c99ae181e2e051f9d813ad69fc440d373e1341a9",
            "isKey": false,
            "numCitedBy": 190,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "Relation extraction is the task of finding semantic relations between entities from text. The state-of-the-art methods for relation extraction are mostly based on statistical learning, and thus all have to deal with feature selection, which can significantly affect the classification performance. In this paper, we systematically explore a large space of features for relation extraction and evaluate the effectiveness of different feature subspaces. We present a general definition of feature spaces based on a graphic representation of relation instances, and explore three different representations of relation instances and features of different complexities within this framework. Our experiments show that using only basic unit features is generally sufficient to achieve state-of-the-art performance, while overinclusion of complex features may hurt the performance. A combination of features of different levels of complexity and from different sentence representations, coupled with task-oriented feature pruning, gives the best performance."
            },
            "slug": "A-Systematic-Exploration-of-the-Feature-Space-for-Jiang-Zhai",
            "title": {
                "fragments": [],
                "text": "A Systematic Exploration of the Feature Space for Relation Extraction"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This paper systematically explore a large space of features for relation extraction and evaluates the effectiveness of different feature subspaces, and presents a general definition of feature spaces based on a graphic representation of relation instances."
            },
            "venue": {
                "fragments": [],
                "text": "NAACL"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2867844"
                        ],
                        "name": "Nancy A. Chinchor",
                        "slug": "Nancy-A.-Chinchor",
                        "structuredName": {
                            "firstName": "Nancy",
                            "lastName": "Chinchor",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nancy A. Chinchor"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 60588668,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "07ebbe478946c18862c9926b96f5e1fd7d994cd3",
            "isKey": false,
            "numCitedBy": 234,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract : The tasks performed by the systems participating in the seventh Message Understanding Conference and the Second Multilingual Entity Task are described here in general terms with examples. On the level of entity extraction, Named Entities (NE) were defined as proper names and quantities of interest. Person, organization, and location names were marked as well as dates, times, percentages, and monetary amounts. The annotation was SGML within the text stream. An example from MUC-7 (New York Times News Service) in English follows. The ENAMEX TYPE=LOCATIONU.K./ENAMEX satellite television broadcaster said its subscriber base grew NUMEX TYPE=PERCENT17.5 percent/NUMEX during TIMEX TYPE=DATEthe past year/TIMEX to 5.35 million The Named Entity task was carried out in Chinese and Japanese (MET-2) concurrently with English (MUC-7)."
            },
            "slug": "Overview-of-MUC-7/MET-2-Chinchor",
            "title": {
                "fragments": [],
                "text": "Overview of MUC-7/MET-2"
            },
            "tldr": {
                "abstractSimilarityScore": 95,
                "text": "The tasks performed by the systems participating in the seventh Message Understanding Conference and the Second Multilingual Entity Task are described here in general terms with examples."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143845796"
                        ],
                        "name": "Jeffrey Pennington",
                        "slug": "Jeffrey-Pennington",
                        "structuredName": {
                            "firstName": "Jeffrey",
                            "lastName": "Pennington",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jeffrey Pennington"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2166511"
                        ],
                        "name": "R. Socher",
                        "slug": "R.-Socher",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Socher",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Socher"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144783904"
                        ],
                        "name": "Christopher D. Manning",
                        "slug": "Christopher-D.-Manning",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Manning",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christopher D. Manning"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 87,
                                "start": 64
                            }
                        ],
                        "text": "Word embeddings are initialized with the 100-dimensional GloVe (Pennington et al., 2014) vectors, pretrained on 6 billion words from Wikipedia and web text."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1957433,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f37e1b62a767a307c046404ca96bc140b3e68cb5",
            "isKey": false,
            "numCitedBy": 22537,
            "numCiting": 40,
            "paperAbstract": {
                "fragments": [],
                "text": "Recent methods for learning vector space representations of words have succeeded in capturing fine-grained semantic and syntactic regularities using vector arithmetic, but the origin of these regularities has remained opaque. We analyze and make explicit the model properties needed for such regularities to emerge in word vectors. The result is a new global logbilinear regression model that combines the advantages of the two major model families in the literature: global matrix factorization and local context window methods. Our model efficiently leverages statistical information by training only on the nonzero elements in a word-word cooccurrence matrix, rather than on the entire sparse matrix or on individual context windows in a large corpus. The model produces a vector space with meaningful substructure, as evidenced by its performance of 75% on a recent word analogy task. It also outperforms related models on similarity tasks and named entity recognition."
            },
            "slug": "GloVe:-Global-Vectors-for-Word-Representation-Pennington-Socher",
            "title": {
                "fragments": [],
                "text": "GloVe: Global Vectors for Word Representation"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "A new global logbilinear regression model that combines the advantages of the two major model families in the literature: global matrix factorization and local context window methods and produces a vector space with meaningful substructure."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143957226"
                        ],
                        "name": "Ryan T. McDonald",
                        "slug": "Ryan-T.-McDonald",
                        "structuredName": {
                            "firstName": "Ryan",
                            "lastName": "McDonald",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ryan T. McDonald"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145366908"
                        ],
                        "name": "Fernando C Pereira",
                        "slug": "Fernando-C-Pereira",
                        "structuredName": {
                            "firstName": "Fernando",
                            "lastName": "Pereira",
                            "middleNames": [
                                "C"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Fernando C Pereira"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2695965"
                        ],
                        "name": "S. Kulick",
                        "slug": "S.-Kulick",
                        "structuredName": {
                            "firstName": "S.",
                            "lastName": "Kulick",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Kulick"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145367902"
                        ],
                        "name": "R. S. Winters",
                        "slug": "R.-S.-Winters",
                        "structuredName": {
                            "firstName": "R.",
                            "lastName": "Winters",
                            "middleNames": [
                                "Scott"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. S. Winters"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2122755354"
                        ],
                        "name": "Yang Jin",
                        "slug": "Yang-Jin",
                        "structuredName": {
                            "firstName": "Yang",
                            "lastName": "Jin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yang Jin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2093255704"
                        ],
                        "name": "Peter S. White",
                        "slug": "Peter-S.-White",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "White",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Peter S. White"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 68,
                                "start": 47
                            }
                        ],
                        "text": "It has also been studied in biomedical domain (McDonald et al., 2005), but only the instances within a single sentence are considered."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 752623,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "228f2a3ac8934a9c8b2cab8f066e2d42d66cae2d",
            "isKey": false,
            "numCitedBy": 146,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "A complex relation is any n-ary relation in which some of the arguments may be be unspecified. We present here a simple two-stage method for extracting complex relations between named entities in text. The first stage creates a graph from pairs of entities that are likely to be related, and the second stage scores maximal cliques in that graph as potential complex relation instances. We evaluate the new method against a standard baseline for extracting genomic variation relations from biomedical text."
            },
            "slug": "Simple-Algorithms-for-Complex-Relation-Extraction-McDonald-Pereira",
            "title": {
                "fragments": [],
                "text": "Simple Algorithms for Complex Relation Extraction with Applications to Biomedical IE"
            },
            "tldr": {
                "abstractSimilarityScore": 53,
                "text": "A simple two-stage method for extracting complex relations between named entities in text that creates a graph from pairs of entities that are likely to be related, and scores maximal cliques in that graph as potential complex relation instances."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2008458"
                        ],
                        "name": "Hongyu Gong",
                        "slug": "Hongyu-Gong",
                        "structuredName": {
                            "firstName": "Hongyu",
                            "lastName": "Gong",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hongyu Gong"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145355558"
                        ],
                        "name": "S. Bhat",
                        "slug": "S.-Bhat",
                        "structuredName": {
                            "firstName": "S.",
                            "lastName": "Bhat",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Bhat"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144768649"
                        ],
                        "name": "P. Viswanath",
                        "slug": "P.-Viswanath",
                        "structuredName": {
                            "firstName": "Pramod",
                            "lastName": "Viswanath",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Viswanath"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 97,
                                "start": 80
                            }
                        ],
                        "text": "Not only content words, but also propositions can introduce word sense problem (Gong et al., 2018)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 43977290,
            "fieldsOfStudy": [
                "Computer Science",
                "Linguistics"
            ],
            "id": "850ce40ec9eee29bba1268299e1a0ce654e60d22",
            "isKey": false,
            "numCitedBy": 6,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "Prepositions are among the most frequent words in English and play complex roles in the syntax and semantics of sentences. Not surprisingly, they pose well-known difficulties in automatic processing of sentences (prepositional attachment ambiguities and idiosyncratic uses in phrases). Existing methods on preposition representation treat prepositions no different from content words (e.g., word2vec and GloVe). In addition, recent studies aiming at solving prepositional attachment and preposition selection problems depend heavily on external linguistic resources and use dataset-specific word representations. In this paper we use word-triple counts (one of the triples being a preposition) to capture a preposition\u2019s interaction with its attachment and complement. We then derive preposition embeddings via tensor decomposition on a large unlabeled corpus. We reveal a new geometry involving Hadamard products and empirically demonstrate its utility in paraphrasing phrasal verbs. Furthermore, our preposition embeddings are used as simple features in two challenging downstream tasks: preposition selection and prepositional attachment disambiguation. We achieve results comparable to or better than the state-of-the-art on multiple standardized datasets."
            },
            "slug": "Embedding-Syntax-and-Semantics-of-Prepositions-via-Gong-Bhat",
            "title": {
                "fragments": [],
                "text": "Embedding Syntax and Semantics of Prepositions via Tensor Decomposition"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This paper uses word-triple counts to capture a preposition\u2019s interaction with its attachment and complement, and derives preposition embeddings via tensor decomposition on a large unlabeled corpus."
            },
            "venue": {
                "fragments": [],
                "text": "NAACL"
            },
            "year": 2018
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145755155"
                        ],
                        "name": "Martha Palmer",
                        "slug": "Martha-Palmer",
                        "structuredName": {
                            "firstName": "Martha",
                            "lastName": "Palmer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Martha Palmer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2489901"
                        ],
                        "name": "Paul R. Kingsbury",
                        "slug": "Paul-R.-Kingsbury",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Kingsbury",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Paul R. Kingsbury"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1793218"
                        ],
                        "name": "D. Gildea",
                        "slug": "D.-Gildea",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Gildea",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Gildea"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 104,
                                "start": 85
                            }
                        ],
                        "text": "While most existing work extracts relations within a sentence (Zelenko et al., 2003; Palmer et al., 2005; Zhao and Grishman, 2005; Jiang and Zhai, 2007; Plank and Moschitti, 2013; Li and Ji, 2014; Gormley et al., 2015; Miwa and Bansal, 2016; Zhang et al., 2017), the task of cross-sentence relation\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 261,
                                "start": 62
                            }
                        ],
                        "text": "While most existing work extracts relations within a sentence (Zelenko et al., 2003; Palmer et al., 2005; Zhao and Grishman, 2005; Jiang and Zhai, 2007; Plank and Moschitti, 2013; Li and Ji, 2014; Gormley et al., 2015; Miwa and Bansal, 2016; Zhang et al., 2017), the task of cross-sentence relation extraction has received increasing attention (Gerber and Chai, 2010; Yoshikawa et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2486369,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "99d2dcdcf4cf05facaa101a48c7e31d140b4736d",
            "isKey": false,
            "numCitedBy": 2394,
            "numCiting": 68,
            "paperAbstract": {
                "fragments": [],
                "text": "The Proposition Bank project takes a practical approach to semantic representation, adding a layer of predicate-argument information, or semantic role labels, to the syntactic structures of the Penn Treebank. The resulting resource can be thought of as shallow, in that it does not represent coreference, quantification, and many other higher-order phenomena, but also broad, in that it covers every instance of every verb in the corpus and allows representative statistics to be calculated. We discuss the criteria used to define the sets of semantic roles used in the annotation process and to analyze the frequency of syntactic/semantic alternations in the corpus. We describe an automatic system for semantic role tagging trained on the corpus and discuss the effect on its performance of various types of information, including a comparison of full syntactic parsing with a flat representation and the contribution of the empty trace categories of the treebank."
            },
            "slug": "The-Proposition-Bank:-An-Annotated-Corpus-of-Roles-Palmer-Kingsbury",
            "title": {
                "fragments": [],
                "text": "The Proposition Bank: An Annotated Corpus of Semantic Roles"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "An automatic system for semantic role tagging trained on the corpus is described and the effect on its performance of various types of information is discussed, including a comparison of full syntactic parsing with a flat representation and the contribution of the empty trace categories of the treebank."
            },
            "venue": {
                "fragments": [],
                "text": "CL"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1708288"
                        ],
                        "name": "Iris Hendrickx",
                        "slug": "Iris-Hendrickx",
                        "structuredName": {
                            "firstName": "Iris",
                            "lastName": "Hendrickx",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Iris Hendrickx"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1736741380"
                        ],
                        "name": "Su Nam Kim",
                        "slug": "Su-Nam-Kim",
                        "structuredName": {
                            "firstName": "Su Nam",
                            "lastName": "Kim",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Su Nam Kim"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1714932"
                        ],
                        "name": "Zornitsa Kozareva",
                        "slug": "Zornitsa-Kozareva",
                        "structuredName": {
                            "firstName": "Zornitsa",
                            "lastName": "Kozareva",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zornitsa Kozareva"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1683562"
                        ],
                        "name": "Preslav Nakov",
                        "slug": "Preslav-Nakov",
                        "structuredName": {
                            "firstName": "Preslav",
                            "lastName": "Nakov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Preslav Nakov"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8311581"
                        ],
                        "name": "Diarmuid \u00d3 S\u00e9aghdha",
                        "slug": "Diarmuid-\u00d3-S\u00e9aghdha",
                        "structuredName": {
                            "firstName": "Diarmuid",
                            "lastName": "S\u00e9aghdha",
                            "middleNames": [
                                "\u00d3"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Diarmuid \u00d3 S\u00e9aghdha"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1708581"
                        ],
                        "name": "Sebastian Pad\u00f3",
                        "slug": "Sebastian-Pad\u00f3",
                        "structuredName": {
                            "firstName": "Sebastian",
                            "lastName": "Pad\u00f3",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sebastian Pad\u00f3"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145375801"
                        ],
                        "name": "M. Pennacchiotti",
                        "slug": "M.-Pennacchiotti",
                        "structuredName": {
                            "firstName": "Marco",
                            "lastName": "Pennacchiotti",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Pennacchiotti"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31790611"
                        ],
                        "name": "Lorenza Romano",
                        "slug": "Lorenza-Romano",
                        "structuredName": {
                            "firstName": "Lorenza",
                            "lastName": "Romano",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lorenza Romano"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1795595"
                        ],
                        "name": "S. Szpakowicz",
                        "slug": "S.-Szpakowicz",
                        "structuredName": {
                            "firstName": "Stan",
                            "lastName": "Szpakowicz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Szpakowicz"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 105,
                                "start": 83
                            }
                        ],
                        "text": "It has been shown to be useful for detecting explicit facts, such as cause-effect (Hendrickx et al., 2009), and predicting the effectiveness of a medicine on a cancer caused by mutation of a certain gene in the biomedical domain (Quirk and Poon, 2017; Peng et al., 2017)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 106,
                                "start": 82
                            }
                        ],
                        "text": "It has been shown to be useful for detecting explicit facts, such as cause-effect (Hendrickx et al., 2009), and predicting the effectiveness of a medicine on a cancer caused by mutation of a certain gene in the biomedical domain (Quirk and Poon, 2017; Peng et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 436023,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "04221cd779dc8a9a2cc5d921a3449dbead8d7890",
            "isKey": false,
            "numCitedBy": 463,
            "numCiting": 37,
            "paperAbstract": {
                "fragments": [],
                "text": "SemEval-2 Task 8 focuses on Multi-way classification of semantic relations between pairs of nominals. The task was designed to compare different approaches to semantic relation classification and to provide a standard testbed for future research. This paper defines the task, describes the training and test data and the process of their creation, lists the participating systems (10 teams, 28 runs), and discusses their results."
            },
            "slug": "SemEval-2010-Task-8:-Multi-Way-Classification-of-of-Hendrickx-Kim",
            "title": {
                "fragments": [],
                "text": "SemEval-2010 Task 8: Multi-Way Classification of Semantic Relations between Pairs of Nominals"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "This paper defines the task, describes the training and test data and the process of their creation, lists the participating systems (10 teams, 28 runs), and discusses their results."
            },
            "venue": {
                "fragments": [],
                "text": "*SEMEVAL"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40348417"
                        ],
                        "name": "Ashish Vaswani",
                        "slug": "Ashish-Vaswani",
                        "structuredName": {
                            "firstName": "Ashish",
                            "lastName": "Vaswani",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ashish Vaswani"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1846258"
                        ],
                        "name": "Noam M. Shazeer",
                        "slug": "Noam-M.-Shazeer",
                        "structuredName": {
                            "firstName": "Noam",
                            "lastName": "Shazeer",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Noam M. Shazeer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3877127"
                        ],
                        "name": "Niki Parmar",
                        "slug": "Niki-Parmar",
                        "structuredName": {
                            "firstName": "Niki",
                            "lastName": "Parmar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Niki Parmar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39328010"
                        ],
                        "name": "Jakob Uszkoreit",
                        "slug": "Jakob-Uszkoreit",
                        "structuredName": {
                            "firstName": "Jakob",
                            "lastName": "Uszkoreit",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jakob Uszkoreit"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145024664"
                        ],
                        "name": "Llion Jones",
                        "slug": "Llion-Jones",
                        "structuredName": {
                            "firstName": "Llion",
                            "lastName": "Jones",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Llion Jones"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "19177000"
                        ],
                        "name": "Aidan N. Gomez",
                        "slug": "Aidan-N.-Gomez",
                        "structuredName": {
                            "firstName": "Aidan",
                            "lastName": "Gomez",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Aidan N. Gomez"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40527594"
                        ],
                        "name": "Lukasz Kaiser",
                        "slug": "Lukasz-Kaiser",
                        "structuredName": {
                            "firstName": "Lukasz",
                            "lastName": "Kaiser",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lukasz Kaiser"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3443442"
                        ],
                        "name": "Illia Polosukhin",
                        "slug": "Illia-Polosukhin",
                        "structuredName": {
                            "firstName": "Illia",
                            "lastName": "Polosukhin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Illia Polosukhin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 161,
                                "start": 141
                            }
                        ],
                        "text": "\u2026by building a graph structure of neighboring words and a sentence-level node, showing that the encoder outperforms BiLSTMs and Transformer (Vaswani et al., 2017) on classification and sequence labeling tasks; Song et al. (2018) build a GRN for encoding AMR graphs, showing that the\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 208,
                                "start": 185
                            }
                        ],
                        "text": "In particular, Zhang et al. (2018) use GRN to represent raw sentences by building a graph structure of neighboring words and a sentence-level node, showing that the encoder outperforms BiLSTMs and Transformer (Vaswani et al., 2017) on classification and sequence labeling tasks; Song et al. (2018) build a GRN for encoding AMR graphs, showing that the representation is superior compared to BiLSTM on serialized AMR."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 203,
                                "start": 181
                            }
                        ],
                        "text": "(2018) use GRN to represent raw sentences by building a graph structure of neighboring words and a sentence-level node, showing that the encoder outperforms BiLSTMs and Transformer (Vaswani et al., 2017) on classification and sequence labeling tasks; Song et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 13756489,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "204e3073870fae3d05bcbc2f6a8e263d9b72e776",
            "isKey": false,
            "numCitedBy": 35164,
            "numCiting": 44,
            "paperAbstract": {
                "fragments": [],
                "text": "The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-to-German translation task, improving over the existing best results, including ensembles by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data."
            },
            "slug": "Attention-is-All-you-Need-Vaswani-Shazeer",
            "title": {
                "fragments": [],
                "text": "Attention is All you Need"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely is proposed, which generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3190501"
                        ],
                        "name": "D. Zelenko",
                        "slug": "D.-Zelenko",
                        "structuredName": {
                            "firstName": "Dmitry",
                            "lastName": "Zelenko",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Zelenko"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2939759"
                        ],
                        "name": "Chinatsu Aone",
                        "slug": "Chinatsu-Aone",
                        "structuredName": {
                            "firstName": "Chinatsu",
                            "lastName": "Aone",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chinatsu Aone"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49754061"
                        ],
                        "name": "A. Richardella",
                        "slug": "A.-Richardella",
                        "structuredName": {
                            "firstName": "Anthony",
                            "lastName": "Richardella",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Richardella"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 83,
                                "start": 63
                            }
                        ],
                        "text": "While most existing work extracts relations within a sentence (Zelenko et al., 2003; Palmer et al., 2005; Zhao and Grishman, 2005; Jiang and Zhai, 2007; Plank and Moschitti, 2013; Li and Ji, 2014; Gormley et al., 2015; Miwa and Bansal, 2016; Zhang et al., 2017), the task of cross-sentence relation\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 261,
                                "start": 62
                            }
                        ],
                        "text": "While most existing work extracts relations within a sentence (Zelenko et al., 2003; Palmer et al., 2005; Zhao and Grishman, 2005; Jiang and Zhai, 2007; Plank and Moschitti, 2013; Li and Ji, 2014; Gormley et al., 2015; Miwa and Bansal, 2016; Zhang et al., 2017), the task of cross-sentence relation extraction has received increasing attention (Gerber and Chai, 2010; Yoshikawa et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 11074539,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cc1cad12521b5aab43fdda5b4dec67586aef1f87",
            "isKey": false,
            "numCitedBy": 919,
            "numCiting": 49,
            "paperAbstract": {
                "fragments": [],
                "text": "We present an application of kernel methods to extracting relations from unstructured natural language sources. We introduce kernels defined over shallow parse representations of text, and design efficient algorithms for computing the kernels. We use the devised kernels in conjunction with Support Vector Machine and Voted Perceptron learning algorithms for the task of extracting person-affiliation and organization-location relations from text. We experimentally evaluate the proposed methods and compare them with feature-based learning algorithms, with promising results."
            },
            "slug": "Kernel-Methods-for-Relation-Extraction-Zelenko-Aone",
            "title": {
                "fragments": [],
                "text": "Kernel Methods for Relation Extraction"
            },
            "tldr": {
                "abstractSimilarityScore": 68,
                "text": "This work introduces kernels defined over shallow parse representations of text, and design efficient algorithms for computing the kernels, and uses the devised kernels in conjunction with Support Vector Machine and Voted Perceptron learning algorithms for the task of extracting person-affiliation and organization-location relations from text."
            },
            "venue": {
                "fragments": [],
                "text": "J. Mach. Learn. Res."
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2059184073"
                        ],
                        "name": "Matthew Gerber",
                        "slug": "Matthew-Gerber",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Gerber",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Matthew Gerber"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1707259"
                        ],
                        "name": "J. Chai",
                        "slug": "J.-Chai",
                        "structuredName": {
                            "firstName": "Joyce",
                            "lastName": "Chai",
                            "middleNames": [
                                "Yue"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Chai"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 149,
                                "start": 102
                            }
                        ],
                        "text": "Previous work on cross-sentence relation extraction relies on either explicit co-reference annotation (Gerber and Chai, 2010; Yoshikawa et al., 2011), or the assumption that the whole document refers to a single coherent event (Wick et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 137,
                                "start": 90
                            }
                        ],
                        "text": ", 2017), the task of cross-sentence relation extraction has received increasing attention (Gerber and Chai, 2010; Yoshikawa et al., 2011)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 13804679,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d8259bcbe9cb0cf5bad6ea25645f4407fc544a1c",
            "isKey": false,
            "numCitedBy": 109,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "Despite its substantial coverage, NomBank does not account for all within-sentence arguments and ignores extra-sentential arguments altogether. These arguments, which we call implicit, are important to semantic processing, and their recovery could potentially benefit many NLP applications. We present a study of implicit arguments for a select group of frequent nominal predicates. We show that implicit arguments are pervasive for these predicates, adding 65% to the coverage of NomBank. We demonstrate the feasibility of recovering implicit arguments with a supervised classification model. Our results and analyses provide a baseline for future work on this emerging task."
            },
            "slug": "Beyond-NomBank:-A-Study-of-Implicit-Arguments-for-Gerber-Chai",
            "title": {
                "fragments": [],
                "text": "Beyond NomBank: A Study of Implicit Arguments for Nominal Predicates"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "It is shown that implicit arguments are pervasive for these predicates, adding 65% to the coverage of NomBank, and demonstrated the feasibility of recovering implicit arguments with a supervised classification model."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144783904"
                        ],
                        "name": "Christopher D. Manning",
                        "slug": "Christopher-D.-Manning",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Manning",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christopher D. Manning"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1760868"
                        ],
                        "name": "M. Surdeanu",
                        "slug": "M.-Surdeanu",
                        "structuredName": {
                            "firstName": "Mihai",
                            "lastName": "Surdeanu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Surdeanu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144661918"
                        ],
                        "name": "John Bauer",
                        "slug": "John-Bauer",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Bauer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "John Bauer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2784228"
                        ],
                        "name": "J. Finkel",
                        "slug": "J.-Finkel",
                        "structuredName": {
                            "firstName": "Jenny",
                            "lastName": "Finkel",
                            "middleNames": [
                                "Rose"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Finkel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2105138"
                        ],
                        "name": "Steven Bethard",
                        "slug": "Steven-Bethard",
                        "structuredName": {
                            "firstName": "Steven",
                            "lastName": "Bethard",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Steven Bethard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2240597"
                        ],
                        "name": "David McClosky",
                        "slug": "David-McClosky",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "McClosky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David McClosky"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 52,
                                "start": 32
                            }
                        ],
                        "text": "In particular, Stanford parser (Manning et al., 2014) is used to assign syntactic structure to input sentences, and heads of two consecutive sentences are connected to represent discourse information, resulting in a graph structure."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14068874,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2f5102ec3f70d0dea98c957cc2cab4d15d83a2da",
            "isKey": false,
            "numCitedBy": 6057,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe the design and use of the Stanford CoreNLP toolkit, an extensible pipeline that provides core natural language analysis. This toolkit is quite widely used, both in the research NLP community and also among commercial and government users of open source NLP technology. We suggest that this follows from a simple, approachable design, straightforward interfaces, the inclusion of robust and good quality analysis components, and not requiring use of a large amount of associated baggage."
            },
            "slug": "The-Stanford-CoreNLP-Natural-Language-Processing-Manning-Surdeanu",
            "title": {
                "fragments": [],
                "text": "The Stanford CoreNLP Natural Language Processing Toolkit"
            },
            "tldr": {
                "abstractSimilarityScore": 57,
                "text": "The design and use of the Stanford CoreNLP toolkit is described, an extensible pipeline that provides core natural language analysis, and it is suggested that this follows from a simple, approachable design, straightforward interfaces, the inclusion of robust and good quality analysis components, and not requiring use of a large amount of associated baggage."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1726807"
                        ],
                        "name": "Diederik P. Kingma",
                        "slug": "Diederik-P.-Kingma",
                        "structuredName": {
                            "firstName": "Diederik",
                            "lastName": "Kingma",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Diederik P. Kingma"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2503659"
                        ],
                        "name": "Jimmy Ba",
                        "slug": "Jimmy-Ba",
                        "structuredName": {
                            "firstName": "Jimmy",
                            "lastName": "Ba",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jimmy Ba"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 26,
                                "start": 5
                            }
                        ],
                        "text": "Adam (Kingma and Ba, 2014) with a learning rate of Data Avg."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6628106,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a6cb366736791bcccc5c8639de5a8f9636bf87e8",
            "isKey": false,
            "numCitedBy": 90076,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce Adam, an algorithm for first-order gradient-based optimization of stochastic objective functions, based on adaptive estimates of lower-order moments. The method is straightforward to implement, is computationally efficient, has little memory requirements, is invariant to diagonal rescaling of the gradients, and is well suited for problems that are large in terms of data and/or parameters. The method is also appropriate for non-stationary objectives and problems with very noisy and/or sparse gradients. The hyper-parameters have intuitive interpretations and typically require little tuning. Some connections to related algorithms, on which Adam was inspired, are discussed. We also analyze the theoretical convergence properties of the algorithm and provide a regret bound on the convergence rate that is comparable to the best known results under the online convex optimization framework. Empirical results demonstrate that Adam works well in practice and compares favorably to other stochastic optimization methods. Finally, we discuss AdaMax, a variant of Adam based on the infinity norm."
            },
            "slug": "Adam:-A-Method-for-Stochastic-Optimization-Kingma-Ba",
            "title": {
                "fragments": [],
                "text": "Adam: A Method for Stochastic Optimization"
            },
            "tldr": {
                "abstractSimilarityScore": 69,
                "text": "This work introduces Adam, an algorithm for first-order gradient-based optimization of stochastic objective functions, based on adaptive estimates of lower-order moments, and provides a regret bound on the convergence rate that is comparable to the best known results under the online convex optimization framework."
            },
            "venue": {
                "fragments": [],
                "text": "ICLR"
            },
            "year": 2015
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 122,
                                "start": 45
                            }
                        ],
                        "text": "Recently, graph convolutional networks (GCN) (Kipf and Welling, 2017; Marcheggiani and Titov, 2017; Bastings et al., 2017) and graph recurrent networks (GRN) (Song et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 41,
                                "start": 38
                            }
                        ],
                        "text": "We leave it to future work to compare GCN and GRN for our task."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 9,
                                "start": 6
                            }
                        ],
                        "text": "While GCNs use CNN for information exchange, GRNs take gated recurrent steps to this end."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 43,
                                "start": 40
                            }
                        ],
                        "text": "Recently, graph convolutional networks (GCN) (Kipf and Welling, 2017; Marcheggiani and Titov, 2017; Bastings et al., 2017) and graph recurrent networks (GRN) (Song et al., 2018; Zhang et al., 2018) have been proposed for representing graph structures for NLP tasks."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 33,
                                "start": 30
                            }
                        ],
                        "text": "Graph convolutional networks (GCNs) and very recently graph recurrent networks (GRNs) have been used to model graph structures in NLP tasks, such as semantic role labeling (Marcheggiani and Titov, 2017), machine translation (Bastings et al., 2017), text generation (Song et al., 2018), text representation (Zhang et al., 2018) and semantic parsing (Xu et al., 2018b,a)."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Semisupervised classification with graph convolutional networks"
            },
            "venue": {
                "fragments": [],
                "text": "International Conference on Learning Representations (ICLR)."
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "73422065"
                        ],
                        "name": "I. Hendrickx",
                        "slug": "I.-Hendrickx",
                        "structuredName": {
                            "firstName": "Iris",
                            "lastName": "Hendrickx",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Hendrickx"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1736741380"
                        ],
                        "name": "Su Nam Kim",
                        "slug": "Su-Nam-Kim",
                        "structuredName": {
                            "firstName": "Su Nam",
                            "lastName": "Kim",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Su Nam Kim"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1714932"
                        ],
                        "name": "Zornitsa Kozareva",
                        "slug": "Zornitsa-Kozareva",
                        "structuredName": {
                            "firstName": "Zornitsa",
                            "lastName": "Kozareva",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zornitsa Kozareva"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1683562"
                        ],
                        "name": "Preslav Nakov",
                        "slug": "Preslav-Nakov",
                        "structuredName": {
                            "firstName": "Preslav",
                            "lastName": "Nakov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Preslav Nakov"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8311581"
                        ],
                        "name": "Diarmuid \u00d3 S\u00e9aghdha",
                        "slug": "Diarmuid-\u00d3-S\u00e9aghdha",
                        "structuredName": {
                            "firstName": "Diarmuid",
                            "lastName": "S\u00e9aghdha",
                            "middleNames": [
                                "\u00d3"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Diarmuid \u00d3 S\u00e9aghdha"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145375801"
                        ],
                        "name": "M. Pennacchiotti",
                        "slug": "M.-Pennacchiotti",
                        "structuredName": {
                            "firstName": "Marco",
                            "lastName": "Pennacchiotti",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Pennacchiotti"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31790611"
                        ],
                        "name": "Lorenza Romano",
                        "slug": "Lorenza-Romano",
                        "structuredName": {
                            "firstName": "Lorenza",
                            "lastName": "Romano",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lorenza Romano"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1795595"
                        ],
                        "name": "S. Szpakowicz",
                        "slug": "S.-Szpakowicz",
                        "structuredName": {
                            "firstName": "Stan",
                            "lastName": "Szpakowicz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Szpakowicz"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 105,
                                "start": 83
                            }
                        ],
                        "text": "It has been shown to be useful for detecting explicit facts, such as cause-effect (Hendrickx et al., 2009), and predicting the effectiveness of a medicine on a cancer caused by mutation of a certain gene in the biomedical domain (Quirk and Poon, 2017; Peng et al., 2017)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 52836516,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2768040d345e016c010312c7cd747c0959effb86",
            "isKey": false,
            "numCitedBy": 314,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a brief overview of the main challenges in the extraction of semantic relations from English text, and discuss the shortcomings of previous data sets and shared tasks. This leads us to introduce a new task, which will be part of SemEval-2010: multi-way classification of mutually exclusive semantic relations between pairs of common nominals. The task is designed to compare different approaches to the problem and to provide a standard testbed for future research, which can benefit many applications in Natural Language Processing."
            },
            "slug": "SemEval-2010-Task-8:-Multi-Way-Classification-of-of-Hendrickx-Kim",
            "title": {
                "fragments": [],
                "text": "SemEval-2010 Task 8: Multi-Way Classification of Semantic Relations Between Pairs of Nominals"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A new task is introduced, which will be part of SemEval-2010: multi-way classification of mutually exclusive semantic relations between pairs of common nominals."
            },
            "venue": {
                "fragments": [],
                "text": "HLT-NAACL 2009"
            },
            "year": 2009
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 27,
            "methodology": 10,
            "result": 2
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 33,
        "totalPages": 4
    },
    "page_url": "https://www.semanticscholar.org/paper/N-ary-Relation-Extraction-using-Graph-State-LSTM-Song-Zhang/749c00144b6a005f0fbe3ee8cc07e0090a45f7b8?sort=total-citations"
}