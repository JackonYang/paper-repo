{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2577784"
                        ],
                        "name": "Yiru Shen",
                        "slug": "Yiru-Shen",
                        "structuredName": {
                            "firstName": "Yiru",
                            "lastName": "Shen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yiru Shen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144066717"
                        ],
                        "name": "Chen Feng",
                        "slug": "Chen-Feng",
                        "structuredName": {
                            "firstName": "Chen",
                            "lastName": "Feng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chen Feng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49576470"
                        ],
                        "name": "Yaoqing Yang",
                        "slug": "Yaoqing-Yang",
                        "structuredName": {
                            "firstName": "Yaoqing",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yaoqing Yang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144309297"
                        ],
                        "name": "Dong Tian",
                        "slug": "Dong-Tian",
                        "structuredName": {
                            "firstName": "Dong",
                            "lastName": "Tian",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dong Tian"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "part segmentation testing results for tables, chairs and lamps. compare our results with PointNet [Qi et al. 2017b], PointNet++ [Qi et al. 2017c], Kd-Net [Klokov and Lempitsky 2017], LocalFeatureNet [Shen et al. 2017], PCNN [Atzmon et al. 2018], and PointCNN [Li et al. 2018a]. The evaluation results are shown in Table 6. We also visually compare the results of our model and PointNet in Figure 7. More examples are"
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "ently and subsequently applying a symmetric function to accumulate features. Various extensions of PointNet consider neighborhoods of points rather than acting on each independently [Qi et al. 2017c; Shen et al. 2017]; these allow the network to exploit local features, improving upon performance of the basic model. These techniques largely treat points independently at local scale to maintain permutation invarian"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 85563065,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6951a3fa2535f3d487d7e813b21405a30bb4c8a2",
            "isKey": false,
            "numCitedBy": 32,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "Unlike on images, semantic learning on 3D point clouds using a deep network is challenging due to the naturally unordered data structure. Among existing works, PointNet has achieved promising results by directly learning on point sets. However, it does not take full advantage of a point's local neighborhood that contains fine-grained structural information which turns out to be helpful towards better semantic learning. In this regard, we present two new operations to improve PointNet with more efficient exploitation of local structures. The first one focuses on local 3D geometric structures. In analogy with a convolution kernel for images, we define a point-set kernel as a set of learnable points that jointly respond to a set of neighboring data points according to their geometric affinity measured by kernel correlation, adapted from a similar technique for point cloud registration. The second one exploits local feature structures by recursive feature aggregation on a nearest-neighbor-graph computed from 3D positions. Experiments show that our network is able to robustly capture local information and efficiently achieve better performance on major datasets."
            },
            "slug": "Neighbors-Do-Help:-Deeply-Exploiting-Local-of-Point-Shen-Feng",
            "title": {
                "fragments": [],
                "text": "Neighbors Do Help: Deeply Exploiting Local Structures of Point Clouds"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "Two new operations to improve PointNet with more efficient exploitation of local structures are presented, one focuses on local 3D geometric structures and the other exploits local feature structures by recursive feature aggregation on a nearest-neighbor-graph computed from 3D positions."
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144329939"
                        ],
                        "name": "C. Qi",
                        "slug": "C.-Qi",
                        "structuredName": {
                            "firstName": "C.",
                            "lastName": "Qi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Qi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144914140"
                        ],
                        "name": "Hao Su",
                        "slug": "Hao-Su",
                        "structuredName": {
                            "firstName": "Hao",
                            "lastName": "Su",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hao Su"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2216377"
                        ],
                        "name": "Kaichun Mo",
                        "slug": "Kaichun-Mo",
                        "structuredName": {
                            "firstName": "Kaichun",
                            "lastName": "Mo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kaichun Mo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1744254"
                        ],
                        "name": "L. Guibas",
                        "slug": "L.-Guibas",
                        "structuredName": {
                            "firstName": "Leonidas",
                            "lastName": "Guibas",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Guibas"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 50,
                                "start": 46
                            }
                        ],
                        "text": "Training We use the same training strategy as [34]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 44,
                                "start": 40
                            }
                        ],
                        "text": "This approach was pioneered by PointNet [34], which achieves permutation invariance of points by operating on each point independently and subsequently applying a symmetric function to accumulate features."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 24,
                                "start": 20
                            }
                        ],
                        "text": "PointNets PointNets [34] comprise a special class of architectures for point sets like 3D point clouds."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 44,
                                "start": 40
                            }
                        ],
                        "text": "We compare our model with both PointNet [34] and PointNet baseline, where additional point features (local point density, local curvature and normal) are used to construct handcrafted features and then fed to an MLP classifier."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 164,
                                "start": 145
                            }
                        ],
                        "text": "Other methods replace the standard building blocks of deep neural architectures with special operations suitable for unstructured geometric data [29, 6, 31, 34, 36]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 41,
                                "start": 37
                            }
                        ],
                        "text": "We compare our results with PointNet [34], PointNet++ [36], KdNet [20], and LocalFeatureNet [43]."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 52,
                                "start": 48
                            }
                        ],
                        "text": "We follow verbatim the experimental settings of [34]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 37,
                                "start": 33
                            }
                        ],
                        "text": "We follow the same setting as in [34], where each room is split into blocks with area 1m \u00d7 1m, and each point is represented as a 9D vector (XYZ, RGB, and normalized spatial coordinates)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 5115938,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d997beefc0922d97202789d2ac307c55c2c52fba",
            "isKey": true,
            "numCitedBy": 6136,
            "numCiting": 40,
            "paperAbstract": {
                "fragments": [],
                "text": "Point cloud is an important type of geometric data structure. Due to its irregular format, most researchers transform such data to regular 3D voxel grids or collections of images. This, however, renders data unnecessarily voluminous and causes issues. In this paper, we design a novel type of neural network that directly consumes point clouds, which well respects the permutation invariance of points in the input. Our network, named PointNet, provides a unified architecture for applications ranging from object classification, part segmentation, to scene semantic parsing. Though simple, PointNet is highly efficient and effective. Empirically, it shows strong performance on par or even better than state of the art. Theoretically, we provide analysis towards understanding of what the network has learnt and why the network is robust with respect to input perturbation and corruption."
            },
            "slug": "PointNet:-Deep-Learning-on-Point-Sets-for-3D-and-Qi-Su",
            "title": {
                "fragments": [],
                "text": "PointNet: Deep Learning on Point Sets for 3D Classification and Segmentation"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This paper designs a novel type of neural network that directly consumes point clouds, which well respects the permutation invariance of points in the input and provides a unified architecture for applications ranging from object classification, part segmentation, to scene semantic parsing."
            },
            "venue": {
                "fragments": [],
                "text": "2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49576470"
                        ],
                        "name": "Yaoqing Yang",
                        "slug": "Yaoqing-Yang",
                        "structuredName": {
                            "firstName": "Yaoqing",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yaoqing Yang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144066717"
                        ],
                        "name": "Chen Feng",
                        "slug": "Chen-Feng",
                        "structuredName": {
                            "firstName": "Chen",
                            "lastName": "Feng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chen Feng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2577784"
                        ],
                        "name": "Yiru Shen",
                        "slug": "Yiru-Shen",
                        "structuredName": {
                            "firstName": "Yiru",
                            "lastName": "Shen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yiru Shen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144309297"
                        ],
                        "name": "Dong Tian",
                        "slug": "Dong-Tian",
                        "structuredName": {
                            "firstName": "Dong",
                            "lastName": "Tian",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dong Tian"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "pe completion; a similar architecture was used by Ranjan et al. [2018] for 3D face synthesis. For point clouds, multiple generative architectures have been proposed [Fan et al. 2017; Li et al. 2018b; Yang et al. 2018]. 3 OUR APPROACH We propose an approach inspired by PointNet and convolution operations. Instead of working on individual points like PointNet, however, we exploit local geometric structures by const"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 8338993,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "572a5aa00f0569887469ffb7554699c21156ba0b",
            "isKey": false,
            "numCitedBy": 557,
            "numCiting": 61,
            "paperAbstract": {
                "fragments": [],
                "text": "Recent deep networks that directly handle points in a point set, e.g., PointNet, have been state-of-the-art for supervised learning tasks on point clouds such as classification and segmentation. In this work, a novel end-to-end deep auto-encoder is proposed to address unsupervised learning challenges on point clouds. On the encoder side, a graph-based enhancement is enforced to promote local structures on top of PointNet. Then, a novel folding-based decoder deforms a canonical 2D grid onto the underlying 3D object surface of a point cloud, achieving low reconstruction errors even for objects with delicate structures. The proposed decoder only uses about 7% parameters of a decoder with fully-connected neural networks, yet leads to a more discriminative representation that achieves higher linear SVM classification accuracy than the benchmark. In addition, the proposed decoder structure is shown, in theory, to be a generic architecture that is able to reconstruct an arbitrary point cloud from a 2D grid. Our code is available at http://www.merl.com/research/license#FoldingNet"
            },
            "slug": "FoldingNet:-Point-Cloud-Auto-Encoder-via-Deep-Grid-Yang-Feng",
            "title": {
                "fragments": [],
                "text": "FoldingNet: Point Cloud Auto-Encoder via Deep Grid Deformation"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "A novel end-to-end deep auto-encoder is proposed to address unsupervised learning challenges on point clouds, and is shown, in theory, to be a generic architecture that is able to reconstruct an arbitrary point cloud from a 2D grid."
            },
            "venue": {
                "fragments": [],
                "text": "2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2018
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145630914"
                        ],
                        "name": "Paul Guerrero",
                        "slug": "Paul-Guerrero",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Guerrero",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Paul Guerrero"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3119575"
                        ],
                        "name": "Yanir Kleiman",
                        "slug": "Yanir-Kleiman",
                        "structuredName": {
                            "firstName": "Yanir",
                            "lastName": "Kleiman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yanir Kleiman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1690177"
                        ],
                        "name": "M. Ovsjanikov",
                        "slug": "M.-Ovsjanikov",
                        "structuredName": {
                            "firstName": "Maks",
                            "lastName": "Ovsjanikov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Ovsjanikov"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1710455"
                        ],
                        "name": "N. Mitra",
                        "slug": "N.-Mitra",
                        "structuredName": {
                            "firstName": "Niloy",
                            "lastName": "Mitra",
                            "middleNames": [
                                "Jyoti"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Mitra"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 3275654,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "55de5d37a78a560f99bdc7ba8ced5393b700ee96",
            "isKey": false,
            "numCitedBy": 189,
            "numCiting": 41,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we propose PCPNET, a deep\u2010learning based approach for estimating local 3D shape properties in point clouds. In contrast to the majority of prior techniques that concentrate on global or mid\u2010level attributes, e.g., for shape classification or semantic labeling, we suggest a patch\u2010based learning method, in which a series of local patches at multiple scales around each point is encoded in a structured manner. Our approach is especially well\u2010adapted for estimating local shape properties such as normals (both unoriented and oriented) and curvature from raw point clouds in the presence of strong noise and multi\u2010scale features. Our main contributions include both a novel multi\u2010scale variant of the recently proposed PointNet architecture with emphasis on local shape information, and a series of novel applications in which we demonstrate how learning from training data arising from well\u2010structured triangle meshes, and applying the trained model to noisy point clouds can produce superior results compared to specialized state\u2010of\u2010the\u2010art techniques. Finally, we demonstrate the utility of our approach in the context of shape reconstruction, by showing how it can be used to extract normal orientation information from point clouds."
            },
            "slug": "PCPNet-Learning-Local-Shape-Properties-from-Raw-Guerrero-Kleiman",
            "title": {
                "fragments": [],
                "text": "PCPNet Learning Local Shape Properties from Raw Point Clouds"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The utility of the PCPNET approach in the context of shape reconstruction is demonstrated, by showing how it can be used to extract normal orientation information from point clouds."
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Graph. Forum"
            },
            "year": 2018
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1410529269"
                        ],
                        "name": "Danielle Ezuz",
                        "slug": "Danielle-Ezuz",
                        "structuredName": {
                            "firstName": "Danielle",
                            "lastName": "Ezuz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Danielle Ezuz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1932072"
                        ],
                        "name": "J. Solomon",
                        "slug": "J.-Solomon",
                        "structuredName": {
                            "firstName": "Justin",
                            "lastName": "Solomon",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Solomon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3082383"
                        ],
                        "name": "Vladimir G. Kim",
                        "slug": "Vladimir-G.-Kim",
                        "structuredName": {
                            "firstName": "Vladimir",
                            "lastName": "Kim",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Vladimir G. Kim"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1398681470"
                        ],
                        "name": "M. Ben-Chen",
                        "slug": "M.-Ben-Chen",
                        "structuredName": {
                            "firstName": "Mirela",
                            "lastName": "Ben-Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Ben-Chen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 3090322,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d22a270ec055216580164b4f297089845065ff23",
            "isKey": false,
            "numCitedBy": 60,
            "numCiting": 55,
            "paperAbstract": {
                "fragments": [],
                "text": "Deep neural networks provide a promising tool for incorporating semantic information in geometry processing applications. Unlike image and video processing, however, geometry processing requires handling unstructured geometric data, and thus data representation becomes an important challenge in this framework. Existing approaches tackle this challenge by converting point clouds, meshes, or polygon soups into regular representations using, e.g., multi\u2010view images, volumetric grids or planar parameterizations. In each of these cases, geometric data representation is treated as a fixed pre\u2010process that is largely disconnected from the machine learning tool. In contrast, we propose to optimize for the geometric representation during the network learning process using a novel metric alignment layer. Our approach maps unstructured geometric data to a regular domain by minimizing the metric distortion of the map using the regularized Gromov\u2013Wasserstein objective. This objective is parameterized by the metric of the target domain and is differentiable; thus, it can be easily incorporated into a deep network framework. Furthermore, the objective aims to align the metrics of the input and output domains, promoting consistent output for similar shapes. We show the effectiveness of our layer within a deep network trained for shape classification, demonstrating state\u2010of\u2010the\u2010art performance for nonrigid shapes."
            },
            "slug": "GWCNN:-A-Metric-Alignment-Layer-for-Deep-Shape-Ezuz-Solomon",
            "title": {
                "fragments": [],
                "text": "GWCNN: A Metric Alignment Layer for Deep Shape Analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "This work proposes to optimize for the geometric representation during the network learning process using a novel metric alignment layer that maps unstructured geometric data to a regular domain by minimizing the metric distortion of the map using the regularized Gromov\u2013Wasserstein objective."
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Graph. Forum"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1920864"
                        ],
                        "name": "Yangyan Li",
                        "slug": "Yangyan-Li",
                        "structuredName": {
                            "firstName": "Yangyan",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yangyan Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35526877"
                        ],
                        "name": "Rui Bu",
                        "slug": "Rui-Bu",
                        "structuredName": {
                            "firstName": "Rui",
                            "lastName": "Bu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Rui Bu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "71614496"
                        ],
                        "name": "Mingchao Sun",
                        "slug": "Mingchao-Sun",
                        "structuredName": {
                            "firstName": "Mingchao",
                            "lastName": "Sun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mingchao Sun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39533001"
                        ],
                        "name": "Wei Wu",
                        "slug": "Wei-Wu",
                        "structuredName": {
                            "firstName": "Wei",
                            "lastName": "Wu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wei Wu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7759488"
                        ],
                        "name": "X. Di",
                        "slug": "X.-Di",
                        "structuredName": {
                            "firstName": "Xinhan",
                            "lastName": "Di",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "X. Di"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2028246830"
                        ],
                        "name": "Baoquan Chen",
                        "slug": "Baoquan-Chen",
                        "structuredName": {
                            "firstName": "Baoquan",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Baoquan Chen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 53399839,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6400c36efdb8a66b401b6aef26c057227266fddd",
            "isKey": false,
            "numCitedBy": 1012,
            "numCiting": 71,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a simple and general framework for feature learning from point clouds. The key to the success of CNNs is the convolution operator that is capable of leveraging spatially-local correlation in data represented densely in grids (e.g. images). However, point clouds are irregular and unordered, thus directly convolving kernels against features associated with the points will result in desertion of shape information and variance to point ordering. To address these problems, we propose to learn an \u03a7-transformation from the input points to simultaneously promote two causes: the first is the weighting of the input features associated with the points, and the second is the permutation of the points into a latent and potentially canonical order. Element-wise product and sum operations of the typical convolution operator are subsequently applied on the \u03a7-transformed features. The proposed method is a generalization of typical CNNs to feature learning from point clouds, thus we call it PointCNN. Experiments show that PointCNN achieves on par or better performance than state-of-the-art methods on multiple challenging benchmark datasets and tasks."
            },
            "slug": "PointCNN:-Convolution-On-X-Transformed-Points-Li-Bu",
            "title": {
                "fragments": [],
                "text": "PointCNN: Convolution On X-Transformed Points"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This work proposes to learn an \u03a7-transformation from the input points to simultaneously promote two causes: the first is the weighting of the input features associated with the points, and the second is the permutation of the points into a latent and potentially canonical order."
            },
            "venue": {
                "fragments": [],
                "text": "NeurIPS"
            },
            "year": 2018
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144904233"
                        ],
                        "name": "Hang Su",
                        "slug": "Hang-Su",
                        "structuredName": {
                            "firstName": "Hang",
                            "lastName": "Su",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hang Su"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2745026"
                        ],
                        "name": "V. Jampani",
                        "slug": "V.-Jampani",
                        "structuredName": {
                            "firstName": "V.",
                            "lastName": "Jampani",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Jampani"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3232265"
                        ],
                        "name": "Deqing Sun",
                        "slug": "Deqing-Sun",
                        "structuredName": {
                            "firstName": "Deqing",
                            "lastName": "Sun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Deqing Sun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35208858"
                        ],
                        "name": "Subhransu Maji",
                        "slug": "Subhransu-Maji",
                        "structuredName": {
                            "firstName": "Subhransu",
                            "lastName": "Maji",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Subhransu Maji"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2808670"
                        ],
                        "name": "E. Kalogerakis",
                        "slug": "E.-Kalogerakis",
                        "structuredName": {
                            "firstName": "Evangelos",
                            "lastName": "Kalogerakis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Kalogerakis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1715634"
                        ],
                        "name": "Ming-Hsuan Yang",
                        "slug": "Ming-Hsuan-Yang",
                        "structuredName": {
                            "firstName": "Ming-Hsuan",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ming-Hsuan Yang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1690538"
                        ],
                        "name": "J. Kautz",
                        "slug": "J.-Kautz",
                        "structuredName": {
                            "firstName": "Jan",
                            "lastName": "Kautz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Kautz"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "2017], sparse network lattice [Su et al. 2018], or spline [Fey et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 3525655,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9ebdd272db2596f4f4bee741d6399363b2b6559f",
            "isKey": false,
            "numCitedBy": 510,
            "numCiting": 62,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a network architecture for processing point clouds that directly operates on a collection of points represented as a sparse set of samples in a high-dimensional lattice. Na\u00c3\u00afvely applying convolutions on this lattice scales poorly, both in terms of memory and computational cost, as the size of the lattice increases. Instead, our network uses sparse bilateral convolutional layers as building blocks. These layers maintain efficiency by using indexing structures to apply convolutions only on occupied parts of the lattice, and allow flexible specifications of the lattice structure enabling hierarchical and spatially-aware feature learning, as well as joint 2D-3D reasoning. Both point-based and image-based representations can be easily incorporated in a network with such layers and the resulting model can be trained in an end-to-end manner. We present results on 3D segmentation tasks where our approach outperforms existing state-of-the-art techniques."
            },
            "slug": "SPLATNet:-Sparse-Lattice-Networks-for-Point-Cloud-Su-Jampani",
            "title": {
                "fragments": [],
                "text": "SPLATNet: Sparse Lattice Networks for Point Cloud Processing"
            },
            "tldr": {
                "abstractSimilarityScore": 78,
                "text": "A network architecture for processing point clouds that directly operates on a collection of points represented as a sparse set of samples in a high-dimensional lattice that outperforms existing state-of-the-art techniques on 3D segmentation tasks."
            },
            "venue": {
                "fragments": [],
                "text": "2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2018
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "10714572"
                        ],
                        "name": "Roman Klokov",
                        "slug": "Roman-Klokov",
                        "structuredName": {
                            "firstName": "Roman",
                            "lastName": "Klokov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Roman Klokov"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1740145"
                        ],
                        "name": "V. Lempitsky",
                        "slug": "V.-Lempitsky",
                        "structuredName": {
                            "firstName": "Victor",
                            "lastName": "Lempitsky",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Lempitsky"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9597281,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f48d322244c906b45792b28206df7cfb23495004",
            "isKey": false,
            "numCitedBy": 699,
            "numCiting": 44,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a new deep learning architecture (called Kdnetwork) that is designed for 3D model recognition tasks and works with unstructured point clouds. The new architecture performs multiplicative transformations and shares parameters of these transformations according to the subdivisions of the point clouds imposed onto them by kdtrees. Unlike the currently dominant convolutional architectures that usually require rasterization on uniform twodimensional or three-dimensional grids, Kd-networks do not rely on such grids in any way and therefore avoid poor scaling behavior. In a series of experiments with popular shape recognition benchmarks, Kd-networks demonstrate competitive performance in a number of shape recognition tasks such as shape classification, shape retrieval and shape part segmentation."
            },
            "slug": "Escape-from-Cells:-Deep-Kd-Networks-for-the-of-3D-Klokov-Lempitsky",
            "title": {
                "fragments": [],
                "text": "Escape from Cells: Deep Kd-Networks for the Recognition of 3D Point Cloud Models"
            },
            "tldr": {
                "abstractSimilarityScore": 65,
                "text": "A new deep learning architecture that is designed for 3D model recognition tasks and works with unstructured point clouds, Kd-networks, which demonstrates competitive performance in a number of shape recognition tasks such as shape classification, shape retrieval and shape part segmentation."
            },
            "venue": {
                "fragments": [],
                "text": "2017 IEEE International Conference on Computer Vision (ICCV)"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40902317"
                        ],
                        "name": "Matan Atzmon",
                        "slug": "Matan-Atzmon",
                        "structuredName": {
                            "firstName": "Matan",
                            "lastName": "Atzmon",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Matan Atzmon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3416939"
                        ],
                        "name": "Haggai Maron",
                        "slug": "Haggai-Maron",
                        "structuredName": {
                            "firstName": "Haggai",
                            "lastName": "Maron",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Haggai Maron"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3232072"
                        ],
                        "name": "Y. Lipman",
                        "slug": "Y.-Lipman",
                        "structuredName": {
                            "firstName": "Yaron",
                            "lastName": "Lipman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Lipman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 32,
                                "start": 12
                            }
                        ],
                        "text": "2017), PCNN (Atzmon et al. 2018), and PointCNN (Li et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 92,
                                "start": 72
                            }
                        ],
                        "text": "2017a) \u2211 h\u03b8 m,wn (xi , xj ) = \u03b8m \u00b7 (xj \u0434w n (u (xi , xj ))) wn ,\u03b8m PCNN (Atzmon et al. 2018) \u2211 h\u03b8 m (xi , xj ) = (\u03b8m \u00b7 xj )\u0434(u (xi , xj )) \u03b8m"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 35,
                                "start": 15
                            }
                        ],
                        "text": "Note that PCNN (Atzmon et al. 2018) uses additional augmentation techniques like randomly sampling 1,024 points out of 1,200 points during both training and testing."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 51,
                                "start": 31
                            }
                        ],
                        "text": "2017), and the concurrent work (Atzmon et al. 2018) are themost related approaches."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 4412075,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "04b54d8c4a327f143c3d00fc432740e1183f2337",
            "isKey": true,
            "numCitedBy": 305,
            "numCiting": 87,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents Point Convolutional Neural Networks (PCNN): a novel framework for applying convolutional neural networks to point clouds. The framework consists of two operators: extension and restriction, mapping point cloud functions to volumetric functions and vise-versa. A point cloud convolution is defined by pull-back of the Euclidean volumetric convolution via an extension-restriction mechanism. The point cloud convolution is computationally efficient, invariant to the order of points in the point cloud, robust to different samplings and varying densities, and translation invariant, that is the same convolution kernel is used at all points. PCNN generalizes image CNNs and allows readily adapting their architectures to the point cloud setting. Evaluation of PCNN on three central point cloud learning benchmarks convincingly outperform competing point cloud learning methods, and the vast majority of methods working with more informative shape representations such as surfaces and/or normals."
            },
            "slug": "Point-convolutional-neural-networks-by-extension-Atzmon-Maron",
            "title": {
                "fragments": [],
                "text": "Point convolutional neural networks by extension operators"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "Evaluation of PCNN on three central point cloudlearning benchmarks convincingly outperform competing point cloud learning methods, and the vast majority of methods working with more informative shape representations such as surfaces and/or normals."
            },
            "venue": {
                "fragments": [],
                "text": "ACM Trans. Graph."
            },
            "year": 2018
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144329939"
                        ],
                        "name": "C. Qi",
                        "slug": "C.-Qi",
                        "structuredName": {
                            "firstName": "C.",
                            "lastName": "Qi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Qi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47782132"
                        ],
                        "name": "L. Yi",
                        "slug": "L.-Yi",
                        "structuredName": {
                            "firstName": "L.",
                            "lastName": "Yi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Yi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144914140"
                        ],
                        "name": "Hao Su",
                        "slug": "Hao-Su",
                        "structuredName": {
                            "firstName": "Hao",
                            "lastName": "Su",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hao Su"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1744254"
                        ],
                        "name": "L. Guibas",
                        "slug": "L.-Guibas",
                        "structuredName": {
                            "firstName": "Leonidas",
                            "lastName": "Guibas",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Guibas"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "] 83.0 85.9 Subvolume [Qi et al. 2016] 86.0 89.2 VRN (single view) [Brock et al. 2016] 88.98 - VRN (multiple views) [Brock et al. 2016] 91.33 - ECC [Simonovsky and Komodakis 2017] 83.2 87.4 PointNet [Qi et al. 2017b] 86.0 89.2 PointNet++ [Qi et al. 2017c] - 90.7 Kd-net [Klokov and Lempitsky 2017] - 90.6 PointCNN [Li et al. 2018a] 88.1 92.2 PCNN [Atzmon et al. 2018] - 92.3 Ours (baseline) 88.9 91.7 Ours 90.2 92."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "igned specifically to handle the irregularity of point clouds, directly manipulating raw pointclouddataratherthanpassingtoanintermediateregularrepresentation. This approach was pioneered by PointNet [Qi et al. 2017b], which achieves permutation invariance of points by operating on each point independently and subsequently applying a symmetric function to accumulate features. Various extensions of PointNet consi"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "ions [Klokov and Lempitsky 2017; Maturana and Scherer 2015; Tatarchenko et al. 2017; Wu et al. 2015]\u2014or their combination [Qi et al. 2016]\u2014\u201cplace\u201d geometric data onto a grid. More recently, PointNet [Qi et al. 2017b,c] exemplifies a broad class of deep learning architectures on non-Euclidean data (graphs and manifolds) termed geometric deep learning [Bronstein et al. 2017]. These date back to early methods to c"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "rticle 1. Publication date: January 2019. 1:6 \u2022 Yue Wang, Yongbin Sun, Ziwei Liu, Sanjay E. Sarma, Michael M. Bronstein, and Justin M. Solomon Aggregation Edge Function Learnable parameters PointNet [Qi et al. 2017b] \u2014 h\u0398(x i,xj)= h\u0398(x ) \u0398 PointNet++ [Qi et al. 2017c] max h\u0398(xi,x j)= h\u0398(x ) \u0398 MoNet [Monti et al. 2017a] \u02dd h\u03b8 m,wn (xi,xj)= \u03b8 m\u00b7(xj \u2299\u0434w n (u(xi,xj))) wn,\u03b8 PCNN [Atzmon et al. 2018] \u02dd h\u03b8 m (x i,x j)="
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "echniques in the presence of noise. A few of the many recent applications of point cloud processing and analysis include indoor navigation [Zhu et al. 2017], self-driving vehicles [Liang et al. 2018; Qi et al. 2017a; Wang et al. 2018b], robotics [Rusu et al. 2008b], and shape synthesis and modeling [Golovinskiy et al. 2009; Guerrero et al. 2018]. These modern applications demand high-level processing of point c"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1745976,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8674494bd7a076286b905912d26d47f7501c4046",
            "isKey": true,
            "numCitedBy": 4152,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": "Few prior works study deep learning on point sets. PointNet by Qi et al. is a pioneer in this direction. However, by design PointNet does not capture local structures induced by the metric space points live in, limiting its ability to recognize fine-grained patterns and generalizability to complex scenes. In this work, we introduce a hierarchical neural network that applies PointNet recursively on a nested partitioning of the input point set. By exploiting metric space distances, our network is able to learn local features with increasing contextual scales. With further observation that point sets are usually sampled with varying densities, which results in greatly decreased performance for networks trained on uniform densities, we propose novel set learning layers to adaptively combine features from multiple scales. Experiments show that our network called PointNet++ is able to learn deep point set features efficiently and robustly. In particular, results significantly better than state-of-the-art have been obtained on challenging benchmarks of 3D point clouds."
            },
            "slug": "PointNet++:-Deep-Hierarchical-Feature-Learning-on-a-Qi-Yi",
            "title": {
                "fragments": [],
                "text": "PointNet++: Deep Hierarchical Feature Learning on Point Sets in a Metric Space"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A hierarchical neural network that applies PointNet recursively on a nested partitioning of the input point set and proposes novel set learning layers to adaptively combine features from multiple scales to learn deep point set features efficiently and robustly."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2116729195"
                        ],
                        "name": "Chun-Liang Li",
                        "slug": "Chun-Liang-Li",
                        "structuredName": {
                            "firstName": "Chun-Liang",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chun-Liang Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1771307"
                        ],
                        "name": "M. Zaheer",
                        "slug": "M.-Zaheer",
                        "structuredName": {
                            "firstName": "Manzil",
                            "lastName": "Zaheer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Zaheer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2145953857"
                        ],
                        "name": "Yang Zhang",
                        "slug": "Yang-Zhang",
                        "structuredName": {
                            "firstName": "Yang",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yang Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1719347"
                        ],
                        "name": "B. P\u00f3czos",
                        "slug": "B.-P\u00f3czos",
                        "structuredName": {
                            "firstName": "Barnab\u00e1s",
                            "lastName": "P\u00f3czos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. P\u00f3czos"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145124475"
                        ],
                        "name": "R. Salakhutdinov",
                        "slug": "R.-Salakhutdinov",
                        "structuredName": {
                            "firstName": "Ruslan",
                            "lastName": "Salakhutdinov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Salakhutdinov"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 123,
                                "start": 71
                            }
                        ],
                        "text": "For point clouds, multiple generative architectures have been proposed [Fan et al. 2017; Li et al. 2018b; Yang et al. 2018]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 53114704,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "170e2f4778f975768aaa5e888349fc0cb23d576f",
            "isKey": false,
            "numCitedBy": 93,
            "numCiting": 67,
            "paperAbstract": {
                "fragments": [],
                "text": "Generative Adversarial Networks (GAN) can achieve promising performance on learning complex data distributions on different types of data. In this paper, we first show a straightforward extension of existing GAN algorithm is not applicable to point clouds, because the constraint required for discriminators is undefined for set data. We propose a two fold modification to GAN algorithm for learning to generate point clouds (PC-GAN). First, we combine ideas from hierarchical Bayesian modeling and implicit generative models by learning a hierarchical and interpretable sampling process. A key component of our method is that we train a posterior inference network for the hidden variables. Second, instead of using only state-of-the-art Wasserstein GAN objective, we propose a sandwiching objective, which results in a tighter Wasserstein distance estimate than the commonly used dual form. Thereby, PC-GAN defines a generic framework that can incorporate many existing GAN algorithms. We validate our claims on ModelNet40 benchmark dataset. Using the distance between generated point clouds and true meshes as metric, we find that PC-GAN trained by the sandwiching objective achieves better results on test data than the existing methods. Moreover, as a byproduct, PC- GAN learns versatile latent representations of point clouds, which can achieve competitive performance with other unsupervised learning algorithms on object recognition task. Lastly, we also provide studies on generating unseen classes of objects and transforming image to point cloud, which demonstrates the compelling generalization capability and potentials of PC-GAN."
            },
            "slug": "Point-Cloud-GAN-Li-Zaheer",
            "title": {
                "fragments": [],
                "text": "Point Cloud GAN"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "A two fold modification to GAN algorithm for learning to generate point clouds (PC-GAN), which combines ideas from hierarchical Bayesian modeling and implicit generative models by learning a hierarchical and interpretable sampling process and defines a generic framework that can incorporate many existing GAN algorithms."
            },
            "venue": {
                "fragments": [],
                "text": "DGS@ICLR"
            },
            "year": 2019
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144329939"
                        ],
                        "name": "C. Qi",
                        "slug": "C.-Qi",
                        "structuredName": {
                            "firstName": "C.",
                            "lastName": "Qi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Qi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144914140"
                        ],
                        "name": "Hao Su",
                        "slug": "Hao-Su",
                        "structuredName": {
                            "firstName": "Hao",
                            "lastName": "Su",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hao Su"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2209612"
                        ],
                        "name": "M. Nie\u00dfner",
                        "slug": "M.-Nie\u00dfner",
                        "structuredName": {
                            "firstName": "Matthias",
                            "lastName": "Nie\u00dfner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Nie\u00dfner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2208531"
                        ],
                        "name": "Angela Dai",
                        "slug": "Angela-Dai",
                        "structuredName": {
                            "firstName": "Angela",
                            "lastName": "Dai",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Angela Dai"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3235234"
                        ],
                        "name": "Mengyuan Yan",
                        "slug": "Mengyuan-Yan",
                        "structuredName": {
                            "firstName": "Mengyuan",
                            "lastName": "Yan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mengyuan Yan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1744254"
                        ],
                        "name": "L. Guibas",
                        "slug": "L.-Guibas",
                        "structuredName": {
                            "firstName": "Leonidas",
                            "lastName": "Guibas",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Guibas"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "2015]\u2014or their combination [Qi et al. 2016]\u2014\u201cplace\u201d geometric data onto a grid."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Subvolume [Qi et al. 2016] 86."
                    },
                    "intents": []
                }
            ],
            "corpusId": 1009127,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4cdcf2ae5e1fafebd9b3613247a7b1962584da34",
            "isKey": false,
            "numCitedBy": 1191,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": "3D shape models are becoming widely available and easier to capture, making available 3D information crucial for progress in object classification. Current state-of-theart methods rely on CNNs to address this problem. Recently, we witness two types of CNNs being developed: CNNs based upon volumetric representations versus CNNs based upon multi-view representations. Empirical results from these two types of CNNs exhibit a large gap, indicating that existing volumetric CNN architectures and approaches are unable to fully exploit the power of 3D representations. In this paper, we aim to improve both volumetric CNNs and multi-view CNNs according to extensive analysis of existing approaches. To this end, we introduce two distinct network architectures of volumetric CNNs. In addition, we examine multi-view CNNs, where we introduce multiresolution filtering in 3D. Overall, we are able to outperform current state-of-the-art methods for both volumetric CNNs and multi-view CNNs. We provide extensive experiments designed to evaluate underlying design choices, thus providing a better understanding of the space of methods available for object classification on 3D data."
            },
            "slug": "Volumetric-and-Multi-view-CNNs-for-Object-on-3D-Qi-Su",
            "title": {
                "fragments": [],
                "text": "Volumetric and Multi-view CNNs for Object Classification on 3D Data"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This paper introduces two distinct network architectures of volumetric CNNs and examines multi-view CNNs, providing a better understanding of the space of methods available for object classification on 3D data."
            },
            "venue": {
                "fragments": [],
                "text": "2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47782132"
                        ],
                        "name": "L. Yi",
                        "slug": "L.-Yi",
                        "structuredName": {
                            "firstName": "L.",
                            "lastName": "Yi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Yi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144914140"
                        ],
                        "name": "Hao Su",
                        "slug": "Hao-Su",
                        "structuredName": {
                            "firstName": "Hao",
                            "lastName": "Su",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hao Su"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8395288"
                        ],
                        "name": "Xingwen Guo",
                        "slug": "Xingwen-Guo",
                        "structuredName": {
                            "firstName": "Xingwen",
                            "lastName": "Guo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xingwen Guo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1744254"
                        ],
                        "name": "L. Guibas",
                        "slug": "L.-Guibas",
                        "structuredName": {
                            "firstName": "Leonidas",
                            "lastName": "Guibas",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Guibas"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "ulty, however, is that the Laplacian eigenbasis is domain-dependent; thus, a \ufb01lter learned on one shape may not generalize to others. Spectral transformer networks address this problem to some extent [56]. An alternative de\ufb01nition of non-Euclidean convolution employs spatial rather than spectral \ufb01lters. The Geodesic CNN (GCNN) is a deep CNN on meshes generalizing the notion of patches using local intr"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14487589,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ade1b1bfe2abefbcfe324499aa284db2b8fc50a6",
            "isKey": false,
            "numCitedBy": 367,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we study the problem of semantic annotation on 3D models that are represented as shape graphs. A functional view is taken to represent localized information on graphs, so that annotations such as part segment or keypoint are nothing but 0-1 indicator vertex functions. Compared with images that are 2D grids, shape graphs are irregular and non-isomorphic data structures. To enable the prediction of vertex functions on them by convolutional neural networks, we resort to spectral CNN method that enables weight sharing by parametrizing kernels in the spectral domain spanned by graph Laplacian eigenbases. Under this setting, our network, named SyncSpecCNN, strives to overcome two key challenges: how to share coefficients and conduct multi-scale analysis in different parts of the graph for a single shape, and how to share information across related but different shapes that may be represented by very different graphs. Towards these goals, we introduce a spectral parametrization of dilated convolutional kernels and a spectral transformer network. Experimentally we tested SyncSpecCNN on various tasks, including 3D shape part segmentation and keypoint prediction. State-of-the-art performance has been achieved on all benchmark datasets."
            },
            "slug": "SyncSpecCNN:-Synchronized-Spectral-CNN-for-3D-Shape-Yi-Su",
            "title": {
                "fragments": [],
                "text": "SyncSpecCNN: Synchronized Spectral CNN for 3D Shape Segmentation"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This paper introduces a spectral parametrization of dilated convolutional kernels and a spectral transformer network that enables weight sharing by parametrizing kernels in the spectral domain spanned by graph Laplacian eigenbases and strives to overcome two key challenges: how to share coefficients and conduct multi-scale analysis in different parts of the graph for a single shape."
            },
            "venue": {
                "fragments": [],
                "text": "2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1934546"
                        ],
                        "name": "Haoqiang Fan",
                        "slug": "Haoqiang-Fan",
                        "structuredName": {
                            "firstName": "Haoqiang",
                            "lastName": "Fan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Haoqiang Fan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144914140"
                        ],
                        "name": "Hao Su",
                        "slug": "Hao-Su",
                        "structuredName": {
                            "firstName": "Hao",
                            "lastName": "Su",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hao Su"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1744254"
                        ],
                        "name": "L. Guibas",
                        "slug": "L.-Guibas",
                        "structuredName": {
                            "firstName": "Leonidas",
                            "lastName": "Guibas",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Guibas"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "For point clouds, multiple generative architectures have been proposed [Fan et al. 2017; Li et al. 2018b; Yang et al. 2018]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 6746759,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "41d08fb733f3e50ac183490f84d6377dffccf350",
            "isKey": false,
            "numCitedBy": 1188,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "Generation of 3D data by deep neural network has been attracting increasing attention in the research community. The majority of extant works resort to regular representations such as volumetric grids or collection of images, however, these representations obscure the natural invariance of 3D shapes under geometric transformations, and also suffer from a number of other issues. In this paper we address the problem of 3D reconstruction from a single image, generating a straight-forward form of output &#x2013; point cloud coordinates. Along with this problem arises a unique and interesting issue, that the groundtruth shape for an input image may be ambiguous. Driven by this unorthordox output form and the inherent ambiguity in groundtruth, we design architecture, loss function and learning paradigm that are novel and effective. Our final solution is a conditional shape sampler, capable of predicting multiple plausible 3D point clouds from an input image. In experiments not only can our system outperform state-of-the-art methods on single image based 3D reconstruction benchmarks, but it also shows strong performance for 3D shape completion and promising ability in making multiple plausible predictions."
            },
            "slug": "A-Point-Set-Generation-Network-for-3D-Object-from-a-Fan-Su",
            "title": {
                "fragments": [],
                "text": "A Point Set Generation Network for 3D Object Reconstruction from a Single Image"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This paper addresses the problem of 3D reconstruction from a single image, generating a straight-forward form of output unorthordox, and designs architecture, loss function and learning paradigm that are novel and effective, capable of predicting multiple plausible 3D point clouds from an input image."
            },
            "venue": {
                "fragments": [],
                "text": "2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3414491"
                        ],
                        "name": "Francis Engelmann",
                        "slug": "Francis-Engelmann",
                        "structuredName": {
                            "firstName": "Francis",
                            "lastName": "Engelmann",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Francis Engelmann"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8413536"
                        ],
                        "name": "Theodora Kontogianni",
                        "slug": "Theodora-Kontogianni",
                        "structuredName": {
                            "firstName": "Theodora",
                            "lastName": "Kontogianni",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Theodora Kontogianni"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "36665147"
                        ],
                        "name": "Alexander Hermans",
                        "slug": "Alexander-Hermans",
                        "structuredName": {
                            "firstName": "Alexander",
                            "lastName": "Hermans",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alexander Hermans"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1789756"
                        ],
                        "name": "B. Leibe",
                        "slug": "B.-Leibe",
                        "structuredName": {
                            "firstName": "B.",
                            "lastName": "Leibe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Leibe"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "seline, where additional point features (local point density, local curvature and normal) are used to construct handcrafted features and then fed to an MLP classi\ufb01er. We further compare our work with [12], who present network architectures to enlarge the receptive \ufb01eld over the 3D scene. Two different approaches are proposed in their work: MS+CU for multi-scale block features with consolidation units;"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "evaluation results in Table 6, and visually compare the results of PointNet and our model in Figure 13. MEAN OVERALL IOU ACCURACY POINTNET (BASELINE) [34] 20.1 53.2 POINTNET [34] 47.6 78.5 MS + CU(2) [12] 47.8 79.2 G + RCU [12] 49.7 81.1 OURS 56.1 84.1 Table 6. 3D semantic segmentation results on S3DIS. MS+CU for multi-scale block features with consolidation units; G+RCU for the grid-blocks with recur"
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                }
            ],
            "corpusId": 3609891,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d734a8365f7dab731a698cf77a8588b44166b4b2",
            "isKey": true,
            "numCitedBy": 190,
            "numCiting": 41,
            "paperAbstract": {
                "fragments": [],
                "text": "Deep learning approaches have made tremendous progress in the field of semantic segmentation over the past few years. However, most current approaches operate in the 2D image space. Direct semantic segmentation of unstructured 3D point clouds is still an open research problem. The recently proposed PointNet architecture presents an interesting step ahead in that it can operate on unstructured point clouds, achieving encouraging segmentation results. However, it subdivides the input points into a grid of blocks and processes each such block individually. In this paper, we investigate the question how such an architecture can be extended to incorporate larger-scale spatial context. We build upon PointNet and propose two extensions that enlarge the receptive field over the 3D scene. We evaluate the proposed strategies on challenging indoor and outdoor datasets and show improved results in both scenarios."
            },
            "slug": "Exploring-Spatial-Context-for-3D-Semantic-of-Point-Engelmann-Kontogianni",
            "title": {
                "fragments": [],
                "text": "Exploring Spatial Context for 3D Semantic Segmentation of Point Clouds"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This paper builds upon PointNet and proposes two extensions that enlarge the receptive field over the 3D scene and evaluates the proposed strategies on challenging indoor and outdoor datasets and shows improved results in both scenarios."
            },
            "venue": {
                "fragments": [],
                "text": "2017 IEEE International Conference on Computer Vision Workshops (ICCVW)"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152247501"
                        ],
                        "name": "Zhirong Wu",
                        "slug": "Zhirong-Wu",
                        "structuredName": {
                            "firstName": "Zhirong",
                            "lastName": "Wu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zhirong Wu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3340170"
                        ],
                        "name": "S. Song",
                        "slug": "S.-Song",
                        "structuredName": {
                            "firstName": "Shuran",
                            "lastName": "Song",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Song"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2556428"
                        ],
                        "name": "A. Khosla",
                        "slug": "A.-Khosla",
                        "structuredName": {
                            "firstName": "Aditya",
                            "lastName": "Khosla",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Khosla"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1807197"
                        ],
                        "name": "F. Yu",
                        "slug": "F.-Yu",
                        "structuredName": {
                            "firstName": "Fisher",
                            "lastName": "Yu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Yu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3064662"
                        ],
                        "name": "Linguang Zhang",
                        "slug": "Linguang-Zhang",
                        "structuredName": {
                            "firstName": "Linguang",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Linguang Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50295995"
                        ],
                        "name": "Xiaoou Tang",
                        "slug": "Xiaoou-Tang",
                        "structuredName": {
                            "firstName": "Xiaoou",
                            "lastName": "Tang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xiaoou Tang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40599257"
                        ],
                        "name": "Jianxiong Xiao",
                        "slug": "Jianxiong-Xiao",
                        "structuredName": {
                            "firstName": "Jianxiong",
                            "lastName": "Xiao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jianxiong Xiao"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 206592833,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7c8a51d04522496c43db68f2582efd45eaf59fea",
            "isKey": false,
            "numCitedBy": 3086,
            "numCiting": 45,
            "paperAbstract": {
                "fragments": [],
                "text": "3D shape is a crucial but heavily underutilized cue in today's computer vision systems, mostly due to the lack of a good generic shape representation. With the recent availability of inexpensive 2.5D depth sensors (e.g. Microsoft Kinect), it is becoming increasingly important to have a powerful 3D shape representation in the loop. Apart from category recognition, recovering full 3D shapes from view-based 2.5D depth maps is also a critical part of visual understanding. To this end, we propose to represent a geometric 3D shape as a probability distribution of binary variables on a 3D voxel grid, using a Convolutional Deep Belief Network. Our model, 3D ShapeNets, learns the distribution of complex 3D shapes across different object categories and arbitrary poses from raw CAD data, and discovers hierarchical compositional part representation automatically. It naturally supports joint object recognition and shape completion from 2.5D depth maps, and it enables active object recognition through view planning. To train our 3D deep learning model, we construct ModelNet - a large-scale 3D CAD model dataset. Extensive experiments show that our 3D deep representation enables significant performance improvement over the-state-of-the-arts in a variety of tasks."
            },
            "slug": "3D-ShapeNets:-A-deep-representation-for-volumetric-Wu-Song",
            "title": {
                "fragments": [],
                "text": "3D ShapeNets: A deep representation for volumetric shapes"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This work proposes to represent a geometric 3D shape as a probability distribution of binary variables on a 3D voxel grid, using a Convolutional Deep Belief Network, and shows that this 3D deep representation enables significant performance improvement over the-state-of-the-arts in a variety of tasks."
            },
            "venue": {
                "fragments": [],
                "text": "2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3416939"
                        ],
                        "name": "Haggai Maron",
                        "slug": "Haggai-Maron",
                        "structuredName": {
                            "firstName": "Haggai",
                            "lastName": "Maron",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Haggai Maron"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2991672"
                        ],
                        "name": "M. Galun",
                        "slug": "M.-Galun",
                        "structuredName": {
                            "firstName": "Meirav",
                            "lastName": "Galun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Galun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2248475"
                        ],
                        "name": "Noam Aigerman",
                        "slug": "Noam-Aigerman",
                        "structuredName": {
                            "firstName": "Noam",
                            "lastName": "Aigerman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Noam Aigerman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145586857"
                        ],
                        "name": "M. Trope",
                        "slug": "M.-Trope",
                        "structuredName": {
                            "firstName": "M.",
                            "lastName": "Trope",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Trope"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3046344"
                        ],
                        "name": "Nadav Dym",
                        "slug": "Nadav-Dym",
                        "structuredName": {
                            "firstName": "Nadav",
                            "lastName": "Dym",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nadav Dym"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8020964"
                        ],
                        "name": "Ersin Yumer",
                        "slug": "Ersin-Yumer",
                        "structuredName": {
                            "firstName": "Ersin",
                            "lastName": "Yumer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ersin Yumer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3082383"
                        ],
                        "name": "Vladimir G. Kim",
                        "slug": "Vladimir-G.-Kim",
                        "structuredName": {
                            "firstName": "Vladimir",
                            "lastName": "Kim",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Vladimir G. Kim"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3232072"
                        ],
                        "name": "Y. Lipman",
                        "slug": "Y.-Lipman",
                        "structuredName": {
                            "firstName": "Yaron",
                            "lastName": "Lipman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Lipman"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 215762985,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f7cf506bcec60de34469b8399acc92406f6ecbc6",
            "isKey": false,
            "numCitedBy": 163,
            "numCiting": 47,
            "paperAbstract": {
                "fragments": [],
                "text": "The recent success of convolutional neural networks (CNNs) for image processing tasks is inspiring research efforts attempting to achieve similar success for geometric tasks. One of the main challenges in applying CNNs to surfaces is defining a natural convolution operator on surfaces. In this paper we present a method for applying deep learning to sphere-type shapes using a global seamless parameterization to a planar flat-torus, for which the convolution operator is well defined. As a result, the standard deep learning framework can be readily applied for learning semantic, high-level properties of the shape. An indication of our success in bridging the gap between images and surfaces is the fact that our algorithm succeeds in learning semantic information from an input of raw low-dimensional feature vectors. We demonstrate the usefulness of our approach by presenting two applications: human body segmentation, and automatic landmark detection on anatomical surfaces. We show that our algorithm compares favorably with competing geometric deep-learning algorithms for segmentation tasks, and is able to produce meaningful correspondences on anatomical surfaces where hand-crafted features are bound to fail."
            },
            "slug": "Convolutional-neural-networks-on-surfaces-via-toric-Maron-Galun",
            "title": {
                "fragments": [],
                "text": "Convolutional neural networks on surfaces via seamless toric covers"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This paper presents a method for applying deep learning to sphere-type shapes using a global seamless parameterization to a planar flat-torus, for which the convolution operator is well defined and the standard deep learning framework can be readily applied for learning semantic, high-level properties of the shape."
            },
            "venue": {
                "fragments": [],
                "text": "ACM Trans. Graph."
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2500309"
                        ],
                        "name": "Federico Monti",
                        "slug": "Federico-Monti",
                        "structuredName": {
                            "firstName": "Federico",
                            "lastName": "Monti",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Federico Monti"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1804261"
                        ],
                        "name": "D. Boscaini",
                        "slug": "D.-Boscaini",
                        "structuredName": {
                            "firstName": "D.",
                            "lastName": "Boscaini",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Boscaini"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2426718"
                        ],
                        "name": "Jonathan Masci",
                        "slug": "Jonathan-Masci",
                        "structuredName": {
                            "firstName": "Jonathan",
                            "lastName": "Masci",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jonathan Masci"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1796150"
                        ],
                        "name": "E. Rodol\u00e0",
                        "slug": "E.-Rodol\u00e0",
                        "structuredName": {
                            "firstName": "Emanuele",
                            "lastName": "Rodol\u00e0",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Rodol\u00e0"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2064928589"
                        ],
                        "name": "Jan Svoboda",
                        "slug": "Jan-Svoboda",
                        "structuredName": {
                            "firstName": "Jan",
                            "lastName": "Svoboda",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jan Svoboda"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1732570"
                        ],
                        "name": "M. Bronstein",
                        "slug": "M.-Bronstein",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Bronstein",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Bronstein"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 301319,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f09f7888aa5aeaf88a2a44aea768d9a8747e97d2",
            "isKey": false,
            "numCitedBy": 1185,
            "numCiting": 72,
            "paperAbstract": {
                "fragments": [],
                "text": "Deep learning has achieved a remarkable performance breakthrough in several fields, most notably in speech recognition, natural language processing, and computer vision. In particular, convolutional neural network (CNN) architectures currently produce state-of-the-art performance on a variety of image analysis tasks such as object detection and recognition. Most of deep learning research has so far focused on dealing with 1D, 2D, or 3D Euclidean-structured data such as acoustic signals, images, or videos. Recently, there has been an increasing interest in geometric deep learning, attempting to generalize deep learning methods to non-Euclidean structured data such as graphs and manifolds, with a variety of applications from the domains of network analysis, computational social science, or computer graphics. In this paper, we propose a unified framework allowing to generalize CNN architectures to non-Euclidean domains (graphs and manifolds) and learn local, stationary, and compositional task-specific features. We show that various non-Euclidean CNN methods previously proposed in the literature can be considered as particular instances of our framework. We test the proposed method on standard tasks from the realms of image-, graph-and 3D shape analysis and show that it consistently outperforms previous approaches."
            },
            "slug": "Geometric-Deep-Learning-on-Graphs-and-Manifolds-Monti-Boscaini",
            "title": {
                "fragments": [],
                "text": "Geometric Deep Learning on Graphs and Manifolds Using Mixture Model CNNs"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This paper proposes a unified framework allowing to generalize CNN architectures to non-Euclidean domains (graphs and manifolds) and learn local, stationary, and compositional task-specific features and test the proposed method on standard tasks from the realms of image-, graph-and 3D shape analysis and show that it consistently outperforms previous approaches."
            },
            "venue": {
                "fragments": [],
                "text": "2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3410500"
                        ],
                        "name": "Matthias Fey",
                        "slug": "Matthias-Fey",
                        "structuredName": {
                            "firstName": "Matthias",
                            "lastName": "Fey",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Matthias Fey"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9572099"
                        ],
                        "name": "J. E. Lenssen",
                        "slug": "J.-E.-Lenssen",
                        "structuredName": {
                            "firstName": "Jan",
                            "lastName": "Lenssen",
                            "middleNames": [
                                "Eric"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. E. Lenssen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2595376"
                        ],
                        "name": "F. Weichert",
                        "slug": "F.-Weichert",
                        "structuredName": {
                            "firstName": "Frank",
                            "lastName": "Weichert",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Weichert"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2151194196"
                        ],
                        "name": "H. M\u00fcller",
                        "slug": "H.-M\u00fcller",
                        "structuredName": {
                            "firstName": "Heinrich",
                            "lastName": "M\u00fcller",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. M\u00fcller"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "the shape into a domain with shift-invariant structure such as the sphere [Sinha et al. 2016], torus [Maron et al. 2017], plane [Ezuz et al. 2017], sparse network lattice [Su et al. 2018], or spline [Fey et al. 2018]. Finally, we should mention geometric generative models, which attempt to generalize models such as autoencoders, variational autoencoders (VAE) [Kingma and Welling 2013], and generative adversarial"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 21694791,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a73531abe4cafbccd5b3e949e84410a50016bd33",
            "isKey": false,
            "numCitedBy": 268,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "We present Spline-based Convolutional Neural Networks (SplineCNNs), a variant of deep neural networks for irregular structured and geometric input, e.g., graphs or meshes. Our main contribution is a novel convolution operator based on B-splines, that makes the computation time independent from the kernel size due to the local support property of the B-spline basis functions. As a result, we obtain a generalization of the traditional CNN convolution operator by using continuous kernel functions parametrized by a fixed number of trainable weights. In contrast to related approaches that filter in the spectral domain, the proposed method aggregates features purely in the spatial domain. In addition, SplineCNN allows entire end-to-end training of deep architectures, using only the geometric structure as input, instead of handcrafted feature descriptors. For validation, we apply our method on tasks from the fields of image graph classification, shape correspondence and graph node classification, and show that it outperforms or pars state-of-the-art approaches while being significantly faster and having favorable properties like domain-independence. Our source code is available on GitHub1."
            },
            "slug": "SplineCNN:-Fast-Geometric-Deep-Learning-with-Fey-Lenssen",
            "title": {
                "fragments": [],
                "text": "SplineCNN: Fast Geometric Deep Learning with Continuous B-Spline Kernels"
            },
            "tldr": {
                "abstractSimilarityScore": 72,
                "text": "This work presents Spline-based Convolutional Neural Networks (SplineCNNs), a variant of deep neural networks for irregular structured and geometric input, e.g., graphs or meshes, that is a generalization of the traditional CNN convolution operator by using continuous kernel functions parametrized by a fixed number of trainable weights."
            },
            "venue": {
                "fragments": [],
                "text": "2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2018
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144329939"
                        ],
                        "name": "C. Qi",
                        "slug": "C.-Qi",
                        "structuredName": {
                            "firstName": "C.",
                            "lastName": "Qi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Qi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46641573"
                        ],
                        "name": "W. Liu",
                        "slug": "W.-Liu",
                        "structuredName": {
                            "firstName": "W.",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Liu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2484982"
                        ],
                        "name": "Chenxia Wu",
                        "slug": "Chenxia-Wu",
                        "structuredName": {
                            "firstName": "Chenxia",
                            "lastName": "Wu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chenxia Wu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1423723631"
                        ],
                        "name": "Hao Su",
                        "slug": "Hao-Su",
                        "structuredName": {
                            "firstName": "Hao",
                            "lastName": "Su",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hao Su"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1744254"
                        ],
                        "name": "L. Guibas",
                        "slug": "L.-Guibas",
                        "structuredName": {
                            "firstName": "Leonidas",
                            "lastName": "Guibas",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Guibas"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "rations or instability of these techniques in the presence of noise. A few of the many recent applications of point cloud processing and analysis include indoor navigation [57], self-driving vehicles [33], robotics [40], and shape synthesis and modeling [14]. Modern applications demand high-level processing of point clouds. Rather than identifying salient geometric features like corners and edges, rec"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 4868248,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "526cf249c2760b7bdbb28f2a2a7c85851d3c2727",
            "isKey": false,
            "numCitedBy": 1261,
            "numCiting": 44,
            "paperAbstract": {
                "fragments": [],
                "text": "In this work, we study 3D object detection from RGBD data in both indoor and outdoor scenes. While previous methods focus on images or 3D voxels, often obscuring natural 3D patterns and invariances of 3D data, we directly operate on raw point clouds by popping up RGB-D scans. However, a key challenge of this approach is how to efficiently localize objects in point clouds of large-scale scenes (region proposal). Instead of solely relying on 3D proposals, our method leverages both mature 2D object detectors and advanced 3D deep learning for object localization, achieving efficiency as well as high recall for even small objects. Benefited from learning directly in raw point clouds, our method is also able to precisely estimate 3D bounding boxes even under strong occlusion or with very sparse points. Evaluated on KITTI and SUN RGB-D 3D detection benchmarks, our method outperforms the state of the art by remarkable margins while having real-time capability."
            },
            "slug": "Frustum-PointNets-for-3D-Object-Detection-from-Data-Qi-Liu",
            "title": {
                "fragments": [],
                "text": "Frustum PointNets for 3D Object Detection from RGB-D Data"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This work directly operates on raw point clouds by popping up RGBD scans and leverages both mature 2D object detectors and advanced 3D deep learning for object localization, achieving efficiency as well as high recall for even small objects."
            },
            "venue": {
                "fragments": [],
                "text": "2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2018
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2689311"
                        ],
                        "name": "R. Rusu",
                        "slug": "R.-Rusu",
                        "structuredName": {
                            "firstName": "Radu",
                            "lastName": "Rusu",
                            "middleNames": [
                                "Bogdan"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Rusu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1810221"
                        ],
                        "name": "Nico Blodow",
                        "slug": "Nico-Blodow",
                        "structuredName": {
                            "firstName": "Nico",
                            "lastName": "Blodow",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nico Blodow"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1746229"
                        ],
                        "name": "M. Beetz",
                        "slug": "M.-Beetz",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Beetz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Beetz"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "nd segmentation, two model tasks in point cloud processing. Traditional methods for solving these problems employ handcrafted features to capture geometric properties of point clouds [Lu et al. 2014; Rusu et al. 2009, 2008a]. More recently, the success of deep neural networks for image processing has motivated a data-driven approach to learning features on point clouds. Deep point cloud processingandanalysismetho"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 15022990,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "940dd2fa074ad97d5e8efa7e867b1f4460cfb8d5",
            "isKey": false,
            "numCitedBy": 2388,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "In our recent work [1], [2], we proposed Point Feature Histograms (PFH) as robust multi-dimensional features which describe the local geometry around a point p for 3D point cloud datasets. In this paper, we modify their mathematical expressions and perform a rigorous analysis on their robustness and complexity for the problem of 3D registration for overlapping point cloud views. More concretely, we present several optimizations that reduce their computation times drastically by either caching previously computed values or by revising their theoretical formulations. The latter results in a new type of local features, called Fast Point Feature Histograms (FPFH), which retain most of the discriminative power of the PFH. Moreover, we propose an algorithm for the online computation of FPFH features for realtime applications. To validate our results we demonstrate their efficiency for 3D registration and propose a new sample consensus based method for bringing two datasets into the convergence basin of a local non-linear optimizer: SAC-IA (SAmple Consensus Initial Alignment)."
            },
            "slug": "Fast-Point-Feature-Histograms-(FPFH)-for-3D-Rusu-Blodow",
            "title": {
                "fragments": [],
                "text": "Fast Point Feature Histograms (FPFH) for 3D registration"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This paper modifications their mathematical expressions and performs a rigorous analysis on their robustness and complexity for the problem of 3D registration for overlapping point cloud views, and proposes an algorithm for the online computation of FPFH features for realtime applications."
            },
            "venue": {
                "fragments": [],
                "text": "2009 IEEE International Conference on Robotics and Automation"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3365480"
                        ],
                        "name": "Ayan Sinha",
                        "slug": "Ayan-Sinha",
                        "structuredName": {
                            "firstName": "Ayan",
                            "lastName": "Sinha",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ayan Sinha"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2113829925"
                        ],
                        "name": "Jing Bai",
                        "slug": "Jing-Bai",
                        "structuredName": {
                            "firstName": "Jing",
                            "lastName": "Bai",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jing Bai"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144861331"
                        ],
                        "name": "K. Ramani",
                        "slug": "K.-Ramani",
                        "structuredName": {
                            "firstName": "Karthik",
                            "lastName": "Ramani",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Ramani"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 189,
                                "start": 185
                            }
                        ],
                        "text": "The last class of geometric deep learning approaches attempt to pull back a convolution operation by embedding the shape into a domain with shift-invariant structure such as the sphere [46], torus [28], or plane [13]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 8846709,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b1cc562330b933bd5b6af2e909ee1d6283eed934",
            "isKey": false,
            "numCitedBy": 257,
            "numCiting": 40,
            "paperAbstract": {
                "fragments": [],
                "text": "Surfaces serve as a natural parametrization to 3D shapes. Learning surfaces using convolutional neural networks (CNNs) is a challenging task. Current paradigms to tackle this challenge are to either adapt the convolutional filters to operate on surfaces, learn spectral descriptors defined by the Laplace-Beltrami operator, or to drop surfaces altogether in lieu of voxelized inputs. Here we adopt an approach of converting the 3D shape into a \u2018geometry image\u2019 so that standard CNNs can directly be used to learn 3D shapes. We qualitatively and quantitatively validate that creating geometry images using authalic parametrization on a spherical domain is suitable for robust learning of 3D shape surfaces. This spherically parameterized shape is then projected and cut to convert the original 3D shape into a flat and regular geometry image. We propose a way to implicitly learn the topology and structure of 3D shapes using geometry images encoded with suitable features. We show the efficacy of our approach to learn 3D shape surfaces for classification and retrieval tasks on non-rigid and rigid shape datasets."
            },
            "slug": "Deep-Learning-3D-Shape-Surfaces-Using-Geometry-Sinha-Bai",
            "title": {
                "fragments": [],
                "text": "Deep Learning 3D Shape Surfaces Using Geometry Images"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This work qualitatively and quantitatively validate that creating geometry images using authalic parametrization on a spherical domain is suitable for robust learning of 3D shape surfaces, and proposes a way to implicitly learn the topology and structure of3D shapes using geometry images encoded with suitable features."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3451689"
                        ],
                        "name": "Martin Simonovsky",
                        "slug": "Martin-Simonovsky",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "Simonovsky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Martin Simonovsky"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2505902"
                        ],
                        "name": "N. Komodakis",
                        "slug": "N.-Komodakis",
                        "structuredName": {
                            "firstName": "Nikos",
                            "lastName": "Komodakis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Komodakis"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 38,
                                "start": 34
                            }
                        ],
                        "text": "Among graph CNNs, MoNet [31], ECC [45], and Graph Attention Networks [52] are the most related approaches."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 20,
                                "start": 16
                            }
                        ],
                        "text": "1The methods of [45] and [52] can be considered as instances of [31], with the difference that the weights are constructed employing features from the adjacent nodes instead of the graph structure."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 17648673,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1a39bb2caa151d15efd6718f3a80d9f4bff95af2",
            "isKey": false,
            "numCitedBy": 738,
            "numCiting": 51,
            "paperAbstract": {
                "fragments": [],
                "text": "A number of problems can be formulated as prediction on graph-structured data. In this work, we generalize the convolution operator from regular grids to arbitrary graphs while avoiding the spectral domain, which allows us to handle graphs of varying size and connectivity. To move beyond a simple diffusion, filter weights are conditioned on the specific edge labels in the neighborhood of a vertex. Together with the proper choice of graph coarsening, we explore constructing deep neural networks for graph classification. In particular, we demonstrate the generality of our formulation in point cloud classification, where we set the new state of the art, and on a graph classification dataset, where we outperform other deep learning approaches."
            },
            "slug": "Dynamic-Edge-Conditioned-Filters-in-Convolutional-Simonovsky-Komodakis",
            "title": {
                "fragments": [],
                "text": "Dynamic Edge-Conditioned Filters in Convolutional Neural Networks on Graphs"
            },
            "tldr": {
                "abstractSimilarityScore": 57,
                "text": "This work generalizes the convolution operator from regular grids to arbitrary graphs while avoiding the spectral domain, which allows us to handle graphs of varying size and connectivity."
            },
            "venue": {
                "fragments": [],
                "text": "2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2689311"
                        ],
                        "name": "R. Rusu",
                        "slug": "R.-Rusu",
                        "structuredName": {
                            "firstName": "Radu",
                            "lastName": "Rusu",
                            "middleNames": [
                                "Bogdan"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Rusu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1810221"
                        ],
                        "name": "Nico Blodow",
                        "slug": "Nico-Blodow",
                        "structuredName": {
                            "firstName": "Nico",
                            "lastName": "Blodow",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nico Blodow"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1709715"
                        ],
                        "name": "Zolt\u00e1n-Csaba M\u00e1rton",
                        "slug": "Zolt\u00e1n-Csaba-M\u00e1rton",
                        "structuredName": {
                            "firstName": "Zolt\u00e1n-Csaba",
                            "lastName": "M\u00e1rton",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zolt\u00e1n-Csaba M\u00e1rton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1746229"
                        ],
                        "name": "M. Beetz",
                        "slug": "M.-Beetz",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Beetz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Beetz"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "ation and segmentation, two model tasks in the point cloud processing world. Traditional methods for solving these problems employ handcrafted features to capture geometric properties of point clouds [26, 38, 39]. More recently, the success of deep neural networks for image processing has motivated a data-driven approach to learning features on point clouds. Deep point cloud processing and analysis methods ar"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "rom the coordinates of the shape in 3D space and includes classical methods like shape context [3], spin images [17], integral features [27], distance-based descriptors [24], point feature histograms [39, 38], and normal histograms [50], to name a few. Intrinsic descriptors treat the 3D shape as a manifold whose metric structure is discretized as a mesh or graph; quantities expressed in terms of the metri"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1038604,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "aef7f3c512cd9f96a2108b96a717d6d64882e187",
            "isKey": false,
            "numCitedBy": 679,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we investigate the usage of persistent point feature histograms for the problem of aligning point cloud data views into a consistent global model. Given a collection of noisy point clouds, our algorithm estimates a set of robust 16D features which describe the geometry of each point locally. By analyzing the persistence of the features at different scales, we extract an optimal set which best characterizes a given point cloud. The resulted persistent features are used in an initial alignment algorithm to estimate a rigid transformation that approximately registers the input datasets. The algorithm provides good starting points for iterative registration algorithms such as ICP (Iterative Closest Point), by transforming the datasets to its convergence basin. We show that our approach is invariant to pose and sampling density, and can cope well with noisy data coming from both indoor and outdoor laser scans."
            },
            "slug": "Aligning-point-cloud-views-using-persistent-feature-Rusu-Blodow",
            "title": {
                "fragments": [],
                "text": "Aligning point cloud views using persistent feature histograms"
            },
            "tldr": {
                "abstractSimilarityScore": 77,
                "text": "This paper investigates the usage of persistent point feature histograms for the problem of aligning point cloud data views into a consistent global model, and estimates a set of robust 16D features which describe the geometry of each point locally."
            },
            "venue": {
                "fragments": [],
                "text": "2008 IEEE/RSJ International Conference on Intelligent Robots and Systems"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2000906"
                        ],
                        "name": "Ilya Kostrikov",
                        "slug": "Ilya-Kostrikov",
                        "structuredName": {
                            "firstName": "Ilya",
                            "lastName": "Kostrikov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ilya Kostrikov"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143627859"
                        ],
                        "name": "Joan Bruna",
                        "slug": "Joan-Bruna",
                        "structuredName": {
                            "firstName": "Joan",
                            "lastName": "Bruna",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Joan Bruna"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3241132"
                        ],
                        "name": "Daniele Panozzo",
                        "slug": "Daniele-Panozzo",
                        "structuredName": {
                            "firstName": "Daniele",
                            "lastName": "Panozzo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Daniele Panozzo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145516498"
                        ],
                        "name": "D. Zorin",
                        "slug": "D.-Zorin",
                        "structuredName": {
                            "firstName": "Denis",
                            "lastName": "Zorin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Zorin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 4537842,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "000e210c806721db5c6d3e2c72a83d91e084d5a4",
            "isKey": false,
            "numCitedBy": 80,
            "numCiting": 114,
            "paperAbstract": {
                "fragments": [],
                "text": "We study data-driven representations for three-dimensional triangle meshes, which are one of the prevalent objects used to represent 3D geometry. Recent works have developed models that exploit the intrinsic geometry of manifolds and graphs, namely the Graph Neural Networks (GNNs) and its spectral variants, which learn from the local metric tensor via the Laplacian operator. Despite offering excellent sample complexity and built-in invariances, intrinsic geometry alone is invariant to isometric deformations, making it unsuitable for many applications. To overcome this limitation, we propose several upgrades to GNNs to leverage extrinsic differential geometry properties of three-dimensional surfaces, increasing its modeling power. In particular, we propose to exploit the Dirac operator, whose spectrum detects principal curvature directions - this is in stark contrast with the classical Laplace operator, which directly measures mean curvature. We coin the resulting models Surface Networks (SN). We prove that these models define shape representations that are stable to deformation and to discretization, and we demonstrate the efficiency and versatility of SNs on two challenging tasks: temporal prediction of mesh deformations under non-linear dynamics and generative models using a variational autoencoder framework with encoders/decoders given by SNs."
            },
            "slug": "Surface-Networks-Kostrikov-Bruna",
            "title": {
                "fragments": [],
                "text": "Surface Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This work proposes several upgrades to GNNs to leverage extrinsic differential geometry properties of three-dimensional surfaces, increasing its modeling power, and proposes to exploit the Dirac operator, whose spectrum detects principal curvature directions - in stark contrast with the classical Laplace operator, which directly measures mean curvature."
            },
            "venue": {
                "fragments": [],
                "text": "2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2018
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2528439"
                        ],
                        "name": "O. Litany",
                        "slug": "O.-Litany",
                        "structuredName": {
                            "firstName": "Or",
                            "lastName": "Litany",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Litany"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49791556"
                        ],
                        "name": "A. Bronstein",
                        "slug": "A.-Bronstein",
                        "structuredName": {
                            "firstName": "Alexander",
                            "lastName": "Bronstein",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Bronstein"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1732570"
                        ],
                        "name": "M. Bronstein",
                        "slug": "M.-Bronstein",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Bronstein",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Bronstein"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2159982"
                        ],
                        "name": "A. Makadia",
                        "slug": "A.-Makadia",
                        "structuredName": {
                            "firstName": "Ameesh",
                            "lastName": "Makadia",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Makadia"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "p work proposed different local charting techniques using anisotropic diffusion [Boscaini et al. 2016] or Gaussian mixture models [Monti et al. 2017a; Veli\u010dkovi\u0107 et al. 2017]. In [Halimi et al. 2018; Litany et al. 2017b], a differentiable functional map [Ovsjanikov et al. 2012] layer was incorporated into a geometric deep neural network, allowing to do intrinsic structured prediction of correspondence between nonri"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 4587604,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "66bc2f209dfa9b547b0523311dd69f8aaafda971",
            "isKey": false,
            "numCitedBy": 165,
            "numCiting": 75,
            "paperAbstract": {
                "fragments": [],
                "text": "The availability of affordable and portable depth sensors has made scanning objects and people simpler than ever. However, dealing with occlusions and missing parts is still a significant challenge. The problem of reconstructing a (possibly non-rigidly moving) 3D object from a single or multiple partial scans has received increasing attention in recent years. In this work, we propose a novel learning-based method for the completion of partial shapes. Unlike the majority of existing approaches, our method focuses on objects that can undergo non-rigid deformations. The core of our method is a variational autoencoder with graph convolutional operations that learns a latent space for complete realistic shapes. At inference, we optimize to find the representation in this latent space that best fits the generated shape to the known partial input. The completed shape exhibits a realistic appearance on the unknown part. We show promising results towards the completion of synthetic and real scans of human body and face meshes exhibiting different styles of articulation and partiality."
            },
            "slug": "Deformable-Shape-Completion-with-Graph-Autoencoders-Litany-Bronstein",
            "title": {
                "fragments": [],
                "text": "Deformable Shape Completion with Graph Convolutional Autoencoders"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "This work proposes a novel learning-based method for the completion of partial shapes using a variational autoencoder with graph convolutional operations that learns a latent space for complete realistic shapes that best fits the generated shape to the known partial input."
            },
            "venue": {
                "fragments": [],
                "text": "2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2018
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1804261"
                        ],
                        "name": "D. Boscaini",
                        "slug": "D.-Boscaini",
                        "structuredName": {
                            "firstName": "D.",
                            "lastName": "Boscaini",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Boscaini"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2426718"
                        ],
                        "name": "Jonathan Masci",
                        "slug": "Jonathan-Masci",
                        "structuredName": {
                            "firstName": "Jonathan",
                            "lastName": "Masci",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jonathan Masci"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1796150"
                        ],
                        "name": "E. Rodol\u00e0",
                        "slug": "E.-Rodol\u00e0",
                        "structuredName": {
                            "firstName": "Emanuele",
                            "lastName": "Rodol\u00e0",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Rodol\u00e0"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1732570"
                        ],
                        "name": "M. Bronstein",
                        "slug": "M.-Bronstein",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Bronstein",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Bronstein"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Follow-up work proposed different local charting techniques using anisotropic diffusion [Boscaini et al. 2016] or Gaussian mixture models [Monti et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 15425191,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ba8d37f2e98d70f917d0d3a49c387cef6867e65e",
            "isKey": false,
            "numCitedBy": 404,
            "numCiting": 72,
            "paperAbstract": {
                "fragments": [],
                "text": "Establishing correspondence between shapes is a fundamental problem in geometry processing, arising in a wide variety of applications. The problem is especially difficult in the setting of non-isometric deformations, as well as in the presence of topological noise and missing parts, mainly due to the limited capability to model such deformations axiomatically. Several recent works showed that invariance to complex shape transformations can be learned from examples. In this paper, we introduce an intrinsic convolutional neural network architecture based on anisotropic diffusion kernels, which we term Anisotropic Convolutional Neural Network (ACNN). In our construction, we generalize convolutions to non-Euclidean domains by constructing a set of oriented anisotropic diffusion kernels, creating in this way a local intrinsic polar representation of the data (`patch'), which is then correlated with a filter. Several cascades of such filters, linear, and non-linear operators are stacked to form a deep neural network whose parameters are learned by minimizing a task-specific cost. We use ACNNs to effectively learn intrinsic dense correspondences between deformable shapes in very challenging settings, achieving state-of-the-art results on some of the most difficult recent correspondence benchmarks."
            },
            "slug": "Learning-shape-correspondence-with-anisotropic-Boscaini-Masci",
            "title": {
                "fragments": [],
                "text": "Learning shape correspondence with anisotropic convolutional neural networks"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "An intrinsic convolutional neural network architecture based on anisotropic diffusion kernels is introduced, which is term Anisotropic Convolutional Neural Network (ACNN), and is used to effectively learn intrinsic dense correspondences between deformable shapes in very challenging settings."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2043965"
                        ],
                        "name": "Daniel Maturana",
                        "slug": "Daniel-Maturana",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Maturana",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Daniel Maturana"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32634992"
                        ],
                        "name": "S. Scherer",
                        "slug": "S.-Scherer",
                        "structuredName": {
                            "firstName": "Sebastian",
                            "lastName": "Scherer",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Scherer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "++. An advanced version including a local-aware network and dynamical graph recomputation achieves best results on this dataset. MEAN OVERALL CLASS ACCURACY ACCURACY 3DSHAPENETS [54] 77.3 84.7 VOXNET [30] 83.0 85.9 SUBVOLUME [35] 86.0 89.2 ECC [45] 83.2 87.4 POINTNET [34] 86.0 89.2 POINTNET++ [36] - 90.7 KD-NET (DEPTH 10) [20] - 90.6 KD-NET (DEPTH 15) [20] - 91.8 OURS (BASELINE) 88.8 91.2 OURS 90.2 92"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "nput space. spatial distribution. One common approach to process point cloud data using deep learning models is to \ufb01rst convert raw point cloud data into a volumetric representation, namely a 3D grid [30, 54]. This approach, however, usually introduces quantization artifacts and excessive memory usage, making it dif\ufb01cult to go to capture high-resolution or \ufb01negrained features. State-of-the-art deep neural"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": " case a single view can be used. Volumetric Methods Voxelization is a straightforward way to convert unstructured geometric data to a regular 3D grid over which standard CNN operations can be applied [30, 54]. These volumetric representations are often wasteful, since voxelization produces a sparsely-occupied 3D grid. Time and space complexity considerations limit the resolution of the volumetric grids, y"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14620252,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3f1c6749edfaf4f89bac38b2d15a0493bd9aa253",
            "isKey": true,
            "numCitedBy": 2071,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "Robust object recognition is a crucial skill for robots operating autonomously in real world environments. Range sensors such as LiDAR and RGBD cameras are increasingly found in modern robotic systems, providing a rich source of 3D information that can aid in this task. However, many current systems do not fully utilize this information and have trouble efficiently dealing with large amounts of point cloud data. In this paper, we propose VoxNet, an architecture to tackle this problem by integrating a volumetric Occupancy Grid representation with a supervised 3D Convolutional Neural Network (3D CNN). We evaluate our approach on publicly available benchmarks using LiDAR, RGBD, and CAD data. VoxNet achieves accuracy beyond the state of the art while labeling hundreds of instances per second."
            },
            "slug": "VoxNet:-A-3D-Convolutional-Neural-Network-for-Maturana-Scherer",
            "title": {
                "fragments": [],
                "text": "VoxNet: A 3D Convolutional Neural Network for real-time object recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "VoxNet is proposed, an architecture to tackle the problem of robust object recognition by integrating a volumetric Occupancy Grid representation with a supervised 3D Convolutional Neural Network (3D CNN)."
            },
            "venue": {
                "fragments": [],
                "text": "2015 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144904233"
                        ],
                        "name": "Hang Su",
                        "slug": "Hang-Su",
                        "structuredName": {
                            "firstName": "Hang",
                            "lastName": "Su",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hang Su"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35208858"
                        ],
                        "name": "Subhransu Maji",
                        "slug": "Subhransu-Maji",
                        "structuredName": {
                            "firstName": "Subhransu",
                            "lastName": "Maji",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Subhransu Maji"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2808670"
                        ],
                        "name": "E. Kalogerakis",
                        "slug": "E.-Kalogerakis",
                        "structuredName": {
                            "firstName": "Evangelos",
                            "lastName": "Kalogerakis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Kalogerakis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1389846455"
                        ],
                        "name": "E. Learned-Miller",
                        "slug": "E.-Learned-Miller",
                        "structuredName": {
                            "firstName": "Erik",
                            "lastName": "Learned-Miller",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Learned-Miller"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 84,
                                "start": 51
                            }
                        ],
                        "text": "As a simple way to overcome this issue, view-based [Su et al. 2015; Wei et al. 2016] and volumetric representations [Klokov and Lempitsky 2017; Maturana and Scherer 2015; Tatarchenko et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2407217,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1ba8376f416e90fe434977ae9f300997667498d2",
            "isKey": false,
            "numCitedBy": 2015,
            "numCiting": 42,
            "paperAbstract": {
                "fragments": [],
                "text": "A longstanding question in computer vision concerns the representation of 3D shapes for recognition: should 3D shapes be represented with descriptors operating on their native 3D formats, such as voxel grid or polygon mesh, or can they be effectively represented with view-based descriptors? We address this question in the context of learning to recognize 3D shapes from a collection of their rendered views on 2D images. We first present a standard CNN architecture trained to recognize the shapes' rendered views independently of each other, and show that a 3D shape can be recognized even from a single view at an accuracy far higher than using state-of-the-art 3D shape descriptors. Recognition rates further increase when multiple views of the shapes are provided. In addition, we present a novel CNN architecture that combines information from multiple views of a 3D shape into a single and compact shape descriptor offering even better recognition performance. The same architecture can be applied to accurately recognize human hand-drawn sketches of shapes. We conclude that a collection of 2D views can be highly informative for 3D shape recognition and is amenable to emerging CNN architectures and their derivatives."
            },
            "slug": "Multi-view-Convolutional-Neural-Networks-for-3D-Su-Maji",
            "title": {
                "fragments": [],
                "text": "Multi-view Convolutional Neural Networks for 3D Shape Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This work presents a standard CNN architecture trained to recognize the shapes' rendered views independently of each other, and shows that a 3D shape can be recognized even from a single view at an accuracy far higher than using state-of-the-art3D shape descriptors."
            },
            "venue": {
                "fragments": [],
                "text": "2015 IEEE International Conference on Computer Vision (ICCV)"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3139470"
                        ],
                        "name": "Aleksey Golovinskiy",
                        "slug": "Aleksey-Golovinskiy",
                        "structuredName": {
                            "firstName": "Aleksey",
                            "lastName": "Golovinskiy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Aleksey Golovinskiy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3082383"
                        ],
                        "name": "Vladimir G. Kim",
                        "slug": "Vladimir-G.-Kim",
                        "structuredName": {
                            "firstName": "Vladimir",
                            "lastName": "Kim",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Vladimir G. Kim"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1807080"
                        ],
                        "name": "T. Funkhouser",
                        "slug": "T.-Funkhouser",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Funkhouser",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Funkhouser"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 189,
                                "start": 185
                            }
                        ],
                        "text": "A few of the many recent applications of point cloud processing and analysis include indoor navigation [57], self-driving vehicles [33], robotics [40], and shape synthesis and modeling [14]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 557652,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "31f830a268bacc243701dc1950b60756d0e27dbd",
            "isKey": false,
            "numCitedBy": 440,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper investigates the design of a system for recognizing objects in 3D point clouds of urban environments. The system is decomposed into four steps: locating, segmenting, characterizing, and classifying clusters of 3D points. Specifically, we first cluster nearby points to form a set of potential object locations (with hierarchical clustering). Then, we segment points near those locations into foreground and background sets (with a graph-cut algorithm). Next, we build a feature vector for each point cluster (based on both its shape and its context). Finally, we label the feature vectors using a classifier trained on a set of manually labeled objects. The paper presents several alternative methods for each step. We quantitatively evaluate the system and tradeoffs of different alternatives in a truthed part of a scan of Ottawa that contains approximately 100 million points and 1000 objects of interest. Then, we use this truth data as a training set to recognize objects amidst approximately 1 billion points of the remainder of the Ottawa scan."
            },
            "slug": "Shape-based-recognition-of-3D-point-clouds-in-urban-Golovinskiy-Kim",
            "title": {
                "fragments": [],
                "text": "Shape-based recognition of 3D point clouds in urban environments"
            },
            "tldr": {
                "abstractSimilarityScore": 59,
                "text": "This paper quantitatively evaluate the design of a system for recognizing objects in 3D point clouds of urban environments and tradeoffs of different alternatives in a truthed part of a scan of Ottawa that contains approximately 100 million points and 1000 objects of interest."
            },
            "venue": {
                "fragments": [],
                "text": "2009 IEEE 12th International Conference on Computer Vision"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2689311"
                        ],
                        "name": "R. Rusu",
                        "slug": "R.-Rusu",
                        "structuredName": {
                            "firstName": "Radu",
                            "lastName": "Rusu",
                            "middleNames": [
                                "Bogdan"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Rusu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1709715"
                        ],
                        "name": "Zolt\u00e1n-Csaba M\u00e1rton",
                        "slug": "Zolt\u00e1n-Csaba-M\u00e1rton",
                        "structuredName": {
                            "firstName": "Zolt\u00e1n-Csaba",
                            "lastName": "M\u00e1rton",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zolt\u00e1n-Csaba M\u00e1rton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1810221"
                        ],
                        "name": "Nico Blodow",
                        "slug": "Nico-Blodow",
                        "structuredName": {
                            "firstName": "Nico",
                            "lastName": "Blodow",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nico Blodow"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1746229"
                        ],
                        "name": "M. Beetz",
                        "slug": "M.-Beetz",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Beetz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Beetz"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1834227,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5aee411f0b4228ba63c85df0e8ed64cab5844aed",
            "isKey": false,
            "numCitedBy": 226,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper proposes a novel way of characterizing the local geometry of 3D points, using persistent feature histograms. The relationships between the neighbors of a point are analyzed and the resulted values are stored in a 16-bin histogram. The histograms are pose and point cloud density invariant and cope well with noisy datasets. We show that geometric primitives have unique signatures in this feature space, preserved even in the presence of additive noise. To extract a compact subset of points which characterizes a point cloud dataset, we perform an in-depth analysis of all point feature histograms using different distance metrics. Preliminary results show that point clouds can be roughly segmented based on the uniqueness of geometric primitives feature histograms. We validate our approach on datasets acquired from laser sensors in indoor (kitchen) environments."
            },
            "slug": "Persistent-Point-Feature-Histograms-for-3D-Point-Rusu-M\u00e1rton",
            "title": {
                "fragments": [],
                "text": "Persistent Point Feature Histograms for 3D Point Clouds"
            },
            "tldr": {
                "abstractSimilarityScore": 70,
                "text": "This paper proposes a novel way of characterizing the local geometry of 3D points, using persistent feature histograms, and shows that geometric primitives have unique signatures in this feature space, preserved even in the presence of additive noise."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145830541"
                        ],
                        "name": "Angel X. Chang",
                        "slug": "Angel-X.-Chang",
                        "structuredName": {
                            "firstName": "Angel",
                            "lastName": "Chang",
                            "middleNames": [
                                "X."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Angel X. Chang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1807080"
                        ],
                        "name": "T. Funkhouser",
                        "slug": "T.-Funkhouser",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Funkhouser",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Funkhouser"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1744254"
                        ],
                        "name": "L. Guibas",
                        "slug": "L.-Guibas",
                        "structuredName": {
                            "firstName": "Leonidas",
                            "lastName": "Guibas",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Guibas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144872229"
                        ],
                        "name": "P. Hanrahan",
                        "slug": "P.-Hanrahan",
                        "structuredName": {
                            "firstName": "Pat",
                            "lastName": "Hanrahan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Hanrahan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32798502"
                        ],
                        "name": "Qixing Huang",
                        "slug": "Qixing-Huang",
                        "structuredName": {
                            "firstName": "Qixing",
                            "lastName": "Huang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Qixing Huang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2825680"
                        ],
                        "name": "Zimo Li",
                        "slug": "Zimo-Li",
                        "structuredName": {
                            "firstName": "Zimo",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zimo Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1702137"
                        ],
                        "name": "S. Savarese",
                        "slug": "S.-Savarese",
                        "structuredName": {
                            "firstName": "Silvio",
                            "lastName": "Savarese",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Savarese"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2295141"
                        ],
                        "name": "M. Savva",
                        "slug": "M.-Savva",
                        "structuredName": {
                            "firstName": "Manolis",
                            "lastName": "Savva",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Savva"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3340170"
                        ],
                        "name": "S. Song",
                        "slug": "S.-Song",
                        "structuredName": {
                            "firstName": "Shuran",
                            "lastName": "Song",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Song"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144914140"
                        ],
                        "name": "Hao Su",
                        "slug": "Hao-Su",
                        "structuredName": {
                            "firstName": "Hao",
                            "lastName": "Su",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hao Su"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40599257"
                        ],
                        "name": "Jianxiong Xiao",
                        "slug": "Jianxiong-Xiao",
                        "structuredName": {
                            "firstName": "Jianxiong",
                            "lastName": "Xiao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jianxiong Xiao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47782132"
                        ],
                        "name": "L. Yi",
                        "slug": "L.-Yi",
                        "structuredName": {
                            "firstName": "L.",
                            "lastName": "Yi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Yi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1807197"
                        ],
                        "name": "F. Yu",
                        "slug": "F.-Yu",
                        "structuredName": {
                            "firstName": "Fisher",
                            "lastName": "Yu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Yu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2554264,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9b686d76914befea66377ec79c1f9258d70ea7e3",
            "isKey": false,
            "numCitedBy": 2553,
            "numCiting": 41,
            "paperAbstract": {
                "fragments": [],
                "text": "We present ShapeNet: a richly-annotated, large-scale repository of shapes represented by 3D CAD models of objects. ShapeNet contains 3D models from a multitude of semantic categories and organizes them under the WordNet taxonomy. It is a collection of datasets providing many semantic annotations for each 3D model such as consistent rigid alignments, parts and bilateral symmetry planes, physical sizes, keywords, as well as other planned annotations. Annotations are made available through a public web-based interface to enable data visualization of object attributes, promote data-driven geometric analysis, and provide a large-scale quantitative benchmark for research in computer graphics and vision. At the time of this technical report, ShapeNet has indexed more than 3,000,000 models, 220,000 models out of which are classified into 3,135 categories (WordNet synsets). In this report we describe the ShapeNet effort as a whole, provide details for all currently available datasets, and summarize future plans."
            },
            "slug": "ShapeNet:-An-Information-Rich-3D-Model-Repository-Chang-Funkhouser",
            "title": {
                "fragments": [],
                "text": "ShapeNet: An Information-Rich 3D Model Repository"
            },
            "tldr": {
                "abstractSimilarityScore": 65,
                "text": "ShapeNet contains 3D models from a multitude of semantic categories and organizes them under the WordNet taxonomy, a collection of datasets providing many semantic annotations for each 3D model such as consistent rigid alignments, parts and bilateral symmetry planes, physical sizes, keywords, as well as other planned annotations."
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2528439"
                        ],
                        "name": "O. Litany",
                        "slug": "O.-Litany",
                        "structuredName": {
                            "firstName": "Or",
                            "lastName": "Litany",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Litany"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2211633"
                        ],
                        "name": "Tal Remez",
                        "slug": "Tal-Remez",
                        "structuredName": {
                            "firstName": "Tal",
                            "lastName": "Remez",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tal Remez"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1796150"
                        ],
                        "name": "E. Rodol\u00e0",
                        "slug": "E.-Rodol\u00e0",
                        "structuredName": {
                            "firstName": "Emanuele",
                            "lastName": "Rodol\u00e0",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Rodol\u00e0"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49791556"
                        ],
                        "name": "A. Bronstein",
                        "slug": "A.-Bronstein",
                        "structuredName": {
                            "firstName": "Alexander",
                            "lastName": "Bronstein",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Bronstein"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1732570"
                        ],
                        "name": "M. Bronstein",
                        "slug": "M.-Bronstein",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Bronstein",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Bronstein"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "In [Halimi et al. 2018; Litany et al. 2017b], a differentiable functional map [Ovsjanikov et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 4215682,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "114339ab11fb244202ad1e2491e9105e8ea4a355",
            "isKey": false,
            "numCitedBy": 169,
            "numCiting": 51,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce a new framework for learning dense correspondence between deformable 3D shapes. Existing learning based approaches model shape correspondence as a labelling problem, where each point of a query shape receives a label identifying a point on some reference domain; the correspondence is then constructed a posteriori by composing the label predictions of two input shapes. We propose a paradigm shift and design a structured prediction model in the space of functional maps, linear operators that provide a compact representation of the correspondence. We model the learning process via a deep residual network which takes dense descriptor fields defined on two shapes as input, and outputs a soft map between the two given objects. The resulting correspondence is shown to be accurate on several challenging benchmarks comprising multiple categories, synthetic models, real scans with acquisition artifacts, topological noise, and partiality."
            },
            "slug": "Deep-Functional-Maps:-Structured-Prediction-for-Litany-Remez",
            "title": {
                "fragments": [],
                "text": "Deep Functional Maps: Structured Prediction for Dense Shape Correspondence"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A paradigm shift is proposed and a structured prediction model in the space of functional maps, linear operators that provide a compact representation of the correspondence is designed."
            },
            "venue": {
                "fragments": [],
                "text": "2017 IEEE International Conference on Computer Vision (ICCV)"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1792471"
                        ],
                        "name": "Lingyu Wei",
                        "slug": "Lingyu-Wei",
                        "structuredName": {
                            "firstName": "Lingyu",
                            "lastName": "Wei",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lingyu Wei"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32798502"
                        ],
                        "name": "Qixing Huang",
                        "slug": "Qixing-Huang",
                        "structuredName": {
                            "firstName": "Qixing",
                            "lastName": "Huang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Qixing Huang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39686979"
                        ],
                        "name": "Duygu Ceylan",
                        "slug": "Duygu-Ceylan",
                        "structuredName": {
                            "firstName": "Duygu",
                            "lastName": "Ceylan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Duygu Ceylan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143614752"
                        ],
                        "name": "E. Vouga",
                        "slug": "E.-Vouga",
                        "structuredName": {
                            "firstName": "Etienne",
                            "lastName": "Vouga",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Vouga"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1706574"
                        ],
                        "name": "Hao Li",
                        "slug": "Hao-Li",
                        "structuredName": {
                            "firstName": "Hao",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hao Li"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "oes not have an underlying grid, requiring new building blocks replacing convolution and pooling or adaptation to a grid structure. As a simple way to overcome this issue, view-based [Su et al. 2015; Wei et al. 2016] and volumetric representations [Klokov and Lempitsky 2017; Maturana and Scherer 2015; Tatarchenko et al. 2017; Wu et al. 2015]\u2014or their combination [Qi et al. 2016]\u2014\u201cplace\u201d geometric data onto a gri"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 6356896,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "555c81b21f7f1ca525a9dec924b417fcddc78e44",
            "isKey": false,
            "numCitedBy": 189,
            "numCiting": 62,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a deep learning approach for finding dense correspondences between 3D scans of people. Our method requires only partial geometric information in the form of two depth maps or partial reconstructed surfaces, works for humans in arbitrary poses and wearing any clothing, does not require the two people to be scanned from similar view-points, and runs in real time. We use a deep convolutional neural network to train a feature descriptor on depth map pixels, but crucially, rather than training the network to solve the shape correspondence problem directly, we train it to solve a body region classification problem, modified to increase the smoothness of the learned descriptors near region boundaries. This approach ensures that nearby points on the human body are nearby in feature space, and vice versa, rendering the feature descriptor suitable for computing dense correspondences between the scans. We validate our method on real and synthetic data for both clothed and unclothed humans, and show that our correspondences are more robust than is possible with state-of-the-art unsupervised methods, and more accurate than those found using methods that require full watertight 3D geometry."
            },
            "slug": "Dense-Human-Body-Correspondences-Using-Networks-Wei-Huang",
            "title": {
                "fragments": [],
                "text": "Dense Human Body Correspondences Using Convolutional Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This work uses a deep convolutional neural network to train a feature descriptor on depth map pixels, but crucially, rather than training the network to solve the shape correspondence problem directly, it trains it to solve a body region classification problem, modified to increase the smoothness of the learned descriptors near region boundaries."
            },
            "venue": {
                "fragments": [],
                "text": "2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143785357"
                        ],
                        "name": "Min Lu",
                        "slug": "Min-Lu",
                        "structuredName": {
                            "firstName": "Min",
                            "lastName": "Lu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Min Lu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2985328"
                        ],
                        "name": "Yulan Guo",
                        "slug": "Yulan-Guo",
                        "structuredName": {
                            "firstName": "Yulan",
                            "lastName": "Guo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yulan Guo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2155659550"
                        ],
                        "name": "Jun Zhang",
                        "slug": "Jun-Zhang",
                        "structuredName": {
                            "firstName": "Jun",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jun Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3107145"
                        ],
                        "name": "Yanxin Ma",
                        "slug": "Yanxin-Ma",
                        "structuredName": {
                            "firstName": "Yanxin",
                            "lastName": "Ma",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yanxin Ma"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46359335"
                        ],
                        "name": "Yinjie Lei",
                        "slug": "Yinjie-Lei",
                        "structuredName": {
                            "firstName": "Yinjie",
                            "lastName": "Lei",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yinjie Lei"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7233317,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "458d4c5b8d16abfbbb2c60a423b334d111249cb7",
            "isKey": false,
            "numCitedBy": 21,
            "numCiting": 41,
            "paperAbstract": {
                "fragments": [],
                "text": "Recognizing 3D objects from point clouds in the presence of significant clutter and occlusion is a highly challenging task. In this paper, we present a coarse-to-fine 3D object recognition algorithm. During the phase of offline training, each model is represented with a set of multi-scale local surface features. During the phase of online recognition, a set of keypoints are first detected from each scene. The local surfaces around these keypoints are further encoded with multi-scale feature descriptors. These scene features are then matched against all model features to generate recognition hypotheses, which include model hypotheses and pose hypotheses. Finally, these hypotheses are verified to produce recognition results. The proposed algorithm was tested on two standard datasets, with rigorous comparisons to the state-of-the-art algorithms. Experimental results show that our algorithm was fully automatic and highly effective. It was also very robust to occlusion and clutter. It achieved the best recognition performance on all of these datasets, showing its superiority compared to existing algorithms."
            },
            "slug": "Recognizing-Objects-in-3D-Point-Clouds-with-Local-Lu-Guo",
            "title": {
                "fragments": [],
                "text": "Recognizing Objects in 3D Point Clouds with Multi-Scale Local Features"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "This paper presents a coarse-to-fine 3D object recognition algorithm that was fully automatic and highly effective, and was also very robust to occlusion and clutter."
            },
            "venue": {
                "fragments": [],
                "text": "Sensors"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1804261"
                        ],
                        "name": "D. Boscaini",
                        "slug": "D.-Boscaini",
                        "structuredName": {
                            "firstName": "D.",
                            "lastName": "Boscaini",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Boscaini"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2426718"
                        ],
                        "name": "Jonathan Masci",
                        "slug": "Jonathan-Masci",
                        "structuredName": {
                            "firstName": "Jonathan",
                            "lastName": "Masci",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jonathan Masci"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1972186"
                        ],
                        "name": "S. Melzi",
                        "slug": "S.-Melzi",
                        "structuredName": {
                            "firstName": "Simone",
                            "lastName": "Melzi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Melzi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1732570"
                        ],
                        "name": "M. Bronstein",
                        "slug": "M.-Bronstein",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Bronstein",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Bronstein"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1794185"
                        ],
                        "name": "U. Castellani",
                        "slug": "U.-Castellani",
                        "structuredName": {
                            "firstName": "Umberto",
                            "lastName": "Castellani",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "U. Castellani"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1697397"
                        ],
                        "name": "P. Vandergheynst",
                        "slug": "P.-Vandergheynst",
                        "structuredName": {
                            "firstName": "Pierre",
                            "lastName": "Vandergheynst",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Vandergheynst"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 116,
                                "start": 113
                            }
                        ],
                        "text": "Spectral graph CNN models are notable for isometry invariance and hence have applied to non-rigid shape analysis [5]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 3817802,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "705ecaa4774ebb68bb212c82a3857c9b2fd74c02",
            "isKey": false,
            "numCitedBy": 190,
            "numCiting": 48,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we propose a generalization of convolutional neural networks (CNN) to non\u2010Euclidean domains for the analysis of deformable shapes. Our construction is based on localized frequency analysis (a generalization of the windowed Fourier transform to manifolds) that is used to extract the local behavior of some dense intrinsic descriptor, roughly acting as an analogy to patches in images. The resulting local frequency representations are then passed through a bank of filters whose coefficient are determined by a learning procedure minimizing a task\u2010specific cost. Our approach generalizes several previous methods such as HKS, WKS, spectral CNN, and GPS embeddings. Experimental results show that the proposed approach allows learning class\u2010specific shape descriptors significantly outperforming recent state\u2010of\u2010the\u2010art methods on standard benchmarks."
            },
            "slug": "Learning-class\u2010specific-descriptors-for-deformable-Boscaini-Masci",
            "title": {
                "fragments": [],
                "text": "Learning class\u2010specific descriptors for deformable shapes using localized spectral convolutional networks"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "Experimental results show that the proposed approach allows learning class\u2010specific shape descriptors significantly outperforming recent state\u2010of\u2010the\u2010art methods on standard benchmarks."
            },
            "venue": {
                "fragments": [],
                "text": "SGP '15"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47782132"
                        ],
                        "name": "L. Yi",
                        "slug": "L.-Yi",
                        "structuredName": {
                            "firstName": "L.",
                            "lastName": "Yi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Yi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3082383"
                        ],
                        "name": "Vladimir G. Kim",
                        "slug": "Vladimir-G.-Kim",
                        "structuredName": {
                            "firstName": "Vladimir",
                            "lastName": "Kim",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Vladimir G. Kim"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39686979"
                        ],
                        "name": "Duygu Ceylan",
                        "slug": "Duygu-Ceylan",
                        "structuredName": {
                            "firstName": "Duygu",
                            "lastName": "Ceylan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Duygu Ceylan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34023939"
                        ],
                        "name": "I-Chao Shen",
                        "slug": "I-Chao-Shen",
                        "structuredName": {
                            "firstName": "I-Chao",
                            "lastName": "Shen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I-Chao Shen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7890549"
                        ],
                        "name": "Mengyan Yan",
                        "slug": "Mengyan-Yan",
                        "structuredName": {
                            "firstName": "Mengyan",
                            "lastName": "Yan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mengyan Yan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144914140"
                        ],
                        "name": "Hao Su",
                        "slug": "Hao-Su",
                        "structuredName": {
                            "firstName": "Hao",
                            "lastName": "Su",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hao Su"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1830034"
                        ],
                        "name": "Cewu Lu",
                        "slug": "Cewu-Lu",
                        "structuredName": {
                            "firstName": "Cewu",
                            "lastName": "Lu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Cewu Lu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32798502"
                        ],
                        "name": "Qixing Huang",
                        "slug": "Qixing-Huang",
                        "structuredName": {
                            "firstName": "Qixing",
                            "lastName": "Huang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Qixing Huang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1778286"
                        ],
                        "name": "A. Sheffer",
                        "slug": "A.-Sheffer",
                        "structuredName": {
                            "firstName": "Alla",
                            "lastName": "Sheffer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Sheffer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1744254"
                        ],
                        "name": "L. Guibas",
                        "slug": "L.-Guibas",
                        "structuredName": {
                            "firstName": "Leonidas",
                            "lastName": "Guibas",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Guibas"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2880712,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "729d5c7dc6bfb32e47b5bd24cdb01ccaaf62bba5",
            "isKey": false,
            "numCitedBy": 578,
            "numCiting": 37,
            "paperAbstract": {
                "fragments": [],
                "text": "Large repositories of 3D shapes provide valuable input for data-driven analysis and modeling tools. They are especially powerful once annotated with semantic information such as salient regions and functional parts. We propose a novel active learning method capable of enriching massive geometric datasets with accurate semantic region annotations. Given a shape collection and a user-specified region label our goal is to correctly demarcate the corresponding regions with minimal manual work. Our active framework achieves this goal by cycling between manually annotating the regions, automatically propagating these annotations across the rest of the shapes, manually verifying both human and automatic annotations, and learning from the verification results to improve the automatic propagation algorithm. We use a unified utility function that explicitly models the time cost of human input across all steps of our method. This allows us to jointly optimize for the set of models to annotate and for the set of models to verify based on the predicted impact of these actions on the human efficiency. We demonstrate that incorporating verification of all produced labelings within this unified objective improves both accuracy and efficiency of the active learning procedure. We automatically propagate human labels across a dynamic shape network using a conditional random field (CRF) framework, taking advantage of global shape-to-shape similarities, local feature similarities, and point-to-point correspondences. By combining these diverse cues we achieve higher accuracy than existing alternatives. We validate our framework on existing benchmarks demonstrating it to be significantly more efficient at using human input compared to previous techniques. We further validate its efficiency and robustness by annotating a massive shape dataset, labeling over 93,000 shape parts, across multiple model classes, and providing a labeled part collection more than one order of magnitude larger than existing ones."
            },
            "slug": "A-scalable-active-framework-for-region-annotation-Yi-Kim",
            "title": {
                "fragments": [],
                "text": "A scalable active framework for region annotation in 3D shape collections"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This work proposes a novel active learning method capable of enriching massive geometric datasets with accurate semantic region annotations, and demonstrates that incorporating verification of all produced labelings within this unified objective improves both accuracy and efficiency of the active learning procedure."
            },
            "venue": {
                "fragments": [],
                "text": "ACM Trans. Graph."
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3422350"
                        ],
                        "name": "M. Defferrard",
                        "slug": "M.-Defferrard",
                        "structuredName": {
                            "firstName": "Micha\u00ebl",
                            "lastName": "Defferrard",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Defferrard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2549032"
                        ],
                        "name": "X. Bresson",
                        "slug": "X.-Bresson",
                        "structuredName": {
                            "firstName": "Xavier",
                            "lastName": "Bresson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "X. Bresson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1697397"
                        ],
                        "name": "P. Vandergheynst",
                        "slug": "P.-Vandergheynst",
                        "structuredName": {
                            "firstName": "Pierre",
                            "lastName": "Vandergheynst",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Vandergheynst"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Computational drawbacks of this foundational approach were alleviated in follow-up works using polynomial [Defferrard et al. 2016; Kipf and Welling 2017; Monti et al. 2017b, 2018], or rational [Levie et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 3016223,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c41eb895616e453dcba1a70c9b942c5063cc656c",
            "isKey": false,
            "numCitedBy": 4145,
            "numCiting": 46,
            "paperAbstract": {
                "fragments": [],
                "text": "In this work, we are interested in generalizing convolutional neural networks (CNNs) from low-dimensional regular grids, where image, video and speech are represented, to high-dimensional irregular domains, such as social networks, brain connectomes or words' embedding, represented by graphs. We present a formulation of CNNs in the context of spectral graph theory, which provides the necessary mathematical background and efficient numerical schemes to design fast localized convolutional filters on graphs. Importantly, the proposed technique offers the same linear computational complexity and constant learning complexity as classical CNNs, while being universal to any graph structure. Experiments on MNIST and 20NEWS demonstrate the ability of this novel deep learning system to learn local, stationary, and compositional features on graphs."
            },
            "slug": "Convolutional-Neural-Networks-on-Graphs-with-Fast-Defferrard-Bresson",
            "title": {
                "fragments": [],
                "text": "Convolutional Neural Networks on Graphs with Fast Localized Spectral Filtering"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This work presents a formulation of CNNs in the context of spectral graph theory, which provides the necessary mathematical background and efficient numerical schemes to design fast localized convolutional filters on graphs."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1892247"
                        ],
                        "name": "Shenlong Wang",
                        "slug": "Shenlong-Wang",
                        "structuredName": {
                            "firstName": "Shenlong",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shenlong Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1721212"
                        ],
                        "name": "Simon Suo",
                        "slug": "Simon-Suo",
                        "structuredName": {
                            "firstName": "Simon",
                            "lastName": "Suo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Simon Suo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2650832"
                        ],
                        "name": "Wei-Chiu Ma",
                        "slug": "Wei-Chiu-Ma",
                        "structuredName": {
                            "firstName": "Wei-Chiu",
                            "lastName": "Ma",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wei-Chiu Ma"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49224681"
                        ],
                        "name": "A. Pokrovsky",
                        "slug": "A.-Pokrovsky",
                        "structuredName": {
                            "firstName": "Andrei",
                            "lastName": "Pokrovsky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Pokrovsky"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2422559"
                        ],
                        "name": "R. Urtasun",
                        "slug": "R.-Urtasun",
                        "structuredName": {
                            "firstName": "Raquel",
                            "lastName": "Urtasun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Urtasun"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "2017], self-driving vehicles [Liang et al. 2018; Qi et al. 2017a; Wang et al. 2018b], robotics [Rusu et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "a connection to existing work, Non-local Neural Networks [Wang et al. 2018a] explored similar ideas in the video recognition field, and follow-up work by Xie et al. [2018] proposed using non-local blocks to denoise feature maps to defend against adversarial attacks."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 49367415,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7bbcd665f4847652e307ca717b209de92cd95dd2",
            "isKey": false,
            "numCitedBy": 266,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": "Standard convolutional neural networks assume a grid structured input is available and exploit discrete convolutions as their fundamental building blocks. This limits their applicability to many real-world applications. In this paper we propose Parametric Continuous Convolution, a new learnable operator that operates over non-grid structured data. The key idea is to exploit parameterized kernel functions that span the full continuous vector space. This generalization allows us to learn over arbitrary data structures as long as their support relationship is computable. Our experiments show significant improvement over the state-of-the-art in point cloud segmentation of indoor and outdoor scenes, and lidar motion estimation of driving scenes."
            },
            "slug": "Deep-Parametric-Continuous-Convolutional-Neural-Wang-Suo",
            "title": {
                "fragments": [],
                "text": "Deep Parametric Continuous Convolutional Neural Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "The key idea is to exploit parameterized kernel functions that span the full continuous vector space, which allows us to learn over arbitrary data structures as long as their support relationship is computable."
            },
            "venue": {
                "fragments": [],
                "text": "2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2018
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3332944"
                        ],
                        "name": "Maxim Tatarchenko",
                        "slug": "Maxim-Tatarchenko",
                        "structuredName": {
                            "firstName": "Maxim",
                            "lastName": "Tatarchenko",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Maxim Tatarchenko"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2841331"
                        ],
                        "name": "A. Dosovitskiy",
                        "slug": "A.-Dosovitskiy",
                        "structuredName": {
                            "firstName": "Alexey",
                            "lastName": "Dosovitskiy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Dosovitskiy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1710872"
                        ],
                        "name": "T. Brox",
                        "slug": "T.-Brox",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Brox",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Brox"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "ptation to a grid structure. As a simple way to overcome this issue, view-based [Su et al. 2015; Wei et al. 2016] and volumetric representations [Klokov and Lempitsky 2017; Maturana and Scherer 2015; Tatarchenko et al. 2017; Wu et al. 2015]\u2014or their combination [Qi et al. 2016]\u2014\u201cplace\u201d geometric data onto a grid. More recently, PointNet [Qi et al. 2017b,c] exemplifies a broad class of deep learning architectures on non-"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 60945,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f7bdfb229fc58c696459ea09c3792b80005644f2",
            "isKey": false,
            "numCitedBy": 539,
            "numCiting": 43,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a deep convolutional decoder architecture that can generate volumetric 3D outputs in a compute- and memory-efficient manner by using an octree representation. The network learns to predict both the structure of the octree, and the occupancy values of individual cells. This makes it a particularly valuable technique for generating 3D shapes. In contrast to standard decoders acting on regular voxel grids, the architecture does not have cubic complexity. This allows representing much higher resolution outputs with a limited memory budget. We demonstrate this in several application domains, including 3D convolutional autoencoders, generation of objects and whole scenes from high-level representations, and shape from a single image."
            },
            "slug": "Octree-Generating-Networks:-Efficient-Convolutional-Tatarchenko-Dosovitskiy",
            "title": {
                "fragments": [],
                "text": "Octree Generating Networks: Efficient Convolutional Architectures for High-resolution 3D Outputs"
            },
            "tldr": {
                "abstractSimilarityScore": 93,
                "text": "A deep convolutional decoder architecture that can generate volumetric 3D outputs in a compute- and memory-efficient manner by using an octree representation that learns to predict both the structure of the octree, and the occupancy values of individual cells."
            },
            "venue": {
                "fragments": [],
                "text": "2017 IEEE International Conference on Computer Vision (ICCV)"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143627859"
                        ],
                        "name": "Joan Bruna",
                        "slug": "Joan-Bruna",
                        "structuredName": {
                            "firstName": "Joan",
                            "lastName": "Bruna",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Joan Bruna"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2563432"
                        ],
                        "name": "Wojciech Zaremba",
                        "slug": "Wojciech-Zaremba",
                        "structuredName": {
                            "firstName": "Wojciech",
                            "lastName": "Zaremba",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wojciech Zaremba"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3149531"
                        ],
                        "name": "Arthur D. Szlam",
                        "slug": "Arthur-D.-Szlam",
                        "structuredName": {
                            "firstName": "Arthur",
                            "lastName": "Szlam",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Arthur D. Szlam"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688882"
                        ],
                        "name": "Yann LeCun",
                        "slug": "Yann-LeCun",
                        "structuredName": {
                            "firstName": "Yann",
                            "lastName": "LeCun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yann LeCun"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "f deep learning architectures on non-Euclidean structured data termed geometric deep learning [7]. These methods date back to early methods to construct neural networks on graphs [41]. More recently, [9] proposed a generalization of convolution for graphs via the Laplacian operator [44]. This foundational approach had a number of drawbacks including the computational complexity of Laplacian eigendeco"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 17682909,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5e925a9f1e20df61d1e860a7aa71894b35a1c186",
            "isKey": false,
            "numCitedBy": 2788,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "Convolutional Neural Networks are extremely efficient architectures in image and audio recognition tasks, thanks to their ability to exploit the local translational invariance of signal classes over their domain. In this paper we consider possible generalizations of CNNs to signals defined on more general domains without the action of a translation group. In particular, we propose two constructions, one based upon a hierarchical clustering of the domain, and another based on the spectrum of the graph Laplacian. We show through experiments that for low-dimensional graphs it is possible to learn convolutional layers with a number of parameters independent of the input size, resulting in efficient deep architectures."
            },
            "slug": "Spectral-Networks-and-Locally-Connected-Networks-on-Bruna-Zaremba",
            "title": {
                "fragments": [],
                "text": "Spectral Networks and Locally Connected Networks on Graphs"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This paper considers possible generalizations of CNNs to signals defined on more general domains without the action of a translation group, and proposes two constructions, one based upon a hierarchical clustering of the domain, and another based on the spectrum of the graph Laplacian."
            },
            "venue": {
                "fragments": [],
                "text": "ICLR"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2426718"
                        ],
                        "name": "Jonathan Masci",
                        "slug": "Jonathan-Masci",
                        "structuredName": {
                            "firstName": "Jonathan",
                            "lastName": "Masci",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jonathan Masci"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1804261"
                        ],
                        "name": "D. Boscaini",
                        "slug": "D.-Boscaini",
                        "structuredName": {
                            "firstName": "D.",
                            "lastName": "Boscaini",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Boscaini"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1732570"
                        ],
                        "name": "M. Bronstein",
                        "slug": "M.-Bronstein",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Bronstein",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Bronstein"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1697397"
                        ],
                        "name": "P. Vandergheynst",
                        "slug": "P.-Vandergheynst",
                        "structuredName": {
                            "firstName": "Pierre",
                            "lastName": "Vandergheynst",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Vandergheynst"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 11170942,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "a743115795375666593919cbd48590213c229ae9",
            "isKey": false,
            "numCitedBy": 567,
            "numCiting": 55,
            "paperAbstract": {
                "fragments": [],
                "text": "Feature descriptors play a crucial role in a wide range of geometry analysis and processing applications, including shape correspondence, retrieval, and segmentation. In this paper, we introduce Geodesic Convolutional Neural Networks (GCNN), a generalization of the convolutional neural networks (CNN) paradigm to non-Euclidean manifolds. Our construction is based on a local geodesic system of polar coordinates to extract \"patches\", which are then passed through a cascade of filters and linear and non-linear operators. The coefficients of the filters and linear combination weights are optimization variables that are learned to minimize a task-specific cost function. We use ShapeNet to learn invariant shape features, allowing to achieve state-of-the-art performance in problems such as shape description, retrieval, and correspondence."
            },
            "slug": "Geodesic-Convolutional-Neural-Networks-on-Manifolds-Masci-Boscaini",
            "title": {
                "fragments": [],
                "text": "Geodesic Convolutional Neural Networks on Riemannian Manifolds"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "Geodesic Convolutional Neural Networks (GCNN), a generalization of the convolutional neural networks (CNN) paradigm to non-Euclidean manifolds is introduced, allowing to achieve state-of-the-art performance in problems such as shape description, retrieval, and correspondence."
            },
            "venue": {
                "fragments": [],
                "text": "2015 IEEE International Conference on Computer Vision Workshop (ICCVW)"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3276873"
                        ],
                        "name": "O. V. Kaick",
                        "slug": "O.-V.-Kaick",
                        "structuredName": {
                            "firstName": "Oliver",
                            "lastName": "Kaick",
                            "middleNames": [
                                "Matias",
                                "van"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. V. Kaick"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39497427"
                        ],
                        "name": "Hao Zhang",
                        "slug": "Hao-Zhang",
                        "structuredName": {
                            "firstName": "Hao",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hao Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3049056"
                        ],
                        "name": "G. Hamarneh",
                        "slug": "G.-Hamarneh",
                        "structuredName": {
                            "firstName": "G.",
                            "lastName": "Hamarneh",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Hamarneh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1388323541"
                        ],
                        "name": "D. Cohen-Or",
                        "slug": "D.-Cohen-Or",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Cohen-Or",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Cohen-Or"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6068875,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "95199193e30e7780ec821c0cd0d1ab18a036ebc6",
            "isKey": false,
            "numCitedBy": 416,
            "numCiting": 186,
            "paperAbstract": {
                "fragments": [],
                "text": "We review methods designed to compute correspondences between geometric shapes represented by triangle meshes, contours or point sets. This survey is motivated in part by recent developments in space\u2013time registration, where one seeks a correspondence between non\u2010rigid and time\u2010varying surfaces, and semantic shape analysis, which underlines a recent trend to incorporate shape understanding into the analysis pipeline. Establishing a meaningful correspondence between shapes is often difficult because it generally requires an understanding of the structure of the shapes at both the local and global levels, and sometimes the functionality of the shape parts as well. Despite its inherent complexity, shape correspondence is a recurrent problem and an essential component of numerous geometry processing applications. In this survey, we discuss the different forms of the correspondence problem and review the main solution methods, aided by several classification criteria arising from the problem definition. The main categories of classification are defined in terms of the input and output representation, objective function and solution approach. We conclude the survey by discussing open problems and future perspectives."
            },
            "slug": "A-Survey-on-Shape-Correspondence-Kaick-Zhang",
            "title": {
                "fragments": [],
                "text": "A Survey on Shape Correspondence"
            },
            "tldr": {
                "abstractSimilarityScore": 52,
                "text": "This survey is motivated in part by recent developments in space\u2013time registration, where one seeks a correspondence between non-rigid and time-varying surfaces, and semantic shape analysis, which underlines a recent trend to incorporate shape understanding into the analysis pipeline."
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Graph. Forum"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1952002"
                        ],
                        "name": "Anurag Ranjan",
                        "slug": "Anurag-Ranjan",
                        "structuredName": {
                            "firstName": "Anurag",
                            "lastName": "Ranjan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Anurag Ranjan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1780750"
                        ],
                        "name": "Timo Bolkart",
                        "slug": "Timo-Bolkart",
                        "structuredName": {
                            "firstName": "Timo",
                            "lastName": "Bolkart",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Timo Bolkart"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50456334"
                        ],
                        "name": "Soubhik Sanyal",
                        "slug": "Soubhik-Sanyal",
                        "structuredName": {
                            "firstName": "Soubhik",
                            "lastName": "Sanyal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Soubhik Sanyal"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2105795"
                        ],
                        "name": "Michael J. Black",
                        "slug": "Michael-J.-Black",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Black",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael J. Black"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 50790278,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ccb7ad8ea38991798172c33aee83f4d68a45d376",
            "isKey": false,
            "numCitedBy": 294,
            "numCiting": 57,
            "paperAbstract": {
                "fragments": [],
                "text": "Learned 3D representations of human faces are useful for computer vision problems such as 3D face tracking and reconstruction from images, as well as graphics applications such as character generation and animation. Traditional models learn a latent representation of a face using linear subspaces or higher-order tensor generalizations. Due to this linearity, they can not capture extreme deformations and non-linear expressions. To address this, we introduce a versatile model that learns a non-linear representation of a face using spectral convolutions on a mesh surface. We introduce mesh sampling operations that enable a hierarchical mesh representation that captures non-linear variations in shape and expression at multiple scales within the model. In a variational setting, our model samples diverse realistic 3D faces from a multivariate Gaussian distribution. Our training data consists of 20,466 meshes of extreme expressions captured over 12 different subjects. Despite limited training data, our trained model outperforms state-of-the-art face models with 50% lower reconstruction error, while using 75% fewer parameters. We show that, replacing the expression space of an existing state-of-the-art face model with our model, achieves a lower reconstruction error. Our data, model and code are available at http://coma.is.tue.mpg.de/."
            },
            "slug": "Generating-3D-faces-using-Convolutional-Mesh-Ranjan-Bolkart",
            "title": {
                "fragments": [],
                "text": "Generating 3D faces using Convolutional Mesh Autoencoders"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This work introduces a versatile model that learns a non-linear representation of a face using spectral convolutions on a mesh surface and shows that, replacing the expression space of an existing state-of-the-art face model with this model, achieves a lower reconstruction error."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2018
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39713408"
                        ],
                        "name": "Mikael Henaff",
                        "slug": "Mikael-Henaff",
                        "structuredName": {
                            "firstName": "Mikael",
                            "lastName": "Henaff",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mikael Henaff"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143627859"
                        ],
                        "name": "Joan Bruna",
                        "slug": "Joan-Bruna",
                        "structuredName": {
                            "firstName": "Joan",
                            "lastName": "Bruna",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Joan Bruna"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688882"
                        ],
                        "name": "Yann LeCun",
                        "slug": "Yann-LeCun",
                        "structuredName": {
                            "firstName": "Yann",
                            "lastName": "LeCun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yann LeCun"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 10443309,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e49ff72d420c8d72e62a9353e3abc053445e59bd",
            "isKey": false,
            "numCitedBy": 1159,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "Deep Learning's recent successes have mostly relied on Convolutional Networks, which exploit fundamental statistical properties of images, sounds and video data: the local stationarity and multi-scale compositional structure, that allows expressing long range interactions in terms of shorter, localized interactions. However, there exist other important examples, such as text documents or bioinformatic data, that may lack some or all of these strong statistical regularities. \nIn this paper we consider the general question of how to construct deep architectures with small learning complexity on general non-Euclidean domains, which are typically unknown and need to be estimated from the data. In particular, we develop an extension of Spectral Networks which incorporates a Graph Estimation procedure, that we test on large-scale classification problems, matching or improving over Dropout Networks with far less parameters to estimate."
            },
            "slug": "Deep-Convolutional-Networks-on-Graph-Structured-Henaff-Bruna",
            "title": {
                "fragments": [],
                "text": "Deep Convolutional Networks on Graph-Structured Data"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This paper develops an extension of Spectral Networks which incorporates a Graph Estimation procedure, that is test on large-scale classification problems, matching or improving over Dropout Networks with far less parameters to estimate."
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2112405071"
                        ],
                        "name": "S. A. A. Shah",
                        "slug": "S.-A.-A.-Shah",
                        "structuredName": {
                            "firstName": "Syed",
                            "lastName": "Shah",
                            "middleNames": [
                                "Afaq",
                                "Ali"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. A. A. Shah"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1698675"
                        ],
                        "name": "Bennamoun",
                        "slug": "Bennamoun",
                        "structuredName": {
                            "firstName": "",
                            "lastName": "Bennamoun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bennamoun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2795743"
                        ],
                        "name": "F. Boussa\u00efd",
                        "slug": "F.-Boussa\u00efd",
                        "structuredName": {
                            "firstName": "Farid",
                            "lastName": "Boussa\u00efd",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Boussa\u00efd"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1399029845"
                        ],
                        "name": "A. El-Sallam",
                        "slug": "A.-El-Sallam",
                        "structuredName": {
                            "firstName": "Amar",
                            "lastName": "El-Sallam",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. El-Sallam"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8386230,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "14e5f5387b517725e9ac3d1ebaf7fa34c1328832",
            "isKey": false,
            "numCitedBy": 22,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a novel local surface descriptor, called 3D-Div. The proposed descriptor is based on the concept of 3D vector fields divergence, extensively used in electromagnetic theory. To generate a 3D-Div descriptor of a 3D surface, a keypoint is first extracted on the 3D surface, then a local patch of a certain size is selected around that keypoint. A Local Reference Frame (LRF) is then constructed at the keypoint using all points forming the patch. A normalized 3D vector field is then computed at each point in the patch and referenced with LRF vectors. The 3D-Div descriptors are finally generated as the divergence of the reoriented 3D vector field. We tested our proposed descriptor on the low resolution Washington RGB-D (Kinect) object dataset. Performance was evaluated for the tasks of feature matching and pairwise range image registration. Experimental results showed that the proposed 3D-Div is 88% more computationally efficient and 47% more accurate than commonly used Spin Image (SI) descriptors."
            },
            "slug": "3D-Div:-A-novel-local-surface-descriptor-for-and-Shah-Bennamoun",
            "title": {
                "fragments": [],
                "text": "3D-Div: A novel local surface descriptor for feature matching and pairwise range image registration"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "Experimental results showed that the proposed 3D-Div descriptor is 88% more computationally efficient and 47% more accurate than commonly used Spin Image (SI) descriptors."
            },
            "venue": {
                "fragments": [],
                "text": "2013 IEEE International Conference on Image Processing"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2265243"
                        ],
                        "name": "R. Levie",
                        "slug": "R.-Levie",
                        "structuredName": {
                            "firstName": "Ron",
                            "lastName": "Levie",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Levie"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2500309"
                        ],
                        "name": "Federico Monti",
                        "slug": "Federico-Monti",
                        "structuredName": {
                            "firstName": "Federico",
                            "lastName": "Monti",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Federico Monti"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2549032"
                        ],
                        "name": "X. Bresson",
                        "slug": "X.-Bresson",
                        "structuredName": {
                            "firstName": "Xavier",
                            "lastName": "Bresson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "X. Bresson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1732570"
                        ],
                        "name": "M. Bronstein",
                        "slug": "M.-Bronstein",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Bronstein",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Bronstein"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 10544801,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b5007972c6f5a2294f83357c73e12664dd7c85b3",
            "isKey": false,
            "numCitedBy": 379,
            "numCiting": 44,
            "paperAbstract": {
                "fragments": [],
                "text": "The rise of graph-structured data such as social networks, regulatory networks, citation graphs, and functional brain networks, in combination with resounding success of deep learning in various applications, has brought the interest in generalizing deep learning models to non-Euclidean domains. In this paper, we introduce a new spectral domain convolutional architecture for deep learning on graphs. The core ingredient of our model is a new class of parametric rational complex functions (Cayley polynomials) allowing to efficiently compute spectral filters on graphs that specialize on frequency bands of interest. Our model generates rich spectral filters that are localized in space, scales linearly with the size of the input data for sparsely connected graphs, and can handle different constructions of Laplacian operators. Extensive experimental results show the superior performance of our approach, in comparison to other spectral domain convolutional architectures, on spectral image classification, community detection, vertex classification, and matrix completion tasks."
            },
            "slug": "CayleyNets:-Graph-Convolutional-Neural-Networks-Levie-Monti",
            "title": {
                "fragments": [],
                "text": "CayleyNets: Graph Convolutional Neural Networks With Complex Rational Spectral Filters"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A new spectral domain convolutional architecture for deep learning on graphs with a new class of parametric rational complex functions (Cayley polynomials) allowing to efficiently compute spectral filters on graphs that specialize on frequency bands of interest."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Signal Processing"
            },
            "year": 2019
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1732570"
                        ],
                        "name": "M. Bronstein",
                        "slug": "M.-Bronstein",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Bronstein",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Bronstein"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143627859"
                        ],
                        "name": "Joan Bruna",
                        "slug": "Joan-Bruna",
                        "structuredName": {
                            "firstName": "Joan",
                            "lastName": "Bruna",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Joan Bruna"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688882"
                        ],
                        "name": "Yann LeCun",
                        "slug": "Yann-LeCun",
                        "structuredName": {
                            "firstName": "Yann",
                            "lastName": "LeCun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yann LeCun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3149531"
                        ],
                        "name": "Arthur D. Szlam",
                        "slug": "Arthur-D.-Szlam",
                        "structuredName": {
                            "firstName": "Arthur",
                            "lastName": "Szlam",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Arthur D. Szlam"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1697397"
                        ],
                        "name": "P. Vandergheynst",
                        "slug": "P.-Vandergheynst",
                        "structuredName": {
                            "firstName": "Pierre",
                            "lastName": "Vandergheynst",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Vandergheynst"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15195762,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0e779fd59353a7f1f5b559b9d65fa4bfe367890c",
            "isKey": false,
            "numCitedBy": 1982,
            "numCiting": 129,
            "paperAbstract": {
                "fragments": [],
                "text": "Many scientific fields study data with an underlying structure that is non-Euclidean. Some examples include social networks in computational social sciences, sensor networks in communications, functional networks in brain imaging, regulatory networks in genetics, and meshed surfaces in computer graphics. In many applications, such geometric data are large and complex (in the case of social networks, on the scale of billions) and are natural targets for machine-learning techniques. In particular, we would like to use deep neural networks, which have recently proven to be powerful tools for a broad range of problems from computer vision, natural-language processing, and audio analysis. However, these tools have been most successful on data with an underlying Euclidean or grid-like structure and in cases where the invariances of these structures are built into networks used to model them."
            },
            "slug": "Geometric-Deep-Learning:-Going-beyond-Euclidean-Bronstein-Bruna",
            "title": {
                "fragments": [],
                "text": "Geometric Deep Learning: Going beyond Euclidean data"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "Deep neural networks are used for solving a broad range of problems from computer vision, natural-language processing, and audio analysis where the invariances of these structures are built into networks used to model them."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Signal Processing Magazine"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3444569"
                        ],
                        "name": "Petar Velickovic",
                        "slug": "Petar-Velickovic",
                        "structuredName": {
                            "firstName": "Petar",
                            "lastName": "Velickovic",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Petar Velickovic"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7153363"
                        ],
                        "name": "Guillem Cucurull",
                        "slug": "Guillem-Cucurull",
                        "structuredName": {
                            "firstName": "Guillem",
                            "lastName": "Cucurull",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Guillem Cucurull"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8742492"
                        ],
                        "name": "Arantxa Casanova",
                        "slug": "Arantxa-Casanova",
                        "structuredName": {
                            "firstName": "Arantxa",
                            "lastName": "Casanova",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Arantxa Casanova"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144290131"
                        ],
                        "name": "Adriana Romero",
                        "slug": "Adriana-Romero",
                        "structuredName": {
                            "firstName": "Adriana",
                            "lastName": "Romero",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Adriana Romero"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144269589"
                        ],
                        "name": "P. Lio\u2019",
                        "slug": "P.-Lio\u2019",
                        "structuredName": {
                            "firstName": "Pietro",
                            "lastName": "Lio\u2019",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Lio\u2019"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751762"
                        ],
                        "name": "Yoshua Bengio",
                        "slug": "Yoshua-Bengio",
                        "structuredName": {
                            "firstName": "Yoshua",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoshua Bengio"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "dge function used by PointNet++ is h\u0398(xi,x j)= h\u0398(x ), and the aggregation operation is also a max. AmonggraphCNNs,MoNet[Montietal.2017a],ECC[Simonovsky and Komodakis 2017], Graph Attention Networks [Veli\u010dkovi\u0107 et al. 2017], and the concurrent work [Atzmon et al. 2018] are the most related approaches. Their common denominator is a notion of a local patch on a graph, in which a convolution-type operation can be defined."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "way of constructing directional filters. Follow-up work proposed different local charting techniques using anisotropic diffusion [Boscaini et al. 2016] or Gaussian mixture models [Monti et al. 2017a; Veli\u010dkovi\u0107 et al. 2017]. In [Halimi et al. 2018; Litany et al. 2017b], a differentiable functional map [Ovsjanikov et al. 2012] layer was incorporated into a geometric deep neural network, allowing to do intrinsic structur"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "learnableparametersoftheGaussians (mean and covariance), and {\u03b81,...,\u03b8M}are the learnable filter coefficients.(11) is an instance of our general operation (1), with a 2[Simonovsky and Komodakis 2017; Veli\u010dkovi\u0107 et al. 2017] can be considered instances of [Monti et al. 2017a], with the difference that the weights are constructed employing features from adjacent nodes instead of graph structure; [Atzmon et al. 2018] is a"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 3292002,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "33998aff64ce51df8dee45989cdca4b6b1329ec4",
            "isKey": true,
            "numCitedBy": 5524,
            "numCiting": 47,
            "paperAbstract": {
                "fragments": [],
                "text": "We present graph attention networks (GATs), novel neural network architectures that operate on graph-structured data, leveraging masked self-attentional layers to address the shortcomings of prior methods based on graph convolutions or their approximations. By stacking layers in which nodes are able to attend over their neighborhoods' features, we enable (implicitly) specifying different weights to different nodes in a neighborhood, without requiring any kind of costly matrix operation (such as inversion) or depending on knowing the graph structure upfront. In this way, we address several key challenges of spectral-based graph neural networks simultaneously, and make our model readily applicable to inductive as well as transductive problems. Our GAT models have achieved or matched state-of-the-art results across four established transductive and inductive graph benchmarks: the Cora, Citeseer and Pubmed citation network datasets, as well as a protein-protein interaction dataset (wherein test graphs remain unseen during training)."
            },
            "slug": "Graph-Attention-Networks-Velickovic-Cucurull",
            "title": {
                "fragments": [],
                "text": "Graph Attention Networks"
            },
            "venue": {
                "fragments": [],
                "text": "ICLR"
            },
            "year": 2018
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2500309"
                        ],
                        "name": "Federico Monti",
                        "slug": "Federico-Monti",
                        "structuredName": {
                            "firstName": "Federico",
                            "lastName": "Monti",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Federico Monti"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1732570"
                        ],
                        "name": "M. Bronstein",
                        "slug": "M.-Bronstein",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Bronstein",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Bronstein"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2549032"
                        ],
                        "name": "X. Bresson",
                        "slug": "X.-Bresson",
                        "structuredName": {
                            "firstName": "Xavier",
                            "lastName": "Bresson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "X. Bresson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": " Laplacian eigenvectors [Shuman et al. 2013]. Computational drawbacks of this foundational approach were alleviated in follow-up works using polynomial [Defferrard et al. 2016; Kipf and Welling 2017; Monti et al. 2017b, 2018], or rational [Levie et al. 2017] spectral filters that avoid Laplacian eigendecomposition and guarantee localization. An alternative definition of non-Euclidean convolution employs spatial ra"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": " and {\u03b81,...,\u03b8M}are the learnable filter coefficients.(11) is an instance of our general operation (1), with a 2[Simonovsky and Komodakis 2017; Veli\u010dkovi\u0107 et al. 2017] can be considered instances of [Monti et al. 2017a], with the difference that the weights are constructed employing features from adjacent nodes instead of graph structure; [Atzmon et al. 2018] is also similar except that the weighting function is h"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "chael M. Bronstein, and Justin M. Solomon Aggregation Edge Function Learnable parameters PointNet [Qi et al. 2017b] \u2014 h\u0398(x i,xj)= h\u0398(x ) \u0398 PointNet++ [Qi et al. 2017c] max h\u0398(xi,x j)= h\u0398(x ) \u0398 MoNet [Monti et al. 2017a] \u02dd h\u03b8 m,wn (xi,xj)= \u03b8 m\u00b7(xj \u2299\u0434w n (u(xi,xj))) wn,\u03b8 PCNN [Atzmon et al. 2018] \u02dd h\u03b8 m (x i,x j)= (\u03b8m \u00b7x )\u0434(u(x ,x )) \u03b8m Table 1. Comparison to existing methods. The per-point weight wi in [Atzmon et a"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "ction h\u03b8 m, w n (x i,x j)= \u03b8m \u00b7(xj \u2299\u0434 n (u(x ,x ))) and\u25a1 = \u02dd .Again,theirgraphstructureisfixed,andu isconstructed based on the degrees of nodes. [Atzmon et al. 2018] can be seen as a special case of [Monti et al. 2017a] with\u0434as predefined Gaussian functions. Removing learnable parameters (w1,...,wN )and constructing a dense graph from point clouds, we have x\u2032 im = \u00d5 j:j\u2208V (\u03b8m \u00b7xj)\u0434(u(xi,xj)), (12) where u is the p"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "as well as a simple way of constructing directional filters. Follow-up work proposed different local charting techniques using anisotropic diffusion [Boscaini et al. 2016] or Gaussian mixture models [Monti et al. 2017a; Veli\u010dkovi\u0107 et al. 2017]. In [Halimi et al. 2018; Litany et al. 2017b], a differentiable functional map [Ovsjanikov et al. 2012] layer was incorporated into a geometric deep neural network, allowing"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 18052422,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "137bbe604334584fd4a1d6eb9218a588ae3dda3e",
            "isKey": false,
            "numCitedBy": 345,
            "numCiting": 48,
            "paperAbstract": {
                "fragments": [],
                "text": "Matrix completion models are among the most common formulations of recommender systems. Recent works have showed a boost of performance of these techniques when introducing the pairwise relationships between users/items in the form of graphs, and imposing smoothness priors on these graphs. However, such techniques do not fully exploit the local stationarity structures of user/item graphs, and the number of parameters to learn is linear w.r.t. the number of users and items. We propose a novel approach to overcome these limitations by using geometric deep learning on graphs. Our matrix completion architecture combines graph convolutional neural networks and recurrent neural networks to learn meaningful statistical graph-structured patterns and the non-linear diffusion process that generates the known ratings. This neural network system requires a constant number of parameters independent of the matrix size. We apply our method on both synthetic and real datasets, showing that it outperforms state-of-the-art techniques."
            },
            "slug": "Geometric-Matrix-Completion-with-Recurrent-Neural-Monti-Bronstein",
            "title": {
                "fragments": [],
                "text": "Geometric Matrix Completion with Recurrent Multi-Graph Neural Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This paper proposes a novel approach to overcome limitations of matrix completion techniques by using geometric deep learning on graphs, and applies this method on both synthetic and real datasets, showing that it outperforms state-of-the-art techniques."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1690177"
                        ],
                        "name": "M. Ovsjanikov",
                        "slug": "M.-Ovsjanikov",
                        "structuredName": {
                            "firstName": "Maks",
                            "lastName": "Ovsjanikov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Ovsjanikov"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1398681470"
                        ],
                        "name": "M. Ben-Chen",
                        "slug": "M.-Ben-Chen",
                        "structuredName": {
                            "firstName": "Mirela",
                            "lastName": "Ben-Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Ben-Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1932072"
                        ],
                        "name": "J. Solomon",
                        "slug": "J.-Solomon",
                        "structuredName": {
                            "firstName": "Justin",
                            "lastName": "Solomon",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Solomon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2983668"
                        ],
                        "name": "Adrian Butscher",
                        "slug": "Adrian-Butscher",
                        "structuredName": {
                            "firstName": "Adrian",
                            "lastName": "Butscher",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Adrian Butscher"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1744254"
                        ],
                        "name": "L. Guibas",
                        "slug": "L.-Guibas",
                        "structuredName": {
                            "firstName": "Leonidas",
                            "lastName": "Guibas",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Guibas"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 207194138,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "21a39ca716c37ccc133ff96c31cc71565d0c968e",
            "isKey": false,
            "numCitedBy": 403,
            "numCiting": 37,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a novel representation of maps between pairs of shapes that allows for efficient inference and manipulation. Key to our approach is a generalization of the notion of map that puts in correspondence real-valued functions rather than points on the shapes. By choosing a multi-scale basis for the function space on each shape, such as the eigenfunctions of its Laplace-Beltrami operator, we obtain a representation of a map that is very compact, yet fully suitable for global inference. Perhaps more remarkably, most natural constraints on a map, such as descriptor preservation, landmark correspondences, part preservation and operator commutativity become linear in this formulation. Moreover, the representation naturally supports certain algebraic operations such as map sum, difference and composition, and enables a number of applications, such as function or annotation transfer without establishing point-to-point correspondences. We exploit these properties to devise an efficient shape matching method, at the core of which is a single linear solve. The new method achieves state-of-the-art results on an isometric shape matching benchmark. We also show how this representation can be used to improve the quality of maps produced by existing shape matching methods, and illustrate its usefulness in segmentation transfer and joint analysis of shape collections."
            },
            "slug": "Functional-maps-Ovsjanikov-Ben-Chen",
            "title": {
                "fragments": [],
                "text": "Functional maps"
            },
            "tldr": {
                "abstractSimilarityScore": 61,
                "text": "A novel representation of maps between pairs of shapes that allows for efficient inference and manipulation and supports certain algebraic operations such as map sum, difference and composition, and enables a number of applications, such as function or annotation transfer without establishing point-to-point correspondences."
            },
            "venue": {
                "fragments": [],
                "text": "ACM Trans. Graph."
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47260481"
                        ],
                        "name": "F. Scarselli",
                        "slug": "F.-Scarselli",
                        "structuredName": {
                            "firstName": "Franco",
                            "lastName": "Scarselli",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Scarselli"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145467467"
                        ],
                        "name": "M. Gori",
                        "slug": "M.-Gori",
                        "structuredName": {
                            "firstName": "Marco",
                            "lastName": "Gori",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Gori"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733691"
                        ],
                        "name": "A. Tsoi",
                        "slug": "A.-Tsoi",
                        "structuredName": {
                            "firstName": "Ah",
                            "lastName": "Tsoi",
                            "middleNames": [
                                "Chung"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Tsoi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1784450"
                        ],
                        "name": "M. Hagenbuchner",
                        "slug": "M.-Hagenbuchner",
                        "structuredName": {
                            "firstName": "Markus",
                            "lastName": "Hagenbuchner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Hagenbuchner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3073217"
                        ],
                        "name": "G. Monfardini",
                        "slug": "G.-Monfardini",
                        "structuredName": {
                            "firstName": "Gabriele",
                            "lastName": "Monfardini",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Monfardini"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "plify a broad class of deep learning architectures on non-Euclidean structured data termed geometric deep learning [7]. These methods date back to early methods to construct neural networks on graphs [41]. More recently, [9] proposed a generalization of convolution for graphs via the Laplacian operator [44]. This foundational approach had a number of drawbacks including the computational complexity of"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 206756462,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3efd851140aa28e95221b55fcc5659eea97b172d",
            "isKey": false,
            "numCitedBy": 3206,
            "numCiting": 122,
            "paperAbstract": {
                "fragments": [],
                "text": "Many underlying relationships among data in several areas of science and engineering, e.g., computer vision, molecular chemistry, molecular biology, pattern recognition, and data mining, can be represented in terms of graphs. In this paper, we propose a new neural network model, called graph neural network (GNN) model, that extends existing neural network methods for processing the data represented in graph domains. This GNN model, which can directly process most of the practically useful types of graphs, e.g., acyclic, cyclic, directed, and undirected, implements a function tau(G,n) isin IRm that maps a graph G and one of its nodes n into an m-dimensional Euclidean space. A supervised learning algorithm is derived to estimate the parameters of the proposed GNN model. The computational cost of the proposed algorithm is also considered. Some experimental results are shown to validate the proposed learning algorithm, and to demonstrate its generalization capabilities."
            },
            "slug": "The-Graph-Neural-Network-Model-Scarselli-Gori",
            "title": {
                "fragments": [],
                "text": "The Graph Neural Network Model"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A new neural network model, called graph neural network (GNN) model, that extends existing neural network methods for processing the data represented in graph domains, and implements a function tau(G,n) isin IRm that maps a graph G and one of its nodes n into an m-dimensional Euclidean space."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Neural Networks"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2066145023"
                        ],
                        "name": "Oshri Halimi",
                        "slug": "Oshri-Halimi",
                        "structuredName": {
                            "firstName": "Oshri",
                            "lastName": "Halimi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Oshri Halimi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2528439"
                        ],
                        "name": "O. Litany",
                        "slug": "O.-Litany",
                        "structuredName": {
                            "firstName": "Or",
                            "lastName": "Litany",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Litany"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1796150"
                        ],
                        "name": "E. Rodol\u00e0",
                        "slug": "E.-Rodol\u00e0",
                        "structuredName": {
                            "firstName": "Emanuele",
                            "lastName": "Rodol\u00e0",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Rodol\u00e0"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49791556"
                        ],
                        "name": "A. Bronstein",
                        "slug": "A.-Bronstein",
                        "structuredName": {
                            "firstName": "Alexander",
                            "lastName": "Bronstein",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Bronstein"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143923265"
                        ],
                        "name": "R. Kimmel",
                        "slug": "R.-Kimmel",
                        "structuredName": {
                            "firstName": "Ron",
                            "lastName": "Kimmel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Kimmel"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 54446858,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f1ed01a2c0aa47b4e010861ef884980561ddb542",
            "isKey": false,
            "numCitedBy": 19,
            "numCiting": 51,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce the first completely unsupervised correspondence learning approach for deformable 3D shapes. Key to our model is the understanding that natural deformations (such as changes in pose) approximately preserve the metric structure of the surface, yielding a natural criterion to drive the learning process toward distortion-minimizing predictions. On this basis, we overcome the need for annotated data and replace it by a purely geometric criterion. The resulting learning model is class-agnostic, and is able to leverage any type of deformable geometric data for the training phase. In contrast to existing supervised approaches which specialize on the class seen at training time, we demonstrate stronger generalization as well as applicability to a variety of challenging settings. We showcase our method on a wide selection of correspondence benchmarks, where we outperform other methods in terms of accuracy, generalization, and efficiency."
            },
            "slug": "Self-supervised-Learning-of-Dense-Shape-Halimi-Litany",
            "title": {
                "fragments": [],
                "text": "Self-supervised Learning of Dense Shape Correspondence"
            },
            "tldr": {
                "abstractSimilarityScore": 86,
                "text": "This work introduces the first completely unsupervised correspondence learning approach for deformable 3D shapes, understanding that natural deformations approximately preserve the metric structure of the surface, yielding a natural criterion to drive the learning process toward distortion-minimizing predictions."
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 2018
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2119248435"
                        ],
                        "name": "Ming Liang",
                        "slug": "Ming-Liang",
                        "structuredName": {
                            "firstName": "Ming",
                            "lastName": "Liang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ming Liang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49188662"
                        ],
                        "name": "Binh Yang",
                        "slug": "Binh-Yang",
                        "structuredName": {
                            "firstName": "Binh",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Binh Yang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1892247"
                        ],
                        "name": "Shenlong Wang",
                        "slug": "Shenlong-Wang",
                        "structuredName": {
                            "firstName": "Shenlong",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shenlong Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2422559"
                        ],
                        "name": "R. Urtasun",
                        "slug": "R.-Urtasun",
                        "structuredName": {
                            "firstName": "Raquel",
                            "lastName": "Urtasun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Urtasun"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 84,
                                "start": 29
                            }
                        ],
                        "text": "2017], self-driving vehicles [Liang et al. 2018; Qi et al. 2017a; Wang et al. 2018b], robotics [Rusu et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 52211898,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "85d9aff092d860aebf8ea5aa255b06de25a1930e",
            "isKey": false,
            "numCitedBy": 443,
            "numCiting": 40,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we propose a novel 3D object detector that can exploit both LIDAR as well as cameras to perform very accurate localization. Towards this goal, we design an end-to-end learnable architecture that exploits continuous convolutions to fuse image and LIDAR feature maps at different levels of resolution. Our proposed continuous fusion layer encode both discrete-state image features as well as continuous geometric information. This enables us to design a novel, reliable and efficient end-to-end learnable 3D object detector based on multiple sensors. Our experimental evaluation on both KITTI as well as a large scale 3D object detection benchmark shows significant improvements over the state of the art."
            },
            "slug": "Deep-Continuous-Fusion-for-Multi-sensor-3D-Object-Liang-Yang",
            "title": {
                "fragments": [],
                "text": "Deep Continuous Fusion for Multi-sensor 3D Object Detection"
            },
            "tldr": {
                "abstractSimilarityScore": 92,
                "text": "This paper proposes a novel 3D object detector that can exploit both LIDAR as well as cameras to perform very accurate localization and designs an end-to-end learnable architecture that exploits continuous convolutions to fuse image and LIDar feature maps at different levels of resolution."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2018
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1798372"
                        ],
                        "name": "Iro Armeni",
                        "slug": "Iro-Armeni",
                        "structuredName": {
                            "firstName": "Iro",
                            "lastName": "Armeni",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Iro Armeni"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3114252"
                        ],
                        "name": "Ozan Sener",
                        "slug": "Ozan-Sener",
                        "structuredName": {
                            "firstName": "Ozan",
                            "lastName": "Sener",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ozan Sener"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40029556"
                        ],
                        "name": "A. Zamir",
                        "slug": "A.-Zamir",
                        "structuredName": {
                            "firstName": "Amir",
                            "lastName": "Zamir",
                            "middleNames": [
                                "Roshan"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Zamir"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "4910251"
                        ],
                        "name": "Helen Jiang",
                        "slug": "Helen-Jiang",
                        "structuredName": {
                            "firstName": "Helen",
                            "lastName": "Jiang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Helen Jiang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1770886"
                        ],
                        "name": "I. Brilakis",
                        "slug": "I.-Brilakis",
                        "structuredName": {
                            "firstName": "Ioannis",
                            "lastName": "Brilakis",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Brilakis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2113447583"
                        ],
                        "name": "Martin Fischer",
                        "slug": "Martin-Fischer",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "Fischer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Martin Fischer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1702137"
                        ],
                        "name": "S. Savarese",
                        "slug": "S.-Savarese",
                        "structuredName": {
                            "firstName": "Silvio",
                            "lastName": "Savarese",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Savarese"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9649070,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "dc3f8c8513441915408ab0549e9ac5f2f2f31eec",
            "isKey": false,
            "numCitedBy": 769,
            "numCiting": 43,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we propose a method for semantic parsing the 3D point cloud of an entire building using a hierarchical approach: first, the raw data is parsed into semantically meaningful spaces (e.g. rooms, etc) that are aligned into a canonical reference coordinate system. Second, the spaces are parsed into their structural and building elements (e.g. walls, columns, etc). Performing these with a strong notation of global 3D space is the backbone of our method. The alignment in the first step injects strong 3D priors from the canonical coordinate system into the second step for discovering elements. This allows diverse challenging scenarios as man-made indoor spaces often show recurrent geometric patterns while the appearance features can change drastically. We also argue that identification of structural elements in indoor spaces is essentially a detection problem, rather than segmentation which is commonly used. We evaluated our method on a new dataset of several buildings with a covered area of over 6, 000m2 and over 215 million points, demonstrating robust results readily useful for practical applications."
            },
            "slug": "3D-Semantic-Parsing-of-Large-Scale-Indoor-Spaces-Armeni-Sener",
            "title": {
                "fragments": [],
                "text": "3D Semantic Parsing of Large-Scale Indoor Spaces"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This paper argues that identification of structural elements in indoor spaces is essentially a detection problem, rather than segmentation which is commonly used, and proposes a method for semantic parsing the 3D point cloud of an entire building using a hierarchical approach."
            },
            "venue": {
                "fragments": [],
                "text": "2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1800504"
                        ],
                        "name": "S. Biasotti",
                        "slug": "S.-Biasotti",
                        "structuredName": {
                            "firstName": "Silvia",
                            "lastName": "Biasotti",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Biasotti"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152805888"
                        ],
                        "name": "A. Cerri",
                        "slug": "A.-Cerri",
                        "structuredName": {
                            "firstName": "Andrea",
                            "lastName": "Cerri",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Cerri"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49791556"
                        ],
                        "name": "A. Bronstein",
                        "slug": "A.-Bronstein",
                        "structuredName": {
                            "firstName": "Alexander",
                            "lastName": "Bronstein",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Bronstein"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1732570"
                        ],
                        "name": "M. Bronstein",
                        "slug": "M.-Bronstein",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Bronstein",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Bronstein"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 46244683,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f12fa334b9b50359675035ff67c26f14466cf131",
            "isKey": false,
            "numCitedBy": 103,
            "numCiting": 270,
            "paperAbstract": {
                "fragments": [],
                "text": "The recent introduction of 3D shape analysis frameworks able to quantify the deformation of a shape into another in terms of the variation of real functions yields a new interpretation of the 3D shape similarity assessment and opens new perspectives. Indeed, while the classical approaches to similarity mainly quantify it as a numerical score, map\u2010based methods also define (dense) shape correspondences. After presenting in detail the theoretical foundations underlying these approaches, we classify them by looking at their most salient features, including the kind of structure and invariance properties they capture, as well as the distances and the output modalities according to which the similarity between shapes is assessed and returned. We also review the usage of these methods in a number of 3D shape application domains, ranging from matching and retrieval to annotation and segmentation. Finally, the most promising directions for future research developments are discussed."
            },
            "slug": "Recent-Trends,-Applications,-and-Perspectives-in-3D-Biasotti-Cerri",
            "title": {
                "fragments": [],
                "text": "Recent Trends, Applications, and Perspectives in 3D Shape Similarity Assessment"
            },
            "tldr": {
                "abstractSimilarityScore": 80,
                "text": "3D shape analysis frameworks able to quantify the deformation of a shape into another in terms of the variation of real functions yields a new interpretation of the 3D shape similarity assessment, and the most promising directions for future research developments are discussed."
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Graph. Forum"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2500309"
                        ],
                        "name": "Federico Monti",
                        "slug": "Federico-Monti",
                        "structuredName": {
                            "firstName": "Federico",
                            "lastName": "Monti",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Federico Monti"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "36031867"
                        ],
                        "name": "Karl Otness",
                        "slug": "Karl-Otness",
                        "structuredName": {
                            "firstName": "Karl",
                            "lastName": "Otness",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Karl Otness"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1732570"
                        ],
                        "name": "M. Bronstein",
                        "slug": "M.-Bronstein",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Bronstein",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Bronstein"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 3637261,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e9842f649578886801a3b4ce40a89b9125f51daf",
            "isKey": false,
            "numCitedBy": 73,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "Deep learning on graphs and in particular, graph convolutional neural networks, have recently attracted significant attention in the machine learning community. Many of such techniques explore the analogy between the graph Laplacian eigenvectors and the classical Fourier basis, allowing to formulate the convolution as a multiplication in the spectral domain. One of the key drawback of spectral CNNs is their explicit assumption of an undirected graph, leading to a symmetric Laplacian matrix with orthogonal eigendecomposition. In this work we propose MotifNet, a graph CNN capable of dealing with directed graphs by exploiting local graph motifs. We present experimental evidence showing the advantage of our approach on real data."
            },
            "slug": "MOTIFNET:-A-MOTIF-BASED-GRAPH-CONVOLUTIONAL-NETWORK-Monti-Otness",
            "title": {
                "fragments": [],
                "text": "MOTIFNET: A MOTIF-BASED GRAPH CONVOLUTIONAL NETWORK FOR DIRECTED GRAPHS"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This work proposes MotifNet, a graph CNN capable of dealing with directed graphs by exploiting local graph motifs, and presents experimental evidence showing the advantage of the approach on real data."
            },
            "venue": {
                "fragments": [],
                "text": "2018 IEEE Data Science Workshop (DSW)"
            },
            "year": 2018
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2509955"
                        ],
                        "name": "S. Manay",
                        "slug": "S.-Manay",
                        "structuredName": {
                            "firstName": "Siddharth",
                            "lastName": "Manay",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Manay"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695302"
                        ],
                        "name": "D. Cremers",
                        "slug": "D.-Cremers",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Cremers",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Cremers"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3358033"
                        ],
                        "name": "Byung-Woo Hong",
                        "slug": "Byung-Woo-Hong",
                        "structuredName": {
                            "firstName": "Byung-Woo",
                            "lastName": "Hong",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Byung-Woo Hong"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144599246"
                        ],
                        "name": "A. Yezzi",
                        "slug": "A.-Yezzi",
                        "structuredName": {
                            "firstName": "Anthony",
                            "lastName": "Yezzi",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Yezzi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1715959"
                        ],
                        "name": "Stefano Soatto",
                        "slug": "Stefano-Soatto",
                        "structuredName": {
                            "firstName": "Stefano",
                            "lastName": "Soatto",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Stefano Soatto"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14304601,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "85836e306b669a76934c6dea8bafc8bb0299692e",
            "isKey": false,
            "numCitedBy": 258,
            "numCiting": 113,
            "paperAbstract": {
                "fragments": [],
                "text": "For shapes represented as closed planar contours, we introduce a class of functionals which are invariant with respect to the Euclidean group and which are obtained by performing integral operations. While such integral invariants enjoy some of the desirable properties of their differential counterparts, such as locality of computation (which allows matching under occlusions) and uniqueness of representation (asymptotically), they do not exhibit the noise sensitivity associated with differential quantities and, therefore, do not require presmoothing of the input shape. Our formulation allows the analysis of shapes at multiple scales. Based on integral invariants, we define a notion of distance between shapes. The proposed distance measure can be computed efficiently and allows warping the shape boundaries onto each other; its computation results in optimal point correspondence as an intermediate step. Numerical results on shape matching demonstrate that this framework can match shapes despite the deformation of subparts, missing parts and noise. As a quantitative analysis, we report matching scores for shape retrieval from a database"
            },
            "slug": "Integral-Invariants-for-Shape-Matching-Manay-Cremers",
            "title": {
                "fragments": [],
                "text": "Integral Invariants for Shape Matching"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "Numerical results on shape matching demonstrate that this framework can match shapes despite the deformation of subparts, missing parts and noise, and a notion of distance between shapes is defined."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50058359"
                        ],
                        "name": "D. Shuman",
                        "slug": "D.-Shuman",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Shuman",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Shuman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1799060"
                        ],
                        "name": "S. K. Narang",
                        "slug": "S.-K.-Narang",
                        "structuredName": {
                            "firstName": "Sunil",
                            "lastName": "Narang",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. K. Narang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1703189"
                        ],
                        "name": "P. Frossard",
                        "slug": "P.-Frossard",
                        "structuredName": {
                            "firstName": "Pascal",
                            "lastName": "Frossard",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Frossard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145029825"
                        ],
                        "name": "Antonio Ortega",
                        "slug": "Antonio-Ortega",
                        "structuredName": {
                            "firstName": "Antonio",
                            "lastName": "Ortega",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Antonio Ortega"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1697397"
                        ],
                        "name": "P. Vandergheynst",
                        "slug": "P.-Vandergheynst",
                        "structuredName": {
                            "firstName": "Pierre",
                            "lastName": "Vandergheynst",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Vandergheynst"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "[2015] generalized convolution to graphs via the Laplacian eigenvectors [Shuman et al. 2013]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1594725,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "39e223e6b5a6f8727e9f60b8b7c7720dc40a5dbc",
            "isKey": false,
            "numCitedBy": 2723,
            "numCiting": 73,
            "paperAbstract": {
                "fragments": [],
                "text": "In applications such as social, energy, transportation, sensor, and neuronal networks, high-dimensional data naturally reside on the vertices of weighted graphs. The emerging field of signal processing on graphs merges algebraic and spectral graph theoretic concepts with computational harmonic analysis to process such signals on graphs. In this tutorial overview, we outline the main challenges of the area, discuss different ways to define graph spectral domains, which are the analogs to the classical frequency domain, and highlight the importance of incorporating the irregular structures of graph data domains when processing signals on graphs. We then review methods to generalize fundamental operations such as filtering, translation, modulation, dilation, and downsampling to the graph setting and survey the localized, multiscale transforms that have been proposed to efficiently extract information from high-dimensional data on graphs. We conclude with a brief discussion of open issues and possible extensions."
            },
            "slug": "The-emerging-field-of-signal-processing-on-graphs:-Shuman-Narang",
            "title": {
                "fragments": [],
                "text": "The emerging field of signal processing on graphs: Extending high-dimensional data analysis to networks and other irregular domains"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "This tutorial overview outlines the main challenges of the emerging field of signal processing on graphs, discusses different ways to define graph spectral domains, which are the analogs to the classical frequency domain, and highlights the importance of incorporating the irregular structures of graph data domains when processing signals on graphs."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Signal Processing Magazine"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2689311"
                        ],
                        "name": "R. Rusu",
                        "slug": "R.-Rusu",
                        "structuredName": {
                            "firstName": "Radu",
                            "lastName": "Rusu",
                            "middleNames": [
                                "Bogdan"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Rusu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1709715"
                        ],
                        "name": "Zolt\u00e1n-Csaba M\u00e1rton",
                        "slug": "Zolt\u00e1n-Csaba-M\u00e1rton",
                        "structuredName": {
                            "firstName": "Zolt\u00e1n-Csaba",
                            "lastName": "M\u00e1rton",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zolt\u00e1n-Csaba M\u00e1rton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1810221"
                        ],
                        "name": "Nico Blodow",
                        "slug": "Nico-Blodow",
                        "structuredName": {
                            "firstName": "Nico",
                            "lastName": "Blodow",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nico Blodow"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3275804"
                        ],
                        "name": "Mihai Emanuel Dolha",
                        "slug": "Mihai-Emanuel-Dolha",
                        "structuredName": {
                            "firstName": "Mihai",
                            "lastName": "Dolha",
                            "middleNames": [
                                "Emanuel"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mihai Emanuel Dolha"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1746229"
                        ],
                        "name": "M. Beetz",
                        "slug": "M.-Beetz",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Beetz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Beetz"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 150,
                                "start": 146
                            }
                        ],
                        "text": "A few of the many recent applications of point cloud processing and analysis include indoor navigation [57], self-driving vehicles [33], robotics [40], and shape synthesis and modeling [14]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 12426733,
            "fieldsOfStudy": [
                "Environmental Science"
            ],
            "id": "d312672f278eb3914cc541520737e7a26980503d",
            "isKey": false,
            "numCitedBy": 850,
            "numCiting": 46,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Towards-3D-Point-cloud-based-object-maps-for-Rusu-M\u00e1rton",
            "title": {
                "fragments": [],
                "text": "Towards 3D Point cloud based object maps for household environments"
            },
            "venue": {
                "fragments": [],
                "text": "Robotics Auton. Syst."
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39849136"
                        ],
                        "name": "X. Wang",
                        "slug": "X.-Wang",
                        "structuredName": {
                            "firstName": "X.",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "X. Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2983898"
                        ],
                        "name": "Ross B. Girshick",
                        "slug": "Ross-B.-Girshick",
                        "structuredName": {
                            "firstName": "Ross",
                            "lastName": "Girshick",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ross B. Girshick"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1726095131"
                        ],
                        "name": "A. Gupta",
                        "slug": "A.-Gupta",
                        "structuredName": {
                            "firstName": "Abhinav",
                            "lastName": "Gupta",
                            "middleNames": [
                                "Kumar"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Gupta"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39353098"
                        ],
                        "name": "Kaiming He",
                        "slug": "Kaiming-He",
                        "structuredName": {
                            "firstName": "Kaiming",
                            "lastName": "He",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kaiming He"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "a connection to existing work, Non-local Neural Networks [Wang et al. 2018a] explored similar ideas in the video recognition field, and follow-up work by Xie et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 4852647,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8899094797e82c5c185a0893896320ef77f60e64",
            "isKey": false,
            "numCitedBy": 4088,
            "numCiting": 57,
            "paperAbstract": {
                "fragments": [],
                "text": "Both convolutional and recurrent operations are building blocks that process one local neighborhood at a time. In this paper, we present non-local operations as a generic family of building blocks for capturing long-range dependencies. Inspired by the classical non-local means method [4] in computer vision, our non-local operation computes the response at a position as a weighted sum of the features at all positions. This building block can be plugged into many computer vision architectures. On the task of video classification, even without any bells and whistles, our nonlocal models can compete or outperform current competition winners on both Kinetics and Charades datasets. In static image recognition, our non-local models improve object detection/segmentation and pose estimation on the COCO suite of tasks. Code will be made available."
            },
            "slug": "Non-local-Neural-Networks-Wang-Girshick",
            "title": {
                "fragments": [],
                "text": "Non-local Neural Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "This paper presents non-local operations as a generic family of building blocks for capturing long-range dependencies in computer vision and improves object detection/segmentation and pose estimation on the COCO suite of tasks."
            },
            "venue": {
                "fragments": [],
                "text": "2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2018
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "41016725"
                        ],
                        "name": "Thomas Kipf",
                        "slug": "Thomas-Kipf",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Kipf",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thomas Kipf"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1678311"
                        ],
                        "name": "M. Welling",
                        "slug": "M.-Welling",
                        "structuredName": {
                            "firstName": "Max",
                            "lastName": "Welling",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Welling"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 3144218,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "36eff562f65125511b5dfab68ce7f7a943c27478",
            "isKey": false,
            "numCitedBy": 11719,
            "numCiting": 43,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a scalable approach for semi-supervised learning on graph-structured data that is based on an efficient variant of convolutional neural networks which operate directly on graphs. We motivate the choice of our convolutional architecture via a localized first-order approximation of spectral graph convolutions. Our model scales linearly in the number of graph edges and learns hidden layer representations that encode both local graph structure and features of nodes. In a number of experiments on citation networks and on a knowledge graph dataset we demonstrate that our approach outperforms related methods by a significant margin."
            },
            "slug": "Semi-Supervised-Classification-with-Graph-Networks-Kipf-Welling",
            "title": {
                "fragments": [],
                "text": "Semi-Supervised Classification with Graph Convolutional Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 83,
                "text": "A scalable approach for semi-supervised learning on graph-structured data that is based on an efficient variant of convolutional neural networks which operate directly on graphs which outperforms related methods by a significant margin."
            },
            "venue": {
                "fragments": [],
                "text": "ICLR"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3093886"
                        ],
                        "name": "Max Jaderberg",
                        "slug": "Max-Jaderberg",
                        "structuredName": {
                            "firstName": "Max",
                            "lastName": "Jaderberg",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Max Jaderberg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34838386"
                        ],
                        "name": "K. Simonyan",
                        "slug": "K.-Simonyan",
                        "structuredName": {
                            "firstName": "Karen",
                            "lastName": "Simonyan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Simonyan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688869"
                        ],
                        "name": "Andrew Zisserman",
                        "slug": "Andrew-Zisserman",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Zisserman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Zisserman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2645384"
                        ],
                        "name": "K. Kavukcuoglu",
                        "slug": "K.-Kavukcuoglu",
                        "structuredName": {
                            "firstName": "Koray",
                            "lastName": "Kavukcuoglu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Kavukcuoglu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "ermore, the learned mapping is sensitive to the global transformation of the point cloud; to cope with this issue, PointNet employs a complex and computationally expensive spatial transformer network [16] to learn 3D alignment. Local information is important for feature learning in two ways. First, as for handcrafted descriptors, local features usually account for geometric relationships among neighbo"
                    },
                    "intents": []
                }
            ],
            "corpusId": 6099034,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fe87ea16d5eb1c7509da9a0314bbf4c7b0676506",
            "isKey": false,
            "numCitedBy": 4579,
            "numCiting": 47,
            "paperAbstract": {
                "fragments": [],
                "text": "Convolutional Neural Networks define an exceptionally powerful class of models, but are still limited by the lack of ability to be spatially invariant to the input data in a computationally and parameter efficient manner. In this work we introduce a new learnable module, the Spatial Transformer, which explicitly allows the spatial manipulation of data within the network. This differentiable module can be inserted into existing convolutional architectures, giving neural networks the ability to actively spatially transform feature maps, conditional on the feature map itself, without any extra training supervision or modification to the optimisation process. We show that the use of spatial transformers results in models which learn invariance to translation, scale, rotation and more generic warping, resulting in state-of-the-art performance on several benchmarks, and for a number of classes of transformations."
            },
            "slug": "Spatial-Transformer-Networks-Jaderberg-Simonyan",
            "title": {
                "fragments": [],
                "text": "Spatial Transformer Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "This work introduces a new learnable module, the Spatial Transformer, which explicitly allows the spatial manipulation of data within the network, and can be inserted into existing convolutional architectures, giving neural networks the ability to actively spatially transform feature maps."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50172592"
                        ],
                        "name": "Serge J. Belongie",
                        "slug": "Serge-J.-Belongie",
                        "structuredName": {
                            "firstName": "Serge",
                            "lastName": "Belongie",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Serge J. Belongie"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143751119"
                        ],
                        "name": "Jitendra Malik",
                        "slug": "Jitendra-Malik",
                        "structuredName": {
                            "firstName": "Jitendra",
                            "lastName": "Malik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jitendra Malik"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2121009"
                        ],
                        "name": "J. Puzicha",
                        "slug": "J.-Puzicha",
                        "structuredName": {
                            "firstName": "Jan",
                            "lastName": "Puzicha",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Puzicha"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "can distinguish between extrinsic and intrinsic descriptors. Extrinsic descriptors usually are derived from the coordinates of the shape in 3D space and includes classical methods like shape context [Belongie et al. 2001], spin images [Johnson and Hebert 1999], integral features [Manay et al. 2006], distance-based descriptors [Ling and Jacobs 2007], point feature histograms [Rusu et al .2009, 2008a], and normal histo"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14966986,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8ed3f249e818d9314e90a67cc45df7a24a37d933",
            "isKey": false,
            "numCitedBy": 616,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "We develop an approach to object recognition based on matching shapes and using a resulting measure of similarity in a nearest neighbor classifier. The key algorithmic problem here is that of finding pointwise correspondences between an image shape and a stored prototype shape. We introduce a new shape descriptor, the shape context, which makes this possible, using a simple and robust algorithm. The shape context at a point captures the distribution over relative positions of other shape points and thus summarizes global shape in a rich, local descriptor. We demonstrate that shape contexts greatly simplify recovery of correspondences between points of two given shapes. Once shapes are aligned, shape contexts are used to define a robust score for measuring shape similarity. We have used this score in a nearest-neighbor classifier for recognition of hand written digits as well as 3D objects, using exactly the same distance function. On the benchmark MNIST dataset of handwritten digits, this yields an error rate of 0.63%, outperforming other published techniques."
            },
            "slug": "Shape-Context:-A-New-Descriptor-for-Shape-Matching-Belongie-Malik",
            "title": {
                "fragments": [],
                "text": "Shape Context: A New Descriptor for Shape Matching and Object Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "It is demonstrated that shape contexts greatly simplify recovery of correspondences between points of two given shapes, and is used in a nearest-neighbor classifier for recognition of hand written digits as well as 3D objects, using exactly the same distance function."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2064160"
                        ],
                        "name": "A. Krizhevsky",
                        "slug": "A.-Krizhevsky",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Krizhevsky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Krizhevsky"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1701686"
                        ],
                        "name": "Ilya Sutskever",
                        "slug": "Ilya-Sutskever",
                        "structuredName": {
                            "firstName": "Ilya",
                            "lastName": "Sutskever",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ilya Sutskever"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 195908774,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "abd1c342495432171beb7ca8fd9551ef13cbd0ff",
            "isKey": false,
            "numCitedBy": 80944,
            "numCiting": 50,
            "paperAbstract": {
                "fragments": [],
                "text": "We trained a large, deep convolutional neural network to classify the 1.2 million high-resolution images in the ImageNet LSVRC-2010 contest into the 1000 different classes. On the test data, we achieved top-1 and top-5 error rates of 37.5% and 17.0%, respectively, which is considerably better than the previous state-of-the-art. The neural network, which has 60 million parameters and 650,000 neurons, consists of five convolutional layers, some of which are followed by max-pooling layers, and three fully connected layers with a final 1000-way softmax. To make training faster, we used non-saturating neurons and a very efficient GPU implementation of the convolution operation. To reduce overfitting in the fully connected layers we employed a recently developed regularization method called \"dropout\" that proved to be very effective. We also entered a variant of this model in the ILSVRC-2012 competition and achieved a winning top-5 test error rate of 15.3%, compared to 26.2% achieved by the second-best entry."
            },
            "slug": "ImageNet-classification-with-deep-convolutional-Krizhevsky-Sutskever",
            "title": {
                "fragments": [],
                "text": "ImageNet classification with deep convolutional neural networks"
            },
            "tldr": {
                "abstractSimilarityScore": 71,
                "text": "A large, deep convolutional neural network was trained to classify the 1.2 million high-resolution images in the ImageNet LSVRC-2010 contest into the 1000 different classes and employed a recently developed regularization method called \"dropout\" that proved to be very effective."
            },
            "venue": {
                "fragments": [],
                "text": "Commun. ACM"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1732570"
                        ],
                        "name": "M. Bronstein",
                        "slug": "M.-Bronstein",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Bronstein",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Bronstein"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2010660"
                        ],
                        "name": "Iasonas Kokkinos",
                        "slug": "Iasonas-Kokkinos",
                        "structuredName": {
                            "firstName": "Iasonas",
                            "lastName": "Kokkinos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Iasonas Kokkinos"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9117881,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2ec6dd508e48231fcbe9c11c7e18790b0dee8b26",
            "isKey": false,
            "numCitedBy": 548,
            "numCiting": 51,
            "paperAbstract": {
                "fragments": [],
                "text": "One of the biggest challenges in non-rigid shape retrieval and comparison is the design of a shape descriptor that would maintain invariance under a wide class of transformations the shape can undergo. Recently, heat kernel signature was introduced as an intrinsic local shape descriptor based on diffusion scale-space analysis. In this paper, we develop a scale-invariant version of the heat kernel descriptor. Our construction is based on a logarithmically sampled scale-space in which shape scaling corresponds, up to a multiplicative constant, to a translation. This translation is undone using the magnitude of the Fourier transform. The proposed scale-invariant local descriptors can be used in the bag-of-features framework for shape retrieval in the presence of transformations such as isometric deformations, missing data, topological noise, and global and local scaling. We get significant performance improvement over state-of-the-art algorithms on recently established non-rigid shape retrieval benchmarks."
            },
            "slug": "Scale-invariant-heat-kernel-signatures-for-shape-Bronstein-Kokkinos",
            "title": {
                "fragments": [],
                "text": "Scale-invariant heat kernel signatures for non-rigid shape recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "A scale-invariant version of the heat kernel descriptor that can be used in the bag-of-features framework for shape retrieval in the presence of transformations such as isometric deformations, missing data, topological noise, and global and local scaling."
            },
            "venue": {
                "fragments": [],
                "text": "2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2266326"
                        ],
                        "name": "Federico Tombari",
                        "slug": "Federico-Tombari",
                        "structuredName": {
                            "firstName": "Federico",
                            "lastName": "Tombari",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Federico Tombari"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2607607"
                        ],
                        "name": "Samuele Salti",
                        "slug": "Samuele-Salti",
                        "structuredName": {
                            "firstName": "Samuele",
                            "lastName": "Salti",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Samuele Salti"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9395079"
                        ],
                        "name": "L. D. Stefano",
                        "slug": "L.-D.-Stefano",
                        "structuredName": {
                            "firstName": "Luigi",
                            "lastName": "Stefano",
                            "middleNames": [
                                "di"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. D. Stefano"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 57,
                                "start": 36
                            }
                        ],
                        "text": "2009, 2008a), and normal histograms (Tombari et al. 2011), to name a few."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14020753,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2c93afdbecd3029500cb47a0bcd73ed3aace01e7",
            "isKey": false,
            "numCitedBy": 291,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "Motivated by the increasing availability of 3D sensors capable of delivering both shape and texture information, this paper presents a novel descriptor for feature matching in 3D data enriched with texture. The proposed approach stems from the theory of a recently proposed descriptor for 3D data which relies on shape only, and represents its generalization to the case of multiple cues associated with a 3D mesh. The proposed descriptor, dubbed CSHOT, is demonstrated to notably improve the accuracy of feature matching in challenging object recognition scenarios characterized by the presence of clutter and occlusions."
            },
            "slug": "A-combined-texture-shape-descriptor-for-enhanced-3D-Tombari-Salti",
            "title": {
                "fragments": [],
                "text": "A combined texture-shape descriptor for enhanced 3D feature matching"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "The proposed descriptor, dubbed CSHOT, is demonstrated to notably improve the accuracy of feature matching in challenging object recognition scenarios characterized by the presence of clutter and occlusions."
            },
            "venue": {
                "fragments": [],
                "text": "2011 18th IEEE International Conference on Image Processing"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47002813"
                        ],
                        "name": "Yujia Li",
                        "slug": "Yujia-Li",
                        "structuredName": {
                            "firstName": "Yujia",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yujia Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1725299"
                        ],
                        "name": "Daniel Tarlow",
                        "slug": "Daniel-Tarlow",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Tarlow",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Daniel Tarlow"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2107692"
                        ],
                        "name": "Marc Brockschmidt",
                        "slug": "Marc-Brockschmidt",
                        "structuredName": {
                            "firstName": "Marc",
                            "lastName": "Brockschmidt",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Marc Brockschmidt"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1804104"
                        ],
                        "name": "R. Zemel",
                        "slug": "R.-Zemel",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Zemel",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Zemel"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "2009], recently improved with gated recurrent units [Li et al. 2016] and neural message passing [Gilmer et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 8393918,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "492f57ee9ceb61fb5a47ad7aebfec1121887a175",
            "isKey": false,
            "numCitedBy": 1968,
            "numCiting": 42,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract: Graph-structured data appears frequently in domains including chemistry, natural language semantics, social networks, and knowledge bases. In this work, we study feature learning techniques for graph-structured inputs. Our starting point is previous work on Graph Neural Networks (Scarselli et al., 2009), which we modify to use gated recurrent units and modern optimization techniques and then extend to output sequences. The result is a flexible and broadly useful class of neural network models that has favorable inductive biases relative to purely sequence-based models (e.g., LSTMs) when the problem is graph-structured. We demonstrate the capabilities on some simple AI (bAbI) and graph algorithm learning tasks. We then show it achieves state-of-the-art performance on a problem from program verification, in which subgraphs need to be matched to abstract data structures."
            },
            "slug": "Gated-Graph-Sequence-Neural-Networks-Li-Tarlow",
            "title": {
                "fragments": [],
                "text": "Gated Graph Sequence Neural Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This work studies feature learning techniques for graph-structured inputs and achieves state-of-the-art performance on a problem from program verification, in which subgraphs need to be matched to abstract data structures."
            },
            "venue": {
                "fragments": [],
                "text": "ICLR"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2065040247"
                        ],
                        "name": "Andrew Brock",
                        "slug": "Andrew-Brock",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Brock",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Brock"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2067962067"
                        ],
                        "name": "Theodore Lim",
                        "slug": "Theodore-Lim",
                        "structuredName": {
                            "firstName": "Theodore",
                            "lastName": "Lim",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Theodore Lim"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50361260"
                        ],
                        "name": "J. Ritchie",
                        "slug": "J.-Ritchie",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Ritchie",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Ritchie"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32233090"
                        ],
                        "name": "Nick Weston",
                        "slug": "Nick-Weston",
                        "structuredName": {
                            "firstName": "Nick",
                            "lastName": "Weston",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nick Weston"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2271164,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "87c757138d273ccd38216ca5266406a503507077",
            "isKey": false,
            "numCitedBy": 406,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "When working with three-dimensional data, choice of representation is key. We explore voxel-based models, and present evidence for the viability of voxellated representations in applications including shape modeling and object classification. Our key contributions are methods for training voxel-based variational autoencoders, a user interface for exploring the latent space learned by the autoencoder, and a deep convolutional neural network architecture for object classification. We address challenges unique to voxel-based representations, and empirically evaluate our models on the ModelNet benchmark, where we demonstrate a 51.5% relative improvement in the state of the art for object classification."
            },
            "slug": "Generative-and-Discriminative-Voxel-Modeling-with-Brock-Lim",
            "title": {
                "fragments": [],
                "text": "Generative and Discriminative Voxel Modeling with Convolutional Neural Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "Methods for training voxel-based variational autoencoders, a user interface for exploring the latent space learned by the autoencoder, and a deep convolutional neural network architecture for object classification are presented."
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2117748"
                        ],
                        "name": "Yuke Zhu",
                        "slug": "Yuke-Zhu",
                        "structuredName": {
                            "firstName": "Yuke",
                            "lastName": "Zhu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yuke Zhu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3012475"
                        ],
                        "name": "Roozbeh Mottaghi",
                        "slug": "Roozbeh-Mottaghi",
                        "structuredName": {
                            "firstName": "Roozbeh",
                            "lastName": "Mottaghi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Roozbeh Mottaghi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3386570"
                        ],
                        "name": "Eric Kolve",
                        "slug": "Eric-Kolve",
                        "structuredName": {
                            "firstName": "Eric",
                            "lastName": "Kolve",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Eric Kolve"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35198686"
                        ],
                        "name": "Joseph J. Lim",
                        "slug": "Joseph-J.-Lim",
                        "structuredName": {
                            "firstName": "Joseph",
                            "lastName": "Lim",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Joseph J. Lim"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1726095131"
                        ],
                        "name": "A. Gupta",
                        "slug": "A.-Gupta",
                        "structuredName": {
                            "firstName": "Abhinav",
                            "lastName": "Gupta",
                            "middleNames": [
                                "Kumar"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Gupta"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48004138"
                        ],
                        "name": "Li Fei-Fei",
                        "slug": "Li-Fei-Fei",
                        "structuredName": {
                            "firstName": "Li",
                            "lastName": "Fei-Fei",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Li Fei-Fei"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143787583"
                        ],
                        "name": "Ali Farhadi",
                        "slug": "Ali-Farhadi",
                        "structuredName": {
                            "firstName": "Ali",
                            "lastName": "Farhadi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ali Farhadi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "ing due to ef\ufb01ciency considerations or instability of these techniques in the presence of noise. A few of the many recent applications of point cloud processing and analysis include indoor navigation [57], self-driving vehicles [33], robotics [40], and shape synthesis and modeling [14]. Modern applications demand high-level processing of point clouds. Rather than identifying salient geometric features"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2305273,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7af7f2f539cd3479faae4c66bbef49b0f66202fa",
            "isKey": false,
            "numCitedBy": 991,
            "numCiting": 55,
            "paperAbstract": {
                "fragments": [],
                "text": "Two less addressed issues of deep reinforcement learning are (1) lack of generalization capability to new goals, and (2) data inefficiency, i.e., the model requires several (and often costly) episodes of trial and error to converge, which makes it impractical to be applied to real-world scenarios. In this paper, we address these two issues and apply our model to target-driven visual navigation. To address the first issue, we propose an actor-critic model whose policy is a function of the goal as well as the current state, which allows better generalization. To address the second issue, we propose the AI2-THOR framework, which provides an environment with high-quality 3D scenes and a physics engine. Our framework enables agents to take actions and interact with objects. Hence, we can collect a huge number of training samples efficiently. We show that our proposed method (1) converges faster than the state-of-the-art deep reinforcement learning methods, (2) generalizes across targets and scenes, (3) generalizes to a real robot scenario with a small amount of fine-tuning (although the model is trained in simulation), (4) is end-to-end trainable and does not need feature engineering, feature matching between frames or 3D reconstruction of the environment."
            },
            "slug": "Target-driven-visual-navigation-in-indoor-scenes-Zhu-Mottaghi",
            "title": {
                "fragments": [],
                "text": "Target-driven visual navigation in indoor scenes using deep reinforcement learning"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "This paper proposes an actor-critic model whose policy is a function of the goal as well as the current state, which allows better generalization and proposes the AI2-THOR framework, which provides an environment with high-quality 3D scenes and a physics engine."
            },
            "venue": {
                "fragments": [],
                "text": "2017 IEEE International Conference on Robotics and Automation (ICRA)"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1805398"
                        ],
                        "name": "Haibin Ling",
                        "slug": "Haibin-Ling",
                        "structuredName": {
                            "firstName": "Haibin",
                            "lastName": "Ling",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Haibin Ling"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34734622"
                        ],
                        "name": "D. Jacobs",
                        "slug": "D.-Jacobs",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Jacobs",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Jacobs"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "e shape in 3D space and includes classical methods like shape context [Belongie et al. 2001], spin images [Johnson and Hebert 1999], integral features [Manay et al. 2006], distance-based descriptors [Ling and Jacobs 2007], point feature histograms [Rusu et al .2009, 2008a], and normal histograms [Tombari et al 2011], to name a few. Intrinsic descriptors treat the 3D shape as a manifold whose metric structure is discr"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 17848433,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c9bb27a60b6c2555a4c01c4c0b8808f1e3625403",
            "isKey": false,
            "numCitedBy": 1082,
            "numCiting": 55,
            "paperAbstract": {
                "fragments": [],
                "text": "Part structure and articulation are of fundamental importance in computer and human vision. We propose using the inner-distance to build shape descriptors that are robust to articulation and capture part structure. The inner-distance is defined as the length of the shortest path between landmark points within the shape silhouette. We show that it is articulation insensitive and more effective at capturing part structures than the Euclidean distance. This suggests that the inner-distance can be used as a replacement for the Euclidean distance to build more accurate descriptors for complex shapes, especially for those with articulated parts. In addition, texture information along the shortest path can be used to further improve shape classification. With this idea, we propose three approaches to using the inner-distance. The first method combines the inner-distance and multidimensional scaling (MDS) to build articulation invariant signatures for articulated shapes. The second method uses the inner-distance to build a new shape descriptor based on shape contexts. The third one extends the second one by considering the texture information along shortest paths. The proposed approaches have been tested on a variety of shape databases, including an articulated shape data set, MPEG7 CE-Shape-1, Kimia silhouettes, the ETH-80 data set, two leaf data sets, and a human motion silhouette data set. In all the experiments, our methods demonstrate effective performance compared with other algorithms"
            },
            "slug": "Shape-Classification-Using-the-Inner-Distance-Ling-Jacobs",
            "title": {
                "fragments": [],
                "text": "Shape Classification Using the Inner-Distance"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "It is suggested that the inner-distance can be used as a replacement for the Euclidean distance to build more accurate descriptors for complex shapes, especially for those with articulated parts."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153440022"
                        ],
                        "name": "Ian J. Goodfellow",
                        "slug": "Ian-J.-Goodfellow",
                        "structuredName": {
                            "firstName": "Ian",
                            "lastName": "Goodfellow",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ian J. Goodfellow"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1403025868"
                        ],
                        "name": "Jean Pouget-Abadie",
                        "slug": "Jean-Pouget-Abadie",
                        "structuredName": {
                            "firstName": "Jean",
                            "lastName": "Pouget-Abadie",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jean Pouget-Abadie"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153583218"
                        ],
                        "name": "Mehdi Mirza",
                        "slug": "Mehdi-Mirza",
                        "structuredName": {
                            "firstName": "Mehdi",
                            "lastName": "Mirza",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mehdi Mirza"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2113742925"
                        ],
                        "name": "Bing Xu",
                        "slug": "Bing-Xu",
                        "structuredName": {
                            "firstName": "Bing",
                            "lastName": "Xu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bing Xu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1393680089"
                        ],
                        "name": "David Warde-Farley",
                        "slug": "David-Warde-Farley",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Warde-Farley",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David Warde-Farley"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1955694"
                        ],
                        "name": "Sherjil Ozair",
                        "slug": "Sherjil-Ozair",
                        "structuredName": {
                            "firstName": "Sherjil",
                            "lastName": "Ozair",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sherjil Ozair"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1760871"
                        ],
                        "name": "Aaron C. Courville",
                        "slug": "Aaron-C.-Courville",
                        "structuredName": {
                            "firstName": "Aaron",
                            "lastName": "Courville",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Aaron C. Courville"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751762"
                        ],
                        "name": "Yoshua Bengio",
                        "slug": "Yoshua-Bengio",
                        "structuredName": {
                            "firstName": "Yoshua",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoshua Bengio"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1033682,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "54e325aee6b2d476bbbb88615ac15e251c6e8214",
            "isKey": false,
            "numCitedBy": 29654,
            "numCiting": 41,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a new framework for estimating generative models via an adversarial process, in which we simultaneously train two models: a generative model G that captures the data distribution, and a discriminative model D that estimates the probability that a sample came from the training data rather than G. The training procedure for G is to maximize the probability of D making a mistake. This framework corresponds to a minimax two-player game. In the space of arbitrary functions G and D, a unique solution exists, with G recovering the training data distribution and D equal to \u00bd everywhere. In the case where G and D are defined by multilayer perceptrons, the entire system can be trained with backpropagation. There is no need for any Markov chains or unrolled approximate inference networks during either training or generation of samples. Experiments demonstrate the potential of the framework through qualitative and quantitative evaluation of the generated samples."
            },
            "slug": "Generative-Adversarial-Nets-Goodfellow-Pouget-Abadie",
            "title": {
                "fragments": [],
                "text": "Generative Adversarial Nets"
            },
            "tldr": {
                "abstractSimilarityScore": 93,
                "text": "A new framework for estimating generative models via an adversarial process, in which two models are simultaneously train: a generative model G that captures the data distribution and a discriminative model D that estimates the probability that a sample came from the training data rather than G."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39668247"
                        ],
                        "name": "A. Berg",
                        "slug": "A.-Berg",
                        "structuredName": {
                            "firstName": "Alexander",
                            "lastName": "Berg",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Berg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143751119"
                        ],
                        "name": "Jitendra Malik",
                        "slug": "Jitendra-Malik",
                        "structuredName": {
                            "firstName": "Jitendra",
                            "lastName": "Malik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jitendra Malik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 181,
                                "start": 119
                            }
                        ],
                        "text": "A comprehensive overview of hand-designed point features is out of the scope of this paper, but we refer the reader to [Biasotti et al. 2016; Guo et al. 2014; Van Kaick et al. 2011] for discussion."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 8152491,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cc1d7345c22c17735222762ba8bac4ffa348b85d",
            "isKey": false,
            "numCitedBy": 142,
            "numCiting": 55,
            "paperAbstract": {
                "fragments": [],
                "text": "We address comparing related, but not identical shapes in images following a deformable template strategy. At the heart of this is the notion of an alignment between the shapes to be matched. The transformation necessary for alignment and the remaining differences after alignment are then used to make a comparison. \nA model determines what kind of deformations or alignments are acceptable, and what variation in appearance should remain after alignment. This ties strongly with the idea that the difference in shape is the residual difference, after some family of transformations has been applied for alignment. \nFinding an alignment of a model to a novel object involves search through the space of possible alignments. In many settings this search is quite difficult. This work shows that the search can be approximated by an easier discrete matching problem between key points on a model and a novel object. This is a departure from traditional approaches to deformable template matching that concentrate on analyzing differential models. This thesis presents theories and experiments on searching for, identifying, and using alignments found via discrete matchings. \nIn particular we present a mathematical and ecological motivation for a medium scale descriptor of shape, geometric blur. Geometric blur is an average over transformations of a sparse signal or feature channel, and can be computed using a spatially varying convolution. The resulting shape descriptors are useful for evaluating local shape similarity. Experiments demonstrate their efficacy for image classification and shape correspondence. \nFinding alignments between shapes is formulated as an optimization problem over discrete matchings between feature points in images. Similarity between putative correspondences is measured using geometric blur, and the deformation in the configuration of points is measured by summing over deformations in pairwise relationships. The snatching problem is formulated as an integer quadratic programming problem and approximated with a simple technique. Experimental results indicate that this generic model of local shape and deformation is applicable across a wide variety of object categories, providing good (currently the best known) performance for object recognition and localization on a difficult object recognition benchmark. \nFurthermore this generic object alignment strategy can be used to model variation in images of an object category, identifying the repeated object structures and providing automatic localization of the objects."
            },
            "slug": "Shape-Matching-and-Object-Recognition-Berg-Malik",
            "title": {
                "fragments": [],
                "text": "Shape Matching and Object Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "Experimental results indicate that this generic model of local shape and deformation is applicable across a wide variety of object categories, providing good performance for object recognition and localization on a difficult object recognition benchmark."
            },
            "venue": {
                "fragments": [],
                "text": "Toward Category-Level Object Recognition"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2152147554"
                        ],
                        "name": "Jian Sun",
                        "slug": "Jian-Sun",
                        "structuredName": {
                            "firstName": "Jian",
                            "lastName": "Sun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jian Sun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1690177"
                        ],
                        "name": "M. Ovsjanikov",
                        "slug": "M.-Ovsjanikov",
                        "structuredName": {
                            "firstName": "Maks",
                            "lastName": "Ovsjanikov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Ovsjanikov"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1744254"
                        ],
                        "name": "L. Guibas",
                        "slug": "L.-Guibas",
                        "structuredName": {
                            "firstName": "Leonidas",
                            "lastName": "Guibas",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Guibas"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "are by de\ufb01nition intrinsic and invariant to isometric deformation. Representatives of this class include spectral descriptors such as global point signatures [37], the heat and wave kernel signatures [48, 2], and variants [8]. Most recently, several approaches wrap machine learning schemes around standard descriptors [15, 42]. Learned Features. In computer vision, approaches relying on \u2018hand-crafted\u2019 fea"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 12701882,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3e847a57817dd4a24eb0d843ac62a2f602058808",
            "isKey": false,
            "numCitedBy": 1427,
            "numCiting": 43,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a novel point signature based on the properties of the heat diffusion process on a shape. Our signature, called the Heat Kernel Signature (or HKS), is obtained by restricting the well\u2010known heat kernel to the temporal domain. Remarkably we show that under certain mild assumptions, HKS captures all of the information contained in the heat kernel, and characterizes the shape up to isometry. This means that the restriction to the temporal domain, on the one hand, makes HKS much more concise and easily commensurable, while on the other hand, it preserves all of the information about the intrinsic geometry of the shape. In addition, HKS inherits many useful properties from the heat kernel, which means, in particular, that it is stable under perturbations of the shape. Our signature also provides a natural and efficiently computable multi\u2010scale way to capture information about neighborhoods of a given point, which can be extremely useful in many applications. To demonstrate the practical relevance of our signature, we present several methods for non\u2010rigid multi\u2010scale matching based on the HKS and use it to detect repeated structure within the same shape and across a collection of shapes."
            },
            "slug": "A-Concise-and-Provably-Informative-Multi\u2010Scale-on-Sun-Ovsjanikov",
            "title": {
                "fragments": [],
                "text": "A Concise and Provably Informative Multi\u2010Scale Signature Based on Heat Diffusion"
            },
            "tldr": {
                "abstractSimilarityScore": 53,
                "text": "The Heat Kernel Signature, called the HKS, is obtained by restricting the well\u2010known heat kernel to the temporal domain and shows that under certain mild assumptions, HKS captures all of the information contained in the heat kernel, and characterizes the shape up to isometry."
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Graph. Forum"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3011497"
                        ],
                        "name": "Cihang Xie",
                        "slug": "Cihang-Xie",
                        "structuredName": {
                            "firstName": "Cihang",
                            "lastName": "Xie",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Cihang Xie"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "98264506"
                        ],
                        "name": "Yuxin Wu",
                        "slug": "Yuxin-Wu",
                        "structuredName": {
                            "firstName": "Yuxin",
                            "lastName": "Wu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yuxin Wu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1803520"
                        ],
                        "name": "L. V. D. Maaten",
                        "slug": "L.-V.-D.-Maaten",
                        "structuredName": {
                            "firstName": "Laurens",
                            "lastName": "Maaten",
                            "middleNames": [
                                "van",
                                "der"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. V. D. Maaten"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145081362"
                        ],
                        "name": "A. Yuille",
                        "slug": "A.-Yuille",
                        "structuredName": {
                            "firstName": "Alan",
                            "lastName": "Yuille",
                            "middleNames": [
                                "Loddon"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Yuille"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39353098"
                        ],
                        "name": "Kaiming He",
                        "slug": "Kaiming-He",
                        "structuredName": {
                            "firstName": "Kaiming",
                            "lastName": "He",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kaiming He"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 54462665,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "41071dbbbcbb27af3fec70de045f19c28535f5b7",
            "isKey": false,
            "numCitedBy": 534,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "Adversarial attacks to image classification systems present challenges to convolutional networks and opportunities for understanding them. This study suggests that adversarial perturbations on images lead to noise in the features constructed by these networks. Motivated by this observation, we develop new network architectures that increase adversarial robustness by performing feature denoising. Specifically, our networks contain blocks that denoise the features using non-local means or other filters; the entire networks are trained end-to-end. When combined with adversarial training, our feature denoising networks substantially improve the state-of-the-art in adversarial robustness in both white-box and black-box attack settings. On ImageNet, under 10-iteration PGD white-box attacks where prior art has 27.9% accuracy, our method achieves 55.7%; even under extreme 2000-iteration PGD white-box attacks, our method secures 42.6% accuracy. Our method was ranked first in Competition on Adversarial Attacks and Defenses (CAAD) 2018 --- it achieved 50.6% classification accuracy on a secret, ImageNet-like test dataset against 48 unknown attackers, surpassing the runner-up approach by ~10%. Code is available at https://github.com/facebookresearch/ImageNet-Adversarial-Training."
            },
            "slug": "Feature-Denoising-for-Improving-Adversarial-Xie-Wu",
            "title": {
                "fragments": [],
                "text": "Feature Denoising for Improving Adversarial Robustness"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "It is suggested that adversarial perturbations on images lead to noise in the features constructed by these networks, and new network architectures are developed that increase adversarial robustness by performing feature denoising."
            },
            "venue": {
                "fragments": [],
                "text": "2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)"
            },
            "year": 2019
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2058362"
                        ],
                        "name": "J. Gilmer",
                        "slug": "J.-Gilmer",
                        "structuredName": {
                            "firstName": "Justin",
                            "lastName": "Gilmer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Gilmer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2601641"
                        ],
                        "name": "S. Schoenholz",
                        "slug": "S.-Schoenholz",
                        "structuredName": {
                            "firstName": "Samuel",
                            "lastName": "Schoenholz",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Schoenholz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "119508204"
                        ],
                        "name": "Patrick F. Riley",
                        "slug": "Patrick-F.-Riley",
                        "structuredName": {
                            "firstName": "Patrick",
                            "lastName": "Riley",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Patrick F. Riley"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1689108"
                        ],
                        "name": "Oriol Vinyals",
                        "slug": "Oriol-Vinyals",
                        "structuredName": {
                            "firstName": "Oriol",
                            "lastName": "Vinyals",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Oriol Vinyals"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35188630"
                        ],
                        "name": "George E. Dahl",
                        "slug": "George-E.-Dahl",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Dahl",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "George E. Dahl"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9665943,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e24cdf73b3e7e590c2fe5ecac9ae8aa983801367",
            "isKey": false,
            "numCitedBy": 3235,
            "numCiting": 43,
            "paperAbstract": {
                "fragments": [],
                "text": "Supervised learning on molecules has incredible potential to be useful in chemistry, drug discovery, and materials science. Luckily, several promising and closely related neural network models invariant to molecular symmetries have already been described in the literature. These models learn a message passing algorithm and aggregation procedure to compute a function of their entire input graph. At this point, the next step is to find a particularly effective variant of this general approach and apply it to chemical prediction benchmarks until we either solve them or reach the limits of the approach. In this paper, we reformulate existing models into a single common framework we call Message Passing Neural Networks (MPNNs) and explore additional novel variations within this framework. Using MPNNs we demonstrate state of the art results on an important molecular property prediction benchmark; these results are strong enough that we believe future work should focus on datasets with larger molecules or more accurate ground truth labels."
            },
            "slug": "Neural-Message-Passing-for-Quantum-Chemistry-Gilmer-Schoenholz",
            "title": {
                "fragments": [],
                "text": "Neural Message Passing for Quantum Chemistry"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "Using MPNNs, state of the art results on an important molecular property prediction benchmark are demonstrated and it is believed future work should focus on datasets with larger molecules or more accurate ground truth labels."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1726807"
                        ],
                        "name": "Diederik P. Kingma",
                        "slug": "Diederik-P.-Kingma",
                        "structuredName": {
                            "firstName": "Diederik",
                            "lastName": "Kingma",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Diederik P. Kingma"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2503659"
                        ],
                        "name": "Jimmy Ba",
                        "slug": "Jimmy-Ba",
                        "structuredName": {
                            "firstName": "Jimmy",
                            "lastName": "Ba",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jimmy Ba"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": ". Dropout with keep probability of 0.5 is used in the last two fully-connected layers. All layers include ReLU and batch normalization. Training We use the same training strategy as [34]. We use Adam [18] with learning rate 0.001 that is divided by 2 every 20 epochs. The decay rate for batch normalization is initially 0.5 and 0.99 \ufb01nally. The batch size is 32 and the momentum is 0.9. Results Table 1 s"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 6628106,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a6cb366736791bcccc5c8639de5a8f9636bf87e8",
            "isKey": true,
            "numCitedBy": 90052,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce Adam, an algorithm for first-order gradient-based optimization of stochastic objective functions, based on adaptive estimates of lower-order moments. The method is straightforward to implement, is computationally efficient, has little memory requirements, is invariant to diagonal rescaling of the gradients, and is well suited for problems that are large in terms of data and/or parameters. The method is also appropriate for non-stationary objectives and problems with very noisy and/or sparse gradients. The hyper-parameters have intuitive interpretations and typically require little tuning. Some connections to related algorithms, on which Adam was inspired, are discussed. We also analyze the theoretical convergence properties of the algorithm and provide a regret bound on the convergence rate that is comparable to the best known results under the online convex optimization framework. Empirical results demonstrate that Adam works well in practice and compares favorably to other stochastic optimization methods. Finally, we discuss AdaMax, a variant of Adam based on the infinity norm."
            },
            "slug": "Adam:-A-Method-for-Stochastic-Optimization-Kingma-Ba",
            "title": {
                "fragments": [],
                "text": "Adam: A Method for Stochastic Optimization"
            },
            "tldr": {
                "abstractSimilarityScore": 69,
                "text": "This work introduces Adam, an algorithm for first-order gradient-based optimization of stochastic objective functions, based on adaptive estimates of lower-order moments, and provides a regret bound on the convergence rate that is comparable to the best known results under the online convex optimization framework."
            },
            "venue": {
                "fragments": [],
                "text": "ICLR"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2985328"
                        ],
                        "name": "Yulan Guo",
                        "slug": "Yulan-Guo",
                        "structuredName": {
                            "firstName": "Yulan",
                            "lastName": "Guo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yulan Guo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1698675"
                        ],
                        "name": "Bennamoun",
                        "slug": "Bennamoun",
                        "structuredName": {
                            "firstName": "",
                            "lastName": "Bennamoun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bennamoun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2470423"
                        ],
                        "name": "Ferdous Sohel",
                        "slug": "Ferdous-Sohel",
                        "structuredName": {
                            "firstName": "Ferdous",
                            "lastName": "Sohel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ferdous Sohel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143785357"
                        ],
                        "name": "Min Lu",
                        "slug": "Min-Lu",
                        "structuredName": {
                            "firstName": "Min",
                            "lastName": "Lu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Min Lu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7763855"
                        ],
                        "name": "Jianwei Wan",
                        "slug": "Jianwei-Wan",
                        "structuredName": {
                            "firstName": "Jianwei",
                            "lastName": "Wan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jianwei Wan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "iptors such as global point signatures [37], the heat and wave kernel signatures [48, 2], and variants [8]. Most recently, several approaches wrap machine learning schemes around standard descriptors [15, 42]. Learned Features. In computer vision, approaches relying on \u2018hand-crafted\u2019 features have reached a plateau in performance on challenging image analysis problems like image recognition. A breakthroug"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "escriptors for point clouds suitable for different problems and data structures. A comprehensive overview of hand-designed point features is out of the scope of this paper, but we refer the reader to [51, 15, 4] for comprehensive discussion. Broadly speaking, one can distinguish between extrinsic and intrinsic descriptors. Extrinsic descriptors usually are derived from the coordinates of the shape in 3D spac"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 8063966,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f22da4c1730bd392b90d1bac680fec67361e2a9d",
            "isKey": false,
            "numCitedBy": 475,
            "numCiting": 147,
            "paperAbstract": {
                "fragments": [],
                "text": "3D object recognition in cluttered scenes is a rapidly growing research area. Based on the used types of features, 3D object recognition methods can broadly be divided into two categories-global or local feature based methods. Intensive research has been done on local surface feature based methods as they are more robust to occlusion and clutter which are frequently present in a real-world scene. This paper presents a comprehensive survey of existing local surface feature based 3D object recognition methods. These methods generally comprise three phases: 3D keypoint detection, local surface feature description, and surface matching. This paper covers an extensive literature survey of each phase of the process. It also enlists a number of popular and contemporary databases together with their relevant attributes."
            },
            "slug": "3D-Object-Recognition-in-Cluttered-Scenes-with-A-Guo-Bennamoun",
            "title": {
                "fragments": [],
                "text": "3D Object Recognition in Cluttered Scenes with Local Surface Features: A Survey"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "This paper presents a comprehensive survey of existing local surface feature based 3D object recognition methods and enlists a number of popular and contemporary databases together with their relevant attributes."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3037691"
                        ],
                        "name": "A. Johnson",
                        "slug": "A.-Johnson",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Johnson",
                            "middleNames": [
                                "Edie"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Johnson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145670946"
                        ],
                        "name": "M. Hebert",
                        "slug": "M.-Hebert",
                        "structuredName": {
                            "firstName": "Martial",
                            "lastName": "Hebert",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Hebert"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 159,
                                "start": 155
                            }
                        ],
                        "text": "Extrinsic descriptors usually are derived from the coordinates of the shape in 3D space and includes classical methods like shape context [3], spin images [17], integral features [27], distance-based descriptors [24], point feature histograms [39, 38], and normal histograms [50], to name a few."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1377132,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "df6c0c55864252090b4099237aa821a6c75b52c2",
            "isKey": false,
            "numCitedBy": 2634,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a 3D shape-based object recognition system for simultaneous recognition of multiple objects in scenes containing clutter and occlusion. Recognition is based on matching surfaces by matching points using the spin image representation. The spin image is a data level shape descriptor that is used to match surfaces represented as surface meshes. We present a compression scheme for spin images that results in efficient multiple object recognition which we verify with results showing the simultaneous recognition of multiple objects from a library of 20 models. Furthermore, we demonstrate the robust performance of recognition in the presence of clutter and occlusion through analysis of recognition trials on 100 scenes."
            },
            "slug": "Using-Spin-Images-for-Efficient-Object-Recognition-Johnson-Hebert",
            "title": {
                "fragments": [],
                "text": "Using Spin Images for Efficient Object Recognition in Cluttered 3D Scenes"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "A compression scheme for spin images that results in efficient multiple object recognition which is verified with results showing the simultaneous recognition of multiple objects from a library of 20 models."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2559604"
                        ],
                        "name": "R. Rustamov",
                        "slug": "R.-Rustamov",
                        "structuredName": {
                            "firstName": "Raif",
                            "lastName": "Rustamov",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Rustamov"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "nating from each connected vertex. expressed in terms of the metric are invariant to isometric deformation. Representatives of this class include spectral descriptors such as global point signatures [Rustamov 2007], the heat and wave kernel signatures [Aubry et al. 2011; Sun et al. 2009], and variants [Bronstein and Kokkinos 2010]. Most recently, several approaches wrap machine learning schemes around standard"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 16217354,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "405f4bfb4ea3ae23f13df22b845ba65cd1bc927d",
            "isKey": false,
            "numCitedBy": 642,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "A deformation invariant representation of surfaces, the GPS embedding, is introduced using the eigenvalues and eigenfunctions of the Laplace-Beltrami differential operator. Notably, since the definition of the GPS embedding completely avoids the use of geodesic distances, and is based on objects of global character, the obtained representation is robust to local topology changes. The GPS embedding captures enough information to handle various shape processing tasks as shape classification, segmentation, and correspondence. To demonstrate the practical relevance of the GPS embedding, we introduce a deformation invariant shape descriptor called G2-distributions, and demonstrate their discriminative power, invariance under natural deformations, and robustness."
            },
            "slug": "Laplace-Beltrami-eigenfunctions-for-deformation-Rustamov",
            "title": {
                "fragments": [],
                "text": "Laplace-Beltrami eigenfunctions for deformation invariant shape representation"
            },
            "tldr": {
                "abstractSimilarityScore": 83,
                "text": "A deformation invariant representation of surfaces, the GPS embedding, is introduced using the eigenvalues and eigenfunctions of the Laplace-Beltrami differential operator, and the obtained representation is robust to local topology changes."
            },
            "venue": {
                "fragments": [],
                "text": "Symposium on Geometry Processing"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1726807"
                        ],
                        "name": "Diederik P. Kingma",
                        "slug": "Diederik-P.-Kingma",
                        "structuredName": {
                            "firstName": "Diederik",
                            "lastName": "Kingma",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Diederik P. Kingma"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1678311"
                        ],
                        "name": "M. Welling",
                        "slug": "M.-Welling",
                        "structuredName": {
                            "firstName": "Max",
                            "lastName": "Welling",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Welling"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "lattice [Su et al. 2018], or spline [Fey et al. 2018]. Finally, we should mention geometric generative models, which attempt to generalize models such as autoencoders, variational autoencoders (VAE) [Kingma and Welling 2013], and generative adversarial networks (GAN) [Goodfellow et al. 2014] to the non-Euclidean setting. One of the fundamental differences between these two settings is the lack of canonical order between"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 216078090,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5f5dc5b9a2ba710937e2c413b37b053cd673df02",
            "isKey": false,
            "numCitedBy": 16774,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract: How can we perform efficient inference and learning in directed probabilistic models, in the presence of continuous latent variables with intractable posterior distributions, and large datasets? We introduce a stochastic variational inference and learning algorithm that scales to large datasets and, under some mild differentiability conditions, even works in the intractable case. Our contributions is two-fold. First, we show that a reparameterization of the variational lower bound yields a lower bound estimator that can be straightforwardly optimized using standard stochastic gradient methods. Second, we show that for i.i.d. datasets with continuous latent variables per datapoint, posterior inference can be made especially efficient by fitting an approximate inference model (also called a recognition model) to the intractable posterior using the proposed lower bound estimator. Theoretical advantages are reflected in experimental results."
            },
            "slug": "Auto-Encoding-Variational-Bayes-Kingma-Welling",
            "title": {
                "fragments": [],
                "text": "Auto-Encoding Variational Bayes"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "A stochastic variational inference and learning algorithm that scales to large datasets and, under some mild differentiability conditions, even works in the intractable case is introduced."
            },
            "venue": {
                "fragments": [],
                "text": "ICLR"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "12752013"
                        ],
                        "name": "O. Arslan",
                        "slug": "O.-Arslan",
                        "structuredName": {
                            "firstName": "Ozan",
                            "lastName": "Arslan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Arslan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 769948,
            "fieldsOfStudy": [
                "Environmental Science"
            ],
            "id": "04383d489f95f628ba7fc9b340127cf8a375c0fa",
            "isKey": false,
            "numCitedBy": 31,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "Normal 0 21 false false false TR X-NONE X-NONE This paper describes the photogrammetric techniques and approaches developed for 3D object reconstruction based on a single image. It is possible to get metric information from a single view when the stereo-based photogrammetric technique is not available. In this scope some advanced multidisciplinary techniques which allow an automatic capture of meaningful elements for perspective models from a single image are discussed"
            },
            "slug": "3d-Object-Reconstruction-from-a-Single-Image.-Arslan",
            "title": {
                "fragments": [],
                "text": "3d Object Reconstruction from a Single Image."
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "In this scope some advanced multidisciplinary techniques which allow an automatic capture of meaningful elements for perspective models from a single image are discussed."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48582897"
                        ],
                        "name": "Mathieu Aubry",
                        "slug": "Mathieu-Aubry",
                        "structuredName": {
                            "firstName": "Mathieu",
                            "lastName": "Aubry",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mathieu Aubry"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3123320"
                        ],
                        "name": "Ulrich Schlickewei",
                        "slug": "Ulrich-Schlickewei",
                        "structuredName": {
                            "firstName": "Ulrich",
                            "lastName": "Schlickewei",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ulrich Schlickewei"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695302"
                        ],
                        "name": "D. Cremers",
                        "slug": "D.-Cremers",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Cremers",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Cremers"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 140,
                                "start": 133
                            }
                        ],
                        "text": "Representatives of this class include spectral descriptors such as global point signatures [37], the heat and wave kernel signatures [48, 2], and variants [8]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 17847588,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "955635d7179484f106f584c3d5766dee0cfa45db",
            "isKey": false,
            "numCitedBy": 641,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce the Wave Kernel Signature (WKS) for characterizing points on non-rigid three-dimensional shapes. The WKS represents the average probability of measuring a quantum mechanical particle at a specific location. By letting vary the energy of the particle, the WKS encodes and separates information from various different Laplace eigenfrequencies. This clear scale separation makes the WKS well suited for a large variety of applications. Both theoretically and in quantitative experiments we demonstrate that the WKS is substantially more discriminative and therefore allows for better feature matching than the commonly used Heat Kernel Signature (HKS). As an application of the WKS in shape analysis we show results on shape matching."
            },
            "slug": "The-wave-kernel-signature:-A-quantum-mechanical-to-Aubry-Schlickewei",
            "title": {
                "fragments": [],
                "text": "The wave kernel signature: A quantum mechanical approach to shape analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "Both theoretically and in quantitative experiments it is demonstrated that the WKS is substantially more discriminative and therefore allows for better feature matching than the commonly used Heat Kernel Signature."
            },
            "venue": {
                "fragments": [],
                "text": "2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops)"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1678656"
                        ],
                        "name": "I. Loshchilov",
                        "slug": "I.-Loshchilov",
                        "structuredName": {
                            "firstName": "Ilya",
                            "lastName": "Loshchilov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Loshchilov"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144661829"
                        ],
                        "name": "F. Hutter",
                        "slug": "F.-Hutter",
                        "structuredName": {
                            "firstName": "Frank",
                            "lastName": "Hutter",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Hutter"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14337532,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b022f2a277a4bf5f42382e86e4380b96340b9e86",
            "isKey": false,
            "numCitedBy": 2723,
            "numCiting": 45,
            "paperAbstract": {
                "fragments": [],
                "text": "Restart techniques are common in gradient-free optimization to deal with multimodal functions. Partial warm restarts are also gaining popularity in gradient-based optimization to improve the rate of convergence in accelerated gradient schemes to deal with ill-conditioned functions. In this paper, we propose a simple warm restart technique for stochastic gradient descent to improve its anytime performance when training deep neural networks. We empirically study its performance on the CIFAR-10 and CIFAR-100 datasets, where we demonstrate new state-of-the-art results at 3.14% and 16.21%, respectively. We also demonstrate its advantages on a dataset of EEG recordings and on a downsampled version of the ImageNet dataset. Our source code is available at this https URL"
            },
            "slug": "SGDR:-Stochastic-Gradient-Descent-with-Warm-Loshchilov-Hutter",
            "title": {
                "fragments": [],
                "text": "SGDR: Stochastic Gradient Descent with Warm Restarts"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This paper proposes a simple warm restart technique for stochastic gradient descent to improve its anytime performance when training deep neural networks and empirically studies its performance on the CIFAR-10 and CIFARS datasets."
            },
            "venue": {
                "fragments": [],
                "text": "ICLR"
            },
            "year": 2017
        },
        {
            "authors": [],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 180,
                                "start": 144
                            }
                        ],
                        "text": "Representatives of this class include spectral descriptors such as global point signatures (Rustamov 2007), the heat and wave kernel signatures (Aubry et al. 2011; Sun et al. 2009), and variants (Bronstein and Kokkinos 2010)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 8579005,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "ccdd9c2f5ece5a7d1c33d683ca2bbc968a70d58d",
            "isKey": false,
            "numCitedBy": 3,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Let us return to the subject of \" good distributions \" as exemplified by Dirac delta 'functions' and the Schwartz kernels of pseudodifferential operators. In fact we shall associate a space of \" conormal distributions \" with any submanifold of a manifold. Thus let X be a C \u221e manifold and Y \u2282 X a closed embedded submanifold \u2013 we can easily drop the assumption that Y is closed and even replace embedded by immersed, but let's treat the simplest case first! To say that Y is embedded means that each \u00af y \u2208 Y has a coordinate neighbourhood U, in X, with coordinate x 1 ,. .. , x n in terms of which \u00af y = 0 and (9.1) Y \u2229 U = {x, = \u00b7 \u00b7 \u00b7 = x k = 0}."
            },
            "slug": "The-Wave-Kernel",
            "title": {
                "fragments": [],
                "text": "The Wave Kernel"
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688882"
                        ],
                        "name": "Yann LeCun",
                        "slug": "Yann-LeCun",
                        "structuredName": {
                            "firstName": "Yann",
                            "lastName": "LeCun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yann LeCun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2219581"
                        ],
                        "name": "B. Boser",
                        "slug": "B.-Boser",
                        "structuredName": {
                            "firstName": "Bernhard",
                            "lastName": "Boser",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Boser"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1747317"
                        ],
                        "name": "J. Denker",
                        "slug": "J.-Denker",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Denker",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Denker"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "37274089"
                        ],
                        "name": "D. Henderson",
                        "slug": "D.-Henderson",
                        "structuredName": {
                            "firstName": "Donnie",
                            "lastName": "Henderson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Henderson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2799635"
                        ],
                        "name": "R. Howard",
                        "slug": "R.-Howard",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Howard",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Howard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34859193"
                        ],
                        "name": "W. Hubbard",
                        "slug": "W.-Hubbard",
                        "structuredName": {
                            "firstName": "Wayne",
                            "lastName": "Hubbard",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Hubbard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2041866"
                        ],
                        "name": "L. Jackel",
                        "slug": "L.-Jackel",
                        "structuredName": {
                            "firstName": "Lawrence",
                            "lastName": "Jackel",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Jackel"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 81,
                                "start": 73
                            }
                        ],
                        "text": "A breakthrough came with the use of convolutional neural networks (CNNs) [22, 21], leading to an overwhelming trend to abandon hand-crafted features in favor of models that learn task-specific features from data."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 41312633,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a8e8f3c8d4418c8d62e306538c9c1292635e9d27",
            "isKey": false,
            "numCitedBy": 7829,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "The ability of learning networks to generalize can be greatly enhanced by providing constraints from the task domain. This paper demonstrates how such constraints can be integrated into a backpropagation network through the architecture of the network. This approach has been successfully applied to the recognition of handwritten zip code digits provided by the U.S. Postal Service. A single network learns the entire recognition operation, going from the normalized image of the character to the final classification."
            },
            "slug": "Backpropagation-Applied-to-Handwritten-Zip-Code-LeCun-Boser",
            "title": {
                "fragments": [],
                "text": "Backpropagation Applied to Handwritten Zip Code Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 56,
                "text": "This paper demonstrates how constraints from the task domain can be integrated into a backpropagation network through the architecture of the network, successfully applied to the recognition of handwritten zip code digits provided by the U.S. Postal Service."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2059358552"
                        ],
                        "name": "P. Cochat",
                        "slug": "P.-Cochat",
                        "structuredName": {
                            "firstName": "P.",
                            "lastName": "Cochat",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Cochat"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "13267685"
                        ],
                        "name": "L. Vaucoret",
                        "slug": "L.-Vaucoret",
                        "structuredName": {
                            "firstName": "L",
                            "lastName": "Vaucoret",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Vaucoret"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2097644863"
                        ],
                        "name": "J. Sarles",
                        "slug": "J.-Sarles",
                        "structuredName": {
                            "firstName": "J",
                            "lastName": "Sarles",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Sarles"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 209,
                                "start": 205
                            }
                        ],
                        "text": "Furthermore, the learned mapping is sensitive to the global transformation of the point cloud; to cope with this issue, PointNet employs a complex and computationally expensive spatial transformer network [16] to learn 3D alignment."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 11759366,
            "fieldsOfStudy": [
                "Medicine"
            ],
            "id": "bc6dff14a130c57a91d5a21339c23471faf1d46f",
            "isKey": false,
            "numCitedBy": 57729,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "disasters. Plenum, 2001. 11. Haley R, Thomas L, Hom J. Is there a Gulf War Syndrome? Searching for syndromes by factor analysis of symptoms. JAMA 1997;277:215\u201322. 12. Fukuda K, Nisenbaum R, Stewart G, et al. Chronic multi-symptom illness affecting Air Force veterans of the Gulf War. JAMA 1998;280:981\u20138. 13. Ismail K, Everitt B, Blatchley N, et al. Is there a Gulf War Syndrome? Lancet 1999;353:179\u201382. 14. Shapiro S, Lasarev M, McCauley L. Factor analysis of Gulf War illness: what does it add to our understanding of possible health effects of deployment. Am J Epidemiol 2002;156:578\u201385. 15. Doebbeling B, Clarke W, Watson D, et al. Is there a Persian Gulf War Syndrome? Evidence from a large population-based survey of veterans and nondeployed controls. Am J Med 2000;108:695\u2013704. 16. Knoke J, Smith T, Gray G, et al. Factor analysis of self reported symptoms: Does it identify a Gulf War Syndrome? Am J Epidemiol 2000;152:379\u201388. 17. Kang H, Mahan C, Lee K, et al. Evidence for a deployment-related Gulf War syndrome by factor analysis. Arch Environ Health 2002;57:61\u20138."
            },
            "slug": "Et-al-Cochat-Vaucoret",
            "title": {
                "fragments": [],
                "text": "Et al"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "A large population-based survey of veterans and nondeployed controls found evidence of a deployment-related Gulf War syndrome by factor analysis in Air Force veterans and controls."
            },
            "venue": {
                "fragments": [],
                "text": "Archives de pediatrie : organe officiel de la Societe francaise de pediatrie"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7941636"
                        ],
                        "name": "A. Fine",
                        "slug": "A.-Fine",
                        "structuredName": {
                            "firstName": "Allan",
                            "lastName": "Fine",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Fine"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 130,
                                "start": 119
                            }
                        ],
                        "text": "A comprehensive overview of hand-designed point features is out of the scope of this paper, but we refer the reader to [51, 15, 4] for comprehensive discussion."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6742416,
            "fieldsOfStudy": [
                "Medicine"
            ],
            "id": "7faaed082d2084b0e82916690d7eaf4e1bbd6acf",
            "isKey": false,
            "numCitedBy": 255,
            "numCiting": 3,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Recent-trends.-Fine",
            "title": {
                "fragments": [],
                "text": "Recent trends."
            },
            "venue": {
                "fragments": [],
                "text": "Managed care quarterly"
            },
            "year": 2003
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 160,
                                "start": 138
                            }
                        ],
                        "text": "Extrinsic descriptors usually are derived from the coordinates of the shape in 3D space and includes classical methods like shape context (Belongie et al. 2001), spin images (Johnson and Hebert 1999), integral features (Manay et al."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Shape context: A newdescriptor"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2001
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 160,
                                "start": 138
                            }
                        ],
                        "text": "Extrinsic descriptors usually are derived from the coordinates of the shape in 3D space and includes classical methods like shape context (Belongie et al. 2001), spin images (Johnson and Hebert 1999), integral features (Manay et al."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Shape context: A newdescriptor for shape matching and object recognition"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the NIPS."
            },
            "year": 2001
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 123,
                                "start": 71
                            }
                        ],
                        "text": "For point clouds, multiple generative architectures have been proposed (Fan et al. 2017; Li et al. 2018b; Yang et al. 2018)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A point set generation network"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2017
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Abhinav Gupta, and Kaiming He. 2018a. Non-local neural networks"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the CVPR"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Scale-invariant heat kernel signa"
            },
            "venue": {
                "fragments": [],
                "text": "Signal Process. Mag. 34,"
            },
            "year": 2017
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Non-rigid Shape Recognition"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2013
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "agenet classification with deep convolutional neural networks"
            },
            "venue": {
                "fragments": [],
                "text": "Proc . NIPS"
            },
            "year": 2012
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 164,
                                "start": 123
                            }
                        ],
                        "text": "Traditional methods for solving these problems employ handcrafted features to capture geometric properties of point clouds (Lu et al. 2014; Rusu et al. 2009, 2008a)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Recognizing objects"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2014
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Backpropagation applied to hand"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1989
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 71,
                                "start": 63
                            }
                        ],
                        "text": "These issues are alleviated in follow-up work using polynomial [11, 19] or rational [23] spectral filters that avoid the Laplacian eigendecomposition and also guarantee localization."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Semi-supervised classification with graph convolutional networks. 2017"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2017
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "3D Object Recognition in Cluttered Scenes with Local Surface Features: a"
            },
            "venue": {
                "fragments": [],
                "text": "Survey. Trans. PAMI"
            },
            "year": 2014
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 160,
                                "start": 138
                            }
                        ],
                        "text": "Extrinsic descriptors usually are derived from the coordinates of the shape in 3D space and includes classical methods like shape context [Belongie et al. 2001], spin images [Johnson and Hebert 1999], integral features [Manay et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Shape Context: A New Descriptor"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2001
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Laurens van der Maaten, Alan Yuille, and Kaiming He"
            },
            "venue": {
                "fragments": [],
                "text": "Feature denoising for improving adversarial robustness"
            },
            "year": 2018
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "agenet classification with deep convolutional neural networks"
            },
            "venue": {
                "fragments": [],
                "text": "In Proc . NIPS"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Abhinav Gupta, and Kaiming He"
            },
            "venue": {
                "fragments": [],
                "text": "Non-local Neural Networks. CVPR"
            },
            "year": 2018
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "3D point cloud models"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2017
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 34,
            "methodology": 27,
            "result": 3
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 104,
        "totalPages": 11
    },
    "page_url": "https://www.semanticscholar.org/paper/Dynamic-Graph-CNN-for-Learning-on-Point-Clouds-Wang-Sun/e1799aaf23c12af6932dc0ef3dfb1638f01413d1?sort=total-citations"
}