{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2115625054"
                        ],
                        "name": "Yalin Wang",
                        "slug": "Yalin-Wang",
                        "structuredName": {
                            "firstName": "Yalin",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yalin Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1710238"
                        ],
                        "name": "R. Haralick",
                        "slug": "R.-Haralick",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Haralick",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Haralick"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1744200"
                        ],
                        "name": "I. T. Phillips",
                        "slug": "I.-T.-Phillips",
                        "structuredName": {
                            "firstName": "Ihsin",
                            "lastName": "Phillips",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. T. Phillips"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Conclusions and future work are given in Section 8."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 628973,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cd7e243fb7041c582a479116a11126904f2be010",
            "isKey": false,
            "numCitedBy": 61,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "We first describe an automatic table ground truth generation system which can efficiently generate a large amount of accurate table ground truth suitable for the development of table detection algorithms. Then a novel background analysis-based, coarse-to-fine table identification algorithm and an X-Y cut table decomposition algorithm are described. We discuss an experimental protocol to evaluate the table detection algorithms. For a total of 1,125 document pages having 518 table entities and a total of 10,941 cell entities, our table detection algorithm takes line, word segmentation results as input and obtains around 90% cell correct detection rates."
            },
            "slug": "Automatic-table-ground-truth-generation-and-a-table-Wang-Haralick",
            "title": {
                "fragments": [],
                "text": "Automatic table ground truth generation and a background-analysis-based table structure extraction method"
            },
            "tldr": {
                "abstractSimilarityScore": 83,
                "text": "An automatic table groundtruth generation system which can efficiently generate a large amount of accurate table ground truth suitable for the development of table detection algorithms and an X-Y cut table decomposition algorithm are described."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of Sixth International Conference on Document Analysis and Recognition"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47756656"
                        ],
                        "name": "Jianying Hu",
                        "slug": "Jianying-Hu",
                        "structuredName": {
                            "firstName": "Jianying",
                            "lastName": "Hu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jianying Hu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32225756"
                        ],
                        "name": "R. Kashi",
                        "slug": "R.-Kashi",
                        "structuredName": {
                            "firstName": "Ramanujan",
                            "lastName": "Kashi",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Kashi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1828940"
                        ],
                        "name": "D. Lopresti",
                        "slug": "D.-Lopresti",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Lopresti",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Lopresti"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2859740"
                        ],
                        "name": "G. Wilfong",
                        "slug": "G.-Wilfong",
                        "structuredName": {
                            "firstName": "Gordon",
                            "lastName": "Wilfong",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Wilfong"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Conclusions and future work are given in Section 8."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 41490827,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1e9383c894019f34e8cd77b68b89af5c1d42c7e9",
            "isKey": false,
            "numCitedBy": 71,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "Tables are an important means for communicating information in written media, and understanding such tables is a challenging problem in document layout analysis. In this paper we describe a general solution to the problem of recognizing the structure of a detected table region. First hierarchial clustering is used to identify columns and then spatial and lexical criteria to classify headers. We also address the problem of evaluating table structure recognition. Our model is based on a directed acyclic attribute graph, or table DAG. We describe a new paradigm, 'random graph probing,' for comparing the results returned by the recognition system and the representation created during ground-truthing. Probing is in fact a general concept that could be applied to other document recognition tasks and perhaps even other computer vision problems as well."
            },
            "slug": "Table-structure-recognition-and-its-evaluation-Hu-Kashi",
            "title": {
                "fragments": [],
                "text": "Table structure recognition and its evaluation"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A new paradigm, 'random graph probing,' is described for comparing the results returned by the recognition system and the representation created during ground-truthing, which could be applied to other document recognition tasks and perhaps even other computer vision problems as well."
            },
            "venue": {
                "fragments": [],
                "text": "IS&T/SPIE Electronic Imaging"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47756656"
                        ],
                        "name": "Jianying Hu",
                        "slug": "Jianying-Hu",
                        "structuredName": {
                            "firstName": "Jianying",
                            "lastName": "Hu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jianying Hu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32225756"
                        ],
                        "name": "R. Kashi",
                        "slug": "R.-Kashi",
                        "structuredName": {
                            "firstName": "Ramanujan",
                            "lastName": "Kashi",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Kashi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1828940"
                        ],
                        "name": "D. Lopresti",
                        "slug": "D.-Lopresti",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Lopresti",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Lopresti"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2859740"
                        ],
                        "name": "G. Wilfong",
                        "slug": "G.-Wilfong",
                        "structuredName": {
                            "firstName": "Gordon",
                            "lastName": "Wilfong",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Wilfong"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 37293831,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "edbd577d793a083de4f337acac992ec7837609e0",
            "isKey": false,
            "numCitedBy": 90,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "An important step towards the goal of table understanding is a method for reliable table detection. This paper describes a general solution for detecting tables based on computing an optimal partitioning of a document into some number of tables. A dynamic programming algorithm is given to solve the resulting optimization problem. This high-level framework is independent of any particular table quality measure and independent of the document medium. Moreover, it does not rely on the presence of ruling lines or other table delimiters. We also present table quality measures based on white space correlation and vertical connected component analysis. These measures can be applied equally well to ASCII text and scanned images. We report on some preliminary experiments using this method to detect tables in both ASCII text and scanned images, yielding promising results. We present detailed evaluation of these results using three different criteria which by themselves pose interesting research questions."
            },
            "slug": "Medium-independent-table-detection-Hu-Kashi",
            "title": {
                "fragments": [],
                "text": "Medium-independent table detection"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "A general solution for detecting tables based on computing an optimal partitioning of a document into some number of tables is described and a dynamic programming algorithm is given to solve the resulting optimization problem."
            },
            "venue": {
                "fragments": [],
                "text": "Electronic Imaging"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1780258"
                        ],
                        "name": "Jisheng Liang",
                        "slug": "Jisheng-Liang",
                        "structuredName": {
                            "firstName": "Jisheng",
                            "lastName": "Liang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jisheng Liang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1710238"
                        ],
                        "name": "R. Haralick",
                        "slug": "R.-Haralick",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Haralick",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Haralick"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 61043620,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "884a67cb5ad2ee95c7f5a42cc86b47f204e563b1",
            "isKey": false,
            "numCitedBy": 25,
            "numCiting": 61,
            "paperAbstract": {
                "fragments": [],
                "text": "The goal of document image structure analysis is to find an optimal solution partitioning the set of glyphs on a given document image into a hierarchical tree structure where entities within the hierarchy are associated with their physical properties and semantic labels. In this dissertation, we present a unified document image structure extraction algorithm that is probability based, where the probabilities are estimated from an extensive training set of various kinds of measurements of distances between the terminal and non-terminal entities with which the algorithm works. The off-line probabilities estimated in the training then drive all decisions in the on-line segmentation module. An iterative, relaxation-like method is used to find the partitioning solution that maximizes the joint probability. This approach can be uniformly apply to the construction of the document hierarchy at any level. We have implemented a text line segmentation algorithm and a text block extraction algorithm using this framework. Another example is the development of a system that detects and recognizes special symbols (Greek letters, mathematical symbols, etc.) on technical document pages, that are not handled by the current Optical Character Recognition (OCR) systems. \nA large quantity of ground-truth data, varying in quality, is required in order to give an accurate measurement of the performance of an algorithm under different conditions. \nWe have constructed the University of Washington English Document Image Database-III, which contains 1600 scanned scientific/technical document image pages that come with manually edited ground-truth of entity bounding boxes and properties. Based on the ground-truth data, we can evaluate the performance of document analysis algorithms and build statistical models to characterize various types of document image structures. In this dissertation, we present a set of quantitative performance metrics for each kind of information a document image analysis technique infers. The text line and text block extraction algorithms were trained and evaluated on the UW-III database using a cross-validation method. The text line extraction algorithm identifies and segments 99.76% of text lines correctly, while the preliminary result of the text block extraction shows 91% accuracy."
            },
            "slug": "Document-structure-analysis-and-performance-Liang-Haralick",
            "title": {
                "fragments": [],
                "text": "Document structure analysis and performance evaluation"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This dissertation presents a unified document image structure extraction algorithm that is probability based, where the probabilities are estimated from an extensive training set of various kinds of measurements of distances between the terminal and non-terminal entities with which the algorithm works."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32392240"
                        ],
                        "name": "H. Wasserman",
                        "slug": "H.-Wasserman",
                        "structuredName": {
                            "firstName": "Howard",
                            "lastName": "Wasserman",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Wasserman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3303960"
                        ],
                        "name": "Keitaro Yukawa",
                        "slug": "Keitaro-Yukawa",
                        "structuredName": {
                            "firstName": "Keitaro",
                            "lastName": "Yukawa",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Keitaro Yukawa"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1881895"
                        ],
                        "name": "B. Sy",
                        "slug": "B.-Sy",
                        "structuredName": {
                            "firstName": "Bon",
                            "lastName": "Sy",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Sy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145219946"
                        ],
                        "name": "K. Kwok",
                        "slug": "K.-Kwok",
                        "structuredName": {
                            "firstName": "Kui-Lam",
                            "lastName": "Kwok",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Kwok"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1744200"
                        ],
                        "name": "I. T. Phillips",
                        "slug": "I.-T.-Phillips",
                        "structuredName": {
                            "firstName": "Ihsin",
                            "lastName": "Phillips",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. T. Phillips"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5740466,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4e9ce92b0f7701da4178bb70af1bf217d49e9198",
            "isKey": false,
            "numCitedBy": 5,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "The algorithm described in this paper is designed to detect potential table regions in the document, to decide whether a potential table region is, in fact, a table, and, when it is, to analyze the table structure. The decision and analysis phases of the algorithm and the resulting system are based primarily on a precise definition of table, and it is such a definition that is discussed in this paper. An adequate definition need not be complete in the sense of encompassing all possible structures that might be deemed to be tables, but it should encompass most such structures, it should include essential features of tables, and it should exclude features never or very rarely possessed by tables."
            },
            "slug": "A-Theoretical-Foundation-and-a-Method-for-Document-Wasserman-Yukawa",
            "title": {
                "fragments": [],
                "text": "A Theoretical Foundation and a Method for Document Table Structure Extraction and Decompositon"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "The algorithm described in this paper is designed to detect potential table regions in the document, to decide whether a potential table region is, in fact, a table, and, when it is, to analyze the table structure."
            },
            "venue": {
                "fragments": [],
                "text": "Document Analysis Systems"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47756656"
                        ],
                        "name": "Jianying Hu",
                        "slug": "Jianying-Hu",
                        "structuredName": {
                            "firstName": "Jianying",
                            "lastName": "Hu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jianying Hu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32225756"
                        ],
                        "name": "R. Kashi",
                        "slug": "R.-Kashi",
                        "structuredName": {
                            "firstName": "Ramanujan",
                            "lastName": "Kashi",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Kashi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1828940"
                        ],
                        "name": "D. Lopresti",
                        "slug": "D.-Lopresti",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Lopresti",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Lopresti"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2859740"
                        ],
                        "name": "G. Wilfong",
                        "slug": "G.-Wilfong",
                        "structuredName": {
                            "firstName": "Gordon",
                            "lastName": "Wilfong",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Wilfong"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Conclusions and future work are given in Section 8."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7630958,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "af42cc46f93bc9cf413770af4f7243f54a31336e",
            "isKey": false,
            "numCitedBy": 89,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract. While techniques for evaluating the performance of lower-level document analysis tasks such as optical character recognition have gained acceptance in the literature, attempts to formalize the problem for higher-level algorithms, while receiving a fair amount of attention in terms of theory, have generally been less successful in practice, perhaps owing to their complexity. In this paper, we introduce intuitive, easy-to-implement evaluation schemes for the related problems of table detection and table structure recognition. We also present the results of several small experiments, demonstrating how well the methodologies work and the useful sorts of feedback they provide. We first consider the table detection problem. Here algorithms can yield various classes of errors, including non-table regions improperly labeled as tables (insertion errors), tables missed completely (deletion errors), larger tables broken into a number of smaller ones (splitting errors), and groups of smaller tables combined to form larger ones (merging errors). This leads naturally to the use of an edit distance approach for assessing the results of table detection. Next we address the problem of evaluating table structure recognition. Our model is based on a directed acyclic attribute graph, or table DAG. We describe a new paradigm, \u201cgraph probing,\u201d for comparing the results returned by the recognition system and the representation created during ground-truthing. Probing is in fact a general concept that could be applied to other document recognition tasks as well."
            },
            "slug": "Evaluating-the-performance-of-table-processing-Hu-Kashi",
            "title": {
                "fragments": [],
                "text": "Evaluating the performance of table processing algorithms"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "An intuitive, easy-to-implement evaluation schemes for the related problems of table detection and table structure recognition are introduced and a new paradigm, \u201cgraph probing,\u201d is described for comparing the results returned by the recognition system and the representation created during ground-truthing."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal on Document Analysis and Recognition"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47756656"
                        ],
                        "name": "Jianying Hu",
                        "slug": "Jianying-Hu",
                        "structuredName": {
                            "firstName": "Jianying",
                            "lastName": "Hu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jianying Hu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32225756"
                        ],
                        "name": "R. Kashi",
                        "slug": "R.-Kashi",
                        "structuredName": {
                            "firstName": "Ramanujan",
                            "lastName": "Kashi",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Kashi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1828940"
                        ],
                        "name": "D. Lopresti",
                        "slug": "D.-Lopresti",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Lopresti",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Lopresti"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2859740"
                        ],
                        "name": "G. Wilfong",
                        "slug": "G.-Wilfong",
                        "structuredName": {
                            "firstName": "Gordon",
                            "lastName": "Wilfong",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Wilfong"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145916951"
                        ],
                        "name": "G. Nagy",
                        "slug": "G.-Nagy",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Nagy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Nagy"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Conclusions and future work are given in Section 8."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 16106027,
            "fieldsOfStudy": [
                "Computer Science",
                "Philosophy"
            ],
            "id": "9e16dcd290d9ab780107270c666d71c00e569b22",
            "isKey": false,
            "numCitedBy": 95,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "The principle that for every document analysis task there exists a mechanism for creating well-defined ground-truth is a widely held tenet. Past experience with standard datasets providing ground-truth for character recognition and page segmentation tasks supports this belief. In the process of attempting to evaluate several table recognition algorithms we have been developing, however, we have uncovered a number of serious hurdles connected with the ground-truthing of tables. This problem may, in fact, be much more difficult than it appears. We present a detailed analysis of why table ground-truthing is so hard, including the notions that there may exist more than one acceptable \"truth\" and/or incomplete or partial \"truths\"."
            },
            "slug": "Why-table-ground-truthing-is-hard-Hu-Kashi",
            "title": {
                "fragments": [],
                "text": "Why table ground-truthing is hard"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This work presents a detailed analysis of why table ground-truthing is so hard, including the notions that there may exist more than one acceptable \"truth\" and/or incomplete or partial \"truths\"."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of Sixth International Conference on Document Analysis and Recognition"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2094489850"
                        ],
                        "name": "Konstantin Zuyev",
                        "slug": "Konstantin-Zuyev",
                        "structuredName": {
                            "firstName": "Konstantin",
                            "lastName": "Zuyev",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Konstantin Zuyev"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Conclusions and future work are given in Section 8."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 206775477,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6863be337e896e638b5a52c89caac04e76aa62e4",
            "isKey": false,
            "numCitedBy": 47,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "Algorithm for table image segmentation, a part of complete document recognition system is presented. The proposed approach introduces a concept of table grid which can serve for advanced methods of table structure analysis. It provides a layer of terminal symbols for the table, which is used by syntactical methods. Detailed discussion of grid detection is presented which is performed through the analysis of connected components projection profile. Simple rules for analysis of table structure cover majority of real life tables. The system is implemented, rested, and is now extensively used in FineReader OCR product."
            },
            "slug": "Table-image-segmentation-Zuyev",
            "title": {
                "fragments": [],
                "text": "Table image segmentation"
            },
            "tldr": {
                "abstractSimilarityScore": 53,
                "text": "The proposed approach introduces a concept of table grid which can serve for advanced methods of table structure analysis, which provides a layer of terminal symbols for the table, which is used by syntactical methods."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Fourth International Conference on Document Analysis and Recognition"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1500661115"
                        ],
                        "name": "Toyohide Watanabe",
                        "slug": "Toyohide-Watanabe",
                        "structuredName": {
                            "firstName": "Toyohide",
                            "lastName": "Watanabe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Toyohide Watanabe"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2074293587"
                        ],
                        "name": "Q. Luo",
                        "slug": "Q.-Luo",
                        "structuredName": {
                            "firstName": "Qin",
                            "lastName": "Luo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Q. Luo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1692608"
                        ],
                        "name": "N. Sugie",
                        "slug": "N.-Sugie",
                        "structuredName": {
                            "firstName": "Noboru",
                            "lastName": "Sugie",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Sugie"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 117,
                                "start": 114
                            }
                        ],
                        "text": "Tables are compact and e>cient for presenting relational information and most of the documents produced today contain various types of tables."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 23198522,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fa208b677239912cb394e5dbc6e7483a75f16ea4",
            "isKey": false,
            "numCitedBy": 140,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "Many approaches have reported that knowledge-based layout recognition methods are very successful in classifying the meaningful data from document images automatically. However, these approaches are applicable to only the same kind of documents because they are based on the paradigm that specifies the structure definition information in advance so as to be able to analyze a particular class of documents intelligently. In this paper, the authors propose a method to recognize the layout structures of multi-kinds of table-form document images. For this purpose, the authors introduce a classification tree to manage the relationships among different classes of layout structures. The authors' recognition system has two modes: layout knowledge acquisition and layout structure recognition. In the layout knowledge acquisition mode, table-form document images are distinguished according to this. Classification tree and then the structure description trees which specify the logical structures of table-form documents are generated automatically. While, in the layout structure recognition mode, individual item fields in the table-form document images are extracted and classified successfully by searching the classification tree and interpreting the structure description tree. >"
            },
            "slug": "Layout-Recognition-of-Multi-Kinds-of-Table-Form-Watanabe-Luo",
            "title": {
                "fragments": [],
                "text": "Layout Recognition of Multi-Kinds of Table-Form Documents"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "The authors introduce a classification tree to manage the relationships among different classes of layout structures and propose a method to recognize the layout structures of multi-kinds of table-form document images."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3320897"
                        ],
                        "name": "T. Kieninger",
                        "slug": "T.-Kieninger",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Kieninger",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kieninger"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145279674"
                        ],
                        "name": "A. Dengel",
                        "slug": "A.-Dengel",
                        "structuredName": {
                            "firstName": "Andreas",
                            "lastName": "Dengel",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Dengel"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Conclusions and future work are given in Section 8."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 206776168,
            "fieldsOfStudy": [
                "Business"
            ],
            "id": "d25a61cc0cd816eba75864912fe2f6f44be3cecf",
            "isKey": false,
            "numCitedBy": 75,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper summarizes the core idea of the T-Recs table recognition system, an integrated system covering block-segmentation, table location and a model-free structural analysis of tables. T-Recs works on the output of commercial OCR systems that provide the word bounding box geometry together with the text itself (e.g. Xerox ScanWorX). While T-Recs performs well on a number of document categories, business letters still remained a challenging domain because the T-Recs location heuristics are mislead by their header or footer resulting in a low recognition precision. Business letters such as invoices are a very interesting domain for industrial applications due to the large amount of documents to be analyzed and the importance of the data carried within their tables. Hence, we developed a more restrictive approach which is implemented in the T-Recs++ prototype. This paper describes the ideas of the T-Recs++ location and also proposes a quality evaluation measure that reflects the bottom-up strategy of either T-Recs or T-Recs++. Finally, some results comparing both systems on a collection of business letters are given."
            },
            "slug": "Applying-the-T-Recs-table-recognition-system-to-the-Kieninger-Dengel",
            "title": {
                "fragments": [],
                "text": "Applying the T-Recs table recognition system to the business letter domain"
            },
            "tldr": {
                "abstractSimilarityScore": 79,
                "text": "This paper summarizes the core idea of the T-Recs table recognition system, an integrated system covering block-segmentation, table location and a model-free structural analysis of tables, and proposes a quality evaluation measure that reflects the bottom-up strategy of either T-recs or T- Recs++."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of Sixth International Conference on Document Analysis and Recognition"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3320897"
                        ],
                        "name": "T. Kieninger",
                        "slug": "T.-Kieninger",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Kieninger",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kieninger"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Conclusions and future work are given in Section 8."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 206405589,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "108030474840ce5e1086cc8ef598ff3e6c13693c",
            "isKey": false,
            "numCitedBy": 120,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents an efficient approach to identify tabular structures within either electronic or paper documents. The resulting T-Recs system takes word bounding box information as input, and outputs the corresponding logical text block units. Starting with an arbitrary word as block seed the algorithm recursively expands this block to all words that interleave with their vertical neighbors. Since even smallest gaps of table columns prevent their words from mutual interleaving, this initial segmentation is able to identify and isolate such columns. In order to deal with some inherent segmentation errors caused by isolated lines, overhanging words, or cells spawning more than one column, a series of postprocessing steps is added. These steps benefit form a very simple distinction between type 1 and type 2 blocks: type 1 blocks are those of at most one word per line, all others are of type 2. This distinction allows the selective application of heuristics to each group of blocks. The conjoint decomposition of column blocks into subsets of table cells leads to the final block segmentation of a homogeneous abstraction level. These segments serve the final layout analysis which identifies table environments and cells that are stretching over several rows and/or columns."
            },
            "slug": "Table-structure-recognition-based-on-robust-block-Kieninger",
            "title": {
                "fragments": [],
                "text": "Table structure recognition based on robust block segmentation"
            },
            "tldr": {
                "abstractSimilarityScore": 79,
                "text": "An efficient approach to identify tabular structures within either electronic or paper documents by taking word bounding box information as input, and outputs the corresponding logical text block units through the T-Recs system."
            },
            "venue": {
                "fragments": [],
                "text": "Electronic Imaging"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1780258"
                        ],
                        "name": "Jisheng Liang",
                        "slug": "Jisheng-Liang",
                        "structuredName": {
                            "firstName": "Jisheng",
                            "lastName": "Liang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jisheng Liang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1744200"
                        ],
                        "name": "I. T. Phillips",
                        "slug": "I.-T.-Phillips",
                        "structuredName": {
                            "firstName": "Ihsin",
                            "lastName": "Phillips",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. T. Phillips"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1710238"
                        ],
                        "name": "R. Haralick",
                        "slug": "R.-Haralick",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Haralick",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Haralick"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 3344752,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a14e88e41a727737171f0c02e28555112445ad6a",
            "isKey": false,
            "numCitedBy": 7,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract:This paper presents a text block extraction algorithm that takes as its input a set of text lines of a given document, and partitions the text lines into a set of text blocks, where each text block is associated with a set of homogeneous formatting attributes, e.g. text-alignment, indentation. The text block extraction algorithm described in this paper is probability based. We adopt an engineering approach to systematically characterising the text block structures based on a large document image database, and develop statistical methods to extract the text block structures from the image. All the probabilities are estimated from an extensive training set of various kinds of measurements among the text lines, and among the text blocks in the training data set. The off-line probabilities estimated in the training then drive all decisions in the on-line text block extraction. An iterative, relaxation-like method is used to find the partitioning solution that maximizes the joint probability. To evaluate the performance of our text block extraction algorithm, we used a three-fold validation method and developed a quantitative performance measure. The algorithm was evaluated on the UW-III database of some 1600 scanned document image pages. The text block extraction algorithm identifies and segments 91% of text blocks correctly."
            },
            "slug": "Consistent-Partition-and-Labelling-of-Text-Blocks-Liang-Phillips",
            "title": {
                "fragments": [],
                "text": "Consistent Partition and Labelling of Text Blocks"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "An engineering approach to systematically characterising the text block structures based on a large document image database is adopted, and statistical methods to extract theText block structures from the image are developed."
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Analysis & Applications"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2115625054"
                        ],
                        "name": "Yalin Wang",
                        "slug": "Yalin-Wang",
                        "structuredName": {
                            "firstName": "Yalin",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yalin Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1710238"
                        ],
                        "name": "R. Haralick",
                        "slug": "R.-Haralick",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Haralick",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Haralick"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1744200"
                        ],
                        "name": "I. T. Phillips",
                        "slug": "I.-T.-Phillips",
                        "structuredName": {
                            "firstName": "Ihsin",
                            "lastName": "Phillips",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. T. Phillips"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 3063945,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cce5b4c397ca657a4b7129677f90a23db3862ed9",
            "isKey": false,
            "numCitedBy": 16,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a text word extraction algorithm that takes a set of bounding boxes of glyphs and their associated text lines of a given document and partitions the glyphs into a set of text words, using only the geometric information of the input glyphs. The algorithm is probability based. An iterative, relaxation-like method is used to find the partitioning solution that maximizes the joint probability. To evaluate the performance of our test word extraction algorithm, we used a 3-fold validation method and developed a quantitative performance measure. The algorithm was evaluated on the UW-III database of some 1600 scanned document image pages. An area-overlap measure was used to find the correspondence between the detected entities and the ground-truth. For a total of 827, 433 ground truth words, the algorithm identified and segmented 800, 149 words correctly, an accuracy of 97.43%."
            },
            "slug": "Statistical-based-approach-to-word-segmentation-Wang-Haralick",
            "title": {
                "fragments": [],
                "text": "Statistical-based approach to word segmentation"
            },
            "tldr": {
                "abstractSimilarityScore": 92,
                "text": "A text word extraction algorithm that takes a set of bounding boxes of glyphs and their associated text lines of a given document and partitions the glyphs into aSet of text words, using only the geometric information of the input glyphs, is presented."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings 15th International Conference on Pattern Recognition. ICPR-2000"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1780258"
                        ],
                        "name": "Jisheng Liang",
                        "slug": "Jisheng-Liang",
                        "structuredName": {
                            "firstName": "Jisheng",
                            "lastName": "Liang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jisheng Liang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2053206762"
                        ],
                        "name": "R. Rogers",
                        "slug": "R.-Rogers",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Rogers",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Rogers"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1710238"
                        ],
                        "name": "R. Haralick",
                        "slug": "R.-Haralick",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Haralick",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Haralick"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1744200"
                        ],
                        "name": "I. T. Phillips",
                        "slug": "I.-T.-Phillips",
                        "structuredName": {
                            "firstName": "Ihsin",
                            "lastName": "Phillips",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. T. Phillips"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7869564,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "38f43b60ae9307c3aba4755ced2f14a595e95dbe",
            "isKey": false,
            "numCitedBy": 20,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "A document image analysis toolbox including a collection of data structures and algorithms to support a variety of applications, is described in this paper. An experimental environment is built to allow developers to develop, test and optimize their algorithms and systems. Appropriate and quantitative performance metrics for each kind of information a document analysis technique infers have been developed. The performance of each algorithm has been evaluated based on these metrics and the UW-III document image database which contains a total of 1600 English document images randomly selected from scientific and technical journals."
            },
            "slug": "UW-ISL-document-image-analysis-toolbox:-an-Liang-Rogers",
            "title": {
                "fragments": [],
                "text": "UW-ISL document image analysis toolbox: an experimental environment"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "A document image analysis toolbox including a collection of data structures and algorithms to support a variety of applications, is described in this paper."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Fourth International Conference on Document Analysis and Recognition"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2456613"
                        ],
                        "name": "J. H. Shamilian",
                        "slug": "J.-H.-Shamilian",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Shamilian",
                            "middleNames": [
                                "H"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. H. Shamilian"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1723766"
                        ],
                        "name": "H. Baird",
                        "slug": "H.-Baird",
                        "structuredName": {
                            "firstName": "Henry",
                            "lastName": "Baird",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Baird"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1394247998"
                        ],
                        "name": "T. Wood",
                        "slug": "T.-Wood",
                        "structuredName": {
                            "firstName": "T.",
                            "lastName": "Wood",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Wood"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 70,
                                "start": 67
                            }
                        ],
                        "text": "In Section 6, we describe a table structure understanding performance evaluation protocol based on rectangular overlap."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 206775234,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5ad7b7fe1c5e346b1cb9034af4fa18b5afe4d45e",
            "isKey": false,
            "numCitedBy": 55,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe the architecture of a system for reading machine-printed documents in known predefined tabular-data layout styles. In these tables, textual data are presented in record lines made up of fixed-width fields. Tables often do not rely on line-art (ruled lines) to delimit fields, and in this way differ crucially from fixed forms. Our system performs these steps: copes with multiple tables per page; identifies records within tables; segments records into fields; and recognizes characters within fields, constrained by field-specific contextual knowledge. Obstacles to good performance on tables include small print, tight line-spacing, poor-quality text (such as photocopies), and line-art or background patterns that touch the text. Precise skew-correction and pitch-estimation, and high-performance OCR using neural nets proved crucial in overcoming these obstacles. The most significant technical advances in this work appear to be algorithms for identifying and segmenting records with known layout, and integration of these algorithms with a graphical user interface (GUI) for defining new layouts. This GUI has been ergonomically designed to make efficient and intuitive use of exemplary images, so that the skill and manual effort required to retarget the system to new table layouts are held to a minimum. The system has been applied in this way to more than 400 distinct tabular layouts. During the last three years the system has read over fifty million records with high accuracy."
            },
            "slug": "A-retargetable-table-reader-Shamilian-Baird",
            "title": {
                "fragments": [],
                "text": "A retargetable table reader"
            },
            "tldr": {
                "abstractSimilarityScore": 62,
                "text": "The architecture of a system for reading machine-printed documents in known predefined tabular-data layout styles, and algorithms for identifying and segmenting records with known layout, and integration of these algorithms with a graphical user interface (GUI) for defining new layouts are described."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Fourth International Conference on Document Analysis and Recognition"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34996245"
                        ],
                        "name": "B. Klein",
                        "slug": "B.-Klein",
                        "structuredName": {
                            "firstName": "Bertin",
                            "lastName": "Klein",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Klein"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2602600"
                        ],
                        "name": "Serdar G\u00f6kkus",
                        "slug": "Serdar-G\u00f6kkus",
                        "structuredName": {
                            "firstName": "Serdar",
                            "lastName": "G\u00f6kkus",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Serdar G\u00f6kkus"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3320897"
                        ],
                        "name": "T. Kieninger",
                        "slug": "T.-Kieninger",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Kieninger",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kieninger"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145279674"
                        ],
                        "name": "A. Dengel",
                        "slug": "A.-Dengel",
                        "structuredName": {
                            "firstName": "Andreas",
                            "lastName": "Dengel",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Dengel"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Conclusions and future work are given in Section 8."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 42252433,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ea049d0fc3995977b52c10be08fc288789b86ac1",
            "isKey": false,
            "numCitedBy": 37,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper introduces three approaches for an industrial, comprehensive document analysis system to enable it to spot tables in documents. Searching for a set of known table headers (approach 1) works rather well in a significant number of documents. But this approach (though it is implemented tolerant to OCR errors) is not tolerant enough towards some kinds of even minor aberrations. This not only decreases the recognition results, but also, even worse, makes users feel uncomfortable. Pragmatically trying to mimic for what the human eyes might key, leads to our two further, complementary approaches: searching for layout structures which resemble parts of columns (approach 2), and searching for groupings of similar lines (approach 3). The suitability of the approaches for our system requires them to be very simple to implement and simple to explain to users, computationally cheap, and combinable. In the domain of health insurances who receive huge amounts of so called medical liquidations on a daily basis we obtain very good results. On document samples representative for the every day practice of five customers-health insurance companies-tables were spotted as good and as fast as the customers expected the system to be. We thus consider our current approaches as a step towards cognitive adequacy."
            },
            "slug": "Three-approaches-to-\"industrial\"-table-spotting-Klein-G\u00f6kkus",
            "title": {
                "fragments": [],
                "text": "Three approaches to \"industrial\" table spotting"
            },
            "tldr": {
                "abstractSimilarityScore": 78,
                "text": "This paper introduces three approaches for an industrial, comprehensive document analysis system to enable it to spot tables in documents, and considers the current approaches as a step towards cognitive adequacy."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of Sixth International Conference on Document Analysis and Recognition"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144881104"
                        ],
                        "name": "E. A. Green",
                        "slug": "E.-A.-Green",
                        "structuredName": {
                            "firstName": "Edward",
                            "lastName": "Green",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. A. Green"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751773"
                        ],
                        "name": "M. Krishnamoorthy",
                        "slug": "M.-Krishnamoorthy",
                        "structuredName": {
                            "firstName": "Mukkai",
                            "lastName": "Krishnamoorthy",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Krishnamoorthy"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 13,
                                "start": 10
                            }
                        ],
                        "text": "We developed a software package that can\n0031-3203/$30.00 ?"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 866386,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ecb5fdcdeff0d56ebf61b151ac8617ae3b30881e",
            "isKey": true,
            "numCitedBy": 52,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "We develop a strategy for extracting the underlying relational information from the images of printed tables. Visual clues that exist in the image are used for extracting first the physical, and then the logical structure of the table. Since these visual clues generally have a logical meaning, there must be some association made between the graphical attributes extracted and their function of reflecting the logic expressed by the table; this knowledge is coordinated in a model. This approach, therefore, can be adapted to all tables which have graphical attributes discernible to the image analysis being used."
            },
            "slug": "Model-based-analysis-of-printed-tables-Green-Krishnamoorthy",
            "title": {
                "fragments": [],
                "text": "Model-based analysis of printed tables"
            },
            "tldr": {
                "abstractSimilarityScore": 63,
                "text": "This strategy for extracting the underlying relational information from the images of printed tables is developed and can be adapted to all tables which have graphical attributes discernible to the image analysis being used."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of 3rd International Conference on Document Analysis and Recognition"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2115625054"
                        ],
                        "name": "Yalin Wang",
                        "slug": "Yalin-Wang",
                        "structuredName": {
                            "firstName": "Yalin",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yalin Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1744200"
                        ],
                        "name": "I. T. Phillips",
                        "slug": "I.-T.-Phillips",
                        "structuredName": {
                            "firstName": "Ihsin",
                            "lastName": "Phillips",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. T. Phillips"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[24]) of the page and groups them into a collection of equivalence subsets."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[24] for de nition) with br rows and bc columns and with lefttop vertex coordinate (xb1; yb1), is a vertical blank block separator, BK= (br; bc; xb1; yb1), if and only if it satis es the following conditions:"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 48,
                                "start": 44
                            }
                        ],
                        "text": "\u2022 Ratio of total large vertical blank block [24] and large horizontal blank block [24] areas over identi ed table area."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 27,
                                "start": 23
                            }
                        ],
                        "text": "\u2022 Vertical blank block [24] area ratio, ra, taken over each table\u2019s area."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 3181078,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c582c2971395c3957a4152956081bb52e78be259",
            "isKey": true,
            "numCitedBy": 17,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents an improved zone content classification method. Motivated by our novel background-analysis-based table identification research, we added two new features to the feature vector from one previously published method [7]. The new features are the total area of large horizontal and large vertical blank blocks and the number of text glyphs in the zone. A binary decision tree is used to assign a zone class on the basis of its feature vector. The training and testing data sets for the algorithm include images drawn from the UWCDROM-III document image database. The classifier is able to classify each given scientific and technical document zone into one of the nine classes, text classes (of font size pt and font size pt), math, table, halftone, map/drawing, ruling, logo, and others. The improved zone classification method raised the accuracy rate to from and reduced the median false alarm rate to from . 1 Problem Statement Let ! be a set of zone entities. Let \" be a set of content labels, such as text, table, math, etc. The function #%$&!(')\" associates each element of * with a label. The function +,$-!.'0/ specifies measurements made on each element of ! , where / is the measurement space. The zone content classification problem can be formulated as follows: Given a zone set ! and a content label set \" , find a classification function #1$2!3'4\" , that has the maximum probability: 576 # 6 !98;: + 6 !98 8 (1) In our current approach, we assume conditional independence between the zone classifications, so the probability in Equation 1 may be decomposed as 576 # 6 !98;: + 6 !98 8= @ A B 576 # 6DC 8;: + 6DC 8 8 (2) The problem can be solved by maximizing each individual probability 576 # 6DC 8;: + 6DC 8 8 in Equation 2, where CFE ! . In our zone content classification experiment, the elements in set ! are zone groundtruth entities from UWCDROM III document image database [6]. The elements of set \" are text with font size GIH J pt, text with font size KLH M pt, math, table, halftone, map/drawing, ruling, logo, and others. + 6DC 8 is a feature vector generated for C , where CNE ! . We used a decision tree classifier to compute the probability in Equation 2 and make the assignment. 2 Related Work and Paper Organization A complete document image understanding system can transform paper documents into a hierarchical representation of their structure and content. The transformed document representation enables document interchange, editing, browsing, indexing, filing and retrieval. The zone classification technique plays the key role in the success of such a document understanding system. Not only is it useful for successive applications such as OCR, table understanding, etc, but it can be used to assist and validate document segmentation. In the literature, Sivaramakrishnan et. al [7] extracted features for each zone such as run length mean and variance, spatial mean and variance, fraction of the total number of black pixels in the zone, and the zone width ratio for each zone. They used the decision tree classifier to assign a zone class on the basis of its feature vector. They did their experiments on MPO M document images from UWCDROM I image database. Liang et. al [5] developed a feature based zone classifier using only the knowledge of the widths and the heights of the connected components within a given zone. Le et. al [4] proposed an automated labeling of zones from scanned images with labels such as titles, authors, affiliations and abstracts. The labeling is based on features calculated from optical character recognition(OCR) output, neural network models, machine learning methods, and a set of rules that is derived from an analysis of the page layout for each journal and from generic typesetting knowledge for English text. We developed a novel background-analysis-based table identification technique. We repeated Sivaramakrishnan et. al\u2019s work [7] on a larger database with a goal to improve its performance on table zone classification. Although some background analysis techniques can be found in the literature([1],[2]), none of them, to our knowledge, has been used in the table identification problem. We added two new features: the total area of large horizontal and vertical blank blocks and the number of text glyphs in the given zone, to the original feature vector. We improved the accuracy rate and reduced the false alarm rates for most of the nine classes. The rest of this paper is divided into Q sections. section 3 gives the definitions of large horizontal and large vertical blank blocks. The two new features are described in section 4. A brief introduction to the decision tree classifier is given in section 5. The experimental results are reported in section 6. Our conclusion and statement of future work are discussed in section 7."
            },
            "slug": "IMPROVEMENT-OF-ZONE-CONTENT-CLASSIFICATION-BY-USING-Wang-Phillips",
            "title": {
                "fragments": [],
                "text": "IMPROVEMENT OF ZONE CONTENT CLASSIFICATION BY USING BACKGROUND ANALYSIS"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "The improved zone content classification method raised the accuracy rate and reduced the median false alarm rate and the total area of large horizontal and large vertical blank blocks and the number of text glyphs in the zone."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35074265"
                        ],
                        "name": "J. Handley",
                        "slug": "J.-Handley",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Handley",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Handley"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 31720553,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "c730e6636e4245e2e282725d3c62a307e442eb02",
            "isKey": false,
            "numCitedBy": 29,
            "numCiting": 3,
            "paperAbstract": {
                "fragments": [],
                "text": "A table in a document is a rectilinear arrangement of cells where each cell contains a sequence of words. Several lines of text may compose one cell. Cells may be delimited by horizontal or vertical lines, but often this is not the case. A table analysis system is described which reconstructs table formatting information from table images whether or not the cells are explicitly delimited. Inputs to the system are word bounding boxes and any horizontal and vertical lines that delimit cells. Using a sequence of carefully-crafted rules, multi-line cells and their interrelationships are found even though no explicit delimiters are visible. This robust system is a component of a commercial document recognition system."
            },
            "slug": "Table-analysis-for-multiline-cell-identification-Handley",
            "title": {
                "fragments": [],
                "text": "Table analysis for multiline cell identification"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "A table analysis system is described which reconstructs table formatting information from table images whether or not the cells are explicitly delimited, and is a component of a commercial document recognition system."
            },
            "venue": {
                "fragments": [],
                "text": "IS&T/SPIE Electronic Imaging"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "25727408"
                        ],
                        "name": "Surekha Chandran",
                        "slug": "Surekha-Chandran",
                        "structuredName": {
                            "firstName": "Surekha",
                            "lastName": "Chandran",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Surekha Chandran"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3110392"
                        ],
                        "name": "R. Kasturi",
                        "slug": "R.-Kasturi",
                        "structuredName": {
                            "firstName": "Rangachar",
                            "lastName": "Kasturi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Kasturi"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 3,
                                "start": 0
                            }
                        ],
                        "text": "Large data sets with ground truth are essential in assessing the performance of computer vision algorithms."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 30719791,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "4c8cb8fd8a87ff2e60094385492a13c30977554b",
            "isKey": false,
            "numCitedBy": 55,
            "numCiting": 3,
            "paperAbstract": {
                "fragments": [],
                "text": "A system for extraction of structural information of a table from its image is discussed. Following the initial binarization and deskewing operations, the image is scanned to extract all horizontal and vertical lines that are present. The table's dimensions are estimated based on these lines. Unlike other systems, the procedure described does not depend on the sole existence of lines to mark the item blocks. White streams are recognized in both the horizontal and vertical direction as substitutes for any missing demarcation lines. A structure interpretation procedure uses the extracted demarcation information to identify each of the item blocks in the table. Subsequently, the interrelations of these item blocks are used to recognize the structure of the tabulated data.<<ETX>>"
            },
            "slug": "Structural-recognition-of-tabulated-data-Chandran-Kasturi",
            "title": {
                "fragments": [],
                "text": "Structural recognition of tabulated data"
            },
            "tldr": {
                "abstractSimilarityScore": 64,
                "text": "A system for extraction of structural information of a table from its image using white streams as substitutes for any missing demarcation lines to identify each of the item blocks in the table."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of 2nd International Conference on Document Analysis and Recognition (ICDAR '93)"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1768769"
                        ],
                        "name": "F. Cesarini",
                        "slug": "F.-Cesarini",
                        "structuredName": {
                            "firstName": "Francesca",
                            "lastName": "Cesarini",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Cesarini"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145467467"
                        ],
                        "name": "M. Gori",
                        "slug": "M.-Gori",
                        "structuredName": {
                            "firstName": "Marco",
                            "lastName": "Gori",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Gori"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3285734"
                        ],
                        "name": "S. Marinai",
                        "slug": "S.-Marinai",
                        "structuredName": {
                            "firstName": "Simone",
                            "lastName": "Marinai",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Marinai"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2540925"
                        ],
                        "name": "G. Soda",
                        "slug": "G.-Soda",
                        "structuredName": {
                            "firstName": "Giovanni",
                            "lastName": "Soda",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Soda"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 125,
                                "start": 122
                            }
                        ],
                        "text": "Tables are compact and e>cient for presenting relational information and most of the documents produced today contain various types of tables."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5595658,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "abc89e4eee4efc4d7b682b9bad6ba7cf118f168d",
            "isKey": false,
            "numCitedBy": 100,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a flexible form-reader system capable of extracting textual information from accounting documents, like invoices and bills of service companies. In this kind of document, the extraction of some information fields cannot take place without having detected the corresponding instruction fields, which are only constrained to range in given domains. We propose modeling the document's layout by means of attributed relational graphs, which turn out to be very effective for form registration, as well as for performing a focused search for instruction fields. This search is carried out by means of a hybrid model, where proper algorithms, based on morphological operations and connected components, are integrated with connectionist models. Experimental results are given in order to assess the actual performance of the system."
            },
            "slug": "INFORMys:-A-Flexible-Invoice-Like-Form-Reader-Cesarini-Gori",
            "title": {
                "fragments": [],
                "text": "INFORMys: A Flexible Invoice-Like Form-Reader System"
            },
            "tldr": {
                "abstractSimilarityScore": 69,
                "text": "A flexible form-reader system capable of extracting textual information from accounting documents, like invoices and bills of service companies, is described by means of attributed relational graphs, which turn out to be very effective for form registration, as well as for performing a focused search for instruction fields."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1744200"
                        ],
                        "name": "I. T. Phillips",
                        "slug": "I.-T.-Phillips",
                        "structuredName": {
                            "firstName": "Ihsin",
                            "lastName": "Phillips",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. T. Phillips"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2111237291"
                        ],
                        "name": "Su S. Chen",
                        "slug": "Su-S.-Chen",
                        "structuredName": {
                            "firstName": "Su",
                            "lastName": "Chen",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Su S. Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1710238"
                        ],
                        "name": "R. Haralick",
                        "slug": "R.-Haralick",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Haralick",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Haralick"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Conclusions and future work are given in Section 8."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 3258255,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "de1580d4cc0c47e4985c8ce52d106c6a7432ff70",
            "isKey": false,
            "numCitedBy": 127,
            "numCiting": 1,
            "paperAbstract": {
                "fragments": [],
                "text": "The design of a comprehensive standard document database for machine-printed documents is presented. The effort to produce a series of carefully ground-truthed document databases to be issued on CD-ROMs is described in detail. The databases can be utilized by the OCR and document understanding community as a common platform to develop, test, and evaluate their algorithms.<<ETX>>"
            },
            "slug": "CD-ROM-document-database-standard-Phillips-Chen",
            "title": {
                "fragments": [],
                "text": "CD-ROM document database standard"
            },
            "tldr": {
                "abstractSimilarityScore": 65,
                "text": "The design of a comprehensive standard document database for machine-printed documents is presented and can be utilized by the OCR and document understanding community as a common platform to develop, test, and evaluate their algorithms."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of 2nd International Conference on Document Analysis and Recognition (ICDAR '93)"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2116415943"
                        ],
                        "name": "B. Yu",
                        "slug": "B.-Yu",
                        "structuredName": {
                            "firstName": "Bin",
                            "lastName": "Yu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Yu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145295484"
                        ],
                        "name": "Anil K. Jain",
                        "slug": "Anil-K.-Jain",
                        "structuredName": {
                            "firstName": "Anil",
                            "lastName": "Jain",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Anil K. Jain"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 38916969,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6c41d71ca5ae222ab72d16f254edb5fbd4e2de93",
            "isKey": false,
            "numCitedBy": 134,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "Recent advances in intelligent character recognition are enabling us to address many challenging problems in document image analysis. One of them is intelligent form analysis. This paper describes a generic system for form dropout when the filled-in characters or symbols are either touching or crossing the form frames. We propose a method to separate these characters from form frames whose locations are unknown. Since some of the character strokes are either touching or crossing the form frames, we need to address the following three issues: 1) localization of form frames; 2) separation of characters and form frames; and 3) reconstruction of broken strokes introduced during separation. The form frame is automatically located by finding long straight lines based on the block adjacency graph. Form frame separation and character reconstruction are implemented by means of this graph. The proposed system includes form structure learning and form dropout. First, a form structure-based template is automatically generated from a blank form which includes form frames, preprinted data areas and skew angle. With this form template, our system can then extract both handwritten and machine-typed filled-in data. Experimental results on three different types of forms show the performance of our system. Further, the proposed method is robust to noise and skew that is introduced during scanning."
            },
            "slug": "A-Generic-System-for-Form-Dropout-Yu-Jain",
            "title": {
                "fragments": [],
                "text": "A Generic System for Form Dropout"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "A generic system for form dropout when the filled-in characters or symbols are either touching or crossing the form frames and a method to separate these characters from form frames whose locations are unknown is proposed."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39738361"
                        ],
                        "name": "Gang Liu",
                        "slug": "Gang-Liu",
                        "structuredName": {
                            "firstName": "Gang",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Gang Liu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1710238"
                        ],
                        "name": "R. Haralick",
                        "slug": "R.-Haralick",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Haralick",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Haralick"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Conclusions and future work are given in Section 8."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 28603590,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "50d590200af76021a1264d659004c8acbb33c45a",
            "isKey": false,
            "numCitedBy": 7,
            "numCiting": 43,
            "paperAbstract": {
                "fragments": [],
                "text": "A model-based FLIR ATR algorithm is described. It uti- lizes boundary contrast for target detection and recognition. Bound- ary contrast is related to the location uncertainty at target boundary points. A polygon model is used for deriving target centroid location uncertainty caused by the boundary point location uncertainty. The significance of the work lies in the sound mathematical models used in deriving the relationship between contrast and location uncer- tainty for the boundary points and the relationship between bound- ary point location uncertainty and centroid location uncertainty. Ex- periment results show significantly improved performance in detection, recognition, and localization. \u00a9 2000 SPIE and IS&T. (S1017-9909(00)01602-0) 1 Introduction In the ATR application, the sensory images are usually taken in uncontrolled environment where the conditions of the image forming process may vary greatly, e.g., in out- door scenes with unknown numbers and types of targets, complicated terrain background, significant amount of clut- ter, all kinds of weather conditions, different season of the year and different time of the day, occlusion and camou- flage of the targets, etc. The great complexity in the image forming process has made ATR a distinctively difficult problem where the input image is characterized by ex- tremely high variability in the content and quality. This is particularly true with the forward-looking infrared ~FLIR! imagery. Compared with the first generation sensors, the second generation FLIR sensors give much better image with higher resolution, higher signal-to-noise ratio, and higher stability. The better image quality, especially increased number of pixels on targets, reveals more structure of the target appearance in the image, and allows the design of knowledge- and model-based algorithms. The situation is further improved by dramatically improving computing power which strongly supports sophisticated algorithms. There has been significant improvement in the observed performance of the ATR systems since the late 1980's. Since the second generation FLIR sensor has ap- proached the optical limits of sensor resolution, 1 improve- ment in ATR performance should be expected mainly from advancement in ATR algorithm instead of from further im- proved image quality. Model-based approaches to the ATR problem are the most promising in developing high perfor- mance systems. The ability of low-level feature extraction algorithms is restricted by their limited information input from the local image neighborhood. High-level information can be very useful to overcome this restriction. This is typically done in the model-based approaches. In these approaches, either the target models are directly utilized in the low-level informa- tion extraction modules, or hard decisions about the infor- mation content in the imagery are avoided on low-level measurements until they are combined, via the use of target models, into medium- or high-level evidence. In doing this, weak but consistent evidence in the low quality imagery can be recovered with significantly improved reliability. In this article, we describe an algorithm that computes a target saliency measure by properly utilizing the target boundary contrast evidence. The two major pieces in devel- oping the algorithm are the development of the relationship between boundary contrast and boundary point location un- certainty and the development of the model for target cen- troid location uncertainty induced by the boundary point location uncertainty. In experiments, the developed algo- rithm shows improved detection performance and more im- pressive improvement in recognition performance. The lo- calization performance is also good."
            },
            "slug": "FLIR-ATR-using-location-uncertainty-Liu-Haralick",
            "title": {
                "fragments": [],
                "text": "FLIR ATR using location uncertainty"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "An algorithm that computes a target saliency measure by properly utilizing the target boundary contrast evidence is described, which shows significantly improved performance in detection, recognition, and localization."
            },
            "venue": {
                "fragments": [],
                "text": "J. Electronic Imaging"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2122930"
                        ],
                        "name": "J. Ha",
                        "slug": "J.-Ha",
                        "structuredName": {
                            "firstName": "Jaekyu",
                            "lastName": "Ha",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Ha"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1710238"
                        ],
                        "name": "R. Haralick",
                        "slug": "R.-Haralick",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Haralick",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Haralick"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1744200"
                        ],
                        "name": "I. T. Phillips",
                        "slug": "I.-T.-Phillips",
                        "structuredName": {
                            "firstName": "Ihsin",
                            "lastName": "Phillips",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. T. Phillips"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 17179084,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f03c5e7b1e66936544eaf329cbe38c57ccf5feb0",
            "isKey": false,
            "numCitedBy": 176,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "A top-down page segmentation technique known as the recursive X-Y cut decomposes a document image recursively into a set of rectangular blocks. This paper proposes that the recursive X-Y cut be implemented using bounding boxes of connected components of black pixels instead of using image pixels. The advantage is that great improvement can be achieved in computation. In fact, once bounding boxes of connected components are obtained, the recursive X-Y cut is completed within an order of a second on Sparc-10 workstations for letter-sized document images scanned at 900 dpi resolution."
            },
            "slug": "Recursive-X-Y-cut-using-bounding-boxes-of-connected-Ha-Haralick",
            "title": {
                "fragments": [],
                "text": "Recursive X-Y cut using bounding boxes of connected components"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This paper proposes that the recursive X-Y cut be implemented using bounding boxes of connected components of black pixels instead of using image pixels, so that great improvement can be achieved in computation."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of 3rd International Conference on Document Analysis and Recognition"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49430588"
                        ],
                        "name": "M. Goossens",
                        "slug": "M.-Goossens",
                        "structuredName": {
                            "firstName": "Michel",
                            "lastName": "Goossens",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Goossens"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2348013"
                        ],
                        "name": "F. Mittelbach",
                        "slug": "F.-Mittelbach",
                        "structuredName": {
                            "firstName": "Frank",
                            "lastName": "Mittelbach",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Mittelbach"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2064034981"
                        ],
                        "name": "A. Samarin",
                        "slug": "A.-Samarin",
                        "structuredName": {
                            "firstName": "Alexander",
                            "lastName": "Samarin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Samarin"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 42,
                                "start": 37
                            }
                        ],
                        "text": "This software writes out two ?les: a LATEX ?le and a partial ground truth ?le."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 5,
                                "start": 0
                            }
                        ],
                        "text": "LATEX produces DVI ?les."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 90,
                                "start": 85
                            }
                        ],
                        "text": "Sets C, P are the contents of table entities and non-table entities in the generated LATEX [27] ?les, respectively."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 95,
                                "start": 91
                            }
                        ],
                        "text": "Sets C, P are the contents of table entities and non-table entities in the generated LATEX [27] les, respectively."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 60713571,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9b8e27e8f588f1278ba5010da78343297ec46a19",
            "isKey": true,
            "numCitedBy": 299,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "From the Publisher: \nLATEX is an accessible and effective tool for typesetting written documents. Users at all levels of experience, however, sometimes require help not readily available: techniques for defining new commands, styles for producing tables or graphics, explanations for changing fonts. This book, The LATEX Companion, is packed with information needed to use LATEX even more productively. It is a true companion to Leslie Lamport's original user's guide, also published by Addison-Wesley, and indeed, it is a valuable complement to any LATEX introduction. It is designed to enhance, not to replace, your basic documentation. \nCoinciding with the publication of The LATEX Companion is the availability of a revised LATEX standard- LATEX 2. This new release incorporates important LATEX developments over the past several years and provides a common basis for all LATEX enhancements. Some new styles, improve font handling, and a facility to produce PostScript graphics are included in the release. As part of the broad and unique coverage of this book, you will find complete documentation for all these added features. \nHIGHLIGHTS \nCovers all versions of LATEX now in use, including LATEX 2. Describes over 150 convenient styles for floats, graphics, tables, and much more Shows how to define new commands and environments Explains the use of PostScript Covers the latest extensions and programs for producing pictures, indexes,bibliographies, and advanced mathematics Includes techniques for multi-language support Describes the New Font Selection Scheme"
            },
            "slug": "The-LaTeX-companion-Goossens-Mittelbach",
            "title": {
                "fragments": [],
                "text": "The LaTeX companion"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This book is a true companion to Leslie Lamport's original user's guide and is a valuable complement to any LATEX introduction, designed to enhance, not to replace, your basic documentation."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2256718"
                        ],
                        "name": "W. Press",
                        "slug": "W.-Press",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Press",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Press"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48590121"
                        ],
                        "name": "S. Teukolsky",
                        "slug": "S.-Teukolsky",
                        "structuredName": {
                            "firstName": "Saul",
                            "lastName": "Teukolsky",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Teukolsky"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2608024"
                        ],
                        "name": "W. Vetterling",
                        "slug": "W.-Vetterling",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Vetterling",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Vetterling"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35046585"
                        ],
                        "name": "B. Flannery",
                        "slug": "B.-Flannery",
                        "structuredName": {
                            "firstName": "Brian",
                            "lastName": "Flannery",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Flannery"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 61769312,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "ca2832d2c30287a9ee5b8584cc498d2b1cb14753",
            "isKey": false,
            "numCitedBy": 16689,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Note: Includes bibliographical references, 3 appendixes and 2 indexes.- Diskette v 2.06, 3.5''[1.44M] for IBM PC, PS/2 and compatibles [DOS] Reference Record created on 2004-09-07, modified on 2016-08-08"
            },
            "slug": "Numerical-recipes-in-C-Press-Teukolsky",
            "title": {
                "fragments": [],
                "text": "Numerical recipes in C"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The Diskette v 2.06, 3.5''[1.44M] for IBM PC, PS/2 and compatibles [DOS] Reference Record created on 2004-09-07, modified on 2016-08-08."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1604429801"
                        ],
                        "name": "Robert M. Haralock",
                        "slug": "Robert-M.-Haralock",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Haralock",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Robert M. Haralock"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1809809"
                        ],
                        "name": "L. Shapiro",
                        "slug": "L.-Shapiro",
                        "structuredName": {
                            "firstName": "Linda",
                            "lastName": "Shapiro",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Shapiro"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "A hold-out cross validation experiment [33] was conducted on all the data with N = 9."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 61087042,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a9eaaecf23f3a4b7822e4bcca924e02cd5b4dc4e",
            "isKey": false,
            "numCitedBy": 3343,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "From the Publisher: \nThis two-volume set is an authoritative, comprehensive, modern work on computer vision that covers all of the different areas of vision with a balanced and unified approach. The discussion in \"Volume I\" focuses on image in, and image out or feature set out. \"Volume II\" covers the higher level techniques of illumination, perspective projection, analytical photogrammetry, motion, image matching, consistent labeling, model matching, and knowledge-based vision systems."
            },
            "slug": "Computer-and-Robot-Vision-Haralock-Shapiro",
            "title": {
                "fragments": [],
                "text": "Computer and Robot Vision"
            },
            "tldr": {
                "abstractSimilarityScore": 89,
                "text": "This two-volume set is an authoritative, comprehensive, modern work on computer vision that covers all of the different areas of vision with a balanced and unified approach."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1750195"
                        ],
                        "name": "E. Trucco",
                        "slug": "E.-Trucco",
                        "structuredName": {
                            "firstName": "Emanuele",
                            "lastName": "Trucco",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Trucco"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 60788031,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0ab81a64aa4f5a9099e2099cd3fffbe21e5bcbb1",
            "isKey": false,
            "numCitedBy": 1741,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Computer and Robot Vision Vol. 1, by R.M. Haralick and Linda G. Shapiro, Addison-Wesley, 1992, ISBN 0-201-10887-1."
            },
            "slug": "Computer-and-Robot-Vision-Trucco",
            "title": {
                "fragments": [],
                "text": "Computer and Robot Vision"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 21,
                                "start": 18
                            }
                        ],
                        "text": "Clearly, UW CDROM III cannot be directly used to evaluate table detection system."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 64,
                                "start": 60
                            }
                        ],
                        "text": "Elements ofP are the text ground truth le from UW CDROM III [17]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 56,
                                "start": 52
                            }
                        ],
                        "text": "In the UW document image database III (UWCDROM III) [17], there are 215 marked table zones but no structure data for them."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 60,
                                "start": 57
                            }
                        ],
                        "text": "Elements ofP are the text ground truth ?le from UW CDROM III [17]."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Users\u2019 Reference Manual"
            },
            "venue": {
                "fragments": [],
                "text": "CD-ROM, UW-III Document Image Database-III"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49132848"
                        ],
                        "name": "Wang Ya-lin",
                        "slug": "Wang-Ya-lin",
                        "structuredName": {
                            "firstName": "Wang",
                            "lastName": "Ya-lin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wang Ya-lin"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 34,
                                "start": 30
                            }
                        ],
                        "text": "The table structure understanding problem includes two subproblems: the table detection problem and the table decomposition problem."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 58,
                                "start": 54
                            }
                        ],
                        "text": "Table structure understanding algorithm segments tables from the document pages and extracts the information from these tables."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 59721094,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "096b3dad175d17788e8935027c5df24cb3e9e621",
            "isKey": false,
            "numCitedBy": 15,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Document-ANalysis:-Table-Structure-Understanding-Ya-lin",
            "title": {
                "fragments": [],
                "text": "Document ANalysis: Table Structure Understanding and Zone Content Classification"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2002
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 26,
                                "start": 22
                            }
                        ],
                        "text": "The DVI2TIFF software [28] converts DVI ?le to a TIFF ?le and a so-called character ground truth ?le which contains the bounding box coordinates, the type and size of the font, and the ASCII code for every individual character in the image."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Dvi2tiJ user manual"
            },
            "venue": {
                "fragments": [],
                "text": "UW English Document Image Database-(I) Manual"
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 26,
                                "start": 22
                            }
                        ],
                        "text": "The DVI2TIFF software [28] converts DVI le to a TIFF le and a so-called character ground truth le which contains the bounding box coordinates, the type and size of the font, and the ASCII code for every individual character in the image."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Dvi2ti user manual"
            },
            "venue": {
                "fragments": [],
                "text": "UW English Document Image Database-(I) Manual"
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Conclusions and future work are given in Section 8."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Medium-independent table detection, in: SPIE Document Recognition and Retrieval VII"
            },
            "venue": {
                "fragments": [],
                "text": "Medium-independent table detection, in: SPIE Document Recognition and Retrieval VII"
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 18,
                                "start": 11
                            }
                        ],
                        "text": "Two papers [12,13] reported their research on the table decomposition problem."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 12,
                                "start": 8
                            }
                        ],
                        "text": "Handley [13] presented a table analysis system which reconstructed table formatting information from table images no matter whether or not the cells were explicitly delimited."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Table analysis for multi-line cell identi cation, in: SPIE Document Recognition and Retrieval"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2001
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Haralick , Flir atr using location uncertainty"
            },
            "venue": {
                "fragments": [],
                "text": "J . Electron . Imaging"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "DAFS: Document Attribute Format Speci\u00ffcation"
            },
            "venue": {
                "fragments": [],
                "text": "RAF Technology Inc"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 94,
                                "start": 90
                            }
                        ],
                        "text": "Sets C, P are the contents of table entities and non-table entities in the generated LTEX [27] ?les, respectively."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The LTEX Companion"
            },
            "venue": {
                "fragments": [],
                "text": "Addison-Wesley Publishing Company, Reading, MA"
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Conclusions and future work are given in Section 8."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Image Database-III"
            },
            "venue": {
                "fragments": [],
                "text": "Image Database-III"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 37,
                                "start": 33
                            }
                        ],
                        "text": "\u2019s dynamic programming algorithm [10] was 0:8760 + 0:6522 = 1:5282 and the performance of Wasserman et al."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 60,
                                "start": 56
                            }
                        ],
                        "text": "\u2019s dynamic programming based table extraction algorithm [10] performance results on whole image data set performance evaluation result on the table level"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Medium-independent table detection, in: SPIE Document Recognition and Retrieval"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 5,
                                "start": 0
                            }
                        ],
                        "text": "[8,9] presented a bottom-up approach to the table detection algorithm."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Applying the t-rec table recognition system to the business letter domain, in: Sixth International Conference on Document Analysis and Recognition"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2001
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Improvement of zone content classi\u00ffcation by using background analysis, in: Fourth IAPR International Workshop on Document Analysis Systems (DAS2000)"
            },
            "venue": {
                "fragments": [],
                "text": "Improvement of zone content classi\u00ffcation by using background analysis, in: Fourth IAPR International Workshop on Document Analysis Systems (DAS2000)"
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Dvi2tii user manual, UW English Document Image Database-(I) Manual"
            },
            "venue": {
                "fragments": [],
                "text": "Dvi2tii user manual, UW English Document Image Database-(I) Manual"
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Conclusions and future work are given in Section 8."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Table analysis for multi-line cell identi\u00ffcation, in: SPIE Document Recognition and Retrieval VIII"
            },
            "venue": {
                "fragments": [],
                "text": "Table analysis for multi-line cell identi\u00ffcation, in: SPIE Document Recognition and Retrieval VIII"
            },
            "year": 2001
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 120,
                                "start": 116
                            }
                        ],
                        "text": "The CHARTRU2DAFS software [26] combines each TIFF le and its character ground truth le and converts it to a DAFS le [29]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "RAF Technology Inc., DAFS: Document Attribute Format"
            },
            "venue": {
                "fragments": [],
                "text": "Speci cation,"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A theoretical foundation and a method for document table structure extraction and decomposition"
            },
            "venue": {
                "fragments": [],
                "text": "A theoretical foundation and a method for document table structure extraction and decomposition"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[11] introduced three approaches for an industrial document analysis system."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Three approaches to \u201cindustrial"
            },
            "venue": {
                "fragments": [],
                "text": "Sixth International Conference on Document Analysis and Recognition (ICDAR01),"
            },
            "year": 2001
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Document Analysis Systems V, Fifth IAPR International Workship on Document Analysis Systems"
            },
            "venue": {
                "fragments": [],
                "text": "Document Analysis Systems V, Fifth IAPR International Workship on Document Analysis Systems"
            },
            "year": 2002
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Illuminator User's Manual"
            },
            "venue": {
                "fragments": [],
                "text": "Illuminator User's Manual"
            },
            "year": 1995
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 25,
            "methodology": 6
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 49,
        "totalPages": 5
    },
    "page_url": "https://www.semanticscholar.org/paper/Table-structure-understanding-and-its-performance-Wang-Phillips/a46ba896cdb3386f591db1a2d6172459f1bd2523?sort=total-citations"
}