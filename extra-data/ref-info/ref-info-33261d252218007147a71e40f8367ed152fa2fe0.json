{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38087946"
                        ],
                        "name": "Anthony Fader",
                        "slug": "Anthony-Fader",
                        "structuredName": {
                            "firstName": "Anthony",
                            "lastName": "Fader",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Anthony Fader"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1982950"
                        ],
                        "name": "Luke Zettlemoyer",
                        "slug": "Luke-Zettlemoyer",
                        "structuredName": {
                            "firstName": "Luke",
                            "lastName": "Zettlemoyer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Luke Zettlemoyer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1741101"
                        ],
                        "name": "Oren Etzioni",
                        "slug": "Oren-Etzioni",
                        "structuredName": {
                            "firstName": "Oren",
                            "lastName": "Etzioni",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Oren Etzioni"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 32,
                                "start": 14
                            }
                        ],
                        "text": "In contrast, (Fader et al., 2013) proposed a framework for open QA requiring almost no human annotation."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 53,
                                "start": 35
                            }
                        ],
                        "text": "To overcome this issue, we follow (Fader et al., 2013) and supplement our training data with an indirect supervision signal made of pairs of question paraphrases collected from the WIKIANSWERS website."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 98,
                                "start": 80
                            }
                        ],
                        "text": "On WIKIANSWERS, users can tag pairs of questions as rephrasings of each other: (Fader et al., 2013) harvested a set of 2M distinct questions from WIKIANSWERS, which were grouped into 350k paraphrase clusters."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 237,
                                "start": 219
                            }
                        ],
                        "text": "(Bordes et al., 2014b) introduced an embedding model, which learns lowdimensional vector representations of words and symbols (such as KBs constituents) and can be trained with even less supervision than the system of (Fader et al., 2013) while being able to achieve better prediction performance."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 224,
                                "start": 204
                            }
                        ],
                        "text": ", 2014b) introduced an embedding model, which learns lowdimensional vector representations of words and symbols (such as KBs constituents) and can be trained with even less supervision than the system of (Fader et al., 2013) while being able to achieve better prediction performance."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 64,
                                "start": 46
                            }
                        ],
                        "text": "However, this approach is only compared with (Fader et al., 2013) which operates in a simplified setting and has not been applied in more realistic conditions nor evaluated against the best performing methods."
                    },
                    "intents": []
                }
            ],
            "corpusId": 8893912,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c0be2ac2f45681f1852fc1d298af5dceb85834f4",
            "isKey": true,
            "numCitedBy": 325,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "We study question answering as a machine learning problem, and induce a function that maps open-domain questions to queries over a database of web extractions. Given a large, community-authored, question-paraphrase corpus, we demonstrate that it is possible to learn a semantic lexicon and linear ranking function without manually annotating questions. Our approach automatically generalizes a seed lexicon and includes a scalable, parallelized perceptron parameter estimation scheme. Experiments show that our approach more than quadruples the recall of the seed lexicon, with only an 8% loss in precision."
            },
            "slug": "Paraphrase-Driven-Learning-for-Open-Question-Fader-Zettlemoyer",
            "title": {
                "fragments": [],
                "text": "Paraphrase-Driven Learning for Open Question Answering"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "This work demonstrates that it is possible to learn a semantic lexicon and linear ranking function without manually annotating questions and automatically generalizes a seed lexicon, and includes a scalable, parallelized perceptron parameter estimation scheme."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "33219438"
                        ],
                        "name": "Xuchen Yao",
                        "slug": "Xuchen-Yao",
                        "structuredName": {
                            "firstName": "Xuchen",
                            "lastName": "Yao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xuchen Yao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7536576"
                        ],
                        "name": "Benjamin Van Durme",
                        "slug": "Benjamin-Van-Durme",
                        "structuredName": {
                            "firstName": "Benjamin",
                            "lastName": "Durme",
                            "middleNames": [
                                "Van"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Benjamin Van Durme"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2131938,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "319e572fcddff77513eed8a25effbc7d9ff8ef85",
            "isKey": false,
            "numCitedBy": 412,
            "numCiting": 48,
            "paperAbstract": {
                "fragments": [],
                "text": "Answering natural language questions using the Freebase knowledge base has recently been explored as a platform for advancing the state of the art in open domain semantic parsing. Those efforts map questions to sophisticated meaning representations that are then attempted to be matched against viable answer candidates in the knowledge base. Here we show that relatively modest information extraction techniques, when paired with a webscale corpus, can outperform these sophisticated approaches by roughly 34% relative gain."
            },
            "slug": "Information-Extraction-over-Structured-Data:-with-Yao-Durme",
            "title": {
                "fragments": [],
                "text": "Information Extraction over Structured Data: Question Answering with Freebase"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "It is shown that relatively modest information extraction techniques, when paired with a webscale corpus, can outperform these sophisticated approaches by roughly 34% relative gain."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1713934"
                        ],
                        "name": "Antoine Bordes",
                        "slug": "Antoine-Bordes",
                        "structuredName": {
                            "firstName": "Antoine",
                            "lastName": "Bordes",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Antoine Bordes"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145183709"
                        ],
                        "name": "J. Weston",
                        "slug": "J.-Weston",
                        "structuredName": {
                            "firstName": "Jason",
                            "lastName": "Weston",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Weston"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1746841"
                        ],
                        "name": "Nicolas Usunier",
                        "slug": "Nicolas-Usunier",
                        "structuredName": {
                            "firstName": "Nicolas",
                            "lastName": "Usunier",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nicolas Usunier"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 238,
                                "start": 218
                            }
                        ],
                        "text": "\u2026entity (even when there are a set of correct answers), comparing to recently published systems.3 The upper part of Table 1 indicates that our approach outperforms (Yao and Van Durme, 2014), (Berant et al., 2013) and (Bordes et al., 2014b), and performs similarly as (Berant and Liang, 2014)."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 161,
                                "start": 141
                            }
                        ],
                        "text": "The main contributions of the paper are: (1) a more sophisticated inference procedure that is both efficient and can consider longer paths ((Bordes et al., 2014b) considered only answers directly connected to the\n615\nquestion in the graph); and (2) a richer representation of the answers which\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 50,
                                "start": 30
                            }
                        ],
                        "text": "3Results of baselines except (Bordes et al., 2014b) have been extracted from the original papers."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 87,
                                "start": 67
                            }
                        ],
                        "text": "Finally, we demonstrate that we greatly improve upon the model of (Bordes et al., 2014b), which actually corresponds to a setting with the Path representation and C1 as candidate set."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 34,
                                "start": 12
                            }
                        ],
                        "text": ", 2013) and (Bordes et al., 2014b), and performs similarly as (Berant and Liang, 2014)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 60,
                                "start": 40
                            }
                        ],
                        "text": "In this paper, we improve the model of (Bordes et al., 2014b) by providing the ability to answer more complicated questions."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 22,
                                "start": 0
                            }
                        ],
                        "text": "(Bordes et al., 2014b) introduced an embedding model, which learns lowdimensional vector representations of words and symbols (such as KBs constituents) and can be trained with even less supervision than the system of (Fader et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 34,
                                "start": 12
                            }
                        ],
                        "text": "Inspired by (Bordes et al., 2014b), our model works by learning low-dimensional vector embed-"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 21,
                                "start": 1
                            }
                        ],
                        "text": "(Bordes et al., 2014b) introduced an embedding model, which learns lowdimensional vector representations of words and symbols (such as KBs constituents) and can be trained with even less supervision than the system of (Fader et al., 2013) while being able to achieve better prediction performance."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 91,
                                "start": 71
                            }
                        ],
                        "text": "More examples and details are given in a longer version of this paper (Bordes et al., 2014a)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 162,
                                "start": 140
                            }
                        ],
                        "text": "The main contributions of the paper are: (1) a more sophisticated inference procedure that is both efficient and can consider longer paths ((Bordes et al., 2014b) considered only answers directly connected to the"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 50,
                                "start": 28
                            }
                        ],
                        "text": "Results of baselines except (Bordes et al., 2014b) have been extracted from the original papers."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 33,
                                "start": 13
                            }
                        ],
                        "text": "Inspired by (Bordes et al., 2014b), our model works by learning low-dimensional vector embeddings of words appearing in questions and of entities and relation types of FREEBASE, so that representations of questions and of their corresponding answers are close to each other in the joint embedding\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1849689,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a584211768d49f80192f13b8ed2fda9c058dec34",
            "isKey": false,
            "numCitedBy": 294,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "Building computers able to answer questions on any subject is a long standing goal of artificial intelligence. Promising progress has recently been achieved by methods that learn to map questions to logical forms or database queries. Such approaches can be effective but at the cost of either large amounts of human-labeled data or by defining lexicons and grammars tailored by practitioners. In this paper, we instead take the radical approach of learning to map questions to vectorial feature representations. By mapping answers into the same space one can query any knowledge base independent of its schema, without requiring any grammar or lexicon. Our method is trained with a new optimization procedure combining stochastic gradient descent followed by a fine-tuning step using the weak supervision provided by blending automatically and collaboratively generated resources. We empirically demonstrate that our model can capture meaningful signals from its noisy supervision leading to major improvements over paralex, the only existing method able to be trained on similar weakly labeled data."
            },
            "slug": "Open-Question-Answering-with-Weakly-Supervised-Bordes-Weston",
            "title": {
                "fragments": [],
                "text": "Open Question Answering with Weakly Supervised Embedding Models"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This paper empirically demonstrate that the model can capture meaningful signals from its noisy supervision leading to major improvements over paralex, the only existing method able to be trained on similar weakly labeled data."
            },
            "venue": {
                "fragments": [],
                "text": "ECML/PKDD"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38087946"
                        ],
                        "name": "Anthony Fader",
                        "slug": "Anthony-Fader",
                        "structuredName": {
                            "firstName": "Anthony",
                            "lastName": "Fader",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Anthony Fader"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1982950"
                        ],
                        "name": "Luke Zettlemoyer",
                        "slug": "Luke-Zettlemoyer",
                        "structuredName": {
                            "firstName": "Luke",
                            "lastName": "Zettlemoyer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Luke Zettlemoyer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1741101"
                        ],
                        "name": "Oren Etzioni",
                        "slug": "Oren-Etzioni",
                        "structuredName": {
                            "firstName": "Oren",
                            "lastName": "Etzioni",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Oren Etzioni"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 118,
                                "start": 100
                            }
                        ],
                        "text": "Interestingly, recent works (Berant et al., 2013; Kwiatkowski et al., 2013; Berant and Liang, 2014; Fader et al., 2014) have shown that such systems can be efficiently trained under indirect and imperfect supervision and hence scale to large-scale regimes, while bypassing most of the annotation\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 119,
                                "start": 28
                            }
                        ],
                        "text": "Interestingly, recent works (Berant et al., 2013; Kwiatkowski et al., 2013; Berant and Liang, 2014; Fader et al., 2014) have shown that such systems can be efficiently trained under indirect and imperfect su-"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 207214527,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f86ec155cce6259e5230aaad3b762343757feb1d",
            "isKey": false,
            "numCitedBy": 379,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "We consider the problem of open-domain question answering (Open QA) over massive knowledge bases (KBs). Existing approaches use either manually curated KBs like Freebase or KBs automatically extracted from unstructured text. In this paper, we present OQA, the first approach to leverage both curated and extracted KBs. A key technical challenge is designing systems that are robust to the high variability in both natural language questions and massive KBs. OQA achieves robustness by decomposing the full Open QA problem into smaller sub-problems including question paraphrasing and query reformulation. OQA solves these sub-problems by mining millions of rules from an unlabeled question corpus and across multiple KBs. OQA then learns to integrate these rules by performing discriminative training on question-answer pairs using a latent-variable structured perceptron algorithm. We evaluate OQA on three benchmark question sets and demonstrate that it achieves up to twice the precision and recall of a state-of-the-art Open QA system."
            },
            "slug": "Open-question-answering-over-curated-and-extracted-Fader-Zettlemoyer",
            "title": {
                "fragments": [],
                "text": "Open question answering over curated and extracted knowledge bases"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This paper presents OQA, the first approach to leverage both curated and extracted KBs, and demonstrates that it achieves up to twice the precision and recall of a state-of-the-art Open QA system."
            },
            "venue": {
                "fragments": [],
                "text": "KDD"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1750652"
                        ],
                        "name": "Jonathan Berant",
                        "slug": "Jonathan-Berant",
                        "structuredName": {
                            "firstName": "Jonathan",
                            "lastName": "Berant",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jonathan Berant"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2059149862"
                        ],
                        "name": "A. Chou",
                        "slug": "A.-Chou",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Chou",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Chou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34765463"
                        ],
                        "name": "Roy Frostig",
                        "slug": "Roy-Frostig",
                        "structuredName": {
                            "firstName": "Roy",
                            "lastName": "Frostig",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Roy Frostig"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145419642"
                        ],
                        "name": "Percy Liang",
                        "slug": "Percy-Liang",
                        "structuredName": {
                            "firstName": "Percy",
                            "lastName": "Liang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Percy Liang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 211,
                                "start": 192
                            }
                        ],
                        "text": "\u2026entity (even when there are a set of correct answers), comparing to recently published systems.3 The upper part of Table 1 indicates that our approach outperforms (Yao and Van Durme, 2014), (Berant et al., 2013) and (Bordes et al., 2014b), and performs similarly as (Berant and Liang, 2014)."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 118,
                                "start": 99
                            }
                        ],
                        "text": "Our approach is competitive with the current stateof-the-art on the recent benchmark WEBQUESTIONS (Berant et al., 2013) without using any lexicon, rules or additional system for part-of-speech tagging, syntactic or dependency parsing during training as most other systems do."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 31,
                                "start": 10
                            }
                        ],
                        "text": "Following (Berant et al., 2013), we also created questions using CLUEWEB extractions provided by (Lin et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 50,
                                "start": 29
                            }
                        ],
                        "text": "(%) (Berant) (Yao) Baselines (Berant et al., 2013) \u2013 31."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 30,
                                "start": 11
                            }
                        ],
                        "text": "Following (Berant et al., 2013), we also created questions using CLUEWEB extractions provided by (Lin et al., 2012)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 116,
                                "start": 95
                            }
                        ],
                        "text": "3 The upper part of Table 1 indicates that our approach outperforms (Yao and Van Durme, 2014), (Berant et al., 2013) and (Bordes et al."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 119,
                                "start": 28
                            }
                        ],
                        "text": "Interestingly, recent works (Berant et al., 2013; Kwiatkowski et al., 2013; Berant and Liang, 2014; Fader et al., 2014) have shown that such systems can be efficiently trained under indirect and imperfect su-"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 40,
                                "start": 21
                            }
                        ],
                        "text": "We use WEBQUESTIONS (Berant et al., 2013) as our evaluation bemchmark."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 48,
                                "start": 29
                            }
                        ],
                        "text": "Interestingly, recent works (Berant et al., 2013; Kwiatkowski et al., 2013; Berant and Liang, 2014; Fader et al., 2014) have shown that such systems can be efficiently trained under indirect and imperfect supervision and hence scale to large-scale regimes, while bypassing most of the annotation\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6401679,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b29447ba499507a259ae9d8f685d60cc1597d7d3",
            "isKey": true,
            "numCitedBy": 1337,
            "numCiting": 46,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we train a semantic parser that scales up to Freebase. Instead of relying on annotated logical forms, which is especially expensive to obtain at large scale, we learn from question-answer pairs. The main challenge in this setting is narrowing down the huge number of possible logical predicates for a given question. We tackle this problem in two ways: First, we build a coarse mapping from phrases to predicates using a knowledge base and a large text corpus. Second, we use a bridging operation to generate additional predicates based on neighboring predicates. On the dataset of Cai and Yates (2013), despite not having annotated logical forms, our system outperforms their state-of-the-art parser. Additionally, we collected a more realistic and challenging dataset of question-answer pairs and improves over a natural baseline."
            },
            "slug": "Semantic-Parsing-on-Freebase-from-Question-Answer-Berant-Chou",
            "title": {
                "fragments": [],
                "text": "Semantic Parsing on Freebase from Question-Answer Pairs"
            },
            "tldr": {
                "abstractSimilarityScore": 61,
                "text": "This paper trains a semantic parser that scales up to Freebase and outperforms their state-of-the-art parser on the dataset of Cai and Yates (2013), despite not having annotated logical forms."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3242104"
                        ],
                        "name": "O. Kolomiyets",
                        "slug": "O.-Kolomiyets",
                        "structuredName": {
                            "firstName": "Oleksandr",
                            "lastName": "Kolomiyets",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Kolomiyets"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145446752"
                        ],
                        "name": "Marie-Francine Moens",
                        "slug": "Marie-Francine-Moens",
                        "structuredName": {
                            "firstName": "Marie-Francine",
                            "lastName": "Moens",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Marie-Francine Moens"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 318,
                                "start": 245
                            }
                        ],
                        "text": "Information retrieval systems first retrieve a broad set of candidate answers by querying the search API of KBs with a transformation of the question into a valid query and then use fine-grained detection heuristics to identify the exact answer (Kolomiyets and Moens, 2011; Unger et al., 2012; Yao and Van Durme, 2014)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 31237456,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d11923075c47f8fd2cee47b8d6ae2ad0e7c966e8",
            "isKey": false,
            "numCitedBy": 211,
            "numCiting": 193,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-survey-on-question-answering-technology-from-an-Kolomiyets-Moens",
            "title": {
                "fragments": [],
                "text": "A survey on question answering technology from an information retrieval perspective"
            },
            "venue": {
                "fragments": [],
                "text": "Inf. Sci."
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1750652"
                        ],
                        "name": "Jonathan Berant",
                        "slug": "Jonathan-Berant",
                        "structuredName": {
                            "firstName": "Jonathan",
                            "lastName": "Berant",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jonathan Berant"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145419642"
                        ],
                        "name": "Percy Liang",
                        "slug": "Percy-Liang",
                        "structuredName": {
                            "firstName": "Percy",
                            "lastName": "Liang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Percy Liang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 83,
                                "start": 59
                            }
                        ],
                        "text": "We also considered an ensemble of our approach and that of (Berant and Liang, 2014)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 60,
                                "start": 36
                            }
                        ],
                        "text": ", 2014b), and performs similarly as (Berant and Liang, 2014)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 119,
                                "start": 28
                            }
                        ],
                        "text": "Interestingly, recent works (Berant et al., 2013; Kwiatkowski et al., 2013; Berant and Liang, 2014; Fader et al., 2014) have shown that such systems can be efficiently trained under indirect and imperfect su-"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 183,
                                "start": 159
                            }
                        ],
                        "text": "We chose a threshold such that our approach predicts 50% of the time (when S(q, a) is above its value), and the other 50% of the time we use the prediction of (Berant and Liang, 2014) instead."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 59,
                                "start": 35
                            }
                        ],
                        "text": "These are similar to those used in (Berant and Liang, 2014)."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                }
            ],
            "corpusId": 1336493,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3d1d42c9435b419ac928ebf7bcf4c86a460d6ef4",
            "isKey": true,
            "numCitedBy": 479,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": "A central challenge in semantic parsing is handling the myriad ways in which knowledge base predicates can be expressed. Traditionally, semantic parsers are trained primarily from text paired with knowledge base information. Our goal is to exploit the much larger amounts of raw text not tied to any knowledge base. In this paper, we turn semantic parsing on its head. Given an input utterance, we first use a simple method to deterministically generate a set of candidate logical forms with a canonical realization in natural language for each. Then, we use a paraphrase model to choose the realization that best paraphrases the input, and output the corresponding logical form. We present two simple paraphrase models, an association model and a vector space model, and train them jointly from question-answer pairs. Our system PARASEMPRE improves stateof-the-art accuracies on two recently released question-answering datasets."
            },
            "slug": "Semantic-Parsing-via-Paraphrasing-Berant-Liang",
            "title": {
                "fragments": [],
                "text": "Semantic Parsing via Paraphrasing"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This paper presents two simple paraphrase models, an association model and a vector space model, and trains them jointly from question-answer pairs, improving state-of-the-art accuracies on two recently released question-answering datasets."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1711387"
                        ],
                        "name": "Christina Unger",
                        "slug": "Christina-Unger",
                        "structuredName": {
                            "firstName": "Christina",
                            "lastName": "Unger",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christina Unger"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2625507"
                        ],
                        "name": "Lorenz B\u00fchmann",
                        "slug": "Lorenz-B\u00fchmann",
                        "structuredName": {
                            "firstName": "Lorenz",
                            "lastName": "B\u00fchmann",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lorenz B\u00fchmann"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144568027"
                        ],
                        "name": "Jens Lehmann",
                        "slug": "Jens-Lehmann",
                        "structuredName": {
                            "firstName": "Jens",
                            "lastName": "Lehmann",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jens Lehmann"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712107"
                        ],
                        "name": "A. N. Ngomo",
                        "slug": "A.-N.-Ngomo",
                        "structuredName": {
                            "firstName": "Axel-Cyrille",
                            "lastName": "Ngomo",
                            "middleNames": [
                                "Ngonga"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. N. Ngomo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49786121"
                        ],
                        "name": "D. Gerber",
                        "slug": "D.-Gerber",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Gerber",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Gerber"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1748977"
                        ],
                        "name": "P. Cimiano",
                        "slug": "P.-Cimiano",
                        "structuredName": {
                            "firstName": "Philipp",
                            "lastName": "Cimiano",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Cimiano"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 271,
                                "start": 253
                            }
                        ],
                        "text": "\u2026systems first retrieve a broad set of candidate answers by querying the search API of KBs with a transformation of the question into a valid query and then use fine-grained detection heuristics to identify the exact answer (Kolomiyets and Moens, 2011; Unger et al., 2012;\nYao and Van Durme, 2014)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 318,
                                "start": 245
                            }
                        ],
                        "text": "Information retrieval systems first retrieve a broad set of candidate answers by querying the search API of KBs with a transformation of the question into a valid query and then use fine-grained detection heuristics to identify the exact answer (Kolomiyets and Moens, 2011; Unger et al., 2012; Yao and Van Durme, 2014)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6638292,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "eb04bd49bdc2c9218624435eb277be2a973b21a5",
            "isKey": false,
            "numCitedBy": 474,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "As an increasing amount of RDF data is published as Linked Data, intuitive ways of accessing this data become more and more important. Question answering approaches have been proposed as a good compromise between intuitiveness and expressivity. Most question answering systems translate questions into triples which are matched against the RDF data to retrieve an answer, typically relying on some similarity metric. However, in many cases, triples do not represent a faithful representation of the semantic structure of the natural language question, with the result that more expressive queries can not be answered. To circumvent this problem, we present a novel approach that relies on a parse of the question to produce a SPARQL template that directly mirrors the internal structure of the question. This template is then instantiated using statistical entity identification and predicate detection. We show that this approach is competitive and discuss cases of questions that can be answered with our approach but not with competing approaches."
            },
            "slug": "Template-based-question-answering-over-RDF-data-Unger-B\u00fchmann",
            "title": {
                "fragments": [],
                "text": "Template-based question answering over RDF data"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A novel approach that relies on a parse of the question to produce a SPARQL template that directly mirrors the internal structure of theQuestion answering system, which is then instantiated using statistical entity identification and predicate detection."
            },
            "venue": {
                "fragments": [],
                "text": "WWW"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "15652489"
                        ],
                        "name": "T. Kwiatkowski",
                        "slug": "T.-Kwiatkowski",
                        "structuredName": {
                            "firstName": "Tom",
                            "lastName": "Kwiatkowski",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kwiatkowski"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2890423"
                        ],
                        "name": "Eunsol Choi",
                        "slug": "Eunsol-Choi",
                        "structuredName": {
                            "firstName": "Eunsol",
                            "lastName": "Choi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Eunsol Choi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3167681"
                        ],
                        "name": "Yoav Artzi",
                        "slug": "Yoav-Artzi",
                        "structuredName": {
                            "firstName": "Yoav",
                            "lastName": "Artzi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoav Artzi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1982950"
                        ],
                        "name": "Luke Zettlemoyer",
                        "slug": "Luke-Zettlemoyer",
                        "structuredName": {
                            "firstName": "Luke",
                            "lastName": "Zettlemoyer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Luke Zettlemoyer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 74,
                                "start": 50
                            }
                        ],
                        "text": "Interestingly, recent works (Berant et al., 2013; Kwiatkowski et al., 2013; Berant and Liang, 2014; Fader et al., 2014) have shown that such systems can be efficiently trained under indirect and imperfect supervision and hence scale to large-scale regimes, while bypassing most of the annotation\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 119,
                                "start": 28
                            }
                        ],
                        "text": "Interestingly, recent works (Berant et al., 2013; Kwiatkowski et al., 2013; Berant and Liang, 2014; Fader et al., 2014) have shown that such systems can be efficiently trained under indirect and imperfect su-"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14341841,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b2ac51e10a3510eadac5eac5e4fb828f086fab88",
            "isKey": false,
            "numCitedBy": 317,
            "numCiting": 41,
            "paperAbstract": {
                "fragments": [],
                "text": "We consider the challenge of learning semantic parsers that scale to large, open-domain problems, such as question answering with Freebase. In such settings, the sentences cover a wide variety of topics and include many phrases whose meaning is difficult to represent in a fixed target ontology. For example, even simple phrases such as \u2018daughter\u2019 and \u2018number of people living in\u2019 cannot be directly represented in Freebase, whose ontology instead encodes facts about gender, parenthood, and population. In this paper, we introduce a new semantic parsing approach that learns to resolve such ontological mismatches. The parser is learned from question-answer pairs, uses a probabilistic CCG to build linguistically motivated logicalform meaning representations, and includes an ontology matching model that adapts the output logical forms for each target ontology. Experiments demonstrate state-of-the-art performance on two benchmark semantic parsing datasets, including a nine point accuracy improvement on a recent Freebase QA corpus."
            },
            "slug": "Scaling-Semantic-Parsers-with-On-the-Fly-Ontology-Kwiatkowski-Choi",
            "title": {
                "fragments": [],
                "text": "Scaling Semantic Parsers with On-the-Fly Ontology Matching"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "A new semantic parsing approach that learns to resolve ontological mismatches, which is learned from question-answer pairs, uses a probabilistic CCG to build linguistically motivated logicalform meaning representations, and includes an ontology matching model that adapts the output logical forms for each target ontology."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145183709"
                        ],
                        "name": "J. Weston",
                        "slug": "J.-Weston",
                        "structuredName": {
                            "firstName": "Jason",
                            "lastName": "Weston",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Weston"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751569"
                        ],
                        "name": "Samy Bengio",
                        "slug": "Samy-Bengio",
                        "structuredName": {
                            "firstName": "Samy",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Samy Bengio"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1746841"
                        ],
                        "name": "Nicolas Usunier",
                        "slug": "Nicolas-Usunier",
                        "structuredName": {
                            "firstName": "Nicolas",
                            "lastName": "Usunier",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nicolas Usunier"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 26,
                                "start": 7
                            }
                        ],
                        "text": "As in (Weston et al., 2010), we train our model using a margin-based ranking loss function."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 7587705,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "aea0f946e8dcddb65cc2e907456c42453f246a50",
            "isKey": false,
            "numCitedBy": 420,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "Image annotation datasets are becoming larger and larger, with tens of millions of images and tens of thousands of possible annotations. We propose a strongly performing method that scales to such datasets by simultaneously learning to optimize precision at k of the ranked list of annotations for a given image and learning a low-dimensional joint embedding space for both images and annotations. Our method both outperforms several baseline methods and, in comparison to them, is faster and consumes less memory. We also demonstrate how our method learns an interpretable model, where annotations with alternate spellings or even languages are close in the embedding space. Hence, even when our model does not predict the exact annotation given by a human labeler, it often predicts similar annotations, a fact that we try to quantify by measuring the newly introduced \u201csibling\u201d precision metric, where our method also obtains excellent results."
            },
            "slug": "Large-scale-image-annotation:-learning\u00a0to\u00a0rank-Weston-Bengio",
            "title": {
                "fragments": [],
                "text": "Large scale image annotation: learning\u00a0to\u00a0rank with\u00a0joint word-image embeddings"
            },
            "tldr": {
                "abstractSimilarityScore": 51,
                "text": "This work proposes a strongly performing method that scales to image annotation datasets by simultaneously learning to optimize precision at k of the ranked list of annotations for a given image and learning a low-dimensional joint embedding space for both images and annotations."
            },
            "venue": {
                "fragments": [],
                "text": "Machine Learning"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144739109"
                        ],
                        "name": "Thomas Lin",
                        "slug": "Thomas-Lin",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Lin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thomas Lin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2674444"
                        ],
                        "name": "Mausam",
                        "slug": "Mausam",
                        "structuredName": {
                            "firstName": "",
                            "lastName": "Mausam",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mausam"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1741101"
                        ],
                        "name": "Oren Etzioni",
                        "slug": "Oren-Etzioni",
                        "structuredName": {
                            "firstName": "Oren",
                            "lastName": "Etzioni",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Oren Etzioni"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 114,
                                "start": 98
                            }
                        ],
                        "text": "Following (Berant et al., 2013), we also created questions using CLUEWEB extractions provided by (Lin et al., 2012)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 91,
                                "start": 73
                            }
                        ],
                        "text": ", 2013), we also created questions using CLUEWEB extractions provided by (Lin et al., 2012)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 10824175,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c5c08e6dec3bf8a036607593e11e389697e03f45",
            "isKey": false,
            "numCitedBy": 116,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper investigates entity linking over millions of high-precision extractions from a corpus of 500 million Web documents, toward the goal of creating a useful knowledge base of general facts. This paper is the first to report on entity linking over this many extractions, and describes new opportunities (such as corpus-level features) and challenges we found when entity linking at Web scale. We present several techniques that we developed and also lessons that we learned. We envision a future where information extraction and entity linking are paired to automatically generate knowledge bases with billions of assertions over millions of linked entities."
            },
            "slug": "Entity-Linking-at-Web-Scale-Lin-Mausam",
            "title": {
                "fragments": [],
                "text": "Entity Linking at Web Scale"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "This paper is the first to report on entity linking over this many extractions, and describes new opportunities (such as corpus-level features) and challenges that are found when entity linking at Web scale."
            },
            "venue": {
                "fragments": [],
                "text": "AKBC-WEKEX@NAACL-HLT"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1742448"
                        ],
                        "name": "K. Bollacker",
                        "slug": "K.-Bollacker",
                        "structuredName": {
                            "firstName": "Kurt",
                            "lastName": "Bollacker",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Bollacker"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2065123479"
                        ],
                        "name": "Colin Evans",
                        "slug": "Colin-Evans",
                        "structuredName": {
                            "firstName": "Colin",
                            "lastName": "Evans",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Colin Evans"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2990264"
                        ],
                        "name": "Praveen K. Paritosh",
                        "slug": "Praveen-K.-Paritosh",
                        "structuredName": {
                            "firstName": "Praveen",
                            "lastName": "Paritosh",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Praveen K. Paritosh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1399112633"
                        ],
                        "name": "Tim Sturge",
                        "slug": "Tim-Sturge",
                        "structuredName": {
                            "firstName": "Tim",
                            "lastName": "Sturge",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tim Sturge"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2110748390"
                        ],
                        "name": "Jamie Taylor",
                        "slug": "Jamie-Taylor",
                        "structuredName": {
                            "firstName": "Jamie",
                            "lastName": "Taylor",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jamie Taylor"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 42,
                                "start": 18
                            }
                        ],
                        "text": "Freebase FREEBASE (Bollacker et al., 2008) is a huge and freely available database of general facts; data is organized as triplets (subject, type1."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 41,
                                "start": 19
                            }
                        ],
                        "text": "Freebase FREEBASE (Bollacker et al., 2008) is a huge and freely available database of general facts; data is organized as triplets (subject, type1.type2.predicate, object),\nwhere two entities subject and object (identified by mids) are connected by the relation type type1.type2.predicate."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 51,
                                "start": 29
                            }
                        ],
                        "text": "These KBs, such as FREEBASE (Bollacker et al., 2008) encompass huge ever growing amounts of information and ease open QA by organizing a great variety of answers in a structured format."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 207167677,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1976c9eeccc7115d18a04f1e7fb5145db6b96002",
            "isKey": true,
            "numCitedBy": 3826,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "Freebase is a practical, scalable tuple database used to structure general human knowledge. The data in Freebase is collaboratively created, structured, and maintained. Freebase currently contains more than 125,000,000 tuples, more than 4000 types, and more than 7000 properties. Public read/write access to Freebase is allowed through an HTTP-based graph-query API using the Metaweb Query Language (MQL) as a data query and manipulation language. MQL provides an easy-to-use object-oriented interface to the tuple data in Freebase and is designed to facilitate the creation of collaborative, Web-based data-oriented applications."
            },
            "slug": "Freebase:-a-collaboratively-created-graph-database-Bollacker-Evans",
            "title": {
                "fragments": [],
                "text": "Freebase: a collaboratively created graph database for structuring human knowledge"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "MQL provides an easy-to-use object-oriented interface to the tuple data in Freebase and is designed to facilitate the creation of collaborative, Web-based data-oriented applications."
            },
            "venue": {
                "fragments": [],
                "text": "SIGMOD Conference"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9229182"
                        ],
                        "name": "B. Recht",
                        "slug": "B.-Recht",
                        "structuredName": {
                            "firstName": "Benjamin",
                            "lastName": "Recht",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Recht"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1803218"
                        ],
                        "name": "Christopher R\u00e9",
                        "slug": "Christopher-R\u00e9",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "R\u00e9",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christopher R\u00e9"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144731788"
                        ],
                        "name": "Stephen J. Wright",
                        "slug": "Stephen-J.-Wright",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Wright",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Stephen J. Wright"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47657030"
                        ],
                        "name": "Feng Niu",
                        "slug": "Feng-Niu",
                        "structuredName": {
                            "firstName": "Feng",
                            "lastName": "Niu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Feng Niu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 113,
                                "start": 93
                            }
                        ],
                        "text": "Optimization is accomplished using stochastic gradient descent, multi-threaded with Hogwild! (Recht et al., 2011), with the constraint that the columns wi of W remain within the unit-ball, i."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 19,
                                "start": 1
                            }
                        ],
                        "text": "(Recht et al., 2011), with the constraint that the columns wi of W remain within the unit-ball, i.e., \u2200i, ||wi||2 \u2264 1."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 92,
                                "start": 84
                            }
                        ],
                        "text": "Optimization is accomplished using stochastic gradient descent, multi-threaded with Hogwild!"
                    },
                    "intents": []
                }
            ],
            "corpusId": 6108215,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "36f49b05d764bf5c10428b082c2d96c13c4203b9",
            "isKey": true,
            "numCitedBy": 2018,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "Stochastic Gradient Descent (SGD) is a popular algorithm that can achieve state-of-the-art performance on a variety of machine learning tasks. Several researchers have recently proposed schemes to parallelize SGD, but all require performance-destroying memory locking and synchronization. This work aims to show using novel theoretical analysis, algorithms, and implementation that SGD can be implemented without any locking. We present an update scheme called HOGWILD! which allows processors access to shared memory with the possibility of overwriting each other's work. We show that when the associated optimization problem is sparse, meaning most gradient updates only modify small parts of the decision variable, then HOGWILD! achieves a nearly optimal rate of convergence. We demonstrate experimentally that HOGWILD! outperforms alternative schemes that use locking by an order of magnitude."
            },
            "slug": "Hogwild:-A-Lock-Free-Approach-to-Parallelizing-Recht-R\u00e9",
            "title": {
                "fragments": [],
                "text": "Hogwild: A Lock-Free Approach to Parallelizing Stochastic Gradient Descent"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This work aims to show using novel theoretical analysis, algorithms, and implementation that SGD can be implemented without any locking, and presents an update scheme called HOGWILD! which allows processors access to shared memory with the possibility of overwriting each other's work."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2011
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 238,
                                "start": 218
                            }
                        ],
                        "text": "\u2026entity (even when there are a set of correct answers), comparing to recently published systems.3 The upper part of Table 1 indicates that our approach outperforms (Yao and Van Durme, 2014), (Berant et al., 2013) and (Bordes et al., 2014b), and performs similarly as (Berant and Liang, 2014)."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 161,
                                "start": 141
                            }
                        ],
                        "text": "The main contributions of the paper are: (1) a more sophisticated inference procedure that is both efficient and can consider longer paths ((Bordes et al., 2014b) considered only answers directly connected to the\n615\nquestion in the graph); and (2) a richer representation of the answers which\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 50,
                                "start": 30
                            }
                        ],
                        "text": "3Results of baselines except (Bordes et al., 2014b) have been extracted from the original papers."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 87,
                                "start": 67
                            }
                        ],
                        "text": "Finally, we demonstrate that we greatly improve upon the model of (Bordes et al., 2014b), which actually corresponds to a setting with the Path representation and C1 as candidate set."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 60,
                                "start": 40
                            }
                        ],
                        "text": "In this paper, we improve the model of (Bordes et al., 2014b) by providing the ability to answer more complicated questions."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 21,
                                "start": 1
                            }
                        ],
                        "text": "(Bordes et al., 2014b) introduced an embedding model, which learns lowdimensional vector representations of words and symbols (such as KBs constituents) and can be trained with even less supervision than the system of (Fader et al., 2013) while being able to achieve better prediction performance."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 91,
                                "start": 71
                            }
                        ],
                        "text": "More examples and details are given in a longer version of this paper (Bordes et al., 2014a)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 40,
                                "start": 20
                            }
                        ],
                        "text": "We used a subset, created by only keeping triples where one of the entities was appearing in either the WEBQUESTIONS training/validation set or in CLUEWEB extractions."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 33,
                                "start": 13
                            }
                        ],
                        "text": "Inspired by (Bordes et al., 2014b), our model works by learning low-dimensional vector embeddings of words appearing in questions and of entities and relation types of FREEBASE, so that representations of questions and of their corresponding answers are close to each other in the joint embedding\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Question answering with subgraph embeddings . CoRR, abs/1406"
            },
            "venue": {
                "fragments": [],
                "text": "Question answering with subgraph embeddings . CoRR, abs/1406"
            },
            "year": 2014
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 238,
                                "start": 218
                            }
                        ],
                        "text": "\u2026entity (even when there are a set of correct answers), comparing to recently published systems.3 The upper part of Table 1 indicates that our approach outperforms (Yao and Van Durme, 2014), (Berant et al., 2013) and (Bordes et al., 2014b), and performs similarly as (Berant and Liang, 2014)."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 161,
                                "start": 141
                            }
                        ],
                        "text": "The main contributions of the paper are: (1) a more sophisticated inference procedure that is both efficient and can consider longer paths ((Bordes et al., 2014b) considered only answers directly connected to the\n615\nquestion in the graph); and (2) a richer representation of the answers which\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 50,
                                "start": 30
                            }
                        ],
                        "text": "3Results of baselines except (Bordes et al., 2014b) have been extracted from the original papers."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 87,
                                "start": 67
                            }
                        ],
                        "text": "Finally, we demonstrate that we greatly improve upon the model of (Bordes et al., 2014b), which actually corresponds to a setting with the Path representation and C1 as candidate set."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 60,
                                "start": 40
                            }
                        ],
                        "text": "In this paper, we improve the model of (Bordes et al., 2014b) by providing the ability to answer more complicated questions."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 21,
                                "start": 1
                            }
                        ],
                        "text": "(Bordes et al., 2014b) introduced an embedding model, which learns lowdimensional vector representations of words and symbols (such as KBs constituents) and can be trained with even less supervision than the system of (Fader et al., 2013) while being able to achieve better prediction performance."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 91,
                                "start": 71
                            }
                        ],
                        "text": "More examples and details are given in a longer version of this paper (Bordes et al., 2014a)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 33,
                                "start": 13
                            }
                        ],
                        "text": "Inspired by (Bordes et al., 2014b), our model works by learning low-dimensional vector embeddings of words appearing in questions and of entities and relation types of FREEBASE, so that representations of questions and of their corresponding answers are close to each other in the joint embedding\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Question answering with subgraph embeddings"
            },
            "venue": {
                "fragments": [],
                "text": "CoRR, abs/1406.3676."
            },
            "year": 2014
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A lock - free approach to paral - lelizing stochastic gradient descent"
            },
            "venue": {
                "fragments": [],
                "text": "Advances in Neural Information Processing Systems ( NIPS 24 ) ."
            },
            "year": 2011
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Scaling semantic parsers with onthefly ontology matching Entity linking at web scale"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2012
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "tion set: k was chosen among {64, 128, 256}, the learning rate on a log. scale between 10 \u22124 and 10 \u22121 and we used at most 100 paths in the subgraph representation"
            },
            "venue": {
                "fragments": [],
                "text": "tion set: k was chosen among {64, 128, 256}, the learning rate on a log. scale between 10 \u22124 and 10 \u22121 and we used at most 100 paths in the subgraph representation"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 83,
                                "start": 79
                            }
                        ],
                        "text": "Following [1], we also created questions using ClueWeb extractions provided by [10]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Entity linking at web scale. In Proceedings of the Joint Workshop on Automatic Knowledge Base Construction and Web-scale Knowledge Extraction, pages 84\u201388"
            },
            "venue": {
                "fragments": [],
                "text": "Association for Computational Linguistics,"
            },
            "year": 2012
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 12,
            "methodology": 9,
            "result": 5
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 19,
        "totalPages": 2
    },
    "page_url": "https://www.semanticscholar.org/paper/Question-Answering-with-Subgraph-Embeddings-Bordes-Chopra/33261d252218007147a71e40f8367ed152fa2fe0?sort=total-citations"
}