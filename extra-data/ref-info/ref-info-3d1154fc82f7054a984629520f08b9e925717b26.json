{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2148896777"
                        ],
                        "name": "Kai Wang",
                        "slug": "Kai-Wang",
                        "structuredName": {
                            "firstName": "Kai",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kai Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2490700"
                        ],
                        "name": "Boris Babenko",
                        "slug": "Boris-Babenko",
                        "structuredName": {
                            "firstName": "Boris",
                            "lastName": "Babenko",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Boris Babenko"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50172592"
                        ],
                        "name": "Serge J. Belongie",
                        "slug": "Serge-J.-Belongie",
                        "structuredName": {
                            "firstName": "Serge",
                            "lastName": "Belongie",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Serge J. Belongie"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14136313,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "32b8f58a038df83138435b12a499c8bf0de13811",
            "isKey": false,
            "numCitedBy": 909,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper focuses on the problem of word detection and recognition in natural images. The problem is significantly more challenging than reading text in scanned documents, and has only recently gained attention from the computer vision community. Sub-components of the problem, such as text detection and cropped image word recognition, have been studied in isolation [7, 4, 20]. However, what is unclear is how these recent approaches contribute to solving the end-to-end problem of word recognition. We fill this gap by constructing and evaluating two systems. The first, representing the de facto state-of-the-art, is a two stage pipeline consisting of text detection followed by a leading OCR engine. The second is a system rooted in generic object recognition, an extension of our previous work in [20]. We show that the latter approach achieves superior performance. While scene text recognition has generally been treated with highly domain-specific methods, our results demonstrate the suitability of applying generic computer vision methods. Adopting this approach opens the door for real world scene text recognition to benefit from the rapid advances that have been taking place in object recognition."
            },
            "slug": "End-to-end-scene-text-recognition-Wang-Babenko",
            "title": {
                "fragments": [],
                "text": "End-to-end scene text recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "While scene text recognition has generally been treated with highly domain-specific methods, the results demonstrate the suitability of applying generic computer vision methods."
            },
            "venue": {
                "fragments": [],
                "text": "2011 International Conference on Computer Vision"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2156632012"
                        ],
                        "name": "Tao Wang",
                        "slug": "Tao-Wang",
                        "structuredName": {
                            "firstName": "Tao",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tao Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "25629078"
                        ],
                        "name": "David J. Wu",
                        "slug": "David-J.-Wu",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Wu",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David J. Wu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144638694"
                        ],
                        "name": "Adam Coates",
                        "slug": "Adam-Coates",
                        "structuredName": {
                            "firstName": "Adam",
                            "lastName": "Coates",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Adam Coates"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34699434"
                        ],
                        "name": "A. Ng",
                        "slug": "A.-Ng",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Ng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Ng"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 212,
                                "start": 208
                            }
                        ],
                        "text": "Non-linear Niblack and proposed method show better performance for text recognition without lexicon than existing methods, and the performance when using a lexicon is quite close to the very recent result in [27]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 3126988,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "26cb14c9d22cf946314d685fe3541ef9f641e429",
            "isKey": false,
            "numCitedBy": 792,
            "numCiting": 49,
            "paperAbstract": {
                "fragments": [],
                "text": "Full end-to-end text recognition in natural images is a challenging problem that has received much attention recently. Traditional systems in this area have relied on elaborate models incorporating carefully hand-engineered features or large amounts of prior knowledge. In this paper, we take a different route and combine the representational power of large, multilayer neural networks together with recent developments in unsupervised feature learning, which allows us to use a common framework to train highly-accurate text detector and character recognizer modules. Then, using only simple off-the-shelf methods, we integrate these two modules into a full end-to-end, lexicon-driven, scene text recognition system that achieves state-of-the-art performance on standard benchmarks, namely Street View Text and ICDAR 2003."
            },
            "slug": "End-to-end-text-recognition-with-convolutional-Wang-Wu",
            "title": {
                "fragments": [],
                "text": "End-to-end text recognition with convolutional neural networks"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This paper combines the representational power of large, multilayer neural networks together with recent developments in unsupervised feature learning, which allows them to use a common framework to train highly-accurate text detector and character recognizer modules."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 21st International Conference on Pattern Recognition (ICPR2012)"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3058140"
                        ],
                        "name": "K. Ntirogiannis",
                        "slug": "K.-Ntirogiannis",
                        "structuredName": {
                            "firstName": "Konstantinos",
                            "lastName": "Ntirogiannis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Ntirogiannis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7232446"
                        ],
                        "name": "B. Gatos",
                        "slug": "B.-Gatos",
                        "structuredName": {
                            "firstName": "Basilios",
                            "lastName": "Gatos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Gatos"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1748249"
                        ],
                        "name": "I. Pratikakis",
                        "slug": "I.-Pratikakis",
                        "structuredName": {
                            "firstName": "Ioannis",
                            "lastName": "Pratikakis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Pratikakis"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 167,
                                "start": 164
                            }
                        ],
                        "text": "Perhaps surprisingly, such a simple approach has not been investigated in much detail, despite the fact that text binarization of scanned documents is well-studied [1]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 16009475,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f5cc141f0e90f8544c2cc16496e4b6adc4bd87b6",
            "isKey": false,
            "numCitedBy": 86,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "Evaluation of document image binarization techniques is a tedious task that is mainly performedby a human expert or by involving an OCR engine. This paper presents an objective evaluation methodology for document image binarization techniques that aims to reduce the human involvement in the ground truth construction and consecutive testing. A skeletonized ground truth image is produced by the user following a semi-automatic procedure. The estimated ground truth image can aid in evaluating the binarization result in terms of recall and precision as well as to further analyze the result by calculating broken and missing text, deformations and false alarms. A detailed description of the methodology along with a benchmarking of the six (6) most promising state-of-the-art binarization algorithms based on the proposed methodology is presented."
            },
            "slug": "An-Objective-Evaluation-Methodology-for-Document-Ntirogiannis-Gatos",
            "title": {
                "fragments": [],
                "text": "An Objective Evaluation Methodology for Document Image Binarization Techniques"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "An objective evaluation methodology that aims to reduce the human involvement in the ground truth construction and consecutive testing and a benchmarking of the six most promising state-of-the-art binarization algorithms based on the proposed methodology is presented."
            },
            "venue": {
                "fragments": [],
                "text": "2008 The Eighth IAPR International Workshop on Document Analysis Systems"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1704694"
                        ],
                        "name": "J. Sauvola",
                        "slug": "J.-Sauvola",
                        "structuredName": {
                            "firstName": "Jaakko",
                            "lastName": "Sauvola",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Sauvola"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145962204"
                        ],
                        "name": "M. Pietik\u00e4inen",
                        "slug": "M.-Pietik\u00e4inen",
                        "structuredName": {
                            "firstName": "Matti",
                            "lastName": "Pietik\u00e4inen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Pietik\u00e4inen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 119,
                                "start": 115
                            }
                        ],
                        "text": "We have included methods commonly used for document images, namely Otsu [8], Kittler [9], Niblack [11] and Sauvola [10]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 54,
                                "start": 47
                            }
                        ],
                        "text": "Gatos et al. [13] used two binarized images by Sauvola\u2019s method for original gray-scale and inverted images for rough estimation of background and thresholded the difference between original and binarized images."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 215,
                                "start": 211
                            }
                        ],
                        "text": "These methods can be roughly divided into two groups: the first group uses a fixed threshold for a given image (Otsu [8], Kittler [9]), while the second group (local binarization) uses local thresholds (Sauvola [10], Niblack [11])."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 30,
                                "start": 23
                            }
                        ],
                        "text": "The parameters for the Sauvola method were set as suggested in [22]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 97,
                                "start": 93
                            }
                        ],
                        "text": "The most popular methods for document image binarization like Otsu [8], Kittler [9], Sauvola [10] show significantly degraded performance on natural scenes."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 8543445,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "be97923dbcdaf8b1496b637ed156656d8874f552",
            "isKey": true,
            "numCitedBy": 2016,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Adaptive-document-image-binarization-Sauvola-Pietik\u00e4inen",
            "title": {
                "fragments": [],
                "text": "Adaptive document image binarization"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit."
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3061097"
                        ],
                        "name": "N. Ezaki",
                        "slug": "N.-Ezaki",
                        "structuredName": {
                            "firstName": "Nobuo",
                            "lastName": "Ezaki",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Ezaki"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1806816"
                        ],
                        "name": "M. Bulacu",
                        "slug": "M.-Bulacu",
                        "structuredName": {
                            "firstName": "Marius",
                            "lastName": "Bulacu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Bulacu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1799278"
                        ],
                        "name": "Lambert Schomaker",
                        "slug": "Lambert-Schomaker",
                        "structuredName": {
                            "firstName": "Lambert",
                            "lastName": "Schomaker",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lambert Schomaker"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 8,
                                "start": 4
                            }
                        ],
                        "text": "For [14], [13], [16], [7] we used parameters suggested by the authors."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 70,
                                "start": 66
                            }
                        ],
                        "text": "We have also included methods developed for natural images: Ezaki [14], Gatos [13], Minetto [16] and non-linear Niblack decomposition [7]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[14] proposed generating connected components by combination of mathematical morphology operations, edge extraction and Otsu thresholding of image color channels."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 5,
                                "start": 0
                            }
                        ],
                        "text": "Ezaki et al. [14] proposed generating connected components by combination of mathematical morphology operations, edge extraction and Otsu thresholding of image color channels."
                    },
                    "intents": []
                }
            ],
            "corpusId": 2561294,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "95e6599c7ac506446c4feefbf5a22841d24b08b0",
            "isKey": true,
            "numCitedBy": 217,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a system that reads the text encountered in natural scenes with the aim to provide assistance to the visually impaired persons. This paper describes the system design and evaluates several character extraction methods. Automatic text recognition from natural images receives a growing attention because of potential applications in image retrieval, robotics and intelligent transport system. Camera-based document analysis becomes a real possibility with the increasing resolution and availability of digital cameras. However, in the case of a blind person, finding the text region is the first important problem that must be addressed, because it cannot be assumed that the acquired image contains only characters. At first, our system tries to find in the image areas with small characters. Then it zooms into the found areas to retake higher resolution images necessary for character recognition. In the present paper, we propose four character-extraction methods based on connected components. We tested the effectiveness of our methods on the ICDAR 2003 Robust Reading Competition data. The performance of the different methods depends on character size. In the data, bigger characters are more prevalent and the most effective extraction method proves to be the sequence: Sobel edge detection, Otsu binarization, connected component extraction and rule-based connected component filtering."
            },
            "slug": "Text-detection-from-natural-scene-images:-towards-a-Ezaki-Bulacu",
            "title": {
                "fragments": [],
                "text": "Text detection from natural scene images: towards a system for visually impaired persons"
            },
            "tldr": {
                "abstractSimilarityScore": 76,
                "text": "A system that reads the text encountered in natural scenes with the aim to provide assistance to the visually impaired persons and evaluates several character extraction methods based on connected components."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 17th International Conference on Pattern Recognition, 2004. ICPR 2004."
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39719398"
                        ],
                        "name": "Anand Mishra",
                        "slug": "Anand-Mishra",
                        "structuredName": {
                            "firstName": "Anand",
                            "lastName": "Mishra",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Anand Mishra"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "72492981"
                        ],
                        "name": "Alahari Karteek",
                        "slug": "Alahari-Karteek",
                        "structuredName": {
                            "firstName": "Alahari",
                            "lastName": "Karteek",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alahari Karteek"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694502"
                        ],
                        "name": "C. Jawahar",
                        "slug": "C.-Jawahar",
                        "structuredName": {
                            "firstName": "C.",
                            "lastName": "Jawahar",
                            "middleNames": [
                                "V."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Jawahar"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 25,
                                "start": 22
                            }
                        ],
                        "text": "Several recent papers [2], [3] propose new methods for binarization of natural scene text in cropped word images assuming that text localization is done at the previous step of a pipeline (which, in practice, is highly non-trivial)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 3,
                                "start": 0
                            }
                        ],
                        "text": "[2] proposed a method for text binarization using iterated graph cut."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 22,
                                "start": 19
                            }
                        ],
                        "text": "Other recent works [2], [3] focus on the binarization of cropped text assuming that the text is correctly localized in the preceeding steps of the pipeline."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1175264,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7f57f38a4cfb97bf242c0acc720e9335cd9e7d0e",
            "isKey": false,
            "numCitedBy": 108,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "Inspired by the success of MRF models for solving object segmentation problems, we formulate the binarization problem in this framework. We represent the pixels in a document image as random variables in an MRF, and introduce a new energy (or cost) function on these variables. Each variable takes a foreground or background label, and the quality of the binarization (or labelling) is determined by the value of the energy function. We minimize the energy function, i.e. find the optimal binarization, using an iterative graph cut scheme. Our model is robust to variations in foreground and background colours as we use a Gaussian Mixture Model in the energy function. In addition, our algorithm is efficient to compute, and adapts to a variety of document images. We show results on word images from the challenging ICDAR 2003 dataset, and compare our performance with previously reported methods. Our approach shows significant improvement in pixel level accuracy as well as OCR accuracy."
            },
            "slug": "An-MRF-Model-for-Binarization-of-Natural-Scene-Text-Mishra-Karteek",
            "title": {
                "fragments": [],
                "text": "An MRF Model for Binarization of Natural Scene Text"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This work represents the pixels in a document image as random variables in an MRF, and introduces a new energy function on these variables to find the optimal binarization, using an iterative graph cut scheme."
            },
            "venue": {
                "fragments": [],
                "text": "2011 International Conference on Document Analysis and Recognition"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145532509"
                        ],
                        "name": "Luk\u00e1s Neumann",
                        "slug": "Luk\u00e1s-Neumann",
                        "structuredName": {
                            "firstName": "Luk\u00e1s",
                            "lastName": "Neumann",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Luk\u00e1s Neumann"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145564537"
                        ],
                        "name": "Jiri Matas",
                        "slug": "Jiri-Matas",
                        "structuredName": {
                            "firstName": "Jiri",
                            "lastName": "Matas",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jiri Matas"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 17,
                                "start": 0
                            }
                        ],
                        "text": "Neumann and Matas[28] 0.37 0.37 0.36 Proposed (no lexicon provided) 0.66 0.46 0.54 Proposed (fixed lexicon provided) 0.89 0.49 0.64"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 182,
                                "start": 178
                            }
                        ],
                        "text": "So finally we selected our method and performed experiments on the ICDAR 2011 dataset with the results presented in table III comparing to the recent result of Neumann and Matas [28] (to the best of our knowledge, this is the only published result for end-to-end text understanding on this dataset)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 55,
                                "start": 38
                            }
                        ],
                        "text": "Wang [25] (no lexicon) 0.54 0.30 0.38 Neumann and Matas (no lexicon) [26] 0.42 0.41 0.41 NL Niblack (no lexicon) 0.63 0.41 0.50 Multiscale NL Niblack (no lexicon) 0.62 0.43 0.50 Proposed (no lexicon) 0.66 0.48 0.55 Wang [25] (fixed lexicon) 0.45 0.54 0.51 Wang [27] (fixed lexicon) - - 0.67 NL Niblack (fixed lexicon) 0.85 0.44 0.58 Multiscale NL Niblack (fixed lexicon) 0.81 0.47 0.60 Proposed (fixed lexicon) 0.88 0.50 0.63 ICDAR 2011 dataset Method Prec."
                    },
                    "intents": []
                }
            ],
            "corpusId": 206591895,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d8b595c9e969e5605f62da51b6c16dad8aad3e0e",
            "isKey": true,
            "numCitedBy": 790,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "An end-to-end real-time scene text localization and recognition method is presented. The real-time performance is achieved by posing the character detection problem as an efficient sequential selection from the set of Extremal Regions (ERs). The ER detector is robust to blur, illumination, color and texture variation and handles low-contrast text. In the first classification stage, the probability of each ER being a character is estimated using novel features calculated with O(1) complexity per region tested. Only ERs with locally maximal probability are selected for the second stage, where the classification is improved using more computationally expensive features. A highly efficient exhaustive search with feedback loops is then applied to group ERs into words and to select the most probable character segmentation. Finally, text is recognized in an OCR stage trained using synthetic fonts. The method was evaluated on two public datasets. On the ICDAR 2011 dataset, the method achieves state-of-the-art text localization results amongst published methods and it is the first one to report results for end-to-end text recognition. On the more challenging Street View Text dataset, the method achieves state-of-the-art recall. The robustness of the proposed method against noise and low contrast of characters is demonstrated by \u201cfalse positives\u201d caused by detected watermark text in the dataset."
            },
            "slug": "Real-time-scene-text-localization-and-recognition-Neumann-Matas",
            "title": {
                "fragments": [],
                "text": "Real-time scene text localization and recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 58,
                "text": "The proposed end-to-end real-time scene text localization and recognition method achieves state-of-the-art text localization results amongst published methods and it is the first one to report results for end- to-end text recognition."
            },
            "venue": {
                "fragments": [],
                "text": "2012 IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1684042"
                        ],
                        "name": "A. Clavelli",
                        "slug": "A.-Clavelli",
                        "structuredName": {
                            "firstName": "Antonio",
                            "lastName": "Clavelli",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Clavelli"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694974"
                        ],
                        "name": "Dimosthenis Karatzas",
                        "slug": "Dimosthenis-Karatzas",
                        "structuredName": {
                            "firstName": "Dimosthenis",
                            "lastName": "Karatzas",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dimosthenis Karatzas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143826881"
                        ],
                        "name": "J. Llad\u00f3s",
                        "slug": "J.-Llad\u00f3s",
                        "structuredName": {
                            "firstName": "Josep",
                            "lastName": "Llad\u00f3s",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Llad\u00f3s"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 63,
                                "start": 59
                            }
                        ],
                        "text": "Therefore we also report morphological metrics proposed in [24]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 121,
                                "start": 117
                            }
                        ],
                        "text": "To evaluate the text binarization we compute the fraction of segments of each of the mentioned types as suggested in [24]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 15841280,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "71c7cb830ab8f8c93128760aac1bf12ee96d55eb",
            "isKey": false,
            "numCitedBy": 43,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "The availability of open, ground-truthed datasets and clear performance metrics is a crucial factor in the development of an application domain. The domain of colour text image analysis (real scenes, Web and spam images, scanned colour documents) has traditionally suffered from a lack of a comprehensive performance evaluation framework. Such a framework is extremely difficult to specify, and corresponding pixel-level accurate information tedious to define. In this paper we discuss the challenges and technical issues associated with developing such a framework. Then, we describe a complete framework for the evaluation of text extraction methods at multiple levels, provide a detailed ground-truth specification and present a case study on how this framework can be used in a real-life situation."
            },
            "slug": "A-framework-for-the-assessment-of-text-extraction-Clavelli-Karatzas",
            "title": {
                "fragments": [],
                "text": "A framework for the assessment of text extraction algorithms on complex colour images"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "A complete framework for the evaluation of text extraction methods at multiple levels is described, a detailed ground-truth specification is provided and a case study is presented on how this framework can be used in a real-life situation."
            },
            "venue": {
                "fragments": [],
                "text": "DAS '10"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144899680"
                        ],
                        "name": "Christian Wolf",
                        "slug": "Christian-Wolf",
                        "structuredName": {
                            "firstName": "Christian",
                            "lastName": "Wolf",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christian Wolf"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48471936"
                        ],
                        "name": "D. Doermann",
                        "slug": "D.-Doermann",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Doermann",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Doermann"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 88,
                                "start": 84
                            }
                        ],
                        "text": "We have also included several recent methods for document binarization, namely Wolf [19] 2, Howe [12], and Lu [20]3, the last one being a runner-up at ICDAR 2011 Document Image Binarization Contest (DIBCO 2011) [21]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 8165672,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "86452e55663b5b31f509d047dd8dae4ca124d912",
            "isKey": false,
            "numCitedBy": 80,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "Binarization techniques have been developed in the document analysis community for over 30 years and many algorithms have been used successfully. On the other hand, document analysis tasks are more and more frequently being applied to multimedia documents such as video sequences. Due to low resolution and lossy compression, the binarization of text included in the frames is a non-trivial task. Existing techniques work without a model of the spatial relationships in the image, which makes them less powerful. We introduce a new technique based on a Markov random field model of the document. The model parameters (clique potentials) are learned from training data and the binary image is estimated in a Bayesian framework. The performance is evaluated using commercial OCR software."
            },
            "slug": "Binarization-of-low-quality-text-using-a-Markov-Wolf-Doermann",
            "title": {
                "fragments": [],
                "text": "Binarization of low quality text using a Markov random field model"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A new technique based on a Markov random field model of the document and the model parameters (clique potentials) are learned from training data and the binary image is estimated in a Bayesian framework is introduced."
            },
            "venue": {
                "fragments": [],
                "text": "Object recognition supported by user interaction for service robots"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2113842186"
                        ],
                        "name": "Kaihua Zhu",
                        "slug": "Kaihua-Zhu",
                        "structuredName": {
                            "firstName": "Kaihua",
                            "lastName": "Zhu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kaihua Zhu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46534338"
                        ],
                        "name": "F. Qi",
                        "slug": "F.-Qi",
                        "structuredName": {
                            "firstName": "Feihu",
                            "lastName": "Qi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Qi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "29434033"
                        ],
                        "name": "R. Jiang",
                        "slug": "R.-Jiang",
                        "structuredName": {
                            "firstName": "Ren",
                            "lastName": "Jiang",
                            "middleNames": [
                                "Jie"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Jiang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2112318118"
                        ],
                        "name": "Li Xu",
                        "slug": "Li-Xu",
                        "structuredName": {
                            "firstName": "Li",
                            "lastName": "Xu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Li Xu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "37937365"
                        ],
                        "name": "M. Kimachi",
                        "slug": "M.-Kimachi",
                        "structuredName": {
                            "firstName": "Masatoshi",
                            "lastName": "Kimachi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Kimachi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2109035640"
                        ],
                        "name": "Yue Wu",
                        "slug": "Yue-Wu",
                        "structuredName": {
                            "firstName": "Yue",
                            "lastName": "Wu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yue Wu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2602120"
                        ],
                        "name": "Tomoyoshi Aizawa",
                        "slug": "Tomoyoshi-Aizawa",
                        "structuredName": {
                            "firstName": "Tomoyoshi",
                            "lastName": "Aizawa",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tomoyoshi Aizawa"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 25,
                                "start": 22
                            }
                        ],
                        "text": "For [14], [13], [16], [7] we used parameters suggested by the authors."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 137,
                                "start": 134
                            }
                        ],
                        "text": "We have also included methods developed for natural images: Ezaki [14], Gatos [13], Minetto [16] and non-linear Niblack decomposition [7]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 3,
                                "start": 0
                            }
                        ],
                        "text": "[7] suggested using the ordered statistics filter for estimating thresholds in the non-linear Nilblack decomposition."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 79,
                                "start": 76
                            }
                        ],
                        "text": "We find that even a standard binarization method such as non-linear Niblack [7] in combination with an off-the-shelf OCR module show performance competitive to fancier state-of-the-art text understanding methods."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 23151434,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ea694d3e24515df7bed5d9832fd3f502f79a5173",
            "isKey": true,
            "numCitedBy": 51,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a robust connected-component (CC) based method for automatic detection and segmentation of text in real-scene images. This technique can be applied in robot vision, sign recognition, meeting processing and video indexing. First, a non-linear Niblack method (NLNiblack) is proposed to decompose the image into candidate CCs. Then, we feed all these CCs into a cascade of classifiers trained by Adaboost algorithm. Each classifier in the cascade responds to one feature of the CC. We propose 12 novel features which are insensitive to noise, scale, text orientation and text language. The classifier cascade allows non-text CCs of the image to be quickly discarded while spending more computation on promising text-like CCs. The CCs passing through the cascade are considered as text components and are used to form the segmentation result. We have built a prototype system and the experimental results prove the effectiveness and efficiency of the proposed method."
            },
            "slug": "Using-Adaboost-to-Detect-and-Segment-Characters-Zhu-Qi",
            "title": {
                "fragments": [],
                "text": "Using Adaboost to Detect and Segment Characters from Natural Scenes"
            },
            "tldr": {
                "abstractSimilarityScore": 70,
                "text": "A robust connected-component (CC) based method for automatic detection and segmentation of text in real-scene images and 12 novel features which are insensitive to noise, scale, text orientation and text language are proposed."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2146721"
                        ],
                        "name": "C. Yao",
                        "slug": "C.-Yao",
                        "structuredName": {
                            "firstName": "Cong",
                            "lastName": "Yao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Yao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145905113"
                        ],
                        "name": "X. Bai",
                        "slug": "X.-Bai",
                        "structuredName": {
                            "firstName": "Xiang",
                            "lastName": "Bai",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "X. Bai"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1743698"
                        ],
                        "name": "Wenyu Liu",
                        "slug": "Wenyu-Liu",
                        "structuredName": {
                            "firstName": "Wenyu",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wenyu Liu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2146275501"
                        ],
                        "name": "Yi Ma",
                        "slug": "Yi-Ma",
                        "structuredName": {
                            "firstName": "Yi",
                            "lastName": "Ma",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yi Ma"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144035504"
                        ],
                        "name": "Z. Tu",
                        "slug": "Z.-Tu",
                        "structuredName": {
                            "firstName": "Zhuowen",
                            "lastName": "Tu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Z. Tu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 110,
                                "start": 107
                            }
                        ],
                        "text": "Image binarization has been also used as a part of different text detection and recognition pipelines [4], [5], [6]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14015069,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "955028d46ab7237a30cfaab3a351c34f38ee0be5",
            "isKey": false,
            "numCitedBy": 635,
            "numCiting": 82,
            "paperAbstract": {
                "fragments": [],
                "text": "With the increasing popularity of practical vision systems and smart phones, text detection in natural scenes becomes a critical yet challenging task. Most existing methods have focused on detecting horizontal or near-horizontal texts. In this paper, we propose a system which detects texts of arbitrary orientations in natural images. Our algorithm is equipped with a two-level classification scheme and two sets of features specially designed for capturing both the intrinsic characteristics of texts. To better evaluate our algorithm and compare it with other competing algorithms, we generate a new dataset, which includes various texts in diverse real-world scenarios; we also propose a protocol for performance evaluation. Experiments on benchmark datasets and the proposed dataset demonstrate that our algorithm compares favorably with the state-of-the-art algorithms when handling horizontal texts and achieves significantly enhanced performance on texts of arbitrary orientations in complex natural scenes."
            },
            "slug": "Detecting-texts-of-arbitrary-orientations-in-images-Yao-Bai",
            "title": {
                "fragments": [],
                "text": "Detecting texts of arbitrary orientations in natural images"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A system which detects texts of arbitrary orientations in natural images using a two-level classification scheme and two sets of features specially designed for capturing both the intrinsic characteristics of texts to better evaluate its algorithm and compare it with other competing algorithms."
            },
            "venue": {
                "fragments": [],
                "text": "2012 IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1771189"
                        ],
                        "name": "Shijian Lu",
                        "slug": "Shijian-Lu",
                        "structuredName": {
                            "firstName": "Shijian",
                            "lastName": "Lu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shijian Lu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1795547"
                        ],
                        "name": "Bolan Su",
                        "slug": "Bolan-Su",
                        "structuredName": {
                            "firstName": "Bolan",
                            "lastName": "Su",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bolan Su"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1679749"
                        ],
                        "name": "C. Tan",
                        "slug": "C.-Tan",
                        "structuredName": {
                            "firstName": "Chew",
                            "lastName": "Tan",
                            "middleNames": [
                                "Lim"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Tan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 114,
                                "start": 110
                            }
                        ],
                        "text": "We have also included several recent methods for document binarization, namely Wolf [19] 2, Howe [12], and Lu [20]3, the last one being a runner-up at ICDAR 2011 Document Image Binarization Contest (DIBCO 2011) [21]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[20] showed low performance compared to other methods thus highlighting the gap between the text binarization in scanned document images and natural scene images."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                }
            ],
            "corpusId": 13357550,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7e7f3f3a3c7a498d44acaf3aca22b6e529ee44bb",
            "isKey": false,
            "numCitedBy": 266,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "Document images often suffer from different types of degradation that renders the document image binarization a challenging task. This paper presents a document image binarization technique that segments the text from badly degraded document images accurately. The proposed technique is based on the observations that the text documents usually have a document background of the uniform color and texture and the document text within it has a different intensity level compared with the surrounding document background. Given a document image, the proposed technique first estimates a document background surface through an iterative polynomial smoothing procedure. Different types of document degradation are then compensated by using the estimated document background surface. The text stroke edge is further detected from the compensated document image by using L1-norm image gradient. Finally, the document text is segmented by a local threshold that is estimated based on the detected text stroke edges. The proposed technique was submitted to the recent document image binarization contest (DIBCO) held under the framework of ICDAR 2009 and has achieved the top performance among 43 algorithms that are submitted from 35 international research groups."
            },
            "slug": "Document-image-binarization-using-background-and-Lu-Su",
            "title": {
                "fragments": [],
                "text": "Document image binarization using background estimation and stroke edges"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "The proposed technique was submitted to the recent document image binarization contest (DIBCO) held under the framework of ICDAR 2009 and has achieved the top performance among 43 algorithms that are submitted from 35 international research groups."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal on Document Analysis and Recognition (IJDAR)"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34555868"
                        ],
                        "name": "Takafumi Yamazoe",
                        "slug": "Takafumi-Yamazoe",
                        "structuredName": {
                            "firstName": "Takafumi",
                            "lastName": "Yamazoe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Takafumi Yamazoe"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8268643"
                        ],
                        "name": "M. Etoh",
                        "slug": "M.-Etoh",
                        "structuredName": {
                            "firstName": "Minoru",
                            "lastName": "Etoh",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Etoh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2057829060"
                        ],
                        "name": "Takeshi Yoshimura",
                        "slug": "Takeshi-Yoshimura",
                        "structuredName": {
                            "firstName": "Takeshi",
                            "lastName": "Yoshimura",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Takeshi Yoshimura"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "30227952"
                        ],
                        "name": "Kousuke Tsujino",
                        "slug": "Kousuke-Tsujino",
                        "structuredName": {
                            "firstName": "Kousuke",
                            "lastName": "Tsujino",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kousuke Tsujino"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 3,
                                "start": 0
                            }
                        ],
                        "text": "[6]) in multi-scale fashion in order to achieve higher recall."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 115,
                                "start": 112
                            }
                        ],
                        "text": "Image binarization has been also used as a part of different text detection and recognition pipelines [4], [5], [6]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 31908858,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "359b3fd75e6000fba40ae3d4f6337cd830d186a9",
            "isKey": false,
            "numCitedBy": 16,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper shows that the use of Weighted Finite-State Transducer (WFST) significantly eliminates large-scale ambiguity in scene text recognition, especially for Japanese Kanji characters. The proposed method consists of two WFSTs called WFST-OCR and WFST-Lexicon. WFST-OCR handles the multiple hypotheses caused by erroneous text location, character segmentation and character recognition processes. The following WFST-Lexicon and its convolution of WFST-OCR resolve the hypotheses. The WFSTs integrate the conventional OCR and post-processing processes into one process. The benefit from the proposed method is that all the ambiguities are held as WFST data, and solved in one integrated step, the system outputs texts that are statistically consistent with regard to segmentation possibilities and the given language model. An experimental system demonstrates practical performance in spite of the hypothesis complexity inherent in the ICDAR test set and Kanji character texts."
            },
            "slug": "Hypothesis-Preservation-Approach-to-Scene-Text-with-Yamazoe-Etoh",
            "title": {
                "fragments": [],
                "text": "Hypothesis Preservation Approach to Scene Text Recognition with Weighted Finite-State Transducer"
            },
            "tldr": {
                "abstractSimilarityScore": 95,
                "text": "It is shown that the use of Weighted Finite-State Transducer (WFST) significantly eliminates large-scale ambiguity in scene text recognition, especially for Japanese Kanji characters."
            },
            "venue": {
                "fragments": [],
                "text": "2011 International Conference on Document Analysis and Recognition"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38340927"
                        ],
                        "name": "Yi-Feng Pan",
                        "slug": "Yi-Feng-Pan",
                        "structuredName": {
                            "firstName": "Yi-Feng",
                            "lastName": "Pan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yi-Feng Pan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1761961"
                        ],
                        "name": "Xinwen Hou",
                        "slug": "Xinwen-Hou",
                        "structuredName": {
                            "firstName": "Xinwen",
                            "lastName": "Hou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xinwen Hou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1689269"
                        ],
                        "name": "Cheng-Lin Liu",
                        "slug": "Cheng-Lin-Liu",
                        "structuredName": {
                            "firstName": "Cheng-Lin",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Cheng-Lin Liu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 61,
                                "start": 58
                            }
                        ],
                        "text": "The parameters of Niblack method were set as suggested in [4]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 59,
                                "start": 56
                            }
                        ],
                        "text": "image and some text detection and recognition pipelines [4] precede local binarization with the local text scale estimation."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 11,
                                "start": 8
                            }
                        ],
                        "text": "4 as in [4] and w = 21 in order to obtain finer segmentation for small letters."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 105,
                                "start": 102
                            }
                        ],
                        "text": "Image binarization has been also used as a part of different text detection and recognition pipelines [4], [5], [6]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 18095798,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "639530d07be756454c56aac9fe00cd233d970bc0",
            "isKey": true,
            "numCitedBy": 164,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper proposes a novel hybrid method to robustly and accurately localize texts in natural scene images. A text region detector is designed to generate a text confidence map, based on which text components can be segmented by local binarization approach. A Conditional Random Field (CRF) model, considering the unary component property as well as binary neighboring component relationship, is then presented to label components as \"text\" or \"non-text\". Last, text components are grouped into text lines with an energy minimization approach. Experimental results show that the proposed method gives promising performance comparing with the existing methods on ICDAR 2003 competition dataset."
            },
            "slug": "Text-Localization-in-Natural-Scene-Images-Based-on-Pan-Hou",
            "title": {
                "fragments": [],
                "text": "Text Localization in Natural Scene Images Based on Conditional Random Field"
            },
            "tldr": {
                "abstractSimilarityScore": 62,
                "text": "A novel hybrid method to robustly and accurately localize texts in natural scene images by considering the unary component property as well as binary neighboring component relationship is proposed."
            },
            "venue": {
                "fragments": [],
                "text": "2009 10th International Conference on Document Analysis and Recognition"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145532509"
                        ],
                        "name": "Luk\u00e1s Neumann",
                        "slug": "Luk\u00e1s-Neumann",
                        "structuredName": {
                            "firstName": "Luk\u00e1s",
                            "lastName": "Neumann",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Luk\u00e1s Neumann"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145564537"
                        ],
                        "name": "Jiri Matas",
                        "slug": "Jiri-Matas",
                        "structuredName": {
                            "firstName": "Jiri",
                            "lastName": "Matas",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jiri Matas"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 38,
                                "start": 34
                            }
                        ],
                        "text": "38 Neumann and Matas (no lexicon) [26] 0."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 81,
                                "start": 77
                            }
                        ],
                        "text": "In the first case, we did not use any lexicon, but fixed the alphabet (as in [26]) and pruned out the recognition results that contained non alpha-numeric characters."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 16169216,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "11ef1cf7743e30e06a857b0344b3cfe1199d85ea",
            "isKey": false,
            "numCitedBy": 6,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "A new method for text line formation for text localization and recognition is proposed. The method exhaustively enumerates short sequences of character regions in order to infer values of hidden text line parameters (such as text direction) and applies the parameters to efficiently limit the search space for longer sequences. The exhaustive enumeration of short sequences is achieved by finding all character region triplets that fulfill constraints of textual content, which keeps the proposed method efficient yet still capable to perform a robust estimation of the hidden parameters in order to correctly initialize the search. The method is applied to character regions which are detected as Maximally Stable Extremal Regions (MSERs). The performance of the method is evaluated on the standard ICDAR 2003 dataset, where the method outperforms (precision 0.60, recall 0.60) a previously published method for text line formation of MSERs."
            },
            "slug": "Estimating-hidden-parameters-for-text-localization-Neumann-Matas",
            "title": {
                "fragments": [],
                "text": "Estimating hidden parameters for text localization and recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "The exhaustive enumeration of short sequences of character regions is achieved by finding all character region triplets that fulfill constraints of textual content, which keeps the proposed method efficient yet still capable to perform a robust estimation of the hidden parameters in order to correctly initialize the search."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1748249"
                        ],
                        "name": "I. Pratikakis",
                        "slug": "I.-Pratikakis",
                        "structuredName": {
                            "firstName": "Ioannis",
                            "lastName": "Pratikakis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Pratikakis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7232446"
                        ],
                        "name": "B. Gatos",
                        "slug": "B.-Gatos",
                        "structuredName": {
                            "firstName": "Basilios",
                            "lastName": "Gatos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Gatos"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3058140"
                        ],
                        "name": "K. Ntirogiannis",
                        "slug": "K.-Ntirogiannis",
                        "structuredName": {
                            "firstName": "Konstantinos",
                            "lastName": "Ntirogiannis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Ntirogiannis"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 215,
                                "start": 211
                            }
                        ],
                        "text": "We have also included several recent methods for document binarization, namely Wolf [19] 2, Howe [12], and Lu [20]3, the last one being a runner-up at ICDAR 2011 Document Image Binarization Contest (DIBCO 2011) [21]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 112,
                                "start": 108
                            }
                        ],
                        "text": "ru/en/science/research/msr/text used in comparative analysis of document binarization techniques (see [23], [21]), they do not describe morphological structure of the generated connected components, which is important for the accuracy of text recognition."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14240014,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "815eac36a4afd0c5d4e53a5443db3a56bb3b3492",
            "isKey": false,
            "numCitedBy": 213,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "DIBCO 2011 is the International Document Image Binarization Contest organized in the context of ICDAR 2011 conference. The general objective of the contest is to identify current advances in document image binarization for both machine-printed and handwritten document images using evaluation performance measures that conform to document image analysis and recognition. This paper describes the contest details including the evaluation measures used as well as the performance of the 18 submitted methods along with a short description of each method."
            },
            "slug": "ICDAR-2011-Document-Image-Binarization-Contest-Pratikakis-Gatos",
            "title": {
                "fragments": [],
                "text": "ICDAR 2011 Document Image Binarization Contest (DIBCO 2011)"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "The contest details including the evaluation measures used as well as the performance of the 18 submitted methods are described along with a short description of each method."
            },
            "venue": {
                "fragments": [],
                "text": "2011 International Conference on Document Analysis and Recognition"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7232446"
                        ],
                        "name": "B. Gatos",
                        "slug": "B.-Gatos",
                        "structuredName": {
                            "firstName": "Basilios",
                            "lastName": "Gatos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Gatos"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1748249"
                        ],
                        "name": "I. Pratikakis",
                        "slug": "I.-Pratikakis",
                        "structuredName": {
                            "firstName": "Ioannis",
                            "lastName": "Pratikakis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Pratikakis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2097431961"
                        ],
                        "name": "K. Kepene",
                        "slug": "K.-Kepene",
                        "structuredName": {
                            "firstName": "K.",
                            "lastName": "Kepene",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Kepene"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2397702"
                        ],
                        "name": "S. Perantonis",
                        "slug": "S.-Perantonis",
                        "structuredName": {
                            "firstName": "Stavros",
                            "lastName": "Perantonis",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Perantonis"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[13] used two binarized images by Sauvola\u2019s method for original gray-scale and inverted images for rough estimation of background and thresholded the difference between original and binarized images."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 14,
                                "start": 10
                            }
                        ],
                        "text": "For [14], [13], [16], [7] we used parameters suggested by the authors."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 5,
                                "start": 0
                            }
                        ],
                        "text": "Gatos et al. [13] used two binarized images by Sauvola\u2019s method for original gray-scale and inverted images for rough estimation of background and thresholded the difference between original and binarized images."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 82,
                                "start": 78
                            }
                        ],
                        "text": "We have also included methods developed for natural images: Ezaki [14], Gatos [13], Minetto [16] and non-linear Niblack decomposition [7]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 18567098,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "28f3869f2868e2b39a2fe7f069c1907e29f17764",
            "isKey": true,
            "numCitedBy": 52,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we propose a novel methodology for text detection in indoor/outdoor scene images. The proposed methodology is based on an efficient binarization and enhancement technique followed by a suitable connected component analysis procedure. Image binarization successfully process indoor/ outdoor scene images having shadows, non-uniform illumination, low contrast and large signal-depended noise. Connected component analysis is used to define the final binary images that mainly consist of text regions. The proposed methodology leads in increased success rates at commercial OCR engines. Experimental results based on the public database of the ICDAR2003 Robust Reading Competition prove the efficiency of the proposed approach."
            },
            "slug": "Detection-in-Indoor-/-Outdoor-Scene-Images-Gatos-Pratikakis",
            "title": {
                "fragments": [],
                "text": "Detection in Indoor / Outdoor Scene Images"
            },
            "tldr": {
                "abstractSimilarityScore": 78,
                "text": "A novel methodology for text detection in indoor/outdoor scene images based on an efficient binarization and enhancement technique followed by a suitable connected component analysis procedure that leads in increased success rates at commercial OCR engines."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3302327"
                        ],
                        "name": "E. Badekas",
                        "slug": "E.-Badekas",
                        "structuredName": {
                            "firstName": "Euthimios",
                            "lastName": "Badekas",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Badekas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144368634"
                        ],
                        "name": "N. Papamarkos",
                        "slug": "N.-Papamarkos",
                        "structuredName": {
                            "firstName": "Nikos",
                            "lastName": "Papamarkos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Papamarkos"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 67,
                                "start": 63
                            }
                        ],
                        "text": "The parameters for the Sauvola method were set as suggested in [22]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 18348559,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "038aa875d9c8f202ce47abd86ef657c69c2db538",
            "isKey": false,
            "numCitedBy": 40,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "Most of the document binarization techniques have many parameters that can initially be specified. Usually, subjective document binarization evaluation, employs human observes for the estimation of the best parameter values of the techniques. Thus, the selection of the best values for these parameters is crucial for the final binarization result. However, there is not any set of parameters that guarantees the best binarization result for all document images. It is important, the estimation of the best values to be adaptive for each one of the processing images. This paper proposes a new method which permits the estimation of the best parameter values for each one of the document binarization techniques and also the estimation of the best document binarization result of all techniques. In this way, document binarization techniques can be compared and evaluated using, for each one of them, the best parameter values for every document image."
            },
            "slug": "Automatic-Evaluation-of-Document-Binarization-Badekas-Papamarkos",
            "title": {
                "fragments": [],
                "text": "Automatic Evaluation of Document Binarization Results"
            },
            "tldr": {
                "abstractSimilarityScore": 51,
                "text": "This paper proposes a new method which permits the estimation of the best parameter values for each one of the document binarization techniques and also the estimationOf the best document Binarization result of all techniques."
            },
            "venue": {
                "fragments": [],
                "text": "CIARP"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3126798"
                        ],
                        "name": "B. Epshtein",
                        "slug": "B.-Epshtein",
                        "structuredName": {
                            "firstName": "Boris",
                            "lastName": "Epshtein",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Epshtein"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "20592981"
                        ],
                        "name": "E. Ofek",
                        "slug": "E.-Ofek",
                        "structuredName": {
                            "firstName": "Eyal",
                            "lastName": "Ofek",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Ofek"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1743988"
                        ],
                        "name": "Y. Wexler",
                        "slug": "Y.-Wexler",
                        "structuredName": {
                            "firstName": "Yonatan",
                            "lastName": "Wexler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Wexler"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 13,
                                "start": 9
                            }
                        ],
                        "text": "Epshtein [15] suggested using a new image operator (Stroke Width Transform) to segment letters."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 83,
                                "start": 79
                            }
                        ],
                        "text": "Finally, we have also included the method based on stroke width transform from [15] implemented in text localization system4."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 8890220,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "39c4ae83b5c92e0fa55de1ec7e5cf12589c408db",
            "isKey": false,
            "numCitedBy": 1470,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a novel image operator that seeks to find the value of stroke width for each image pixel, and demonstrate its use on the task of text detection in natural images. The suggested operator is local and data dependent, which makes it fast and robust enough to eliminate the need for multi-scale computation or scanning windows. Extensive testing shows that the suggested scheme outperforms the latest published algorithms. Its simplicity allows the algorithm to detect texts in many fonts and languages."
            },
            "slug": "Detecting-text-in-natural-scenes-with-stroke-width-Epshtein-Ofek",
            "title": {
                "fragments": [],
                "text": "Detecting text in natural scenes with stroke width transform"
            },
            "tldr": {
                "abstractSimilarityScore": 84,
                "text": "A novel image operator is presented that seeks to find the value of stroke width for each image pixel, and its use on the task of text detection in natural images is demonstrated."
            },
            "venue": {
                "fragments": [],
                "text": "2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7232446"
                        ],
                        "name": "B. Gatos",
                        "slug": "B.-Gatos",
                        "structuredName": {
                            "firstName": "Basilios",
                            "lastName": "Gatos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Gatos"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3058140"
                        ],
                        "name": "K. Ntirogiannis",
                        "slug": "K.-Ntirogiannis",
                        "structuredName": {
                            "firstName": "Konstantinos",
                            "lastName": "Ntirogiannis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Ntirogiannis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1748249"
                        ],
                        "name": "I. Pratikakis",
                        "slug": "I.-Pratikakis",
                        "structuredName": {
                            "firstName": "Ioannis",
                            "lastName": "Pratikakis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Pratikakis"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 106,
                                "start": 102
                            }
                        ],
                        "text": "ru/en/science/research/msr/text used in comparative analysis of document binarization techniques (see [23], [21]), they do not describe morphological structure of the generated connected components, which is important for the accuracy of text recognition."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14761554,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a29812489512ae8029a1c930753ea972b0b72ec0",
            "isKey": false,
            "numCitedBy": 299,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "DIBCO 2009 is the first International Document Image Binarization Contest organized in the context of ICDAR 2009 conference. The general objective of the contest is to identify current advances in document image binarization using established evaluation performance measures. This paper describes the contest details including the evaluation measures used as well as the performance of the 43 submitted methods along with a short description of each method."
            },
            "slug": "ICDAR-2009-Document-Image-Binarization-Contest-Gatos-Ntirogiannis",
            "title": {
                "fragments": [],
                "text": "ICDAR 2009 Document Image Binarization Contest (DIBCO 2009)"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "The contest details including the evaluation measures used as well as the performance of the 43 submitted methods are described along with a short description of each method."
            },
            "venue": {
                "fragments": [],
                "text": "2009 10th International Conference on Document Analysis and Recognition"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38388395"
                        ],
                        "name": "N. Howe",
                        "slug": "N.-Howe",
                        "structuredName": {
                            "firstName": "Nicholas",
                            "lastName": "Howe",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Howe"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 9,
                                "start": 5
                            }
                        ],
                        "text": "Howe [12] proposed to use the Laplacian of the image intensity for scanned document binarization within a Markov Random Field model (which is an algorithmic setup most similar to the one we propose below)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "However its\ncontribution to the overall performance of the system as well as the intuition behind the choice of each particular binarization method was not detailed."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 29,
                                "start": 25
                            }
                        ],
                        "text": "While the method of Howe [12] uses Laplacian-based unary terms similarly to our method, it shows significantly lower accuracy in the case of natural images with complex backgrounds, which we believe is due to better choice of unary and pairwise terms inside the global optimization in proposed method."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 101,
                                "start": 97
                            }
                        ],
                        "text": "We have also included several recent methods for document binarization, namely Wolf [19] 2, Howe [12], and Lu [20]3, the last one being a runner-up at ICDAR 2011 Document Image Binarization Contest (DIBCO 2011) [21]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 17900894,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6e5022b90d4b7d2604e7be93ed2789cd16fa3bea",
            "isKey": true,
            "numCitedBy": 101,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes a new algorithm for document binarization, building upon recent work in energy-based segmentation methods. It uses the Laplacian operator to assess the local likelihood of foreground and background labels, Canny edge detection to identify likely discontinuities, and a graph cut implementation to efficiently find the minimum energy solution of an objective function combining these concepts. The results of this algorithm place it near the top on both the DIBCO-09 and H-DIBCO assessments."
            },
            "slug": "A-Laplacian-Energy-for-Document-Binarization-Howe",
            "title": {
                "fragments": [],
                "text": "A Laplacian Energy for Document Binarization"
            },
            "tldr": {
                "abstractSimilarityScore": 75,
                "text": "A new algorithm for document binarization that uses the Laplacian operator to assess the local likelihood of foreground and background labels, Canny edge detection to identify likely discontinuities, and a graph cut implementation to efficiently find the minimum energy solution of an objective function combining these concepts."
            },
            "venue": {
                "fragments": [],
                "text": "2011 International Conference on Document Analysis and Recognition"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1692688"
                        ],
                        "name": "Yuri Boykov",
                        "slug": "Yuri-Boykov",
                        "structuredName": {
                            "firstName": "Yuri",
                            "lastName": "Boykov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yuri Boykov"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144653004"
                        ],
                        "name": "V. Kolmogorov",
                        "slug": "V.-Kolmogorov",
                        "structuredName": {
                            "firstName": "Vladimir",
                            "lastName": "Kolmogorov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Kolmogorov"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 93,
                                "start": 89
                            }
                        ],
                        "text": "The global minimum of this energy can be found efficiently using the graph cut inference [18]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 36955056,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6116661b3ed8126bd983024c4158b70ae410f88b",
            "isKey": false,
            "numCitedBy": 2189,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": "After [15], [31], [19], [8], [25], [5], minimum cut/maximum flow algorithms on graphs emerged as an increasingly useful tool for exact or approximate energy minimization in low-level vision. The combinatorial optimization literature provides many min-cut/max-flow algorithms with different polynomial time complexity. Their practical efficiency, however, has to date been studied mainly outside the scope of computer vision. The goal of this paper is to provide an experimental comparison of the efficiency of min-cut/max flow algorithms for applications in vision. We compare the running times of several standard algorithms, as well as a new algorithm that we have recently developed. The algorithms we study include both Goldberg-Tarjan style \"push-relabel\" methods and algorithms based on Ford-Fulkerson style \"augmenting paths.\" We benchmark these algorithms on a number of typical graphs in the contexts of image restoration, stereo, and segmentation. In many cases, our new algorithm works several times faster than any of the other methods, making near real-time performance possible. An implementation of our max-flow/min-cut algorithm is available upon request for research purposes."
            },
            "slug": "An-experimental-comparison-of-min-cut/max-flow-for-Boykov-Kolmogorov",
            "title": {
                "fragments": [],
                "text": "An experimental comparison of min-cut/max-flow algorithms for energy minimization in vision."
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This paper compares the running times of several standard algorithms, as well as a new algorithm that is recently developed that works several times faster than any of the other methods, making near real-time performance possible."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE transactions on pattern analysis and machine intelligence"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1796455"
                        ],
                        "name": "R. Minetto",
                        "slug": "R.-Minetto",
                        "structuredName": {
                            "firstName": "Rodrigo",
                            "lastName": "Minetto",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Minetto"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1728523"
                        ],
                        "name": "Nicolas Thome",
                        "slug": "Nicolas-Thome",
                        "structuredName": {
                            "firstName": "Nicolas",
                            "lastName": "Thome",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nicolas Thome"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "51021910"
                        ],
                        "name": "M. Cord",
                        "slug": "M.-Cord",
                        "structuredName": {
                            "firstName": "Matthieu",
                            "lastName": "Cord",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Cord"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1719901"
                        ],
                        "name": "J. Stolfi",
                        "slug": "J.-Stolfi",
                        "structuredName": {
                            "firstName": "Jorge",
                            "lastName": "Stolfi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Stolfi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1699175"
                        ],
                        "name": "F. Precioso",
                        "slug": "F.-Precioso",
                        "structuredName": {
                            "firstName": "Fr\u00e9d\u00e9ric",
                            "lastName": "Precioso",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Precioso"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2030869"
                        ],
                        "name": "Jonathan Guyomard",
                        "slug": "Jonathan-Guyomard",
                        "structuredName": {
                            "firstName": "Jonathan",
                            "lastName": "Guyomard",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jonathan Guyomard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1756125"
                        ],
                        "name": "N. J. Leite",
                        "slug": "N.-J.-Leite",
                        "structuredName": {
                            "firstName": "Neucimar",
                            "lastName": "Leite",
                            "middleNames": [
                                "Jer\u00f4nimo"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. J. Leite"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 20,
                                "start": 16
                            }
                        ],
                        "text": "For [14], [13], [16], [7] we used parameters suggested by the authors."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[16] proposed using toggle mapping for character segmentation in a multiresolutional way since natural scene images have large character size variations and strong background clutter."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 7,
                                "start": 0
                            }
                        ],
                        "text": "Minetto et al. [16] proposed using toggle mapping for character segmentation in a multiresolutional way since natural scene images have large character size variations and strong background clutter."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 96,
                                "start": 92
                            }
                        ],
                        "text": "We have also included methods developed for natural images: Ezaki [14], Gatos [13], Minetto [16] and non-linear Niblack decomposition [7]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2257115,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "19525c3d68f509b0e39eba044b47dab60093e4d5",
            "isKey": true,
            "numCitedBy": 36,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "Text detection and recognition in real images taken in unconstrained environments, such as street view images, remain surprisingly challenging in Computer Vision."
            },
            "slug": "Text-detection-and-recognition-in-urban-scenes-Minetto-Thome",
            "title": {
                "fragments": [],
                "text": "Text detection and recognition in urban scenes"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "Text detection and recognition in real images taken in unconstrained environments, such as street view images, remain surprisingly challenging in Computer Vision."
            },
            "venue": {
                "fragments": [],
                "text": "2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops)"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2141915"
                        ],
                        "name": "W. Niblack",
                        "slug": "W.-Niblack",
                        "structuredName": {
                            "firstName": "Wayne",
                            "lastName": "Niblack",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Niblack"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 102,
                                "start": 98
                            }
                        ],
                        "text": "We have included methods commonly used for document images, namely Otsu [8], Kittler [9], Niblack [11] and Sauvola [10]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 229,
                                "start": 225
                            }
                        ],
                        "text": "These methods can be roughly divided into two groups: the first group uses a fixed threshold for a given image (Otsu [8], Kittler [9]), while the second group (local binarization) uses local thresholds (Sauvola [10], Niblack [11])."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 60929037,
            "fieldsOfStudy": [
                "Art"
            ],
            "id": "43678765df1d0b4594f7a49298cf27d75e174787",
            "isKey": false,
            "numCitedBy": 1417,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "An-introduction-to-digital-image-processing-Niblack",
            "title": {
                "fragments": [],
                "text": "An introduction to digital image processing"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1692688"
                        ],
                        "name": "Yuri Boykov",
                        "slug": "Yuri-Boykov",
                        "structuredName": {
                            "firstName": "Yuri",
                            "lastName": "Boykov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yuri Boykov"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144197071"
                        ],
                        "name": "M. Jolly",
                        "slug": "M.-Jolly",
                        "structuredName": {
                            "firstName": "Marie-Pierre",
                            "lastName": "Jolly",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Jolly"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 78,
                                "start": 74
                            }
                        ],
                        "text": "We use a conventional pairwise term traditional to graph cut segmentation [17]: Esmooth(f |I) = \u03bb \u2211 (i,j)\u2208N esmooth(i, j), defined by pixel similarity:"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2245438,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1175608cde3de3d3b6e17aea53ccbafbda6eb638",
            "isKey": false,
            "numCitedBy": 4174,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we describe a new technique for general purpose interactive segmentation of N-dimensional images. The user marks certain pixels as \"object\" or \"background\" to provide hard constraints for segmentation. Additional soft constraints incorporate both boundary and region information. Graph cuts are used to find the globally optimal segmentation of the N-dimensional image. The obtained solution gives the best balance of boundary and region properties among all segmentations satisfying the constraints. The topology of our segmentation is unrestricted and both \"object\" and \"background\" segments may consist of several isolated parts. Some experimental results are presented in the context of photo/video editing and medical image segmentation. We also demonstrate an interesting Gestalt example. A fast implementation of our segmentation method is possible via a new max-flow algorithm."
            },
            "slug": "Interactive-graph-cuts-for-optimal-boundary-&-of-in-Boykov-Jolly",
            "title": {
                "fragments": [],
                "text": "Interactive Graph Cuts for Optimal Boundary and Region Segmentation of Objects in N-D Images"
            },
            "tldr": {
                "abstractSimilarityScore": 87,
                "text": "A new technique for general purpose interactive segmentation of N-dimensional images where the user marks certain pixels as \"object\" or \"background\" to provide hard constraints for segmentation."
            },
            "venue": {
                "fragments": [],
                "text": "ICCV"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3056361"
                        ],
                        "name": "J. Friedman",
                        "slug": "J.-Friedman",
                        "structuredName": {
                            "firstName": "Jerome",
                            "lastName": "Friedman",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Friedman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1784682"
                        ],
                        "name": "T. Hastie",
                        "slug": "T.-Hastie",
                        "structuredName": {
                            "firstName": "Trevor",
                            "lastName": "Hastie",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Hastie"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1761784"
                        ],
                        "name": "R. Tibshirani",
                        "slug": "R.-Tibshirani",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Tibshirani",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Tibshirani"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1703537"
                        ],
                        "name": "Y. Freund",
                        "slug": "Y.-Freund",
                        "structuredName": {
                            "firstName": "Yoav",
                            "lastName": "Freund",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Freund"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716301"
                        ],
                        "name": "R. Schapire",
                        "slug": "R.-Schapire",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Schapire",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Schapire"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 171,
                                "start": 167
                            }
                        ],
                        "text": "For each word candidates that passed the filters we computed the average probabilistic classifier output for the segments that constitute this word (sigmoid transform [29] are considered to map the outputs of boosted classifier to probabilities)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2354909,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "277c2139eb4e11455a0b16759b7249c3b95b479e",
            "isKey": false,
            "numCitedBy": 1352,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "The main and important contribution of this paper is in establishing a connection between boosting, a newcomer to the statistics scene, and additive models. One of the main properties of boosting that has made it interesting to statisticians and others is its relative (but not complete) immunity to overrtting. As pointed out by the authors, the current paper does not address this issue. Leo Breiman 1] tried to explain this behaviour in terms of bias and variance. In our paper with Bartlett and Lee 4], we gave an explanation in terms of the \\margins\" of the training examples and the VC-dimension of the base class. Breiman, as well as the current paper, point out that our bounds are very rough and yield bounds that are not useful in practice. While this is clearly true at this time, it is also true that the analysis given by Breiman and by this paper yield no provable bounds whatsoever. It is completely unclear whether this analysis can be used to predict the performance of classiication rules outside of the training sample. At the root of this argument about boosting is a much more fundamental argument about the type of prior assumptions that one should make when embarking on the task of inducing a classiication rule from data. The assumption that seems to underlie the use of maximum likelihood in the 1"
            },
            "slug": "Discussion-of-the-Paper-\\additive-Logistic-a-View-Friedman-Hastie",
            "title": {
                "fragments": [],
                "text": "Discussion of the Paper \\additive Logistic Regression: a Statistical View of Boosting\" By"
            },
            "tldr": {
                "abstractSimilarityScore": 66,
                "text": "This paper establishes a connection between boosting, a newcomer to the statistics scene, and additive models and investigates the assumption that seems to underlie the use of maximum likelihood in the additive models."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1809629"
                        ],
                        "name": "N. Otsu",
                        "slug": "N.-Otsu",
                        "structuredName": {
                            "firstName": "Nobuyuki",
                            "lastName": "Otsu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Otsu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 137,
                                "start": 133
                            }
                        ],
                        "text": "Ezaki et al. [14] proposed generating connected components by combination of mathematical morphology operations, edge extraction and Otsu thresholding of image color channels."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 75,
                                "start": 72
                            }
                        ],
                        "text": "We have included methods commonly used for document images, namely Otsu [8], Kittler [9], Niblack [11] and Sauvola [10]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 120,
                                "start": 117
                            }
                        ],
                        "text": "These methods can be roughly divided into two groups: the first group uses a fixed threshold for a given image (Otsu [8], Kittler [9]), while the second group (local binarization) uses local thresholds (Sauvola [10], Niblack [11])."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 99,
                                "start": 96
                            }
                        ],
                        "text": "In the cases when color and illumination variations are high, global thresholding methods (Otsu [8], Kittler [9]) are unable to divide natural images into text and background using a single threshold."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 70,
                                "start": 67
                            }
                        ],
                        "text": "The most popular methods for document image binarization like Otsu [8], Kittler [9], Sauvola [10] show significantly degraded performance on natural scenes."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 15326934,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "1d4816c612e38dac86f2149af667a5581686cdef",
            "isKey": true,
            "numCitedBy": 32883,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "A nonparametric and unsupervised method ofautomatic threshold selection for picture segmentation is presented. An optimal threshold is selected by the discriminant criterion, namely, so as to maximize the separability of the resultant classes in gray levels. The procedure is very simple, utilizing only the zerothand the first-order cumulative moments of the gray-level histogram. It is straightforward to extend the method to multithreshold problems. Several experimental results are also presented to support the validity of the method."
            },
            "slug": "A-threshold-selection-method-from-gray-level-Otsu",
            "title": {
                "fragments": [],
                "text": "A threshold selection method from gray level histograms"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1979
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145801638"
                        ],
                        "name": "J. Kittler",
                        "slug": "J.-Kittler",
                        "structuredName": {
                            "firstName": "Josef",
                            "lastName": "Kittler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Kittler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144275801"
                        ],
                        "name": "J. Illingworth",
                        "slug": "J.-Illingworth",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Illingworth",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Illingworth"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 83,
                                "start": 80
                            }
                        ],
                        "text": "The most popular methods for document image binarization like Otsu [8], Kittler [9], Sauvola [10] show significantly degraded performance on natural scenes."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 88,
                                "start": 85
                            }
                        ],
                        "text": "We have included methods commonly used for document images, namely Otsu [8], Kittler [9], Niblack [11] and Sauvola [10]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 133,
                                "start": 130
                            }
                        ],
                        "text": "These methods can be roughly divided into two groups: the first group uses a fixed threshold for a given image (Otsu [8], Kittler [9]), while the second group (local binarization) uses local thresholds (Sauvola [10], Niblack [11])."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 112,
                                "start": 109
                            }
                        ],
                        "text": "In the cases when color and illumination variations are high, global thresholding methods (Otsu [8], Kittler [9]) are unable to divide natural images into text and background using a single threshold."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 205012622,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "00f2938d9f10e4bd37336f01b18a41d518f749ba",
            "isKey": true,
            "numCitedBy": 2083,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Minimum-error-thresholding-Kittler-Illingworth",
            "title": {
                "fragments": [],
                "text": "Minimum error thresholding"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit."
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "71411026"
                        ],
                        "name": "Kitagawa Kohei",
                        "slug": "Kitagawa-Kohei",
                        "structuredName": {
                            "firstName": "Kitagawa",
                            "lastName": "Kohei",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kitagawa Kohei"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "72111300"
                        ],
                        "name": "Wakahara Toru",
                        "slug": "Wakahara-Toru",
                        "structuredName": {
                            "firstName": "Wakahara",
                            "lastName": "Toru",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wakahara Toru"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 3,
                                "start": 0
                            }
                        ],
                        "text": "[3] proposed a method based on k-means clustering and letter candidates classification for a similar cropped image scenario."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 30,
                                "start": 27
                            }
                        ],
                        "text": "Several recent papers [2], [3] propose new methods for binarization of natural scene text in cropped word images assuming that text localization is done at the previous step of a pipeline (which, in practice, is highly non-trivial)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 27,
                                "start": 24
                            }
                        ],
                        "text": "Other recent works [2], [3] focus on the binarization of cropped text assuming that the text is correctly localized in the preceeding steps of the pipeline."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 67420662,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b56c92611a04fa580ec60b1c2f9e43edf91d8f6d",
            "isKey": false,
            "numCitedBy": 14,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Binarization-of-Color-Character-Strings-in-Scene-Kohei-Toru",
            "title": {
                "fragments": [],
                "text": "Binarization of Color Character Strings in Scene Images Using K-means Clustering and Support Vector Machines"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2010
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 7,
            "methodology": 26,
            "result": 1
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 29,
        "totalPages": 3
    },
    "page_url": "https://www.semanticscholar.org/paper/Image-Binarization-for-End-to-End-Text-in-Natural-Milyaev-Barinova/3d1154fc82f7054a984629520f08b9e925717b26?sort=total-citations"
}