{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3188179"
                        ],
                        "name": "A. Opelt",
                        "slug": "A.-Opelt",
                        "structuredName": {
                            "firstName": "Andreas",
                            "lastName": "Opelt",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Opelt"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40446025"
                        ],
                        "name": "M. Fussenegger",
                        "slug": "M.-Fussenegger",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Fussenegger",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Fussenegger"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1718587"
                        ],
                        "name": "A. Pinz",
                        "slug": "A.-Pinz",
                        "structuredName": {
                            "firstName": "Axel",
                            "lastName": "Pinz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Pinz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144543541"
                        ],
                        "name": "P. Auer",
                        "slug": "P.-Auer",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Auer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Auer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "0162-8828/06/$20.00 2006 IEEE Published by the IEEE Computer Society"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 16562909,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0c91808994a250d7be332400a534a9291ca3b60e",
            "isKey": false,
            "numCitedBy": 333,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we describe the first stage of a new learning system for object detection and recognition. For our system we propose Boosting (5) as the underlying learning technique. This allows the use of very diverse sets of visual features in the learning process within a com- mon framework: Boosting \u2014 together with a weak hypotheses finder \u2014 may choose very inhomogeneous features as most relevant for combina- tion into a final hypothesis. As another advantage the weak hypotheses finder may search the weak hypotheses space without explicit calculation of all available hypotheses, reducing computation time. This contrasts the related work of Agarwal and Roth (1) where Winnow was used as learning algorithm and all weak hypotheses were calculated explicitly. In our first empirical evaluation we use four types of local descriptors: two basic ones consisting of a set of grayvalues and intensity moments and two high level descriptors: moment invariants (8) and SIFTs (12). The descriptors are calculated from local patches detected by an inter- est point operator. The weak hypotheses finder selects one of the local patches and one type of local descriptor and efficiently searches for the most discriminative similarity threshold. This differs from other work on Boosting for object recognition where simple rectangular hypotheses (22) or complex classifiers (20) have been used. In relatively simple images, where the objects are prominent, our approach yields results comparable to the state-of-the-art (3). But we also obtain very good results on more complex images, where the objects are located in arbitrary positions, poses, and scales in the images. These results indicate that our flexible approach, which also allows the inclusion of features from segmented re- gions and even spatial relationships, leads us a significant step towards generic object recognition."
            },
            "slug": "Weak-Hypotheses-and-Boosting-for-Generic-Object-and-Opelt-Fussenegger",
            "title": {
                "fragments": [],
                "text": "Weak Hypotheses and Boosting for Generic Object Detection and Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 64,
                "text": "The first stage of a new learning system for object detection and recognition using Boosting as the underlying learning technique and the inclusion of features from segmented re- gions and even spatial relationships leads us a significant step towards generic object recognition."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40446025"
                        ],
                        "name": "M. Fussenegger",
                        "slug": "M.-Fussenegger",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Fussenegger",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Fussenegger"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3188179"
                        ],
                        "name": "A. Opelt",
                        "slug": "A.-Opelt",
                        "structuredName": {
                            "firstName": "Andreas",
                            "lastName": "Opelt",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Opelt"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1718587"
                        ],
                        "name": "A. Pinz",
                        "slug": "A.-Pinz",
                        "structuredName": {
                            "firstName": "Axel",
                            "lastName": "Pinz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Pinz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144543541"
                        ],
                        "name": "P. Auer",
                        "slug": "P.-Auer",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Auer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Auer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 95,
                                "start": 91
                            }
                        ],
                        "text": "We have developed a new algorithm - \u201cSimilarity-Measure-Se gm ntation\u201d (first presented in [13]) which is described in detail subsequently."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 15796618,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e3ffb65484e9815366d5eec55b44fbba53b4afbd",
            "isKey": false,
            "numCitedBy": 19,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "A new method is presented to learn object categories from unlabeled and unsegmented images for generic object recognition. We assume that each object can be characterized by a set of typical regions, and use a new segmentation method - \"similarity-measure segmentation\" - to split the images into regions of interest. This approach may also deliver segments, which are split into several disconnected parts, which turn out to be a powerful description of local similarities. Several textural features are calculated for each region, which are used to learn object categories with boosting. We demonstrate the flexibility and power of our method by excellent results on various datasets. In comparison, our recognition results are significantly higher than the results published in related work."
            },
            "slug": "Object-recognition-using-segmentation-for-feature-Fussenegger-Opelt",
            "title": {
                "fragments": [],
                "text": "Object recognition using segmentation for feature detection"
            },
            "tldr": {
                "abstractSimilarityScore": 72,
                "text": "A new method is presented to learn object categories from unlabeled and unsegmented images for generic object recognition using a new segmentation method - \"similarity-measure segmentation\" - to split the images into regions of interest."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 17th International Conference on Pattern Recognition, 2004. ICPR 2004."
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "118939247"
                        ],
                        "name": "J. Thureson",
                        "slug": "J.-Thureson",
                        "structuredName": {
                            "firstName": "Johan",
                            "lastName": "Thureson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Thureson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153120475"
                        ],
                        "name": "S. Carlsson",
                        "slug": "S.-Carlsson",
                        "structuredName": {
                            "firstName": "Stefan",
                            "lastName": "Carlsson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Carlsson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 14,
                                "start": 10
                            }
                        ],
                        "text": "[9], [2], [35]) use just one kind o f description method, we combine multiple information extraction methods to capture the essential ch racteristics of various object categories (e."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 105,
                                "start": 101
                            }
                        ],
                        "text": "A new possibility of describing objects for categorization is introduced by Thureson and Carlsson in [35]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1943838,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ac3645f03959b9e06c0a437e318a00278b4a20da",
            "isKey": false,
            "numCitedBy": 56,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "The problem of recognizing classes of objects as opposed to special instances requires methods of comparing images that capture the variation within the class while they discriminate against objects outside the class. We present a simple method for image description based on histograms of qualitative shape indexes computed from the combination of triplets of sampled locations and gradient directions in the image. We demonstrate that this method indeed is able to capture variation within classes of objects and we apply it to the problem of recognizing four different categories from a large database. Using our descriptor on the whole image, containing varying degrees of background clutter, we obtain results for two of the objects that are superior to the best results published so far for this database. By cropping images manually we demonstrate that our method has a potential to handle also the other objects when supplied with an algorithm for searching the image. We argue that our method, based on qualitative image properties, capture the large range of variation that is typically encountered within an object class. This means that our method can be used on substantially larger patches of images than existing methods based on simpler criteria for evaluating image similarity."
            },
            "slug": "Appearance-Based-Qualitative-Image-Description-for-Thureson-Carlsson",
            "title": {
                "fragments": [],
                "text": "Appearance Based Qualitative Image Description for Object Class Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "It is argued that the method presented, based on qualitative image properties, capture the large range of variation that is typically encountered within an object class and can be used on substantially larger patches of images than existing methods based on simpler criteria for evaluating image similarity."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1731948"
                        ],
                        "name": "Paul A. Viola",
                        "slug": "Paul-A.-Viola",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Viola",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Paul A. Viola"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145319478"
                        ],
                        "name": "Michael J. Jones",
                        "slug": "Michael-J.-Jones",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Jones",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael J. Jones"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2715202,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "dc6ea0e30e46163b706f2f8bdc9c67ca87f83d63",
            "isKey": false,
            "numCitedBy": 17887,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes a machine learning approach for visual object detection which is capable of processing images extremely rapidly and achieving high detection rates. This work is distinguished by three key contributions. The first is the introduction of a new image representation called the \"integral image\" which allows the features used by our detector to be computed very quickly. The second is a learning algorithm, based on AdaBoost, which selects a small number of critical visual features from a larger set and yields extremely efficient classifiers. The third contribution is a method for combining increasingly more complex classifiers in a \"cascade\" which allows background regions of the image to be quickly discarded while spending more computation on promising object-like regions. The cascade can be viewed as an object specific focus-of-attention mechanism which unlike previous approaches provides statistical guarantees that discarded regions are unlikely to contain the object of interest. In the domain of face detection the system yields detection rates comparable to the best previous systems. Used in real-time applications, the detector runs at 15 frames per second without resorting to image differencing or skin color detection."
            },
            "slug": "Rapid-object-detection-using-a-boosted-cascade-of-Viola-Jones",
            "title": {
                "fragments": [],
                "text": "Rapid object detection using a boosted cascade of simple features"
            },
            "tldr": {
                "abstractSimilarityScore": 72,
                "text": "A machine learning approach for visual object detection which is capable of processing images extremely rapidly and achieving high detection rates and the introduction of a new image representation called the \"integral image\" which allows the features used by the detector to be computed very quickly."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 2001 IEEE Computer Society Conference on Computer Vision and Pattern Recognition. CVPR 2001"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2085375589"
                        ],
                        "name": "H. Schneiderman",
                        "slug": "H.-Schneiderman",
                        "structuredName": {
                            "firstName": "Henry",
                            "lastName": "Schneiderman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Schneiderman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733113"
                        ],
                        "name": "T. Kanade",
                        "slug": "T.-Kanade",
                        "structuredName": {
                            "firstName": "Takeo",
                            "lastName": "Kanade",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kanade"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 79,
                                "start": 75
                            }
                        ],
                        "text": "Thus, we use Boosting as a learning technique that can elegantly form category-specific vectors of very diverse descriptors."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14133530,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "36cd88ed2c17a596001e9c7d89533ac46c28dec0",
            "isKey": false,
            "numCitedBy": 406,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we describe a trainable object detector and its instantiations for detecting faces and cars at any size, location, and pose. To cope with variation in object orientation, the detector uses multiple classifiers, each spanning a different range of orientation. Each of these classifiers determines whether the object is present at a specified size within a fixed-size image window. To find the object at any location and size, these classifiers scan the image exhaustively.Each classifier is based on the statistics of localized parts. Each part is a transform from a subset of wavelet coefficients to a discrete set of values. Such parts are designed to capture various combinations of locality in space, frequency, and orientation. In building each classifier, we gathered the class-conditional statistics of these part values from representative samples of object and non-object images. We trained each classifier to minimize classification error on the training set by using Adaboost with Confidence-Weighted Predictions (Shapire and Singer, 1999). In detection, each classifier computes the part values within the image window and looks up their associated class-conditional probabilities. The classifier then makes a decision by applying a likelihood ratio test. For efficiency, the classifier evaluates this likelihood ratio in stages. At each stage, the classifier compares the partial likelihood ratio to a threshold and makes a decision about whether to cease evaluation\u2014labeling the input as non-object\u2014or to continue further evaluation. The detector orders these stages of evaluation from a low-resolution to a high-resolution search of the image. Our trainable object detector achieves reliable and efficient detection of human faces and passenger cars with out-of-plane rotation."
            },
            "slug": "Object-Detection-Using-the-Statistics-of-Parts-Schneiderman-Kanade",
            "title": {
                "fragments": [],
                "text": "Object Detection Using the Statistics of Parts"
            },
            "tldr": {
                "abstractSimilarityScore": 57,
                "text": "A trainable object detector achieves reliable and efficient detection of human faces and passenger cars with out-of-plane rotation."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1891864"
                        ],
                        "name": "Gyuri Dork\u00f3",
                        "slug": "Gyuri-Dork\u00f3",
                        "structuredName": {
                            "firstName": "Gyuri",
                            "lastName": "Dork\u00f3",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Gyuri Dork\u00f3"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2462253"
                        ],
                        "name": "C. Schmid",
                        "slug": "C.-Schmid",
                        "structuredName": {
                            "firstName": "Cordelia",
                            "lastName": "Schmid",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Schmid"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 230,
                                "start": 224
                            }
                        ],
                        "text": "For the Harris-Laplace detector and the affine invariant interest point detector, we normalized the regions around the interest points to square patches with a side length of w \u00bc 6 I (ajar to the value used by Mikolajczyk and Schmid in [27])."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 70,
                                "start": 64
                            }
                        ],
                        "text": "Another object recognition approach was introduced by Dorko and Schmid [6]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 55,
                                "start": 49
                            }
                        ],
                        "text": "The authors are grateful to David Lowe, Cordelia Schmid, and Krystian Mikolajczyk for providing the binaries of their detectors/descriptors, available on the Web."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 61,
                                "start": 55
                            }
                        ],
                        "text": "Based on the evaluation of interest point detectors by Schmid et al. [31], we decided to use the scale invariant Harris-Laplace detector [26] and the affine invariant interest point detector [27], both by Mikolajczyk and Schmid."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 110,
                                "start": 104
                            }
                        ],
                        "text": "This choice was partly based on the performance evaluation of local descriptors done by Mikolajczyk and Schmid [28]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 75,
                                "start": 72
                            }
                        ],
                        "text": "Another object recognition approach was introduced by Dork o and Schmid [7]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 7887211,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "96d9ab468299fe51a4e14d86d8ea953ccf62b900",
            "isKey": true,
            "numCitedBy": 355,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce a novel method for constructing and selecting scale-invariant object parts. Scale-invariant local descriptors are first grouped into basic parts. A classifier is then learned for each of these parts, and feature selection is used to determine the most discriminative ones. This approach allows robust pan detection, and it is invariant under scale changes-that is, neither the training images nor the test images have to be normalized. The proposed method is evaluated in car detection tasks with significant variations in viewing conditions, and promising results are demonstrated. Different local regions, classifiers and feature selection methods are quantitatively compared. Our evaluation shows that local invariant descriptors are an appropriate representation for object classes such as cars, and it underlines the importance of feature selection."
            },
            "slug": "Selection-of-scale-invariant-parts-for-object-class-Dork\u00f3-Schmid",
            "title": {
                "fragments": [],
                "text": "Selection of scale-invariant parts for object class recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The evaluation shows that local invariant descriptors are an appropriate representation for object classes such as cars, and it underlines the importance of feature selection."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings Ninth IEEE International Conference on Computer Vision"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688882"
                        ],
                        "name": "Yann LeCun",
                        "slug": "Yann-LeCun",
                        "structuredName": {
                            "firstName": "Yann",
                            "lastName": "LeCun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yann LeCun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "13919023"
                        ],
                        "name": "F. Huang",
                        "slug": "F.-Huang",
                        "structuredName": {
                            "firstName": "Fu",
                            "lastName": "Huang",
                            "middleNames": [
                                "Jie"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Huang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "52184096"
                        ],
                        "name": "L. Bottou",
                        "slug": "L.-Bottou",
                        "structuredName": {
                            "firstName": "L\u00e9on",
                            "lastName": "Bottou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Bottou"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 126,
                                "start": 122
                            }
                        ],
                        "text": "For information on obtaining reprints of this article, please send e-mail to: tpami@computer.org, and reference IEEECS Log Number TPAMI-0346-0704."
                    },
                    "intents": []
                }
            ],
            "corpusId": 712708,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f354310098e09c1e1dc88758fca36767fd9d084d",
            "isKey": false,
            "numCitedBy": 1306,
            "numCiting": 41,
            "paperAbstract": {
                "fragments": [],
                "text": "We assess the applicability of several popular learning methods for the problem of recognizing generic visual categories with invariance to pose, lighting, and surrounding clutter. A large dataset comprising stereo image pairs of 50 uniform-colored toys under 36 azimuths, 9 elevations, and 6 lighting conditions was collected (for a total of 194,400 individual images). The objects were 10 instances of 5 generic categories: four-legged animals, human figures, airplanes, trucks, and cars. Five instances of each category were used for training, and the other five for testing. Low-resolution grayscale images of the objects with various amounts of variability and surrounding clutter were used for training and testing. Nearest neighbor methods, support vector machines, and convolutional networks, operating on raw pixels or on PCA-derived features were tested. Test error rates for unseen object instances placed on uniform backgrounds were around 13% for SVM and 7% for convolutional nets. On a segmentation/recognition task with highly cluttered images, SVM proved impractical, while convolutional nets yielded 16/7% error. A real-time version of the system was implemented that can detect and classify objects in natural scenes at around 10 frames per second."
            },
            "slug": "Learning-methods-for-generic-object-recognition-to-LeCun-Huang",
            "title": {
                "fragments": [],
                "text": "Learning methods for generic object recognition with invariance to pose and lighting"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "A real-time version of the system was implemented that can detect and classify objects in natural scenes at around 10 frames per second and proved impractical, while convolutional nets yielded 16/7% error."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 2004 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2004. CVPR 2004."
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2797063"
                        ],
                        "name": "S. Agarwal",
                        "slug": "S.-Agarwal",
                        "structuredName": {
                            "firstName": "Shivani",
                            "lastName": "Agarwal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Agarwal"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144590225"
                        ],
                        "name": "D. Roth",
                        "slug": "D.-Roth",
                        "structuredName": {
                            "firstName": "Dan",
                            "lastName": "Roth",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Roth"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 36,
                                "start": 20
                            }
                        ],
                        "text": "To give an example, Agarwal and Roth [1] present small rectangular regions which contain just the object of interest (a car viewed from the side)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 8,
                                "start": 5
                            }
                        ],
                        "text": "[8], [2]) show the objects with just small variations in scale and objects are generall y viewed at similar poses."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 8,
                                "start": 5
                            }
                        ],
                        "text": "[9], [2], [35]) use just one kind o f description method, we combine multiple information extraction methods to capture the essential ch racteristics of various object categories (e."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 101,
                                "start": 98
                            }
                        ],
                        "text": "This error rate is calculated as the percentage of the a rea under the ROC-curve (for details see [2])."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 28,
                                "start": 12
                            }
                        ],
                        "text": "The idea of Agarwal and Roth was picked up by Leibe et al. [20], who use this codebook of appearance and add an implicit shape model."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 33,
                                "start": 30
                            }
                        ],
                        "text": "For example, Agarwal and Roth [2] use Winnow as the underlying learning algorithm for the recognition of cars from side views."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 29,
                                "start": 13
                            }
                        ],
                        "text": "For example, Agarwal and Roth [1] use Winnow as the underlying learning algorithm for the recognition of cars from side views."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 58,
                                "start": 42
                            }
                        ],
                        "text": "But, in their approach, as in the work of Agarwal and Roth, the authors manually crop out the objects for training to reduce complexity."
                    },
                    "intents": []
                }
            ],
            "corpusId": 262977,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3d081b80b1850df9b1e382f97a7a244890d6485e",
            "isKey": true,
            "numCitedBy": 638,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "We present an approach for learning to detect objects in still gray images, that is based on a sparse, part-based representation of objects. A vocabulary of information-rich object parts is automatically constructed from a set of sample images of the object class of interest. Images are then represented using parts from this vocabulary, along with spatial relations observed among them. Based on this representation, a feature-efficient learning algorithm is used to learn to detect instances of the object class. The framework developed can be applied to any object with distinguishable parts in a relatively fixed spatial configuration. We report experiments on images of side views of cars. Our experiments show that the method achieves high detection accuracy on a difficult test set of real-world images, and is highly robust to partial occlusion and background variation.In addition, we discuss and offer solutions to several methodological issues that are significant for the research community to be able to evaluate object detection approaches."
            },
            "slug": "Learning-a-Sparse-Representation-for-Object-Agarwal-Roth",
            "title": {
                "fragments": [],
                "text": "Learning a Sparse Representation for Object Detection"
            },
            "tldr": {
                "abstractSimilarityScore": 65,
                "text": "An approach for learning to detect objects in still gray images, that is based on a sparse, part-based representation of objects, that achieves high detection accuracy on a difficult test set of real-world images, and is highly robust to partial occlusion and background variation."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143865718"
                        ],
                        "name": "V. Ferrari",
                        "slug": "V.-Ferrari",
                        "structuredName": {
                            "firstName": "Vittorio",
                            "lastName": "Ferrari",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Ferrari"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1704728"
                        ],
                        "name": "T. Tuytelaars",
                        "slug": "T.-Tuytelaars",
                        "structuredName": {
                            "firstName": "Tinne",
                            "lastName": "Tuytelaars",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Tuytelaars"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1681236"
                        ],
                        "name": "L. Gool",
                        "slug": "L.-Gool",
                        "structuredName": {
                            "firstName": "Luc",
                            "lastName": "Gool",
                            "middleNames": [
                                "Van"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Gool"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[10] present an approach where object recognition works even if aggravating factors like background clutter, scale variations or occlusion are very strong."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5853861,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7706afc51a71a20d088b494672085f763798ba7a",
            "isKey": false,
            "numCitedBy": 159,
            "numCiting": 51,
            "paperAbstract": {
                "fragments": [],
                "text": "Methods based on local, viewpoint invariant features have proven capable of recognizing objects in spite of viewpoint changes, occlusion and clutter. However, these approaches fail when these factors are too strong, due to the limited repeatability and discriminative power of the features. As additional shortcomings, the objects need to be rigid and only their approximate location is found. We present a novel Object Recognition approach which overcomes these limitations. An initial set of feature correspondences is first generated. The method anchors on it and then gradually explores the surrounding area, trying to construct more and more matching features, increasingly farther from the initial ones. The resulting process covers the object with matches, and simultaneously separates the correct matches from the wrong ones. Hence, recognition and segmentation are achieved at the same time. Only very few correct initial matches suffice for reliable recognition. The experimental results demonstrate the stronger power of the presented method in dealing with extensive clutter, dominant occlusion, large scale and viewpoint changes. Moreover non-rigid deformations are explicitly taken into account, and the approximative contours of the object are produced. The approach can extend any viewpoint invariant feature extractor."
            },
            "slug": "Simultaneous-Object-Recognition-and-Segmentation-by-Ferrari-Tuytelaars",
            "title": {
                "fragments": [],
                "text": "Simultaneous Object Recognition and Segmentation by Image Exploration"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A novel Object Recognition approach which overcomes limitations in dealing with extensive clutter, dominant occlusion, large scale and viewpoint changes, and can extend any viewpoint invariant feature extractor."
            },
            "venue": {
                "fragments": [],
                "text": "Toward Category-Level Object Recognition"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2110604335"
                        ],
                        "name": "Markus Weber",
                        "slug": "Markus-Weber",
                        "structuredName": {
                            "firstName": "Markus",
                            "lastName": "Weber",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Markus Weber"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1678311"
                        ],
                        "name": "M. Welling",
                        "slug": "M.-Welling",
                        "structuredName": {
                            "firstName": "Max",
                            "lastName": "Welling",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Welling"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1690922"
                        ],
                        "name": "P. Perona",
                        "slug": "P.-Perona",
                        "structuredName": {
                            "firstName": "Pietro",
                            "lastName": "Perona",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Perona"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 52,
                                "start": 48
                            }
                        ],
                        "text": "Index Terms\u2014Boosting, object categorization, object localization."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 9,
                                "start": 5
                            }
                        ],
                        "text": "E-mail: {opelt, pinz, fussenegger}@tugraz.at."
                    },
                    "intents": []
                }
            ],
            "corpusId": 8970876,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1cf1527807ebb16020b04d4166e7ba8d27652302",
            "isKey": false,
            "numCitedBy": 757,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a method to learn object class models from unlabeled and unsegmented cluttered scenes for the purpose of visual object recognition. We focus on a particular type of model where objects are represented as flexible constellations of rigid parts (features). The variability within a class is represented by a joint probability density function (pdf) on the shape of the constellation and the output of part detectors. In a first stage, the method automatically identifies distinctive parts in the training set by applying a clustering algorithm to patterns selected by an interest operator. It then learns the statistical shape model using expectation maximization. The method achieves very good classification results on human faces and rear views of cars."
            },
            "slug": "Unsupervised-Learning-of-Models-for-Recognition-Weber-Welling",
            "title": {
                "fragments": [],
                "text": "Unsupervised Learning of Models for Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 70,
                "text": "A method to learn object class models from unlabeled and unsegmented cluttered cluttered scenes for the purpose of visual object recognition that achieves very good classification results on human faces and rear views of cars."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1789756"
                        ],
                        "name": "B. Leibe",
                        "slug": "B.-Leibe",
                        "structuredName": {
                            "firstName": "B.",
                            "lastName": "Leibe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Leibe"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1732672"
                        ],
                        "name": "A. Leonardis",
                        "slug": "A.-Leonardis",
                        "structuredName": {
                            "firstName": "Ale\u0161",
                            "lastName": "Leonardis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Leonardis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48920094"
                        ],
                        "name": "B. Schiele",
                        "slug": "B.-Schiele",
                        "structuredName": {
                            "firstName": "Bernt",
                            "lastName": "Schiele",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Schiele"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6533591,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "38101fac622a70b78f13625fc6502000b8756d3a",
            "isKey": false,
            "numCitedBy": 1036,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a method for object categorization in real-world scenes. Following a common consensus in the field, we do not assume that a figure- ground segmentation is available prior to recognition. However, in contrast to most standard approaches for object class recognition, our approach automati- cally segments the object as a result of the categorization. This combination of recognition and segmentation into one process is made pos- sible by our use of an Implicit Shape Model, which integrates both into a common probabilistic framework. In addition to the recognition and segmentation result, it also generates a per-pixel confidence measure specifying the area that supports a hypothesis and how much it can be trusted. We use this confidence to derive a nat- ural extension of the approach to handle multiple objects in a scene and resolve ambiguities between overlapping hypotheses with a novel MDL-based criterion. In addition, we present an extensive evaluation of our method on a standard dataset for car detection and compare its performance to existing methods from the literature. Our results show that the proposed method significantly outper- forms previously published methods while needing one order of magnitude less training examples. Finally, we present results for articulated objects, which show that the proposed method can categorize and segment unfamiliar objects in differ- ent articulations and with widely varying texture patterns, even under significant partial occlusion."
            },
            "slug": "Combined-Object-Categorization-and-Segmentation-an-Leibe-Leonardis",
            "title": {
                "fragments": [],
                "text": "Combined Object Categorization and Segmentation With an Implicit Shape Model"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "Results for articulated objects, which show that the proposed method can categorize and segment unfamiliar objects in differ- ent articulations and with widely varying texture patterns, even under significant partial occlusion."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1793750"
                        ],
                        "name": "C. Wallraven",
                        "slug": "C.-Wallraven",
                        "structuredName": {
                            "firstName": "C.",
                            "lastName": "Wallraven",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Wallraven"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3033284"
                        ],
                        "name": "B. Caputo",
                        "slug": "B.-Caputo",
                        "structuredName": {
                            "firstName": "Barbara",
                            "lastName": "Caputo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Caputo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144813423"
                        ],
                        "name": "Arnulf B. A. Graf",
                        "slug": "Arnulf-B.-A.-Graf",
                        "structuredName": {
                            "firstName": "Arnulf",
                            "lastName": "Graf",
                            "middleNames": [
                                "B.",
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Arnulf B. A. Graf"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 8,
                                "start": 4
                            }
                        ],
                        "text": "Section 7 describes our experimental setup, presents experimental results, and compares them with other approaches for object recognition."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                }
            ],
            "corpusId": 4573035,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c393b31ca71e8c4dd7c8c5a11653b18447c90466",
            "isKey": false,
            "numCitedBy": 462,
            "numCiting": 37,
            "paperAbstract": {
                "fragments": [],
                "text": "Recent developments in computer vision have shown that local features can provide efficient representations suitable for robust object recognition. Support vector machines have been established as powerful learning algorithms with good generalization capabilities. We combine these two approaches and propose a general kernel method for recognition with local features. We show that the proposed kernel satisfies the Mercer condition and that it is, suitable for many established local feature frameworks. Large-scale recognition results are presented on three different databases, which demonstrate that SVMs with the proposed kernel perform better than standard matching techniques on local features. In addition, experiments on noisy and occluded images show that local feature representations significantly outperform global approaches."
            },
            "slug": "Recognition-with-local-features:-the-kernel-recipe-Wallraven-Caputo",
            "title": {
                "fragments": [],
                "text": "Recognition with local features: the kernel recipe"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "Large-scale recognition results are presented, which demonstrate that SVMs with the proposed kernel perform better than standard matching techniques on local features and that local feature representations significantly outperform global approaches."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings Ninth IEEE International Conference on Computer Vision"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2276554"
                        ],
                        "name": "R. Fergus",
                        "slug": "R.-Fergus",
                        "structuredName": {
                            "firstName": "Rob",
                            "lastName": "Fergus",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Fergus"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1690922"
                        ],
                        "name": "P. Perona",
                        "slug": "P.-Perona",
                        "structuredName": {
                            "firstName": "Pietro",
                            "lastName": "Perona",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Perona"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688869"
                        ],
                        "name": "Andrew Zisserman",
                        "slug": "Andrew-Zisserman",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Zisserman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Zisserman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 3,
                                "start": 0
                            }
                        ],
                        "text": "[8], [2]) show the objects with just small variations in scale and objects are generall y viewed at similar poses."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 100,
                                "start": 97
                            }
                        ],
                        "text": "Some examples of the Caltech database, categories cars(rear) , motorbikes and airplanes, used in [8]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 5745749,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "62837ab473124ea43cb8d7c6a4b4ee0f6f14e8c5",
            "isKey": false,
            "numCitedBy": 2487,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a method to learn and recognize object class models from unlabeled and unsegmented cluttered scenes in a scale invariant manner. Objects are modeled as flexible constellations of parts. A probabilistic representation is used for all aspects of the object: shape, appearance, occlusion and relative scale. An entropy-based feature detector is used to select regions and their scale within the image. In learning the parameters of the scale-invariant object model are estimated. This is done using expectation-maximization in a maximum-likelihood setting. In recognition, this model is used in a Bayesian manner to classify images. The flexible nature of the model is demonstrated by excellent results over a range of datasets including geometrically constrained classes (e.g. faces, cars) and flexible objects (such as animals)."
            },
            "slug": "Object-class-recognition-by-unsupervised-learning-Fergus-Perona",
            "title": {
                "fragments": [],
                "text": "Object class recognition by unsupervised scale-invariant learning"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The flexible nature of the model is demonstrated by excellent results over a range of datasets including geometrically constrained classes (e.g. faces, cars) and flexible objects (such as animals)."
            },
            "venue": {
                "fragments": [],
                "text": "2003 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2003. Proceedings."
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1724876"
                        ],
                        "name": "P. Carbonetto",
                        "slug": "P.-Carbonetto",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Carbonetto",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Carbonetto"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1737568"
                        ],
                        "name": "N. D. Freitas",
                        "slug": "N.-D.-Freitas",
                        "structuredName": {
                            "firstName": "Nando",
                            "lastName": "Freitas",
                            "middleNames": [
                                "de"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. D. Freitas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145602732"
                        ],
                        "name": "Kobus Barnard",
                        "slug": "Kobus-Barnard",
                        "structuredName": {
                            "firstName": "Kobus",
                            "lastName": "Barnard",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kobus Barnard"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 3,
                                "start": 0
                            }
                        ],
                        "text": "[4] present an approach for contextual obje ct recognition based on a segmented image."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 8270758,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7925221db50d93142cb5e5a4e31d6b72b2c5af8b",
            "isKey": false,
            "numCitedBy": 315,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "We consider object recognition as the process of attaching meaningful labels to specific regions of an image, and propose a model that learns spatial relationships between objects. Given a set of images and their associated text (e.g. keywords, captions, descriptions), the objective is to segment an image, in either a crude or sophisticated fashion, then to find the proper associations between words and regions. Previous models are limited by the scope of the representation. In particular, they fail to exploit spatial context in the images and words. We develop a more expressive model that takes this into account. We formulate a spatially consistent probabilistic mapping between continuous image feature vectors and the supplied word tokens. By learning both word-to-region associations and object relations, the proposed model augments scene segmentations due to smoothing implicit in spatial consistency. Context introduces cycles to the undirected graph, so we cannot rely on a straightforward implementation of the EM algorithm for estimating the model parameters and densities of the unknown alignment variables. Instead, we develop an approximate EM algorithm that uses loopy belief propagation in the inference step and iterative scaling on the pseudo-likelihood approximation in the parameter update step. The experiments indicate that our approximate inference and learning algorithm converges to good local solutions. Experiments on a diverse array of images show that spatial context considerably improves the accuracy of object recognition. Most significantly, spatial context combined with a nonlinear discrete object representation allows our models to cope well with over-segmented scenes."
            },
            "slug": "A-Statistical-Model-for-General-Contextual-Object-Carbonetto-Freitas",
            "title": {
                "fragments": [],
                "text": "A Statistical Model for General Contextual Object Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "Experiments show that spatial context considerably improves the accuracy of object recognition, and an approximate EM algorithm that uses loopy belief propagation in the inference step and iterative scaling on the pseudo-likelihood approximation in the parameter update step converges to good local solutions."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35238678"
                        ],
                        "name": "D. Lowe",
                        "slug": "D.-Lowe",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Lowe",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Lowe"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 161,
                                "start": 157
                            }
                        ],
                        "text": "Lowe introduced an interest point detector which is invaria nt to translation, scaling and rotation and is minimally affected by small distortions and noise [21]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 78,
                                "start": 74
                            }
                        ],
                        "text": "In addition we use Lowe\u2019s DoG (diffe rence of Gaussian) keypoint detector [21] which is strongly related to SIFTs as local descriptors."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 135,
                                "start": 131
                            }
                        ],
                        "text": "Vector quantization was used to reduce the number of interest point s btained with the difference of Gaussian (DoG) point detector [21]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 16,
                                "start": 12
                            }
                        ],
                        "text": "As shown in [21] the description of the patches with SIFTs is d one by multiple representations in various orientation planes."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 119,
                                "start": 115
                            }
                        ],
                        "text": "In view of the performance evaluation of local descriptors done by Mikolajczyk and Sch mid [26] we took SIFTs (see [21]) as a third and Moment Invariants (see [15]) as a fourth choice."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 5258236,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f9f836d28f52ad260213d32224a6d227f8e8849a",
            "isKey": true,
            "numCitedBy": 16258,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "An object recognition system has been developed that uses a new class of local image features. The features are invariant to image scaling, translation, and rotation, and partially invariant to illumination changes and affine or 3D projection. These features share similar properties with neurons in inferior temporal cortex that are used for object recognition in primate vision. Features are efficiently detected through a staged filtering approach that identifies stable points in scale space. Image keys are created that allow for local geometric deformations by representing blurred image gradients in multiple orientation planes and at multiple scales. The keys are used as input to a nearest neighbor indexing method that identifies candidate object matches. Final verification of each match is achieved by finding a low residual least squares solution for the unknown model parameters. Experimental results show that robust object recognition can be achieved in cluttered partially occluded images with a computation time of under 2 seconds."
            },
            "slug": "Object-recognition-from-local-scale-invariant-Lowe",
            "title": {
                "fragments": [],
                "text": "Object recognition from local scale-invariant features"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "Experimental results show that robust object recognition can be achieved in cluttered partially occluded images with a computation time of under 2 seconds."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Seventh IEEE International Conference on Computer Vision"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712041"
                        ],
                        "name": "K. Mikolajczyk",
                        "slug": "K.-Mikolajczyk",
                        "structuredName": {
                            "firstName": "Krystian",
                            "lastName": "Mikolajczyk",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Mikolajczyk"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2462253"
                        ],
                        "name": "C. Schmid",
                        "slug": "C.-Schmid",
                        "structuredName": {
                            "firstName": "Cordelia",
                            "lastName": "Schmid",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Schmid"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 230,
                                "start": 208
                            }
                        ],
                        "text": "For the Harris-Laplace detector and the affine invariant interest point detector, we normalized the regions around the interest points to square patches with a side length of w \u00bc 6 I (ajar to the value used by Mikolajczyk and Schmid in [27])."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 70,
                                "start": 64
                            }
                        ],
                        "text": "Another object recognition approach was introduced by Dorko and Schmid [6]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 55,
                                "start": 49
                            }
                        ],
                        "text": "The authors are grateful to David Lowe, Cordelia Schmid, and Krystian Mikolajczyk for providing the binaries of their detectors/descriptors, available on the Web."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 227,
                                "start": 205
                            }
                        ],
                        "text": "Based on the evaluation of interest point detectors by Schmid et al. [31], we decided to use the scale invariant Harris-Laplace detector [26] and the affine invariant interest point detector [27], both by Mikolajczyk and Schmid."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 115,
                                "start": 111
                            }
                        ],
                        "text": "This choice was partly based on the performance evaluation of local descriptors done by Mikolajczyk and Schmid [28]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2572455,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "69401bfdafab7cde00bb8e5b2f6c28e9d72d8cfb",
            "isKey": true,
            "numCitedBy": 3666,
            "numCiting": 54,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we compare the performance of descriptors computed for local interest regions, as, for example, extracted by the Harris-Affine detector [Mikolajczyk, K and Schmid, C, 2004]. Many different descriptors have been proposed in the literature. It is unclear which descriptors are more appropriate and how their performance depends on the interest region detector. The descriptors should be distinctive and at the same time robust to changes in viewing conditions as well as to errors of the detector. Our evaluation uses as criterion recall with respect to precision and is carried out for different image transformations. We compare shape context [Belongie, S, et al., April 2002], steerable filters [Freeman, W and Adelson, E, Setp. 1991], PCA-SIFT [Ke, Y and Sukthankar, R, 2004], differential invariants [Koenderink, J and van Doorn, A, 1987], spin images [Lazebnik, S, et al., 2003], SIFT [Lowe, D. G., 1999], complex filters [Schaffalitzky, F and Zisserman, A, 2002], moment invariants [Van Gool, L, et al., 1996], and cross-correlation for different types of interest regions. We also propose an extension of the SIFT descriptor and show that it outperforms the original method. Furthermore, we observe that the ranking of the descriptors is mostly independent of the interest region detector and that the SIFT-based descriptors perform best. Moments and steerable filters show the best performance among the low dimensional descriptors."
            },
            "slug": "A-performance-evaluation-of-local-descriptors-Mikolajczyk-Schmid",
            "title": {
                "fragments": [],
                "text": "A performance evaluation of local descriptors"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "It is observed that the ranking of the descriptors is mostly independent of the interest region detector and that the SIFT-based descriptors perform best and Moments and steerable filters show the best performance among the low dimensional descriptors."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3205375"
                        ],
                        "name": "T. Lindeberg",
                        "slug": "T.-Lindeberg",
                        "structuredName": {
                            "firstName": "Tony",
                            "lastName": "Lindeberg",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Lindeberg"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 723210,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b02f474196fb9bd61fa3d418a7ba8ac500e8d422",
            "isKey": false,
            "numCitedBy": 2940,
            "numCiting": 80,
            "paperAbstract": {
                "fragments": [],
                "text": "The fact that objects in the world appear in different ways depending on the scale of observation has important implications if one aims at describing them. It shows that the notion of scale is of utmost importance when processing unknown measurement data by automatic methods. In their seminal works, Witkin (1983) and Koenderink (1984) proposed to approach this problem by representing image structures at different scales in a so-called scale-space representation. Traditional scale-space theory building on this work, however, does not address the problem of how to select local appropriate scales for further analysis. This article proposes a systematic methodology for dealing with this problem. A framework is presented for generating hypotheses about interesting scale levels in image data, based on a general principle stating that local extrema over scales of different combinations of \u03b3-normalized derivatives are likely candidates to correspond to interesting structures. Specifically, it is shown how this idea can be used as a major mechanism in algorithms for automatic scale selection, which adapt the local scales of processing to the local image structure.Support for the proposed approach is given in terms of a general theoretical investigation of the behaviour of the scale selection method under rescalings of the input pattern and by integration with different types of early visual modules, including experiments on real-world and synthetic data. Support is also given by a detailed analysis of how different types of feature detectors perform when integrated with a scale selection mechanism and then applied to characteristic model patterns. Specifically, it is described in detail how the proposed methodology applies to the problems of blob detection, junction detection, edge detection, ridge detection and local frequency estimation.In many computer vision applications, the poor performance of the low-level vision modules constitutes a major bottleneck. It is argued that the inclusion of mechanisms for automatic scale selection is essential if we are to construct vision systems to automatically analyse complex unknown environments."
            },
            "slug": "Feature-Detection-with-Automatic-Scale-Selection-Lindeberg",
            "title": {
                "fragments": [],
                "text": "Feature Detection with Automatic Scale Selection"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "It is shown how the proposed methodology applies to the problems of blob detection, junction detection, edge detection, ridge detection and local frequency estimation and how it can be used as a major mechanism in algorithms for automatic scale selection, which adapt the local scales of processing to the local image structure."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685020"
                        ],
                        "name": "D. Comaniciu",
                        "slug": "D.-Comaniciu",
                        "structuredName": {
                            "firstName": "Dorin",
                            "lastName": "Comaniciu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Comaniciu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145776090"
                        ],
                        "name": "P. Meer",
                        "slug": "P.-Meer",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Meer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Meer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 119,
                                "start": 116
                            }
                        ],
                        "text": "We compare its performance for object categorization with the well known Mean-Shift algorithm by Comaniciu and Meer [5]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 154,
                                "start": 151
                            }
                        ],
                        "text": "extract regions of homogeneity which are obtained by using two different image segmentation methods: we compare the well known Mean-Shift-Segmentation [5] with our Similarity-MeasureSegmentation."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 172,
                                "start": 169
                            }
                        ],
                        "text": "5) Search all regions smaller than a minimum value regmin, and merge each region with the nearest region larger than regmin (same process as for Mean-Shift segmentation [5])."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 114,
                                "start": 96
                            }
                        ],
                        "text": "We compare its performance for object categorization with the well-known MeanShift algorithm by Comaniciu and Meer [5]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 691081,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "74f4ecc3e4e5b91fbb54330b285ed5214afe2001",
            "isKey": true,
            "numCitedBy": 11481,
            "numCiting": 122,
            "paperAbstract": {
                "fragments": [],
                "text": "A general non-parametric technique is proposed for the analysis of a complex multimodal feature space and to delineate arbitrarily shaped clusters in it. The basic computational module of the technique is an old pattern recognition procedure: the mean shift. For discrete data, we prove the convergence of a recursive mean shift procedure to the nearest stationary point of the underlying density function and, thus, its utility in detecting the modes of the density. The relation of the mean shift procedure to the Nadaraya-Watson estimator from kernel regression and the robust M-estimators; of location is also established. Algorithms for two low-level vision tasks discontinuity-preserving smoothing and image segmentation - are described as applications. In these algorithms, the only user-set parameter is the resolution of the analysis, and either gray-level or color images are accepted as input. Extensive experimental results illustrate their excellent performance."
            },
            "slug": "Mean-Shift:-A-Robust-Approach-Toward-Feature-Space-Comaniciu-Meer",
            "title": {
                "fragments": [],
                "text": "Mean Shift: A Robust Approach Toward Feature Space Analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "It is proved the convergence of a recursive mean shift procedure to the nearest stationary point of the underlying density function and, thus, its utility in detecting the modes of the density."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145602732"
                        ],
                        "name": "Kobus Barnard",
                        "slug": "Kobus-Barnard",
                        "structuredName": {
                            "firstName": "Kobus",
                            "lastName": "Barnard",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kobus Barnard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2446509"
                        ],
                        "name": "P. D. Sahin",
                        "slug": "P.-D.-Sahin",
                        "structuredName": {
                            "firstName": "Pinar",
                            "lastName": "Sahin",
                            "middleNames": [
                                "Duygulu"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. D. Sahin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46560705"
                        ],
                        "name": "R. Guru",
                        "slug": "R.-Guru",
                        "structuredName": {
                            "firstName": "Raghavendra",
                            "lastName": "Guru",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Guru"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1705821"
                        ],
                        "name": "Prasad Gabbur",
                        "slug": "Prasad-Gabbur",
                        "structuredName": {
                            "firstName": "Prasad",
                            "lastName": "Gabbur",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Prasad Gabbur"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144016256"
                        ],
                        "name": "D. Forsyth",
                        "slug": "D.-Forsyth",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Forsyth",
                            "middleNames": [
                                "Alexander"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Forsyth"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 3,
                                "start": 0
                            }
                        ],
                        "text": "[3] use thes e s gmentation methods for learning object categories."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 13030565,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b110a17f078348aef32861f69cb555775799206a",
            "isKey": false,
            "numCitedBy": 78,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "We work with a model of object recognition where words must be placed on image regions. This approach means that large scale experiments are relatively easy, so we can evaluate the effects of various early and midlevel vision algorithms on recognition performance. We evaluate various image segmentation algorithms by determining word prediction accuracy for images segmented in various ways and represented by various features. We take the view that good segmentations respect object boundaries, and so word prediction should be better for a better segmentation. However, it is usually very difficult in practice to obtain segmentations that do not break up objects, so most practitioners attempt to merge segments to get better putative object representations. We demonstrate that our paradigm of word prediction easily allows us to predict potentially useful segment merges, even for segments that do not look similar (for example, merging the black and white halves of a penguin is not possible with feature-based segmentation; the main cue must be \"familiar configuration\"). These studies focus on unsupervised learning of recognition. However, we show that word prediction can be markedly improved by providing supervised information for a relatively small number of regions together with large quantities of unsupervised information. This supervisory information allows a better and more discriminative choice of features and breaks possible symmetries."
            },
            "slug": "The-effects-of-segmentation-and-feature-choice-in-a-Barnard-Sahin",
            "title": {
                "fragments": [],
                "text": "The effects of segmentation and feature choice in a translation model of object recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "It is shown that word prediction can be markedly improved by providing supervised information for a relatively small number of regions together with large quantities of unsupervised information, which allows a better and more discriminative choice of features and breaks possible symmetries."
            },
            "venue": {
                "fragments": [],
                "text": "2003 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2003. Proceedings."
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7785990"
                        ],
                        "name": "A. Salgian",
                        "slug": "A.-Salgian",
                        "structuredName": {
                            "firstName": "Andrea",
                            "lastName": "Salgian",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Salgian"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31614700"
                        ],
                        "name": "R. Nelson",
                        "slug": "R.-Nelson",
                        "structuredName": {
                            "firstName": "Randal",
                            "lastName": "Nelson",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Nelson"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Another interesting approach was introduced by Selinger and Nelson [ 34 ] who perform object recognition in cluttered backgrounds."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6567566,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "16614567ed9ea324d99f828c1f48f542f44a6be4",
            "isKey": false,
            "numCitedBy": 18,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "Appearance-based object recognition systems are currently the most successful approach for dealing with 3D recognition of arbitrary objects in the presence of clutter and occlusion. However, no current system seems directly scalable to human performance levels in this domain. We describe a series of experiments on a previously described object recognition system that try to see, if any, which design axes of such systems hold the greatest potential for improving performance. We look at the potential effect of different design modifications, and conclude that the greatest leverage lies at the level of intermediate feature construction."
            },
            "slug": "Improving-appearance-based-object-recognition-in-Salgian-Nelson",
            "title": {
                "fragments": [],
                "text": "Improving appearance-based object recognition in cluttered backgrounds"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "A series of experiments on a previously described object recognition system try to see, if any, which design axes of such systems hold the greatest potential for improving performance, and conclude that the greatest leverage lies at the level of intermediate feature construction."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings 15th International Conference on Pattern Recognition. ICPR-2000"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1681236"
                        ],
                        "name": "L. Gool",
                        "slug": "L.-Gool",
                        "structuredName": {
                            "firstName": "Luc",
                            "lastName": "Gool",
                            "middleNames": [
                                "Van"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Gool"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2525101"
                        ],
                        "name": "T. Moons",
                        "slug": "T.-Moons",
                        "structuredName": {
                            "firstName": "Theo",
                            "lastName": "Moons",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Moons"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153210127"
                        ],
                        "name": "Dorin Ungureanu",
                        "slug": "Dorin-Ungureanu",
                        "structuredName": {
                            "firstName": "Dorin",
                            "lastName": "Ungureanu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dorin Ungureanu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 163,
                                "start": 159
                            }
                        ],
                        "text": "In view of the performance evaluation of local descriptors done by Mikolajczyk and Sch mid [26] we took SIFTs (see [21]) as a third and Moment Invariants (see [15]) as a fourth choice."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 71,
                                "start": 67
                            }
                        ],
                        "text": "Additionally we took all five second order Invariants described in [15]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 17,
                                "start": 13
                            }
                        ],
                        "text": "According to [15] we selected first and second order Moment In variants."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 36152,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fbdfadd172c2ac3adfd18d497ab81491f3f5f80a",
            "isKey": false,
            "numCitedBy": 337,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "The paper contributes to the viewpoint invariant recognition of planar patterns, especially labels and signs under affine deformations. By their nature, the information of such \u2018eye-catchers\u2019 is not contained in the outline or frame \u2014 they often are affinely equivalent like parallelograms and ellipses \u2014 but in the intensity content within. Moment invariants are well suited for their recognition. They need a closed bounding contour, but this is comparatively easy to provide for the simple shapes considered. On the other hand, they characterize the intensity patterns without the need for error prone feature extraction. This paper uses moments as the basic features, but extends the literature in two respects: (1) deliberate mixes of different types of moments to keep the order of the moments (and hence also the sensitivity to noise) low and yet have a sufficiently large number to safeguard discriminant power; and (2) invariance with respect to photometric changes is incorporated in order to find the simplest moment invariants that can cope with changing lighting conditions which can hardly be avoided when changing viewpoint. The paper gives complete classifications of such affine / photometric moment invariants. Experiments are described that illustrate the use of some of them."
            },
            "slug": "Affine/-Photometric-Invariants-for-Planar-Intensity-Gool-Moons",
            "title": {
                "fragments": [],
                "text": "Affine/ Photometric Invariants for Planar Intensity Patterns"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This paper uses moments as the basic features, but extends the literature in two respects: deliberate mixes of different types of moments to keep the order of the moments low and yet have a sufficiently large number to safeguard discriminant power; and invariance with respect to photometric changes is incorporated in order to find the simplest moment invariants that can cope with changing lighting conditions."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685089"
                        ],
                        "name": "Pedro F. Felzenszwalb",
                        "slug": "Pedro-F.-Felzenszwalb",
                        "structuredName": {
                            "firstName": "Pedro",
                            "lastName": "Felzenszwalb",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Pedro F. Felzenszwalb"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1713089"
                        ],
                        "name": "D. Huttenlocher",
                        "slug": "D.-Huttenlocher",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Huttenlocher",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Huttenlocher"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Index Terms\u2014Boosting, object categorization, object localization."
                    },
                    "intents": []
                }
            ],
            "corpusId": 2277383,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cd9ab441df8b24f473a3635370c69620b00c1e60",
            "isKey": false,
            "numCitedBy": 2424,
            "numCiting": 90,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we present a computationally efficient framework for part-based modeling and recognition of objects. Our work is motivated by the pictorial structure models introduced by Fischler and Elschlager. The basic idea is to represent an object by a collection of parts arranged in a deformable configuration. The appearance of each part is modeled separately, and the deformable configuration is represented by spring-like connections between pairs of parts. These models allow for qualitative descriptions of visual appearance, and are suitable for generic recognition problems. We address the problem of using pictorial structure models to find instances of an object in an image as well as the problem of learning an object model from training examples, presenting efficient algorithms in both cases. We demonstrate the techniques by learning models that represent faces and human bodies and using the resulting models to locate the corresponding objects in novel images."
            },
            "slug": "Pictorial-Structures-for-Object-Recognition-Felzenszwalb-Huttenlocher",
            "title": {
                "fragments": [],
                "text": "Pictorial Structures for Object Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 73,
                "text": "A computationally efficient framework for part-based modeling and recognition of objects, motivated by the pictorial structure models introduced by Fischler and Elschlager, that allows for qualitative descriptions of visual appearance and is suitable for generic recognition problems."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2969789"
                        ],
                        "name": "C. Carson",
                        "slug": "C.-Carson",
                        "structuredName": {
                            "firstName": "Chad",
                            "lastName": "Carson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Carson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50172592"
                        ],
                        "name": "Serge J. Belongie",
                        "slug": "Serge-J.-Belongie",
                        "structuredName": {
                            "firstName": "Serge",
                            "lastName": "Belongie",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Serge J. Belongie"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143942875"
                        ],
                        "name": "H. Greenspan",
                        "slug": "H.-Greenspan",
                        "structuredName": {
                            "firstName": "Hayit",
                            "lastName": "Greenspan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Greenspan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143751119"
                        ],
                        "name": "Jitendra Malik",
                        "slug": "Jitendra-Malik",
                        "structuredName": {
                            "firstName": "Jitendra",
                            "lastName": "Malik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jitendra Malik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 3,
                                "start": 0
                            }
                        ],
                        "text": "[5] and [33]) are t ying to split images into background and prominent foreground objects."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 85,
                                "start": 82
                            }
                        ],
                        "text": "1) Similarity-Measure-Segmentation: Similar to other segmentation algorithms (see [5] and [33]) , we calculate several features for each pixel of the image, in a fi rst processing step."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14715074,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fedf7729b620ec2cf4e79705d2898f82e9a2ba66",
            "isKey": false,
            "numCitedBy": 1629,
            "numCiting": 111,
            "paperAbstract": {
                "fragments": [],
                "text": "Retrieving images from large and varied collections using image content as a key is a challenging and important problem. We present a new image representation that provides a transformation from the raw pixel data to a small set of image regions that are coherent in color and texture. This \"Blobworld\" representation is created by clustering pixels in a joint color-texture-position feature space. The segmentation algorithm is fully automatic and has been run on a collection of 10,000 natural images. We describe a system that uses the Blobworld representation to retrieve images from this collection. An important aspect of the system is that the user is allowed to view the internal representation of the submitted image and the query results. Similar systems do not offer the user this view into the workings of the system; consequently, query results from these systems can be inexplicable, despite the availability of knobs for adjusting the similarity metrics. By finding image regions that roughly correspond to objects, we allow querying at the level of objects rather than global image properties. We present results indicating that querying for images using Blobworld produces higher precision than does querying using color and texture histograms of the entire image in cases where the image contains distinctive objects."
            },
            "slug": "Blobworld:-Image-Segmentation-Using-and-Its-to-Carson-Belongie",
            "title": {
                "fragments": [],
                "text": "Blobworld: Image Segmentation Using Expectation-Maximization and Its Application to Image Querying"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "Results indicating that querying for images using Blobworld produces higher precision than does querying using color and texture histograms of the entire image in cases where the image contains distinctive objects are presented."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145266088"
                        ],
                        "name": "T. Leung",
                        "slug": "T.-Leung",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Leung",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Leung"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2511655"
                        ],
                        "name": "M. Burl",
                        "slug": "M.-Burl",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Burl",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Burl"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1690922"
                        ],
                        "name": "P. Perona",
                        "slug": "P.-Perona",
                        "structuredName": {
                            "firstName": "Pietro",
                            "lastName": "Perona",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Perona"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 147,
                                "start": 143
                            }
                        ],
                        "text": "A. Opelt, A. Pinz, and M. Fussenegger are with the Institute of Electrical Measurement and Measurement Signal Processing, Graz University of Technology, Schiesstattg."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 29742099,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "846b99d151892e70046e5ca541430be4ff67209f",
            "isKey": false,
            "numCitedBy": 57,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "Under a weak perspective camera model, the image plane coordinates in different views of a planar object are related by an affine transformation. Because of this property, researchers have attempted to use affine invariants for recognition. However, there are two problems with this approach: (1) objects or object classes with inherent variability cannot be adequately treated using invariants; and (2) in practice the calculated affine invariants can be quite sensitive to errors in the image plane measurements. In this paper we use probability distributions to address both of these difficulties. Under the assumption that the feature positions of a planar object can be modeled using a jointly Gaussian density, we have derived the joint density over the corresponding set of affine coordinates. Even when the assumptions of a planar object and a weak perspective camera model do not strictly hold, the results are useful because deviations from the ideal can be treated as deformability in the underlying object model."
            },
            "slug": "Probabilistic-affine-invariants-for-recognition-Leung-Burl",
            "title": {
                "fragments": [],
                "text": "Probabilistic affine invariants for recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "Under the assumption that the feature positions of a planar object can be modeled using a jointly Gaussian density, the joint density over the corresponding set of affine coordinates is derived."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings. 1998 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.98CB36231)"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712041"
                        ],
                        "name": "K. Mikolajczyk",
                        "slug": "K.-Mikolajczyk",
                        "structuredName": {
                            "firstName": "Krystian",
                            "lastName": "Mikolajczyk",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Mikolajczyk"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2462253"
                        ],
                        "name": "C. Schmid",
                        "slug": "C.-Schmid",
                        "structuredName": {
                            "firstName": "Cordelia",
                            "lastName": "Schmid",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Schmid"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 72,
                                "start": 68
                            }
                        ],
                        "text": "[30], we decided to use the scale invariant Harris-Laplace detector [24] and the affine invariant interest point detector [25], both by"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2326264,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "6647f56413722e812cb084fbb3597ba18ceada36",
            "isKey": false,
            "numCitedBy": 759,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a new method for detecting scale invariant interest points. The method is based on two recent results on scale space: (1) Interest points can be adapted to scale and give repeatable results (geometrically stable). (2) Local extrema over scale of normalized derivatives indicate the presence of characteristic local structures. Our method first computes a multi-scale representation for the Harris interest point detector. We then select points at which a local measure (the Laplacian) is maximal over scales. This allows a selection of distinctive points for which the characteristic scale is known. These points are invariant to scale, rotation and translation as well as robust to illumination changes and limited changes of viewpoint. For indexing, the image is characterized by a set of scale invariant points; the scale associated with each point allows the computation of a scale invariant descriptor. Our descriptors are, in addition, invariant to image rotation, of affine illumination changes and robust to small perspective deformations. Experimental results for indexing show an excellent performance up to a scale factor of 4 for a database with more than 5000 images."
            },
            "slug": "Indexing-based-on-scale-invariant-interest-points-Mikolajczyk-Schmid",
            "title": {
                "fragments": [],
                "text": "Indexing Based on Scale Invariant Interest Points"
            },
            "tldr": {
                "abstractSimilarityScore": 96,
                "text": "This paper presents a new method for detecting scale invariant interest points based on two recent results on scale space: 1) Interest points can be adapted to scale and give repeatable results (geometrically stable); 2) local extrema over scale of normalized derivatives indicate the presence of characteristic local structures."
            },
            "venue": {
                "fragments": [],
                "text": "ICCV"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46865129"
                        ],
                        "name": "Jianbo Shi",
                        "slug": "Jianbo-Shi",
                        "structuredName": {
                            "firstName": "Jianbo",
                            "lastName": "Shi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jianbo Shi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153652147"
                        ],
                        "name": "J. Malik",
                        "slug": "J.-Malik",
                        "structuredName": {
                            "firstName": "Jitendra",
                            "lastName": "Malik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Malik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 138,
                                "start": 134
                            }
                        ],
                        "text": "Based on the evaluation of interest point detectors by Schmid et al. [31], we decided to use the scale invariant Harris-Laplace detector [26] and the affine invariant interest point detector [27], both by Mikolajczyk and Schmid."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 127,
                                "start": 123
                            }
                        ],
                        "text": "For DoGs, we used the binary of Lowe that already exports the local descriptors (SIFTs) of a circular region with a radius of eight pixels around the detected interest points."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14848918,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b94c7ff9532ab26c3aedbee3988ec4c7a237c173",
            "isKey": false,
            "numCitedBy": 12819,
            "numCiting": 55,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a novel approach for solving the perceptual grouping problem in vision. Rather than focusing on local features and their consistencies in the image data, our approach aims at extracting the global impression of an image. We treat image segmentation as a graph partitioning problem and propose a novel global criterion, the normalized cut, for segmenting the graph. The normalized cut criterion measures both the total dissimilarity between the different groups as well as the total similarity within the groups. We show that an efficient computational technique based on a generalized eigenvalue problem can be used to optimize this criterion. We have applied this approach to segmenting static images and found results very encouraging."
            },
            "slug": "Normalized-cuts-and-image-segmentation-Shi-Malik",
            "title": {
                "fragments": [],
                "text": "Normalized cuts and image segmentation"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This work treats image segmentation as a graph partitioning problem and proposes a novel global criterion, the normalized cut, for segmenting the graph, which measures both the total dissimilarity between the different groups as well as the total similarity within the groups."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40309692"
                        ],
                        "name": "C. G. Harris",
                        "slug": "C.-G.-Harris",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Harris",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. G. Harris"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40365651"
                        ],
                        "name": "M. Stephens",
                        "slug": "M.-Stephens",
                        "structuredName": {
                            "firstName": "M.",
                            "lastName": "Stephens",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Stephens"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 32,
                                "start": 28
                            }
                        ],
                        "text": "Therefore, a reduction of information is necessary."
                    },
                    "intents": []
                }
            ],
            "corpusId": 1694378,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6818668fb895d95861a2eb9673ddc3a41e27b3b3",
            "isKey": false,
            "numCitedBy": 14112,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "The problem we are addressing in Alvey Project MMI149 is that of using computer vision to understand the unconstrained 3D world, in which the viewed scenes will in general contain too wide a diversity of objects for topdown recognition techniques to work. For example, we desire to obtain an understanding of natural scenes, containing roads, buildings, trees, bushes, etc., as typified by the two frames from a sequence illustrated in Figure 1. The solution to this problem that we are pursuing is to use a computer vision system based upon motion analysis of a monocular image sequence from a mobile camera. By extraction and tracking of image features, representations of the 3D analogues of these features can be constructed."
            },
            "slug": "A-Combined-Corner-and-Edge-Detector-Harris-Stephens",
            "title": {
                "fragments": [],
                "text": "A Combined Corner and Edge Detector"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "The problem the authors are addressing in Alvey Project MMI149 is that of using computer vision to understand the unconstrained 3D world, in which the viewed scenes will in general contain too wide a diversity of objects for topdown recognition techniques to work."
            },
            "venue": {
                "fragments": [],
                "text": "Alvey Vision Conference"
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1731948"
                        ],
                        "name": "Paul A. Viola",
                        "slug": "Paul-A.-Viola",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Viola",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Paul A. Viola"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145319478"
                        ],
                        "name": "Michael J. Jones",
                        "slug": "Michael-J.-Jones",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Jones",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael J. Jones"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144626092"
                        ],
                        "name": "D. Snow",
                        "slug": "D.-Snow",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Snow",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Snow"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 82,
                                "start": 78
                            }
                        ],
                        "text": "This paper sets out to explore the limits of weakly supervised object categorization from still images."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 21,
                                "start": 17
                            }
                        ],
                        "text": "This new segmentation method allows the segmentation of nonconnected regions."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 47726,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3702c79b8d118f8f363d685905bd285ab8e33979",
            "isKey": false,
            "numCitedBy": 1526,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes a pedestrian detection system that integrates image intensity information with motion information. We use a detection style algorithm that scans a detector over two consecutive frames of a video sequence. The detector is trained (using AdaBoost) to take advantage of both motion and appearance information to detect a walking person. Past approaches have built detectors based on motion information or detectors based on appearance information, but ours is the first to combine both sources of information in a single detector. The implementation described runs at about 4 frames/second, detects pedestrians at very small scales (as small as 20 \u00d7 15 pixels), and has a very low false positive rate.Our approach builds on the detection work of Viola and Jones. Novel contributions of this paper include: (i) development of a representation of image motion which is extremely efficient, and (ii) implementation of a state of the art pedestrian detection system which operates on low resolution images under difficult conditions (such as rain and snow)."
            },
            "slug": "Detecting-Pedestrians-Using-Patterns-of-Motion-and-Viola-Jones",
            "title": {
                "fragments": [],
                "text": "Detecting Pedestrians Using Patterns of Motion and Appearance"
            },
            "tldr": {
                "abstractSimilarityScore": 52,
                "text": "This pedestrian detection system is the first to combine both sources of information in a single detector, and operates on low resolution images under difficult conditions (such as rain and snow)."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2462253"
                        ],
                        "name": "C. Schmid",
                        "slug": "C.-Schmid",
                        "structuredName": {
                            "firstName": "Cordelia",
                            "lastName": "Schmid",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Schmid"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145299933"
                        ],
                        "name": "R. Mohr",
                        "slug": "R.-Mohr",
                        "structuredName": {
                            "firstName": "Roger",
                            "lastName": "Mohr",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Mohr"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "In some cases, we also report the ROC-AuC rate (area under ROC curve)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 325871,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "49fcd806450d947e56c82ef2b438ad9c484069dc",
            "isKey": false,
            "numCitedBy": 1792,
            "numCiting": 61,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper addresses the problem of retrieving images from large image databases. The method is based on local grayvalue invariants which are computed at automatically detected interest points. A voting algorithm and semilocal constraints make retrieval possible. Indexing allows for efficient retrieval from a database of more than 1,000 images. Experimental results show correct retrieval in the case of partial visibility, similarity transformations, extraneous features, and small perspective deformations."
            },
            "slug": "Local-Grayvalue-Invariants-for-Image-Retrieval-Schmid-Mohr",
            "title": {
                "fragments": [],
                "text": "Local Grayvalue Invariants for Image Retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 82,
                "text": "This paper addresses the problem of retrieving images from large image databases with a method based on local grayvalue invariants which are computed at automatically detected interest points and allows for efficient retrieval from a database of more than 1,000 images."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712041"
                        ],
                        "name": "K. Mikolajczyk",
                        "slug": "K.-Mikolajczyk",
                        "structuredName": {
                            "firstName": "Krystian",
                            "lastName": "Mikolajczyk",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Mikolajczyk"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2462253"
                        ],
                        "name": "C. Schmid",
                        "slug": "C.-Schmid",
                        "structuredName": {
                            "firstName": "Cordelia",
                            "lastName": "Schmid",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Schmid"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 94,
                                "start": 90
                            }
                        ],
                        "text": "We extract a window of size w = 6\u00b7\u03c3I (ajar to the value used by Mikolajczyk and Schmid in [25]) whe re \u03c3I is the characteristic scale of the interest point delivered by the interest point detector."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 126,
                                "start": 122
                            }
                        ],
                        "text": "[30], we decided to use the scale invariant Harris-Laplace detector [24] and the affine invariant interest point detector [25], both by"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 158,
                                "start": 154
                            }
                        ],
                        "text": "Additionally, a n iterative algorithm is used which converges to affine invariant points by modifying the location, scale a nd neighborhood of each point [25]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 8571961,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "id": "9c7a96155f10f152cae0866102c061cdf6da02e8",
            "isKey": false,
            "numCitedBy": 1683,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a novel approach for detecting affine invariant interest points. Our method can deal with significant affine transformations including large scale changes. Such transformations introduce significant changes in the point location as well as in the scale and the shape of the neighbourhood of an interest point. Our approach allows to solve for these problems simultaneously. It is based on three key ideas : 1) The second moment matrix computed in a point can be used to normalize a region in an affine invariant way (skew and stretch). 2) The scale of the local structure is indicated by local extrema of normalized derivatives over scale. 3) An affine-adapted Harris detector determines the location of interest points. A multi-scale version of this detector is used for initialization. An iterative algorithm then modifies location, scale and neighbourhood of each point and converges to affine invariant points. For matching and recognition, the image is characterized by a set of affine invariant points; the affine transformation associated with each point allows the computation of an affine invariant descriptor which is also invariant to affine illumination changes. A quantitative comparison of our detector with existing ones shows a significant improvement in the presence of large affine deformations. Experimental results for wide baseline matching show an excellent performance in the presence of large perspective transformations including significant scale changes. Results for recognition are very good for a database with more than 5000 images."
            },
            "slug": "An-Affine-Invariant-Interest-Point-Detector-Mikolajczyk-Schmid",
            "title": {
                "fragments": [],
                "text": "An Affine Invariant Interest Point Detector"
            },
            "tldr": {
                "abstractSimilarityScore": 72,
                "text": "A novel approach for detecting affine invariant interest points that can deal with significant affine transformations including large scale changes and shows an excellent performance in the presence of large perspective transformations including significant scale changes."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144522420"
                        ],
                        "name": "T. Ojala",
                        "slug": "T.-Ojala",
                        "structuredName": {
                            "firstName": "Timo",
                            "lastName": "Ojala",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Ojala"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145962204"
                        ],
                        "name": "M. Pietik\u00e4inen",
                        "slug": "M.-Pietik\u00e4inen",
                        "structuredName": {
                            "firstName": "Matti",
                            "lastName": "Pietik\u00e4inen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Pietik\u00e4inen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 54,
                                "start": 50
                            }
                        ],
                        "text": "And on the other h and Local Binary Patterns (see [27]), high-pass and Wavelets (see [1]), which consider a certain n eighborhood of a pixel."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 17901216,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "845302fc0a6defb71470c7a9dd1eac754d4c0e8a",
            "isKey": false,
            "numCitedBy": 442,
            "numCiting": 44,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Unsupervised-texture-segmentation-using-feature-Ojala-Pietik\u00e4inen",
            "title": {
                "fragments": [],
                "text": "Unsupervised texture segmentation using feature distributions"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit."
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2035718"
                        ],
                        "name": "R. Lagani\u00e8re",
                        "slug": "R.-Lagani\u00e8re",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Lagani\u00e8re",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Lagani\u00e8re"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 38,
                                "start": 34
                            }
                        ],
                        "text": "Therefore, a reduction of information is necessary."
                    },
                    "intents": []
                }
            ],
            "corpusId": 5601201,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a0866c8fe335bc8cceca7023bd0eb75e1555dd2a",
            "isKey": false,
            "numCitedBy": 49,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-morphological-operator-for-corner-detection-Lagani\u00e8re",
            "title": {
                "fragments": [],
                "text": "A morphological operator for corner detection"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit."
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2056570941"
                        ],
                        "name": "Rui Shi",
                        "slug": "Rui-Shi",
                        "structuredName": {
                            "firstName": "Rui",
                            "lastName": "Shi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Rui Shi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2113268317"
                        ],
                        "name": "W. Zeng",
                        "slug": "W.-Zeng",
                        "structuredName": {
                            "firstName": "Wei",
                            "lastName": "Zeng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Zeng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3154357"
                        ],
                        "name": "Zhengyu Su",
                        "slug": "Zhengyu-Su",
                        "structuredName": {
                            "firstName": "Zhengyu",
                            "lastName": "Su",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zhengyu Su"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2149533120"
                        ],
                        "name": "Jian Jiang",
                        "slug": "Jian-Jiang",
                        "structuredName": {
                            "firstName": "Jian",
                            "lastName": "Jiang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jian Jiang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144027810"
                        ],
                        "name": "H. Damasio",
                        "slug": "H.-Damasio",
                        "structuredName": {
                            "firstName": "Hanna",
                            "lastName": "Damasio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Damasio"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "30460080"
                        ],
                        "name": "Zhonglin Lu",
                        "slug": "Zhonglin-Lu",
                        "structuredName": {
                            "firstName": "Zhonglin",
                            "lastName": "Lu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zhonglin Lu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "33973920"
                        ],
                        "name": "Yalin Wang",
                        "slug": "Yalin-Wang",
                        "structuredName": {
                            "firstName": "Yalin",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yalin Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "116303595"
                        ],
                        "name": "S. Yau",
                        "slug": "S.-Yau",
                        "structuredName": {
                            "firstName": "Shing-Tung",
                            "lastName": "Yau",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Yau"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145560807"
                        ],
                        "name": "X. Gu",
                        "slug": "X.-Gu",
                        "structuredName": {
                            "firstName": "Xianfeng",
                            "lastName": "Gu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "X. Gu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 17229197,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "208ebe27e70640de8a94f0638fb13bfda71cd943",
            "isKey": false,
            "numCitedBy": 1069,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "Automatic computation of surface correspondence via harmonic map is an active research field in computer vision, computer graphics and computational geometry. It may help document and understand physical and biological phenomena and also has broad applications in biometrics, medical imaging and motion capture inducstries. Although numerous studies have been devoted to harmonic map research, limited progress has been made to compute a diffeomorphic harmonic map on general topology surfaces with landmark constraints. This work conquers this problem by changing the Riemannian metric on the target surface to a hyperbolic metric so that the harmonic mapping is guaranteed to be a diffeomorphism under landmark constraints. The computational algorithms are based on Ricci flow and nonlinear heat diffusion methods. The approach is general and robust. We employ our algorithm to study the constrained surface registration problem which applies to both computer vision and medical imaging applications. Experimental results demonstrate that, by changing the Riemannian metric, the registrations are always diffeomorphic and achieve relatively high performance when evaluated with some popular surface registration evaluation standards."
            },
            "slug": "IEEE-TRANSACTIONS-ON-PATTERN-ANALYSIS-AND-MACHINE-Shi-Zeng",
            "title": {
                "fragments": [],
                "text": "IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This work conquers the constrained surface registration problem by changing the Riemannian metric on the target surface to a hyperbolic metric so that the harmonic mapping is guaranteed to be a diffeomorphism under landmark constraints."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1768236"
                        ],
                        "name": "W. Freeman",
                        "slug": "W.-Freeman",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Freeman",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Freeman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145358192"
                        ],
                        "name": "E. Adelson",
                        "slug": "E.-Adelson",
                        "structuredName": {
                            "firstName": "Edward",
                            "lastName": "Adelson",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Adelson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 90,
                                "start": 86
                            }
                        ],
                        "text": "For regions of discontinuity, local descriptors have been researched quite well (e.g. [11], [23], [32], [15])."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 29187618,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "993b1083455b5c4d631eaf44f230b061994e75c3",
            "isKey": false,
            "numCitedBy": 3379,
            "numCiting": 55,
            "paperAbstract": {
                "fragments": [],
                "text": "The authors present an efficient architecture to synthesize filters of arbitrary orientations from linear combinations of basis filters, allowing one to adaptively steer a filter to any orientation, and to determine analytically the filter output as a function of orientation. Steerable filters may be designed in quadrature pairs to allow adaptive control over phase as well as orientation. The authors show how to design and steer the filters and present examples of their use in the analysis of orientation and phase, angularly adaptive filtering, edge detection, and shape from shading. One can also build a self-similar steerable pyramid representation. The same concepts can be generalized to the design of 3-D steerable filters. >"
            },
            "slug": "The-Design-and-Use-of-Steerable-Filters-Freeman-Adelson",
            "title": {
                "fragments": [],
                "text": "The Design and Use of Steerable Filters"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "The authors present an efficient architecture to synthesize filters of arbitrary orientations from linear combinations of basis filters, allowing one to adaptively steer a filter to any orientation, and to determine analytically the filter output as a function of orientation."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2276554"
                        ],
                        "name": "R. Fergus",
                        "slug": "R.-Fergus",
                        "structuredName": {
                            "firstName": "Rob",
                            "lastName": "Fergus",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Fergus"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1690922"
                        ],
                        "name": "P. Perona",
                        "slug": "P.-Perona",
                        "structuredName": {
                            "firstName": "Pietro",
                            "lastName": "Perona",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Perona"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688869"
                        ],
                        "name": "Andrew Zisserman",
                        "slug": "Andrew-Zisserman",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Zisserman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Zisserman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 6,
                                "start": 3
                            }
                        ],
                        "text": "They are extracted with various existing methods."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 51,
                                "start": 48
                            }
                        ],
                        "text": "P. Auer is with the Institute for Computer Science, University of Leoben, Franz-Josef-Stra\u00dfe 18, A-8700 Leoben, Austria."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14320675,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "8fa41eef4c4e60709b0b134bf8d4ee242bff7a74",
            "isKey": false,
            "numCitedBy": 335,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "We extend the constellation model to include heterogeneous parts which may represent either the appearance or the geometry of a region of the object. The parts and their spatial configuration are learnt simultaneously and automatically, without supervision, from cluttered images."
            },
            "slug": "A-Visual-Category-Filter-for-Google-Images-Fergus-Perona",
            "title": {
                "fragments": [],
                "text": "A Visual Category Filter for Google Images"
            },
            "tldr": {
                "abstractSimilarityScore": 93,
                "text": "The constellation model is extended to include heterogeneous parts which may represent either the appearance or the geometry of a region of the object and their spatial configuration are learnt simultaneously and automatically, without supervision, from cluttered images."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2462253"
                        ],
                        "name": "C. Schmid",
                        "slug": "C.-Schmid",
                        "structuredName": {
                            "firstName": "Cordelia",
                            "lastName": "Schmid",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Schmid"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145299933"
                        ],
                        "name": "R. Mohr",
                        "slug": "R.-Mohr",
                        "structuredName": {
                            "firstName": "Roger",
                            "lastName": "Mohr",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Mohr"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1692283"
                        ],
                        "name": "C. Bauckhage",
                        "slug": "C.-Bauckhage",
                        "structuredName": {
                            "firstName": "Christian",
                            "lastName": "Bauckhage",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Bauckhage"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 55,
                                "start": 51
                            }
                        ],
                        "text": "But, we also want to be capable of learning many object categories without restrictions to shape or appearance of the objects."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14571093,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2713e7a59105a832e20c01c3c202b9dcd2b5f889",
            "isKey": false,
            "numCitedBy": 1730,
            "numCiting": 64,
            "paperAbstract": {
                "fragments": [],
                "text": "Many different low-level feature detectors exist and it is widely agreed that the evaluation of detectors is important. In this paper we introduce two evaluation criteria for interest points' repeatability rate and information content. Repeatability rate evaluates the geometric stability under different transformations. Information content measures the distinctiveness of features. Different interest point detectors are compared using these two criteria. We determine which detector gives the best results and show that it satisfies the criteria well."
            },
            "slug": "Evaluation-of-Interest-Point-Detectors-Schmid-Mohr",
            "title": {
                "fragments": [],
                "text": "Evaluation of Interest Point Detectors"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "Two evaluation criteria for interest points' repeatability rate and information content are introduced and different interest point detectors are compared using these two criteria."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145247053"
                        ],
                        "name": "W. Maass",
                        "slug": "W.-Maass",
                        "structuredName": {
                            "firstName": "Wolfgang",
                            "lastName": "Maass",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Maass"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1794034"
                        ],
                        "name": "Manfred K. Warmuth",
                        "slug": "Manfred-K.-Warmuth",
                        "structuredName": {
                            "firstName": "Manfred",
                            "lastName": "Warmuth",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Manfred K. Warmuth"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 4002640,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cb6211c56dab41b6043a1a8705350d557e93efb4",
            "isKey": false,
            "numCitedBy": 52,
            "numCiting": 45,
            "paperAbstract": {
                "fragments": [],
                "text": "We reduce learning simple geometric concept classes to learning disjunctions over exponentially many variables. We then apply an on-line algorithm called Winnow whose number of prediction mistakes grows only logarithmically with the number of variables. The hypotheses of Winnow are linear threshold functions with one weight per variable. We find ways to keep the exponentially many weights of Winnow implicitly so that the time for the algorithm to compute a prediction and update its ``virtual'''' weights is polynomial. Our method can be used to learn d-dimensional axis-parallel boxes when d is variable, and unions of d-dimensional axis-parallel boxes when d is constant. The worst-case number of mistakes of our algorithms for the above classes is optimal to within a constant factor, and our algorithms inherit the noise robustness of Winnow. We think that other on-line algorithms with multiplicative weight updates whose loss bounds grow logarithmically with the dimension are amenable to our methods."
            },
            "slug": "Efficient-Learning-With-Virtual-Threshold-Gates-Maass-Warmuth",
            "title": {
                "fragments": [],
                "text": "Efficient Learning With Virtual Threshold Gates"
            },
            "tldr": {
                "abstractSimilarityScore": 94,
                "text": "This work reduces learning simple geometric concept classes to learning disjunctions over exponentially many variables and applies an on-line algorithm called Winnow whose number of prediction mistakes grows only logarithmically with the number of variables."
            },
            "venue": {
                "fragments": [],
                "text": "Inf. Comput."
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3038814"
                        ],
                        "name": "R. W\u00fcrtz",
                        "slug": "R.-W\u00fcrtz",
                        "structuredName": {
                            "firstName": "Rolf",
                            "lastName": "W\u00fcrtz",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. W\u00fcrtz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1699895"
                        ],
                        "name": "T. Lourens",
                        "slug": "T.-Lourens",
                        "structuredName": {
                            "firstName": "Tino",
                            "lastName": "Lourens",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Lourens"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 314015,
            "fieldsOfStudy": [
                "Computer Science",
                "Biology"
            ],
            "id": "cff14abfe271c786139f933c64bacce96fd8e315",
            "isKey": false,
            "numCitedBy": 42,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a corner-detection algorithm based on a model for end-stopping cells in the visual cortex. Shortcomings of this model are overcome by a combination over several scales. The notion of an end-stopped cell and the resulting corner detector is generalized to color channels in a biologically plausible way. The resulting corner detection method yields good results in the presence of high frequency texture, noise, varying contrast, and rounded corners. This compares favorably with known corner detectors."
            },
            "slug": "Corner-Detection-in-Color-Images-by-Multiscale-of-W\u00fcrtz-Lourens",
            "title": {
                "fragments": [],
                "text": "Corner Detection in Color Images by Multiscale Combination of End-Stopped Cortical Cells"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The notion of an end-stopped cell and the resulting corner detector is generalized to color channels in a biologically plausible way and yields good results in the presence of high frequency texture, noise, varying contrast, and rounded corners."
            },
            "venue": {
                "fragments": [],
                "text": "ICANN"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2510182"
                        ],
                        "name": "Erez Shilat",
                        "slug": "Erez-Shilat",
                        "structuredName": {
                            "firstName": "Erez",
                            "lastName": "Shilat",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Erez Shilat"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "27379268"
                        ],
                        "name": "M. Werman",
                        "slug": "M.-Werman",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Werman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Werman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1915667"
                        ],
                        "name": "Y. Gdalyahu",
                        "slug": "Y.-Gdalyahu",
                        "structuredName": {
                            "firstName": "Yoram",
                            "lastName": "Gdalyahu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Gdalyahu"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 16,
                                "start": 12
                            }
                        ],
                        "text": "[17], [18], [34], [ 39]), and at varying scales (e."
                    },
                    "intents": []
                }
            ],
            "corpusId": 2918158,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "6cb26f49e5fc202a557824f0ce6f9f0b778ee6b9",
            "isKey": false,
            "numCitedBy": 40,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "Traditionally, corners are found along step edges. In this paper we present an alternative approach-corners along ridges/troughs and local minima points. These features seem to be more reliable for tracking. A new approach for sub-pixel localization of these corners is suggested, using a local approximation of the image surface."
            },
            "slug": "Ridge's-corner-detection-and-correspondence-Shilat-Werman",
            "title": {
                "fragments": [],
                "text": "Ridge's corner detection and correspondence"
            },
            "tldr": {
                "abstractSimilarityScore": 73,
                "text": "This paper presents an alternative approach-corners along ridges/troughs and local minima points and these features seem to be more reliable for tracking, using a local approximation of the image surface."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2063028306"
                        ],
                        "name": "S. Maitra",
                        "slug": "S.-Maitra",
                        "structuredName": {
                            "firstName": "S.",
                            "lastName": "Maitra",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Maitra"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "The second group contains invariant moments (see [23]), which are invariant with respect to scaling, rotation and translation."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 10426680,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "362e2cd493e986819e084e9ef7bf037c46662f17",
            "isKey": false,
            "numCitedBy": 191,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "Possible improvements in recent work on moment invariants are pointed out. Invariants that correctly take into account the effect of change in scale and illumination are described. An example, using two images with arbitrary shift, rotation, scale and contrast change, is also provided."
            },
            "slug": "Moment-invariants-Maitra",
            "title": {
                "fragments": [],
                "text": "Moment invariants"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the IEEE"
            },
            "year": 1979
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1409513867"
                        ],
                        "name": "M.",
                        "slug": "M.",
                        "structuredName": {
                            "firstName": "",
                            "lastName": "M.",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M."
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 93,
                                "start": 89
                            }
                        ],
                        "text": "For regions of homogeneity, we chose two description techniques: intensity distributions [16] and invariant moments [25]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 137,
                                "start": 136
                            }
                        ],
                        "text": "We set up a new weak-hypotheses-finder that selects the most discriminant description vector in each iteration of the AdaBoost algorithm."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1990278,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "f7625798c6e08daa9a603551c71bab68f9abe5dd",
            "isKey": false,
            "numCitedBy": 3671,
            "numCiting": 90,
            "paperAbstract": {
                "fragments": [],
                "text": "A b m t-I n this survey we review the impge processing literature on the various approaches and models investigators have uaed for texture."
            },
            "slug": "Statistical-and-Structural-Approaches-to-Texture-M.",
            "title": {
                "fragments": [],
                "text": "Statistical and Structural Approaches to Texture"
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145509578"
                        ],
                        "name": "A. Cohen",
                        "slug": "A.-Cohen",
                        "structuredName": {
                            "firstName": "Albert",
                            "lastName": "Cohen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Cohen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1737063"
                        ],
                        "name": "I. Daubechies",
                        "slug": "I.-Daubechies",
                        "structuredName": {
                            "firstName": "Ingrid",
                            "lastName": "Daubechies",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Daubechies"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "70027952"
                        ],
                        "name": "J. Feauveau",
                        "slug": "J.-Feauveau",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Feauveau",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Feauveau"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 98,
                                "start": 95
                            }
                        ],
                        "text": "Existing data sets for object recognition used by other research groups (e.g., [8], [1]) show the objects with just small variations in scale and objects are generally viewed at similar poses."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 48351350,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "fdaa9a15aa97e385cc240c517e1d255ae92f4fa9",
            "isKey": false,
            "numCitedBy": 2943,
            "numCiting": 52,
            "paperAbstract": {
                "fragments": [],
                "text": "Orthonormal bases of compactly supported wavelet bases correspond to subband coding schemes with exact reconstruction in which the analysis and synthesis filters coincide. We show here that under fairly general conditions, exact reconstruction schemes with synthesis filters different from the analysis filters give rise: to two dual Riesz bases of compactly supported wavelets. We give necessary and sufficient conditions for biorthogonality of the corresponding scaling functions, and we present a sufficient condition for the decay of their Fourier transforms. We study the regularity of these biorthogonal bases. We provide several families of examples, all symmetric (corresponding to \u201clinear phase\u201d filters). In particular we can construct symmetric biorthogonal wavelet bases with arbitrarily high preassigned regularity; we also show how to construct symmetric biorthogonal wavelet bases \u201cclose\u201d to a (nonsymmetric) orthonormal basis."
            },
            "slug": "Biorthogonal-bases-of-compactly-supported-wavelets-Cohen-Daubechies",
            "title": {
                "fragments": [],
                "text": "Biorthogonal bases of compactly supported wavelets"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 20,
                                "start": 16
                            }
                        ],
                        "text": "We use Boosting [12] as learning technique."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 229,
                                "start": 225
                            }
                        ],
                        "text": "First, it is intuitiv ely quite clear that weak hypotheses with high discriminative power \u2014 with a large difference of the su ms in equation (4) \u2014 are preferable, and indeed this is shown in the convergence proof of AdaBoost [12] ."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 74,
                                "start": 70
                            }
                        ],
                        "text": "L EARNING MODEL Our learning model is based on the AdaBoost algorithm [12]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 42,
                                "start": 38
                            }
                        ],
                        "text": "Shows the standard AdaBoost algorithm [12]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 25,
                                "start": 21
                            }
                        ],
                        "text": "Lea ning by AdaBoost [12], leads to a final hypothesis which consists of several weak hypotheses."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 105,
                                "start": 101
                            }
                        ],
                        "text": "To calculate this classification function H we use an adaptation of the classical AdaBoost algorithm [12] ."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 49,
                                "start": 45
                            }
                        ],
                        "text": "Our new learning method is based on Boosting [12]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A decision theoretic generalisation of o  nline learning"
            },
            "venue": {
                "fragments": [],
                "text": "Computer and System Sciences  , 55(1):119\u2013139,"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 132,
                                "start": 128
                            }
                        ],
                        "text": "We do not experiment with all possible combinations, but we focus on methods with high performance based on results reported in [29] and [30]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 99,
                                "start": 95
                            }
                        ],
                        "text": "this numbers were experimentally evaluated and depend on the image complexity, for details see [29]"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 128,
                                "start": 124
                            }
                        ],
                        "text": "Also the points with the smallest characteristic scale were skipped (the neglectable influence of these points was shown in [29])."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Feature selection for scaled interest points"
            },
            "venue": {
                "fragments": [],
                "text": "Master\u2019s thesis, Graz University of Technology,"
            },
            "year": 2003
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 37,
                                "start": 31
                            }
                        ],
                        "text": "Additionally, Schneiderman and Kanade undertake rather specific object recognition as they train each object from different viewpoints."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 29,
                                "start": 25
                            }
                        ],
                        "text": "Schne iderman and Kanade [32] also use Boosting to improve an already complex classifier."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 23,
                                "start": 17
                            }
                        ],
                        "text": "Schneiderman and Kanade [33] use Boosting to improve an already complex classifier."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Object detection using the statistics  of parts.International"
            },
            "venue": {
                "fragments": [],
                "text": "Journal of Computer Vision  ,"
            },
            "year": 2004
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "It shows the distribution of learned information that is directly related with the object and the learned contextual information."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 51,
                                "start": 47
                            }
                        ],
                        "text": "The first part (Section 7.1) specifies the parameter settings."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "0162-8828/06/$20.00 2006 IEEE Published by the IEEE Computer Society"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A Decision Theoretic Generalisation of Online Learning"
            },
            "venue": {
                "fragments": [],
                "text": "Computer and System Sciences"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "0162-8828/06/$20.00 2006 IEEE Published by the IEEE Computer Society"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Feature Selection for Scaled Interest Points, \" master's thesis"
            },
            "venue": {
                "fragments": [],
                "text": "Feature Selection for Scaled Interest Points, \" master's thesis"
            },
            "year": 2003
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Object detection using the statisticsof parts"
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[30], we decided to use the scale invariant Harris-Laplace detector [24] and the affine invariant interest point detector [25], both by"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Evaluation of interest po  int detectors"
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision , pages 151\u2013172,"
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 120,
                                "start": 116
                            }
                        ],
                        "text": "For regions of homogeneity, we chose two description techniques: intensity distributions [16] and invariant moments [25]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 57,
                                "start": 53
                            }
                        ],
                        "text": "This weak-hypothesesfinder is extended to be capable of using various description methods in one learning step."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Proc. IEEE"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. IEEE"
            },
            "year": 1979
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[37] use Support Vector Machines combined wi th local features for object recognition."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Recognition with local featur  es: the kernel recipe"
            },
            "venue": {
                "fragments": [],
                "text": "InProc. International Conference on Computer Vision  , pages 257\u2013264,"
            },
            "year": 2003
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The design and use of steerable filter  s"
            },
            "venue": {
                "fragments": [],
                "text": "PAMI, pages 891\u2013906,"
            },
            "year": 1991
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Unsupervised learning of m  dels for recognition"
            },
            "venue": {
                "fragments": [],
                "text": "InProc. European Conference on Computer Vision,"
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 79,
                                "start": 75
                            }
                        ],
                        "text": "Weak-Hypotheses-Finder with Multiple Description Method s In an outlook in [29] we discussed the possibility of using mu ltiple description methods in one learning procedure."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 65,
                                "start": 61
                            }
                        ],
                        "text": "This database 2 (further on termed GRAZ-01) that was used in [29], contains 45 0 images of category person (P), 350 of category bike (B) and 250 of category \u201ccounter-cla ss\u201d (N, meaning it contains no bikes and no persons)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Weak hypothes  es and boosting for generic object detection and recognition"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. European Conference on Computer Vision  , volume 2, pages 71\u201384,"
            },
            "year": 2004
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 24,
            "methodology": 23,
            "result": 1
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 54,
        "totalPages": 6
    },
    "page_url": "https://www.semanticscholar.org/paper/Generic-object-recognition-with-boosting-Opelt-Pinz/6bb4de9c81b221f97d541b81134aab9029c42b91?sort=total-citations"
}