{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694191"
                        ],
                        "name": "J. Hull",
                        "slug": "J.-Hull",
                        "structuredName": {
                            "firstName": "Jonathan",
                            "lastName": "Hull",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Hull"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 233,
                                "start": 213
                            }
                        ],
                        "text": "\u2026features and algorithms can be used directly to answer queries based on layout similarities (Cullen et al. 1997, Doermann 1997), or as pre-processing steps for some of the more detailed page matching algorithms (Hull and Cullen 1997, Doermann et al. 1997) for purposes such as duplicate detection."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 11147263,
            "fieldsOfStudy": [
                "Computer Science",
                "Environmental Science"
            ],
            "id": "2771ce6ea5bbcb89deb038e6ed4b6d90c4fb737b",
            "isKey": false,
            "numCitedBy": 26,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract. An algorithm is presented for determining the similarity and equivalence of document images. Features extracted from the CCITT fax-compressed representations of two images are compared to determine their visual similarity and whether they are equivalent (i.e., scanned from the same original). Pass codes in the compressed data are used as features. A fixed grid is imposed on the image and a feature vector is derived from the number of pass codes in each grid cell. The features vectors are compared to locate a group of documents that are visually similar to the input image. The equivalence of two documents is determined by applying the Hausdorff distance to the two-dimensional arrangement of pass codes in small patches of each image."
            },
            "slug": "Document-image-similarity-and-equivalence-detection-Hull",
            "title": {
                "fragments": [],
                "text": "Document image similarity and equivalence detection"
            },
            "tldr": {
                "abstractSimilarityScore": 66,
                "text": "An algorithm is presented for determining the similarity and equivalence of document images by applying the Hausdorff distance to the two-dimensional arrangement of pass codes in small patches of each image."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Fourth International Conference on Document Analysis and Recognition"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2107125703"
                        ],
                        "name": "W. Zhu",
                        "slug": "W.-Zhu",
                        "structuredName": {
                            "firstName": "Wei",
                            "lastName": "Zhu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Zhu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2193427"
                        ],
                        "name": "T. Syeda-Mahmood",
                        "slug": "T.-Syeda-Mahmood",
                        "structuredName": {
                            "firstName": "Tanveer",
                            "lastName": "Syeda-Mahmood",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Syeda-Mahmood"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 240,
                                "start": 214
                            }
                        ],
                        "text": "Zhu and Syeda-Mahmood viewed document layout similarity as a special case of regional layout similarity of general images and proposed a region topology-based shape formalism called constrained affine shape model (Zhu and Syeda-Mahmood 1998)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 80,
                                "start": 52
                            }
                        ],
                        "text": "A high-level representation such as the one used in Zhu and Syeda-Mahmood (1998) provides a better characterization of the image, but is less resilient to low-level processing errors, and generally requires a more\ncomplicated distance computation."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 19004361,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c223bb981ca5833cdf349b0b5ad1dc4526650e31",
            "isKey": false,
            "numCitedBy": 8,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "In content-based access of image databases, there is a need for a shape formalism that allows a precise description and recognition of a wider class of shape variations that evoke the same overall perceptual similarity in appearance. Such a description not only allows images of a database to be organized into shape categories for efficient indexing, but also makes a wider class of shape-similarity queries possible. This paper presents a region topology-based shape model called the constrained affine shape model, that captures the spatial layout similarity between members of a class by a set of constrained affine deformations from a prototypical member. The shape model is proposed for use in organizing images of a database into shape categories represented by prototypical members and the associated shape constraints. An efficient matching algorithm is presented for use in shape categorization and querying. The effect of global pose changes on the constraints of the shape model are analyzed to make shape matching robust to global pose changes. An application of the model for document retrieval based on document shape genres is presented. Finally, the effectiveness of the shape model in content-based access of such databases is evaluated."
            },
            "slug": "Image-organization-and-retrieval-using-a-flexible-Zhu-Syeda-Mahmood",
            "title": {
                "fragments": [],
                "text": "Image organization and retrieval using a flexible shape model"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "A region topology-based shape model is presented, that captures the spatial layout similarity between members of a class by a set of constrained affine deformations from a prototypical member, that is proposed for use in organizing images of a database into shape categories represented by prototypical members and the associated shape constraints."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings 1998 IEEE International Workshop on Content-Based Access of Image and Video Database"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1723766"
                        ],
                        "name": "H. Baird",
                        "slug": "H.-Baird",
                        "structuredName": {
                            "firstName": "Henry",
                            "lastName": "Baird",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Baird"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 163,
                                "start": 153
                            }
                        ],
                        "text": "The particular segmentation scheme we have adopted uses white space as a generic layout delimiter and is suitable for machine-printed Manhattan layouts (Baird 1994)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 26229616,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "da44af7e967c0c847e63b9600811a58ee7716f45",
            "isKey": false,
            "numCitedBy": 123,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "A method for analyzing the structure of the white background in document images is described, along with applications to the problem of isolating blocks of machine-printed text. The approach is based on computational-geometry algorithms for off-line enumeration of maximal white rectangles and on-line rectangle unification. These support a fast, simple, and general heuristic for geometric layout segmentation, in which white space is covered greedily by rectangles until all text blocks are isolated. Design of the heuristic can be substantially automated by an analysis of the empirical statistical distribution of properties of covering rectangles: for example, the stopping rule can be chosen by Rosenblatt\u2019s perceptron training algorithm. Experimental trials show good behavior on the large and useful class of textual Manhattan layouts. On complex layouts from English-language technical journals of many publishers, the method finds good segmentations in a uniform and nearly parameter-free manner. On a variety of non-Latin texts, some with vertical text lines, the method finds good segmentations without prior knowledge of page and text-line orientation."
            },
            "slug": "Background-Structure-in-Document-Images-Baird",
            "title": {
                "fragments": [],
                "text": "Background Structure in Document Images"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "A method for analyzing the structure of the white background in document images is described, along with applications to the problem of isolating blocks of machine-printed text."
            },
            "venue": {
                "fragments": [],
                "text": "Int. J. Pattern Recognit. Artif. Intell."
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48471936"
                        ],
                        "name": "D. Doermann",
                        "slug": "D.-Doermann",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Doermann",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Doermann"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 158,
                                "start": 145
                            }
                        ],
                        "text": "\u2026retrieval point of view, these features and algorithms can be used directly to answer queries based on layout similarities (Cullen et al. 1997, Doermann 1997), or as pre-processing steps for some of the more detailed page matching algorithms (Hull and Cullen 1997, Doermann et al. 1997) for\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 44700246,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "18cd9fd60db93554ec8d9032c5f94cee58f6f572",
            "isKey": false,
            "numCitedBy": 24,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "The economic feasibility of creating large databases of document images has left a tremendous need for robust ways to access the information these images contain. Printed documents are often scanned for archiving or an an attempt to move toward a paper-less office and stored as images, but without adequate index information. In order to make full use of the capabilities of traditional database indexing and retrieval techniques, a full conversion of the document may be required. There are many factors, however, which may prohibit complete conversion including its high cost, insufficient document quality, or the fact that parts of the document can simply not be adequately represented in a converted form. In this paper, we provide a survey of methods developed by researchers to access document images without relying on complete and accurate conversion. We briefly discuss traditional text indexing techniques on imperfect data and the retrieval of partially converted documents, followed by a more complete review of techniques for the direct retrieval and characterization of document images including text, drawings and graphics."
            },
            "slug": "The-retrieval-of-document-images:-a-brief-survey-Doermann",
            "title": {
                "fragments": [],
                "text": "The retrieval of document images: a brief survey"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This paper provides a survey of methods developed by researchers to access document images without relying on complete and accurate conversion and discusses traditional text indexing techniques on imperfect data and the retrieval of partially converted documents."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Fourth International Conference on Document Analysis and Recognition"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2055718517"
                        ],
                        "name": "J. Cullen",
                        "slug": "J.-Cullen",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Cullen",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Cullen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694191"
                        ],
                        "name": "J. Hull",
                        "slug": "J.-Hull",
                        "structuredName": {
                            "firstName": "Jonathan",
                            "lastName": "Hull",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Hull"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3108177"
                        ],
                        "name": "P. Hart",
                        "slug": "P.-Hart",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Hart",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Hart"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 163,
                                "start": 145
                            }
                        ],
                        "text": "From the information retrieval point of view, these features and algorithms can be used directly to answer queries based on layout similarities (Cullen et al. 1997, Doermann 1997), or as pre-processing steps for some of the more detailed page matching algorithms (Hull and Cullen 1997, Doermann et\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 11847492,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bf35ae1a26238e104fd8e4bffa4b26dc350228f1",
            "isKey": false,
            "numCitedBy": 55,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "A system is presented that uses texture to retrieve and browse images stored in a large document image database. A method of graphically generating a candidate search image is used that shows the visual layout and content of a target document. All images similar to this candidate are returned for the purpose of browsing or further query. The system is accessed using a World Wide Web (Web) browser. Applications include the retrieval and browsing of document images including newspapers, fares and business letters."
            },
            "slug": "Document-image-database-retrieval-and-browsing-Cullen-Hull",
            "title": {
                "fragments": [],
                "text": "Document image database retrieval and browsing using texture analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 70,
                "text": "A system is presented that uses texture to retrieve and browse images stored in a large document image database for the retrieval and browsing of document images including newspapers, fares and business letters."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Fourth International Conference on Document Analysis and Recognition"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48471936"
                        ],
                        "name": "D. Doermann",
                        "slug": "D.-Doermann",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Doermann",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Doermann"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2115196978"
                        ],
                        "name": "Huiping Li",
                        "slug": "Huiping-Li",
                        "structuredName": {
                            "firstName": "Huiping",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Huiping Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3272081"
                        ],
                        "name": "O. Kia",
                        "slug": "O.-Kia",
                        "structuredName": {
                            "firstName": "Omid",
                            "lastName": "Kia",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Kia"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 255,
                                "start": 235
                            }
                        ],
                        "text": "\u2026features and algorithms can be used directly to answer queries based on layout similarities (Cullen et al. 1997, Doermann 1997), or as pre-processing steps for some of the more detailed page matching algorithms (Hull and Cullen 1997, Doermann et al. 1997) for purposes such as duplicate detection."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 18082468,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e2ea97cf48d20a97d6ef2607baf380b45067fbbb",
            "isKey": false,
            "numCitedBy": 61,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose and implement a method for detecting duplicate documents in very large image databases. The method is based on a robust \"signature\" extracted from each document image which is used to index into a table of previously processed documents. The approach has a number of advantages over OCR or other recognition based methods, including speed and robustness to imaging distortions. To justify the approach and test the scalability, we have developed a simulator which allows us to change parameters of the system and examine performance for millions of document signatures. A complete system is implemented and tested on a test collection of technical articles and memos."
            },
            "slug": "The-detection-of-duplicates-in-document-image-Doermann-Li",
            "title": {
                "fragments": [],
                "text": "The detection of duplicates in document image databases"
            },
            "tldr": {
                "abstractSimilarityScore": 85,
                "text": "A method for detecting duplicate documents in very large image databases based on a robust \"signature\" extracted from each document image which is used to index into a table of previously processed documents has a number of advantages over OCR or other recognition based methods, including speed and robustness to imaging distortions."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Fourth International Conference on Document Analysis and Recognition"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2477111"
                        ],
                        "name": "H. Walischewski",
                        "slug": "H.-Walischewski",
                        "structuredName": {
                            "firstName": "Hanno",
                            "lastName": "Walischewski",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Walischewski"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 230,
                                "start": 213
                            }
                        ],
                        "text": "The results of such classification can then be verified by more elaborate methods using more complicated geometric and syntactic models for each particular class (e.g., Dengel and Dubiel 1996, Taylor et al. 1995, Walischewski 1997)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 21791102,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "74760f03537772678b518c40276f7ca7cef112ea",
            "isKey": false,
            "numCitedBy": 47,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, a qualitative representation for the layout of structured documents as well as classes of documents is presented, which is established by means of supervised learning from a labeled training set of documents. For this formal representation, an inference algorithm has been developed, adopted from error-tolerant subgraph isomorphism, which assigns logic labels to the layout objects of a test document."
            },
            "slug": "Automatic-knowledge-acquisition-for-spatial-Walischewski",
            "title": {
                "fragments": [],
                "text": "Automatic knowledge acquisition for spatial document interpretation"
            },
            "tldr": {
                "abstractSimilarityScore": 94,
                "text": "A qualitative representation for the layout of structured documents as well as classes of documents is presented, which is established by means of supervised learning from a labeled training set of documents."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Fourth International Conference on Document Analysis and Recognition"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145279674"
                        ],
                        "name": "A. Dengel",
                        "slug": "A.-Dengel",
                        "structuredName": {
                            "firstName": "Andreas",
                            "lastName": "Dengel",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Dengel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2642099"
                        ],
                        "name": "F. Dubiel",
                        "slug": "F.-Dubiel",
                        "structuredName": {
                            "firstName": "Frank",
                            "lastName": "Dubiel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Dubiel"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 191,
                                "start": 169
                            }
                        ],
                        "text": "The results of such classification can then be verified by more elaborate methods using more complicated geometric and syntactic models for each particular class (e.g., Dengel and Dubiel 1996, Taylor et al. 1995, Walischewski 1997)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 10954392,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4a3370269d516d569a800b37781adceb4089c7d1",
            "isKey": false,
            "numCitedBy": 14,
            "numCiting": 2,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a system which is capable of learning the presentation of document logical structure, exemplary as shown for business letters. Presenting a set of instances to the system, it clusters them into structural concepts and induces a concept hierarchy. This concept hierarchy is taken as a reference for classifying future input. The article introduces the sequence of learning steps and describes how the resulting concept hierarchy is applied to logical labeling, and reports the results. \u00a9 1996 John Wiley & Sons, Inc."
            },
            "slug": "Computer-understanding-of-document-structure-Dengel-Dubiel",
            "title": {
                "fragments": [],
                "text": "Computer understanding of document structure"
            },
            "tldr": {
                "abstractSimilarityScore": 78,
                "text": "A system which is capable of learning the presentation of document logical structure, exemplary as shown for business letters is described, which clusters them into structural concepts and induces a concept hierarchy."
            },
            "venue": {
                "fragments": [],
                "text": "Int. J. Imaging Syst. Technol."
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47756656"
                        ],
                        "name": "Jianying Hu",
                        "slug": "Jianying-Hu",
                        "structuredName": {
                            "firstName": "Jianying",
                            "lastName": "Hu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jianying Hu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2111287403"
                        ],
                        "name": "Michael K. Brown",
                        "slug": "Michael-K.-Brown",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Brown",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael K. Brown"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1788607"
                        ],
                        "name": "W. Turin",
                        "slug": "W.-Turin",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Turin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Turin"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 200,
                                "start": 186
                            }
                        ],
                        "text": "Second, HMMs have been well studied and have proven to be very effective in modeling other stochastic sequences of signals such as speech or on-line handwriting (Rabiner and Juang 1993, Hu et al. 1996)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 36724454,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0702de16d0ab9a9f6122f7a8c44a9bd9b0637b2f",
            "isKey": false,
            "numCitedBy": 244,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "Hidden Markov model (HMM) based recognition of handwriting is now quite common, but the incorporation of HMM's into a complex stochastic language model for handwriting recognition is still in its infancy. We have taken advantage of developments in the speech processing field to build a more sophisticated handwriting recognition system. The pattern elements of the handwriting model are subcharacter stroke types modeled by HMMs. These HMMs are concatenated to form letter models, which are further embedded in a stochastic language model. In addition to better language modeling, we introduce new handwriting recognition features of various kinds. Some of these features have invariance properties, and some are segmental, covering a larger region of the input pattern. We have achieved a writer independent recognition rate of 94.5% on 3,823 unconstrained handwritten word samples from 18 writers covering a 32 word vocabulary."
            },
            "slug": "HMM-Based-On-Line-Handwriting-Recognition-Hu-Brown",
            "title": {
                "fragments": [],
                "text": "HMM Based On-Line Handwriting Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A more sophisticated handwriting recognition system that achieves a writer independent recognition rate of 94.5% on 3,823 unconstrained handwritten word samples from 18 writers covering a 32 word vocabulary is built."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2779846"
                        ],
                        "name": "H. Sakoe",
                        "slug": "H.-Sakoe",
                        "structuredName": {
                            "firstName": "Hiroaki",
                            "lastName": "Sakoe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Sakoe"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35805230"
                        ],
                        "name": "S. Chiba",
                        "slug": "S.-Chiba",
                        "structuredName": {
                            "firstName": "Seibi",
                            "lastName": "Chiba",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Chiba"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 58,
                                "start": 46
                            }
                        ],
                        "text": "In the application of DP techniques Sakoe and Chiba (1978), a family of mappings\u03bb(l ) are provided from the rows of the template page to the rows of the test page."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 17900407,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "18f355d7ef4aa9f82bf5c00f84e46714efa5fd77",
            "isKey": false,
            "numCitedBy": 5371,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper reports on an optimum dynamic progxamming (DP) based time-normalization algorithm for spoken word recognition. First, a general principle of time-normalization is given using time-warping function. Then, two time-normalized distance definitions, called symmetric and asymmetric forms, are derived from the principle. These two forms are compared with each other through theoretical discussions and experimental studies. The symmetric form algorithm superiority is established. A new technique, called slope constraint, is successfully introduced, in which the warping function slope is restricted so as to improve discrimination between words in different categories. The effective slope constraint characteristic is qualitatively analyzed, and the optimum slope constraint condition is determined through experiments. The optimized algorithm is then extensively subjected to experimental comparison with various DP-algorithms, previously applied to spoken word recognition by different research groups. The experiment shows that the present algorithm gives no more than about two-thirds errors, even compared to the best conventional algorithm."
            },
            "slug": "Dynamic-programming-algorithm-optimization-for-word-Sakoe-Chiba",
            "title": {
                "fragments": [],
                "text": "Dynamic programming algorithm optimization for spoken word recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 71,
                "text": "This paper reports on an optimum dynamic progxamming (DP) based time-normalization algorithm for spoken word recognition, in which the warping function slope is restricted so as to improve discrimination between words in different categories."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1978
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32225756"
                        ],
                        "name": "R. Kashi",
                        "slug": "R.-Kashi",
                        "structuredName": {
                            "firstName": "Ramanujan",
                            "lastName": "Kashi",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Kashi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2157423763"
                        ],
                        "name": "J. Hu",
                        "slug": "J.-Hu",
                        "structuredName": {
                            "firstName": "Juan",
                            "lastName": "Hu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Hu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50494932"
                        ],
                        "name": "W. Nelson",
                        "slug": "W.-Nelson",
                        "structuredName": {
                            "firstName": "W.",
                            "lastName": "Nelson",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Nelson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1788607"
                        ],
                        "name": "W. Turin",
                        "slug": "W.-Turin",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Turin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Turin"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 295,
                                "start": 278
                            }
                        ],
                        "text": "In order to allow more flexibility we chose to use a mechanism called explicit duration modeling, resulting in a variable-duration HMM which was first introduced in speech recognition (Ferguson 1980, Levinson 1986) and later proved effective for signature verification as well (Kashi et al. 1997)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2875147,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "abbbc8c15c228864d3dfb06faaa10b5eef00fcbb",
            "isKey": false,
            "numCitedBy": 114,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "A method for the automatic verification of on-line handwritten signatures using both global and local features as described. The global and local features capture various aspects of signature shape and dynamics of signature production. The authors demonstrate that with the addition to the global features of a local feature based on the signature likelihood obtained from hidden Markov models (HMM) the performance of signature verification improves significantly. The current version of the program, has 2.5% equal error rate. At the 1% false rejection (FR) point, the addition of the local information to the algorithm with only global features reduced the false acceptance (FA) rate from 13% to 5%."
            },
            "slug": "On-line-handwritten-signature-verification-using-Kashi-Hu",
            "title": {
                "fragments": [],
                "text": "On-line handwritten signature verification using hidden Markov model features"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "The authors demonstrate that with the addition to the global features of a local feature based on the signature likelihood obtained from hidden Markov models (HMM) the performance of signature verification improves significantly."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Fourth International Conference on Document Analysis and Recognition"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1759195"
                        ],
                        "name": "S. Levinson",
                        "slug": "S.-Levinson",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Levinson",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Levinson"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 121831295,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "7c3f98c68b6609599771b1161c0d94200eae03dc",
            "isKey": false,
            "numCitedBy": 501,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Continuously-variable-duration-hidden-Markov-models-Levinson",
            "title": {
                "fragments": [],
                "text": "Continuously variable duration hidden Markov models for automatic speech recognition"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144799688"
                        ],
                        "name": "S. Taylor",
                        "slug": "S.-Taylor",
                        "structuredName": {
                            "firstName": "Suzanne",
                            "lastName": "Taylor",
                            "middleNames": [
                                "Liebowitz"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Taylor"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144615052"
                        ],
                        "name": "M. Lipshutz",
                        "slug": "M.-Lipshutz",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Lipshutz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Lipshutz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32028661"
                        ],
                        "name": "R. Nilson",
                        "slug": "R.-Nilson",
                        "structuredName": {
                            "firstName": "Roslyn",
                            "lastName": "Nilson",
                            "middleNames": [
                                "Weidner"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Nilson"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 211,
                                "start": 193
                            }
                        ],
                        "text": "The results of such classification can then be verified by more elaborate methods using more complicated geometric and syntactic models for each particular class (e.g., Dengel and Dubiel 1996, Taylor et al. 1995, Walischewski 1997)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "The results of such classification can then be verified by more elaborate methods using more complicated geometric and syntactic models for each particular class (e.g., Dengel and Dubiel 1996,  Taylor et al. 1995,  Walischewski 1997)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "In order to allow more flexibility we chose to use a mechanism called explicit duration modeling, resulting in a variable-duration HMM which was first introduced in speech recognition (Ferguson 1980, Levinson 1986) and later proved effective for signature verification as well ( Kashi et al. 1997 )."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 9004,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f50381a175436d453aa0bbaa98294a8f438a2f6a",
            "isKey": false,
            "numCitedBy": 22,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes recent efforts to develop a document classification system. Our classification approach uses two steps: first, the document is sorted by the number of columns and second, functional landmarks are detected to determine the class. Results for detecting and classifying business class documents are included."
            },
            "slug": "Classification-and-functional-decomposition-of-Taylor-Lipshutz",
            "title": {
                "fragments": [],
                "text": "Classification and functional decomposition of business documents"
            },
            "tldr": {
                "abstractSimilarityScore": 88,
                "text": "This paper describes recent efforts to develop a document classification system that uses two steps: first, the document is sorted by the number of columns and second, functional landmarks are detected to determine the class."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of 3rd International Conference on Document Analysis and Recognition"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2608771"
                        ],
                        "name": "A. Gersho",
                        "slug": "A.-Gersho",
                        "structuredName": {
                            "firstName": "Allen",
                            "lastName": "Gersho",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Gersho"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144790332"
                        ],
                        "name": "R. Gray",
                        "slug": "R.-Gray",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Gray",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Gray"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 108,
                                "start": 88
                            }
                        ],
                        "text": "A simple and effective means for computing clusters is thek-means clustering technique (Gersho and Gray 1992."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 118950728,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c564aa7639a08c280423489e52b6e32055c9aa7f",
            "isKey": false,
            "numCitedBy": 7028,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "1 Introduction.- 1.1 Signals, Coding, and Compression.- 1.2 Optimality.- 1.3 How to Use this Book.- 1.4 Related Reading.- I Basic Tools.- 2 Random Processes and Linear Systems.- 2.1 Introduction.- 2.2 Probability.- 2.3 Random Variables and Vectors.- 2.4 Random Processes.- 2.5 Expectation.- 2.6 Linear Systems.- 2.7 Stationary and Ergodic Properties.- 2.8 Useful Processes.- 2.9 Problems.- 3 Sampling.- 3.1 Introduction.- 3.2 Periodic Sampling.- 3.3 Noise in Sampling.- 3.4 Practical Sampling Schemes.- 3.5 Sampling Jitter.- 3.6 Multidimensional Sampling.- 3.7 Problems.- 4 Linear Prediction.- 4.1 Introduction.- 4.2 Elementary Estimation Theory.- 4.3 Finite-Memory Linear Prediction.- 4.4 Forward and Backward Prediction.- 4.5 The Levinson-Durbin Algorithm.- 4.6 Linear Predictor Design from Empirical Data.- 4.7 Minimum Delay Property.- 4.8 Predictability and Determinism.- 4.9 Infinite Memory Linear Prediction.- 4.10 Simulation of Random Processes.- 4.11 Problems.- II Scalar Coding.- 5 Scalar Quantization I.- 5.1 Introduction.- 5.2 Structure of a Quantizer.- 5.3 Measuring Quantizer Performance.- 5.4 The Uniform Quantizer.- 5.5 Nonuniform Quantization and Companding.- 5.6 High Resolution: General Case.- 5.7 Problems.- 6 Scalar Quantization II.- 6.1 Introduction.- 6.2 Conditions for Optimality.- 6.3 High Resolution Optimal Companding.- 6.4 Quantizer Design Algorithms.- 6.5 Implementation.- 6.6 Problems.- 7 Predictive Quantization.- 7.1 Introduction.- 7.2 Difference Quantization.- 7.3 Closed-Loop Predictive Quantization.- 7.4 Delta Modulation.- 7.5 Problems.- 8 Bit Allocation and Transform Coding.- 8.1 Introduction.- 8.2 The Problem of Bit Allocation.- 8.3 Optimal Bit Allocation Results.- 8.4 Integer Constrained Allocation Techniques.- 8.5 Transform Coding.- 8.6 Karhunen-Loeve Transform.- 8.7 Performance Gain of Transform Coding.- 8.8 Other Transforms.- 8.9 Sub-band Coding.- 8.10 Problems.- 9 Entropy Coding.- 9.1 Introduction.- 9.2 Variable-Length Scalar Noiseless Coding.- 9.3 Prefix Codes.- 9.4 Huffman Coding.- 9.5 Vector Entropy Coding.- 9.6 Arithmetic Coding.- 9.7 Universal and Adaptive Entropy Coding.- 9.8 Ziv-Lempel Coding.- 9.9 Quantization and Entropy Coding.- 9.10 Problems.- III Vector Coding.- 10 Vector Quantization I.- 10.1 Introduction.- 10.2 Structural Properties and Characterization.- 10.3 Measuring Vector Quantizer Performance.- 10.4 Nearest Neighbor Quantizers.- 10.5 Lattice Vector Quantizers.- 10.6 High Resolution Distortion Approximations.- 10.7 Problems.- 11 Vector Quantization II.- 11.1 Introduction.- 11.2 Optimality Conditions for VQ.- 11.3 Vector Quantizer Design.- 11.4 Design Examples.- 11.5 Problems.- 12 Constrained Vector Quantization.- 12.1 Introduction.- 12.2 Complexity and Storage Limitations.- 12.3 Structurally Constrained VQ.- 12.4 Tree-Structured VQ.- 12.5 Classified VQ.- 12.6 Transform VQ.- 12.7 Product Code Techniques.- 12.8 Partitioned VQ.- 12.9 Mean-Removed VQ.- 12.10 Shape-Gain VQ.- 12.11 Multistage VQ.- 12.12 Constrained Storage VQ.- 12.13 Hierarchical and Multiresolution VQ.- 12.14 Nonlinear Interpolative VQ.- 12.15 Lattice Codebook VQ.- 12.16 Fast Nearest Neighbor Encoding.- 12.17 Problems.- 13 Predictive Vector Quantization.- 13.1 Introduction.- 13.2 Predictive Vector Quantization.- 13.3 Vector Linear Prediction.- 13.4 Predictor Design from Empirical Data.- 13.5 Nonlinear Vector Prediction.- 13.6 Design Examples.- 13.7 Problems.- 14 Finite-State Vector Quantization.- 14.1 Recursive Vector Quantizers.- 14.2 Finite-State Vector Quantizers.- 14.3 Labeled-States and Labeled-Transitions.- 14.4 Encoder/Decoder Design.- 14.5 Next-State Function Design.- 14.6 Design Examples.- 14.7 Problems.- 15 Tree and Trellis Encoding.- 15.1 Delayed Decision Encoder.- 15.2 Tree and Trellis Coding.- 15.3 Decoder Design.- 15.4 Predictive Trellis Encoders.- 15.5 Other Design Techniques.- 15.6 Problems.- 16 Adaptive Vector Quantization.- 16.1 Introduction.- 16.2 Mean Adaptation.- 16.3 Gain-Adaptive Vector Quantization.- 16.4 Switched Codebook Adaptation.- 16.5 Adaptive Bit Allocation.- 16.6 Address VQ.- 16.7 Progressive Code Vector Updating.- 16.8 Adaptive Codebook Generation.- 16.9 Vector Excitation Coding.- 16.10 Problems.- 17 Variable Rate Vector Quantization.- 17.1 Variable Rate Coding.- 17.2 Variable Dimension VQ.- 17.3 Alternative Approaches to Variable Rate VQ.- 17.4 Pruned Tree-Structured VQ.- 17.5 The Generalized BFOS Algorithm.- 17.6 Pruned Tree-Structured VQ.- 17.7 Entropy Coded VQ.- 17.8 Greedy Tree Growing.- 17.9 Design Examples.- 17.10 Bit Allocation Revisited.- 17.11 Design Algorithms.- 17.12 Problems."
            },
            "slug": "Vector-quantization-and-signal-compression-Gersho-Gray",
            "title": {
                "fragments": [],
                "text": "Vector quantization and signal compression"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "The author explains the design and implementation of the Levinson-Durbin Algorithm, which automates the very labor-intensive and therefore time-heavy and expensive process of designing and implementing a Quantizer."
            },
            "venue": {
                "fragments": [],
                "text": "The Kluwer international series in engineering and computer science"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712517"
                        ],
                        "name": "L. Rabiner",
                        "slug": "L.-Rabiner",
                        "structuredName": {
                            "firstName": "Lawrence",
                            "lastName": "Rabiner",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Rabiner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143604406"
                        ],
                        "name": "B. Juang",
                        "slug": "B.-Juang",
                        "structuredName": {
                            "firstName": "Biing-Hwang",
                            "lastName": "Juang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Juang"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 184,
                                "start": 162
                            }
                        ],
                        "text": "Second, HMMs have been well studied and have proven to be very effective in modeling other stochastic sequences of signals such as speech or on-line handwriting (Rabiner and Juang 1993, Hu et al. 1996)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 129,
                                "start": 107
                            }
                        ],
                        "text": "Furthermore, there exist well established efficient algorithms for both model training and classification (Rabiner and Juang 1993)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 116,
                                "start": 92
                            }
                        ],
                        "text": "The HMM of each layout class is trained by applying a segmental k-means iterative procedure Rabiner and Juang (1993) across all the training samples in the class."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 264,
                                "start": 242
                            }
                        ],
                        "text": "We use the Viterbi algorithm for both training and classification as opposed to the more rigorous Baum-Welch and forward-backward procedures because the former can easily accommodate explicit duration modeling without much extra computation (Rabiner and Juang 1993)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 7788300,
            "fieldsOfStudy": [
                "Computer Science",
                "Physics"
            ],
            "id": "df50c6e1903b1e2d657f78c28ab041756baca86a",
            "isKey": true,
            "numCitedBy": 8924,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "1. Fundamentals of Speech Recognition. 2. The Speech Signal: Production, Perception, and Acoustic-Phonetic Characterization. 3. Signal Processing and Analysis Methods for Speech Recognition. 4. Pattern Comparison Techniques. 5. Speech Recognition System Design and Implementation Issues. 6. Theory and Implementation of Hidden Markov Models. 7. Speech Recognition Based on Connected Word Models. 8. Large Vocabulary Continuous Speech Recognition. 9. Task-Oriented Applications of Automatic Speech Recognition."
            },
            "slug": "Fundamentals-of-speech-recognition-Rabiner-Juang",
            "title": {
                "fragments": [],
                "text": "Fundamentals of speech recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This book presents a meta-modelling framework for speech recognition that automates the very labor-intensive and therefore time-heavy and therefore expensive and expensive process of manually modeling speech."
            },
            "venue": {
                "fragments": [],
                "text": "Prentice Hall signal processing series"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1788607"
                        ],
                        "name": "W. Turin",
                        "slug": "W.-Turin",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Turin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Turin"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 130,
                                "start": 120
                            }
                        ],
                        "text": "It is easy to prove that any variable duration HMM model is equivalent to the so-called canonical HSMM in whichaii = 0 (Turin 1990)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 132,
                                "start": 122
                            }
                        ],
                        "text": "This model can also be called a Hidden Semi-Markov Model (HSMM), because the underlying process is a semi-Markov process (Turin 1990)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 132,
                                "start": 120
                            }
                        ],
                        "text": "It is easy to prove that any variable duration HMM model is equivalent to the so-called canonical HSMM in which aii = 0 (Turin 1990)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 60654079,
            "fieldsOfStudy": [
                "Business"
            ],
            "id": "d366c72b39319cc3d44d97d703015a723ae905e3",
            "isKey": true,
            "numCitedBy": 75,
            "numCiting": 2,
            "paperAbstract": {
                "fragments": [],
                "text": "If you want to get Performance Analysis of Digital Transmission Systems pdf eBook copy write by good author William Turin, you can download the book copy here. The Performance Analysis of Digital Transmission Systems we think have quite excellent writing style that make it easy to comprehend."
            },
            "slug": "Performance-Analysis-of-Digital-Transmission-Turin",
            "title": {
                "fragments": [],
                "text": "Performance Analysis of Digital Transmission Systems"
            },
            "tldr": {
                "abstractSimilarityScore": 59,
                "text": "The Performance Analysis of Digital Transmission Systems the authors think have quite excellent writing style that make it easy to comprehend."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1693256"
                        ],
                        "name": "D. Sankoff",
                        "slug": "D.-Sankoff",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Sankoff",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Sankoff"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "10398168"
                        ],
                        "name": "J. Kruskal",
                        "slug": "J.-Kruskal",
                        "structuredName": {
                            "firstName": "Joseph",
                            "lastName": "Kruskal",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Kruskal"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1403841706"
                        ],
                        "name": "Time Warps Eds",
                        "slug": "Time-Warps-Eds",
                        "structuredName": {
                            "firstName": "Time",
                            "lastName": "Eds",
                            "middleNames": [
                                "Warps"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Time Warps Eds"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "52535398"
                        ],
                        "name": "String Edits",
                        "slug": "String-Edits",
                        "structuredName": {
                            "firstName": "String",
                            "lastName": "Edits",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "String Edits"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 56729381,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "24ff739a7ade6b79ad92440b0f5f2a9a5fb838af",
            "isKey": false,
            "numCitedBy": 1351,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "A mudflap assembly for use with a dump vehicle having dual tires at the rear end thereof and including a pair of flexible flap sections one of which is supported by a rigid member adjacent the dual tires and the other is located above and to the rear of the rigid member and is secured at its upper end to the dump body. The rigid member is pivotally connected to the dump body and is combined with a cable which assures that the attached flap section maintains substantially the same position when the dump body is in the lowered-carry-position or raised-dump-position."
            },
            "slug": "Macromolecules:-the-theory-and-practice-of-sequence-Sankoff-Kruskal",
            "title": {
                "fragments": [],
                "text": "Macromolecules: the theory and practice of sequence comparison"
            },
            "tldr": {
                "abstractSimilarityScore": 67,
                "text": "A mudflap assembly for use with a dump vehicle having dual tires at the rear end thereof and including a pair of flexible flap sections that assures that the attached flap section maintains substantially the same position when the dump body is in the lowered-carry-position or raised-dump-position."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1983
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2886380"
                        ],
                        "name": "S. Sturrock",
                        "slug": "S.-Sturrock",
                        "structuredName": {
                            "firstName": "Shane",
                            "lastName": "Sturrock",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Sturrock"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 86397843,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "abcab02ebe45bdfc4b8e5e272ebb3f7471a2cdec",
            "isKey": false,
            "numCitedBy": 772,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Time-Warps,-String-Edits,-and-Macromolecules-\u2013-The-Sturrock",
            "title": {
                "fragments": [],
                "text": "Time Warps, String Edits, and Macromolecules \u2013 The Theory and Practice of Sequence Comparison . David Sankoff and Joseph Kruskal. ISBN 1-57586-217-4. Price \u00a313.95 (US$22\u00b795)."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 198,
                                "start": 185
                            }
                        ],
                        "text": "In order to allow more flexibility we chose to use a mechanism called explicit duration modeling, resulting in a variable-duration HMM which was first introduced in speech recognition (Ferguson 1980, Levinson 1986) and later proved effective for signature verification as well (Kashi et al. 1997)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Variable duration models for speech"
            },
            "venue": {
                "fragments": [],
                "text": "Ulm, Germany,"
            },
            "year": 1980
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "ICDAR\u201997, Ulm, Germany, pp. 718\u2013721"
            },
            "venue": {
                "fragments": [],
                "text": "Dengel A and Dubiel F"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "COMPARISON AND CLASSIFICATION OF DOCUMENTS"
            },
            "venue": {
                "fragments": [],
                "text": "COMPARISON AND CLASSIFICATION OF DOCUMENTS"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 295,
                                "start": 278
                            }
                        ],
                        "text": "In order to allow more flexibility we chose to use a mechanism called explicit duration modeling, resulting in a variable-duration HMM which was first introduced in speech recognition (Ferguson 1980, Levinson 1986) and later proved effective for signature verification as well (Kashi et al. 1997)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "On-line handwriting signature verification"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1997
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 3,
            "methodology": 16
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 22,
        "totalPages": 3
    },
    "page_url": "https://www.semanticscholar.org/paper/Comparison-and-Classification-of-Documents-Based-on-Hu-Kashi/8efc295011e191d4830d0f066e0c8d06a9631b15?sort=total-citations"
}