{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145414142"
                        ],
                        "name": "B. Chandrasekaran",
                        "slug": "B.-Chandrasekaran",
                        "structuredName": {
                            "firstName": "B.",
                            "lastName": "Chandrasekaran",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Chandrasekaran"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 42958730,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "f810af6562c2a62a2adcb74781b2270eada89260",
            "isKey": false,
            "numCitedBy": 46,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "A situation of great practical importance in pattern recognition is the case where the designer has only a finite number of sample patterns from each class and the class-conditional density functions are not completely known. Recent results indicate that in this case the dimensionality of the pattern vector, i.e., the number of measurements, should not be arbitrarily increased, since above a certain value (corresponding to the optimal measurement complexity), the performance starts to deteriorate instead of improving steadily. However, whether this phenomenon occurs in the case of independent measurements has been an open question until now. In this paper the following result of practical importance is derived. When the measurements are independent, and a Bayesian approach is taken, one can add extra measurements without fear of this peaking of performance; i.e., the optimal measurement complexity is infinite. In fact, under certain conditions, having just one sample from class 1, and none at all from class 2, can result in a recognition accuracy arbitrarily close to unity for a large enough number of measurements. The implication of these results to practice is discussed, along with the general question of dimensionality and sample size."
            },
            "slug": "Independence-of-measurements-and-the-mean-accuracy-Chandrasekaran",
            "title": {
                "fragments": [],
                "text": "Independence of measurements and the mean recognition accuracy"
            },
            "tldr": {
                "abstractSimilarityScore": 50,
                "text": "In this paper the following result of practical importance is derived: under certain conditions, having just one sample from class 1, and none at all from class 2, can result in a recognition accuracy arbitrarily close to unity for a large enough number of measurements."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Inf. Theory"
            },
            "year": 1971
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "14824508"
                        ],
                        "name": "Donald H. Foley",
                        "slug": "Donald-H.-Foley",
                        "structuredName": {
                            "firstName": "Donald",
                            "lastName": "Foley",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Donald H. Foley"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 29377844,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8823ea9fe521258d78e09584ab9f8d5b8d05cfcd",
            "isKey": false,
            "numCitedBy": 324,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "In many practical pattern-classification problems the underlying probability distributions are not completely known. Consequently, the classification logic must be determined on the basis of vector samples gathered for each class. Although it is common knowledge that the error rate on the design set is a biased estimate of the true error rate of the classifier, the amount of bias as a function of sample size per class and feature size has been an open question. In this paper, the design-set error rate for a two-class problem with multivariate normal distributions is derived as a function of the sample size per class (N) and dimensionality (L) . The design-set error rate is compared to both the corresponding Bayes error rate and the test-set error rate. It is demonstrated that the design-set error rate is an extremely biased estimate of either the Bayes or test-set error rate if the ratio of samples per class to dimensions (N/L) is less than three. Also the variance of the design-set error rate is approximated by a function that is bounded by 1/8N ."
            },
            "slug": "Considerations-of-sample-and-feature-size-Foley",
            "title": {
                "fragments": [],
                "text": "Considerations of sample and feature size"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "The design-set error rate for a two-class problem with multivariate normal distributions is derived as a function of the sample size per class (N) and dimensionality (L) and is demonstrated to be an extremely biased estimate of either the Bayes or test- set error rate."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Inf. Theory"
            },
            "year": 1972
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145295484"
                        ],
                        "name": "Anil K. Jain",
                        "slug": "Anil-K.-Jain",
                        "structuredName": {
                            "firstName": "Anil",
                            "lastName": "Jain",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Anil K. Jain"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3087848"
                        ],
                        "name": "R. Dubes",
                        "slug": "R.-Dubes",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Dubes",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Dubes"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 35189037,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cbceeec05a9e3b7fd21e0694c35fb09a6f35c496",
            "isKey": false,
            "numCitedBy": 40,
            "numCiting": 52,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Feature-definition-in-pattern-recognition-with-size-Jain-Dubes",
            "title": {
                "fragments": [],
                "text": "Feature definition in pattern recognition with small sample size"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit."
            },
            "year": 1978
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2793874"
                        ],
                        "name": "W. Highleyman",
                        "slug": "W.-Highleyman",
                        "structuredName": {
                            "firstName": "Wilbur",
                            "lastName": "Highleyman",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Highleyman"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 123323236,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6a9b3cd5462530aa920f4d3893712cae1e632b76",
            "isKey": false,
            "numCitedBy": 107,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "A popular procedure for testing a pattern recognition machine is to present the machine with a set of patterns taken from the real world. The proportion of these patterns which are misrecognized or rejected is taken as the estimate of the error probability or rejection probability for the machine. In Part I, this testing procedure is discussed for the cases of unknown and known a priori probabilities of occurrence of the pattern classes. The differences between the tests that should be made in the two cases are noted, and confidence intervals for the test results are indicated. These concepts are applied to various published pattern recognition results by determining the appropriate confidence interval for each result. In Part II, the problem of the optimum partitioning of a sample of fixed size between the design and test phases of a pattern recognition machine is discussed. One important nonparametric result is that the proportion of the total sample used for testing the machine should never be less than that proportion used for designing the machine, and in some cases should be a good deal more."
            },
            "slug": "The-design-and-analysis-of-pattern-recognition-Highleyman",
            "title": {
                "fragments": [],
                "text": "The design and analysis of pattern recognition experiments"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "One important nonparametric result is that the proportion of the total sample used for testing the machine should never be less than that proportion used for designing the machine, and in some cases should be a good deal more."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1962
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2066539"
                        ],
                        "name": "G. Hughes",
                        "slug": "G.-Hughes",
                        "structuredName": {
                            "firstName": "Gordon",
                            "lastName": "Hughes",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Hughes"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 206729491,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "3e3ec72e932d7205a541e67e0f9a1fde5235eefd",
            "isKey": false,
            "numCitedBy": 2543,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "The overall mean recognition probability (mean accuracy) of a pattern classifier is calculated and numerically plotted as a function of the pattern measurement complexity n and design data set size m . Utilized is the well-known probabilistic model of a two-class, discrete-measurement pattern environment (no Gaussian or statistical independence assumptions are made). The minimum-error recognition rule (Bayes) is used, with the unknown pattern environment probabilities estimated from the data relative frequencies. In calculating the mean accuracy over all such environments, only three parameters remain in the final equation: n, m , and the prior probability p_{c} of either of the pattern classes. With a fixed design pattern sample, recognition accuracy can first increase as the number of measurements made on a pattern increases, but decay with measurement complexity higher than some optimum value. Graphs of the mean accuracy exhibit both an optimal and a maximum acceptable value of n for fixed m and p_{c} . A four-place tabulation of the optimum n and maximum mean accuracy values is given for equally likely classes and m ranging from 2 to 1000 . The penalty exacted for the generality of the analysis is the use of the mean accuracy itself as a recognizer optimality criterion. Namely, one necessarily always has some particular recognition problem at hand whose Bayes accuracy will be higher or lower than the mean over all recognition problems having fixed n, m , and p_{c} ."
            },
            "slug": "On-the-mean-accuracy-of-statistical-pattern-Hughes",
            "title": {
                "fragments": [],
                "text": "On the mean accuracy of statistical pattern recognizers"
            },
            "tldr": {
                "abstractSimilarityScore": 97,
                "text": "The overall mean recognition probability (mean accuracy) of a pattern classifier is calculated and numerically plotted as a function of the pattern measurement complexity n and design data set size m, using the well-known probabilistic model of a two-class, discrete-measurement pattern environment."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Inf. Theory"
            },
            "year": 1968
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145414142"
                        ],
                        "name": "B. Chandrasekaran",
                        "slug": "B.-Chandrasekaran",
                        "structuredName": {
                            "firstName": "B.",
                            "lastName": "Chandrasekaran",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Chandrasekaran"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145295483"
                        ],
                        "name": "Anil K. Jain",
                        "slug": "Anil-K.-Jain",
                        "structuredName": {
                            "firstName": "Anil",
                            "lastName": "Jain",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Anil K. Jain"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 35360973,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "117842f7ba12e576ef12af9f598c1c0e13a33437",
            "isKey": false,
            "numCitedBy": 40,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "It is known that, in general, the number of measurements in a pattern classification problem cannot be increased arbitrarily, when the class-conditional densities are not completely known and only a finite number of learning samples are available. Above a certain number of measurements, the performance starts deteriorating instead of improving steadily. It was earlier shown by one of the authors that an exception to this \"curse of finite sample size\" is constituted by the case of binary independent measurements if a Bayesian approach is taken and uniform a priori on the unknown parameters are assumed. In this paper, the following generalizations are considered: arbitrary quantization and the use of maximum likelihood estimates. Further, the existence of an optimal quantization complexity is demonstrated, and its relationship to both the dimensionality of the measurement vector and the sample size are discussed. It is shown that the optimum number of quantization levels decreases with increasing dimensionality for a fixed sample size, and increases with the sample size for fixed dimensionality."
            },
            "slug": "Quantization-Complexity-and-Independent-Chandrasekaran-Jain",
            "title": {
                "fragments": [],
                "text": "Quantization Complexity and Independent Measurements"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "It is shown that the optimum number of quantization levels decreases with increasing dimensionality for a fixed sample size, and increases with the sample size for fixed dimensionality."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Computers"
            },
            "year": 1974
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2597670"
                        ],
                        "name": "L. Kanal",
                        "slug": "L.-Kanal",
                        "structuredName": {
                            "firstName": "Laveen",
                            "lastName": "Kanal",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Kanal"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145414142"
                        ],
                        "name": "B. Chandrasekaran",
                        "slug": "B.-Chandrasekaran",
                        "structuredName": {
                            "firstName": "B.",
                            "lastName": "Chandrasekaran",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Chandrasekaran"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 30908100,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "210899af38b9e74b669a23ccbafc4967d5c42794",
            "isKey": false,
            "numCitedBy": 180,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "On-dimensionality-and-sample-size-in-statistical-Kanal-Chandrasekaran",
            "title": {
                "fragments": [],
                "text": "On dimensionality and sample size in statistical pattern classification"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit."
            },
            "year": 1971
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145295484"
                        ],
                        "name": "Anil K. Jain",
                        "slug": "Anil-K.-Jain",
                        "structuredName": {
                            "firstName": "Anil",
                            "lastName": "Jain",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Anil K. Jain"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144265468"
                        ],
                        "name": "W. Waller",
                        "slug": "W.-Waller",
                        "structuredName": {
                            "firstName": "W.",
                            "lastName": "Waller",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Waller"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 45437199,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "020025ea66fe7276ae4322371115f3fb983a2503",
            "isKey": false,
            "numCitedBy": 116,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "On-the-optimal-number-of-features-in-the-of-data-Jain-Waller",
            "title": {
                "fragments": [],
                "text": "On the optimal number of features in the classification of multivariate Gaussian data"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit."
            },
            "year": 1978
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145801638"
                        ],
                        "name": "J. Kittler",
                        "slug": "J.-Kittler",
                        "structuredName": {
                            "firstName": "Josef",
                            "lastName": "Kittler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Kittler"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 31445100,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d893cf1b0939131c1346b105ecc13ccd0e1fa278",
            "isKey": false,
            "numCitedBy": 79,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Mathematics-Methods-of-Feature-Selection-in-Pattern-Kittler",
            "title": {
                "fragments": [],
                "text": "Mathematics Methods of Feature Selection in Pattern Recognition"
            },
            "venue": {
                "fragments": [],
                "text": "Int. J. Man Mach. Stud."
            },
            "year": 1975
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34677154"
                        ],
                        "name": "S. Morgera",
                        "slug": "S.-Morgera",
                        "structuredName": {
                            "firstName": "Salvatore",
                            "lastName": "Morgera",
                            "middleNames": [
                                "Domenic"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Morgera"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2064718531"
                        ],
                        "name": "D. Cooper",
                        "slug": "D.-Cooper",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Cooper",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Cooper"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 8412168,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "09f27374c8fb7d5c8f5f2285f0f39e4bdaa457aa",
            "isKey": false,
            "numCitedBy": 24,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "In this work we explore a number of questions arising in the Gaussian two-category classification problem when the common covariance matrix is unknown and must be estimated in order to approximate the hyperplane for decisionmaking, which is optimum for the true covariance matrix. Computed curves and, in some cases, closed form expressions are presented for describing the performance of such adaptive systems as a function of data dimensionality and learning sample size. In particular, we show that a considerable improvement in performance can be realized through the use of some {\\em a priori} knowledge of covariance matrix structure. We use the adaptive filter output signal-to-interference noise power ratio (SIR) as a measure of detection performance to compare estimators designed for a weakly stationary stochastic process (Toeplitz form covariance matrix) with an estimator designed for a general sample covariance matrix. The ratio of expected SIR performance for a generalized covariance estimate to that for a filter which is optimum for the true covariance matrix is shown to be \\cong [1 - N/N_{s} - 7/N_{s}] , where N is the filter (data) dimension, and N_{s} is the sample size. For a constrained Toeplitz form covariance matrix estimate, it is argued that the expected SIR approaches the optimum SIR as \\cong [1 - \\pi' (N;B)/N_{s} - 7 \\pi'(N;B)/NN_{s}] , with \\pi'(N;B) \\cong A + (B + 1) \\ln N + 1/2N , where A = 0.577 is Euler's constant, and 0 \\leq B is the input data correlation time normalized by the sampling period. Therefore, the constrained Toeplitz covariance matrix estimate appears to operate with an \"effective sample size\" equal to N'_{s} \\cong [N/ \\pi' (N;B)]N_{s} and offers the potential of high expected SIR at a sample size N_{s} for which the generalized estimator may provide poor results. The effective sample size is shown to be {\\em even greater} if the dimensionality of the constrained Toeplitz covariance matrix estimate is tailored to the input data correlation time in the sense that only a band of lags about the main diagonal is estimated. In this case, N'_{s} \\cong (kN^{2})N_{s} , where k is a constant, independent of N. An estimate of the computational error associated with the results, and due primarily to a quadratic approximation employed for the SIR, is derived and compared with the normal statistical error. Because closed form solutions for adaptive filter performance generally involve tedious calculations and involved expressions, certain other workers have relied on a similar approximation, but without the benefit of knowing the quality of the approximation for a given N and N_{s} . Insight is also provided into other matters such as the effect of the specific form of the category mean value vector (signal) on adaptation performance. It is felt that many application areas will benefit from the results presented here, e.g., biomedical image recognition, earth resource satellite multispectral data classification, adaptive linear prediction, adaptive antenna array processing, etc. The manner in which the results impact the array processing area is discussed in some detail."
            },
            "slug": "Structured-estimation:-Sample-size-reduction-for-Morgera-Cooper",
            "title": {
                "fragments": [],
                "text": "Structured estimation: Sample size reduction for adaptive pattern classification"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This work uses the adaptive filter output signal-to-interference noise power ratio (SIR) as a measure of detection performance to compare estimators designed for a weakly stationary stochastic process (Toeplitz form covariance matrix), and shows that a considerable improvement in performance can be realized through the use of some a priori knowledge of covariance Matrix structure."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Inf. Theory"
            },
            "year": 1977
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145414142"
                        ],
                        "name": "B. Chandrasekaran",
                        "slug": "B.-Chandrasekaran",
                        "structuredName": {
                            "firstName": "B.",
                            "lastName": "Chandrasekaran",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Chandrasekaran"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145295484"
                        ],
                        "name": "Anil K. Jain",
                        "slug": "Anil-K.-Jain",
                        "structuredName": {
                            "firstName": "Anil",
                            "lastName": "Jain",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Anil K. Jain"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 11552015,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5c4ec96b64f1c67a82723154b7a6a3deab25188f",
            "isKey": false,
            "numCitedBy": 34,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "If f(x) and g(x) are the densities for the N-dimensional measurement vector x, conditioned on the classes c1 and c2, and if finite sets of samples from the two classes are available, then a decision function based on estimates f(x) and \u00bf(x) can be used to classify future observations. In general, however, when the measurement complexity (the dimensionality N) is increased arbitrarily and the sets of training samples remain finite, a ``peaking phenomenon'' of the following kind is observed: classification accuracy improves at first, peaks at a finite value of N, called the optimum measurement complexity, and starts deteriorating thereafter. We derive, for the case of statistically independent measurements, general conditions under which it can be guaranteed that the peaking phenomenon will not occur, and the correct classification probability will keep increasing to value unity as N \u00bf \u00bf. Several applications are considered which together indicate, contrary to general belief, that independence of measurements alone does not guarantee the absence of the peaking phenomenon."
            },
            "slug": "Independence,-Measurement-Complexity,-and-Chandrasekaran-Jain",
            "title": {
                "fragments": [],
                "text": "Independence, Measurement Complexity, and Classification Performance"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This work derives, for the case of statistically independent measurements, general conditions under which it can be guaranteed that the peaking phenomenon will not occur, and the correct classification probability will keep increasing to value unity as N \u00bf \u00bf."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Systems, Man, and Cybernetics"
            },
            "year": 1975
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3253204"
                        ],
                        "name": "J. V. Ness",
                        "slug": "J.-V.-Ness",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Ness",
                            "middleNames": [
                                "W.",
                                "Van"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. V. Ness"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 13071988,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ec3207745f17b2e041ac8d39177eafd04031b1b6",
            "isKey": false,
            "numCitedBy": 57,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "On-the-dominance-of-non-parametric-Bayes-rule-in-Ness",
            "title": {
                "fragments": [],
                "text": "On the dominance of non-parametric Bayes rule discriminant algorithms in high dimensions"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit."
            },
            "year": 1980
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1752732"
                        ],
                        "name": "T. Cover",
                        "slug": "T.-Cover",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Cover",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Cover"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3108177"
                        ],
                        "name": "P. Hart",
                        "slug": "P.-Hart",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Hart",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Hart"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5246200,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "0efb841403aa6252b39ae6975c1cc5410554ef7b",
            "isKey": false,
            "numCitedBy": 10769,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "The nearest neighbor decision rule assigns to an unclassified sample point the classification of the nearest of a set of previously classified points. This rule is independent of the underlying joint distribution on the sample points and their classifications, and hence the probability of error R of such a rule must be at least as great as the Bayes probability of error R^{\\ast} --the minimum probability of error over all decision rules taking underlying probability structure into account. However, in a large sample analysis, we will show in the M -category case that R^{\\ast} \\leq R \\leq R^{\\ast}(2 --MR^{\\ast}/(M-1)) , where these bounds are the tightest possible, for all suitably smooth underlying distributions. Thus for any number of categories, the probability of error of the nearest neighbor rule is bounded above by twice the Bayes probability of error. In this sense, it may be said that half the classification information in an infinite sample set is contained in the nearest neighbor."
            },
            "slug": "Nearest-neighbor-pattern-classification-Cover-Hart",
            "title": {
                "fragments": [],
                "text": "Nearest neighbor pattern classification"
            },
            "tldr": {
                "abstractSimilarityScore": 75,
                "text": "The nearest neighbor decision rule assigns to an unclassified sample point the classification of the nearest of a set of previously classified points, so it may be said that half the classification information in an infinite sample set is contained in the nearest neighbor."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Inf. Theory"
            },
            "year": 1967
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35242613"
                        ],
                        "name": "R. Kain",
                        "slug": "R.-Kain",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Kain",
                            "middleNames": [
                                "Y."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Kain"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 43498699,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "b79b0894063333a9f8e1595f2403a3cd2b96ac54",
            "isKey": false,
            "numCitedBy": 9,
            "numCiting": 1,
            "paperAbstract": {
                "fragments": [],
                "text": "Hughes [1] presented some curves relating the mean performance of a pattern classifier averaged over all pattern recognition problems of given complexity, when there are two classes of patterns to be distinguished. In this correspondence the mean recognition probability is computed for the case of q pattern classes when the a priori probabilities of the classes are equal. When the a priori probabilities are unequal, the mean performance will improve over the performance with equal a priori probabilities, so these curves provide a lower bound to the performance of recognizers with more than two pattern classes. Some comments on the appropriateness of these statistics to common recognition problems are made."
            },
            "slug": "The-mean-accuracy-of-pattern-recognizers-with-many-Kain",
            "title": {
                "fragments": [],
                "text": "The mean accuracy of pattern recognizers with many pattern classes (Corresp.)"
            },
            "tldr": {
                "abstractSimilarityScore": 74,
                "text": "Some curves relating the mean performance of a pattern classifier averaged over all pattern recognition problems of given complexity provide a lower bound to the performance of recognizers with more than two pattern classes."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Inf. Theory"
            },
            "year": 1969
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145886892"
                        ],
                        "name": "A. Levine",
                        "slug": "A.-Levine",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Levine",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Levine"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8439077"
                        ],
                        "name": "L. Lustick",
                        "slug": "L.-Lustick",
                        "structuredName": {
                            "firstName": "Leonard",
                            "lastName": "Lustick",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Lustick"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1395476406"
                        ],
                        "name": "B. Saltzberg",
                        "slug": "B.-Saltzberg",
                        "structuredName": {
                            "firstName": "Barney",
                            "lastName": "Saltzberg",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Saltzberg"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 7161332,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "5689e19ef7c29b3860b4fd60cde9e856bc9f5571",
            "isKey": false,
            "numCitedBy": 14,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "It is shown in the classification problem, when independent samples are taken from uniform distributions, that for small sample sizes the probability of misclassification when using the nearest-neighbor rule is \"close\" to its asymptotic value. It is also shown that when using this rule the probability of classification in many cases is close to its Bayes optimum even for small sample sizes. Moreover, if one is restricted to a small sample size from one population, it is shown that it is not necessary to \"make up\" this deficiency by taking a large sample from the other population; best results may be obtained when both sample sizes are small."
            },
            "slug": "The-nearest-neighbor-rule-for-small-samples-drawn-Levine-Lustick",
            "title": {
                "fragments": [],
                "text": "The nearest-neighbor rule for small samples drawn from uniform distributions (Corresp.)"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "If one is restricted to a small sample size from one population, it is shown that it is not necessary to \"make up\" this deficiency by taking a large sample from the other population; best results may be obtained when both sample sizes are small."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Inf. Theory"
            },
            "year": 1973
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2068624378"
                        ],
                        "name": "I. T. Young",
                        "slug": "I.-T.-Young",
                        "structuredName": {
                            "firstName": "Ian",
                            "lastName": "Young",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. T. Young"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 19894760,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "918aab49ac158f111d0f66f9cd4074e4b2f2f4e8",
            "isKey": false,
            "numCitedBy": 11,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "It is shown that in the context of a specific pattern classification decision metric the number of samples M needed to characterize a cluster described by N features is M \\geq (1 + \\beta^{-1})(N + 2) where \\beta represents an interval width. The distance metric d^{2}(X)=(X-\\hat{\\mu}_{x})^{t}S_{x}^{-l}(X-\\hat{\\mu}_{x}) is shown to have an F -distribution which leads to the result for M . An additional application of the distribution of d^{2}(X) is discussed in terms of a specific type of pattern classifier."
            },
            "slug": "Further-consideration-of-sample-and-feature-size-Young",
            "title": {
                "fragments": [],
                "text": "Further consideration of sample and feature size (Corresp.)"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "It is shown that in the context of a specific pattern classification decision metric the number of samples M needed to characterize a cluster described by N features is M \\geq (1 + \\beta^{-1})(N + 2) where \\beta represents an interval width."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Inf. Theory"
            },
            "year": 1978
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1752732"
                        ],
                        "name": "T. Cover",
                        "slug": "T.-Cover",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Cover",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Cover"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 18251470,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "445ad69010658097fc317f7b83f1198179eebae8",
            "isKey": false,
            "numCitedBy": 1840,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper develops the separating capacities of families of nonlinear decision surfaces by a direct application of a theorem in classical combinatorial geometry. It is shown that a family of surfaces having d degrees of freedom has a natural separating capacity of 2d pattern vectors, thus extending and unifying results of Winder and others on the pattern-separating capacity of hyperplanes. Applying these ideas to the vertices of a binary n-cube yields bounds on the number of spherically, quadratically, and, in general, nonlinearly separable Boolean functions of n variables. It is shown that the set of all surfaces which separate a dichotomy of an infinite, random, separable set of pattern vectors can be characterized, on the average, by a subset of only 2d extreme pattern vectors. In addition, the problem of generalizing the classifications on a labeled set of pattern points to the classification of a new point is defined, and it is found that the probability of ambiguous generalization is large unless the number of training patterns exceeds the capacity of the set of separating surfaces."
            },
            "slug": "Geometrical-and-Statistical-Properties-of-Systems-Cover",
            "title": {
                "fragments": [],
                "text": "Geometrical and Statistical Properties of Systems of Linear Inequalities with Applications in Pattern Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "It is shown that a family of surfaces having d degrees of freedom has a natural separating capacity of 2d pattern vectors, thus extending and unifying results of Winder and others on the pattern-separating capacity of hyperplanes."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Electron. Comput."
            },
            "year": 1965
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144265468"
                        ],
                        "name": "W. Waller",
                        "slug": "W.-Waller",
                        "structuredName": {
                            "firstName": "W.",
                            "lastName": "Waller",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Waller"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2107170867"
                        ],
                        "name": "A. Jain",
                        "slug": "A.-Jain",
                        "structuredName": {
                            "firstName": "Aneesh",
                            "lastName": "Jain",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Jain"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 27622226,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8a47cee153d39945112a27239ce8e75bb78dc69e",
            "isKey": false,
            "numCitedBy": 35,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "Even with a finite set of training samples, the performance of a Bayesian classifier can not be degraded by increasing the number of features, as long as the old features are recoverable from the new features. This is true even for the general Bayesian classifiers investigated by qq Hughes, a result which contradicts previous interpretations of Hughes' model. The reasons for these difficulties are discussed. It would appear that the peaking behavior of practical classifiers is caused principally by their nonoptimal use of the features."
            },
            "slug": "On-the-monotonicity-of-the-performance-of-Bayesian-Waller-Jain",
            "title": {
                "fragments": [],
                "text": "On the monotonicity of the performance of Bayesian classifiers (Corresp.)"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "It would appear that the peaking behavior of practical classifiers is caused principally by their nonoptimal use of the features, which contradicts previous interpretations of Hughes' model."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Inf. Theory"
            },
            "year": 1978
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47358212"
                        ],
                        "name": "E. Fix",
                        "slug": "E.-Fix",
                        "structuredName": {
                            "firstName": "Evelyn",
                            "lastName": "Fix",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Fix"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2541903"
                        ],
                        "name": "J. L. Hodges",
                        "slug": "J.-L.-Hodges",
                        "structuredName": {
                            "firstName": "Joseph",
                            "lastName": "Hodges",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. L. Hodges"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 115703342,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "1fa93fb4aa010d46b22393131bc61a0a0d041da0",
            "isKey": false,
            "numCitedBy": 218,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract : A classification procedure is worked out for the following situations: Two large samples, one from each of two populations, have been observed. An individual of unknown origin is to be classified as belonging to the first population if the majority of a specified odd number of individuals closet to the individual in question belong to the first population. This method has optimum properties when the number of closest individuals is permitted to be very large. For certain cases involving multivariate normal distributions with the same covariance matrix, the probabilities of possible misclassification have been computed and compared with those of the discriminant function method."
            },
            "slug": "Discriminatory-Analysis-Nonparametric-Small-Sample-Fix-Hodges",
            "title": {
                "fragments": [],
                "text": "Discriminatory Analysis - Nonparametric Discrimination: Small Sample Performance"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1952
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3253204"
                        ],
                        "name": "J. V. Ness",
                        "slug": "J.-V.-Ness",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Ness",
                            "middleNames": [
                                "W.",
                                "Van"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. V. Ness"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2064665421"
                        ],
                        "name": "Cary Simpson",
                        "slug": "Cary-Simpson",
                        "structuredName": {
                            "firstName": "Cary",
                            "lastName": "Simpson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Cary Simpson"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 120452588,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "id": "d33b8e8860f51962e52aa5a0da0b56d6e650d923",
            "isKey": false,
            "numCitedBy": 68,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "Given fixed numbers of labeled objects on which training data can be obtained, how many variables should be used for a particular discriminant algorithm? This, of course, cannot be answeredin general since it depends on the characteristics of the populations, the sample sizes, and the algorithm. Some insight is gained in this article by studying Gaussian populations and five algorithms: linear discrimination with urlknown means and known covariance, linear discrimination with unknown means and unknown covariances, quadratic discrimination with unknown covariances and two nonparametric Bayes-type algorithms having density estimates using different, kernels (Gaussian and Cauchy)."
            },
            "slug": "On-the-Effects-of-Dimension-in-Discriminant-Ness-Simpson",
            "title": {
                "fragments": [],
                "text": "On the Effects of Dimension in Discriminant Analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "Gaussian populations and five algorithms are studied: linear discrimination with urlknown means and known covariance, lineardiscrimination with unknown means and unknown covariances, quadratic discrimination with unknown covariansces, and two nonparametric Bayes-type algorithms having density estimates using different, kernels (Gaussian and Cauchy)."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1976
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46780537"
                        ],
                        "name": "G. Trunk",
                        "slug": "G.-Trunk",
                        "structuredName": {
                            "firstName": "Gerard",
                            "lastName": "Trunk",
                            "middleNames": [
                                "V."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Trunk"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 13086902,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "26cfe4cb725e8cb939cd968f44218b2d9a36a794",
            "isKey": false,
            "numCitedBy": 338,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": "In pattern recognition problems it has been noted that beyond a certain point the inclusion of additional parameters (that have been estimated) leads to higher probabilities of error. A simple problem has been formulated where the probability of error approaches zero as the dimensionality increases and all the parameters are known; on the other hand, the probability of error approaches one-half as the dimensionality increases and parameters are estimated."
            },
            "slug": "A-Problem-of-Dimensionality:-A-Simple-Example-Trunk",
            "title": {
                "fragments": [],
                "text": "A Problem of Dimensionality: A Simple Example"
            },
            "tldr": {
                "abstractSimilarityScore": 85,
                "text": "In pattern recognition problems it has been noted that beyond a certain point the inclusion of additional parameters (that have been estimated) leads to higher probabilities of error, so the probability of error approaches one-half as the dimensionality increases and parameters are estimated."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 1979
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "69577099"
                        ],
                        "name": "T. W. Anderson",
                        "slug": "T.-W.-Anderson",
                        "structuredName": {
                            "firstName": "Theodore",
                            "lastName": "Anderson",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. W. Anderson"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 121329348,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "dcfe0a16eadc7425d3e0d6ad9fa46020ed2a6381",
            "isKey": false,
            "numCitedBy": 203,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "The problem considered is the use of a set of measurements on an individual to decide from which of several populations he has been drawn. It is assumed that in each population there is a probability distribution of the measurements. Principles for choosing the rule of classification are based on costs of misclassification. Optimum procedures are derived in general terms. If the measurements are normally distributed, the procedures use one discriminant function in the case of two populations and several discriminant functions in the cases of more populations. The numerical example given involves three normal populations."
            },
            "slug": "Classification-by-multivariate-analysis-Anderson",
            "title": {
                "fragments": [],
                "text": "Classification by multivariate analysis"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1951
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48043195"
                        ],
                        "name": "R. Sitgreaves",
                        "slug": "R.-Sitgreaves",
                        "structuredName": {
                            "firstName": "Rosedith",
                            "lastName": "Sitgreaves",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Sitgreaves"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 116390598,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "565eeae5f0e8833086f2d6b61af82eb3aa48181c",
            "isKey": false,
            "numCitedBy": 8,
            "numCiting": 2,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "SOME-OPERATING-CHARACTERISTICS-OF-LINEAR-FUNCTIONS-Sitgreaves",
            "title": {
                "fragments": [],
                "text": "SOME OPERATING CHARACTERISTICS OF LINEAR DISCRIMINANT FUNCTIONS"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1973
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2295441"
                        ],
                        "name": "K. Fukunaga",
                        "slug": "K.-Fukunaga",
                        "structuredName": {
                            "firstName": "Keinosuke",
                            "lastName": "Fukunaga",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Fukunaga"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "16614627"
                        ],
                        "name": "D. Kessell",
                        "slug": "D.-Kessell",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Kessell",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Kessell"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 31582087,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "53ab651b1cdef21cc60776993226ecd5e063a66b",
            "isKey": false,
            "numCitedBy": 34,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "In an optimum pattern-recognition system the error rate is determined by the reject function. This correspondence describes how this property may be exploited to provide quantitative tests of model validity using unclassified test samples. These tests are basically goodness-of-fit tests for a function of the observations. One of these tests is shown to provide an improved estimate of error in Monte Carlo studies of complex systems. Results are given for normal distributions when parameters are estimated. In this case error estimates obtained from the empirical reject rate underestimate the actual error and performance depends on the ratio of design samples to dimension."
            },
            "slug": "Application-of-optimum-error-reject-functions-Fukunaga-Kessell",
            "title": {
                "fragments": [],
                "text": "Application of optimum error-reject functions (Corresp.)"
            },
            "tldr": {
                "abstractSimilarityScore": 95,
                "text": "In an optimum pattern-recognition system the error rate is determined by the reject function and this correspondence describes how this property may be exploited to provide quantitative tests of model validity using unclassified test samples, basically goodness-of-fit tests for a function of the observations."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Inf. Theory"
            },
            "year": 1972
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2661913"
                        ],
                        "name": "T. Kaminuma",
                        "slug": "T.-Kaminuma",
                        "structuredName": {
                            "firstName": "Tsuguchika",
                            "lastName": "Kaminuma",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kaminuma"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40423501"
                        ],
                        "name": "Satosi Watanabe",
                        "slug": "Satosi-Watanabe",
                        "structuredName": {
                            "firstName": "Satosi",
                            "lastName": "Watanabe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Satosi Watanabe"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 12441119,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "f6264b2e85d1e55a2505e56a77737bb29b4b5178",
            "isKey": false,
            "numCitedBy": 3,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Fast-converging-adaptive-algorithms-for-separating-Kaminuma-Watanabe",
            "title": {
                "fragments": [],
                "text": "Fast-converging adaptive algorithms for well-balanced separating linear classifier"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit."
            },
            "year": 1972
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1806659"
                        ],
                        "name": "Karl Pettis",
                        "slug": "Karl-Pettis",
                        "structuredName": {
                            "firstName": "Karl",
                            "lastName": "Pettis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Karl Pettis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39396458"
                        ],
                        "name": "Thomas A. Bailey",
                        "slug": "Thomas-A.-Bailey",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Bailey",
                            "middleNames": [
                                "A."
                            ],
                            "suffix": "Jr."
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thomas A. Bailey"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145295484"
                        ],
                        "name": "Anil K. Jain",
                        "slug": "Anil-K.-Jain",
                        "structuredName": {
                            "firstName": "Anil",
                            "lastName": "Jain",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Anil K. Jain"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3087848"
                        ],
                        "name": "R. Dubes",
                        "slug": "R.-Dubes",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Dubes",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Dubes"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 2196461,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e16225f089a52f4f8010cc1890bb5b519e0a6894",
            "isKey": false,
            "numCitedBy": 220,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "The intrinsic dimensionality of a set of patterns is important in determining an appropriate number of features for representing the data and whether a reasonable two- or three-dimensional representation of the data exists. We propose an intuitively appealing, noniterative estimator for intrinsic dimensionality which is based on nearneighbor information. We give plausible arguments supporting the consistency of this estimator. The method works well in identifying the true dimensionality for a variety of artificial data sets and is fairly insensitive to the number of samples and to the algorithmic parameters. Comparisons between this new method and the global eigenvalue approach demonstrate the utility of our estimator."
            },
            "slug": "An-Intrinsic-Dimensionality-Estimator-from-Pettis-Bailey",
            "title": {
                "fragments": [],
                "text": "An Intrinsic Dimensionality Estimator from Near-Neighbor Information"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "An intuitively appealing, noniterative estimator for intrinsic dimensionality which is based on nearneighbor information is proposed which works well in identifying the true dimensionality for a variety of artificial data sets and is fairly insensitive to the number of samples and to the algorithmic parameters."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 1979
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3382525"
                        ],
                        "name": "D. Lindley",
                        "slug": "D.-Lindley",
                        "structuredName": {
                            "firstName": "Dennis",
                            "lastName": "Lindley",
                            "middleNames": [
                                "V."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Lindley"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 124010735,
            "fieldsOfStudy": [
                "Business"
            ],
            "id": "f5f8d7249df5816d3ab0e0b706364e7b40e3f193",
            "isKey": false,
            "numCitedBy": 196,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "Professor R. L. PLACKETT in the Chair] SUMMARY This paper is concerned with the analysis of data from a multiple regression of a single variable, y, on a set of independent variables, xl, x2, .. . ,xr. It is argued that the form of the analysis should depend on the use that is to be made of the regression, and that therefore an approach employing ideas from decision theory may be worth while. Two situations are analysed in this way: in the first it is desired to predict a future value of y; in the second we wish to control y at a preassigned value. The two analyses are found to be different: in particular, the standard errors of the regression coefficients are found to be irrelevant in the prediction problem, but not in the control problem. In the former it is shown that, under rather special assumptions on the multiple regression experiment, the analysis is similar to that recommended by other writers. If the costs of control do not depend on the values at which the control takes place, a similar analysis holds for the second problem. The approach throughout is Bayesian: there is no discussion of this point, I merely ask the non-Bayesian reader to examine the results and consider whether they provide sensible and practical answers."
            },
            "slug": "The-Choice-of-Variables-in-Multiple-Regression-Lindley",
            "title": {
                "fragments": [],
                "text": "The Choice of Variables in Multiple Regression"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1968
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2597670"
                        ],
                        "name": "L. Kanal",
                        "slug": "L.-Kanal",
                        "structuredName": {
                            "firstName": "Laveen",
                            "lastName": "Kanal",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Kanal"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 32356452,
            "fieldsOfStudy": [
                "Computer Science",
                "Business"
            ],
            "id": "a9d03e50751ec8daad969db65adfde91add224e2",
            "isKey": false,
            "numCitedBy": 288,
            "numCiting": 167,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper selectively surveys contributions to major topics in pattern recognition since 1968. Representative books and surveys pattern recognition published during this period are listed. Theoretical models for automatic pattern recognition are contrasted with practical,, design methodology. Research contributions to statistical and structural pattern recognition are selectively discussed, including contributions to error estimation and the experimental design of pattern classifiers. The survey concludes with a representative set of applications of pattern recognition technology."
            },
            "slug": "Patterns-in-pattern-recognition:-1968-1974-Kanal",
            "title": {
                "fragments": [],
                "text": "Patterns in pattern recognition: 1968-1974"
            },
            "tldr": {
                "abstractSimilarityScore": 68,
                "text": "This paper selectively surveys contributions to major topics in pattern recognition since 1968, including contributions to error estimation and the experimental design of pattern classifiers."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Inf. Theory"
            },
            "year": 1974
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "102636025"
                        ],
                        "name": "C. Chow",
                        "slug": "C.-Chow",
                        "structuredName": {
                            "firstName": "C.",
                            "lastName": "Chow",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Chow"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 206730137,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ea36358e4363fa452b55de2325ceae9802a51d81",
            "isKey": false,
            "numCitedBy": 776,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": "The performance of a pattern recognition system is characterized by its error and reject tradeoff. This paper describes an optimum rejection rule and presents a general relation between the error and reject probabilities and some simple properties of the tradeoff in the optimum recognition system. The error rate can be directly evaluated from the reject function. Some practical implications of the results are discussed. Examples in normal distributions and uniform distributions are given."
            },
            "slug": "On-optimum-recognition-error-and-reject-tradeoff-Chow",
            "title": {
                "fragments": [],
                "text": "On optimum recognition error and reject tradeoff"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "An optimum rejection rule is described and a general relation between the error and reject probabilities and some simple properties of the tradeoff in the optimum recognition system are presented."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Inf. Theory"
            },
            "year": 1970
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2004393"
                        ],
                        "name": "T. Boullion",
                        "slug": "T.-Boullion",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Boullion",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Boullion"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2896496"
                        ],
                        "name": "P. Odell",
                        "slug": "P.-Odell",
                        "structuredName": {
                            "firstName": "Patrick",
                            "lastName": "Odell",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Odell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32530082"
                        ],
                        "name": "B. S. Duran",
                        "slug": "B.-S.-Duran",
                        "structuredName": {
                            "firstName": "Benjamin",
                            "lastName": "Duran",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. S. Duran"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 5342671,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "ef68c08449b404280e01492f16b41b1a9b90920f",
            "isKey": false,
            "numCitedBy": 13,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Estimating-the-probability-of-misclassification-and-Boullion-Odell",
            "title": {
                "fragments": [],
                "text": "Estimating the probability of misclassification and variate selection"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit."
            },
            "year": 1975
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3303987"
                        ],
                        "name": "J. V. Campenhout",
                        "slug": "J.-V.-Campenhout",
                        "structuredName": {
                            "firstName": "Jan",
                            "lastName": "Campenhout",
                            "middleNames": [
                                "M.",
                                "Van"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. V. Campenhout"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 46649651,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9d7a9372b5701ca568f4f02bf1e98d40682cfd85",
            "isKey": false,
            "numCitedBy": 31,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "The peaking phenomenon of the Bayes recognition accuracy of pattern classifiers with unknown underlying statistics is addressed. It is shown that this effect, known as the Hughes paradox, arises from improper comparisons of statistically incomparable models. A formalization of the notion of comparability is introduced, and some of the results obtained in the literature are revisited in this context."
            },
            "slug": "On-the-Peaking-of-the-Hughes-Mean-Recognition-The-Campenhout",
            "title": {
                "fragments": [],
                "text": "On the Peaking of the Hughes Mean Recognition Accuracy: The Resolution of an Apparent Paradox"
            },
            "tldr": {
                "abstractSimilarityScore": 88,
                "text": "The peaking phenomenon of the Bayes recognition accuracy of pattern classifiers with unknown underlying statistics is addressed and it is shown that this effect arises from improper comparisons of statistically incomparable models."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Syst. Man Cybern."
            },
            "year": 1978
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2295441"
                        ],
                        "name": "K. Fukunaga",
                        "slug": "K.-Fukunaga",
                        "structuredName": {
                            "firstName": "Keinosuke",
                            "lastName": "Fukunaga",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Fukunaga"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2322936"
                        ],
                        "name": "L. Hostetler",
                        "slug": "L.-Hostetler",
                        "structuredName": {
                            "firstName": "Larry",
                            "lastName": "Hostetler",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Hostetler"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 27985441,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "477f3090ca606035efd9a435b510212b0dec9215",
            "isKey": false,
            "numCitedBy": 175,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "Nonparametric density estimation using the k -nearest-neighbor approach is discussed. By developing a relation between the volume and the coverage of a region, a functional form for the optimum k in terms of the sample size, the dimensionality of the observation space, and the underlying probability distribution is obtained. Within the class of density functions that can be made circularly symmetric by a linear transformation, the optimum matrix for use in a quadratic form metric is obtained. For Gaussian densities this becomes the inverse covariance matrix that is often used without proof of optimality. The close relationship of this approach to that of Parzen estimators is then investigated."
            },
            "slug": "Optimization-of-k-nearest-neighbor-density-Fukunaga-Hostetler",
            "title": {
                "fragments": [],
                "text": "Optimization of k nearest neighbor density estimates"
            },
            "tldr": {
                "abstractSimilarityScore": 73,
                "text": "Nonparametric density estimation using the k -nearest-neighbor approach is discussed and a functional form for the optimum k in terms of the sample size, the dimensionality of the observation space, and the underlying probability distribution is obtained."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Inf. Theory"
            },
            "year": 1973
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145349798"
                        ],
                        "name": "J. T. Chu",
                        "slug": "J.-T.-Chu",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Chu",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. T. Chu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50548358"
                        ],
                        "name": "J. C. Chueh",
                        "slug": "J.-C.-Chueh",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Chueh",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. C. Chueh"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 9419807,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cf7b8aca0f2b57a8f59c440b5a7d4b96755d860b",
            "isKey": false,
            "numCitedBy": 19,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "Upper bounds for the error probability of a Bayes decision function are derived in terms of the differences among the probability distributions of the features used in character recognition. Applications to feature selection and error reduction are discussed. It is shown that if a sufficient number of well-selected features is used, the error probability can be made arbitrarily small."
            },
            "slug": "Error-Probability-in-Decision-Functions-for-Chu-Chueh",
            "title": {
                "fragments": [],
                "text": "Error Probability in Decision Functions for Character Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "Upper bounds for the error probability of a Bayes decision function are derived in terms of the differences among the probability distributions of the features used in character recognition."
            },
            "venue": {
                "fragments": [],
                "text": "JACM"
            },
            "year": 1967
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "6324626"
                        ],
                        "name": "P. Lachenbruch",
                        "slug": "P.-Lachenbruch",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Lachenbruch",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Lachenbruch"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "6402394"
                        ],
                        "name": "M. R. Mickey",
                        "slug": "M.-R.-Mickey",
                        "structuredName": {
                            "firstName": "Max",
                            "lastName": "Mickey",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. R. Mickey"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 122840922,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "3baebcdba313a1a52533fb5c43987169c0c3b5a4",
            "isKey": false,
            "numCitedBy": 1493,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "Several methods of estimating error rates in Discriminant Analysis are evaluated by sampling methods. Multivariate normal samples are generated on a computer which have various true probabilities of misclassification for different combinations of sample sizes and different numbers of parameters. The two methods in most common use are found to be significantly poorer than some new methods that are proposed."
            },
            "slug": "Estimation-of-Error-Rates-in-Discriminant-Analysis-Lachenbruch-Mickey",
            "title": {
                "fragments": [],
                "text": "Estimation of Error Rates in Discriminant Analysis"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1968
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2490865"
                        ],
                        "name": "E. Patrick",
                        "slug": "E.-Patrick",
                        "structuredName": {
                            "firstName": "Edward",
                            "lastName": "Patrick",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Patrick"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35178972"
                        ],
                        "name": "F. P. Fischer",
                        "slug": "F.-P.-Fischer",
                        "structuredName": {
                            "firstName": "Frederic",
                            "lastName": "Fischer",
                            "middleNames": [
                                "P."
                            ],
                            "suffix": "II"
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. P. Fischer"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 120554146,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1e74396061f9fe832bebdfa60552835c14ec0814",
            "isKey": false,
            "numCitedBy": 3,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract : The k - Nearest Neighbor Rule is one specific example of a statistical decision rule. The report deals with a specific modification of this rule. The topics included are the distribution of risk of any sample - based decision rule in terms of the training set sample size, rule structure and underlying probability densities, evaluation of a k - nearest neighbor rule, the metric used in non parametric decision rules. (Author)"
            },
            "slug": "K-Nearest-Neighbor-Rules.-Patrick-Fischer",
            "title": {
                "fragments": [],
                "text": "K-Nearest Neighbor Rules."
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "The topics included are the distribution of risk of any sample - based decision rule in terms of the training set sample size, rule structure and underlying probability densities, evaluation of a k - nearest neighbor rule, the metric used in non parametric decision rules."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1971
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2830023"
                        ],
                        "name": "D. Keehn",
                        "slug": "D.-Keehn",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Keehn",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Keehn"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 38903640,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d27f49cff7bc29d5b4da1bb1bf924b0b536d9adc",
            "isKey": false,
            "numCitedBy": 76,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": "By employing a Bayesian approach to the analysis of learning the probability distribution of property vectors, an estimation likelihood computation scheme for the general Gaussian distribution (quadratic adaptive decision surface) is shown optimum. Some results relating the number of learning samples to Type I misclassification errors are included."
            },
            "slug": "A-note-on-learning-for-Gaussian-properties-Keehn",
            "title": {
                "fragments": [],
                "text": "A note on learning for Gaussian properties"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "By employing a Bayesian approach to the analysis of learning the probability distribution of property vectors, an estimation likelihood computation scheme for the general Gaussian distribution (quadratic adaptive decision surface) is shown optimum."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Inf. Theory"
            },
            "year": 1965
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153340899"
                        ],
                        "name": "J. Aitchison",
                        "slug": "J.-Aitchison",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Aitchison",
                            "middleNames": [
                                "William"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Aitchison"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 121864829,
            "fieldsOfStudy": [
                "Business"
            ],
            "id": "063ff9f07500db39e15cab01cb15f26bca0aedea",
            "isKey": false,
            "numCitedBy": 233,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "SUMMARY Fitting a parametric model or estimating a parametric density function plays an important role in a number of statistical applications. Two widely-used methods, one replacing the unknown parameter by an efficient estimate and so termed estimative and the other using a mixture of the possible density functions and commonly termed predictive, are compared. On a general criterion of closeness of fit based on a discriminating information measure the predictive method is shown to be preferable. Explicit measures of the relative closeness of predictive and estimative fits are obtained for gamma and multinormal models."
            },
            "slug": "Goodness-of-prediction-fit-Aitchison",
            "title": {
                "fragments": [],
                "text": "Goodness of prediction fit"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1975
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145822375"
                        ],
                        "name": "G. Toussaint",
                        "slug": "G.-Toussaint",
                        "structuredName": {
                            "firstName": "Godfried",
                            "lastName": "Toussaint",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Toussaint"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 9833144,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d0508318a2363a7a2c7fd4dd8fed20891ec879c4",
            "isKey": false,
            "numCitedBy": 334,
            "numCiting": 69,
            "paperAbstract": {
                "fragments": [],
                "text": "Articles, books, and technical reports on the theoretical and experimental estimation of probability of misclassification are listed for the case of correctly labeled or preclassified training data. By way of introduction, the problem of estimating the probability of misclassification is discussed in order to characterize the contributions of the literature."
            },
            "slug": "Bibliography-on-estimation-of-misclassification-Toussaint",
            "title": {
                "fragments": [],
                "text": "Bibliography on estimation of misclassification"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "Articles, books, and technical reports on the theoretical and experimental estimation of probability of misclassification are listed for the case of correctly labeled or preclassified training data."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Inf. Theory"
            },
            "year": 1974
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35106875"
                        ],
                        "name": "R. Duda",
                        "slug": "R.-Duda",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Duda",
                            "middleNames": [
                                "O."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Duda"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3108177"
                        ],
                        "name": "P. Hart",
                        "slug": "P.-Hart",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Hart",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Hart"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 12946615,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b07ce649d6f6eb636872527104b0209d3edc8188",
            "isKey": false,
            "numCitedBy": 16928,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Provides a unified, comprehensive and up-to-date treatment of both statistical and descriptive methods for pattern recognition. The topics treated include Bayesian decision theory, supervised and unsupervised learning, nonparametric techniques, discriminant analysis, clustering, preprosessing of pictorial data, spatial filtering, shape description techniques, perspective transformations, projective invariants, linguistic procedures, and artificial intelligence techniques for scene analysis."
            },
            "slug": "Pattern-classification-and-scene-analysis-Duda-Hart",
            "title": {
                "fragments": [],
                "text": "Pattern classification and scene analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 66,
                "text": "The topics treated include Bayesian decision theory, supervised and unsupervised learning, nonparametric techniques, discriminant analysis, clustering, preprosessing of pictorial data, spatial filtering, shape description techniques, perspective transformations, projective invariants, linguistic procedures, and artificial intelligence techniques for scene analysis."
            },
            "venue": {
                "fragments": [],
                "text": "A Wiley-Interscience publication"
            },
            "year": 1973
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153340899"
                        ],
                        "name": "J. Aitchison",
                        "slug": "J.-Aitchison",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Aitchison",
                            "middleNames": [
                                "William"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Aitchison"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145217017"
                        ],
                        "name": "J. Habbema",
                        "slug": "J.-Habbema",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Habbema",
                            "middleNames": [
                                "Dik",
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Habbema"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145889607"
                        ],
                        "name": "J. Kay",
                        "slug": "J.-Kay",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Kay",
                            "middleNames": [
                                "C.",
                                "Ma"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Kay"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 63265652,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "9212e0375beb1d8e761314da1cfe48e3d944ee98",
            "isKey": false,
            "numCitedBy": 101,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "Important clinical differences arising in the application of commonly advocated \n discriminant or diagnostic methods demand a thorough assessment of the realism of \n their different assessments. Recent theoretical work on the estimation of density \n functions provides reasons for these differences and suggests which methods should \n provide greater realism. These suggestions are strongly supported by a simulation \n study. Specific recommendations are made concerning statistical diagnostic practice."
            },
            "slug": "A-critical-comparison-of-two-methods-of-statistical-Aitchison-Habbema",
            "title": {
                "fragments": [],
                "text": "A critical comparison of two methods of statistical discrimination"
            },
            "tldr": {
                "abstractSimilarityScore": 59,
                "text": "Recent theoretical work on the estimation of density functions provides reasons for differences in the application of commonly advocated discriminant or diagnostic methods and suggests which methods should provide greater realism."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1977
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "116431166"
                        ],
                        "name": "\ubbfc\uadc0\ud64d",
                        "slug": "\ubbfc\uadc0\ud64d",
                        "structuredName": {
                            "firstName": "",
                            "lastName": "\ubbfc\uadc0\ud64d",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "\ubbfc\uadc0\ud64d"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "82973857"
                        ],
                        "name": "\uc1a1\uc815\ubbf8",
                        "slug": "\uc1a1\uc815\ubbf8",
                        "structuredName": {
                            "firstName": "",
                            "lastName": "\uc1a1\uc815\ubbf8",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "\uc1a1\uc815\ubbf8"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 197457491,
            "fieldsOfStudy": [
                "Art"
            ],
            "id": "46c69e1154c03fac2473945b4561a7792c13c9b1",
            "isKey": false,
            "numCitedBy": 6,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "\ubc31\ud654\uc810-DM\uad11\uace0\uc758-\uc815\ubcf4\uc131\uacfc-\uc720\uc6a9\uc131\uc5d0-\ub300\ud55c-\uc778\uc2dd\uc774-\uad11\uace0\ud0dc\ub3c4-\ubc0f-\ud68c\ud53c\uc5d0-\ubbf8\uce58\ub294-\uc601\ud5a5-\ubbfc\uadc0\ud64d-\uc1a1\uc815\ubbf8",
            "title": {
                "fragments": [],
                "text": "\ubc31\ud654\uc810 DM\uad11\uace0\uc758 \uc815\ubcf4\uc131\uacfc \uc720\uc6a9\uc131\uc5d0 \ub300\ud55c \uc778\uc2dd\uc774 \uad11\uace0\ud0dc\ub3c4 \ubc0f \ud68c\ud53c\uc5d0 \ubbf8\uce58\ub294 \uc601\ud5a5"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1977
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2145615522"
                        ],
                        "name": "G. D. Murray",
                        "slug": "G.-D.-Murray",
                        "structuredName": {
                            "firstName": "Gordon",
                            "lastName": "Murray",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. D. Murray"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 125311478,
            "fieldsOfStudy": [
                "Medicine"
            ],
            "id": "4b46f6e59e5a1e87fedd6780e62fba39db47080f",
            "isKey": false,
            "numCitedBy": 71,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-Cautionary-Note-on-Selection-of-Variables-in-Murray",
            "title": {
                "fragments": [],
                "text": "A Cautionary Note on Selection of Variables in Discriminant Analysis"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1977
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50658921"
                        ],
                        "name": "Anil K. Jain",
                        "slug": "Anil-K.-Jain",
                        "structuredName": {
                            "firstName": "Anil",
                            "lastName": "Jain",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Anil K. Jain"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 125312861,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "bc2535537c86533b0961c13bf808e4703a74905e",
            "isKey": false,
            "numCitedBy": 27,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "ON-AN-ESTIMATE-OF-THE-BHATTACHARYYA-DISTANCE.-Jain",
            "title": {
                "fragments": [],
                "text": "ON AN ESTIMATE OF THE BHATTACHARYYA DISTANCE."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1976
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144265468"
                        ],
                        "name": "W. Waller",
                        "slug": "W.-Waller",
                        "structuredName": {
                            "firstName": "W.",
                            "lastName": "Waller",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Waller"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50658921"
                        ],
                        "name": "Anil K. Jain",
                        "slug": "Anil-K.-Jain",
                        "structuredName": {
                            "firstName": "Anil",
                            "lastName": "Jain",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Anil K. Jain"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 125233557,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "932b0dcc0035bc151f6572fd00b147391091821f",
            "isKey": false,
            "numCitedBy": 10,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "MEAN-RECOGNITION-ACCURACY-OF-DEPENDENT-BINARY-Waller-Jain",
            "title": {
                "fragments": [],
                "text": "MEAN RECOGNITION ACCURACY OF DEPENDENT BINARY MEASUREMENTS."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1977
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48982805"
                        ],
                        "name": "M. Okamoto",
                        "slug": "M.-Okamoto",
                        "structuredName": {
                            "firstName": "Masashi",
                            "lastName": "Okamoto",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Okamoto"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 122718463,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "c6138c89c76fcf45c321854c2ba763a042f1e39a",
            "isKey": false,
            "numCitedBy": 226,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "An-Asymptotic-Expansion-for-the-Distribution-of-the-Okamoto",
            "title": {
                "fragments": [],
                "text": "An Asymptotic Expansion for the Distribution of the Linear Discriminant Function"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1963
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145797886"
                        ],
                        "name": "A. Wald",
                        "slug": "A.-Wald",
                        "structuredName": {
                            "firstName": "Abraham",
                            "lastName": "Wald",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Wald"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 122922806,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "3cf14ed75e2ace8a3446c2b275c1c8f3cbadcaf0",
            "isKey": false,
            "numCitedBy": 190,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "On-a-Statistical-Problem-Arising-in-the-of-an-into-Wald",
            "title": {
                "fragments": [],
                "text": "On a Statistical Problem Arising in the Classification of an Individual into One of Two Groups"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1944
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145740112"
                        ],
                        "name": "H. Harter",
                        "slug": "H.-Harter",
                        "structuredName": {
                            "firstName": "H.",
                            "lastName": "Harter",
                            "middleNames": [
                                "Leon"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Harter"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 121510431,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "081dac981c8967d69a3923b34a7f3a54663bef68",
            "isKey": false,
            "numCitedBy": 53,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "On-the-Distribution-of-Wald's-Classification-Harter",
            "title": {
                "fragments": [],
                "text": "On the Distribution of Wald's Classification Statistic"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1951
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "116262778"
                        ],
                        "name": "S. John",
                        "slug": "S.-John",
                        "structuredName": {
                            "firstName": "Smith",
                            "lastName": "John",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. John"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 119862731,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "b755db150d9d9cca06467fff6f27abfcbfa6ea02",
            "isKey": false,
            "numCitedBy": 93,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Errors-in-Discrimination-John",
            "title": {
                "fragments": [],
                "text": "Errors in Discrimination"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1961
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48043195"
                        ],
                        "name": "R. Sitgreaves",
                        "slug": "R.-Sitgreaves",
                        "structuredName": {
                            "firstName": "Rosedith",
                            "lastName": "Sitgreaves",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Sitgreaves"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 119720382,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "bddaf6acc828da8c9babd0f5ed84916dad947bd6",
            "isKey": false,
            "numCitedBy": 51,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "On-the-Distribution-of-two-Random-Matrices-used-in-Sitgreaves",
            "title": {
                "fragments": [],
                "text": "On the Distribution of two Random Matrices used in Classification Procedures"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1952
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1690479"
                        ],
                        "name": "D. G. Kabe",
                        "slug": "D.-G.-Kabe",
                        "structuredName": {
                            "firstName": "D.",
                            "lastName": "Kabe",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. G. Kabe"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 120876004,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "3d1a2960dabf366b5829320db1f7290250862d19",
            "isKey": false,
            "numCitedBy": 23,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Some-Results-on-the-Distribution-of-Two-Random-Used-Kabe",
            "title": {
                "fragments": [],
                "text": "Some Results on the Distribution of Two Random Matrices Used in Classification Procedures"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1963
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39072831"
                        ],
                        "name": "A. Bowker",
                        "slug": "A.-Bowker",
                        "structuredName": {
                            "firstName": "Albert",
                            "lastName": "Bowker",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Bowker"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48043195"
                        ],
                        "name": "R. Sitgreaves",
                        "slug": "R.-Sitgreaves",
                        "structuredName": {
                            "firstName": "Rosedith",
                            "lastName": "Sitgreaves",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Sitgreaves"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 118687126,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "40d99d65f79a96bb9fc6da0d57cb2df4f685019d",
            "isKey": false,
            "numCitedBy": 27,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "AN-ASYMPTOTIC-EXPANSION-FOR-THE-DISTRIBUTION-OF-THE-Bowker-Sitgreaves",
            "title": {
                "fragments": [],
                "text": "AN ASYMPTOTIC EXPANSION FOR THE DISTRIBUTION FUNCTION OF THE CLASSIFICATION STATISTIC W"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1959
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2068624378"
                        ],
                        "name": "I. T. Young",
                        "slug": "I.-T.-Young",
                        "structuredName": {
                            "firstName": "Ian",
                            "lastName": "Young",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. T. Young"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 118218747,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "909709b567a1815faeb2b3b3490ce5b0972f1bdc",
            "isKey": false,
            "numCitedBy": 13,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Further-Consideration-of-Sample-and-Feature-Size.-Young",
            "title": {
                "fragments": [],
                "text": "Further Consideration of Sample and Feature Size."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1978
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8051928"
                        ],
                        "name": "W. Gaffey",
                        "slug": "W.-Gaffey",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Gaffey",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Gaffey"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 117785185,
            "fieldsOfStudy": [
                "Education"
            ],
            "id": "fde832f9c90b525f8e0d7133a426905b4c2d5340",
            "isKey": false,
            "numCitedBy": 9,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Discriminatory-Analysis-Perfect-Discrimination-as-Gaffey",
            "title": {
                "fragments": [],
                "text": "Discriminatory Analysis - Perfect Discrimination as the Number of Variables Increases"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1951
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145414142"
                        ],
                        "name": "B. Chandrasekaran",
                        "slug": "B.-Chandrasekaran",
                        "structuredName": {
                            "firstName": "B.",
                            "lastName": "Chandrasekaran",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Chandrasekaran"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145295484"
                        ],
                        "name": "Anil K. Jain",
                        "slug": "Anil-K.-Jain",
                        "structuredName": {
                            "firstName": "Anil",
                            "lastName": "Jain",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Anil K. Jain"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 64807701,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "98eebcff6fba3178b80470f47416cd1659b2e997",
            "isKey": false,
            "numCitedBy": 13,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "ON-BALANCING-DECISION-FUNCTIONS.-Chandrasekaran-Jain",
            "title": {
                "fragments": [],
                "text": "ON BALANCING DECISION FUNCTIONS."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1979
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2107988"
                        ],
                        "name": "K. Abend",
                        "slug": "K.-Abend",
                        "structuredName": {
                            "firstName": "Kenneth",
                            "lastName": "Abend",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Abend"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "16998148"
                        ],
                        "name": "T. Harley",
                        "slug": "T.-Harley",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Harley",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Harley"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145414142"
                        ],
                        "name": "B. Chandrasekaran",
                        "slug": "B.-Chandrasekaran",
                        "structuredName": {
                            "firstName": "B.",
                            "lastName": "Chandrasekaran",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Chandrasekaran"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2066539"
                        ],
                        "name": "G. Hughes",
                        "slug": "G.-Hughes",
                        "structuredName": {
                            "firstName": "Gordon",
                            "lastName": "Hughes",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Hughes"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 20078603,
            "fieldsOfStudy": [
                "Environmental Science"
            ],
            "id": "7c0883a69085b1720577a18ef041957bd3551bff",
            "isKey": false,
            "numCitedBy": 43,
            "numCiting": 3,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Comments-on-\"On-the-mean-accuracy-of-statistical-by-Abend-Harley",
            "title": {
                "fragments": [],
                "text": "Comments on \"On the mean accuracy of statistical pattern recognizers\" by Hughes, G. F"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Inf. Theory"
            },
            "year": 1969
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "14523865"
                        ],
                        "name": "D. Loftsgaarden",
                        "slug": "D.-Loftsgaarden",
                        "structuredName": {
                            "firstName": "Don",
                            "lastName": "Loftsgaarden",
                            "middleNames": [
                                "O."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Loftsgaarden"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "80011542"
                        ],
                        "name": "C. Quesenberry",
                        "slug": "C.-Quesenberry",
                        "structuredName": {
                            "firstName": "Charles",
                            "lastName": "Quesenberry",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Quesenberry"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 121666889,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "83a5c430e65fe74d8905c7e81a8aeaf11aead8e2",
            "isKey": false,
            "numCitedBy": 770,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-nonparametric-estimate-of-a-multivariate-density-Loftsgaarden-Quesenberry",
            "title": {
                "fragments": [],
                "text": "A nonparametric estimate of a multivariate density function"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1965
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {},
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 56,
        "totalPages": 6
    },
    "page_url": "https://www.semanticscholar.org/paper/39-Dimensionality-and-sample-size-considerations-in-Jain-Chandrasekaran/55ab64d91344cdde7d4959a181c7652245c19597?sort=total-citations"
}