{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143750012"
                        ],
                        "name": "R. Hartley",
                        "slug": "R.-Hartley",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Hartley",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Hartley"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153382032"
                        ],
                        "name": "R. Gupta",
                        "slug": "R.-Gupta",
                        "structuredName": {
                            "firstName": "Rajiv",
                            "lastName": "Gupta",
                            "middleNames": [
                                "Kumar"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Gupta"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 3510798,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "ce3029e57741308ab09ec9c266ae636e91c0c062",
            "isKey": false,
            "numCitedBy": 108,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "A new method is given for image rectification, the process of resampling pairs of stereo images taken from widely differing viewpoints in order to produce a pair of matched epipolar projections. These are projections in which the epipolar lines run parallel with the x-axis and disparities between the images are in the x-direction only. The method is based on an examination of the essential matrix of Longuet-Higgins (1981), which describes the epipolar geometry of the image pair. The approach taken is consistent with that advocated by O. Faugeras (1992) of avoiding camera calibration. A matrix called the epipolar transformation matrix is defined. It is used to determine a pair of 2-D projective transforms to be applied to the two images in order to match the epipolar lines. The advantages include the simplicity of the 2-D projective transformation, which allows very fast resampling, as well as subsequent simplification in identifying matched points and in scene reconstruction.<<ETX>>"
            },
            "slug": "Computing-matched-epipolar-projections-Hartley-Gupta",
            "title": {
                "fragments": [],
                "text": "Computing matched-epipolar projections"
            },
            "tldr": {
                "abstractSimilarityScore": 76,
                "text": "A new method for image rectification, the process of resampling pairs of stereo images taken from widely differing viewpoints in order to produce a pair of matched epipolar projections, based on an examination of the essential matrix of Longuet-Higgins (1981), which describes the epipolar geometry of the image pair."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "51064498"
                        ],
                        "name": "Zhengyou Zhang",
                        "slug": "Zhengyou-Zhang",
                        "structuredName": {
                            "firstName": "Zhengyou",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zhengyou Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1702017"
                        ],
                        "name": "R. Deriche",
                        "slug": "R.-Deriche",
                        "structuredName": {
                            "firstName": "Rachid",
                            "lastName": "Deriche",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Deriche"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "33726225"
                        ],
                        "name": "O. Faugeras",
                        "slug": "O.-Faugeras",
                        "structuredName": {
                            "firstName": "Olivier",
                            "lastName": "Faugeras",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Faugeras"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2624076"
                        ],
                        "name": "Q. Luong",
                        "slug": "Q.-Luong",
                        "structuredName": {
                            "firstName": "Quang-Tuan",
                            "lastName": "Luong",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Q. Luong"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5858737,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b3ec4ceea040b7b4129ee5d71b4f95539bf876b7",
            "isKey": false,
            "numCitedBy": 1625,
            "numCiting": 65,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-Robust-Technique-for-Matching-two-Uncalibrated-of-Zhang-Deriche",
            "title": {
                "fragments": [],
                "text": "A Robust Technique for Matching two Uncalibrated Images Through the Recovery of the Unknown Epipolar Geometry"
            },
            "venue": {
                "fragments": [],
                "text": "Artif. Intell."
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1777539"
                        ],
                        "name": "P. Beardsley",
                        "slug": "P.-Beardsley",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Beardsley",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Beardsley"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143635539"
                        ],
                        "name": "P. Torr",
                        "slug": "P.-Torr",
                        "structuredName": {
                            "firstName": "Philip",
                            "lastName": "Torr",
                            "middleNames": [
                                "H.",
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Torr"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688869"
                        ],
                        "name": "Andrew Zisserman",
                        "slug": "Andrew-Zisserman",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Zisserman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Zisserman"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 45380280,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "92e9d8d6ed560f58cd32a72ede6c6252fb1b8311",
            "isKey": false,
            "numCitedBy": 491,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "A method for matching image primitives through a sequence is described, for the purpose of acquiring 3D geometric models. The method includes a novel robust estimator of the trifocal tensor, based on a minimum number of token correspondences across an image triplet; and a novel tracking algorithm in which corners and line segments are matched over image triplets in an integrated framework. The matching techniques are both robust (detecting and discarding mismatches) and fully automatic."
            },
            "slug": "3D-Model-Acquisition-from-Extended-Image-Sequences-Beardsley-Torr",
            "title": {
                "fragments": [],
                "text": "3D Model Acquisition from Extended Image Sequences"
            },
            "tldr": {
                "abstractSimilarityScore": 97,
                "text": "A method for matching image primitives through a sequence is described, for the purpose of acquiring 3D geometric models, which includes a novel robust estimator of the trifocal tensor, based on a minimum number of token correspondences across an image triplet."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "13905674"
                        ],
                        "name": "F. Glazer",
                        "slug": "F.-Glazer",
                        "structuredName": {
                            "firstName": "Frank",
                            "lastName": "Glazer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Glazer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143816432"
                        ],
                        "name": "G. Reynolds",
                        "slug": "G.-Reynolds",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Reynolds",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Reynolds"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145981906"
                        ],
                        "name": "P. Anandan",
                        "slug": "P.-Anandan",
                        "structuredName": {
                            "firstName": "P.",
                            "lastName": "Anandan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Anandan"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 117033770,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "80ae9639809cda98d69f2f873c12251531604078",
            "isKey": false,
            "numCitedBy": 96,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract : In this paper the authors present an implementation of hierarchical scene matching in the VISIONS image processing cone - a pyramidal processing architecture. The problem of scene matching is common to many applications in machine vision including registration, motion detection, and stereo vision. Scene matching by feature correlation can solve this problem but suffers from computational expense and failure in highly textured images. Hierarchical correlation provides both a cheaper matching algorithm and a coarse-to-fine matching strategy that overcomes textural problems by matching on gross image structures first. These methods fit naturally into the processing cone or pyramid architectures that have been proposed for image processing. Presented is a discussion of the architecture of the processing cone, the construction of image pyramids, and the use of these pyramids in hierarchical correlation. A set of experiments illustrates the operation of these ideas."
            },
            "slug": "Scene-Matching-by-Hierarchical-Correlation-Glazer-Reynolds",
            "title": {
                "fragments": [],
                "text": "Scene Matching by Hierarchical Correlation"
            },
            "tldr": {
                "abstractSimilarityScore": 66,
                "text": "An implementation of hierarchical scene matching in the VISIONS image processing cone - a pyramidal processing architecture that provides both a cheaper matching algorithm and a coarse-to-fine matching strategy that overcomes textural problems by matching on gross image structures first."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1983
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1794229"
                        ],
                        "name": "R. Horaud",
                        "slug": "R.-Horaud",
                        "structuredName": {
                            "firstName": "Radu",
                            "lastName": "Horaud",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Horaud"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2244797"
                        ],
                        "name": "T. Skordas",
                        "slug": "T.-Skordas",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Skordas",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Skordas"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6693362,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "90abbca3fda757930b68d2e8a5ee24ed5bea08c3",
            "isKey": false,
            "numCitedBy": 387,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "The authors propose a method for solving the stereo correspondence problem. The method consists of extracting local image structures and matching similar such structures between two images. Linear edge segments are extracted from both the left and right images. Each segment is characterized by its position and orientation in the image as well as its relationships with the nearby segments. A relational graph is thus built from each image. For each segment in one image as set of potential assignments is represented as a set of nodes in a correspondence graph. Arcs in the graph represent compatible assignments established on the basis of segment relationships. Stereo matching becomes equivalent to searching for sets of mutually compatible nodes in this graph. Sets are found by looking for maximal cliques. The maximal clique best suited to represent a stereo correspondence is selected using a benefit function. Numerous results obtained with this method are shown. >"
            },
            "slug": "Stereo-Correspondence-Through-Feature-Grouping-and-Horaud-Skordas",
            "title": {
                "fragments": [],
                "text": "Stereo Correspondence Through Feature Grouping and Maximal Cliques"
            },
            "tldr": {
                "abstractSimilarityScore": 88,
                "text": "The authors propose a method for solving the stereo correspondence problem by extracting local image structures and matching similar such structures between two images using a benefit function."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40309692"
                        ],
                        "name": "C. G. Harris",
                        "slug": "C.-G.-Harris",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Harris",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. G. Harris"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40365651"
                        ],
                        "name": "M. Stephens",
                        "slug": "M.-Stephens",
                        "structuredName": {
                            "firstName": "M.",
                            "lastName": "Stephens",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Stephens"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1694378,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6818668fb895d95861a2eb9673ddc3a41e27b3b3",
            "isKey": false,
            "numCitedBy": 14111,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "The problem we are addressing in Alvey Project MMI149 is that of using computer vision to understand the unconstrained 3D world, in which the viewed scenes will in general contain too wide a diversity of objects for topdown recognition techniques to work. For example, we desire to obtain an understanding of natural scenes, containing roads, buildings, trees, bushes, etc., as typified by the two frames from a sequence illustrated in Figure 1. The solution to this problem that we are pursuing is to use a computer vision system based upon motion analysis of a monocular image sequence from a mobile camera. By extraction and tracking of image features, representations of the 3D analogues of these features can be constructed."
            },
            "slug": "A-Combined-Corner-and-Edge-Detector-Harris-Stephens",
            "title": {
                "fragments": [],
                "text": "A Combined Corner and Edge Detector"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "The problem the authors are addressing in Alvey Project MMI149 is that of using computer vision to understand the unconstrained 3D world, in which the viewed scenes will in general contain too wide a diversity of objects for topdown recognition techniques to work."
            },
            "venue": {
                "fragments": [],
                "text": "Alvey Vision Conference"
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2462253"
                        ],
                        "name": "C. Schmid",
                        "slug": "C.-Schmid",
                        "structuredName": {
                            "firstName": "Cordelia",
                            "lastName": "Schmid",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Schmid"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145299933"
                        ],
                        "name": "R. Mohr",
                        "slug": "R.-Mohr",
                        "structuredName": {
                            "firstName": "Roger",
                            "lastName": "Mohr",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Mohr"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15836461,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5bea2d903ea2b7b567482c0019ec1ad8196ae065",
            "isKey": false,
            "numCitedBy": 52,
            "numCiting": 75,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a matching method which is based on invariants of the luminance function. This makes matching possible in the case of important geometric transformations between images. The method is robust to occlusion, as local properties of the image signal are used. We propose to use differential measures invariant to rotations in a multi-scale framework. Promising results are obtained which might be used for a variety of applications."
            },
            "slug": "Matching-by-local-invariants-Schmid-Mohr",
            "title": {
                "fragments": [],
                "text": "Matching by local invariants"
            },
            "tldr": {
                "abstractSimilarityScore": 86,
                "text": "A matching method which is based on invariants of the luminance function makes matching possible in the case of important geometric transformations between images, and is robust to occlusion, as local properties of the image signal are used."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143635539"
                        ],
                        "name": "P. Torr",
                        "slug": "P.-Torr",
                        "structuredName": {
                            "firstName": "Philip",
                            "lastName": "Torr",
                            "middleNames": [
                                "H.",
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Torr"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48121727"
                        ],
                        "name": "D. W. Murray",
                        "slug": "D.-W.-Murray",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Murray",
                            "middleNames": [
                                "William"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. W. Murray"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 123740333,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "646edc722edfcfffb4c792b337bbec49c7beb621",
            "isKey": false,
            "numCitedBy": 273,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a new method for solving the problem of motion segmentation, identifying the objects within an image moving independently of the background. We utilize the fact that two views of a static 3D point set are linked by a 3 X 3 Fundamental Matrix (F). The Fundamental Matrix contains all the information on structure and motion from a given set of point correspondences and is derived by a least squares method under the assumption that the majority of the image is undergoing a rigid motion. Least squares is the most commonly used method of parameter estimation in computer vision algorithms. However the estimated parameters from a least squares fit can be corrupted beyond recognition in the presence of gross errors or outliers which plague any data from real imagery. Features with a motion independent of the background are those statistically inconsistent from the calculated value of (F). Well founded methods for detecting these outlying points are described."
            },
            "slug": "Outlier-detection-and-motion-segmentation-Torr-Murray",
            "title": {
                "fragments": [],
                "text": "Outlier detection and motion segmentation"
            },
            "tldr": {
                "abstractSimilarityScore": 94,
                "text": "A new method for solving the problem of motion segmentation, identifying the objects within an image moving independently of the background by utilizing the fact that two views of a static 3D point set are linked by a 3 X 3 Fundamental Matrix (F)."
            },
            "venue": {
                "fragments": [],
                "text": "Other Conferences"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3140335"
                        ],
                        "name": "A. Shashua",
                        "slug": "A.-Shashua",
                        "structuredName": {
                            "firstName": "Amnon",
                            "lastName": "Shashua",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Shashua"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 37767210,
            "fieldsOfStudy": [
                "Medicine"
            ],
            "id": "fc62d436ac9ea7fad76b47793151c3793ec82e1a",
            "isKey": false,
            "numCitedBy": 202,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "In the general case, a trilinear relationship between three perspective views is shown to exist. The trilinearity result is shown to be of much practical use in visual recognition by alignment \u2014 yielding a direct method superior to the conventional epipolar line intersection method. The proof of the central result may be of further interest as it demonstrates certain regularities across homographies of the plane."
            },
            "slug": "Trilinearity-in-Visual-Recognition-by-Alignment-Shashua",
            "title": {
                "fragments": [],
                "text": "Trilinearity in Visual Recognition by Alignment"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "The trilinearity result is shown to be of much practical use in visual recognition by alignment \u2014 yielding a direct method superior to the conventional epipolar line intersection method."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1681236"
                        ],
                        "name": "L. Gool",
                        "slug": "L.-Gool",
                        "structuredName": {
                            "firstName": "Luc",
                            "lastName": "Gool",
                            "middleNames": [
                                "Van"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Gool"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2525101"
                        ],
                        "name": "T. Moons",
                        "slug": "T.-Moons",
                        "structuredName": {
                            "firstName": "Theo",
                            "lastName": "Moons",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Moons"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153210127"
                        ],
                        "name": "Dorin Ungureanu",
                        "slug": "Dorin-Ungureanu",
                        "structuredName": {
                            "firstName": "Dorin",
                            "lastName": "Ungureanu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dorin Ungureanu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 36152,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fbdfadd172c2ac3adfd18d497ab81491f3f5f80a",
            "isKey": false,
            "numCitedBy": 337,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "The paper contributes to the viewpoint invariant recognition of planar patterns, especially labels and signs under affine deformations. By their nature, the information of such \u2018eye-catchers\u2019 is not contained in the outline or frame \u2014 they often are affinely equivalent like parallelograms and ellipses \u2014 but in the intensity content within. Moment invariants are well suited for their recognition. They need a closed bounding contour, but this is comparatively easy to provide for the simple shapes considered. On the other hand, they characterize the intensity patterns without the need for error prone feature extraction. This paper uses moments as the basic features, but extends the literature in two respects: (1) deliberate mixes of different types of moments to keep the order of the moments (and hence also the sensitivity to noise) low and yet have a sufficiently large number to safeguard discriminant power; and (2) invariance with respect to photometric changes is incorporated in order to find the simplest moment invariants that can cope with changing lighting conditions which can hardly be avoided when changing viewpoint. The paper gives complete classifications of such affine / photometric moment invariants. Experiments are described that illustrate the use of some of them."
            },
            "slug": "Affine/-Photometric-Invariants-for-Planar-Intensity-Gool-Moons",
            "title": {
                "fragments": [],
                "text": "Affine/ Photometric Invariants for Planar Intensity Patterns"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This paper uses moments as the basic features, but extends the literature in two respects: deliberate mixes of different types of moments to keep the order of the moments low and yet have a sufficiently large number to safeguard discriminant power; and invariance with respect to photometric changes is incorporated in order to find the simplest moment invariants that can cope with changing lighting conditions."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143750012"
                        ],
                        "name": "R. Hartley",
                        "slug": "R.-Hartley",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Hartley",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Hartley"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 1714689,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "51cd6defa26c4ab6ddde8f42729b030130bd0775",
            "isKey": false,
            "numCitedBy": 203,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "Discusses the basic role of the trifocal tensor in scene reconstruction. This 3/spl times/3/spl times/3 tensor plays a role in the analysis of scenes from three views analogous to the role played by the fundamental matrix in the two-view case. In particular, the trifocal tensor maybe computed by a linear algorithm from a set of 13 line correspondences in three views. It is further shown in this paper to be essentially identical to a set of coefficients introduced by Shashua (1994) to effect point transfer in the three-view case. This observation means that the 13-line algorithm may be extended to allow for the computation of the trifocal tensor given any mixture of sufficiently many line and point correspondences. From the trifocal tensor, the camera image matrices may be computed, and the scene may be reconstructed. For unrelated uncalibrated cameras, this reconstruction is unique up to projectivity. Thus, projective reconstruction of a set of lines and points may be reconstructed linearly from three views.<<ETX>>"
            },
            "slug": "A-linear-method-for-reconstruction-from-lines-and-Hartley",
            "title": {
                "fragments": [],
                "text": "A linear method for reconstruction from lines and points"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "The trifocal tensor is shown to be essentially identical to a set of coefficients introduced by Shashua (1994) to effect point transfer in the three-view case and to be extended to allow for the computation of the trifoc tensor given any mixture of sufficiently many line and point correspondences."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IEEE International Conference on Computer Vision"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1764443"
                        ],
                        "name": "R. Bolles",
                        "slug": "R.-Bolles",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Bolles",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Bolles"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1453069517"
                        ],
                        "name": "R. A. Cain",
                        "slug": "R.-A.-Cain",
                        "structuredName": {
                            "firstName": "Ronald",
                            "lastName": "Cain",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. A. Cain"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 208952327,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "de2fa641d79397c3b383aea77776d8ebe49de08a",
            "isKey": false,
            "numCitedBy": 290,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "A new method of locating partially visible two-dimensional objects is presented. The method is used to locate complex industrial parts that may contain several occurrences of local features, such as holes and corners. The matching process utilizes clusters of mutually consistent features to hypothesize objects and also uses templates of objects to verify these hypotheses. The technique is fast because it concentrates on key features that are automatically se lected on the basis of a detailed analysis of computer- aided design (CAD) models of the objects. The automatic analysis applies general-purpose routines for building and analyzing representations of clusters of local features that could be used in procedures to select features for other lo cational strategies. These routines include algorithms for computing the rotational and mirror symmetries of objects in terms of their local features."
            },
            "slug": "Recognizing-and-Locating-Partially-Visible-Objects:-Bolles-Cain",
            "title": {
                "fragments": [],
                "text": "Recognizing and Locating Partially Visible Objects: The Local-Feature-Focus Method"
            },
            "tldr": {
                "abstractSimilarityScore": 62,
                "text": "A new method of locating partially visible two-dimensional objects is presented that concentrates on key features that are automatically focused on on the basis of a detailed analysis of computer- aided design models of the objects."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1982
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2465976"
                        ],
                        "name": "M. Fischler",
                        "slug": "M.-Fischler",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "Fischler",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Fischler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1764443"
                        ],
                        "name": "R. Bolles",
                        "slug": "R.-Bolles",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Bolles",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Bolles"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 972888,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "278c9a78d4505cfaf6b709df364dbd1206a017c1",
            "isKey": false,
            "numCitedBy": 15951,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "A new paradigm, Random Sample Consensus (RANSAC), for fitting a model to experimental data is introduced. RANSAC is capable of interpreting/smoothing data containing a significant percentage of gross errors, and is thus ideally suited for applications in automated image analysis where interpretation is based on the data provided by error-prone feature detectors. A major portion of this paper describes the application of RANSAC to the Location Determination Problem (LDP): Given an image depicting a set of landmarks with known locations, determine that point in space from which the image was obtained. In response to a RANSAC requirement, new results are derived on the minimum number of landmarks needed to obtain a solution, and algorithms are presented for computing these minimum-landmark solutions in closed form. These results provide the basis for an automatic system that can solve the LDP under difficult viewing"
            },
            "slug": "Random-sample-consensus:-a-paradigm-for-model-with-Fischler-Bolles",
            "title": {
                "fragments": [],
                "text": "Random sample consensus: a paradigm for model fitting with applications to image analysis and automated cartography"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "New results are derived on the minimum number of landmarks needed to obtain a solution, and algorithms are presented for computing these minimum-landmark solutions in closed form that provide the basis for an automatic system that can solve the Location Determination Problem under difficult viewing."
            },
            "venue": {
                "fragments": [],
                "text": "CACM"
            },
            "year": 1981
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1764443"
                        ],
                        "name": "R. Bolles",
                        "slug": "R.-Bolles",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Bolles",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Bolles"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15764395,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fd10304d259196b0db929fe02872e700092ce8cc",
            "isKey": false,
            "numCitedBy": 365,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "A new method of locating partially visible two-dimensional objects has been designed. The method is applicable to complex industrial parts that may contain several occurrences of local features such as holes and corners. The matching process is robust, because it bases its decisions on groups of mutually consistent features, and it is relatively fast, because it concentrates on key features that are automatically selected on the basis of a detailed analysis of CAD type of models of the objects."
            },
            "slug": "Locating-Partially-Visible-Objects:-The-Local-Focus-Bolles",
            "title": {
                "fragments": [],
                "text": "Locating Partially Visible Objects: The Local Feature Focus Method"
            },
            "tldr": {
                "abstractSimilarityScore": 97,
                "text": "A new method of locating partially visible two-dimensional objects has been designed that is applicable to complex industrial parts that may contain several occurrences of local features such as holes and corners."
            },
            "venue": {
                "fragments": [],
                "text": "AAAI"
            },
            "year": 1980
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31589308"
                        ],
                        "name": "C. J. Taylor",
                        "slug": "C.-J.-Taylor",
                        "structuredName": {
                            "firstName": "Camillo",
                            "lastName": "Taylor",
                            "middleNames": [
                                "Jose"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. J. Taylor"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1778676"
                        ],
                        "name": "P. Debevec",
                        "slug": "P.-Debevec",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Debevec",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Debevec"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143751119"
                        ],
                        "name": "Jitendra Malik",
                        "slug": "Jitendra-Malik",
                        "structuredName": {
                            "firstName": "Jitendra",
                            "lastName": "Malik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jitendra Malik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 16474707,
            "fieldsOfStudy": [
                "Art",
                "Computer Science"
            ],
            "id": "7f02afdd0e1ee7279d50ba034f00eb424f8e7809",
            "isKey": false,
            "numCitedBy": 57,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a new image-based modeling method that facilitates the recovery of accurate polyhedral models of architectural scenes. The method is particularly effective because it exploits many of the constraints that are characteristic of architectural scenes. This work is placed in the context of the FaCade project, whose goal is to use images to produce photo-realistic novel views of architectural scenes."
            },
            "slug": "Reconstructing-Polyhedral-Models-of-Architectural-Taylor-Debevec",
            "title": {
                "fragments": [],
                "text": "Reconstructing Polyhedral Models of Architectural Scenes from Photographs"
            },
            "tldr": {
                "abstractSimilarityScore": 75,
                "text": "This paper presents a new image-based modeling method that facilitates the recovery of accurate polyhedral models of architectural scenes and is placed in the context of the FaCade project, whose goal is to use images to produce photo-realistic novel views of architectural Scenes."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2302358"
                        ],
                        "name": "P. Burt",
                        "slug": "P.-Burt",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Burt",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Burt"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 122844278,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5cff185f86ee1506a243db0718f1b82a5ee2246d",
            "isKey": false,
            "numCitedBy": 432,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Fast-filter-transform-for-image-processing-Burt",
            "title": {
                "fragments": [],
                "text": "Fast filter transform for image processing"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1981
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2302358"
                        ],
                        "name": "P. Burt",
                        "slug": "P.-Burt",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Burt",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Burt"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 208089664,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "204a548b7ead77260f29fba0db81e834956ce64d",
            "isKey": false,
            "numCitedBy": 467,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Fast-Filter-Transforms-for-Image-Processing-Burt",
            "title": {
                "fragments": [],
                "text": "Fast Filter Transforms for Image Processing"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1981
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Wide baseline stereo matching"
            },
            "venue": {
                "fragments": [],
                "text": "Technical report,"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A combined corner a:nd edge detector"
            },
            "venue": {
                "fragments": [],
                "text": "Fourth Alvey Vision Conference,"
            },
            "year": 1988
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Obtaining correspondences from 2D perspective views with wide angular separation of non-coplanar points"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. of the EuropeanChinese Workshop on Computer Vision,"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Structure from motion usipg line correspondences"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1990
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Projective, Afine and Euclidean Calibration in Compute Vision and the Application of Three Dimensional Perception"
            },
            "venue": {
                "fragments": [],
                "text": "PhD thesis, RobotVis Group, INRIA Sophia-Antipolis,"
            },
            "year": 1996
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {},
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 22,
        "totalPages": 3
    },
    "page_url": "https://www.semanticscholar.org/paper/Wide-baseline-stereo-matching-Pritchett-Zisserman/4da91ba2e80a4d8deb597b1c884cda890f086653?sort=total-citations"
}