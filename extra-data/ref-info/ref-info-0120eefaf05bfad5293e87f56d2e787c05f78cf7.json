{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2105353"
                        ],
                        "name": "K. Narendra",
                        "slug": "K.-Narendra",
                        "structuredName": {
                            "firstName": "Kumpati",
                            "lastName": "Narendra",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Narendra"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1785805"
                        ],
                        "name": "M. Thathachar",
                        "slug": "M.-Thathachar",
                        "structuredName": {
                            "firstName": "Mandayam",
                            "lastName": "Thathachar",
                            "middleNames": [
                                "A.",
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Thathachar"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 17464562,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f5884b40f776c85d7689ea2c440f7982cb1bec46",
            "isKey": false,
            "numCitedBy": 653,
            "numCiting": 99,
            "paperAbstract": {
                "fragments": [],
                "text": "Stochastic automata operating in an unknown random environment have been proposed earlier as models of learning. These automata update their action probabilities in accordance with the inputs received from the environment and can improve their own performance during operation. In this context they are referred to as learning automata. A survey of the available results in the area of learning automata has been attempted in this paper. Attention has been focused on the norms of behavior of learning automata, issues in the design of updating schemes, convergence of the action probabilities, and interaction of several automata. Utilization of learning automata in parameter optimization and hypothesis testing is discussed, and potential areas of application are suggested."
            },
            "slug": "Learning-Automata-A-Survey-Narendra-Thathachar",
            "title": {
                "fragments": [],
                "text": "Learning Automata - A Survey"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "Attention has been focused on the norms of behavior of learning automata, issues in the design of updating schemes, convergence of the action probabilities, and interaction of several automata."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Syst. Man Cybern."
            },
            "year": 1974
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1788765"
                        ],
                        "name": "R. Jarvis",
                        "slug": "R.-Jarvis",
                        "structuredName": {
                            "firstName": "Ray",
                            "lastName": "Jarvis",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Jarvis"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 35050601,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b467c4aaf6a74e3015707f367de315ad446c53c9",
            "isKey": false,
            "numCitedBy": 25,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "A probabilistic automaton with pattern recognition supervision is considered as an on-line real-time adaptive controller for a complex plant with a multimodal performance-index structure and subjected to an environment which randomly fluctuates in time. This environment is considered to be partially measurable but entirely uncontrollable. The automaton discussed is capable not only of learning the optimum control parameters in any given environmental situation but also of acting as an internal teacher in the formation of pattern associations between the measurable state of the environment and the control situation, so that approximately recurrent conditions can be taken advantage of in future relearning situations. These pattern associations, once developed, are used to supervise the future action of the automaton. Furthermore, the pattern associations between the measurable state of the environment and the control situation must themselves be adaptively formed to allow for variations caused by unknown and/or unmeasurable factors in the total environment."
            },
            "slug": "Adaptive-Global-Search-in-a-Time-Variant-Using-a-Jarvis",
            "title": {
                "fragments": [],
                "text": "Adaptive Global Search in a Time-Variant Environment Using a Probabilistic Automaton with Pattern Recognition Supervision"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "The automaton discussed is capable not only of learning the optimum control parameters in any given environmental situation but also of acting as an internal teacher in the formation of pattern associations between the measurable state of the environment and the control situation, so that approximately recurrent conditions can be taken advantage of in future relearning situations."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Syst. Sci. Cybern."
            },
            "year": 1970
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1730590"
                        ],
                        "name": "A. Barto",
                        "slug": "A.-Barto",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Barto",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Barto"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 60381785,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e1848e133cf064c8156ab933f93e31599cef6861",
            "isKey": false,
            "numCitedBy": 17,
            "numCiting": 66,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract : This report describes results obtained from computer simulation experiments designed to systematically develop and evaluate an approach to learning by networks of neuronlike adaptive elements. The characterizing feature of this approach is that the network components, or adaptive elements, are self-interested, goal-seeking agents that implement robust algorithms for furthering their individual interests. These algorithms combine stochastic search and associative learning methods. Results show how these adaptive elements can cooperate as components of layered networks that adaptively create new features by combining existing features. Other simulation experiments are described that systematically examine the performance of individual adaptive elements in tasks that resemble the tasks faced by elements embedded within networks. The performances of a variety of algorithms are compared and contrasted. These results demonstrate the shortcomings of certain algorithms and the effectiveness of others. Experiments examine the effects on learning of delayed reinforcement. We justify the adaptive heuristic critic algorithm for reducing the severity of the temporal credit-assignment problem for tasks with delayed reinforcement. We illustrate the effectiveness of this algorithm in a task requiring the system to learn to control an unstable dynamical system under the influence of low-quality evaluative feedback."
            },
            "slug": "Simulation-Experiments-with-Goal-Seeking-Adaptive-Barto",
            "title": {
                "fragments": [],
                "text": "Simulation Experiments with Goal-Seeking Adaptive Elements."
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "The adaptive heuristic critic algorithm is justified for reducing the severity of the temporal credit-assignment problem for tasks with delayed reinforcement and the effectiveness of this algorithm is illustrated in a task requiring the system to learn to control an unstable dynamical system under the influence of low-quality evaluative feedback."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1984
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1748557"
                        ],
                        "name": "P. Smolensky",
                        "slug": "P.-Smolensky",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Smolensky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Smolensky"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14915217,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7a08f1b9d48c4a3ba5b3672dccafd0e9434e3d1b",
            "isKey": false,
            "numCitedBy": 74,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "Given a set of stimuli presenting views of some environment, how can one characterize the natural modules or \"objects\" that compose the environment? Should a given set of items be encoded as a collection of instances or as a set of rules? Restricted formulations of these questions are addressed by analysis within a new mathematical framework that describes stochastic parallel computation. An algorithm is given for simulating this computation once schemas encoding the modules of the environment have been selected. The concept of computational temperature is introduced. As this temperature is lowered, the system appears to display a dramatic tendency to interpret input, even if the evidence for any particular interpretation is very weak."
            },
            "slug": "Schema-Selection-and-Stochastic-Inference-in-Smolensky",
            "title": {
                "fragments": [],
                "text": "Schema Selection and Stochastic Inference in Modular Environments"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "The concept of computational temperature is introduced and the system appears to display a dramatic tendency to interpret input, even if the evidence for any particular interpretation is very weak."
            },
            "venue": {
                "fragments": [],
                "text": "AAAI"
            },
            "year": 1983
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145970701"
                        ],
                        "name": "R. Atkinson",
                        "slug": "R.-Atkinson",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Atkinson",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Atkinson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "51966268"
                        ],
                        "name": "W. Estes",
                        "slug": "W.-Estes",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Estes",
                            "middleNames": [
                                "Kaye"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Estes"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 62670608,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "434bff7f69273967c46cdda4209b77b4958d0ce4",
            "isKey": false,
            "numCitedBy": 267,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract : Some of the fundamental mathematical techniques of stimuls sampling theory are presented. The simplest of all learning models - the pattern model for simple learning is presented in which the population of available stimulation is ASSUMED TO COMPRISE A SET OF DISTINCT STIMULUS PATTERNS, EXACTLY ONE OF WHICH IS SAMPLED ON EACH TRIAL. In the important special case of the oneelement model, it is assumed that there is only one such pattern and that it recurs intact at the beginning of each experimenta trial. The oneelement model is worthy of study not only for expositional purposes but also for its value as an analytic device in relation to certain types of learning data. After a treatment of pattern models for simple acquisition an for learning under probabilistic reinforcement schedules, the conceptualization of generalization and transfer is discussed; the component models in which the patterns of stimulation effective on individual trials are treated, not as distinct elements, but as overlapping samples from a common population; and, finally, some examples of the more complex multiple-process models which are becoming increasingly important in the analysis of discrimination learning, concept formation, and related phenomena are discussed. (Author)"
            },
            "slug": "Stimulus-Sampling-Theory-Atkinson-Estes",
            "title": {
                "fragments": [],
                "text": "Stimulus Sampling Theory"
            },
            "tldr": {
                "abstractSimilarityScore": 61,
                "text": "Some of the fundamental mathematical techniques of stimuls sampling theory are presented and the oneelement model is worthy of study not only for expositional purposes but also for its value as an analytic device in relation to certain types of learning data."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1967
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49892629"
                        ],
                        "name": "M. Norman",
                        "slug": "M.-Norman",
                        "structuredName": {
                            "firstName": "M.",
                            "lastName": "Norman",
                            "middleNames": [
                                "Frank"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Norman"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 120513559,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "c3d5b5a03e2eb1f8c654a92f7c547ca5b9aa37e4",
            "isKey": false,
            "numCitedBy": 28,
            "numCiting": 1,
            "paperAbstract": {
                "fragments": [],
                "text": "Real-valued Markov processes with steps of the form $\\Delta X_n = \\theta _i (\\lambda _i - X_n )$ or $\\Delta X_n = \\delta _i $, $i = 1, \\cdots ,v$, arise frequently in the theory of human and animal learning. This paper first surveys results pertaining to the asymptotic behavior of such processes as $n \\to \\infty $. Next, general theorems are given that cover limiting behavior as $n \\to \\infty $ and, simultaneously, $\\theta _i \\to 0$ or $\\delta _i \\to 0$. Finally, an example of a two-dimensional learning process $X_n$ is presented."
            },
            "slug": "Markovian-Learning-Processes-Norman",
            "title": {
                "fragments": [],
                "text": "Markovian Learning Processes"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1974
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9419406"
                        ],
                        "name": "I. Witten",
                        "slug": "I.-Witten",
                        "structuredName": {
                            "firstName": "Ian",
                            "lastName": "Witten",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Witten"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 30145758,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "0f2d0e9c57d268fc1d05ce657eaf64eaaeb323c7",
            "isKey": false,
            "numCitedBy": 182,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "An-Adaptive-Optimal-Controller-for-Discrete-Time-Witten",
            "title": {
                "fragments": [],
                "text": "An Adaptive Optimal Controller for Discrete-Time Markov Environments"
            },
            "venue": {
                "fragments": [],
                "text": "Inf. Control."
            },
            "year": 1977
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1913418"
                        ],
                        "name": "B. Widrow",
                        "slug": "B.-Widrow",
                        "structuredName": {
                            "firstName": "Bernard",
                            "lastName": "Widrow",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Widrow"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2115344719"
                        ],
                        "name": "Narendra K. Gupta",
                        "slug": "Narendra-K.-Gupta",
                        "structuredName": {
                            "firstName": "Narendra",
                            "lastName": "Gupta",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Narendra K. Gupta"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34601642"
                        ],
                        "name": "S. Maitra",
                        "slug": "S.-Maitra",
                        "structuredName": {
                            "firstName": "Sidhartha",
                            "lastName": "Maitra",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Maitra"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1487792,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6587a531da06b9cef73e93b6b7627e466ad51d1b",
            "isKey": false,
            "numCitedBy": 298,
            "numCiting": 43,
            "paperAbstract": {
                "fragments": [],
                "text": "An adaptive threshold element is able to \"learn\" a strategy of play for the game blackjack (twenty-one) with a performance close to that of the Thorp optimal strategy although the adaptive system has no prior knowledge of the game and of the objective of play. After each winning game the decisions of the adaptive system are \"rewarded.\" After each losing game the decisions are \"punished.\" Reward is accomplished by adapting while accepting the actual decision as the desired response. Punishment is accomplished by adapting while taking the desired response to be the opposite of that of the actual decision. This learning scheme is unlike \"learning with a teacher\" and unlike \"unsupervised learning.\" It involves \"bootstrap adaptation\" or \"learning with a critic.\" The critic rewards decisions which are members of successful chains of decisions and punishes other decisions. A general analytical model for learning with a critic is formulated and analyzed. The model represents bootstrap learning per se. Although the hypotheses on which the model is based do not perfectly fit blackjack learning, it is applied heuristically to predict adaptation rates with good experimental success. New applications are being explored for bootstrap learning in adaptive controls and multilayered adaptive systems."
            },
            "slug": "Punish/Reward:-Learning-with-a-Critic-in-Adaptive-Widrow-Gupta",
            "title": {
                "fragments": [],
                "text": "Punish/Reward: Learning with a Critic in Adaptive Threshold Systems"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "An adaptive threshold element is able to \"learn\" a strategy of play for the game blackjack (twenty-one) with a performance close to that of the Thorp optimal strategy although the adaptive system has no prior knowledge of the game and of the objective of play."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Syst. Man Cybern."
            },
            "year": 1973
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1752732"
                        ],
                        "name": "T. Cover",
                        "slug": "T.-Cover",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Cover",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Cover"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1782873"
                        ],
                        "name": "M. Hellman",
                        "slug": "M.-Hellman",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "Hellman",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Hellman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 11886750,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6efb077f228f01c5ab61a2f104ef1ff9609ef2b7",
            "isKey": false,
            "numCitedBy": 89,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper solves the classical two-armed-bandit problem under the finite-memory constraint described below. Given are probability densities p_0 and p_1 , and two experiments A and B . It is not known which density is associated with which experiment. Thus the experimental outcome Y of experiment A is as likely to be distributed according to p_0 as it is to be distributed according to p_1 . It is desired to sequentially choose an experiment to be performed on the basis of past observations according to the algorithm T_n = f(T_{n-1}, e_n, Y_n), e_n = e(T_{n-1}) , where T_n \\in \\{1, 2, \\cdots, m\\} is the state of memory at time n, e_n \\in \\{A, B\\} is the choice of experiment, and Y_n , is the random variable observation. The goal is to maximize the asymptotic proportion r of uses of the experiment associated with density p_0 . Let l(y) = p_0 (y) / p_1 (y) , and let \\bar{l} and \\bar{\\bar{l}} denote the almost everywhere greatest lower bound and least upper bound on l(y) . Let 1 = \\max {\\bar{\\bar{l}}, 1/\\bar{l}} . Then the optimal value of r , over all m -state algorithms (f, e) , will be shown to be l^{m-1} / (l^{m-1} + 1) . An e -optimal family of m -state algorithms will be demonstrated. In general, optimal algorithms do not exist, and e -optimal algorithms require artificial randomization."
            },
            "slug": "The-two-armed-bandit-problem-with-time-invariant-Cover-Hellman",
            "title": {
                "fragments": [],
                "text": "The two-armed-bandit problem with time-invariant finite memory"
            },
            "tldr": {
                "abstractSimilarityScore": 70,
                "text": "This paper solves the classical two-armed-bandit problem under the finite-memory constraint described below and shows the optimal value of r, over all m -state algorithms (f, e), will be shown to be l-1 / (l-1 + 1) ."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Inf. Theory"
            },
            "year": 1970
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35106875"
                        ],
                        "name": "R. Duda",
                        "slug": "R.-Duda",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Duda",
                            "middleNames": [
                                "O."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Duda"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3108177"
                        ],
                        "name": "P. Hart",
                        "slug": "P.-Hart",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Hart",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Hart"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 12946615,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b07ce649d6f6eb636872527104b0209d3edc8188",
            "isKey": false,
            "numCitedBy": 16927,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Provides a unified, comprehensive and up-to-date treatment of both statistical and descriptive methods for pattern recognition. The topics treated include Bayesian decision theory, supervised and unsupervised learning, nonparametric techniques, discriminant analysis, clustering, preprosessing of pictorial data, spatial filtering, shape description techniques, perspective transformations, projective invariants, linguistic procedures, and artificial intelligence techniques for scene analysis."
            },
            "slug": "Pattern-classification-and-scene-analysis-Duda-Hart",
            "title": {
                "fragments": [],
                "text": "Pattern classification and scene analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 66,
                "text": "The topics treated include Bayesian decision theory, supervised and unsupervised learning, nonparametric techniques, discriminant analysis, clustering, preprosessing of pictorial data, spatial filtering, shape description techniques, perspective transformations, projective invariants, linguistic procedures, and artificial intelligence techniques for scene analysis."
            },
            "venue": {
                "fragments": [],
                "text": "A Wiley-Interscience publication"
            },
            "year": 1973
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3085659"
                        ],
                        "name": "H. Kushner",
                        "slug": "H.-Kushner",
                        "structuredName": {
                            "firstName": "Harold",
                            "lastName": "Kushner",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Kushner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35229585"
                        ],
                        "name": "D. Clark",
                        "slug": "D.-Clark",
                        "structuredName": {
                            "firstName": "Dean",
                            "lastName": "Clark",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Clark"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 117328031,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "0009c5a2b4b07751a99bcf407d95e911a3064d0f",
            "isKey": false,
            "numCitedBy": 948,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "I. Introduction.- 1.1. General Remarks.- 1.2. The Robbins-Monro Process.- 1.3. A \"Continuous\" Process Version of Section 2.- 1.4. Regulation of a Dynamical System a simple example.- 1.5. Function Minimization: The Kiefer-Wolfowitz Procedure.- 1.6. Constrained Problems.- 1.7. An Economics Example.- II. Convergence w.p.1 for Unconstrained Systems.- 2.1. Preliminaries and Motivation.- 2.2. The Robbins-Monro and Kiefer-Wolfowitz Algorithms: Conditions and Discussion.- 2.3. Convergence Proofs for RM and KW-like Procedures.- 2.3.1. A Basic RM-like Procedure.- 2.3.2. One Dimensional RM and Accelerated RM Procedures.- 2.3.3. A Continuous Parameter RM Procedure.- 2.3.4. The Basic Kiefer-Wolfowitz Procedure.- 2.3.5. Random Directions KW Methods.- 2.4. A General Robbins-Monro Process: \"Exogenous Noise\".- 2.4.1. The Case of Bounded h(*,*).- 2.4.2. Unbounded h(*,*): Exogenous Noise.- 2.5. A General RM Process State Dependent Noise.- 2.5.1. Extensions and Localizations of Theorem 2.5.2.- 2.6. Some Applications.- 2.7. Mensov-Rademacher Estimates.- III. Weak Convergence of Probability Measures.- IV. Weak Convergence for Unconstrained Systems.- 4.1. Conditions and General Discussion.- 4.2. The Robbins-Monro and Kiefer-Wolfowitz Procedures.- 4.2.1. The Basic Robbins-Monro Procedure.- 4.2.2. The One-Dimensional Robbins-Monro Procedure.- 4.2.3. The Kiefer-Wolfowitz Procedure.- 4.2.4. A Case Where the Limit Satisfies a Generalized ODE.- 4.2.5. A Continuous Parameter KW Procedure.- 4.3. A General Robbins-Monro Process: Exogenous Noise.- 4.4. A General RM Process: State Dependent Noise.- 4.5. The Identification Problem.- 4.6. A Counter-Example to Tightness.- 4.7. Boundedness of {Xn} and Tightness of {Xn(*)}.- V. Convergence w.p.1 For Constrained Systems.- 5.1. A Penalty-Multiplier Algorithm for Equality Constraints.- 5.1.1. A Basic RM-like Algorithm, Conditions and Discussion.- 5.1.2. The Noise Condition, Discussion and Generalization.- 5.1.3. Boundedness of {Xn}.- 5.1.4. Proof of the Main Theorem.- 5.1.5. Constrained Function Minimization and Other Extensions.- 5.2. A Lagrangian Method for Inequality Constraints.- 5.2.1. The Algorithm and Conditions.- 5.2.2. The Convergence Theorem 18.- 5.2.3. A Non-Convergent but Useful Algorithm.- 5.2.4. An Application to the Identification Problem.- 5.3. A Projection Algorithm.- 5.4. A Penalty-Multiplier Method for Inequality Constraints.- VI. Weak Convergence: Constrained Systems.- 6.1. A Multiplier Type Algorithm for Equality Constraints.- 6.1.1. Boundedness of {Xn}.- 6.1.2. The Noise Condition, Discussion.- 6.1.3. The Convergence Theorem.- 6.2. The Lagrangian Method.- 6.3. A Projection Algorithm.- 6.4. A Penalty-Multiplier Algorithm for Inequality Constraints.- VII. Rates of Convergence.- 7.1. The Problem Formulation.- 7.2. Conditions and Discussions.- 7.3. Rates of Convergence for Case 1, the KW Algorithm.- 7.4. Discussion of Rates of Convergence for Two KW Algorithms."
            },
            "slug": "wchastic.-approximation-methods-for-constrained-and-Kushner-Clark",
            "title": {
                "fragments": [],
                "text": "wchastic. approximation methods for constrained and unconstrained systems"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The Robbins-Monro and Kiefer-Wolfowitz Algorithm for Inequality Constraints and the Weak Convergence of Probability Measures, a simple example, and the Convergence Theorem, a proof of the Main Theorem."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1978
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2650569"
                        ],
                        "name": "A. Klopf",
                        "slug": "A.-Klopf",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Klopf",
                            "middleNames": [
                                "Harry"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Klopf"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 56108868,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "0c1accd2ef7218534a1726a8de7d6e7c14271a75",
            "isKey": false,
            "numCitedBy": 158,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract : A new theory of intelligent adaptive systems is proposed. The theory provides a single unifying framework within which the neurophysiological, psychological, and sociological properties of living adaptive systems can be understood. Furthermore, the theory offers a new basis for the synthesis of machines possessing adaptive intelligence. The proposed theory is of a heterostatic type. That is to say, it is a theory which assumes that living adaptive systems seek, as their primary goal, a maximal condition (heterostasis) , rather than assuming that the primary goal is a steadystate condition (homeostasis). It is further assumed that the heterostatic nature of animals, including man, derives from the heterostatic nature of neurons. The postulate that the neuron is a heterostat (that is, a maximizer) is a generalization of a more specific postulate, namely, that the neuron is a hedonist. This latter postulate is interpreted strictly in terms of physical variables, yielding the heterostatic neuronal model that is the basis for the detailed development of the theory."
            },
            "slug": "Brain-Function-and-Adaptive-Systems:-A-Heterostatic-Klopf",
            "title": {
                "fragments": [],
                "text": "Brain Function and Adaptive Systems: A Heterostatic Theory"
            },
            "tldr": {
                "abstractSimilarityScore": 73,
                "text": "The theory provides a single unifying framework within which the neurophysiological, psychological, and sociological properties of living adaptive systems can be understood and offers a new basis for the synthesis of machines possessing adaptive intelligence."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1972
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3194361"
                        ],
                        "name": "S. Geman",
                        "slug": "S.-Geman",
                        "structuredName": {
                            "firstName": "Stuart",
                            "lastName": "Geman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Geman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1707642"
                        ],
                        "name": "D. Geman",
                        "slug": "D.-Geman",
                        "structuredName": {
                            "firstName": "Donald",
                            "lastName": "Geman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Geman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5837272,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "459b30a9a960080f3b313e41886b1aa0e51e882c",
            "isKey": false,
            "numCitedBy": 18710,
            "numCiting": 60,
            "paperAbstract": {
                "fragments": [],
                "text": "We make an analogy between images and statistical mechanics systems. Pixel gray levels and the presence and orientation of edges are viewed as states of atoms or molecules in a lattice-like physical system. The assignment of an energy function in the physical system determines its Gibbs distribution. Because of the Gibbs distribution, Markov random field (MRF) equivalence, this assignment also determines an MRF image model. The energy function is a more convenient and natural mechanism for embodying picture attributes than are the local characteristics of the MRF. For a range of degradation mechanisms, including blurring, nonlinear deformations, and multiplicative or additive noise, the posterior distribution is an MRF with a structure akin to the image model. By the analogy, the posterior distribution defines another (imaginary) physical system. Gradual temperature reduction in the physical system isolates low energy states (``annealing''), or what is the same thing, the most probable states under the Gibbs distribution. The analogous operation under the posterior distribution yields the maximum a posteriori (MAP) estimate of the image given the degraded observations. The result is a highly parallel ``relaxation'' algorithm for MAP estimation. We establish convergence properties of the algorithm and we experiment with some simple pictures, for which good restorations are obtained at low signal-to-noise ratios."
            },
            "slug": "Stochastic-Relaxation,-Gibbs-Distributions,-and-the-Geman-Geman",
            "title": {
                "fragments": [],
                "text": "Stochastic Relaxation, Gibbs Distributions, and the Bayesian Restoration of Images"
            },
            "tldr": {
                "abstractSimilarityScore": 52,
                "text": "The analogy between images and statistical mechanics systems is made and the analogous operation under the posterior distribution yields the maximum a posteriori (MAP) estimate of the image given the degraded observations, creating a highly parallel ``relaxation'' algorithm for MAP estimation."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 1984
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145648751"
                        ],
                        "name": "H. Robbins",
                        "slug": "H.-Robbins",
                        "structuredName": {
                            "firstName": "Herbert",
                            "lastName": "Robbins",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Robbins"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2830058,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "126e8b262305e003535701975ed3d6ea9d41b75b",
            "isKey": false,
            "numCitedBy": 87,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "We consider the problem of successively choosing one of two ways of action, each of which may lead to success or failure, in such a way as to maximize the long-run proportion of successes obtained, the choice each time being based on the results of a fixed number of the previous trials."
            },
            "slug": "A-SEQUENTIAL-DECISION-PROBLEM-WITH-A-FINITE-MEMORY.-Robbins",
            "title": {
                "fragments": [],
                "text": "A SEQUENTIAL DECISION PROBLEM WITH A FINITE MEMORY."
            },
            "tldr": {
                "abstractSimilarityScore": 95,
                "text": "This work considers the problem of successively choosing one of two ways of action, each of which may lead to success or failure, in such a way as to maximize the long-run proportion of successes obtained."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the National Academy of Sciences of the United States of America"
            },
            "year": 1956
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34099369"
                        ],
                        "name": "B. Farley",
                        "slug": "B.-Farley",
                        "structuredName": {
                            "firstName": "B.",
                            "lastName": "Farley",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Farley"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2113802893"
                        ],
                        "name": "W. A. Clark",
                        "slug": "W.-A.-Clark",
                        "structuredName": {
                            "firstName": "W.",
                            "lastName": "Clark",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. A. Clark"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 28327238,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "879650714f3dce59b666346ccf63fd73250259d6",
            "isKey": false,
            "numCitedBy": 263,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "A general discussion of ideas and definitions relating to self-organizing systems and their synthesis is given, together with remarks concerning their simulation by digital computer. Synthesis and simulation of an actual system is then described. This system, initially randomly organized within wide limits, organizes itself to perform a simple prescribed task."
            },
            "slug": "Simulation-of-self-organizing-systems-by-digital-Farley-Clark",
            "title": {
                "fragments": [],
                "text": "Simulation of self-organizing systems by digital computer"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "A general discussion of ideas and definitions relating to self-organizing systems and their synthesis is given, together with remarks concerning their simulation by digital computer."
            },
            "venue": {
                "fragments": [],
                "text": "Trans. IRE Prof. Group Inf. Theory"
            },
            "year": 1954
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145847131"
                        ],
                        "name": "S. Kirkpatrick",
                        "slug": "S.-Kirkpatrick",
                        "structuredName": {
                            "firstName": "Scott",
                            "lastName": "Kirkpatrick",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Kirkpatrick"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "5882723"
                        ],
                        "name": "C. D. Gelatt",
                        "slug": "C.-D.-Gelatt",
                        "structuredName": {
                            "firstName": "Charles",
                            "lastName": "Gelatt",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. D. Gelatt"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "88645967"
                        ],
                        "name": "M. Vecchi",
                        "slug": "M.-Vecchi",
                        "structuredName": {
                            "firstName": "Michelle",
                            "lastName": "Vecchi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Vecchi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 205939,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "dd5061631a4d11fa394f4421700ebf7e78dcbc59",
            "isKey": false,
            "numCitedBy": 39640,
            "numCiting": 79,
            "paperAbstract": {
                "fragments": [],
                "text": "There is a deep and useful connection between statistical mechanics (the behavior of systems with many degrees of freedom in thermal equilibrium at a finite temperature) and multivariate or combinatorial optimization (finding the minimum of a given function depending on many parameters). A detailed analogy with annealing in solids provides a framework for optimization of the properties of very large and complex systems. This connection to statistical mechanics exposes new information and provides an unfamiliar perspective on traditional optimization problems and methods."
            },
            "slug": "Optimization-by-Simulated-Annealing-Kirkpatrick-Gelatt",
            "title": {
                "fragments": [],
                "text": "Optimization by Simulated Annealing"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "A detailed analogy with annealing in solids provides a framework for optimization of the properties of very large and complex systems."
            },
            "venue": {
                "fragments": [],
                "text": "Science"
            },
            "year": 1983
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48801723"
                        ],
                        "name": "F. Downton",
                        "slug": "F.-Downton",
                        "structuredName": {
                            "firstName": "F.",
                            "lastName": "Downton",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Downton"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 4224834,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "555a7921231b86464a8db34ada9edade765bf8f0",
            "isKey": false,
            "numCitedBy": 440,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Stochastic ApproximationBy M. T. Wasan. (Cambridge Tracts in Mathematics and Mathematical Physics, No. 58.) Pp. x + 202. (Cambridge University Press: London, June 1969.) 70s; $9.50."
            },
            "slug": "Stochastic-Approximation-Downton",
            "title": {
                "fragments": [],
                "text": "Stochastic Approximation"
            },
            "venue": {
                "fragments": [],
                "text": "Nature"
            },
            "year": 1969
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1847175"
                        ],
                        "name": "M. Minsky",
                        "slug": "M.-Minsky",
                        "structuredName": {
                            "firstName": "Marvin",
                            "lastName": "Minsky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Minsky"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2434678"
                        ],
                        "name": "S. Papert",
                        "slug": "S.-Papert",
                        "structuredName": {
                            "firstName": "Seymour",
                            "lastName": "Papert",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Papert"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 5400596,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f74ded11f72099d16591a1191d72262ae6b5f14a",
            "isKey": false,
            "numCitedBy": 3040,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Cambridge, Mass.: MIT Press, 1972. 2nd. ed. The book's aim is to seek general results from the close study of abstract version of devices known as perceptrons"
            },
            "slug": "Perceptrons-an-introduction-to-computational-Minsky-Papert",
            "title": {
                "fragments": [],
                "text": "Perceptrons - an introduction to computational geometry"
            },
            "tldr": {
                "abstractSimilarityScore": 68,
                "text": "The aim of this book is to seek general results from the close study of abstract version of devices known as perceptrons."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1969
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "4726846"
                        ],
                        "name": "D. Meeter",
                        "slug": "D.-Meeter",
                        "structuredName": {
                            "firstName": "Duane",
                            "lastName": "Meeter",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Meeter"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 122817428,
            "fieldsOfStudy": [
                "Materials Science"
            ],
            "id": "83e50a6d3073ef197b67ed759e04df2c7acc9704",
            "isKey": false,
            "numCitedBy": 62,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "A process for producing a thermoplastic resin sheet having a band of color by feeding a molten thermoplastic resin by an extruder into a sheet-forming flat die having a manifold and extruding said molten resin from an extrusion opening of said flat die, which comprises forcing a stream of a colored molten thermoplastic resin through at least one injection port opened into the manifold of the flat die into a main stream of the molten resin extruded from the extruder and fed to the manifold, associating the main stream of the molten thermoplastic resin and the stream of the colored molten thermoplastic resin within the manifold, and extruding the associated streams from the extrusion opening of said flat die."
            },
            "slug": "Stochastic-Approximation-and-Nonlinear-Regression-Meeter",
            "title": {
                "fragments": [],
                "text": "Stochastic Approximation and Nonlinear Regression"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1969
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49892629"
                        ],
                        "name": "M. Norman",
                        "slug": "M.-Norman",
                        "structuredName": {
                            "firstName": "M.",
                            "lastName": "Norman",
                            "middleNames": [
                                "Frank"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Norman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 122530449,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "cd2e17eba2f61ca9ba6c20573700b6dfccf56ba8",
            "isKey": false,
            "numCitedBy": 41,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-Central-Limit-theorem-for-Markov-Processes-that-Norman",
            "title": {
                "fragments": [],
                "text": "A Central Limit theorem for Markov Processes that Move by Small Steps"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1974
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3365230"
                        ],
                        "name": "C. Derman",
                        "slug": "C.-Derman",
                        "structuredName": {
                            "firstName": "Cyrus",
                            "lastName": "Derman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Derman"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 117572511,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "167be8348ff60a37c96efdfc1e0e3f467a84a470",
            "isKey": false,
            "numCitedBy": 817,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Finite-State-Markovian-Decision-Processes-Derman",
            "title": {
                "fragments": [],
                "text": "Finite State Markovian Decision Processes"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1970
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "67058572"
                        ],
                        "name": "A. S. Harding",
                        "slug": "A.-S.-Harding",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Harding",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. S. Harding"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 61845409,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "c20628cbbd2230b9c7b664c40b6a910380f486fd",
            "isKey": false,
            "numCitedBy": 164,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Markovian-decision-processes-Harding",
            "title": {
                "fragments": [],
                "text": "Markovian decision processes"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1970
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "17044772"
                        ],
                        "name": "M. L. Tsetlin",
                        "slug": "M.-L.-Tsetlin",
                        "structuredName": {
                            "firstName": "M.",
                            "lastName": "Tsetlin",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. L. Tsetlin"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 60832129,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d5cb74a2e0ed05d8298f69d7d24600a583932f49",
            "isKey": false,
            "numCitedBy": 276,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Automaton-theory-and-modeling-of-biological-systems-Tsetlin",
            "title": {
                "fragments": [],
                "text": "Automaton theory and modeling of biological systems"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1973
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Boltzmann machines: Constraint satisfaction networks that learn"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1984
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Boltzmann machines: Constraint satisfaction networks that learn,\" CarnegieMellon University, Pittsburgh, PA"
            },
            "venue": {
                "fragments": [],
                "text": "Tech. Rep. CMU-CS-84-119,"
            },
            "year": 1984
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Neuronlike elements that can solve difficult learning control problems"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1981
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Stochastic approximation,\" in Adaptation, Learning, and Pattern Recognition Systems: Theory and Applications"
            },
            "venue": {
                "fragments": [],
                "text": "New York: Academic,"
            },
            "year": 1970
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Learning automata\u2014A critique,"
            },
            "venue": {
                "fragments": [],
                "text": "Cybern, and Inf. Sci.,"
            },
            "year": 1977
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Theory of neural-analog reinforcement systems and its application to the brain-model problem,"
            },
            "venue": {
                "fragments": [],
                "text": "Ph.D. dissertation Princeton Univ.,"
            },
            "year": 1954
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Analyzing cooperative computation"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. Fifth Ann"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Temporal aspects of credit assignment in reinforcement learning,"
            },
            "venue": {
                "fragments": [],
                "text": "Ph.D. dissertation, Univ. Massachusetts,"
            },
            "year": 1984
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Learning Algorithms and Applications"
            },
            "venue": {
                "fragments": [],
                "text": "New York: Springer-Verlag,"
            },
            "year": 1981
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Jarvis , \" Adaptive global search in a time varying environment using probabilistic automaton with pattern recognition supervision"
            },
            "venue": {
                "fragments": [],
                "text": "Syst . , Sci . , Cybernet ."
            },
            "year": 1963
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "e-optimal learning algorithms-Non-absorbing barrier type"
            },
            "venue": {
                "fragments": [],
                "text": "School of Elee. Eng. and Comput. Sci., Univ. Oklahoma"
            },
            "year": 1979
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Raiffa, Games and Decisions"
            },
            "venue": {
                "fragments": [],
                "text": "New York: Wiley"
            },
            "year": 1957
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Feature generation and selection by a layered network of reinforcement learning elements: Some initial experiments,"
            },
            "venue": {
                "fragments": [],
                "text": "COINS Technical Report 82-12,"
            },
            "year": 1982
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {},
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 36,
        "totalPages": 4
    },
    "page_url": "https://www.semanticscholar.org/paper/Pattern-recognizing-stochastic-learning-automata-Barto-Anandan/0120eefaf05bfad5293e87f56d2e787c05f78cf7?sort=total-citations"
}