{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2064873282"
                        ],
                        "name": "Filip Grali'nski",
                        "slug": "Filip-Grali'nski",
                        "structuredName": {
                            "firstName": "Filip",
                            "lastName": "Grali'nski",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Filip Grali'nski"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1822665"
                        ],
                        "name": "Tomasz Stanislawek",
                        "slug": "Tomasz-Stanislawek",
                        "structuredName": {
                            "firstName": "Tomasz",
                            "lastName": "Stanislawek",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tomasz Stanislawek"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2065175441"
                        ],
                        "name": "Anna Wr'oblewska",
                        "slug": "Anna-Wr'oblewska",
                        "structuredName": {
                            "firstName": "Anna",
                            "lastName": "Wr'oblewska",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Anna Wr'oblewska"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2055968344"
                        ],
                        "name": "Dawid Lipi'nski",
                        "slug": "Dawid-Lipi'nski",
                        "structuredName": {
                            "firstName": "Dawid",
                            "lastName": "Lipi'nski",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dawid Lipi'nski"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2064187520"
                        ],
                        "name": "Agnieszka Kaliska",
                        "slug": "Agnieszka-Kaliska",
                        "structuredName": {
                            "firstName": "Agnieszka",
                            "lastName": "Kaliska",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Agnieszka Kaliska"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2066303178"
                        ],
                        "name": "Paulina Rosalska",
                        "slug": "Paulina-Rosalska",
                        "structuredName": {
                            "firstName": "Paulina",
                            "lastName": "Rosalska",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Paulina Rosalska"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "11016367"
                        ],
                        "name": "Bartosz Topolski",
                        "slug": "Bartosz-Topolski",
                        "structuredName": {
                            "firstName": "Bartosz",
                            "lastName": "Topolski",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bartosz Topolski"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144356944"
                        ],
                        "name": "P. Biecek",
                        "slug": "P.-Biecek",
                        "structuredName": {
                            "firstName": "P.",
                            "lastName": "Biecek",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Biecek"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 212414676,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e2d2f64b3bb200c2c3db5ddc367b06311c369341",
            "isKey": false,
            "numCitedBy": 20,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "State-of-the-art solutions for Natural Language Processing (NLP) are able to capture a broad range of contexts, like the sentence-level context or document-level context for short documents. But these solutions are still struggling when it comes to longer, real-world documents with the information encoded in the spatial structure of the document, such as page elements like tables, forms, headers, openings or footers; complex page layout or presence of multiple pages. \nTo encourage progress on deeper and more complex Information Extraction (IE) we introduce a new task (named Kleister) with two new datasets. Utilizing both textual and structural layout features, an NLP system must find the most important information, about various types of entities, in long formal documents. We propose Pipeline method as a text-only baseline with different Named Entity Recognition architectures (Flair, BERT, RoBERTa). Moreover, we checked the most popular PDF processing tools for text extraction (pdf2djvu, Tesseract and Textract) in order to analyze behavior of IE system in presence of errors introduced by these tools."
            },
            "slug": "Kleister:-A-novel-task-for-Information-Extraction-Grali'nski-Stanislawek",
            "title": {
                "fragments": [],
                "text": "Kleister: A novel task for Information Extraction involving Long Documents with Complex Layout"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A new task is introduced (named Kleister) with two new datasets to encourage progress on deeper and more complex Information Extraction (IE) and Pipeline method is proposed as a text-only baseline with different Named Entity Recognition architectures (Flair, BERT, RoBERTa)."
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 2020
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153368526"
                        ],
                        "name": "Timo I. Denk",
                        "slug": "Timo-I.-Denk",
                        "structuredName": {
                            "firstName": "Timo",
                            "lastName": "Denk",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Timo I. Denk"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9992847"
                        ],
                        "name": "C. Reisswig",
                        "slug": "C.-Reisswig",
                        "structuredName": {
                            "firstName": "Christian",
                            "lastName": "Reisswig",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Reisswig"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 84,
                                "start": 60
                            }
                        ],
                        "text": "This method was used, among others, by Katti et al. (2018); Denk and Reisswig (2019)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 202558968,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2fbda89395f993040b7665730c64182ade3be195",
            "isKey": false,
            "numCitedBy": 48,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "For understanding generic documents, information like font sizes, column layout, and generally the positioning of words may carry semantic information that is crucial for solving a downstream document intelligence task. Our novel BERTgrid, which is based on Chargrid by Katti et al. (2018), represents a document as a grid of contextualized word piece embedding vectors, thereby making its spatial structure and semantics accessible to the processing neural network. The contextualized embedding vectors are retrieved from a BERT language model. We use BERTgrid in combination with a fully convolutional network on a semantic instance segmentation task for extracting fields from invoices. We demonstrate its performance on tabulated line item and document header field extraction."
            },
            "slug": "BERTgrid:-Contextualized-Embedding-for-2D-Document-Denk-Reisswig",
            "title": {
                "fragments": [],
                "text": "BERTgrid: Contextualized Embedding for 2D Document Representation and Understanding"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "The novel BERTgrid, which is based on Chargrid, represents a document as a grid of contextualized word piece embedding vectors, thereby making its spatial structure and semantics accessible to the processing neural network."
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 2019
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1719068"
                        ],
                        "name": "Anoop R. Katti",
                        "slug": "Anoop-R.-Katti",
                        "structuredName": {
                            "firstName": "Anoop",
                            "lastName": "Katti",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Anoop R. Katti"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9992847"
                        ],
                        "name": "C. Reisswig",
                        "slug": "C.-Reisswig",
                        "structuredName": {
                            "firstName": "Christian",
                            "lastName": "Reisswig",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Reisswig"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39387393"
                        ],
                        "name": "Cordula Guder",
                        "slug": "Cordula-Guder",
                        "structuredName": {
                            "firstName": "Cordula",
                            "lastName": "Guder",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Cordula Guder"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "14334250"
                        ],
                        "name": "Sebastian Brarda",
                        "slug": "Sebastian-Brarda",
                        "structuredName": {
                            "firstName": "Sebastian",
                            "lastName": "Brarda",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sebastian Brarda"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2704747"
                        ],
                        "name": "S. Bickel",
                        "slug": "S.-Bickel",
                        "structuredName": {
                            "firstName": "Steffen",
                            "lastName": "Bickel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Bickel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2216963"
                        ],
                        "name": "J. H\u00f6hne",
                        "slug": "J.-H\u00f6hne",
                        "structuredName": {
                            "firstName": "Johannes",
                            "lastName": "H\u00f6hne",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. H\u00f6hne"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2803968"
                        ],
                        "name": "J. Faddoul",
                        "slug": "J.-Faddoul",
                        "structuredName": {
                            "firstName": "Jean",
                            "lastName": "Faddoul",
                            "middleNames": [
                                "Baptiste"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Faddoul"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 58,
                                "start": 39
                            }
                        ],
                        "text": "This method was used, among others, by Katti et al. (2018); Denk and Reisswig (2019)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 52815006,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "15aae08159856cdbf0ce539357d473a04dcbb7f3",
            "isKey": false,
            "numCitedBy": 100,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce a novel type of text representation that preserves the 2D layout of a document. This is achieved by encoding each document page as a two-dimensional grid of characters. Based on this representation, we present a generic document understanding pipeline for structured documents. This pipeline makes use of a fully convolutional encoder-decoder network that predicts a segmentation mask and bounding boxes. We demonstrate its capabilities on an information extraction task from invoices and show that it significantly outperforms approaches based on sequential text or document images."
            },
            "slug": "Chargrid:-Towards-Understanding-2D-Documents-Katti-Reisswig",
            "title": {
                "fragments": [],
                "text": "Chargrid: Towards Understanding 2D Documents"
            },
            "tldr": {
                "abstractSimilarityScore": 71,
                "text": "A novel type of text representation is introduced that preserves the 2D layout of a document by encoding each document page as a two-dimensional grid of characters and it is shown that it significantly outperforms approaches based on sequential text or document images."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 2018
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2110965354"
                        ],
                        "name": "Xiaojing Liu",
                        "slug": "Xiaojing-Liu",
                        "structuredName": {
                            "firstName": "Xiaojing",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xiaojing Liu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2112256"
                        ],
                        "name": "Feiyu Gao",
                        "slug": "Feiyu-Gao",
                        "structuredName": {
                            "firstName": "Feiyu",
                            "lastName": "Gao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Feiyu Gao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2112207346"
                        ],
                        "name": "Qiong Zhang",
                        "slug": "Qiong-Zhang",
                        "structuredName": {
                            "firstName": "Qiong",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Qiong Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "36530509"
                        ],
                        "name": "Huasha Zhao",
                        "slug": "Huasha-Zhao",
                        "structuredName": {
                            "firstName": "Huasha",
                            "lastName": "Zhao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Huasha Zhao"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 21,
                                "start": 14
                            }
                        ],
                        "text": "Both BERT and RoBERTa were used in their smaller, base variants."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 169,
                                "start": 162
                            }
                        ],
                        "text": "Finally, note that while using the winding embeddings in the Charity dataset improves the results of the plain models, in the NDA dataset they remain similar for RoBERTa and worsen in case of BERT."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 29,
                                "start": 22
                            }
                        ],
                        "text": "Also, models based on RoBERTa surpass those based on BERT, which is not surprising."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 53,
                                "start": 35
                            }
                        ],
                        "text": "Such a method has been employed by Liu et al. (2019a)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 11,
                                "start": 4
                            }
                        ],
                        "text": "The RoBERTa behavior again confirms that the model can effectively utilize the layout features,\nwithout forsaking what it learned during pretraining."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 130,
                                "start": 123
                            }
                        ],
                        "text": "In Table 3, we present the evaluation results achieved on downstream tasks by the best models based on pretrained BERT and RoBERTa, using the context embeddings described in Section 3.3."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 182,
                                "start": 165
                            }
                        ],
                        "text": "In this setting, the task of computing token embeddings is solved by Transformer encoders, such as BERT (Devlin et al., 2019) and its modifications such as RoBERTa (Liu et al., 2019b), or ALBERT (Lan et al., 2019)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 101,
                                "start": 94
                            }
                        ],
                        "text": "As a part of our final experiment, we attempted to suppress the sequential information in the RoBERTa-based model using the winding embeddings, in order to study its ability to completely switch from using positional embeddings to layout embeddings."
                    },
                    "intents": []
                }
            ],
            "corpusId": 85528598,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "04df8c70257b5280b9d303502c9d7ddf946f181b",
            "isKey": true,
            "numCitedBy": 86,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "Visually rich documents (VRDs) are ubiquitous in daily business and life. Examples are purchase receipts, insurance policy documents, custom declaration forms and so on. In VRDs, visual and layout information is critical for document understanding, and texts in such documents cannot be serialized into the one-dimensional sequence without losing information. Classic information extraction models such as BiLSTM-CRF typically operate on text sequences and do not incorporate visual features. In this paper, we introduce a graph convolution based model to combine textual and visual information presented in VRDs. Graph embeddings are trained to summarize the context of a text segment in the document, and further combined with text embeddings for entity extraction. Extensive experiments have been conducted to show that our method outperforms BiLSTM-CRF baselines by significant margins, on two real-world datasets. Additionally, ablation studies are also performed to evaluate the effectiveness of each component of our model."
            },
            "slug": "Graph-Convolution-for-Multimodal-Information-from-Liu-Gao",
            "title": {
                "fragments": [],
                "text": "Graph Convolution for Multimodal Information Extraction from Visually Rich Documents"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This paper introduces a graph convolution based model to combine textual and visual information presented in VRDs and outperforms BiLSTM-CRF baselines by significant margins, on two real-world datasets."
            },
            "venue": {
                "fragments": [],
                "text": "NAACL"
            },
            "year": 2019
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1938475"
                        ],
                        "name": "E. Bart",
                        "slug": "E.-Bart",
                        "structuredName": {
                            "firstName": "Evgeniy",
                            "lastName": "Bart",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Bart"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35126187"
                        ],
                        "name": "Prateek Sarkar",
                        "slug": "Prateek-Sarkar",
                        "structuredName": {
                            "firstName": "Prateek",
                            "lastName": "Sarkar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Prateek Sarkar"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 10185814,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "05f216ed26beede85bdb578f6442fc360ca30e58",
            "isKey": false,
            "numCitedBy": 21,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "Repetition of layout structure is prevalent in document images. In document design, such repetition conveys the underlying logical and functional structure of the data. For example, in invoices, the names, unit prices, quantities and other descriptors of every line item are laid out in a consistent spatial structure. We propose a general method for extracting such repeated structure from documents. After receiving a single example of the structure to be found, the proposed method localizes additional instances of this structure in the same document and in additional documents. A wide variety of perceptually motivated cues (such as alignment and saliency) is used for this purpose. These cues are combined in a probabilistic model, and a novel algorithm for exact inference in this model is proposed and used. We demonstrate that this method can cope with complex instances of repeated structure and generalizes successfully across a wide range of structure variations."
            },
            "slug": "Information-extraction-by-finding-repeated-Bart-Sarkar",
            "title": {
                "fragments": [],
                "text": "Information extraction by finding repeated structure"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This work proposes a general method for extracting repeated structure from documents and demonstrates that this method can cope with complex instances of repeated structure and generalizes successfully across a wide range of structure variations."
            },
            "venue": {
                "fragments": [],
                "text": "DAS '10"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38909097"
                        ],
                        "name": "Alec Radford",
                        "slug": "Alec-Radford",
                        "structuredName": {
                            "firstName": "Alec",
                            "lastName": "Radford",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alec Radford"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144958935"
                        ],
                        "name": "Karthik Narasimhan",
                        "slug": "Karthik-Narasimhan",
                        "structuredName": {
                            "firstName": "Karthik",
                            "lastName": "Narasimhan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Karthik Narasimhan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 28,
                                "start": 13
                            }
                        ],
                        "text": ", 2019), GPT (Radford, 2018), and GPT2 (Radford et al."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 126,
                                "start": 113
                            }
                        ],
                        "text": "Other, non-BERT-derived architectures include Transformer-XL (Dai et al., 2019), XLNet (Yang et al., 2019), GPT (Radford, 2018), and GPT2 (Radford et al., 2019)."
                    },
                    "intents": []
                }
            ],
            "corpusId": 49313245,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cd18800a0fe0b668a1cc19f2ec95b5003d0a5035",
            "isKey": false,
            "numCitedBy": 3533,
            "numCiting": 76,
            "paperAbstract": {
                "fragments": [],
                "text": "Natural language understanding comprises a wide range of diverse tasks such as textual entailment, question answering, semantic similarity assessment, and document classi\ufb01cation. Although large unlabeled text corpora are abundant, labeled data for learning these speci\ufb01c tasks is scarce, making it challenging for discriminatively trained models to perform adequately. We demonstrate that large gains on these tasks can be realized by generative pre-training of a language model on a diverse corpus of unlabeled text, followed by discriminative \ufb01ne-tuning on each speci\ufb01c task. In contrast to previous approaches, we make use of task-aware input transformations during \ufb01ne-tuning to achieve effective transfer while requiring minimal changes to the model architecture. We demonstrate the effectiveness of our approach on a wide range of benchmarks for natural language understanding. Our general task-agnostic model outperforms discriminatively trained models that use architectures speci\ufb01cally crafted for each task, signi\ufb01cantly improving upon the state of the art in 9 out of the 12 tasks studied. For instance, we achieve absolute improvements of 8.9% on commonsense reasoning (Stories Cloze Test), 5.7% on question answering (RACE), and 1.5% on textual entailment (MultiNLI)."
            },
            "slug": "Improving-Language-Understanding-by-Generative-Radford-Narasimhan",
            "title": {
                "fragments": [],
                "text": "Improving Language Understanding by Generative Pre-Training"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "The general task-agnostic model outperforms discriminatively trained models that use architectures speci\ufb01cally crafted for each task, improving upon the state of the art in 9 out of the 12 tasks studied."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2018
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144906624"
                        ],
                        "name": "Alex Wang",
                        "slug": "Alex-Wang",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alex Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50286460"
                        ],
                        "name": "Amanpreet Singh",
                        "slug": "Amanpreet-Singh",
                        "structuredName": {
                            "firstName": "Amanpreet",
                            "lastName": "Singh",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Amanpreet Singh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38614754"
                        ],
                        "name": "Julian Michael",
                        "slug": "Julian-Michael",
                        "structuredName": {
                            "firstName": "Julian",
                            "lastName": "Michael",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Julian Michael"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145783676"
                        ],
                        "name": "Felix Hill",
                        "slug": "Felix-Hill",
                        "structuredName": {
                            "firstName": "Felix",
                            "lastName": "Hill",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Felix Hill"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39455775"
                        ],
                        "name": "Omer Levy",
                        "slug": "Omer-Levy",
                        "structuredName": {
                            "firstName": "Omer",
                            "lastName": "Levy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Omer Levy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3644767"
                        ],
                        "name": "Samuel R. Bowman",
                        "slug": "Samuel-R.-Bowman",
                        "structuredName": {
                            "firstName": "Samuel",
                            "lastName": "Bowman",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Samuel R. Bowman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 285,
                                "start": 266
                            }
                        ],
                        "text": "\u2217 Work in progress; this version of the paper was submitted to ACL2020 on December 10, 2019, and withdrawn on February 17, 2020 \u2020The authors \u0141G, RP, TS, and BT have equally contributed to the paper and are listed in alphabetic order top scores on the GLUE benchmark (Wang et al., 2019)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 290,
                                "start": 273
                            }
                        ],
                        "text": "\u2026achieved\n\u2217 Work in progress; this version of the paper was submitted to ACL2020 on December 10, 2019, and withdrawn on February 17, 2020\n\u2020The authors \u0141G, RP, TS, and BT have equally contributed to the paper and are listed in alphabetic order\ntop scores on the GLUE benchmark (Wang et al., 2019)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5034059,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "93b8da28d006415866bf48f9a6e06b5242129195",
            "isKey": false,
            "numCitedBy": 2634,
            "numCiting": 72,
            "paperAbstract": {
                "fragments": [],
                "text": "Human ability to understand language is general, flexible, and robust. In contrast, most NLU models above the word level are designed for a specific task and struggle with out-of-domain data. If we aspire to develop models with understanding beyond the detection of superficial correspondences between inputs and outputs, then it is critical to develop a unified model that can execute a range of linguistic tasks across different domains. To facilitate research in this direction, we present the General Language Understanding Evaluation (GLUE, gluebenchmark.com): a benchmark of nine diverse NLU tasks, an auxiliary dataset for probing models for understanding of specific linguistic phenomena, and an online platform for evaluating and comparing models. For some benchmark tasks, training data is plentiful, but for others it is limited or does not match the genre of the test set. GLUE thus favors models that can represent linguistic knowledge in a way that facilitates sample-efficient learning and effective knowledge-transfer across tasks. While none of the datasets in GLUE were created from scratch for the benchmark, four of them feature privately-held test data, which is used to ensure that the benchmark is used fairly. We evaluate baselines that use ELMo (Peters et al., 2018), a powerful transfer learning technique, as well as state-of-the-art sentence representation models. The best models still achieve fairly low absolute scores. Analysis with our diagnostic dataset yields similarly weak performance over all phenomena tested, with some exceptions."
            },
            "slug": "GLUE:-A-Multi-Task-Benchmark-and-Analysis-Platform-Wang-Singh",
            "title": {
                "fragments": [],
                "text": "GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A benchmark of nine diverse NLU tasks, an auxiliary dataset for probing models for understanding of specific linguistic phenomena, and an online platform for evaluating and comparing models, which favors models that can represent linguistic knowledge in a way that facilitates sample-efficient learning and effective knowledge-transfer across tasks."
            },
            "venue": {
                "fragments": [],
                "text": "BlackboxNLP@EMNLP"
            },
            "year": 2018
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38909097"
                        ],
                        "name": "Alec Radford",
                        "slug": "Alec-Radford",
                        "structuredName": {
                            "firstName": "Alec",
                            "lastName": "Radford",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alec Radford"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49387725"
                        ],
                        "name": "Jeff Wu",
                        "slug": "Jeff-Wu",
                        "structuredName": {
                            "firstName": "Jeff",
                            "lastName": "Wu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jeff Wu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48422824"
                        ],
                        "name": "Rewon Child",
                        "slug": "Rewon-Child",
                        "structuredName": {
                            "firstName": "Rewon",
                            "lastName": "Child",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Rewon Child"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "150970919"
                        ],
                        "name": "D. Luan",
                        "slug": "D.-Luan",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Luan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Luan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2698777"
                        ],
                        "name": "Dario Amodei",
                        "slug": "Dario-Amodei",
                        "structuredName": {
                            "firstName": "Dario",
                            "lastName": "Amodei",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dario Amodei"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1701686"
                        ],
                        "name": "Ilya Sutskever",
                        "slug": "Ilya-Sutskever",
                        "structuredName": {
                            "firstName": "Ilya",
                            "lastName": "Sutskever",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ilya Sutskever"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 160025533,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9405cc0d6169988371b2755e573cc28650d14dfe",
            "isKey": false,
            "numCitedBy": 6284,
            "numCiting": 75,
            "paperAbstract": {
                "fragments": [],
                "text": "Natural language processing tasks, such as question answering, machine translation, reading comprehension, and summarization, are typically approached with supervised learning on taskspecific datasets. We demonstrate that language models begin to learn these tasks without any explicit supervision when trained on a new dataset of millions of webpages called WebText. When conditioned on a document plus questions, the answers generated by the language model reach 55 F1 on the CoQA dataset matching or exceeding the performance of 3 out of 4 baseline systems without using the 127,000+ training examples. The capacity of the language model is essential to the success of zero-shot task transfer and increasing it improves performance in a log-linear fashion across tasks. Our largest model, GPT-2, is a 1.5B parameter Transformer that achieves state of the art results on 7 out of 8 tested language modeling datasets in a zero-shot setting but still underfits WebText. Samples from the model reflect these improvements and contain coherent paragraphs of text. These findings suggest a promising path towards building language processing systems which learn to perform tasks from their naturally occurring demonstrations."
            },
            "slug": "Language-Models-are-Unsupervised-Multitask-Learners-Radford-Wu",
            "title": {
                "fragments": [],
                "text": "Language Models are Unsupervised Multitask Learners"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "It is demonstrated that language models begin to learn these tasks without any explicit supervision when trained on a new dataset of millions of webpages called WebText, suggesting a promising path towards building language processing systems which learn to perform tasks from their naturally occurring demonstrations."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2019
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1778757"
                        ],
                        "name": "Eric Medvet",
                        "slug": "Eric-Medvet",
                        "structuredName": {
                            "firstName": "Eric",
                            "lastName": "Medvet",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Eric Medvet"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39295971"
                        ],
                        "name": "Alberto Bartoli",
                        "slug": "Alberto-Bartoli",
                        "structuredName": {
                            "firstName": "Alberto",
                            "lastName": "Bartoli",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alberto Bartoli"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1770449"
                        ],
                        "name": "G. Davanzo",
                        "slug": "G.-Davanzo",
                        "structuredName": {
                            "firstName": "Giorgio",
                            "lastName": "Davanzo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Davanzo"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 22854184,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8f4e0912f9eb1fd2f87646906dfbf2deabc4b875",
            "isKey": false,
            "numCitedBy": 39,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose an approach for information extraction for multi-page printed document understanding. The approach is designed for scenarios in which the set of possible document classes, i.e., documents sharing similar content and layout, is large and may evolve over time. Describing a new class is a very simple task: the operator merely provides a few samples and then, by means of a GUI, clicks on the OCR-generated blocks of a document containing the information to be extracted. Our approach is based on probability: we derived a general form for the probability that a sequence of blocks contains the searched information. We estimate the parameters for a new class by applying the maximum likelihood method to the samples of the class. All these parameters depend only on block properties that can be extracted automatically from the operator actions on the GUI. Processing a document of a given class consists in finding the sequence of blocks, which maximizes the corresponding probability for that class. We evaluated experimentally our proposal using 807 multi-page printed documents of different domains (invoices, patents, data-sheets), obtaining very good results\u2014e.g., a success rate often greater than 90% even for classes with just two samples."
            },
            "slug": "A-probabilistic-approach-to-printed-document-Medvet-Bartoli",
            "title": {
                "fragments": [],
                "text": "A probabilistic approach to printed document understanding"
            },
            "tldr": {
                "abstractSimilarityScore": 63,
                "text": "The approach is designed for scenarios in which the set of possible document classes, i.e., documents sharing similar content and layout, is large and may evolve over time and derived a general form for the probability that a sequence of blocks contains the searched information."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal on Document Analysis and Recognition (IJDAR)"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143823474"
                        ],
                        "name": "Mar\u00e7al Rusi\u00f1ol",
                        "slug": "Mar\u00e7al-Rusi\u00f1ol",
                        "structuredName": {
                            "firstName": "Mar\u00e7al",
                            "lastName": "Rusi\u00f1ol",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mar\u00e7al Rusi\u00f1ol"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1406403963"
                        ],
                        "name": "Tayeb Benkhelfallah",
                        "slug": "Tayeb-Benkhelfallah",
                        "structuredName": {
                            "firstName": "Tayeb",
                            "lastName": "Benkhelfallah",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tayeb Benkhelfallah"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1401920887"
                        ],
                        "name": "V. P. d'Andecy",
                        "slug": "V.-P.-d'Andecy",
                        "structuredName": {
                            "firstName": "Vincent",
                            "lastName": "d'Andecy",
                            "middleNames": [
                                "Poulain"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. P. d'Andecy"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 12155580,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3170d280095b2198570073eaa068d6b2946334e3",
            "isKey": false,
            "numCitedBy": 41,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we present an incremental framework aimed at extracting field information from administrative document images in the context of a Digital Mail-room scenario. Given a single training sample in which the user has marked which fields have to be extracted from a particular document class, a document model representing structural relationships among words is built. This model is incrementally refined as the system processes more and more documents from the same class. A reformulation of the tf-idf statistic scheme allows to adjust the importance weights of the structural relationships among words. We report in the experimental section our results obtained with a large dataset of real invoices."
            },
            "slug": "Field-Extraction-from-Administrative-Documents-by-Rusi\u00f1ol-Benkhelfallah",
            "title": {
                "fragments": [],
                "text": "Field Extraction from Administrative Documents by Incremental Structural Templates"
            },
            "tldr": {
                "abstractSimilarityScore": 77,
                "text": "An incremental framework aimed at extracting field information from administrative document images in the context of a Digital Mail-room scenario is presented and results obtained with a large dataset of real invoices are reported."
            },
            "venue": {
                "fragments": [],
                "text": "2013 12th International Conference on Document Analysis and Recognition"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39172707"
                        ],
                        "name": "Jacob Devlin",
                        "slug": "Jacob-Devlin",
                        "structuredName": {
                            "firstName": "Jacob",
                            "lastName": "Devlin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jacob Devlin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1744179"
                        ],
                        "name": "Ming-Wei Chang",
                        "slug": "Ming-Wei-Chang",
                        "structuredName": {
                            "firstName": "Ming-Wei",
                            "lastName": "Chang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ming-Wei Chang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2544107"
                        ],
                        "name": "Kenton Lee",
                        "slug": "Kenton-Lee",
                        "structuredName": {
                            "firstName": "Kenton",
                            "lastName": "Lee",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kenton Lee"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3259253"
                        ],
                        "name": "Kristina Toutanova",
                        "slug": "Kristina-Toutanova",
                        "structuredName": {
                            "firstName": "Kristina",
                            "lastName": "Toutanova",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kristina Toutanova"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 93,
                                "start": 73
                            }
                        ],
                        "text": "We employed a learning rate scheduling method similar to the one used by Devlin et al. (2019), increasing the learning rate linearly for the warm-up period of 10% of the training time and then decreasing it linearly to 0."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 124,
                                "start": 105
                            }
                        ],
                        "text": "In this setting, the task of computing token embeddings is solved by Transformer encoders, such as BERT (Devlin et al., 2019) and its modifications such as RoBERTa (Liu et al., 2019b), or ALBERT (Lan et al., 2019)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 125,
                                "start": 104
                            }
                        ],
                        "text": "In this setting, the task of computing token embeddings is solved by Transformer encoders, such as BERT (Devlin et al., 2019) and its modifications such as RoBERTa (Liu et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 52967399,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "df2b0e26d0599ce3e70df8a9da02e51594e0e992",
            "isKey": false,
            "numCitedBy": 33744,
            "numCiting": 60,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models (Peters et al., 2018a; Radford et al., 2018), BERT is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications. BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5 (7.7 point absolute improvement), MultiNLI accuracy to 86.7% (4.6% absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement)."
            },
            "slug": "BERT:-Pre-training-of-Deep-Bidirectional-for-Devlin-Chang",
            "title": {
                "fragments": [],
                "text": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"
            },
            "tldr": {
                "abstractSimilarityScore": 52,
                "text": "A new language representation model, BERT, designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers, which can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks."
            },
            "venue": {
                "fragments": [],
                "text": "NAACL"
            },
            "year": 2019
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35126865"
                        ],
                        "name": "Yasuto Ishitani",
                        "slug": "Yasuto-Ishitani",
                        "structuredName": {
                            "firstName": "Yasuto",
                            "lastName": "Ishitani",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yasuto Ishitani"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14249980,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "84d66383c923ace02113bdf0487368555ef3b47a",
            "isKey": false,
            "numCitedBy": 9,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "When a printed document is to be input to a computer system, the document must be converted to a computer-readable format, e.g., ASCII, PDF, RTF, CSV, or SGML/XML/HTML-tagged data. Then, the information required has to be recognized in documents and stored in the required format. In the natural language understanding field, the extraction of words from documents such as a person\u2019s name, place names, or an organization\u2019s name and their relationship, is called information extraction. In general, it is difficult to extract required keywords and their relationship from printed documents accurately, because such documents have unknown words such as proper nouns, compound words, or incorrect words due to OCR errors. Furthermore, it is necessary to solve word segmentation problems for Japanese documents, because the boundaries between words are ambiguous. In this paper, the author proposes a new document analysis method to extract required keywords/fields and their logical relationship automatically from various printed documents using models which define each category of document. The proposed system can handle not only documents in common use but also forms which are defined by the horizontal and vertical ruled lines. In the next section, method details will be discussed. Following that, experimental results that demonstrate the effectiveness of the proposed method will be presented."
            },
            "slug": "Model-Based-Information-Extraction-and-its-for-Ishitani",
            "title": {
                "fragments": [],
                "text": "Model-Based Information Extraction and its Applications for Document Images"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "A new document analysis method to extract required keywords/fields and their logical relationship automatically from various printed documents using models which define each category of document is proposed."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2362534"
                        ],
                        "name": "Zhenzhong Lan",
                        "slug": "Zhenzhong-Lan",
                        "structuredName": {
                            "firstName": "Zhenzhong",
                            "lastName": "Lan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zhenzhong Lan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46221498"
                        ],
                        "name": "Mingda Chen",
                        "slug": "Mingda-Chen",
                        "structuredName": {
                            "firstName": "Mingda",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mingda Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7685850"
                        ],
                        "name": "Sebastian Goodman",
                        "slug": "Sebastian-Goodman",
                        "structuredName": {
                            "firstName": "Sebastian",
                            "lastName": "Goodman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sebastian Goodman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1700980"
                        ],
                        "name": "Kevin Gimpel",
                        "slug": "Kevin-Gimpel",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Gimpel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kevin Gimpel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48267618"
                        ],
                        "name": "Piyush Sharma",
                        "slug": "Piyush-Sharma",
                        "structuredName": {
                            "firstName": "Piyush",
                            "lastName": "Sharma",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Piyush Sharma"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1737285"
                        ],
                        "name": "Radu Soricut",
                        "slug": "Radu-Soricut",
                        "structuredName": {
                            "firstName": "Radu",
                            "lastName": "Soricut",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Radu Soricut"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 212,
                                "start": 196
                            }
                        ],
                        "text": "In this setting, the task of computing token embeddings is solved by Transformer encoders, such as BERT (Devlin et al., 2019) and its modifications such as RoBERTa (Liu et al., 2019b), or ALBERT (Lan et al., 2019)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 202888986,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7a064df1aeada7e69e5173f7d4c8606f4470365b",
            "isKey": false,
            "numCitedBy": 2706,
            "numCiting": 83,
            "paperAbstract": {
                "fragments": [],
                "text": "Increasing model size when pretraining natural language representations often results in improved performance on downstream tasks. However, at some point further model increases become harder due to GPU/TPU memory limitations and longer training times. To address these problems, we present two parameter-reduction techniques to lower memory consumption and increase the training speed of BERT. Comprehensive empirical evidence shows that our proposed methods lead to models that scale much better compared to the original BERT. We also use a self-supervised loss that focuses on modeling inter-sentence coherence, and show it consistently helps downstream tasks with multi-sentence inputs. As a result, our best model establishes new state-of-the-art results on the GLUE, RACE, and \\squad benchmarks while having fewer parameters compared to BERT-large. The code and the pretrained models are available at this https URL."
            },
            "slug": "ALBERT:-A-Lite-BERT-for-Self-supervised-Learning-of-Lan-Chen",
            "title": {
                "fragments": [],
                "text": "ALBERT: A Lite BERT for Self-supervised Learning of Language Representations"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This work presents two parameter-reduction techniques to lower memory consumption and increase the training speed of BERT, and uses a self-supervised loss that focuses on modeling inter-sentence coherence."
            },
            "venue": {
                "fragments": [],
                "text": "ICLR"
            },
            "year": 2020
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153515321"
                        ],
                        "name": "Wasifur Rahman",
                        "slug": "Wasifur-Rahman",
                        "structuredName": {
                            "firstName": "Wasifur",
                            "lastName": "Rahman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wasifur Rahman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2811524"
                        ],
                        "name": "M. Hasan",
                        "slug": "M.-Hasan",
                        "structuredName": {
                            "firstName": "M.",
                            "lastName": "Hasan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Hasan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144802290"
                        ],
                        "name": "Amir Zadeh",
                        "slug": "Amir-Zadeh",
                        "structuredName": {
                            "firstName": "Amir",
                            "lastName": "Zadeh",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Amir Zadeh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49933077"
                        ],
                        "name": "Louis-Philippe Morency",
                        "slug": "Louis-Philippe-Morency",
                        "structuredName": {
                            "firstName": "Louis-Philippe",
                            "lastName": "Morency",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Louis-Philippe Morency"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144619896"
                        ],
                        "name": "Ehsan Hoque",
                        "slug": "Ehsan-Hoque",
                        "structuredName": {
                            "firstName": "Ehsan",
                            "lastName": "Hoque",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ehsan Hoque"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 75,
                                "start": 55
                            }
                        ],
                        "text": "What makes our work completely different is that while Rahman et al. (2019) consider texts accompanied by audio-visual signal, we apply the idea of extending input embeddings to additional features extracted from formatted texts."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 102,
                                "start": 82
                            }
                        ],
                        "text": "We decided to take yet another approach, similar to the one recently also used by Rahman et al. (2019), which is to inject the layout information into a modified variant of an already pretrained BERT instance, and fine-tune the extended model on datasets containing additional layout features."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 201058363,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "252879b227f494df00d465602342f6c38effd27b",
            "isKey": false,
            "numCitedBy": 22,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "Multimodal language analysis is an emerging research area in natural language processing that models language in a multimodal manner. It aims to understand language from the modalities of text, visual, and acoustic by modeling both intra-modal and cross-modal interactions. BERT (Bidirectional Encoder Representations from Transformers) provides strong contextual language representations after training on large-scale unlabeled corpora. Fine-tuning the vanilla BERT model has shown promising results in building state-ofthe-art models for diverse NLP tasks like question answering and language inference. However, fine-tuning BERT in the presence of information from other modalities remains an open research problem. In this paper, we inject multimodal information within the input space of BERT network for modeling multimodal language. The proposed injection method allows BERT to reach a new state of the art of 84.38% binary accuracy on CMU-MOSI dataset (multimodal sentiment analysis) with a gap of 5.98 percent to the previous state of the art and 1.02 percent to the text-only BERT."
            },
            "slug": "M-BERT:-Injecting-Multimodal-Information-in-the-Rahman-Hasan",
            "title": {
                "fragments": [],
                "text": "M-BERT: Injecting Multimodal Information in the BERT Structure"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "The proposed injection method allows BERT to reach a new state of the art of 84.38% binary accuracy on CMU-MOSI dataset (multimodal sentiment analysis) with a gap of 5.98 percent compared to the previous state-of- the art and 1.02 percent to the text-only BERT."
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 2019
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3422912"
                        ],
                        "name": "Zihang Dai",
                        "slug": "Zihang-Dai",
                        "structuredName": {
                            "firstName": "Zihang",
                            "lastName": "Dai",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zihang Dai"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2109512754"
                        ],
                        "name": "Zhilin Yang",
                        "slug": "Zhilin-Yang",
                        "structuredName": {
                            "firstName": "Zhilin",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zhilin Yang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35729970"
                        ],
                        "name": "Yiming Yang",
                        "slug": "Yiming-Yang",
                        "structuredName": {
                            "firstName": "Yiming",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yiming Yang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143712374"
                        ],
                        "name": "J. Carbonell",
                        "slug": "J.-Carbonell",
                        "structuredName": {
                            "firstName": "Jaime",
                            "lastName": "Carbonell",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Carbonell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2827616"
                        ],
                        "name": "Quoc V. Le",
                        "slug": "Quoc-V.-Le",
                        "structuredName": {
                            "firstName": "Quoc",
                            "lastName": "Le",
                            "middleNames": [
                                "V."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Quoc V. Le"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145124475"
                        ],
                        "name": "R. Salakhutdinov",
                        "slug": "R.-Salakhutdinov",
                        "structuredName": {
                            "firstName": "Ruslan",
                            "lastName": "Salakhutdinov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Salakhutdinov"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 79,
                                "start": 61
                            }
                        ],
                        "text": "Other, non-BERT-derived architectures include Transformer-XL (Dai et al., 2019), XLNet (Yang et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 78,
                                "start": 62
                            }
                        ],
                        "text": "Other, non-BERT-derived architectures include Transformer-XL (Dai et al., 2019), XLNet (Yang et al., 2019), GPT (Radford, 2018), and GPT2 (Radford et al., 2019)."
                    },
                    "intents": []
                }
            ],
            "corpusId": 57759363,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c4744a7c2bb298e4a52289a1e085c71cc3d37bc6",
            "isKey": false,
            "numCitedBy": 1771,
            "numCiting": 68,
            "paperAbstract": {
                "fragments": [],
                "text": "Transformers have a potential of learning longer-term dependency, but are limited by a fixed-length context in the setting of language modeling. We propose a novel neural architecture Transformer-XL that enables learning dependency beyond a fixed length without disrupting temporal coherence. It consists of a segment-level recurrence mechanism and a novel positional encoding scheme. Our method not only enables capturing longer-term dependency, but also resolves the context fragmentation problem. As a result, Transformer-XL learns dependency that is 80% longer than RNNs and 450% longer than vanilla Transformers, achieves better performance on both short and long sequences, and is up to 1,800+ times faster than vanilla Transformers during evaluation. Notably, we improve the state-of-the-art results of bpc/perplexity to 0.99 on enwiki8, 1.08 on text8, 18.3 on WikiText-103, 21.8 on One Billion Word, and 54.5 on Penn Treebank (without finetuning). When trained only on WikiText-103, Transformer-XL manages to generate reasonably coherent, novel text articles with thousands of tokens. Our code, pretrained models, and hyperparameters are available in both Tensorflow and PyTorch."
            },
            "slug": "Transformer-XL:-Attentive-Language-Models-beyond-a-Dai-Yang",
            "title": {
                "fragments": [],
                "text": "Transformer-XL: Attentive Language Models beyond a Fixed-Length Context"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "This work proposes a novel neural architecture Transformer-XL that enables learning dependency beyond a fixed length without disrupting temporal coherence, which consists of a segment-level recurrence mechanism and a novel positional encoding scheme."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2019
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2109512754"
                        ],
                        "name": "Zhilin Yang",
                        "slug": "Zhilin-Yang",
                        "structuredName": {
                            "firstName": "Zhilin",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zhilin Yang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3422912"
                        ],
                        "name": "Zihang Dai",
                        "slug": "Zihang-Dai",
                        "structuredName": {
                            "firstName": "Zihang",
                            "lastName": "Dai",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zihang Dai"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35729970"
                        ],
                        "name": "Yiming Yang",
                        "slug": "Yiming-Yang",
                        "structuredName": {
                            "firstName": "Yiming",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yiming Yang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143712374"
                        ],
                        "name": "J. Carbonell",
                        "slug": "J.-Carbonell",
                        "structuredName": {
                            "firstName": "Jaime",
                            "lastName": "Carbonell",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Carbonell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145124475"
                        ],
                        "name": "R. Salakhutdinov",
                        "slug": "R.-Salakhutdinov",
                        "structuredName": {
                            "firstName": "Ruslan",
                            "lastName": "Salakhutdinov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Salakhutdinov"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2827616"
                        ],
                        "name": "Quoc V. Le",
                        "slug": "Quoc-V.-Le",
                        "structuredName": {
                            "firstName": "Quoc",
                            "lastName": "Le",
                            "middleNames": [
                                "V."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Quoc V. Le"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 34,
                                "start": 15
                            }
                        ],
                        "text": ", 2019), XLNet (Yang et al., 2019), GPT (Radford, 2018), and GPT2 (Radford et al."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 105,
                                "start": 88
                            }
                        ],
                        "text": "Other, non-BERT-derived architectures include Transformer-XL (Dai et al., 2019), XLNet (Yang et al., 2019), GPT (Radford, 2018), and GPT2 (Radford et al., 2019)."
                    },
                    "intents": []
                }
            ],
            "corpusId": 195069387,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e0c6abdbdecf04ffac65c440da77fb9d66bb474c",
            "isKey": false,
            "numCitedBy": 4226,
            "numCiting": 48,
            "paperAbstract": {
                "fragments": [],
                "text": "With the capability of modeling bidirectional contexts, denoising autoencoding based pretraining like BERT achieves better performance than pretraining approaches based on autoregressive language modeling. However, relying on corrupting the input with masks, BERT neglects dependency between the masked positions and suffers from a pretrain-finetune discrepancy. In light of these pros and cons, we propose XLNet, a generalized autoregressive pretraining method that (1) enables learning bidirectional contexts by maximizing the expected likelihood over all permutations of the factorization order and (2) overcomes the limitations of BERT thanks to its autoregressive formulation. Furthermore, XLNet integrates ideas from Transformer-XL, the state-of-the-art autoregressive model, into pretraining. Empirically, under comparable experiment settings, XLNet outperforms BERT on 20 tasks, often by a large margin, including question answering, natural language inference, sentiment analysis, and document ranking."
            },
            "slug": "XLNet:-Generalized-Autoregressive-Pretraining-for-Yang-Dai",
            "title": {
                "fragments": [],
                "text": "XLNet: Generalized Autoregressive Pretraining for Language Understanding"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "XLNet is proposed, a generalized autoregressive pretraining method that enables learning bidirectional contexts by maximizing the expected likelihood over all permutations of the factorization order and overcomes the limitations of BERT thanks to its autore progressive formulation."
            },
            "venue": {
                "fragments": [],
                "text": "NeurIPS"
            },
            "year": 2019
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1768769"
                        ],
                        "name": "F. Cesarini",
                        "slug": "F.-Cesarini",
                        "structuredName": {
                            "firstName": "Francesca",
                            "lastName": "Cesarini",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Cesarini"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751770"
                        ],
                        "name": "E. Francesconi",
                        "slug": "E.-Francesconi",
                        "structuredName": {
                            "firstName": "Enrico",
                            "lastName": "Francesconi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Francesconi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145467467"
                        ],
                        "name": "M. Gori",
                        "slug": "M.-Gori",
                        "structuredName": {
                            "firstName": "Marco",
                            "lastName": "Gori",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Gori"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2540925"
                        ],
                        "name": "G. Soda",
                        "slug": "G.-Soda",
                        "structuredName": {
                            "firstName": "Giovanni",
                            "lastName": "Soda",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Soda"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 10190924,
            "fieldsOfStudy": [
                "Computer Science",
                "Sociology"
            ],
            "id": "b0175f2602256e71c4f40b96b6997422db38f39c",
            "isKey": false,
            "numCitedBy": 48,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract.In this paper a system for processing documents that can be grouped into classes is illustrated. We have considered invoices as a case-study. The system is divided into three phases: document analysis, classification, and understanding. We illustrate the analysis and understanding phases. The system is based on knowledge constructed by means of a learning procedure. The experimental results demonstrate the reliability of our document analysis and understanding procedures. They also present evidence that it is possible to use a small learning set of invoices to obtain reliable knowledge for the understanding phase."
            },
            "slug": "Analysis-and-understanding-of-multi-class-invoices-Cesarini-Francesconi",
            "title": {
                "fragments": [],
                "text": "Analysis and understanding of multi-class invoices"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "The experimental results demonstrate the reliability of the document analysis and understanding procedures and present evidence that it is possible to use a small learning set of invoices to obtain reliable knowledge for the understanding phase."
            },
            "venue": {
                "fragments": [],
                "text": "Document Analysis and Recognition"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2860829"
                        ],
                        "name": "H. Hamza",
                        "slug": "H.-Hamza",
                        "structuredName": {
                            "firstName": "Hatem",
                            "lastName": "Hamza",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Hamza"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2448729"
                        ],
                        "name": "Y. Bela\u00efd",
                        "slug": "Y.-Bela\u00efd",
                        "structuredName": {
                            "firstName": "Yolande",
                            "lastName": "Bela\u00efd",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Bela\u00efd"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2128453"
                        ],
                        "name": "A. Bela\u00efd",
                        "slug": "A.-Bela\u00efd",
                        "structuredName": {
                            "firstName": "Abdel",
                            "lastName": "Bela\u00efd",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Bela\u00efd"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1759420"
                        ],
                        "name": "B. Chaudhuri",
                        "slug": "B.-Chaudhuri",
                        "structuredName": {
                            "firstName": "Bidyut.",
                            "lastName": "Chaudhuri",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Chaudhuri"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14788847,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bfb362c21400dfd1fa9c54b362e80927f2b03d7e",
            "isKey": false,
            "numCitedBy": 20,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents an end-to-end administrative document analysis system. This system uses case-based reasoning in order to process documents from known and unknown classes. For each document, the system retrieves the nearest processing experience in order to analyze and interpret the current document. When a complete analysis is done, this document needs to be added to the document database. This requires an incremental learning process in order to take into account every new information, without losing the previous learnt ones. For this purpose, we proposed an improved version of an already existing neural network called Incremental Growing Neural Gas. Applied on documents learning and classification, this neural network reaches a recognition rate of 97.63%."
            },
            "slug": "An-End-to-End-Administrative-Document-Analysis-Hamza-Bela\u00efd",
            "title": {
                "fragments": [],
                "text": "An End-to-End Administrative Document Analysis System"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "An improved version of an already existing neural network called Incremental Growing Neural Gas is proposed, Applied on documents learning and classification, this neural network reaches a recognition rate of 97.63%."
            },
            "venue": {
                "fragments": [],
                "text": "2008 The Eighth IAPR International Workshop on Document Analysis Systems"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40348417"
                        ],
                        "name": "Ashish Vaswani",
                        "slug": "Ashish-Vaswani",
                        "structuredName": {
                            "firstName": "Ashish",
                            "lastName": "Vaswani",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ashish Vaswani"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1846258"
                        ],
                        "name": "Noam M. Shazeer",
                        "slug": "Noam-M.-Shazeer",
                        "structuredName": {
                            "firstName": "Noam",
                            "lastName": "Shazeer",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Noam M. Shazeer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3877127"
                        ],
                        "name": "Niki Parmar",
                        "slug": "Niki-Parmar",
                        "structuredName": {
                            "firstName": "Niki",
                            "lastName": "Parmar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Niki Parmar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39328010"
                        ],
                        "name": "Jakob Uszkoreit",
                        "slug": "Jakob-Uszkoreit",
                        "structuredName": {
                            "firstName": "Jakob",
                            "lastName": "Uszkoreit",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jakob Uszkoreit"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145024664"
                        ],
                        "name": "Llion Jones",
                        "slug": "Llion-Jones",
                        "structuredName": {
                            "firstName": "Llion",
                            "lastName": "Jones",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Llion Jones"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "19177000"
                        ],
                        "name": "Aidan N. Gomez",
                        "slug": "Aidan-N.-Gomez",
                        "structuredName": {
                            "firstName": "Aidan",
                            "lastName": "Gomez",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Aidan N. Gomez"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40527594"
                        ],
                        "name": "Lukasz Kaiser",
                        "slug": "Lukasz-Kaiser",
                        "structuredName": {
                            "firstName": "Lukasz",
                            "lastName": "Kaiser",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lukasz Kaiser"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3443442"
                        ],
                        "name": "Illia Polosukhin",
                        "slug": "Illia-Polosukhin",
                        "structuredName": {
                            "firstName": "Illia",
                            "lastName": "Polosukhin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Illia Polosukhin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 221,
                                "start": 201
                            }
                        ],
                        "text": "In many Natural Language Processing (NLP) related problems, this linear perspective is sufficient and has led to significant breakthroughs, such as the introduction of Transformer neural architecture (Vaswani et al., 2017)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 24,
                                "start": 3
                            }
                        ],
                        "text": "In Vaswani et al. (2017), the positional embeddings were defined as\npij = F \u03b8 j (i) (5)\nwith \u03b8r being a geometric progression interpolating between 1 and some big number M ."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 13756489,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "204e3073870fae3d05bcbc2f6a8e263d9b72e776",
            "isKey": false,
            "numCitedBy": 35148,
            "numCiting": 44,
            "paperAbstract": {
                "fragments": [],
                "text": "The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-to-German translation task, improving over the existing best results, including ensembles by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data."
            },
            "slug": "Attention-is-All-you-Need-Vaswani-Shazeer",
            "title": {
                "fragments": [],
                "text": "Attention is All you Need"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely is proposed, which generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3081982"
                        ],
                        "name": "Claudio Antonio Peanho",
                        "slug": "Claudio-Antonio-Peanho",
                        "structuredName": {
                            "firstName": "Claudio",
                            "lastName": "Peanho",
                            "middleNames": [
                                "Antonio"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Claudio Antonio Peanho"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3253557"
                        ],
                        "name": "Henrique Stagni",
                        "slug": "Henrique-Stagni",
                        "structuredName": {
                            "firstName": "Henrique",
                            "lastName": "Stagni",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Henrique Stagni"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143813484"
                        ],
                        "name": "F. S. C. D. Silva",
                        "slug": "F.-S.-C.-D.-Silva",
                        "structuredName": {
                            "firstName": "Fl\u00e1vio",
                            "lastName": "Silva",
                            "middleNames": [
                                "S.",
                                "Corr\u00eaa",
                                "da"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. S. C. D. Silva"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 18717919,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8fc797448c1f07fa37fea36776cd8a3def404028",
            "isKey": false,
            "numCitedBy": 24,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "Even though the digital processing of documents is increasingly widespread in industry, printed documents are still largely in use. In order to process electronically the contents of printed documents, information must be extracted from digital images of documents. When dealing with complex documents, in which the contents of different regions and fields can be highly heterogeneous with respect to layout, printing quality and the utilization of fonts and typing standards, the reconstruction of the contents of documents from digital images can be a difficult problem. In the present article we present an efficient solution for this problem, in which the semantic contents of fields in a complex document are extracted from a digital image."
            },
            "slug": "Semantic-information-extraction-from-images-of-Peanho-Stagni",
            "title": {
                "fragments": [],
                "text": "Semantic information extraction from images of complex documents"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The present article presents an efficient solution for this problem, in which the semantic contents of fields in a complex document are extracted from a digital image."
            },
            "venue": {
                "fragments": [],
                "text": "Applied Intelligence"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34939798"
                        ],
                        "name": "Adam W. Harley",
                        "slug": "Adam-W.-Harley",
                        "structuredName": {
                            "firstName": "Adam",
                            "lastName": "Harley",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Adam W. Harley"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2079687415"
                        ],
                        "name": "Alex Ufkes",
                        "slug": "Alex-Ufkes",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Ufkes",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alex Ufkes"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3150825"
                        ],
                        "name": "K. Derpanis",
                        "slug": "K.-Derpanis",
                        "structuredName": {
                            "firstName": "Konstantinos",
                            "lastName": "Derpanis",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Derpanis"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 111,
                                "start": 92
                            }
                        ],
                        "text": "RVL-CDIP The Ryerson Vision Lab Complex Document Information Processing (RVL-CDIP) dataset (Harley et al., 2019) consists of 400k scanned pages of documents of various kinds, including letters, forms, invoices, advertisements, scientific reports, and many others."
                    },
                    "intents": []
                }
            ],
            "corpusId": 2760893,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bd86b4b551b9d3fb498f62008b037e7599365018",
            "isKey": false,
            "numCitedBy": 174,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a new state-of-the-art for document image classification and retrieval, using features learned by deep convolutional neural networks (CNNs). In object and scene analysis, deep neural nets are capable of learning a hierarchical chain of abstraction from pixel inputs to concise and descriptive representations. The current work explores this capacity in the realm of document analysis, and confirms that this representation strategy is superior to a variety of popular handcrafted alternatives. Extensive experiments show that (i) features extracted from CNNs are robust to compression, (ii) CNNs trained on non-document images transfer well to document analysis tasks, and (iii) enforcing region-specific feature-learning is unnecessary given sufficient training data. This work also makes available a new labelled subset of the IIT-CDIP collection, containing 400,000 document images across 16 categories."
            },
            "slug": "Evaluation-of-deep-convolutional-nets-for-document-Harley-Ufkes",
            "title": {
                "fragments": [],
                "text": "Evaluation of deep convolutional nets for document image classification and retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 69,
                "text": "A new state-of-the-art for document image classification and retrieval, using features learned by deep convolutional neural networks (CNNs), and makes available a new labelled subset of the IIT-CDIP collection, containing 400,000 document images across 16 categories."
            },
            "venue": {
                "fragments": [],
                "text": "2015 13th International Conference on Document Analysis and Recognition (ICDAR)"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "11323179"
                        ],
                        "name": "Yinhan Liu",
                        "slug": "Yinhan-Liu",
                        "structuredName": {
                            "firstName": "Yinhan",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yinhan Liu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40511414"
                        ],
                        "name": "Myle Ott",
                        "slug": "Myle-Ott",
                        "structuredName": {
                            "firstName": "Myle",
                            "lastName": "Ott",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Myle Ott"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39589154"
                        ],
                        "name": "Naman Goyal",
                        "slug": "Naman-Goyal",
                        "structuredName": {
                            "firstName": "Naman",
                            "lastName": "Goyal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Naman Goyal"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3048577"
                        ],
                        "name": "Jingfei Du",
                        "slug": "Jingfei-Du",
                        "structuredName": {
                            "firstName": "Jingfei",
                            "lastName": "Du",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jingfei Du"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144863691"
                        ],
                        "name": "Mandar Joshi",
                        "slug": "Mandar-Joshi",
                        "structuredName": {
                            "firstName": "Mandar",
                            "lastName": "Joshi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mandar Joshi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50536468"
                        ],
                        "name": "Danqi Chen",
                        "slug": "Danqi-Chen",
                        "structuredName": {
                            "firstName": "Danqi",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Danqi Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39455775"
                        ],
                        "name": "Omer Levy",
                        "slug": "Omer-Levy",
                        "structuredName": {
                            "firstName": "Omer",
                            "lastName": "Levy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Omer Levy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35084211"
                        ],
                        "name": "M. Lewis",
                        "slug": "M.-Lewis",
                        "structuredName": {
                            "firstName": "Mike",
                            "lastName": "Lewis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Lewis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1982950"
                        ],
                        "name": "Luke Zettlemoyer",
                        "slug": "Luke-Zettlemoyer",
                        "structuredName": {
                            "firstName": "Luke",
                            "lastName": "Zettlemoyer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Luke Zettlemoyer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1759422"
                        ],
                        "name": "Veselin Stoyanov",
                        "slug": "Veselin-Stoyanov",
                        "structuredName": {
                            "firstName": "Veselin",
                            "lastName": "Stoyanov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Veselin Stoyanov"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 21,
                                "start": 14
                            }
                        ],
                        "text": "Both BERT and RoBERTa were used in their smaller, base variants."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 169,
                                "start": 162
                            }
                        ],
                        "text": "Finally, note that while using the winding embeddings in the Charity dataset improves the results of the plain models, in the NDA dataset they remain similar for RoBERTa and worsen in case of BERT."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 29,
                                "start": 22
                            }
                        ],
                        "text": "Also, models based on RoBERTa surpass those based on BERT, which is not surprising."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 53,
                                "start": 35
                            }
                        ],
                        "text": "Such a method has been employed by Liu et al. (2019a)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 11,
                                "start": 4
                            }
                        ],
                        "text": "The RoBERTa behavior again confirms that the model can effectively utilize the layout features,\nwithout forsaking what it learned during pretraining."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 130,
                                "start": 123
                            }
                        ],
                        "text": "In Table 3, we present the evaluation results achieved on downstream tasks by the best models based on pretrained BERT and RoBERTa, using the context embeddings described in Section 3.3."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 182,
                                "start": 165
                            }
                        ],
                        "text": "In this setting, the task of computing token embeddings is solved by Transformer encoders, such as BERT (Devlin et al., 2019) and its modifications such as RoBERTa (Liu et al., 2019b), or ALBERT (Lan et al., 2019)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 101,
                                "start": 94
                            }
                        ],
                        "text": "As a part of our final experiment, we attempted to suppress the sequential information in the RoBERTa-based model using the winding embeddings, in order to study its ability to completely switch from using positional embeddings to layout embeddings."
                    },
                    "intents": []
                }
            ],
            "corpusId": 198953378,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "077f8329a7b6fa3b7c877a57b81eb6c18b5f87de",
            "isKey": true,
            "numCitedBy": 7266,
            "numCiting": 58,
            "paperAbstract": {
                "fragments": [],
                "text": "Language model pretraining has led to significant performance gains but careful comparison between different approaches is challenging. Training is computationally expensive, often done on private datasets of different sizes, and, as we will show, hyperparameter choices have significant impact on the final results. We present a replication study of BERT pretraining (Devlin et al., 2019) that carefully measures the impact of many key hyperparameters and training data size. We find that BERT was significantly undertrained, and can match or exceed the performance of every model published after it. Our best model achieves state-of-the-art results on GLUE, RACE and SQuAD. These results highlight the importance of previously overlooked design choices, and raise questions about the source of recently reported improvements. We release our models and code."
            },
            "slug": "RoBERTa:-A-Robustly-Optimized-BERT-Pretraining-Liu-Ott",
            "title": {
                "fragments": [],
                "text": "RoBERTa: A Robustly Optimized BERT Pretraining Approach"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "It is found that BERT was significantly undertrained, and can match or exceed the performance of every model published after it, and the best model achieves state-of-the-art results on GLUE, RACE and SQuAD."
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 2019
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3360632"
                        ],
                        "name": "Keyulu Xu",
                        "slug": "Keyulu-Xu",
                        "structuredName": {
                            "firstName": "Keyulu",
                            "lastName": "Xu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Keyulu Xu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48594758"
                        ],
                        "name": "Weihua Hu",
                        "slug": "Weihua-Hu",
                        "structuredName": {
                            "firstName": "Weihua",
                            "lastName": "Hu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Weihua Hu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1702139"
                        ],
                        "name": "J. Leskovec",
                        "slug": "J.-Leskovec",
                        "structuredName": {
                            "firstName": "Jure",
                            "lastName": "Leskovec",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Leskovec"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2594093"
                        ],
                        "name": "S. Jegelka",
                        "slug": "S.-Jegelka",
                        "structuredName": {
                            "firstName": "Stefanie",
                            "lastName": "Jegelka",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Jegelka"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 223,
                                "start": 220
                            }
                        ],
                        "text": "The input dimension of the network is 4 (the feature vector of a segment is simply its bounding box), the output dimension of the final linear layer is 128, and all the hidden dimensions (except the output dimensions of GIN modules) are set to 64."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 101,
                                "start": 86
                            }
                        ],
                        "text": "Architecture Our context embeddings are based on the Graph Isomorphism Network (GIN) (Xu et al., 2018), whose main building block is the operator A defined by\nAf(v) = (1 + )f(v) + \u2211 w\u223cv f(w), (6)\nwhich for each vertex v of the graph aggregates the features of its neighbors by summing them, and\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 19,
                                "start": 16
                            }
                        ],
                        "text": "In the original GIN architecture, a single block consists of the operatorA followed by a multi-layer perceptron, and this is also the case in our network."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 64,
                                "start": 61
                            }
                        ],
                        "text": "The network computing the context embeddings is a stack of 2 GIN modules followed by a linear layer."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 83,
                                "start": 80
                            }
                        ],
                        "text": "Architecture Our context embeddings are based on the Graph Isomorphism Network (GIN) (Xu et al., 2018), whose main building block is the operator A defined by\nAf(v) = (1 + )f(v) + \u2211 w\u223cv f(w), (6)\nwhich for each vertex v of the graph aggregates the features of its neighbors by summing them, and combines them with the feature vector of v."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 39,
                                "start": 36
                            }
                        ],
                        "text": "In Figure 2, the architectures of a GIN block and a GIN module consisting of three GIN blocks are presented."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 102,
                                "start": 85
                            }
                        ],
                        "text": "Architecture Our context embeddings are based on the Graph Isomorphism Network (GIN) (Xu et al., 2018), whose main building block is the operator A defined by"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 52895589,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "62ed9bf1d83c8db1f9cbf92ea2f57ea90ef683d9",
            "isKey": true,
            "numCitedBy": 2511,
            "numCiting": 45,
            "paperAbstract": {
                "fragments": [],
                "text": "Graph Neural Networks (GNNs) are an effective framework for representation learning of graphs. GNNs follow a neighborhood aggregation scheme, where the representation vector of a node is computed by recursively aggregating and transforming representation vectors of its neighboring nodes. Many GNN variants have been proposed and have achieved state-of-the-art results on both node and graph classification tasks. However, despite GNNs revolutionizing graph representation learning, there is limited understanding of their representational properties and limitations. Here, we present a theoretical framework for analyzing the expressive power of GNNs to capture different graph structures. Our results characterize the discriminative power of popular GNN variants, such as Graph Convolutional Networks and GraphSAGE, and show that they cannot learn to distinguish certain simple graph structures. We then develop a simple architecture that is provably the most expressive among the class of GNNs and is as powerful as the Weisfeiler-Lehman graph isomorphism test. We empirically validate our theoretical findings on a number of graph classification benchmarks, and demonstrate that our model achieves state-of-the-art performance."
            },
            "slug": "How-Powerful-are-Graph-Neural-Networks-Xu-Hu",
            "title": {
                "fragments": [],
                "text": "How Powerful are Graph Neural Networks?"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This work characterize the discriminative power of popular GNN variants, such as Graph Convolutional Networks and GraphSAGE, and show that they cannot learn to distinguish certain simple graph structures, and develops a simple architecture that is provably the most expressive among the class of GNNs."
            },
            "venue": {
                "fragments": [],
                "text": "ICLR"
            },
            "year": 2019
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "90288920"
                        ],
                        "name": "Adrian Waygood",
                        "slug": "Adrian-Waygood",
                        "structuredName": {
                            "firstName": "Adrian",
                            "lastName": "Waygood",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Adrian Waygood"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 240081945,
            "fieldsOfStudy": [],
            "id": "47d79963ac69111d8dc82a228d26e6a746a4d087",
            "isKey": false,
            "numCitedBy": 63,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Transformers-Waygood",
            "title": {
                "fragments": [],
                "text": "Transformers"
            },
            "venue": {
                "fragments": [],
                "text": "An Introduction to Electrical Science"
            },
            "year": 2018
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 176,
                                "start": 159
                            }
                        ],
                        "text": "The most notable examples are Amazon Textract (Amazon, 2019), Google Cloud Document Understanding AI platform (Google, 2019), and Microsoft Cognitive Services (Microsoft, 2019)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Cognitive Services"
            },
            "venue": {
                "fragments": [],
                "text": "https://az ure.microsoft.com/en-us/services/c ognitive-services/ (accessed November 25, 2019)."
            },
            "year": 2019
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 60,
                                "start": 46
                            }
                        ],
                        "text": "The most notable examples are Amazon Textract (Amazon, 2019), Google Cloud Document Understanding AI platform (Google, 2019), and Microsoft Cognitive Services (Microsoft, 2019)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Amazon textract"
            },
            "venue": {
                "fragments": [],
                "text": "https://aws. amazon.com/textract/ (accessed November 25, 2019)."
            },
            "year": 2019
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Attention for a token at line break"
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Sequential token order: left body of text, table key column, right body of text and table value columns. (b) Attention for a token at line break"
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 118,
                                "start": 107
                            }
                        ],
                        "text": "EDGAR This dataset was retrieved from the Electronic Data Gathering, Analysis and Retrieval (EDGAR) system (SEC, 2019), made publicly available by the U."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Electronic Data Gathering, Analysis and Re-trieval system"
            },
            "venue": {
                "fragments": [],
                "text": "https://www.sec.gov/ed gar.shtml (accessed November 26, 2019)."
            },
            "year": 2019
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 102,
                                "start": 89
                            }
                        ],
                        "text": "cTDaR The dataset from ICDAR 2019 Competition on Table Detection and Recognition (cTDaR) (ICDAR, 2015), containing various kinds of tables, both modern and historical."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Competition on Table Detection and Recognition"
            },
            "venue": {
                "fragments": [],
                "text": "http://sac.founderit.com/ index.html (accessed November 26, 2019)."
            },
            "year": 2015
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Hugging Face"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2019
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Reisswig. BERTgrid: Contextualized embedding for 2D document representation and understanding, 2019"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2019
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 124,
                                "start": 110
                            }
                        ],
                        "text": "The most notable examples are Amazon Textract (Amazon, 2019), Google Cloud Document Understanding AI platform (Google, 2019), and Microsoft Cognitive Services (Microsoft, 2019)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Cloud Document Understanding AI"
            },
            "venue": {
                "fragments": [],
                "text": "https://cloud.google.com/documentunderstanding/docs/ (accessed November 25, 2019)."
            },
            "year": 2019
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 88,
                                "start": 72
                            }
                        ],
                        "text": "This is the case for OCR systems, and also other tools such as PDFMiner (Shinyama, 2019), which we used to process PDF documents."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "PDFMiner"
            },
            "venue": {
                "fragments": [],
                "text": "https:// github.com/euske/pdfminer (accessed November 25, 2019)."
            },
            "year": 2019
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Common Crawl"
            },
            "venue": {
                "fragments": [],
                "text": "https: //commoncrawl.org (accessed December 6, 2019)."
            },
            "year": 2019
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 6,
            "methodology": 11
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 35,
        "totalPages": 4
    },
    "page_url": "https://www.semanticscholar.org/paper/LAMBERT:-Layout-Aware-language-Modeling-using-BERT-Garncarek-Powalski/e551546e51c570fe796b67ae23d97297b0717921?sort=total-citations"
}