{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2433269"
                        ],
                        "name": "Derek Hoiem",
                        "slug": "Derek-Hoiem",
                        "structuredName": {
                            "firstName": "Derek",
                            "lastName": "Hoiem",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Derek Hoiem"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1763086"
                        ],
                        "name": "Alexei A. Efros",
                        "slug": "Alexei-A.-Efros",
                        "structuredName": {
                            "firstName": "Alexei",
                            "lastName": "Efros",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alexei A. Efros"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145670946"
                        ],
                        "name": "M. Hebert",
                        "slug": "M.-Hebert",
                        "structuredName": {
                            "firstName": "Martial",
                            "lastName": "Hebert",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Hebert"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 22,
                                "start": 18
                            }
                        ],
                        "text": "Hoiem et al. [10] and Delage et al. [6] take a two-step approach for recovering 3D structure of outdoor images and indoor images respectively: 1) estimate image region orientation (e.g., ground, vertical) using statistical methods on image properties, such as color, texture, edge orientation,\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 206769405,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "ae89592317675c9c7642a3976c3a064cef736f92",
            "isKey": false,
            "numCitedBy": 757,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "Many computer vision algorithms limit their performance by ignoring the underlying 3D geometric structure in the image. We show that we can estimate the coarse geometric properties of a scene by learning appearance-based models of geometric classes, even in cluttered natural scenes. Geometric classes describe the 3D orientation of an image region with respect to the camera. We provide a multiple-hypothesis framework for robustly estimating scene structure from a single image and obtaining confidences for each geometric label. These confidences can then be used to improve the performance of many other applications. We provide a thorough quantitative evaluation of our algorithm on a set of outdoor images and demonstrate its usefulness in two applications: object detection and automatic single-view reconstruction."
            },
            "slug": "Geometric-context-from-a-single-image-Hoiem-Efros",
            "title": {
                "fragments": [],
                "text": "Geometric context from a single image"
            },
            "tldr": {
                "abstractSimilarityScore": 58,
                "text": "This work shows that it can estimate the coarse geometric properties of a scene by learning appearance-based models of geometric classes, even in cluttered natural scenes, and provides a multiple-hypothesis framework for robustly estimating scene structure from a single image and obtaining confidences for each geometric label."
            },
            "venue": {
                "fragments": [],
                "text": "Tenth IEEE International Conference on Computer Vision (ICCV'05) Volume 1"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [],
                        "name": "Wei Zhang",
                        "slug": "Wei-Zhang",
                        "structuredName": {
                            "firstName": "Wei",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wei Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1743020"
                        ],
                        "name": "J. Kosecka",
                        "slug": "J.-Kosecka",
                        "structuredName": {
                            "firstName": "Jana",
                            "lastName": "Kosecka",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Kosecka"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 132,
                                "start": 128
                            }
                        ],
                        "text": "Using the recovered vanishing points, rectangular surfaces aligned with major orientations were detected by Wei and Kosecka [15] and more recently by Micusik et al. [18]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 35116,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e99191bbd9d5adeaf752bc9ea1ac0c62e9900fe0",
            "isKey": false,
            "numCitedBy": 84,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Extraction,-matching-and-pose-recovery-based-on-Zhang-Kosecka",
            "title": {
                "fragments": [],
                "text": "Extraction, matching and pose recovery based on dominant rectangular structures"
            },
            "venue": {
                "fragments": [],
                "text": "First IEEE International Workshop on Higher-Level Knowledge in 3D Modeling and Motion Analysis, 2003. HLK 2003."
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3203751"
                        ],
                        "name": "E. Delage",
                        "slug": "E.-Delage",
                        "structuredName": {
                            "firstName": "Erick",
                            "lastName": "Delage",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Delage"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1697141"
                        ],
                        "name": "Honglak Lee",
                        "slug": "Honglak-Lee",
                        "structuredName": {
                            "firstName": "Honglak",
                            "lastName": "Lee",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Honglak Lee"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34699434"
                        ],
                        "name": "A. Ng",
                        "slug": "A.-Ng",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Ng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Ng"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5097557,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "5ea3e6ef1012b9e7f39451364d68312595b544b8",
            "isKey": false,
            "numCitedBy": 117,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "3d reconstruction from a single image is inherently an ambiguous problem. Yet when we look at a picture, we can often infer 3d information about the scene. Humans perform single-image 3d reconstructions by using a variety of single-image depth cues, for example, by recognizing objects and surfaces, and reasoning about how these surfaces are connected to each other. In this paper, we focus on the problem of automatic 3d reconstruction of indoor scenes, specifically ones (sometimes called \u201cManhattan worlds\u201d) that consist mainly of orthogonal planes. We use a Markov random field (MRF) model to identify the different planes and edges in the scene, as well as their orientations. Then, an iterative optimization algorithm is applied to infer the most probable position of all the planes, and thereby obtain a 3d reconstruction. Our approach is fully automatic\u2014given an input image, no human intervention is necessary to obtain an approximate 3d reconstruction."
            },
            "slug": "Automatic-Single-Image-3d-Reconstructions-of-Indoor-Delage-Lee",
            "title": {
                "fragments": [],
                "text": "Automatic Single-Image 3d Reconstructions of Indoor Manhattan World Scenes"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This paper uses a Markov random field model to identify the different planes and edges in the scene, as well as their orientations, and applies an iterative optimization algorithm to infer the most probable position of all the planes, and thereby obtain a 3d reconstruction."
            },
            "venue": {
                "fragments": [],
                "text": "ISRR"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2433269"
                        ],
                        "name": "Derek Hoiem",
                        "slug": "Derek-Hoiem",
                        "structuredName": {
                            "firstName": "Derek",
                            "lastName": "Hoiem",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Derek Hoiem"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1763086"
                        ],
                        "name": "Alexei A. Efros",
                        "slug": "Alexei-A.-Efros",
                        "structuredName": {
                            "firstName": "Alexei",
                            "lastName": "Efros",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alexei A. Efros"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145670946"
                        ],
                        "name": "M. Hebert",
                        "slug": "M.-Hebert",
                        "structuredName": {
                            "firstName": "Martial",
                            "lastName": "Hebert",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Hebert"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6152006,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4081e007d7eced95cc618164e976a80d44ff5f4e",
            "isKey": false,
            "numCitedBy": 656,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "Image understanding requires not only individually estimating elements of the visual world but also capturing the interplay among them. In this paper, we provide a framework for placing local object detection in the context of the overall 3D scene by modeling the interdependence of objects, surface orientations, and camera viewpoint. Most object detection methods consider all scales and locations in the image as equally likely. We show that with probabilistic estimates of 3D geometry, both in terms of surfaces and world coordinates, we can put objects into perspective and model the scale and location variance in the image. Our approach reflects the cyclical nature of the problem by allowing probabilistic object hypotheses to refine geometry and vice-versa. Our framework allows painless substitution of almost any object detector and is easily extended to include other aspects of image understanding. Our results confirm the benefits of our integrated approach."
            },
            "slug": "Putting-Objects-in-Perspective-Hoiem-Efros",
            "title": {
                "fragments": [],
                "text": "Putting Objects in Perspective"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "This paper provides a framework for placing local object detection in the context of the overall 3D scene by modeling the interdependence of objects, surface orientations, and camera viewpoint by allowing probabilistic object hypotheses to refine geometry and vice-versa."
            },
            "venue": {
                "fragments": [],
                "text": "2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'06)"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3203751"
                        ],
                        "name": "E. Delage",
                        "slug": "E.-Delage",
                        "structuredName": {
                            "firstName": "Erick",
                            "lastName": "Delage",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Delage"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1697141"
                        ],
                        "name": "Honglak Lee",
                        "slug": "Honglak-Lee",
                        "structuredName": {
                            "firstName": "Honglak",
                            "lastName": "Lee",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Honglak Lee"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34699434"
                        ],
                        "name": "A. Ng",
                        "slug": "A.-Ng",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Ng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Ng"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 44,
                                "start": 41
                            }
                        ],
                        "text": "Hoiem et al. [10] and Delage et al. [6] take a two-step approach for recovering 3D structure of outdoor images and indoor images respectively: 1) estimate image region orientation (e.g., ground, vertical) using statistical methods on image properties, such as color, texture, edge orientation,\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14075351,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1f4789a2effea966c8fd10491fe859cfc7607137",
            "isKey": false,
            "numCitedBy": 237,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "When we look at a picture, our prior knowledge about the world allows us to resolve some of the ambiguities that are inherent to monocular vision, and thereby infer 3d information about the scene. We also recognize different objects, decide on their orientations, and identify how they are connected to their environment. Focusing on the problem of autonomous 3d reconstruction of indoor scenes, in this paper we present a dynamic Bayesian network model capable of resolving some of these ambiguities and recovering 3d information for many images. Our model assumes a \"floorwall\" geometry on the scene and is trained to recognize the floor-wall boundary in each column of the image. When the image is produced under perspective geometry, we show that this model can be used for 3d reconstruction from a single image. To our knowledge, this was the first monocular approach to automatically recover 3d reconstructions from single indoor images."
            },
            "slug": "A-Dynamic-Bayesian-Network-Model-for-Autonomous-3D-Delage-Lee",
            "title": {
                "fragments": [],
                "text": "A Dynamic Bayesian Network Model for Autonomous 3D Reconstruction from a Single Indoor Image"
            },
            "tldr": {
                "abstractSimilarityScore": 52,
                "text": "This paper presents a dynamic Bayesian network model capable of resolving some of the ambiguities of monocular vision and recovering 3d information for many images and shows that this model can be used for 3d reconstruction from a single image."
            },
            "venue": {
                "fragments": [],
                "text": "2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'06)"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733113"
                        ],
                        "name": "T. Kanade",
                        "slug": "T.-Kanade",
                        "structuredName": {
                            "firstName": "Takeo",
                            "lastName": "Kanade",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kanade"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 10,
                                "start": 6
                            }
                        ],
                        "text": "Kanade [13] dealt with \u201corigami world\u201d, which includes hollow shells and planar sheets, and utilized heuristics, such as parallel lines in image are parallel in space."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6117451,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5732ad4b2e63b4bc322d2893188fba8728fd61b4",
            "isKey": false,
            "numCitedBy": 167,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-Theory-of-Origami-World-Kanade",
            "title": {
                "fragments": [],
                "text": "A Theory of Origami World"
            },
            "venue": {
                "fragments": [],
                "text": "Artif. Intell."
            },
            "year": 1980
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2780241"
                        ],
                        "name": "V. Nedovic",
                        "slug": "V.-Nedovic",
                        "structuredName": {
                            "firstName": "Vladimir",
                            "lastName": "Nedovic",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Nedovic"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144638781"
                        ],
                        "name": "A. Smeulders",
                        "slug": "A.-Smeulders",
                        "structuredName": {
                            "firstName": "Arnold",
                            "lastName": "Smeulders",
                            "middleNames": [
                                "W.",
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Smeulders"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3251153"
                        ],
                        "name": "A. Redert",
                        "slug": "A.-Redert",
                        "structuredName": {
                            "firstName": "Andr\u00e9",
                            "lastName": "Redert",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Redert"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1720149"
                        ],
                        "name": "J. Geusebroek",
                        "slug": "J.-Geusebroek",
                        "structuredName": {
                            "firstName": "Jan-Mark",
                            "lastName": "Geusebroek",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Geusebroek"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 67,
                                "start": 63
                            }
                        ],
                        "text": "An interesting observation was made by Nedovic et al. [19] that a typical scene can be categorized into a limited number of categories of 3D scene geometry, which they call \u201cstages\u201d."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2522214,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6f8baea94aa3ebea087dad5e52ce51896ef39aaa",
            "isKey": false,
            "numCitedBy": 41,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": "Recently, methods for estimating 3D scene geometry or absolute scene depth information from 2D image content have been proposed. However, general applicability of these methods in depth estimation may not be realizable, as inconsistencies may be introduced due to a large variety of possible pictorial content. We identify scene categorization as the first step towards efficient and robust depth estimation from single images. To that end, we describe a limited number of typical 3D scene geometries, called stages, each having a unique depth pattern and thus providing a specific context for stage objects. This type of scene information narrows down the possibilities with respect to individual objects' locations, scales and identities. We show how these stage types can be efficiently learned and how they can lead to robust extraction of depth information. Our results indicate that stages without much variation and object clutter can be detected robustly, with up to 60% success rate."
            },
            "slug": "Depth-Information-by-Stage-Classification-Nedovic-Smeulders",
            "title": {
                "fragments": [],
                "text": "Depth Information by Stage Classification"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This work describes a limited number of typical 3D scene geometries, called stages, each having a unique depth pattern and thus providing a specific context for stage objects, and shows how these stage types can be efficiently learned and how they can lead to robust extraction of depth information."
            },
            "venue": {
                "fragments": [],
                "text": "2007 IEEE 11th International Conference on Computer Vision"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1681995"
                        ],
                        "name": "Ashutosh Saxena",
                        "slug": "Ashutosh-Saxena",
                        "structuredName": {
                            "firstName": "Ashutosh",
                            "lastName": "Saxena",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ashutosh Saxena"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2112610462"
                        ],
                        "name": "Sung H. Chung",
                        "slug": "Sung-H.-Chung",
                        "structuredName": {
                            "firstName": "Sung",
                            "lastName": "Chung",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sung H. Chung"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34699434"
                        ],
                        "name": "A. Ng",
                        "slug": "A.-Ng",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Ng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Ng"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 119,
                                "start": 115
                            }
                        ],
                        "text": "Saxena et al. have taken a different approach by estimating absolute depth directly from image properties [21], and smoothly connecting regions under weak assumptions, such as connectivity or coplanarity, without the explicit assumption of a ground plane [22]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 10748875,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cddd92203c8deb022a29b512b11050da531c5f3b",
            "isKey": false,
            "numCitedBy": 981,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "We consider the task of depth estimation from a single monocular image. We take a supervised learning approach to this problem, in which we begin by collecting a training set of monocular images (of unstructured outdoor environments which include forests, trees, buildings, etc.) and their corresponding ground-truth depthmaps. Then, we apply supervised learning to predict the depthmap as a function of the image. Depth estimation is a challenging problem, since local features alone are insufficient to estimate depth at a point, and one needs to consider the global context of the image. Our model uses a discriminatively-trained Markov Random Field (MRF) that incorporates multiscale local- and global-image features, and models both depths at individual points as well as the relation between depths at different points. We show that, even on unstructured scenes, our algorithm is frequently able to recover fairly accurate depthmaps."
            },
            "slug": "Learning-Depth-from-Single-Monocular-Images-Saxena-Chung",
            "title": {
                "fragments": [],
                "text": "Learning Depth from Single Monocular Images"
            },
            "tldr": {
                "abstractSimilarityScore": 54,
                "text": "This work begins by collecting a training set of monocular images (of unstructured outdoor environments which include forests, trees, buildings, etc.) and their corresponding ground-truth depthmaps, and applies supervised learning to predict the depthmap as a function of the image."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3229686"
                        ],
                        "name": "B. Micus\u00edk",
                        "slug": "B.-Micus\u00edk",
                        "structuredName": {
                            "firstName": "Branislav",
                            "lastName": "Micus\u00edk",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Micus\u00edk"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1739561"
                        ],
                        "name": "H. Wildenauer",
                        "slug": "H.-Wildenauer",
                        "structuredName": {
                            "firstName": "Horst",
                            "lastName": "Wildenauer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Wildenauer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1743020"
                        ],
                        "name": "J. Kosecka",
                        "slug": "J.-Kosecka",
                        "structuredName": {
                            "firstName": "Jana",
                            "lastName": "Kosecka",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Kosecka"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 170,
                                "start": 169
                            }
                        ],
                        "text": "Using the recovered vanishing points, rectangular surfaces aligned with major orientations were detected by Wei and Kosecka [15] and more recently by Micusik et al. [18]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 8625511,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ed1db69602fec57d224bf12b46d5a570d30b1043",
            "isKey": false,
            "numCitedBy": 72,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "Indoor and outdoor urban environments posses many regularities which can be efficiently exploited and used for general image parsing tasks. We present a novel approach for detecting rectilinear structures and demonstrate their use for wide baseline stereo matching, planar 3D reconstruction, and computation of geometric context. Assuming a presence of dominant orthogonal vanishing directions, we proceed by formulating the detection of the rectilinear structures as a labeling problem on detected line segments. The line segment labels, respecting the proposed grammar rules, are established as the MAP assignment of the corresponding MRF. The proposed framework allows to detect both full as well as partial rectangles, rectangle-in-rectangle structures, and rectangles sharing edges. The use of detected rectangles is demonstrated in the context of difficult wide baseline matching tasks in the presence of repetitive structures and large appearance changes."
            },
            "slug": "Detection-and-matching-of-rectilinear-structures-Micus\u00edk-Wildenauer",
            "title": {
                "fragments": [],
                "text": "Detection and matching of rectilinear structures"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "A novel approach for detecting rectilinear structures is presented and their use for wide baseline stereo matching, planar 3D reconstruction, and computation of geometric context is demonstrated."
            },
            "venue": {
                "fragments": [],
                "text": "2008 IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716777"
                        ],
                        "name": "A. Criminisi",
                        "slug": "A.-Criminisi",
                        "structuredName": {
                            "firstName": "Antonio",
                            "lastName": "Criminisi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Criminisi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145950884"
                        ],
                        "name": "I. Reid",
                        "slug": "I.-Reid",
                        "structuredName": {
                            "firstName": "Ian",
                            "lastName": "Reid",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Reid"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688869"
                        ],
                        "name": "Andrew Zisserman",
                        "slug": "Andrew-Zisserman",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Zisserman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Zisserman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 3,
                                "start": 0
                            }
                        ],
                        "text": "A commonly used reference is the ground plane."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2499410,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9e96483e264f5a063cadfa232fa325a56d146a0b",
            "isKey": false,
            "numCitedBy": 750,
            "numCiting": 47,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe how 3D affine measurements may be computed from a single perspective view of a scene given only minimal geometric information determined from the image. This minimal information is typically the vanishing line of a reference plane, and a vanishing point for a direction not parallel to the plane. It is shown that affine scene structure may then be determined from the image, without knowledge of the camera's internal calibration (e.g. focal length), nor of the explicit relation between camera and world (pose).In particular, we show how to (i) compute the distance between planes parallel to the reference plane (up to a common scale factor); (ii) compute area and length ratios on any plane parallel to the reference plane; (iii) determine the camera's location. Simple geometric derivations are given for these results. We also develop an algebraic representation which unifies the three types of measurement and, amongst other advantages, permits a first order error propagation analysis to be performed, associating an uncertainty with each measurement.We demonstrate the technique for a variety of applications, including height measurements in forensic images and 3D graphical modelling from single images."
            },
            "slug": "Single-View-Metrology-Criminisi-Reid",
            "title": {
                "fragments": [],
                "text": "Single View Metrology"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "An algebraic representation is developed which unifies the three types of measurement and permits a first order error propagation analysis to be performed, associating an uncertainty with each measurement."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1690624"
                        ],
                        "name": "Alan K. Mackworth",
                        "slug": "Alan-K.-Mackworth",
                        "structuredName": {
                            "firstName": "Alan",
                            "lastName": "Mackworth",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alan K. Mackworth"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 13,
                                "start": 9
                            }
                        ],
                        "text": "Mackworth [17] introduced the concept of gradient space and surface based constraints."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 11978118,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ed165fa39e4ecda494049f459bbe57448101ecc4",
            "isKey": false,
            "numCitedBy": 186,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Interpreting-Pictures-of-Polyhedral-Scenes-Mackworth",
            "title": {
                "fragments": [],
                "text": "Interpreting Pictures of Polyhedral Scenes"
            },
            "venue": {
                "fragments": [],
                "text": "IJCAI"
            },
            "year": 1973
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8436115"
                        ],
                        "name": "J. Coughlan",
                        "slug": "J.-Coughlan",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Coughlan",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Coughlan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145081362"
                        ],
                        "name": "A. Yuille",
                        "slug": "A.-Yuille",
                        "structuredName": {
                            "firstName": "Alan",
                            "lastName": "Yuille",
                            "middleNames": [
                                "Loddon"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Yuille"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14658103,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d0690e1129f652a836bd45c418b9335a38b4c841",
            "isKey": false,
            "numCitedBy": 404,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "When designing computer vision systems for the blind and visually impaired it is important to determine the orientation of the user relative to the scene. We observe that most indoor and outdoor (city) scenes are designed on a Manhattan three-dimensional grid. This Manhattan grid structure puts strong constraints on the intensity gradients in the image. We demonstrate an algorithm for detecting the orientation of the user in such scenes based on Bayesian inference using statistics which we have learnt in this domain. Our algorithm requires a single input image and does not involve pre-processing stages such as edge detection and Hough grouping. We demonstrate strong experimental results on a range of indoor and outdoor images. We also show that estimating the grid structure makes it significantly easier to detect target objects which are not aligned with the grid."
            },
            "slug": "Manhattan-World:-compass-direction-from-a-single-by-Coughlan-Yuille",
            "title": {
                "fragments": [],
                "text": "Manhattan World: compass direction from a single image by Bayesian inference"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "An algorithm for detecting the orientation of the user in such scenes based on Bayesian inference using statistics which has been learnt in this domain is demonstrated."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Seventh IEEE International Conference on Computer Vision"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1756036"
                        ],
                        "name": "C. Rother",
                        "slug": "C.-Rother",
                        "structuredName": {
                            "firstName": "Carsten",
                            "lastName": "Rother",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Rother"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2048989,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "06d4a6e2c59b3c4bf5d7216d32e6e811eb843f43",
            "isKey": false,
            "numCitedBy": 265,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "A man-made environment is characterized by a lot of parallel lines and a lot of orthogonal edges. In this article, a new method for detecting the three mutual orthogonal directions of such an environment is presented. Since realtime performance is not necessary for architectural application, like building reconstruction, a computationally more intensive approach was chosen. On the other hand, our approach is more rigorous than existing techniques, since the information given by the condition of three mutual orthogonal directions in the scene is identified and incorporated. Since knowledge about the camera geometry can be deduced from the vanishing points of three mutual orthogonal directions, we use this knowledge to reject falsely detected vanishing points. Results are presented from interpreting outdoor scenes of buildings."
            },
            "slug": "A-New-Approach-for-Vanishing-Point-Detection-in-Rother",
            "title": {
                "fragments": [],
                "text": "A New Approach for Vanishing Point Detection in Architectural Environments"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "This approach is more rigorous than existing techniques, since the information given by the condition of three mutual orthogonal directions in the scene is identified and incorporated and used to reject falsely detected vanishing points."
            },
            "venue": {
                "fragments": [],
                "text": "BMVC"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1743020"
                        ],
                        "name": "J. Kosecka",
                        "slug": "J.-Kosecka",
                        "structuredName": {
                            "firstName": "Jana",
                            "lastName": "Kosecka",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Kosecka"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [],
                        "name": "Wei Zhang",
                        "slug": "Wei-Zhang",
                        "structuredName": {
                            "firstName": "Wei",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wei Zhang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 23,
                                "start": 19
                            }
                        ],
                        "text": "Kosecka and Wei [14] developed a method to recover vanishing points and camera parameters from a single image by using line segments found in Manhattan structures."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1413778,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d47bca050a09e69be810fd7c677ed5aefe66c797",
            "isKey": false,
            "numCitedBy": 369,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we describe a flexible approach for determining the relative orientation of the camera with respect to the scene. The main premise of the approach is the fact that in man-made environments, the majority of lines is aligned with the principal orthogonal directions of the world coordinate frame. We exploit this observation towards efficient detection and estimation of vanishing points, which provide strong constraints on camera parameters and relative orientation of the camera with respect to the scene.By combining efficient image processing techniques in the line detection and initialization stage we demonstrate that simultaneous grouping and estimation of vanishing directions can be achieved in the absence of internal parameters of the camera. Constraints between vanishing points are then used for partial calibration and relative rotation estimation. The algorithm has been tested in a variety of indoors and outdoors scenes and its efficiency and automation makes it amenable for implementation on robotic platforms."
            },
            "slug": "Video-Compass-Kosecka-Zhang",
            "title": {
                "fragments": [],
                "text": "Video Compass"
            },
            "tldr": {
                "abstractSimilarityScore": 79,
                "text": "A flexible approach for determining the relative orientation of the camera with respect to the scene based on the fact that in man-made environments, the majority of lines is aligned with the principal orthogonal directions of the world coordinate frame is described."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2064563493"
                        ],
                        "name": "Feng Han",
                        "slug": "Feng-Han",
                        "structuredName": {
                            "firstName": "Feng",
                            "lastName": "Han",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Feng Han"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145380991"
                        ],
                        "name": "Song-Chun Zhu",
                        "slug": "Song-Chun-Zhu",
                        "structuredName": {
                            "firstName": "Song-Chun",
                            "lastName": "Zhu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Song-Chun Zhu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 19,
                                "start": 16
                            }
                        ],
                        "text": "Han and Zhu [9] have also worked on finding rectangles aligned with vanishing points from line segments."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5751287,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "338b3f99d1dda11252f27d34e09261a7dedc4cd3",
            "isKey": false,
            "numCitedBy": 153,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we present an attribute graph grammar for image parsing on scenes with man-made objects, such as buildings, hallways, kitchens, and living moms. We choose one class of primitives - 3D planar rectangles projected on images and six graph grammar production rules. Each production rule not only expands a node into its components, but also includes a number of equations that constrain the attributes of a parent node and those of its children. Thus our graph grammar is context sensitive. The grammar rules are used recursively to produce a large number of objects and patterns in images and thus the whole graph grammar is a type of generative model. The inference algorithm integrates bottom-up rectangle detection which activates top-down prediction using the grammar rules. The final results are validated in a Bayesian framework. The output of the inference is a hierarchical parsing graph with objects, surfaces, rectangles, and their spatial relations. In the inference, the acceptance of a grammar rule means recognition of an object, and actions are taken to pass the attributes between a node and its parent through the constraint equations associated with this production rule. When an attribute is passed from a child node to a parent node, it is called bottom-up, and the opposite is called top-down"
            },
            "slug": "Bottom-up/top-down-image-parsing-by-attribute-graph-Han-Zhu",
            "title": {
                "fragments": [],
                "text": "Bottom-up/top-down image parsing by attribute graph grammar"
            },
            "tldr": {
                "abstractSimilarityScore": 70,
                "text": "An attribute graph grammar for image parsing on scenes with man-made objects, such as buildings, hallways, kitchens, and living moms is presented and the inference algorithm integrates bottom-up rectangle detection which activates top-down prediction using the grammar rules."
            },
            "venue": {
                "fragments": [],
                "text": "Tenth IEEE International Conference on Computer Vision (ICCV'05) Volume 1"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1401830631"
                        ],
                        "name": "A. Guzm\u00e1n-Arenas",
                        "slug": "A.-Guzm\u00e1n-Arenas",
                        "structuredName": {
                            "firstName": "Adolfo",
                            "lastName": "Guzm\u00e1n-Arenas",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Guzm\u00e1n-Arenas"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 10,
                                "start": 7
                            }
                        ],
                        "text": "Guzman [8] was the first to interpret line drawings to separate collection of polyhedral objects into\n1\nparts."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14206893,
            "fieldsOfStudy": [
                "Mathematics",
                "Art"
            ],
            "id": "313225cd9b6729c1a239a3af40d2dfeaf6946a52",
            "isKey": false,
            "numCitedBy": 121,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "We consider visual scenes composed by the optical image of a group of bodies. When such a scene is \"seen\" by a computer through a film spot scanner, image dissector, or similar device, it can be treated as a two-dimensional array of numbers, or as a function of two variables."
            },
            "slug": "Decomposition-of-a-visual-scene-into-bodies-Guzm\u00e1n-Arenas",
            "title": {
                "fragments": [],
                "text": "Decomposition of a visual scene into three-dimensional bodies"
            },
            "tldr": {
                "abstractSimilarityScore": 63,
                "text": "This work considers visual scenes composed by the optical image of a group of bodies that can be treated as a two-dimensional array of numbers, or as a function of two variables."
            },
            "venue": {
                "fragments": [],
                "text": "AFIPS '68 (Fall, part I)"
            },
            "year": 1968
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48950628"
                        ],
                        "name": "N. Dalal",
                        "slug": "N.-Dalal",
                        "structuredName": {
                            "firstName": "Navneet",
                            "lastName": "Dalal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Dalal"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1756114"
                        ],
                        "name": "B. Triggs",
                        "slug": "B.-Triggs",
                        "structuredName": {
                            "firstName": "Bill",
                            "lastName": "Triggs",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Triggs"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 206590483,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cec734d7097ab6b1e60d95228ffd64248eb89d66",
            "isKey": false,
            "numCitedBy": 29267,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "We study the question of feature sets for robust visual object recognition; adopting linear SVM based human detection as a test case. After reviewing existing edge and gradient based descriptors, we show experimentally that grids of histograms of oriented gradient (HOG) descriptors significantly outperform existing feature sets for human detection. We study the influence of each stage of the computation on performance, concluding that fine-scale gradients, fine orientation binning, relatively coarse spatial binning, and high-quality local contrast normalization in overlapping descriptor blocks are all important for good results. The new approach gives near-perfect separation on the original MIT pedestrian database, so we introduce a more challenging dataset containing over 1800 annotated human images with a large range of pose variations and backgrounds."
            },
            "slug": "Histograms-of-oriented-gradients-for-human-Dalal-Triggs",
            "title": {
                "fragments": [],
                "text": "Histograms of oriented gradients for human detection"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "It is shown experimentally that grids of histograms of oriented gradient (HOG) descriptors significantly outperform existing feature sets for human detection, and the influence of each stage of the computation on performance is studied."
            },
            "venue": {
                "fragments": [],
                "text": "2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05)"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1788375"
                        ],
                        "name": "D. Waltz",
                        "slug": "D.-Waltz",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Waltz",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Waltz"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 9,
                                "start": 5
                            }
                        ],
                        "text": "Waltz [24] expanded the problem by allowing line drawings to include shadows, cracks, and missing edges (Figure 2)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 60864834,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e1596adff54c958816e5a10d33e69f13a4d8afc5",
            "isKey": false,
            "numCitedBy": 546,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": "This report reproduces a thesis of the same title submitted to the Department of Electrical Engineering, Massachusetts Institute of Technology, in partial fulfillment of the requirements for the degree of Doctor of Philosophy, September 1972."
            },
            "slug": "Generating-Semantic-Descriptions-From-Drawings-of-Waltz",
            "title": {
                "fragments": [],
                "text": "Generating Semantic Descriptions From Drawings of Scenes With Shadows"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "This report reproduces a thesis of the same title submitted to the Department of Electrical Engineering, Massachusetts Institute of Technology, in partial fulfillment of the requirements for the degree of Doctor of Philosophy, September 1972."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1972
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751698"
                        ],
                        "name": "K. Sugihara",
                        "slug": "K.-Sugihara",
                        "structuredName": {
                            "firstName": "Kokichi",
                            "lastName": "Sugihara",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Sugihara"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 15,
                                "start": 11
                            }
                        ],
                        "text": "Sugihara [23] provided an algebraic optimization approach for interpreting line drawings."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 15049476,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "a17cc01c8ce63f6f0ef8249ac5d9a3031a27b1be",
            "isKey": false,
            "numCitedBy": 82,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "As Shapira pointed out, a theorem by the author on line drawings of polyhedral scenes was not accurate. The present paper shows that the validity of the theorem is attained by a slight revision of the formulation."
            },
            "slug": "A-Necessary-and-Sufficient-Condition-for-a-Picture-Sugihara",
            "title": {
                "fragments": [],
                "text": "A Necessary and Sufficient Condition for a Picture to Represent a Polyhedral Scene"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "The present paper shows that the validity of the theorem is attained by a slight revision of the formulation, which was pointed out by the author on line drawings of polyhedral scenes was not accurate."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 1984
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "11079833"
                        ],
                        "name": "S. Sutherland",
                        "slug": "S.-Sutherland",
                        "structuredName": {
                            "firstName": "Stuart",
                            "lastName": "Sutherland",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Sutherland"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 25,
                                "start": 22
                            }
                        ],
                        "text": "Huffman [12] and Clowes [1] came up with a formal scheme of labeling lines into convex, concave, and occluding for polyhedral objects, with which 3D description of objects can be recovered and impossible objects can be rejected."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5479823,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "b3464fb194e5dc5ee6786136aaad08763a700549",
            "isKey": false,
            "numCitedBy": 331,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Visual Processing: Computational, Psychophysical and Cognitive Research.By Roger Watt. Lawrence Erlbaum: 1988. Pp. 152. \u00a314.95, $26.95.Visual Cognition: Computational, Experimental and Neuropsychological Perspectives. By Glyn W. Humphreys and Vicki Bruce. Lawrence Erlbaum: 1989. Pp.330. Hbk \u00a319.95, $37.95; pbk \u00a39.95, $16.95."
            },
            "slug": "Seeing-things-Sutherland",
            "title": {
                "fragments": [],
                "text": "Seeing things"
            },
            "venue": {
                "fragments": [],
                "text": "Nature"
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "33726225"
                        ],
                        "name": "O. Faugeras",
                        "slug": "O.-Faugeras",
                        "structuredName": {
                            "firstName": "Olivier",
                            "lastName": "Faugeras",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Faugeras"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2624076"
                        ],
                        "name": "Q. Luong",
                        "slug": "Q.-Luong",
                        "structuredName": {
                            "firstName": "Quang-Tuan",
                            "lastName": "Luong",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Q. Luong"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "69064006"
                        ],
                        "name": "T. Papadopoulo",
                        "slug": "T.-Papadopoulo",
                        "structuredName": {
                            "firstName": "Thodore",
                            "lastName": "Papadopoulo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Papadopoulo"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 59635978,
            "fieldsOfStudy": [
                "Chemistry"
            ],
            "id": "db56f13011e07f00394821dba6df39b621df9393",
            "isKey": false,
            "numCitedBy": 654,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Nitrocyclopropane is prepared by reacting 3-chloro-1-nitropropane with an amine which has a polar center in addition to an amino function in the presence of a polar, aprotic solvent. For example, the reaction of 3-chloro-1-nitropropane with ethylene diamine in the presence of dimethyl sulfoxide produces nitrocyclopropane in high yield."
            },
            "slug": "The-Geometry-of-Multiple-Images-Faugeras-Luong",
            "title": {
                "fragments": [],
                "text": "The Geometry of Multiple Images"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 7,
                                "start": 3
                            }
                        ],
                        "text": "An interesting observation was made by Nedovic et al. [19] that a typical scene can be categorized into a limited number of categories of 3D scene geometry, which they call \u201cstages\u201d."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Make3d: Learning 3d scene structure from a single still image"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions of Pattern Analysis and Machine Intelligence (PAMI)"
            },
            "year": 2008
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "MATLAB and Octave functions for computer vision and image processing Interpreting pictures of polyhedral scenes"
            },
            "venue": {
                "fragments": [],
                "text": "In Artificial Intelligence"
            },
            "year": 1973
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Appendix: Formulas for 2D to 3D conversion All units of metrics are in camera height, i.e., the distance between the floor and the camera measured perpen"
            },
            "venue": {
                "fragments": [],
                "text": "Appendix: Formulas for 2D to 3D conversion All units of metrics are in camera height, i.e., the distance between the floor and the camera measured perpen"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "MATLAB and Octave functions for computer vision and image processing. School of Computer Science & Software Engineering, The University of Western Australia Available from"
            },
            "venue": {
                "fragments": [],
                "text": "MATLAB and Octave functions for computer vision and image processing. School of Computer Science & Software Engineering, The University of Western Australia Available from"
            }
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 10,
            "methodology": 6
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 25,
        "totalPages": 3
    },
    "page_url": "https://www.semanticscholar.org/paper/Geometric-reasoning-for-single-image-structure-Lee-Hebert/3228234ab663758d7439d9ee8f30c8fb29db8e7f?sort=total-citations"
}