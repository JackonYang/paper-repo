{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46867608"
                        ],
                        "name": "Yu Zhang",
                        "slug": "Yu-Zhang",
                        "structuredName": {
                            "firstName": "Yu",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yu Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152290618"
                        ],
                        "name": "Qiang Yang",
                        "slug": "Qiang-Yang",
                        "structuredName": {
                            "firstName": "Qiang",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Qiang Yang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 11311635,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bb35ef89addbbc28d960bc0cab70d8a29fdf6eee",
            "isKey": false,
            "numCitedBy": 816,
            "numCiting": 279,
            "paperAbstract": {
                "fragments": [],
                "text": "Multi-Task Learning (MTL) is a learning paradigm in machine learning and its aim is to leverage useful information contained in multiple related tasks to help improve the generalization performance of all the tasks. In this paper, we give a survey for MTL. First, we classify different MTL algorithms into several categories, including feature learning approach, low-rank approach, task clustering approach, task relation learning approach, and decomposition approach, and then discuss the characteristics of each approach. In order to improve the performance of learning tasks further, MTL can be combined with other learning paradigms including semi-supervised learning, active learning, unsupervised learning, reinforcement learning, multi-view learning and graphical models. When the number of tasks is large or the data dimensionality is high, batch MTL models are difficult to handle this situation and online, parallel and distributed MTL models as well as dimensionality reduction and feature hashing are reviewed to reveal their computational and storage advantages. Many real-world applications use MTL to boost their performance and we review representative works. Finally, we present theoretical analyses and discuss several future directions for MTL."
            },
            "slug": "A-Survey-on-Multi-Task-Learning-Zhang-Yang",
            "title": {
                "fragments": [],
                "text": "A Survey on Multi-Task Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A survey for MTL is given, which classifies different MTL algorithms into several categories, including feature learning approach, low-rank approach, task clustering approaches, task relation learning approaches, and decomposition approach, and then discusses the characteristics of each approach."
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2925921"
                        ],
                        "name": "Pinghua Gong",
                        "slug": "Pinghua-Gong",
                        "structuredName": {
                            "firstName": "Pinghua",
                            "lastName": "Gong",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Pinghua Gong"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144030870"
                        ],
                        "name": "Jieping Ye",
                        "slug": "Jieping-Ye",
                        "structuredName": {
                            "firstName": "Jieping",
                            "lastName": "Ye",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jieping Ye"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "14966740"
                        ],
                        "name": "Changshui Zhang",
                        "slug": "Changshui-Zhang",
                        "structuredName": {
                            "firstName": "Changshui",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Changshui Zhang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 65,
                                "start": 58
                            }
                        ],
                        "text": "Based on Table 1, we can see that the choices of g (U) in [53,56] make U row-sparse via the \u221e,1 and 2,1 norms, respectively."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 99,
                                "start": 92
                            }
                        ],
                        "text": "For V, h(V) makes it sparse via the 1 norm in [53,54] and column-sparse via the 2,1 norm in [55,56], while in [57], h(V) penalizes the complexity of V via the squared Frobenius norm."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6125599,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8f84c467dd044421b52b39815f601a95b3b917f0",
            "isKey": false,
            "numCitedBy": 266,
            "numCiting": 45,
            "paperAbstract": {
                "fragments": [],
                "text": "Multi-task learning (MTL) aims to improve the performance of multiple related tasks by exploiting the intrinsic relationships among them. Recently, multi-task feature learning algorithms have received increasing attention and they have been successfully applied to many applications involving high dimensional data. However, they assume that all tasks share a common set of features, which is too restrictive and may not hold in real-world applications, since outlier tasks often exist. In this paper, we propose a Robust Multi-Task Feature Learning algorithm (rMTFL) which simultaneously captures a common set of features among relevant tasks and identifies outlier tasks. Specifically, we decompose the weight (model) matrix for all tasks into two components. We impose the well-known group Lasso penalty on row groups of the first component for capturing the shared features among relevant tasks. To simultaneously identify the outlier tasks, we impose the same group Lasso penalty but on column groups of the second component. We propose to employ the accelerated gradient descent to efficiently solve the optimization problem in rMTFL, and show that the proposed algorithm is scalable to large-size problems. In addition, we provide a detailed theoretical analysis on the proposed rMTFL formulation. Specifically, we present a theoretical bound to measure how well our proposed rMTFL approximates the true evaluation, and provide bounds to measure the error between the estimated weights of rMTFL and the underlying true weights. Moreover, by assuming that the underlying true weights are above the noise level, we present a sound theoretical result to show how to obtain the underlying true shared features and outlier tasks (sparsity patterns). Empirical studies on both synthetic and real-world data demonstrate that our proposed rMTFL is capable of simultaneously capturing shared features among tasks and identifying outlier tasks."
            },
            "slug": "Robust-multi-task-feature-learning-Gong-Ye",
            "title": {
                "fragments": [],
                "text": "Robust multi-task feature learning"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This paper proposes a Robust Multi-Task Feature Learning algorithm (rMTFL) which simultaneously captures a common set of features among relevant tasks and identifies outlier tasks, and provides a detailed theoretical analysis on the proposed rMTFL formulation."
            },
            "venue": {
                "fragments": [],
                "text": "KDD"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2112660813"
                        ],
                        "name": "Lei Han",
                        "slug": "Lei-Han",
                        "structuredName": {
                            "firstName": "Lei",
                            "lastName": "Han",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lei Han"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2153632326"
                        ],
                        "name": "Yu Zhang",
                        "slug": "Yu-Zhang",
                        "structuredName": {
                            "firstName": "Yu",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yu Zhang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 112,
                                "start": 108
                            }
                        ],
                        "text": "Unlike [58] where each level involves a subset of tasks, a multi-level taskclustering method is proposed in [34] to cluster all the tasks at each level based on a structurally sparse regularizer \u2211h i=1 \u03bb \u03b7i\u22121 \u2211 k> j \u2016w j i \u2212 wk i \u20162."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 132,
                                "start": 128
                            }
                        ],
                        "text": "In order to automatically determine the number of clusters, a structurally sparse regularizer, \u2211 j>i \u2016wi \u2212 w \u20162, is proposed in [34] to enforce any pair of model parameters to be fused."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 65,
                                "start": 61
                            }
                        ],
                        "text": "Specifically, built on the multi-level taskclustering method [34], a sequential constraint, i."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 17713739,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1d5cf093253105823c82046e2b640aa1f79c0590",
            "isKey": false,
            "numCitedBy": 51,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "\n \n In multi-task learning (MTL), multiple related tasks are learned jointly by sharing information across them. Many MTL algorithms have been proposed to learn the underlying task groups. However, those methods are limited to learn the task groups at only a single level, which may be not sufficient to model the complex structure among tasks in many real-world applications. In this paper, we propose a Multi-Level Task Grouping (MeTaG) method to learn the multi-level grouping structure instead of only one level among tasks. Specifically, by assuming the number of levels to be H, we decompose the parameter matrix into a sum of H component matrices, each of which is regularized with a l2 norm on the pairwise difference among parameters of all the tasks to construct level-specific task groups. For optimization, we employ the smoothing proximal gradient method to efficiently solve the objective function of the MeTaG model. Moreover, we provide theoretical analysis to show that under certain conditions the MeTaG model can recover the true parameter matrix and the true task groups in each level with high probability. We experiment our approach on both synthetic and real-world datasets, showing competitive performance over state-of-the-art MTL methods.\n \n"
            },
            "slug": "Learning-Multi-Level-Task-Groups-in-Multi-Task-Han-Zhang",
            "title": {
                "fragments": [],
                "text": "Learning Multi-Level Task Groups in Multi-Task Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This paper proposes a Multi-Level Task Grouping (MeTaG) method to learn the multi-level grouping structure instead of only one level among tasks, and provides theoretical analysis to show that under certain conditions the MeTaG model can recover the true parameter matrix and the true task groups in each level with high probability."
            },
            "venue": {
                "fragments": [],
                "text": "AAAI"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2925921"
                        ],
                        "name": "Pinghua Gong",
                        "slug": "Pinghua-Gong",
                        "structuredName": {
                            "firstName": "Pinghua",
                            "lastName": "Gong",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Pinghua Gong"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144030870"
                        ],
                        "name": "Jieping Ye",
                        "slug": "Jieping-Ye",
                        "structuredName": {
                            "firstName": "Jieping",
                            "lastName": "Ye",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jieping Ye"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "14966740"
                        ],
                        "name": "Changshui Zhang",
                        "slug": "Changshui-Zhang",
                        "structuredName": {
                            "firstName": "Changshui",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Changshui Zhang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 160,
                                "start": 156
                            }
                        ],
                        "text": "In order to obtain a smaller subset of useful features for multiple tasks, a capped- p,1 penalty, which is defined as \u2211d i=1 min(\u2016wi\u2016p , \u03b8), is proposed in [11]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 862291,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d8feb336c1691aa82a7f655c4fb0f6751dbef277",
            "isKey": false,
            "numCitedBy": 133,
            "numCiting": 43,
            "paperAbstract": {
                "fragments": [],
                "text": "Multi-task sparse feature learning aims to improve the generalization performance by exploiting the shared features among tasks. It has been successfully applied to many applications including computer vision and biomedical informatics. Most of the existing multi-task sparse feature learning algorithms are formulated as a convex sparse regularization problem, which is usually suboptimal, due to its looseness for approximating an [Formula: see text]-type regularizer. In this paper, we propose a non-convex formulation for multi-task sparse feature learning based on a novel regularizer. To solve the non-convex optimization problem, we propose a Multi-Stage Multi-Task Feature Learning (MSMTFL) algorithm. Moreover, we present a detailed theoretical analysis showing that MSMTFL achieves a better parameter estimation error bound than the convex formulation. Empirical studies on both synthetic and real-world data sets demonstrate the effectiveness of MSMTFL in comparison with the state of the art multi-task sparse feature learning algorithms."
            },
            "slug": "Multi-stage-multi-task-feature-learning-Gong-Ye",
            "title": {
                "fragments": [],
                "text": "Multi-stage multi-task feature learning"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "A non-convex formulation for multi-task sparse feature learning based on a novel regularizer is proposed and a detailed theoretical analysis is presented showing that MSMTFL achieves a better parameter estimation error bound than the convex formulation."
            },
            "venue": {
                "fragments": [],
                "text": "J. Mach. Learn. Res."
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46867608"
                        ],
                        "name": "Yu Zhang",
                        "slug": "Yu-Zhang",
                        "structuredName": {
                            "firstName": "Yu",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yu Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1739816"
                        ],
                        "name": "D. Yeung",
                        "slug": "D.-Yeung",
                        "structuredName": {
                            "firstName": "Dit-Yan",
                            "lastName": "Yeung",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Yeung"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 63,
                                "start": 59
                            }
                        ],
                        "text": "In [79], an online algorithm is proposed for theMTRLmethod [44] by updating model parameters and task covariance together."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 81,
                                "start": 77
                            }
                        ],
                        "text": "In [82], a parallelMTLmethod is devised to solve a subproblemof theMTRLmodel [44], which also occurs in many regularized methodsbelonging to the task-relation learning approach."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 95,
                                "start": 88
                            }
                        ],
                        "text": "A regularized model called multi-taskrelationship learning (MTRL) method is proposed in [44,45] by placing a matrix-variate normal prior onW:W \u223c MN (0, I, ), whereMN (M,A,B) denotes a matrix-variate normal distribution with M, A, B as the mean, row covariance and column covariance."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 54,
                                "start": 48
                            }
                        ],
                        "text": "These twomethods extend theMTFLand MTRL methods [5,44], two models in the MTSL setting, to the clustering scenario and the formulations in the proposed two multi-task-clustering methods are almost identical to those in the MTFL and MTRL methods, with the only difference being"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 18237764,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c993431e61e524565cd2e86435978e1b47067949",
            "isKey": false,
            "numCitedBy": 422,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "Multi-task learning is a learning paradigm which seeks to improve the generalization performance of a learning task with the help of some other related tasks. In this paper, we propose a regularization formulation for learning the relationships between tasks in multi-task learning. This formulation can be viewed as a novel generalization of the regularization framework for single-task learning. Besides modeling positive task correlation, our method, called multi-task relationship learning (MTRL), can also describe negative task correlation and identify outlier tasks based on the same underlying principle. Under this regularization framework, the objective function of MTRL is convex. For efficiency, we use an alternating method to learn the optimal model parameters for each task as well as the relationships between tasks. We study MTRL in the symmetric multi-task learning setting and then generalize it to the asymmetric setting as well. We also study the relationships between MTRL and some existing multi-task learning methods. Experiments conducted on a toy problem as well as several benchmark data sets demonstrate the effectiveness of MTRL."
            },
            "slug": "A-Convex-Formulation-for-Learning-Task-in-Learning-Zhang-Yeung",
            "title": {
                "fragments": [],
                "text": "A Convex Formulation for Learning Task Relationships in Multi-Task Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This paper proposes a regularization formulation for learning the relationships between tasks in multi-task learning, called MTRL, which can also describe negative task correlation and identify outlier tasks based on the same underlying principle."
            },
            "venue": {
                "fragments": [],
                "text": "UAI"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46867608"
                        ],
                        "name": "Yu Zhang",
                        "slug": "Yu-Zhang",
                        "structuredName": {
                            "firstName": "Yu",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yu Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1739816"
                        ],
                        "name": "D. Yeung",
                        "slug": "D.-Yeung",
                        "structuredName": {
                            "firstName": "Dit-Yan",
                            "lastName": "Yeung",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Yeung"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 134,
                                "start": 130
                            }
                        ],
                        "text": "Since the prior used in the MTRLmethod implies thatWTW follows aWishart distribution as W(0, ), the MTRL method is generalized in [50] by studying a high-order prior: (WTW)t \u223c W(0, ), where t is a positive integer."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2238781,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4d994974f19fcffd31ca6dcc1159f1f978174f4a",
            "isKey": false,
            "numCitedBy": 33,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "Multi-task learning is a way of bringing inductive transfer studied in human learning to the machine learning community. A central issue in multitask learning is to model the relationships between tasks appropriately and exploit them to aid the simultaneous learning of multiple tasks effectively. While some recent methods model and learn the task relationships from data automatically, only pairwise relationships can be represented by them. In this paper, we propose a new model, called Multi-Task High-Order relationship Learning (MTHOL), which extends in a novel way the use of pairwise task relationships to high-order task relationships. We first propose an alternative formulation of an existing multi-task learning method. Based on the new formulation, we propose a high-order generalization leading to a new prior for the model parameters of different tasks. We then propose a new probabilistic model for multi-task learning and validate it empirically on some benchmark datasets."
            },
            "slug": "Learning-High-Order-Task-Relationships-in-Learning-Zhang-Yeung",
            "title": {
                "fragments": [],
                "text": "Learning High-Order Task Relationships in Multi-Task Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "A new model, called Multi-Task High-Order relationship Learning (MTHOL), which extends in a novel way the use of pairwise task relationships to high-order task relationships and proposes a new probabilistic model for multi-task learning."
            },
            "venue": {
                "fragments": [],
                "text": "IJCAI"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50560709"
                        ],
                        "name": "Jintao Zhang",
                        "slug": "Jintao-Zhang",
                        "structuredName": {
                            "firstName": "Jintao",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jintao Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144733837"
                        ],
                        "name": "Jun Huan",
                        "slug": "Jun-Huan",
                        "structuredName": {
                            "firstName": "Jun",
                            "lastName": "Huan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jun Huan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 85,
                                "start": 78
                            }
                        ],
                        "text": "As a multi-task extension ofmulti-view learning,multi-taskmulti-view learning [80,81] hopes to exploit multiple multiview learning problems to improve the performance over eachmulti-view learning problemby leveraging useful information contained in related tasks."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 7,
                                "start": 3
                            }
                        ],
                        "text": "In [81], different views in each task achieve consensus on unlabeled data and different tasks are learned by exploiting a priori information as in [38] or learning task relations as the MTRLmethod did."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6252604,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5f1ad89c6fb753a88622fedbc09be95520478ccf",
            "isKey": false,
            "numCitedBy": 113,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "In many real-world applications, it is becoming common to have data extracted from multiple diverse sources, known as \"multi-view\" data. Multi-view learning (MVL) has been widely studied in many applications, but existing MVL methods learn a single task individually. In this paper, we study a new direction of multi-view learning where there are multiple related tasks with multi-view data (i.e. multi-view multi-task learning, or MVMT Learning). In our MVMT learning methods, we learn a linear mapping for each view in each task. In a single task, we use co-regularization to obtain functions that are in-agreement with each other on the unlabeled samples and achieve low classification errors on the labeled samples simultaneously. Cross different tasks, additional regularization functions are utilized to ensure the functions that we learn in each view are similar. We also developed two extensions of the MVMT learning algorithm. One extension handles missing views and the other handles non-uniformly related tasks. Experimental studies on three real-world data sets demonstrate that our MVMT methods significantly outperform the existing state-of-the-art methods."
            },
            "slug": "Inductive-multi-task-learning-with-multiple-view-Zhang-Huan",
            "title": {
                "fragments": [],
                "text": "Inductive multi-task learning with multiple view data"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "In this paper, a new direction of multi-view learning where there are multiple related tasks with multi- view data is studied, or MVMT Learning, which learns a linear mapping for each view in each task."
            },
            "venue": {
                "fragments": [],
                "text": "KDD"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46867608"
                        ],
                        "name": "Yu Zhang",
                        "slug": "Yu-Zhang",
                        "structuredName": {
                            "firstName": "Yu",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yu Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1739816"
                        ],
                        "name": "D. Yeung",
                        "slug": "D.-Yeung",
                        "structuredName": {
                            "firstName": "Dit-Yan",
                            "lastName": "Yeung",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Yeung"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 58,
                                "start": 54
                            }
                        ],
                        "text": "The MTRL method is generalized to multi-task boosting [46] and multi-label learning [47], where each label is treated as a task, and extended to learn sparse task relations in [48]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14016961,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8b0b47d97ce12e0116ea7c81ddb4db585715f9fd",
            "isKey": false,
            "numCitedBy": 38,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "Multi-task learning aims at improving the performance of one learning task with the help of other related tasks. It is particularly useful when each task has very limited labeled data. A central issue in multi-task learning is to learn and exploit the relationships between tasks. In this paper, we generalize boosting to the multi-task learning setting and propose a method called multi-task boosting (MTBoost). Different tasks in MTBoost share the same base learners but with different weights which are related to the estimated task relationships in each iteration. In MTBoost, unlike ordinary boosting methods, the base learners, weights and task covariances are learned together in an integrated fashion using an alternating optimization procedure. We conduct theoretical analysis on the convergence of MTBoost and also empirical analysis comparing it with several related methods."
            },
            "slug": "Multi-Task-Boosting-by-Exploiting-Task-Zhang-Yeung",
            "title": {
                "fragments": [],
                "text": "Multi-Task Boosting by Exploiting Task Relationships"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This paper proposes a method called MTBoost, which generalizes boosting to the multi-task learning setting and conducts theoretical analysis on the convergence of MTBoost and also empirical analysis comparing it with several related methods."
            },
            "venue": {
                "fragments": [],
                "text": "ECML/PKDD"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46867608"
                        ],
                        "name": "Yu Zhang",
                        "slug": "Yu-Zhang",
                        "structuredName": {
                            "firstName": "Yu",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yu Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1739816"
                        ],
                        "name": "D. Yeung",
                        "slug": "D.-Yeung",
                        "structuredName": {
                            "firstName": "Dit-Yan",
                            "lastName": "Yeung",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Yeung"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 124,
                                "start": 120
                            }
                        ],
                        "text": "In order to utilize Bayesian averaging to achieve better performance, a multi-task generalized t process is proposed in [43] by placing an inverse-Wishart prior on ."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 12213941,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e7fb16842536659580b839e5a859bafe20cb0dd8",
            "isKey": false,
            "numCitedBy": 64,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "Multi-task learning seeks to improve the generalization performance of a learning task with the help of other related learning tasks. Among the multi-task learning methods proposed thus far, Bonilla et al.\u2019s method (Bonilla et al., 2008) provides a novel multi-task extension of Gaussian process (GP) by using a task covariance matrix to model the relationships between tasks. However, learning the task covariance matrix directly has both computational and representational drawbacks. In this paper, we propose a Bayesian extension by modeling the task covariance matrix as a random matrix with an inverse-Wishart prior and integrating it out to achieve Bayesian model averaging. To make the computation feasible, we first give an alternative weight-space view of Bonilla et al.\u2019s multi-task GP model and then integrate out the task covariance matrix in the model, leading to a multi-task generalized t process (MTGTP). For the likelihood, we use a generalized t noise model which, together with the generalized t process prior, brings about the robustness advantage as well as an analytical form for the marginal likelihood. In order to specify the inverse-Wishart prior, we use the maximum mean discrepancy (MMD) statistic to estimate the parameter matrix of the inverse-Wishart prior. Moreover, we investigate some theoretical properties of MTGTP, such as its asymptotic analysis and learning curve. Comparative experimental studies on two common multi-task learning applications show very promising results. Appearing in Proceedings of the 13 International Conference on Artificial Intelligence and Statistics (AISTATS) 2010, Chia Laguna Resort, Sardinia, Italy. Volume 9 of JMLR: W&CP 9. Copyright 2010 by the authors."
            },
            "slug": "Multi-Task-Learning-using-Generalized-t-Process-Zhang-Yeung",
            "title": {
                "fragments": [],
                "text": "Multi-Task Learning using Generalized t Process"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A Bayesian extension is proposed by modeling the task covariance matrix as a random matrix with an inverse-Wishart prior and integrating it out to achieve Bayesian model averaging in a multi-task generalized t process (MTGTP)."
            },
            "venue": {
                "fragments": [],
                "text": "AISTATS"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3003084"
                        ],
                        "name": "S. Parameswaran",
                        "slug": "S.-Parameswaran",
                        "structuredName": {
                            "firstName": "Shibin",
                            "lastName": "Parameswaran",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Parameswaran"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7446832"
                        ],
                        "name": "Kilian Q. Weinberger",
                        "slug": "Kilian-Q.-Weinberger",
                        "structuredName": {
                            "firstName": "Kilian",
                            "lastName": "Weinberger",
                            "middleNames": [
                                "Q."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kilian Q. Weinberger"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 99,
                                "start": 92
                            }
                        ],
                        "text": "In earlier studies on this approach, task relations are either defined by model assumptions [36,37] or given by a priori information [38\u201341]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 11319685,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "aa4b666c04016063c8039ad01914b394a9b2f4a6",
            "isKey": false,
            "numCitedBy": 277,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "Multi-task learning (MTL) improves the prediction performance on multiple, different but related, learning problems through shared parameters or representations. One of the most prominent multi-task learning algorithms is an extension to support vector machines (svm) by Evgeniou et al. [15]. Although very elegant, multi-task svm is inherently restricted by the fact that support vector machines require each class to be addressed explicitly with its own weight vector which, in a multi-task setting, requires the different learning tasks to share the same set of classes. This paper proposes an alternative formulation for multi-task learning by extending the recently published large margin nearest neighbor (1mnn) algorithm to the MTL paradigm. Instead of relying on separating hyperplanes, its decision function is based on the nearest neighbor rule which inherently extends to many classes and becomes a natural fit for multi-task learning. We evaluate the resulting multi-task 1mnn on real-world insurance data and speech classification problems and show that it consistently outperforms single-task kNN under several metrics and state-of-the-art MTL classifiers."
            },
            "slug": "Large-Margin-Multi-Task-Metric-Learning-Parameswaran-Weinberger",
            "title": {
                "fragments": [],
                "text": "Large Margin Multi-Task Metric Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This paper proposes an alternative formulation for multi-task learning by extending the recently published large margin nearest neighbor (1mnn) algorithm to the MTL paradigm and shows that it consistently outperforms single-task kNN under several metrics and state-of-the-art MTL classifiers."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145727186"
                        ],
                        "name": "R. Caruana",
                        "slug": "R.-Caruana",
                        "structuredName": {
                            "firstName": "Rich",
                            "lastName": "Caruana",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Caruana"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 45998148,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "161ffb54a3fdf0715b198bb57bd22f910242eb49",
            "isKey": false,
            "numCitedBy": 3257,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Multitask Learning is an approach to inductive transfer that improves generalization by using the domain information contained in the training signals of related tasks as an inductive bias. It does this by learning tasks in parallel while using a shared representation; what is learned for each task can help other tasks be learned better. This paper reviews prior work on MTL, presents new evidence that MTL in backprop nets discovers task relatedness without the need of supervisory signals, and presents new results for MTL with k-nearest neighbor and kernel regression. In this paper we demonstrate multitask learning in three domains. We explain how multitask learning works, and show that there are many opportunities for multitask learning in real domains. We present an algorithm and results for multitask learning with case-based methods like k-nearest neighbor and kernel regression, and sketch an algorithm for multitask learning in decision trees. Because multitask learning works, can be applied to many different kinds of domains, and can be used with different learning algorithms, we conjecture there will be many opportunities for its use on real-world problems."
            },
            "slug": "Multitask-Learning-Caruana",
            "title": {
                "fragments": [],
                "text": "Multitask Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "Prior work on MTL is reviewed, new evidence that MTL in backprop nets discovers task relatedness without the need of supervisory signals is presented, and new results for MTL with k-nearest neighbor and kernel regression are presented."
            },
            "venue": {
                "fragments": [],
                "text": "Machine Learning"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3263887"
                        ],
                        "name": "Christian Widmer",
                        "slug": "Christian-Widmer",
                        "structuredName": {
                            "firstName": "Christian",
                            "lastName": "Widmer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christian Widmer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2623567"
                        ],
                        "name": "Nora C. Toussaint",
                        "slug": "Nora-C.-Toussaint",
                        "structuredName": {
                            "firstName": "Nora",
                            "lastName": "Toussaint",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nora C. Toussaint"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1783941"
                        ],
                        "name": "Y. Altun",
                        "slug": "Y.-Altun",
                        "structuredName": {
                            "firstName": "Yasemin",
                            "lastName": "Altun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Altun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2414086"
                        ],
                        "name": "G. R\u00e4tsch",
                        "slug": "G.-R\u00e4tsch",
                        "structuredName": {
                            "firstName": "Gunnar",
                            "lastName": "R\u00e4tsch",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. R\u00e4tsch"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 111,
                                "start": 106
                            }
                        ],
                        "text": "populations [104], construction of personalized brain\u2013computer interfaces [105], MHC-I binding prediction [106], splice-site prediction [106], protein subcellular location prediction [107], Alzheimer\u2019s disease assessment scale cognitive subscale [108], prediction of cognitive outcomes from neuroimaging measures in Alzheimer\u2019s disease [109], identification of longitudinal phenotypic markers for Alzheimer\u2019s disease progression prediction [110], prioritization of disease genes [111], biological image analysis based on natural images [20], survival analysis [112], and multiple genetic trait prediction [113]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7388181,
            "fieldsOfStudy": [
                "Computer Science",
                "Biology"
            ],
            "id": "895af6c7f3008f20e5109d89dadbc2bb5cdc7c17",
            "isKey": false,
            "numCitedBy": 66,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "BackgroundThe lack of sufficient training data is the limiting factor for many Machine Learning applications in Computational Biology. If data is available for several different but related problem domains, Multitask Learning algorithms can be used to learn a model based on all available information. In Bioinformatics, many problems can be cast into the Multitask Learning scenario by incorporating data from several organisms. However, combining information from several tasks requires careful consideration of the degree of similarity between tasks. Our proposed method simultaneously learns or refines the similarity between tasks along with the Multitask Learning classifier. This is done by formulating the Multitask Learning problem as Multiple Kernel Learning, using the recently published q-Norm MKL algorithm.ResultsWe demonstrate the performance of our method on two problems from Computational Biology. First, we show that our method is able to improve performance on a splice site dataset with given hierarchical task structure by refining the task relationships. Second, we consider an MHC-I dataset, for which we assume no knowledge about the degree of task relatedness. Here, we are able to learn the task similarities ab initio along with the Multitask classifiers. In both cases, we outperform baseline methods that we compare against.ConclusionsWe present a novel approach to Multitask Learning that is capable of learning task similarity along with the classifiers. The framework is very general as it allows to incorporate prior knowledge about tasks relationships if available, but is also able to identify task similarities in absence of such prior information. Both variants show promising results in applications from Computational Biology."
            },
            "slug": "Inferring-latent-task-structure-for-Multitask-by-Widmer-Toussaint",
            "title": {
                "fragments": [],
                "text": "Inferring latent task structure for Multitask Learning by Multiple Kernel Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A novel approach to Multitask Learning that is capable of learning task similarity along with the classifiers and is able to identify task similarities in absence of such prior information is presented."
            },
            "venue": {
                "fragments": [],
                "text": "BMC Bioinformatics"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145462236"
                        ],
                        "name": "Laurent Jacob",
                        "slug": "Laurent-Jacob",
                        "structuredName": {
                            "firstName": "Laurent",
                            "lastName": "Jacob",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Laurent Jacob"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144570279"
                        ],
                        "name": "F. Bach",
                        "slug": "F.-Bach",
                        "structuredName": {
                            "firstName": "Francis",
                            "lastName": "Bach",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Bach"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152303545"
                        ],
                        "name": "Jean-Philippe Vert",
                        "slug": "Jean-Philippe-Vert",
                        "structuredName": {
                            "firstName": "Jean-Philippe",
                            "lastName": "Vert",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jean-Philippe Vert"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 488434,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9491bcc1e54b52bea617283f7f716cf009068bce",
            "isKey": false,
            "numCitedBy": 450,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "In multi-task learning several related tasks are considered simultaneously, with the hope that by an appropriate sharing of information across tasks, each task may benefit from the others. In the context of learning linear functions for supervised classification or regression, this can be achieved by including a priori information about the weight vectors associated with the tasks, and how they are expected to be related to each other. In this paper, we assume that tasks are clustered into groups, which are unknown beforehand, and that tasks within a group have similar weight vectors. We design a new spectral norm that encodes this a priori assumption, without the prior knowledge of the partition of tasks into groups, resulting in a new convex optimization formulation for multi-task learning. We show in simulations on synthetic examples and on the IEDB MHC-I binding dataset, that our approach outperforms well-known convex methods for multi-task learning, as well as related non-convex methods dedicated to the same problem."
            },
            "slug": "Clustered-Multi-Task-Learning:-A-Convex-Formulation-Jacob-Bach",
            "title": {
                "fragments": [],
                "text": "Clustered Multi-Task Learning: A Convex Formulation"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A new spectral norm is designed that encodes this a priori assumption that tasks are clustered into groups, which are unknown beforehand, and that tasks within a group have similar weight vectors, resulting in a new convex optimization formulation for multi-task learning."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2112660813"
                        ],
                        "name": "Lei Han",
                        "slug": "Lei-Han",
                        "structuredName": {
                            "firstName": "Lei",
                            "lastName": "Han",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lei Han"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2153632326"
                        ],
                        "name": "Yu Zhang",
                        "slug": "Yu-Zhang",
                        "structuredName": {
                            "firstName": "Yu",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yu Zhang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 104,
                                "start": 100
                            }
                        ],
                        "text": "Unlike the aforementioned methods where different component matrices have no direct interaction, in [60], with direct connections between component matrices at successive levels, the complex hierarchical/tree structure among tasks can be learned from data."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 71,
                                "start": 67
                            }
                        ],
                        "text": "|w j i\u22121 \u2212 wk i\u22121| \u2265 |w j i \u2212 wk i | \u2200i \u2265 2 \u2200k > j , is devised in [60] to help make the whole structure become a tree."
                    },
                    "intents": []
                }
            ],
            "corpusId": 9376286,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1d3a524e651f7454190032ffb65aac1d35292467",
            "isKey": false,
            "numCitedBy": 60,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "In multi-task learning (MTL), multiple related tasks are learned jointly by sharing information according to task relations. One promising approach is to utilize the given tree structure, which describes the hierarchical relations among tasks, to learn model parameters under the regularization framework. However, such a priori information is rarely available in most applications. To the best of our knowledge, there is no work to learn the tree structure among tasks and model parameters simultaneously under the regularization framework and in this paper, we develop a TAsk Tree (TAT) model for MTL to achieve this. By specifying the number of layers in the tree as H, the TAT method decomposes the parameter matrix into H component matrices, each of which corresponds to the model parameters in each layer of the tree. In order to learn the tree structure, we devise sequential constraints to make the distance between the parameters in the component matrices corresponding to each pair of tasks decrease over layers, and hence the component parameters will keep fused until the topmost layer, once they become fused in a layer. Moreover, to make the component parameters have chance to fuse in different layers, we develop a structural sparsity regularizer, which is the sum of the l2 norm on the pairwise difference among the component parameters, to learn layer-specific task structure. In order to solve the resulting non-convex objective function, we use the general iterative shrinkage and thresholding (GIST) method. By using the alternating direction method of multipliers (ADMM) method, we decompose the proximal problem in the GIST method into three independent subproblems, where a key subproblem with the sequential constraints has an efficient solution as the other two subproblems do. We also provide some theoretical analysis for the TAT model. Experiments on both synthetic and real-world datasets show the effectiveness of the TAT model."
            },
            "slug": "Learning-Tree-Structure-in-Multi-Task-Learning-Han-Zhang",
            "title": {
                "fragments": [],
                "text": "Learning Tree Structure in Multi-Task Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A TAsk Tree (TAT) model for MTL is developed, which devise sequential constraints to make the distance between the parameters in the component matrices corresponding to each pair of tasks decrease over layers, and hence the component parameters will keep fused until the topmost layer, once they become fused in a layer."
            },
            "venue": {
                "fragments": [],
                "text": "KDD"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2853049"
                        ],
                        "name": "Z. Kang",
                        "slug": "Z.-Kang",
                        "structuredName": {
                            "firstName": "Zhuoliang",
                            "lastName": "Kang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Z. Kang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1794409"
                        ],
                        "name": "K. Grauman",
                        "slug": "K.-Grauman",
                        "structuredName": {
                            "firstName": "Kristen",
                            "lastName": "Grauman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Grauman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145757665"
                        ],
                        "name": "Fei Sha",
                        "slug": "Fei-Sha",
                        "structuredName": {
                            "firstName": "Fei",
                            "lastName": "Sha",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Fei Sha"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 35,
                                "start": 31
                            }
                        ],
                        "text": "The MTFL method is extended in [32] to the case of multiple clusters, where each cluster applies the MTFL method, and in order to learn the cluster structure, a regularizer, i."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 12817931,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d2d35fc47bfcd9bbcdf1905b23be6e5dcee05e9c",
            "isKey": false,
            "numCitedBy": 327,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "In multi-task learning (MTL), multiple tasks are learnt jointly. A major assumption for this paradigm is that all those tasks are indeed related so that the joint training is appropriate and beneficial. In this paper, we study the problem of multi-task learning of shared feature representations among tasks, while simultaneously determining \"with whom\" each task should share. We formulate the problem as a mixed integer programming and provide an alternating minimization technique to solve the optimization problem of jointly identifying grouping structures and parameters. The algorithm mono-tonically decreases the objective function and converges to a local optimum. Compared to the standard MTL paradigm where all tasks are in a single group, our algorithm improves its performance with statistical significance for three out of the four datasets we have studied. We also demonstrate its advantage over other task grouping techniques investigated in literature."
            },
            "slug": "Learning-with-Whom-to-Share-in-Multi-task-Feature-Kang-Grauman",
            "title": {
                "fragments": [],
                "text": "Learning with Whom to Share in Multi-task Feature Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This paper forms the problem of multi-task learning of shared feature representations among tasks, while simultaneously determining \"with whom\" each task should share as a mixed integer programming and provides an alternating minimization technique to solve the optimization problem of jointly identifying grouping structures and parameters."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46867608"
                        ],
                        "name": "Yu Zhang",
                        "slug": "Yu-Zhang",
                        "structuredName": {
                            "firstName": "Yu",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yu Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1739816"
                        ],
                        "name": "D. Yeung",
                        "slug": "D.-Yeung",
                        "structuredName": {
                            "firstName": "Dit-Yan",
                            "lastName": "Yeung",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Yeung"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 95,
                                "start": 88
                            }
                        ],
                        "text": "A regularized model called multi-taskrelationship learning (MTRL) method is proposed in [44,45] by placing a matrix-variate normal prior onW:W \u223c MN (0, I, ), whereMN (M,A,B) denotes a matrix-variate normal distribution with M, A, B as the mean, row covariance and column covariance."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14879495,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f96ffb3a66f757d78ccf01240710762e658ddf4e",
            "isKey": false,
            "numCitedBy": 106,
            "numCiting": 61,
            "paperAbstract": {
                "fragments": [],
                "text": "Multitask learning is a learning paradigm that seeks to improve the generalization performance of a learning task with the help of some other related tasks. In this article, we propose a regularization approach to learning the relationships between tasks in multitask learning. This approach can be viewed as a novel generalization of the regularized formulation for single-task learning. Besides modeling positive task correlation, our approach\u2014multitask relationship learning (MTRL)\u2014can also describe negative task correlation and identify outlier tasks based on the same underlying principle. By utilizing a matrix-variate normal distribution as a prior on the model parameters of all tasks, our MTRL method has a jointly convex objective function. For efficiency, we use an alternating method to learn the optimal model parameters for each task as well as the relationships between tasks. We study MTRL in the symmetric multitask learning setting and then generalize it to the asymmetric setting as well. We also discuss some variants of the regularization approach to demonstrate the use of other matrix-variate priors for learning task relationships. Moreover, to gain more insight into our model, we also study the relationships between MTRL and some existing multitask learning methods. Experiments conducted on a toy problem as well as several benchmark datasets demonstrate the effectiveness of MTRL as well as its high interpretability revealed by the task covariance matrix."
            },
            "slug": "A-Regularization-Approach-to-Learning-Task-in-Zhang-Yeung",
            "title": {
                "fragments": [],
                "text": "A Regularization Approach to Learning Task Relationships in Multitask Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A regularization approach to learning the relationships between tasks in multitask learning that can also describe negative task correlation and identify outlier tasks based on the same underlying principle is proposed."
            },
            "venue": {
                "fragments": [],
                "text": "ACM Trans. Knowl. Discov. Data"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108513551"
                        ],
                        "name": "Jianhui Chen",
                        "slug": "Jianhui-Chen",
                        "structuredName": {
                            "firstName": "Jianhui",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jianhui Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145487992"
                        ],
                        "name": "Jiayu Zhou",
                        "slug": "Jiayu-Zhou",
                        "structuredName": {
                            "firstName": "Jiayu",
                            "lastName": "Zhou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jiayu Zhou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144030870"
                        ],
                        "name": "Jieping Ye",
                        "slug": "Jieping-Ye",
                        "structuredName": {
                            "firstName": "Jieping",
                            "lastName": "Ye",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jieping Ye"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 31,
                                "start": 24
                            }
                        ],
                        "text": "The choices of g (U) in [54,55] enforce U to be low-rank via the trace norm as the regularizer and constraint, respectively."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 99,
                                "start": 92
                            }
                        ],
                        "text": "For V, h(V) makes it sparse via the 1 norm in [53,54] and column-sparse via the 2,1 norm in [55,56], while in [57], h(V) penalizes the complexity of V via the squared Frobenius norm."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2098528,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1248ec7fae6c2b34a40cc0b99100227af6d2e980",
            "isKey": false,
            "numCitedBy": 290,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": "Multi-task learning (MTL) aims at improving the generalization performance by utilizing the intrinsic relationships among multiple related tasks. A key assumption in most MTL algorithms is that all tasks are related, which, however, may not be the case in many real-world applications. In this paper, we propose a robust multi-task learning (RMTL) algorithm which learns multiple tasks simultaneously as well as identifies the irrelevant (outlier) tasks. Specifically, the proposed RMTL algorithm captures the task relationships using a low-rank structure, and simultaneously identifies the outlier tasks using a group-sparse structure. The proposed RMTL algorithm is formulated as a non-smooth convex (unconstrained) optimization problem. We propose to adopt the accelerated proximal method (APM) for solving such an optimization problem. The key component in APM is the computation of the proximal operator, which can be shown to admit an analytic solution. We also theoretically analyze the effectiveness of the RMTL algorithm. In particular, we derive a key property of the optimal solution to RMTL; moreover, based on this key property, we establish a theoretical bound for characterizing the learning performance of RMTL. Our experimental results on benchmark data sets demonstrate the effectiveness and efficiency of the proposed algorithm."
            },
            "slug": "Integrating-low-rank-and-group-sparse-structures-Chen-Zhou",
            "title": {
                "fragments": [],
                "text": "Integrating low-rank and group-sparse structures for robust multi-task learning"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "A robust multi-task learning algorithm which learns multiple tasks simultaneously as well as identifies the irrelevant (outlier) tasks, and derives a key property of the optimal solution to RMTL, which establishes a theoretical bound for characterizing the learning performance of R MTL."
            },
            "venue": {
                "fragments": [],
                "text": "KDD"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2439765"
                        ],
                        "name": "Daniele Calandriello",
                        "slug": "Daniele-Calandriello",
                        "structuredName": {
                            "firstName": "Daniele",
                            "lastName": "Calandriello",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Daniele Calandriello"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3254390"
                        ],
                        "name": "A. Lazaric",
                        "slug": "A.-Lazaric",
                        "structuredName": {
                            "firstName": "Alessandro",
                            "lastName": "Lazaric",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Lazaric"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1792167"
                        ],
                        "name": "Marcello Restelli",
                        "slug": "Marcello-Restelli",
                        "structuredName": {
                            "firstName": "Marcello",
                            "lastName": "Restelli",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Marcello Restelli"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 7,
                                "start": 3
                            }
                        ],
                        "text": "In [72], the value functions in different tasks are assumed to share sparse parameters and it applies the multi-task feature selection method with the 2,1 regularization [8] and the MTFL method [5] to learn all the value functions simultaneously."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 7683572,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ea4cc7249645b5e3ea8ce65ed2c3b53383bd1e1b",
            "isKey": false,
            "numCitedBy": 62,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "In multi-task reinforcement learning (MTRL), the objective is to simultaneously learn multiple tasks and exploit their similarity to improve the performance w.r.t. single-task learning. In this paper we investigate the case when all the tasks can be accurately represented in a linear approximation space using the same small subset of the original (large) set of features. This is equivalent to assuming that the weight vectors of the task value functions are jointly sparse, i.e., the set of their non-zero components is small and it is shared across tasks. Building on existing results in multi-task regression, we develop two multi-task extensions of the fitted Q-iteration algorithm. While the first algorithm assumes that the tasks are jointly sparse in the given representation, the second one learns a transformation of the features in the attempt of finding a more sparse representation. For both algorithms we provide a sample complexity analysis and numerical simulations."
            },
            "slug": "Sparse-multi-task-reinforcement-learning-Calandriello-Lazaric",
            "title": {
                "fragments": [],
                "text": "Sparse multi-task reinforcement learning"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This paper develops two multi-task extensions of the fitted Q-iteration algorithm that assume that the tasks are jointly sparse in the given representation and learns a transformation of the features in the attempt of finding a more sparse representation."
            },
            "venue": {
                "fragments": [],
                "text": "Intelligenza Artificiale"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2055723368"
                        ],
                        "name": "Meng Fang",
                        "slug": "Meng-Fang",
                        "structuredName": {
                            "firstName": "Meng",
                            "lastName": "Fang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Meng Fang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143719920"
                        ],
                        "name": "D. Tao",
                        "slug": "D.-Tao",
                        "structuredName": {
                            "firstName": "Dacheng",
                            "lastName": "Tao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Tao"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 203,
                                "start": 199
                            }
                        ],
                        "text": "Moreover, a selection strategy, a tradeoffbetween the learning riskof a low-rankMTL model based on the trace-norm regularization and a confidence bound similar to multi-armed bandits, is proposed in [68]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 40685419,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "75d3aba4866c978b643f2fdcb9a45f8a84706b35",
            "isKey": false,
            "numCitedBy": 25,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "In multi-task learning, the multiple related tasks allow each one to benefit from the learning of the others, and labeling instances for one task can also affect the other tasks especially when the task has a small number of labeled data. Thus labeling effective instances across different learning tasks is important for improving the generalization error of all tasks. In this paper, we propose a new active multi-task learning paradigm, which selectively samples effective instances for multi-task learning. Inspired by the multi-armed bandits, which can balance the trade-off between the exploitation and exploration, we introduce a new active learning strategy and cast the selection procedure as a bandit framework. We consider both the risk of multi-task learner and the corresponding confidence bounds and our selection tries to balance this trade-off. Our proposed method is a sequential algorithm, which at each round maintains a sampling distribution on the pool of data, queries the label for an instance according to this distribution and updates the distribution based on the newly trained multi-task learner. We provide an implementation of our algorithm based on a popular multi-task learning algorithm that is trace-norm regularization method. Theoretical guarantees are developed by exploiting the Rademacher complexities. Comprehensive experiments show the effectiveness and efficiency of the proposed approach."
            },
            "slug": "Active-Multi-task-Learning-via-Bandits-Fang-Tao",
            "title": {
                "fragments": [],
                "text": "Active Multi-task Learning via Bandits"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This paper introduces a new active multi- task learning paradigm, which selectively samples effective instances for multi-task learning and cast the selection procedure as a bandit framework, and provides an implementation of the algorithm based on a popular multi- Task learning algorithm that is trace-norm regularization method."
            },
            "venue": {
                "fragments": [],
                "text": "SDM"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46867608"
                        ],
                        "name": "Yu Zhang",
                        "slug": "Yu-Zhang",
                        "structuredName": {
                            "firstName": "Yu",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yu Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1739816"
                        ],
                        "name": "D. Yeung",
                        "slug": "D.-Yeung",
                        "structuredName": {
                            "firstName": "Dit-Yan",
                            "lastName": "Yeung",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Yeung"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 82,
                                "start": 78
                            }
                        ],
                        "text": "Unlike [63,64], a semi-supervised multi-task regression method is proposed in [65], where each task adopts a Gaussian process and unlabeled data are used to define the kernel function, andGaussian processes in all the tasks share a common prior on kernel parameters."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2385031,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b120905e34e9a9cb157927e5d53f1b4158fcc9ea",
            "isKey": false,
            "numCitedBy": 63,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "Labeled data are needed for many machine learning applications but the amount available in some applications is scarce. Semi-supervised learning and multi-task learning are two of the approaches that have been proposed to alleviate this problem. In this paper, we seek to integrate these two approaches for regression applications. We first propose a new supervised multi-task regression method called SMTR, which is based on Gaussian processes (GP) with the assumption that the kernel parameters for all tasks share a common prior. We then incorporate unlabeled data into SMTR by changing the kernel function of the GP prior to a data-dependent kernel function, resulting in a semi-supervised extension of SMTR, called SSMTR. Moreover, we incorporate pairwise information into SSMTR to further boost the learning performance for applications in which such information is available. Experiments conducted on two commonly used data sets for multi-task regression demonstrate the effectiveness of our methods."
            },
            "slug": "Semi-Supervised-Multi-Task-Regression-Zhang-Yeung",
            "title": {
                "fragments": [],
                "text": "Semi-Supervised Multi-Task Regression"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This paper proposes a new supervised multi-task regression method called SMTR, which is based on Gaussian processes (GP) with the assumption that the kernel parameters for all tasks share a common prior, and incorporates unlabeled data into SMTR by changing the kernel function of the GP prior to a data-dependent kernel function, resulting in a semi-supervised extension, called SSMTR."
            },
            "venue": {
                "fragments": [],
                "text": "ECML/PKDD"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2112660813"
                        ],
                        "name": "Lei Han",
                        "slug": "Lei-Han",
                        "structuredName": {
                            "firstName": "Lei",
                            "lastName": "Han",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lei Han"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2153632326"
                        ],
                        "name": "Yu Zhang",
                        "slug": "Yu-Zhang",
                        "structuredName": {
                            "firstName": "Yu",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yu Zhang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 159,
                                "start": 155
                            }
                        ],
                        "text": "Similar to what the capped- p,1 penalty did to the p,1 norm, a variant of the trace-norm regularization called the capped-trace regularizer is proposed in [27] and defined as \u2211min(m,d) i=1 min(\u03bci (W), \u03b8), where \u03b8 is a parameter defined by users."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7872314,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c1c6ab77eeff0767fa200430eded567bdafaf1ae",
            "isKey": false,
            "numCitedBy": 47,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": "\n \n Multi-task learning (MTL) seeks to improve the generalization performance by sharing information among multiple tasks. Many existing MTL approaches aim to learn the low-rank structure on the weight matrix, which stores the model parameters of all tasks, to achieve task sharing, and as a consequence the trace norm regularization is widely used in the MTL literature. A major limitation of these approaches based on trace norm regularization is that all the singular values of the weight matrix are penalized simultaneously, leading to impaired estimation on recovering the larger singular values in the weight matrix. To address the issue, we propose a Reduced rAnk MUlti-Stage multi-tAsk learning (RAMUSA) method based on the recently proposed capped norms. Different from existing trace-norm-based MTL approaches which minimize the sum of all the singular values, the RAMUSA method uses a capped trace norm regularizer to minimize only the singular values smaller than some threshold. Due to the non-convexity of the capped trace norm, we develop a simple but well guaranteed multi-stage algorithm to learn the weight matrix iteratively. We theoretically prove that the estimation error at each stage in the proposed algorithm shrinks and finally achieves a lower upper-bound as the number of stages becomes large enough. Empirical studies on synthetic and real-world datasets demonstrate the effectiveness of the RAMUSA method in comparison with the state-of-the-art methods.\n \n"
            },
            "slug": "Multi-Stage-Multi-Task-Learning-with-Reduced-Rank-Han-Zhang",
            "title": {
                "fragments": [],
                "text": "Multi-Stage Multi-Task Learning with Reduced Rank"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A simple but well guaranteed multi-stage algorithm to learn the weight matrix iteratively based on the recently proposed capped norms and theoretically proves that the estimation error at each stage in the proposed algorithm shrinks and finally achieves a lower upper-bound as the number of stages becomes large enough."
            },
            "venue": {
                "fragments": [],
                "text": "AAAI"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1707242"
                        ],
                        "name": "Minh-Thang Luong",
                        "slug": "Minh-Thang-Luong",
                        "structuredName": {
                            "firstName": "Minh-Thang",
                            "lastName": "Luong",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Minh-Thang Luong"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2827616"
                        ],
                        "name": "Quoc V. Le",
                        "slug": "Quoc-V.-Le",
                        "structuredName": {
                            "firstName": "Quoc",
                            "lastName": "Le",
                            "middleNames": [
                                "V."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Quoc V. Le"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1701686"
                        ],
                        "name": "Ilya Sutskever",
                        "slug": "Ilya-Sutskever",
                        "structuredName": {
                            "firstName": "Ilya",
                            "lastName": "Sutskever",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ilya Sutskever"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1689108"
                        ],
                        "name": "Oriol Vinyals",
                        "slug": "Oriol-Vinyals",
                        "structuredName": {
                            "firstName": "Oriol",
                            "lastName": "Vinyals",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Oriol Vinyals"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40527594"
                        ],
                        "name": "Lukasz Kaiser",
                        "slug": "Lukasz-Kaiser",
                        "structuredName": {
                            "firstName": "Lukasz",
                            "lastName": "Kaiser",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lukasz Kaiser"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6954272,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d76c07211479e233f7c6a6f32d5346c983c5598f",
            "isKey": false,
            "numCitedBy": 683,
            "numCiting": 50,
            "paperAbstract": {
                "fragments": [],
                "text": "Sequence to sequence learning has recently emerged as a new paradigm in supervised learning. To date, most of its applications focused on only one task and not much work explored this framework for multiple tasks. This paper examines three multi-task learning (MTL) settings for sequence to sequence models: (a) the oneto-many setting - where the encoder is shared between several tasks such as machine translation and syntactic parsing, (b) the many-to-one setting - useful when only the decoder can be shared, as in the case of translation and image caption generation, and (c) the many-to-many setting - where multiple encoders and decoders are shared, which is the case with unsupervised objectives and translation. Our results show that training on a small amount of parsing and image caption data can improve the translation quality between English and German by up to 1.5 BLEU points over strong single-task baselines on the WMT benchmarks. Furthermore, we have established a new state-of-the-art result in constituent parsing with 93.0 F1. Lastly, we reveal interesting properties of the two unsupervised learning objectives, autoencoder and skip-thought, in the MTL context: autoencoder helps less in terms of perplexities but more on BLEU scores compared to skip-thought."
            },
            "slug": "Multi-task-Sequence-to-Sequence-Learning-Luong-Le",
            "title": {
                "fragments": [],
                "text": "Multi-task Sequence to Sequence Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The results show that training on a small amount of parsing and image caption data can improve the translation quality between English and German by up to 1.5 BLEU points over strong single-task baselines on the WMT benchmarks, and reveal interesting properties of the two unsupervised learning objectives, autoencoder and skip-thought, in the MTL context."
            },
            "venue": {
                "fragments": [],
                "text": "ICLR"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3428689"
                        ],
                        "name": "Giwoong Lee",
                        "slug": "Giwoong-Lee",
                        "structuredName": {
                            "firstName": "Giwoong",
                            "lastName": "Lee",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Giwoong Lee"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1720494"
                        ],
                        "name": "Eunho Yang",
                        "slug": "Eunho-Yang",
                        "structuredName": {
                            "firstName": "Eunho",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Eunho Yang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35788904"
                        ],
                        "name": "Sung Ju Hwang",
                        "slug": "Sung-Ju-Hwang",
                        "structuredName": {
                            "firstName": "Sung",
                            "lastName": "Hwang",
                            "middleNames": [
                                "Ju"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sung Ju Hwang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 7,
                                "start": 3
                            }
                        ],
                        "text": "In [51], a similar regularizer to that of the MTRL method is proposed by assuming a parametric form of as \u22121 = (Im \u2212 A)(Im \u2212 A)T , where A is an asymmetric task relation claimed in [51]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2354006,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f4669ac0185c2ca1a1cf6fe4f48234c6970c15af",
            "isKey": false,
            "numCitedBy": 77,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a novel multi-task learning method that minimizes the effect of negative transfer by allowing asymmetric transfer between the tasks based on task relatedness as well as the amount of individual task losses, which we refer to as Asymmetric Multi-task Learning (AMTL). To tackle this problem, we couple multiple tasks via a sparse, directed regularization graph, that enforces each task parameter to be reconstructed as a sparse combination of other tasks selected based on the task-wise loss. We present two different algorithms that jointly learn the task predictors as well as the regularization graph. The first algorithm solves for the original learning objective using alternative optimization, and the second algorithm solves an approximation of it using curriculum learning strategy, that learns one task at a time. We perform experiments on multiple datasets for classification and regression, on which we obtain significant improvements in performance over the single task learning and existing multitask learning models."
            },
            "slug": "Asymmetric-multi-task-learning-based-on-task-and-Lee-Yang",
            "title": {
                "fragments": [],
                "text": "Asymmetric multi-task learning based on task relatedness and loss"
            },
            "tldr": {
                "abstractSimilarityScore": 94,
                "text": "A novel multi-task learning method that minimizes the effect of negative transfer by allowing asymmetric transfer between the tasks based on task relatedness as well as the amount of individual task losses is proposed, which is referred to as Asymmetric Multi-task Learning (AMTL)."
            },
            "venue": {
                "fragments": [],
                "text": "ICML 2016"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1801089"
                        ],
                        "name": "T. Evgeniou",
                        "slug": "T.-Evgeniou",
                        "structuredName": {
                            "firstName": "Theodoros",
                            "lastName": "Evgeniou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Evgeniou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1704699"
                        ],
                        "name": "M. Pontil",
                        "slug": "M.-Pontil",
                        "structuredName": {
                            "firstName": "Massimiliano",
                            "lastName": "Pontil",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Pontil"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 99,
                                "start": 92
                            }
                        ],
                        "text": "In earlier studies on this approach, task relations are either defined by model assumptions [36,37] or given by a priori information [38\u201341]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 49,
                                "start": 45
                            }
                        ],
                        "text": "Here s (Wt) uses the regularizer proposed in [36] to enforce different columns inWt to be close to their average."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 719551,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e219a61354d972a28954e655a7c53373508a08b6",
            "isKey": false,
            "numCitedBy": 1468,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "Past empirical work has shown that learning multiple related tasks from data simultaneously can be advantageous in terms of predictive performance relative to learning these tasks independently. In this paper we present an approach to multi--task learning based on the minimization of regularization functionals similar to existing ones, such as the one for Support Vector Machines (SVMs), that have been successfully used in the past for single--task learning. Our approach allows to model the relation between tasks in terms of a novel kernel function that uses a task--coupling parameter. We implement an instance of the proposed approach similar to SVMs and test it empirically using simulated as well as real data. The experimental results show that the proposed method performs better than existing multi--task learning methods and largely outperforms single--task learning using SVMs."
            },
            "slug": "Regularized-multi--task-learning-Evgeniou-Pontil",
            "title": {
                "fragments": [],
                "text": "Regularized multi--task learning"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "An approach to multi--task learning based on the minimization of regularization functionals similar to existing ones, such as the one for Support Vector Machines, that have been successfully used in the past for single-- task learning is presented."
            },
            "venue": {
                "fragments": [],
                "text": "KDD"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2243832"
                        ],
                        "name": "Leon Wenliang Zhong",
                        "slug": "Leon-Wenliang-Zhong",
                        "structuredName": {
                            "firstName": "Leon",
                            "lastName": "Zhong",
                            "middleNames": [
                                "Wenliang"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Leon Wenliang Zhong"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145193332"
                        ],
                        "name": "J. Kwok",
                        "slug": "J.-Kwok",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Kwok",
                            "middleNames": [
                                "Tin-Yau"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Kwok"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 35,
                                "start": 31
                            }
                        ],
                        "text": "Unlike these methods, g (U) in [57] penalizes its complexity via the squared Frobenius norm and clusters feature in different tasks based on the fused lasso regularizer."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[57] g (U) = \u03bb1 \u2211d i=1 \u2211 k> j |ui j \u2212 ui k | + \u03bb2\u2016U\u2016(2)F h(V) = \u03bb3\u2016V\u2016(2)F"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 114,
                                "start": 110
                            }
                        ],
                        "text": "For V, h(V) makes it sparse via the 1 norm in [53,54] and column-sparse via the 2,1 norm in [55,56], while in [57], h(V) penalizes the complexity of V via the squared Frobenius norm."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 18961224,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ebb578b6610efc8fe78b1af99d858d9e71c65f20",
            "isKey": false,
            "numCitedBy": 62,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "Traditionally, multitask learning (MTL) assumes that all the tasks are related. This can lead to negative transfer when tasks are indeed incoherent. Recently, a number of approaches have been proposed that alleviate this problem by discovering the underlying task clusters or relationships. However, they are limited to modeling these relationships at the task level, which may be restrictive in some applications. In this paper, we propose a novel MTL formulation that captures task relationships at the feature-level. Depending on the interactions among tasks and features, the proposed method construct different task clusters for different features, without even the need of pre-specifying the number of clusters. Computationally, the proposed formulation is strongly convex, and can be efficiently solved by accelerated proximal methods. Experiments are performed on a number of synthetic and real-world data sets. Under various degrees of task relationships, the accuracy of the proposed method is consistently among the best. Moreover, the feature-specific task clusters obtained agree with the known/plausible task structures of the data."
            },
            "slug": "Convex-Multitask-Learning-with-Flexible-Task-Zhong-Kwok",
            "title": {
                "fragments": [],
                "text": "Convex Multitask Learning with Flexible Task Clusters"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This paper proposes a novel MTL formulation that captures task relationships at the feature-level, and can be efficiently solved by accelerated proximal methods."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1801089"
                        ],
                        "name": "T. Evgeniou",
                        "slug": "T.-Evgeniou",
                        "structuredName": {
                            "firstName": "Theodoros",
                            "lastName": "Evgeniou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Evgeniou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1708279"
                        ],
                        "name": "C. Micchelli",
                        "slug": "C.-Micchelli",
                        "structuredName": {
                            "firstName": "Charles",
                            "lastName": "Micchelli",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Micchelli"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1704699"
                        ],
                        "name": "M. Pontil",
                        "slug": "M.-Pontil",
                        "structuredName": {
                            "firstName": "Massimiliano",
                            "lastName": "Pontil",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Pontil"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 151,
                                "start": 147
                            }
                        ],
                        "text": "In [81], different views in each task achieve consensus on unlabeled data and different tasks are learned by exploiting a priori information as in [38] or learning task relations as the MTRLmethod did."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 16193644,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0af75728bec67f698a8c619645165de13780c2fa",
            "isKey": false,
            "numCitedBy": 905,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "We study the problem of learning many related tasks simultaneously using kernel methods and regularization. The standard single-task kernel methods, such as support vector machines and regularization networks, are extended to the case of multi-task learning. Our analysis shows that the problem of estimating many task functions with regularization can be cast as a single task learning problem if a family of multi-task kernel functions we define is used. These kernels model relations among the tasks and are derived from a novel form of regularizers. Specific kernels that can be used for multi-task learning are provided and experimentally tested on two real data sets. In agreement with past empirical work on multi-task learning, the experiments show that learning multiple related tasks simultaneously using the proposed approach can significantly outperform standard single-task learning particularly when there are many related tasks but few data per task."
            },
            "slug": "Learning-Multiple-Tasks-with-Kernel-Methods-Evgeniou-Micchelli",
            "title": {
                "fragments": [],
                "text": "Learning Multiple Tasks with Kernel Methods"
            },
            "tldr": {
                "abstractSimilarityScore": 55,
                "text": "The experiments show that learning multiple related tasks simultaneously using the proposed approach can significantly outperform standard single-task learning particularly when there are many related tasks but few data per task."
            },
            "venue": {
                "fragments": [],
                "text": "J. Mach. Learn. Res."
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46867608"
                        ],
                        "name": "Yu Zhang",
                        "slug": "Yu-Zhang",
                        "structuredName": {
                            "firstName": "Yu",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yu Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152290618"
                        ],
                        "name": "Qiang Yang",
                        "slug": "Qiang-Yang",
                        "structuredName": {
                            "firstName": "Qiang",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Qiang Yang"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 180,
                                "start": 176
                            }
                        ],
                        "text": "The MTRL method is generalized to multi-task boosting [46] and multi-label learning [47], where each label is treated as a task, and extended to learn sparse task relations in [48]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 29157927,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f41533c9a76d048dafeebf9b4da565737ba78096",
            "isKey": false,
            "numCitedBy": 31,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "\n \n In multi-task learning, when the number of tasks is large, pairwise task relations exhibit sparse patterns since usually a task cannot be helpful to all of the other tasks and moreover, sparse task relations can reduce the risk of overfitting compared with the dense ones. In this paper, we focus on learning sparse task relations. Based on a regularization framework which can learn task relations among multiple tasks, we propose a SParse covAriance based mulTi-taSk (SPATS) model to learn a sparse covariance by using the \u2113l regularization. The resulting objective function of the SPATS method is convex, which allows us to devise an alternating method to solve it. Moreover, some theoretical properties of the proposed model are studied. Experiments on synthetic and real-world datasets demonstrate the effectiveness of the proposed method.\n \n"
            },
            "slug": "Learning-Sparse-Task-Relations-in-Multi-Task-Zhang-Yang",
            "title": {
                "fragments": [],
                "text": "Learning Sparse Task Relations in Multi-Task Learning"
            },
            "venue": {
                "fragments": [],
                "text": "AAAI"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2948486"
                        ],
                        "name": "Nico G\u00f6rnitz",
                        "slug": "Nico-G\u00f6rnitz",
                        "structuredName": {
                            "firstName": "Nico",
                            "lastName": "G\u00f6rnitz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nico G\u00f6rnitz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3263887"
                        ],
                        "name": "Christian Widmer",
                        "slug": "Christian-Widmer",
                        "structuredName": {
                            "firstName": "Christian",
                            "lastName": "Widmer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christian Widmer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2095043"
                        ],
                        "name": "G. Zeller",
                        "slug": "G.-Zeller",
                        "structuredName": {
                            "firstName": "Georg",
                            "lastName": "Zeller",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Zeller"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144760967"
                        ],
                        "name": "A. Kahles",
                        "slug": "A.-Kahles",
                        "structuredName": {
                            "firstName": "Andr\u00e9",
                            "lastName": "Kahles",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Kahles"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3029782"
                        ],
                        "name": "S. Sonnenburg",
                        "slug": "S.-Sonnenburg",
                        "structuredName": {
                            "firstName": "S\u00f6ren",
                            "lastName": "Sonnenburg",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Sonnenburg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2414086"
                        ],
                        "name": "G. R\u00e4tsch",
                        "slug": "G.-R\u00e4tsch",
                        "structuredName": {
                            "firstName": "Gunnar",
                            "lastName": "R\u00e4tsch",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. R\u00e4tsch"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 10407397,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b6437567425cf20de10ab57e5c79dd6e4d124596",
            "isKey": false,
            "numCitedBy": 44,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a novel regularization-based Multitask Learning (MTL) formulation for Structured Output (SO) prediction for the case of hierarchical task relations. Structured output prediction often leads to difficult inference problems and hence requires large amounts of training data to obtain accurate models. We propose to use MTL to exploit additional information from related learning tasks by means of hierarchical regularization. Training SO models on the combined set of examples from multiple tasks can easily become infeasible for real world applications. To be able to solve the optimization problems underlying multitask structured output learning, we propose an efficient algorithm based on bundle-methods. We demonstrate the performance of our approach in applications from the domain of computational biology addressing the key problem of gene finding. We show that 1) our proposed solver achieves much faster convergence than previous methods and 2) that the Hierarchical SO-MTL approach outperforms considered non-MTL methods."
            },
            "slug": "Hierarchical-Multitask-Structured-Output-Learning-G\u00f6rnitz-Widmer",
            "title": {
                "fragments": [],
                "text": "Hierarchical Multitask Structured Output Learning for Large-scale Sequence Segmentation"
            },
            "tldr": {
                "abstractSimilarityScore": 68,
                "text": "This work presents a novel regularization-based Multitask Learning (MTL) formulation for Structured Output (SO) prediction for the case of hierarchical task relations and demonstrates the performance of the approach in applications from the domain of computational biology addressing the key problem of gene finding."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108513551"
                        ],
                        "name": "Jianhui Chen",
                        "slug": "Jianhui-Chen",
                        "structuredName": {
                            "firstName": "Jianhui",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jianhui Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38414402"
                        ],
                        "name": "Lei Tang",
                        "slug": "Lei-Tang",
                        "structuredName": {
                            "firstName": "Lei",
                            "lastName": "Tang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lei Tang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39497343"
                        ],
                        "name": "Jun Liu",
                        "slug": "Jun-Liu",
                        "structuredName": {
                            "firstName": "Jun",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jun Liu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144030870"
                        ],
                        "name": "Jieping Ye",
                        "slug": "Jieping-Ye",
                        "structuredName": {
                            "firstName": "Jieping",
                            "lastName": "Ye",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jieping Ye"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 38,
                                "start": 34
                            }
                        ],
                        "text": "This model is then generalized in [25] by adding a squared Frobenius regularization on W and this generalized model can be relaxed to have a convex objective function."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 5356447,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "382a129c95162bbbc2d26fa9e3d89c4dae5d3229",
            "isKey": false,
            "numCitedBy": 190,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "Multi-task learning (MTL) aims to improve generalization performance by learning multiple related tasks simultaneously. In this paper, we consider the problem of learning shared structures from multiple related tasks. We present an improved formulation (iASO) for multi-task learning based on the non-convex alternating structure optimization (ASO) algorithm, in which all tasks are related by a shared feature representation. We convert iASO, a non-convex formulation, into a relaxed convex one, which is, however, not scalable to large data sets due to its complex constraints. We propose an alternating optimization (cASO) algorithm which solves the convex relaxation efficiently, and further show that cASO converges to a global optimum. In addition, we present a theoretical condition, under which cASO can find a globally optimal solution to iASO. Experiments on several benchmark data sets confirm our theoretical analysis."
            },
            "slug": "A-convex-formulation-for-learning-shared-structures-Chen-Tang",
            "title": {
                "fragments": [],
                "text": "A convex formulation for learning shared structures from multiple tasks"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "An improved formulation for multi-task learning based on the non-convex alternating structure optimization (ASO) algorithm, in which all tasks are related by a shared feature representation, is presented."
            },
            "venue": {
                "fragments": [],
                "text": "ICML '09"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50033175"
                        ],
                        "name": "Andreas Argyriou",
                        "slug": "Andreas-Argyriou",
                        "structuredName": {
                            "firstName": "Andreas",
                            "lastName": "Argyriou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andreas Argyriou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1801089"
                        ],
                        "name": "T. Evgeniou",
                        "slug": "T.-Evgeniou",
                        "structuredName": {
                            "firstName": "Theodoros",
                            "lastName": "Evgeniou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Evgeniou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1704699"
                        ],
                        "name": "M. Pontil",
                        "slug": "M.-Pontil",
                        "structuredName": {
                            "firstName": "Massimiliano",
                            "lastName": "Pontil",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Pontil"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7502194,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "dbb3342599c9b431a3152a0d5c813d3e56967a27",
            "isKey": false,
            "numCitedBy": 1379,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a method for learning a low-dimensional representation which is shared across a set of multiple related tasks. The method builds upon the well-known 1-norm regularization problem using a new regularizer which controls the number of learned features common for all the tasks. We show that this problem is equivalent to a convex optimization problem and develop an iterative algorithm for solving it. The algorithm has a simple interpretation: it alternately performs a supervised and an unsupervised step, where in the latter step we learn commonacross-tasks representations and in the former step we learn task-specific functions using these representations. We report experiments on a simulated and a real data set which demonstrate that the proposed method dramatically improves the performance relative to learning each task independently. Our algorithm can also be used, as a special case, to simply select \u2013 not learn \u2013 a few common features across the tasks."
            },
            "slug": "Multi-Task-Feature-Learning-Argyriou-Evgeniou",
            "title": {
                "fragments": [],
                "text": "Multi-Task Feature Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "The method builds upon the well-known 1-norm regularization problem using a new regularizer which controls the number of learned features common for all the tasks, and develops an iterative algorithm for solving it."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50033175"
                        ],
                        "name": "Andreas Argyriou",
                        "slug": "Andreas-Argyriou",
                        "structuredName": {
                            "firstName": "Andreas",
                            "lastName": "Argyriou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andreas Argyriou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1801089"
                        ],
                        "name": "T. Evgeniou",
                        "slug": "T.-Evgeniou",
                        "structuredName": {
                            "firstName": "Theodoros",
                            "lastName": "Evgeniou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Evgeniou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1704699"
                        ],
                        "name": "M. Pontil",
                        "slug": "M.-Pontil",
                        "structuredName": {
                            "firstName": "Massimiliano",
                            "lastName": "Pontil",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Pontil"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6617228,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9e7b0395d7b34e9d34cca779afd0c10da6e135b5",
            "isKey": false,
            "numCitedBy": 1446,
            "numCiting": 61,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract\nWe present a method for learning sparse representations shared across multiple tasks. This method is a generalization of the well-known single-task 1-norm regularization. It is based on a novel non-convex regularizer which controls the number of learned features common across the tasks. We prove that the method is equivalent to solving a convex optimization problem for which there is an iterative algorithm which converges to an optimal solution. The algorithm has a simple interpretation: it alternately performs a supervised and an unsupervised step, where in the former step it learns task-specific functions and in the latter step it learns common-across-tasks sparse representations for these functions. We also provide an extension of the algorithm which learns sparse nonlinear representations using kernels. We report experiments on simulated and real data sets which demonstrate that the proposed method can both improve the performance relative to learning each task independently and lead to a few learned features common across related tasks. Our algorithm can also be used, as a special case, to simply select\u2014not learn\u2014a few common variables across the tasks.\n"
            },
            "slug": "Convex-multi-task-feature-learning-Argyriou-Evgeniou",
            "title": {
                "fragments": [],
                "text": "Convex multi-task feature learning"
            },
            "tldr": {
                "abstractSimilarityScore": 59,
                "text": "It is proved that the method for learning sparse representations shared across multiple tasks is equivalent to solving a convex optimization problem for which there is an iterative algorithm which converges to an optimal solution."
            },
            "venue": {
                "fragments": [],
                "text": "Machine Learning"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2113829681"
                        ],
                        "name": "Jing Bai",
                        "slug": "Jing-Bai",
                        "structuredName": {
                            "firstName": "Jing",
                            "lastName": "Bai",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jing Bai"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143904275"
                        ],
                        "name": "Ke Zhou",
                        "slug": "Ke-Zhou",
                        "structuredName": {
                            "firstName": "Ke",
                            "lastName": "Zhou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ke Zhou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1701421"
                        ],
                        "name": "Gui-Rong Xue",
                        "slug": "Gui-Rong-Xue",
                        "structuredName": {
                            "firstName": "Gui-Rong",
                            "lastName": "Xue",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Gui-Rong Xue"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145203884"
                        ],
                        "name": "H. Zha",
                        "slug": "H.-Zha",
                        "structuredName": {
                            "firstName": "Hongyuan",
                            "lastName": "Zha",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Zha"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2148463679"
                        ],
                        "name": "G. Sun",
                        "slug": "G.-Sun",
                        "structuredName": {
                            "firstName": "Gordon",
                            "lastName": "Sun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Sun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2409063"
                        ],
                        "name": "B. Tseng",
                        "slug": "B.-Tseng",
                        "structuredName": {
                            "firstName": "Belle",
                            "lastName": "Tseng",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Tseng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1749245"
                        ],
                        "name": "Zhaohui Zheng",
                        "slug": "Zhaohui-Zheng",
                        "structuredName": {
                            "firstName": "Zhaohui",
                            "lastName": "Zheng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zhaohui Zheng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145882798"
                        ],
                        "name": "Yi Chang",
                        "slug": "Yi-Chang",
                        "structuredName": {
                            "firstName": "Yi",
                            "lastName": "Chang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yi Chang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 76,
                                "start": 71
                            }
                        ],
                        "text": "Web applications based on MTL include learning to rank in web searches [121], web search ranking [122], multi-domain collaborative filtering [123], behavioral targeting [124], and conversion maximization in display advertising [125]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 7912150,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c35b56363d40bbfea54a53f26f00c9fb62c80ea1",
            "isKey": false,
            "numCitedBy": 40,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "Both the quality and quantity of training data have significant impact on the performance of ranking functions in the context of learning to rank for web search. Due to resource constraints, training data for smaller search engine markets are scarce and we need to leverage existing training data from large markets to enhance the learning of ranking function for smaller markets. In this paper, we present a boosting framework for learning to rank in the multi-task learning context for this purpose. In particular, we propose to learn non-parametric common structures adaptively from multiple tasks in a stage-wise way. An algorithm is developed to iteratively discover super-features that are effective for all the tasks. The estimation of the functions for each task is then learned as a linear combination of those super-features. We evaluate the performance of this multi-task learning method for web search ranking using data from a search engine. Our results demonstrate that multi-task learning methods bring significant relevance improvements over existing baseline methods."
            },
            "slug": "Multi-task-learning-for-learning-to-rank-in-web-Bai-Zhou",
            "title": {
                "fragments": [],
                "text": "Multi-task learning for learning to rank in web search"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "A boosting framework for learning to rank in the multi- task learning context to learn non-parametric common structures adaptively from multiple tasks in a stage-wise way and demonstrates that multi-task learning methods bring significant relevance improvements over existing baseline methods."
            },
            "venue": {
                "fragments": [],
                "text": "CIKM"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50199457"
                        ],
                        "name": "Chunfen Yuan",
                        "slug": "Chunfen-Yuan",
                        "structuredName": {
                            "firstName": "Chunfen",
                            "lastName": "Yuan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chunfen Yuan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40506509"
                        ],
                        "name": "Weiming Hu",
                        "slug": "Weiming-Hu",
                        "structuredName": {
                            "firstName": "Weiming",
                            "lastName": "Hu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Weiming Hu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2922163"
                        ],
                        "name": "Guodong Tian",
                        "slug": "Guodong-Tian",
                        "structuredName": {
                            "firstName": "Guodong",
                            "lastName": "Tian",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Guodong Tian"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2132170463"
                        ],
                        "name": "Shuang Yang",
                        "slug": "Shuang-Yang",
                        "structuredName": {
                            "firstName": "Shuang",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shuang Yang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2118011762"
                        ],
                        "name": "Haoran Wang",
                        "slug": "Haoran-Wang",
                        "structuredName": {
                            "firstName": "Haoran",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Haoran Wang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2066395,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2aca4fca2c72e6e4c4a39712de0a22b5891fdc65",
            "isKey": false,
            "numCitedBy": 44,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we formulate human action recognition as a novel Multi-Task Sparse Learning(MTSL) framework which aims to construct a test sample with multiple features from as few bases as possible. Learning the sparse representation under each feature modality is considered as a single task in MTSL. Since the tasks are generated from multiple features associated with the same visual input, they are not independent but inter-related. We introduce a Beta process(BP) prior to the hierarchical MTSL model, which efficiently learns a compact dictionary and infers the sparse structure shared across all the tasks. The MTSL model enforces the robustness in coefficient estimation compared with performing each task independently. Besides, the sparseness is achieved via the Beta process formulation rather than the computationally expensive L1 norm penalty. In terms of non-informative gamma hyper-priors, the sparsity level is totally decided by the data. Finally, the learning problem is solved by Gibbs sampling inference which estimates the full posterior on the model parameters. Experimental results on the KTH and UCF sports datasets demonstrate the effectiveness of the proposed MTSL approach for action recognition."
            },
            "slug": "Multi-task-Sparse-Learning-with-Beta-Process-Prior-Yuan-Hu",
            "title": {
                "fragments": [],
                "text": "Multi-task Sparse Learning with Beta Process Prior for Action Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A Beta process is introduced prior to the hierarchical MTSL model, which efficiently learns a compact dictionary and infers the sparse structure shared across all the tasks, which enforces the robustness in coefficient estimation compared with performing each task independently."
            },
            "venue": {
                "fragments": [],
                "text": "2013 IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1388574404"
                        ],
                        "name": "D. Hern\u00e1ndez-Lobato",
                        "slug": "D.-Hern\u00e1ndez-Lobato",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Hern\u00e1ndez-Lobato",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Hern\u00e1ndez-Lobato"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1388574431"
                        ],
                        "name": "Jos\u00e9 Miguel Hern\u00e1ndez-Lobato",
                        "slug": "Jos\u00e9-Miguel-Hern\u00e1ndez-Lobato",
                        "structuredName": {
                            "firstName": "Jos\u00e9 Miguel",
                            "lastName": "Hern\u00e1ndez-Lobato",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jos\u00e9 Miguel Hern\u00e1ndez-Lobato"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 27,
                                "start": 23
                            }
                        ],
                        "text": "The difference between [16] and [17] is that in [16], the horseshoeprior is generalized to learn feature covariance, while in [17], the horseshoe prior is used as a basic prior and the whole model is to identify outlier tasks in a way different from [15]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 10,
                                "start": 3
                            }
                        ],
                        "text": "In [16,17], the horseshoe prior is utilized to select features for MTL."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 10049572,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6f15b86ea60ba3cd0a5480902729cd43e773d3bf",
            "isKey": false,
            "numCitedBy": 29,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "A probabilistic model based on the horseshoe prior is proposed for learning dependencies in the process of identifying relevant features for prediction. Exact inference is intractable in this model. However, expectation propagation offers an approximate alternative. Because the process of estimating feature selection dependencies may suffer from over-fitting in the model proposed, additional data from a multi-task learning scenario are considered for induction. The same model can be used in this setting with few modifications. Furthermore, the assumptions made are less restrictive than in other multi-task methods: The different tasks must share feature selection dependencies, but can have different relevant features and model coefficients. Experiments with real and synthetic data show that this model performs better than other multi-task alternatives from the literature. The experiments also show that the model is able to induce suitable feature selection dependencies for the problems considered, only from the training data."
            },
            "slug": "Learning-Feature-Selection-Dependencies-in-Learning-Hern\u00e1ndez-Lobato-Hern\u00e1ndez-Lobato",
            "title": {
                "fragments": [],
                "text": "Learning Feature Selection Dependencies in Multi-task Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 68,
                "text": "A probabilistic model based on the horseshoe prior for learning dependencies in the process of identifying relevant features for prediction performs better than other multi-task alternatives from the literature and is able to induce suitable feature selection dependencies for the problems considered."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2112660813"
                        ],
                        "name": "Lei Han",
                        "slug": "Lei-Han",
                        "structuredName": {
                            "firstName": "Lei",
                            "lastName": "Han",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lei Han"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2153632326"
                        ],
                        "name": "Yu Zhang",
                        "slug": "Yu-Zhang",
                        "structuredName": {
                            "firstName": "Yu",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yu Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2090871"
                        ],
                        "name": "Guojie Song",
                        "slug": "Guojie-Song",
                        "structuredName": {
                            "firstName": "Guojie",
                            "lastName": "Song",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Guojie Song"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38388863"
                        ],
                        "name": "Kunqing Xie",
                        "slug": "Kunqing-Xie",
                        "structuredName": {
                            "firstName": "Kunqing",
                            "lastName": "Xie",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kunqing Xie"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 33,
                                "start": 26
                            }
                        ],
                        "text": "This model is extended in [13,14] to more general settings."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1702051,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4a037be6e10c78599ea28fa3554f01e784037767",
            "isKey": false,
            "numCitedBy": 36,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "\n \n Multi-task learning seeks to improve the generalization performance by sharing common information among multiple related tasks. A key assumption in most MTL algorithms is that all tasks are related, which, however, may not hold in many real-world applications. Existing techniques, which attempt to address this issue, aim to identify groups of related tasks using group sparsity. In this paper, we propose a probabilistic tree sparsity (PTS) model to utilize the tree structure to obtain the sparse solution instead of the group structure. Specifically, each model coefficient in the learning model is decomposed into a product of multiple component coefficients each of which corresponds to a node in the tree. Based on the decomposition, Gaussian and Cauchy distributions are placed on the component coefficients as priors to restrict the model complexity. We devise an efficient expectation maximization algorithm to learn the model parameters. Experiments conducted on both synthetic and real-world problems show the effectiveness of our model compared with state-of-the-art baselines.\n \n"
            },
            "slug": "Encoding-Tree-Sparsity-in-Multi-Task-Learning:-A-Han-Zhang",
            "title": {
                "fragments": [],
                "text": "Encoding Tree Sparsity in Multi-Task Learning: A Probabilistic Framework"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A probabilistic tree sparsity model to utilize the tree structure to obtain the sparse solution instead of the group structure is proposed and an efficient expectation maximization algorithm is devised to learn the model parameters."
            },
            "venue": {
                "fragments": [],
                "text": "AAAI"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "22807442"
                        ],
                        "name": "Qiuhua Liu",
                        "slug": "Qiuhua-Liu",
                        "structuredName": {
                            "firstName": "Qiuhua",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Qiuhua Liu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2585822"
                        ],
                        "name": "X. Liao",
                        "slug": "X.-Liao",
                        "structuredName": {
                            "firstName": "X.",
                            "lastName": "Liao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "X. Liao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [],
                        "name": "Hui Li",
                        "slug": "Hui-Li",
                        "structuredName": {
                            "firstName": "Hui",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hui Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "37168548"
                        ],
                        "name": "J. Stack",
                        "slug": "J.-Stack",
                        "structuredName": {
                            "firstName": "Jason",
                            "lastName": "Stack",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Stack"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145006560"
                        ],
                        "name": "L. Carin",
                        "slug": "L.-Carin",
                        "structuredName": {
                            "firstName": "Lawrence",
                            "lastName": "Carin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Carin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 14,
                                "start": 7
                            }
                        ],
                        "text": "Unlike [63,64], a semi-supervised multi-task regression method is proposed in [65], where each task adopts a Gaussian process and unlabeled data are used to define the kernel function, andGaussian processes in all the tasks share a common prior on kernel parameters."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 74,
                                "start": 67
                            }
                        ],
                        "text": "For multitask semi-supervised classification, a method proposed in [63,64] follows the task-clustering approach to do task clustering on different tasks based on a relaxed Dirichlet process, while in each task, random walk is used to exploit useful information contained in the unlabeled data."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 17468577,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b3188bedf1c60383b39b88e77f99b5f11ff3d10e",
            "isKey": false,
            "numCitedBy": 85,
            "numCiting": 46,
            "paperAbstract": {
                "fragments": [],
                "text": "Context plays an important role when performing classification, and in this paper we examine context from two perspectives. First, the classification of items within a single task is placed within the context of distinct concurrent or previous classification tasks (multiple distinct data collections). This is referred to as multi-task learning (MTL), and is implemented here in a statistical manner, using a simplified form of the Dirichlet process. In addition, when performing many classification tasks one has simultaneous access to all unlabeled data that must be classified, and therefore there is an opportunity to place the classification of any one feature vector within the context of all unlabeled feature vectors; this is referred to as semi-supervised learning. In this paper we integrate MTL and semi-supervised learning into a single framework, thereby exploiting two forms of contextual information. Example results are presented on a \"toy\" example, to demonstrate the concept, and the algorithm is also applied to three real data sets."
            },
            "slug": "Semisupervised-Multitask-Learning-Liu-Liao",
            "title": {
                "fragments": [],
                "text": "Semisupervised Multitask Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This paper integrates MTL and semi-supervised learning into a single framework, thereby exploiting two forms of contextual information."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1719301"
                        ],
                        "name": "G. Pillonetto",
                        "slug": "G.-Pillonetto",
                        "structuredName": {
                            "firstName": "Gianluigi",
                            "lastName": "Pillonetto",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Pillonetto"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3125402"
                        ],
                        "name": "Francesco Dinuzzo",
                        "slug": "Francesco-Dinuzzo",
                        "structuredName": {
                            "firstName": "Francesco",
                            "lastName": "Dinuzzo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Francesco Dinuzzo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7648294"
                        ],
                        "name": "G. Nicolao",
                        "slug": "G.-Nicolao",
                        "structuredName": {
                            "firstName": "Giuseppe",
                            "lastName": "Nicolao",
                            "middleNames": [
                                "De"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Nicolao"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 7,
                                "start": 3
                            }
                        ],
                        "text": "In [78], a Bayesian online algorithm is proposed for a multi-task Gaussian process that shares kernel parameters among tasks."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 16236462,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "724e0e4ad67833163ffff3de70b49a66aced7425",
            "isKey": false,
            "numCitedBy": 70,
            "numCiting": 61,
            "paperAbstract": {
                "fragments": [],
                "text": "Standard single-task kernel methods have recently been extended to the case of multitask learning in the context of regularization theory. There are experimental results, especially in biomedicine, showing the benefit of the multitask approach compared to the single-task one. However, a possible drawback is computational complexity. For instance, when regularization networks are used, complexity scales as the cube of the overall number of training data, which may be large when several tasks are involved. The aim of this paper is to derive an efficient computational scheme for an important class of multitask kernels. More precisely, a quadratic loss is assumed and each task consists of the sum of a common term and a task-specific one. Within a Bayesian setting, a recursive online algorithm is obtained, which updates both estimates and confidence intervals as new data become available. The algorithm is tested on two simulated problems and a real data set relative to xenobiotics administration in human patients."
            },
            "slug": "Bayesian-Online-Multitask-Learning-of-Gaussian-Pillonetto-Dinuzzo",
            "title": {
                "fragments": [],
                "text": "Bayesian Online Multitask Learning of Gaussian Processes"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The aim of this paper is to derive an efficient computational scheme for an important class of multitask kernels, where a quadratic loss is assumed and each task consists of the sum of a common term and a task-specific one."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50333123"
                        ],
                        "name": "Abhishek Kumar",
                        "slug": "Abhishek-Kumar",
                        "structuredName": {
                            "firstName": "Abhishek",
                            "lastName": "Kumar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Abhishek Kumar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1722360"
                        ],
                        "name": "Hal Daum\u00e9",
                        "slug": "Hal-Daum\u00e9",
                        "structuredName": {
                            "firstName": "Hal",
                            "lastName": "Daum\u00e9",
                            "middleNames": [],
                            "suffix": "III"
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hal Daum\u00e9"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 18,
                                "start": 11
                            }
                        ],
                        "text": "Both works [33,35] decomposeW asW = LS where columns in L consist of basis parameter vectors in different clusters and S contains combination coefficients."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 32,
                                "start": 28
                            }
                        ],
                        "text": "Specifically, the method in [33] aims to identify overlapping task clusters where each task can belong tomultiple clusters and hence it learns a sparse S via the 1 regularization, while in [35], each task lies in only one cluster and hence the 2 norm of each column in the 0/1 matrix S is enforced to be 1."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 9494747,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d3c04a424fff21d3d12ff8b0543734cf244d5f67",
            "isKey": false,
            "numCitedBy": 432,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "In the paradigm of multi-task learning, multiple related prediction tasks are learned jointly, sharing information across the tasks. We propose a framework for multi-task learning that enables one to selectively share the information across the tasks. We assume that each task parameter vector is a linear combination of a finite number of underlying basis tasks. The coefficients of the linear combination are sparse in nature and the overlap in the sparsity patterns of two tasks controls the amount of sharing across these. Our model is based on the assumption that task parameters within a group lie in a low dimensional subspace but allows the tasks in different groups to overlap with each other in one or more bases. Experimental results on four datasets show that our approach outperforms competing methods."
            },
            "slug": "Learning-Task-Grouping-and-Overlap-in-Multi-task-Kumar-Daum\u00e9",
            "title": {
                "fragments": [],
                "text": "Learning Task Grouping and Overlap in Multi-task Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 54,
                "text": "This work proposes a framework for multi-task learning that enables one to selectively share the information across the tasks, based on the assumption that task parameters within a group lie in a low dimensional subspace but allows the tasks in different groups to overlap with each other in one or more bases."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145644275"
                        ],
                        "name": "Y. Xue",
                        "slug": "Y.-Xue",
                        "structuredName": {
                            "firstName": "Ya",
                            "lastName": "Xue",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Xue"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2585822"
                        ],
                        "name": "X. Liao",
                        "slug": "X.-Liao",
                        "structuredName": {
                            "firstName": "X.",
                            "lastName": "Liao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "X. Liao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145006560"
                        ],
                        "name": "L. Carin",
                        "slug": "L.-Carin",
                        "structuredName": {
                            "firstName": "Lawrence",
                            "lastName": "Carin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Carin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1765150"
                        ],
                        "name": "B. Krishnapuram",
                        "slug": "B.-Krishnapuram",
                        "structuredName": {
                            "firstName": "Balaji",
                            "lastName": "Krishnapuram",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Krishnapuram"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 14,
                                "start": 7
                            }
                        ],
                        "text": "Unlike [29,30], which areBayesianmodels, there are several regularized methods [31\u201335] to do task clustering."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 106,
                                "start": 102
                            }
                        ],
                        "text": "TheDirichlet process, which is widely used in Bayesian learning to do data clustering, is employed in [30] to do task clustering based on model parameters {wi }."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 715932,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "89c808af926ecb20870b2521fbaa7dcbb85be106",
            "isKey": false,
            "numCitedBy": 571,
            "numCiting": 45,
            "paperAbstract": {
                "fragments": [],
                "text": "Consider the problem of learning logistic-regression models for multiple classification tasks, where the training data set for each task is not drawn from the same statistical distribution. In such a multi-task learning (MTL) scenario, it is necessary to identify groups of similar tasks that should be learned jointly. Relying on a Dirichlet process (DP) based statistical model to learn the extent of similarity between classification tasks, we develop computationally efficient algorithms for two different forms of the MTL problem. First, we consider a symmetric multi-task learning (SMTL) situation in which classifiers for multiple tasks are learned jointly using a variational Bayesian (VB) algorithm. Second, we consider an asymmetric multi-task learning (AMTL) formulation in which the posterior density function from the SMTL model parameters (from previous tasks) is used as a prior for a new task: this approach has the significant advantage of not requiring storage and use of all previous data from prior tasks. The AMTL formulation is solved with a simple Markov Chain Monte Carlo (MCMC) construction. Experimental results on two real life MTL problems indicate that the proposed algorithms: (a) automatically identify subgroups of related tasks whose training data appear to be drawn from similar distributions; and (b) are more accurate than simpler approaches such as single-task learning, pooling of data across all tasks, and simplified approximations to DP."
            },
            "slug": "Multi-Task-Learning-for-Classification-with-Process-Xue-Liao",
            "title": {
                "fragments": [],
                "text": "Multi-Task Learning for Classification with Dirichlet Process Priors"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "Experimental results on two real life MTL problems indicate that the proposed algorithms automatically identify subgroups of related tasks whose training data appear to be drawn from similar distributions are more accurate than simpler approaches such as single-task learning, pooling of data across all tasks, and simplified approximations to DP."
            },
            "venue": {
                "fragments": [],
                "text": "J. Mach. Learn. Res."
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "37395525"
                        ],
                        "name": "Jingrui He",
                        "slug": "Jingrui-He",
                        "structuredName": {
                            "firstName": "Jingrui",
                            "lastName": "He",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jingrui He"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "19319499"
                        ],
                        "name": "Richard D. Lawrence",
                        "slug": "Richard-D.-Lawrence",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Lawrence",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Richard D. Lawrence"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 85,
                                "start": 78
                            }
                        ],
                        "text": "As a multi-task extension ofmulti-view learning,multi-taskmulti-view learning [80,81] hopes to exploit multiple multiview learning problems to improve the performance over eachmulti-view learning problemby leveraging useful information contained in related tasks."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 21,
                                "start": 17
                            }
                        ],
                        "text": "Specifically, in [80], the first multi-task multiview classifier is proposed to utilize the task relatedness based on common views shared by tasks and view consistency among views in each task."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 6539200,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0e8d3013012025a51128a96c2f15db26a0ac95d3",
            "isKey": false,
            "numCitedBy": 118,
            "numCiting": 65,
            "paperAbstract": {
                "fragments": [],
                "text": "Many real-world problems exhibit dual-heterogeneity. A single learning task might have features in multiple views (i.e., feature heterogeneity); multiple learning tasks might be related with each other through one or more shared views (i.e., task heterogeneity). Existing multi-task learning or multi-view learning algorithms only capture one type of heterogeneity. \n \nIn this paper, we introduce Multi-Task Multi-View (M2TV) learning for such complicated learning problems with both feature heterogeneity and task heterogeneity. We propose a graph-based framework (GraM2) to take full advantage of the dual-heterogeneous nature. Our framework has a natural connection to Reproducing Kernel Hilbert Space (RKHS). Furthermore, we propose an iterative algorithm (IteM2) for GraM2 framework, and analyze its optimality, convergence and time complexity. Experimental results on various real data sets demonstrate its effectiveness."
            },
            "slug": "A-Graphbased-Framework-for-Multi-Task-Multi-View-He-Lawrence",
            "title": {
                "fragments": [],
                "text": "A Graphbased Framework for Multi-Task Multi-View Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "This paper introduces Multi-Task Multi-View (M2TV) learning for such complicated learning problems with both feature heterogeneity and task heterogeneity, and proposes a graph-based framework (GraM2) to take full advantage of the dual-heterogeneous nature."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2110342116"
                        ],
                        "name": "Tsuyoshi Kato",
                        "slug": "Tsuyoshi-Kato",
                        "structuredName": {
                            "firstName": "Tsuyoshi",
                            "lastName": "Kato",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tsuyoshi Kato"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2785830"
                        ],
                        "name": "H. Kashima",
                        "slug": "H.-Kashima",
                        "structuredName": {
                            "firstName": "Hisashi",
                            "lastName": "Kashima",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Kashima"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "67154907"
                        ],
                        "name": "Masashi Sugiyama",
                        "slug": "Masashi-Sugiyama",
                        "structuredName": {
                            "firstName": "Masashi",
                            "lastName": "Sugiyama",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Masashi Sugiyama"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1699299"
                        ],
                        "name": "K. Asai",
                        "slug": "K.-Asai",
                        "structuredName": {
                            "firstName": "Kiyoshi",
                            "lastName": "Asai",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Asai"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 220869,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6f1fdfcdf03cb4e6827d647f5d8cfbc93b33c980",
            "isKey": false,
            "numCitedBy": 102,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "When we have several related tasks, solving them simultaneously is shown to be more effective than solving them individually. This approach is called multi-task learning (MTL) and has been studied extensively. Existing approaches to MTL often treat all the tasks as uniformly related to each other and the relatedness of the tasks is controlled globally. For this reason, the existing methods can lead to undesired solutions when some tasks are not highly related to each other, and some pairs of related tasks can have significantly different solutions. In this paper, we propose a novel MTL algorithm that can overcome these problems. Our method makes use of a task network, which describes the relation structure among tasks. This allows us to deal with intricate relation structures in a systematic way. Furthermore, we control the relatedness of the tasks locally, so all pairs of related tasks are guaranteed to have similar solutions. We apply the above idea to support vector machines (SVMs) and show that the optimization problem can be cast as a second order cone program, which is convex and can be solved efficiently. The usefulness of our approach is demonstrated through simulations with protein super-family classification and ordinal regression problems."
            },
            "slug": "Multi-Task-Learning-via-Conic-Programming-Kato-Kashima",
            "title": {
                "fragments": [],
                "text": "Multi-Task Learning via Conic Programming"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This paper proposes a novel MTL algorithm that makes use of a task network, which describes the relation structure among tasks and control the relatedness of the tasks locally, so all pairs of related tasks are guaranteed to have similar solutions."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144867807"
                        ],
                        "name": "S. Thrun",
                        "slug": "S.-Thrun",
                        "structuredName": {
                            "firstName": "Sebastian",
                            "lastName": "Thrun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Thrun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1395754302"
                        ],
                        "name": "Joseph O'Sullivan",
                        "slug": "Joseph-O'Sullivan",
                        "structuredName": {
                            "firstName": "Joseph",
                            "lastName": "O'Sullivan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Joseph O'Sullivan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 52,
                                "start": 48
                            }
                        ],
                        "text": "The first task-clustering algorithm proposed in [28] decouples the task-clustering procedure and the model-learning procedure."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 10420876,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2f42a55da3a222184eee20c67d374a9134b77bdc",
            "isKey": false,
            "numCitedBy": 244,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": "Recently, there has been an increased interest in \u201clifelong\u201d machine learning methods, that transfer knowledge across multiple learning tasks. Such methods have repeatedly been found to outperform conventional, single-task learning algorithms when the learning tasks are appropriately related. To increase robustness of such approaches, methods are desirable that can reason about the relatedness of individual learning tasks, in order to avoid the danger arising from tasks that are unrelated and thus potentially misleading. This paper describes the task-clustering (TC) algorithm. TC clusters learning tasks into classes of mutually related tasks. When facing a new learning task, TC first determines the most related task cluster, then exploits information selectively from this task cluster only. An empirical study carried out in a mobile robot domain shows that TC outperforms its non-selective counterpart in situations where only a small number of tasks is relevant."
            },
            "slug": "Discovering-Structure-in-Multiple-Learning-Tasks:-Thrun-O'Sullivan",
            "title": {
                "fragments": [],
                "text": "Discovering Structure in Multiple Learning Tasks: The TC Algorithm"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "The task-clustering algorithm TC clusters learning tasks into classes of mutually related tasks, and outperforms its non-selective counterpart in situations where only a small number of tasks is relevant."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2153634676"
                        ],
                        "name": "Yu Zhang",
                        "slug": "Yu-Zhang",
                        "structuredName": {
                            "firstName": "Yu",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yu Zhang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 164,
                                "start": 160
                            }
                        ],
                        "text": "Unlike the aforementioned methods, which rely on global learning models, local learning methods such as the k-nearest-neighbor (kNN) classifier are extended in [52] to the multi-task setting and the learning function is defined as f (xj ) = \u2211 (p,q)\u2208Nk (i, j ) \u03c3i p s (x i j , x p q )y p q , where Nk(i, j) denotes the set of task and instance indices for k nearest neighbors of xj , s(\u00b7, \u00b7) defines the similarity between instances, and \u03c3 ip represents the similarity of task Tp to Ti ."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 82,
                                "start": 78
                            }
                        ],
                        "text": "By enforcing \u03c3 ip to be close to \u03c3 pi, a regularizer \u2016 \u2212 \u2016(2)F is proposed in [52] to learn task similarities, where each \u03c3 ip needs to satisfy that \u03c3 ii \u2265 0 and |\u03c3 ip| \u2264 \u03c3 ii for i = p."
                    },
                    "intents": []
                }
            ],
            "corpusId": 2859706,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2a68a4b74427c2d0c2826299a7664cfd97e4a03d",
            "isKey": false,
            "numCitedBy": 27,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "All the existing multi-task local learning methods are defined on homogeneous neighborhood which consists of all data points from only one task. In this paper, different from existing methods, we propose local learning methods for multitask classification and regression problems based on heterogeneous neighborhood which is defined on data points from all tasks. Specifically, we extend the k-nearest-neighbor classifier by formulating the decision function for each data point as a weighted voting among the neighbors from all tasks where the weights are task-specific. By defining a regularizer to enforce the task-specific weight matrix to approach a symmetric one, a regularized objective function is proposed and an efficient coordinate descent method is developed to solve it. For regression problems, we extend the kernel regression to multi-task setting in a similar way to the classification case. Experiments on some toy data and real-world datasets demonstrate the effectiveness of our proposed methods."
            },
            "slug": "Heterogeneous-Neighborhood-based-Multi-Task-Local-Zhang",
            "title": {
                "fragments": [],
                "text": "Heterogeneous-Neighborhood-based Multi-Task Local Learning Algorithms"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This paper extends the k-nearest-neighbor classifier by formulating the decision function for each data point as a weighted voting among the neighbors from all tasks where the weights are task-specific."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3039887"
                        ],
                        "name": "Min-Ling Zhang",
                        "slug": "Min-Ling-Zhang",
                        "structuredName": {
                            "firstName": "Min-Ling",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Min-Ling Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145624000"
                        ],
                        "name": "Zhi-Hua Zhou",
                        "slug": "Zhi-Hua-Zhou",
                        "structuredName": {
                            "firstName": "Zhi-Hua",
                            "lastName": "Zhou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zhi-Hua Zhou"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 107,
                                "start": 104
                            }
                        ],
                        "text": "MTL is related to other areas in machine learning, including transfer learning [2],multi-label learning [3] andmulti-output regression, but exhibits different characteristics."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1008003,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0bfc6add0390f1b4cfbd0e90ac71475cca88b2d5",
            "isKey": false,
            "numCitedBy": 1930,
            "numCiting": 219,
            "paperAbstract": {
                "fragments": [],
                "text": "Multi-label learning studies the problem where each example is represented by a single instance while associated with a set of labels simultaneously. During the past decade, significant amount of progresses have been made toward this emerging machine learning paradigm. This paper aims to provide a timely review on this area with emphasis on state-of-the-art multi-label learning algorithms. Firstly, fundamentals on multi-label learning including formal definition and evaluation metrics are given. Secondly and primarily, eight representative multi-label learning algorithms are scrutinized under common notations with relevant analyses and discussions. Thirdly, several related learning settings are briefly summarized. As a conclusion, online resources and open research problems on multi-label learning are outlined for reference purposes."
            },
            "slug": "A-Review-on-Multi-Label-Learning-Algorithms-Zhang-Zhou",
            "title": {
                "fragments": [],
                "text": "A Review on Multi-Label Learning Algorithms"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This paper aims to provide a timely review on this area with emphasis on state-of-the-art multi-label learning algorithms with relevant analyses and discussions."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Knowledge and Data Engineering"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46867608"
                        ],
                        "name": "Yu Zhang",
                        "slug": "Yu-Zhang",
                        "structuredName": {
                            "firstName": "Yu",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yu Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1739816"
                        ],
                        "name": "D. Yeung",
                        "slug": "D.-Yeung",
                        "structuredName": {
                            "firstName": "Dit-Yan",
                            "lastName": "Yeung",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Yeung"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2149106394"
                        ],
                        "name": "Qian Xu",
                        "slug": "Qian-Xu",
                        "structuredName": {
                            "firstName": "Qian",
                            "lastName": "Xu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Qian Xu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 124,
                                "start": 120
                            }
                        ],
                        "text": "For multi-task feature selection methods based on the p,1 regularization, a probabilistic interpretation is proposed in [15], which shows that the p,1 regularizer corresponds to a prior: w j i \u223c GN (0, \u03c1 j , p), where GN (\u00b7, \u00b7, \u00b7) denotes the generalized normal distribution."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 254,
                                "start": 250
                            }
                        ],
                        "text": "The difference between [16] and [17] is that in [16], the horseshoeprior is generalized to learn feature covariance, while in [17], the horseshoe prior is used as a basic prior and the whole model is to identify outlier tasks in a way different from [15]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 35,
                                "start": 31
                            }
                        ],
                        "text": "Then this prior is extended in [15] to thematrix-variate generalized normal prior to learn relations among tasks and identify outlier tasks simultaneously."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 10474507,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "095ea511a1f3c08525f0c4a507c4b406b847562b",
            "isKey": false,
            "numCitedBy": 91,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": "Recently, some variants of the l1 norm, particularly matrix norms such as the l1,2 and l1,\u221e norms, have been widely used in multi-task learning, compressed sensing and other related areas to enforce sparsity via joint regularization. In this paper, we unify the l1,2 and l1,\u221e norms by considering a family of l1,q norms for 1 < q < \u221e and study the problem of determining the most appropriate sparsity enforcing norm to use in the context of multi-task feature selection. Using the generalized normal distribution, we provide a probabilistic interpretation of the general multi-task feature selection problem using the l1,q norm. Based on this probabilistic interpretation, we develop a probabilistic model using the noninformative Jeffreys prior. We also extend the model to learn and exploit more general types of pairwise relationships between tasks. For both versions of the model, we devise expectation-maximization (EM) algorithms to learn all model parameters, including q, automatically. Experiments have been conducted on two cancer classification applications using microarray gene expression data."
            },
            "slug": "Probabilistic-Multi-Task-Feature-Selection-Zhang-Yeung",
            "title": {
                "fragments": [],
                "text": "Probabilistic Multi-Task Feature Selection"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A probabilistic interpretation of the general multi-task feature selection problem using the l1,q norm is provided and a Probabilistic model is developed using the noninformative Jeffreys prior to extend the model to learn and exploit more general types of pairwise relationships between tasks."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2153634676"
                        ],
                        "name": "Yu Zhang",
                        "slug": "Yu-Zhang",
                        "structuredName": {
                            "firstName": "Yu",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yu Zhang"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 7,
                                "start": 3
                            }
                        ],
                        "text": "In [82], a parallelMTLmethod is devised to solve a subproblemof theMTRLmodel [44], which also occurs in many regularized methodsbelonging to the task-relation learning approach."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 104,
                                "start": 100
                            }
                        ],
                        "text": "Moreover, three loss functions, including the hinge, -insensitive and square losses, are studied in [82], making this parallel method applicable to both classification and regression problems inMTSL."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 11231496,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a433f22ce308e0df7a9c572fd6fe2c8613a33d44",
            "isKey": false,
            "numCitedBy": 27,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we develop parallel algorithms for a family of regularized multi-task methods which can model task relations under the regularization framework. Since those multi-task methods cannot be parallelized directly, we use the FISTA algorithm, which in each iteration constructs a surrogate function of the original problem by utilizing the Lipschitz structure of the objective function based on the solution in the last iteration, to solve it. Specifically, we investigate the dual form of the objective function in those methods by adopting the hinge, e-insensitive, and square losses to deal with multi-task classification and regression problems, and then utilize the Lipschitz structure to construct the surrogate function for the dual forms. The surrogate functions constructed in the FISTA algorithm are founded to be decomposable, leading to parallel designs for those multi-task methods. Experiments on several benchmark datasets show that the convergence of the proposed algorithms is as fast as that of SMO-style algorithms and the parallel design can speedup the computation."
            },
            "slug": "Parallel-Multi-task-Learning-Zhang",
            "title": {
                "fragments": [],
                "text": "Parallel Multi-task Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "Experiments on several benchmark datasets show that the convergence of the proposed algorithms is as fast as that of SMO-style algorithms and the parallel design can speedup the computation."
            },
            "venue": {
                "fragments": [],
                "text": "2015 IEEE International Conference on Data Mining"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1720974"
                        ],
                        "name": "Pratik Jawanpuria",
                        "slug": "Pratik-Jawanpuria",
                        "structuredName": {
                            "firstName": "Pratik",
                            "lastName": "Jawanpuria",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Pratik Jawanpuria"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145475872"
                        ],
                        "name": "SakethaNath Jagarlapudi",
                        "slug": "SakethaNath-Jagarlapudi",
                        "structuredName": {
                            "firstName": "SakethaNath",
                            "lastName": "Jagarlapudi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "SakethaNath Jagarlapudi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 11,
                                "start": 7
                            }
                        ],
                        "text": "Unlike [58] where each level involves a subset of tasks, a multi-level taskclustering method is proposed in [34] to cluster all the tasks at each level based on a structurally sparse regularizer \u2211h i=1 \u03bb \u03b7i\u22121 \u2211 k> j \u2016w j i \u2212 wk i \u20162."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 7,
                                "start": 3
                            }
                        ],
                        "text": "In [58], all possible task clusters are enumerated,"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 483797,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e5a97aad11c105d7c2defc90b4ea9e5fd6f736b5",
            "isKey": false,
            "numCitedBy": 24,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper considers the multi-task learning problem and in the setting where some relevant features could be shared across few related tasks. Most of the existing methods assume the extent to which the given tasks are related or share a common feature space to be known apriori. In real-world applications however, it is desirable to automatically discover the groups of related tasks that share a feature space. In this paper we aim at searching the exponentially large space of all possible groups of tasks that may share a feature space. The main contribution is a convex formulation that employs a graph-based regularizer and simultaneously discovers few groups of related tasks, having close-by task parameters, as well as the feature space shared within each group. The regularizer encodes an important structure among the groups of tasks leading to an efficient algorithm for solving it: if there is no feature space under which a group of tasks has close-by task parameters, then there does not exist such a feature space for any of its supersets. An efficient active set algorithm that exploits this simplification and performs a clever search in the exponentially large space is presented. The algorithm is guaranteed to solve the proposed formulation (within some precision) in a time polynomial in the number of groups of related tasks discovered. Empirical results on benchmark datasets show that the proposed formulation achieves good generalization and outperforms state-of-the-art multi-task learning algorithms in some cases."
            },
            "slug": "A-Convex-Feature-Learning-Formulation-for-Latent-Jawanpuria-Jagarlapudi",
            "title": {
                "fragments": [],
                "text": "A Convex Feature Learning Formulation for Latent Task Structure Discovery"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "The main contribution is a convex formulation that employs a graph-based regularizer and simultaneously discovers few groups of related tasks, having close-by task parameters, as well as the feature space shared within each group."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1806773"
                        ],
                        "name": "Ishan Misra",
                        "slug": "Ishan-Misra",
                        "structuredName": {
                            "firstName": "Ishan",
                            "lastName": "Misra",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ishan Misra"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1781242"
                        ],
                        "name": "Abhinav Shrivastava",
                        "slug": "Abhinav-Shrivastava",
                        "structuredName": {
                            "firstName": "Abhinav",
                            "lastName": "Shrivastava",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Abhinav Shrivastava"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1726095131"
                        ],
                        "name": "A. Gupta",
                        "slug": "A.-Gupta",
                        "structuredName": {
                            "firstName": "Abhinav",
                            "lastName": "Gupta",
                            "middleNames": [
                                "Kumar"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Gupta"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145670946"
                        ],
                        "name": "M. Hebert",
                        "slug": "M.-Hebert",
                        "structuredName": {
                            "firstName": "Martial",
                            "lastName": "Hebert",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Hebert"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 67,
                                "start": 63
                            }
                        ],
                        "text": "Unlike these deep models, the cross-stitch network proposed in [23] combines the hidden feature representations of two tasks to construct more powerful hidden feature representations."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1923223,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f14325ec3041a73118bc4d819204cbbca07d5a71",
            "isKey": false,
            "numCitedBy": 709,
            "numCiting": 68,
            "paperAbstract": {
                "fragments": [],
                "text": "Multi-task learning in Convolutional Networks has displayed remarkable success in the field of recognition. This success can be largely attributed to learning shared representations from multiple supervisory tasks. However, existing multi-task approaches rely on enumerating multiple network architectures specific to the tasks at hand, that do not generalize. In this paper, we propose a principled approach to learn shared representations in ConvNets using multitask learning. Specifically, we propose a new sharing unit: \"cross-stitch\" unit. These units combine the activations from multiple networks and can be trained end-to-end. A network with cross-stitch units can learn an optimal combination of shared and task-specific representations. Our proposed method generalizes across multiple tasks and shows dramatically improved performance over baseline methods for categories with few training examples."
            },
            "slug": "Cross-Stitch-Networks-for-Multi-task-Learning-Misra-Shrivastava",
            "title": {
                "fragments": [],
                "text": "Cross-Stitch Networks for Multi-task Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This paper proposes a principled approach to learn shared representations in Convolutional Networks using multitask learning using a new sharing unit: \"cross-stitch\" unit that combines the activations from multiple networks and can be trained end-to-end."
            },
            "venue": {
                "fragments": [],
                "text": "2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38070424"
                        ],
                        "name": "R. Ando",
                        "slug": "R.-Ando",
                        "structuredName": {
                            "firstName": "Rie",
                            "lastName": "Ando",
                            "middleNames": [
                                "Kubota"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Ando"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2117881943"
                        ],
                        "name": "Tong Zhang",
                        "slug": "Tong-Zhang",
                        "structuredName": {
                            "firstName": "Tong",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tong Zhang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 7,
                                "start": 3
                            }
                        ],
                        "text": "In [24], the model parameters of the m tasks are assumed to share a low-rank subspace, leading to a"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 13650160,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "944e1a7b2c5c62e952418d7684e3cade89c76f87",
            "isKey": false,
            "numCitedBy": 1414,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "One of the most important issues in machine learning is whether one can improve the performance of a supervised learning algorithm by including unlabeled data. Methods that use both labeled and unlabeled data are generally referred to as semi-supervised learning. Although a number of such methods are proposed, at the current stage, we still don't have a complete understanding of their effectiveness. This paper investigates a closely related problem, which leads to a novel approach to semi-supervised learning. Specifically we consider learning predictive structures on hypothesis spaces (that is, what kind of classifiers have good predictive power) from multiple learning tasks. We present a general framework in which the structural learning problem can be formulated and analyzed theoretically, and relate it to learning with unlabeled data. Under this framework, algorithms for structural learning will be proposed, and computational issues will be investigated. Experiments will be given to demonstrate the effectiveness of the proposed algorithms in the semi-supervised learning setting."
            },
            "slug": "A-Framework-for-Learning-Predictive-Structures-from-Ando-Zhang",
            "title": {
                "fragments": [],
                "text": "A Framework for Learning Predictive Structures from Multiple Tasks and Unlabeled Data"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This paper presents a general framework in which the structural learning problem can be formulated and analyzed theoretically, and relate it to learning with unlabeled data, and algorithms for structural learning will be proposed, and computational issues will be investigated."
            },
            "venue": {
                "fragments": [],
                "text": "J. Mach. Learn. Res."
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2153634676"
                        ],
                        "name": "Yu Zhang",
                        "slug": "Yu-Zhang",
                        "structuredName": {
                            "firstName": "Yu",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yu Zhang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 181,
                                "start": 176
                            }
                        ],
                        "text": "[7,134] for the feature transform approach, [135] for the feature selection approach, [24,135\u2013138] for the lowrank approach, [136] for the task-relation learning approach, and [138] for the dirty approach."
                    },
                    "intents": []
                }
            ],
            "corpusId": 490376,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "19fcc801e4e758b428202b15f2dbb4be17e9cb64",
            "isKey": false,
            "numCitedBy": 31,
            "numCiting": 41,
            "paperAbstract": {
                "fragments": [],
                "text": "\n \n In this paper, we study multi-task algorithms from the perspective of the algorithmic stability. We give a definition of the multi-task uniform stability, a generalization of the conventional uniform stability, which measures the maximum difference between the loss of a multi-task algorithm trained on a data set and that of the multi-task algorithm trained on the same data set but with a data point removed in each task. In order to analyze multi-task algorithms based on multi-task uniform stability, we prove a generalized McDiarmid's inequality which assumes the difference bound condition holds by changing multiple input arguments instead of only one in the conventional McDiarmid's inequality. By using the generalized McDiarmid's inequality as a tool, we can analyze the generalization performance of general multi-task algorithms in terms of the multi-task uniform stability. Moreover, as applications, we prove generalization bounds of several representative regularized multi-task algorithms.\n \n"
            },
            "slug": "Multi-Task-Learning-and-Algorithmic-Stability-Zhang",
            "title": {
                "fragments": [],
                "text": "Multi-Task Learning and Algorithmic Stability"
            },
            "tldr": {
                "abstractSimilarityScore": 67,
                "text": "In this paper, a definition of the multi-task uniform stability is given, a generalization of the conventional uniform stability, which measures the maximum difference between the loss of a multi- task algorithm trained on a data set but with a data point removed in each task."
            },
            "venue": {
                "fragments": [],
                "text": "AAAI"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3243047"
                        ],
                        "name": "A. Acharya",
                        "slug": "A.-Acharya",
                        "structuredName": {
                            "firstName": "Ayan",
                            "lastName": "Acharya",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Acharya"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1797655"
                        ],
                        "name": "R. Mooney",
                        "slug": "R.-Mooney",
                        "structuredName": {
                            "firstName": "Raymond",
                            "lastName": "Mooney",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Mooney"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1379535322"
                        ],
                        "name": "J. Ghosh",
                        "slug": "J.-Ghosh",
                        "structuredName": {
                            "firstName": "Joydeep",
                            "lastName": "Ghosh",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Ghosh"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 20,
                                "start": 16
                            }
                        ],
                        "text": "Unlike [66], in [67] where the learner in each task is a supervised latent Dirichlet allocation model, the selection criterion for unlabeled data is the expected error reduction."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 215543105,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "15f00a519e7d754cbeb0b6e344eb9512b139803a",
            "isKey": false,
            "numCitedBy": 33,
            "numCiting": 49,
            "paperAbstract": {
                "fragments": [],
                "text": "Multitask learning (MTL) via a shared representation has been adopted to alleviate problems with sparsity of labeled data across different learning tasks. Active learning, on the other hand, reduces the cost of labeling examples by making informative queries over an unlabeled pool of data. Therefore, a unification of both of these approaches can potentially be useful in settings where labeled information is expensive to obtain but the learning tasks or domains have some common characteristics. This paper introduces two such models \u2013 Active Doubly Supervised Latent Dirichlet Allocation (Act-DSLDA) and its non-parametric variation (ActNPDSLDA) that integrate MTL and active learning in the same framework. These models make use of both latent and supervised shared topics to accomplish multitask learning. Experimental results on both document and image classification show that integrating MTL and active learning along with shared latent and supervised topics is superior to other methods which do not employ all of these components."
            },
            "slug": "Active-Multitask-Learning-Using-Both-Latent-and-Acharya-Mooney",
            "title": {
                "fragments": [],
                "text": "Active Multitask Learning Using Both Latent and Supervised Shared Topics"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "Experimental results show that integrating MTL and active learning along with shared latent and supervised topics is superior to other methods which do not employ all of these components."
            },
            "venue": {
                "fragments": [],
                "text": "SDM"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143602278"
                        ],
                        "name": "A. Jalali",
                        "slug": "A.-Jalali",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Jalali",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Jalali"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145969795"
                        ],
                        "name": "Pradeep Ravikumar",
                        "slug": "Pradeep-Ravikumar",
                        "structuredName": {
                            "firstName": "Pradeep",
                            "lastName": "Ravikumar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Pradeep Ravikumar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1701677"
                        ],
                        "name": "S. Sanghavi",
                        "slug": "S.-Sanghavi",
                        "structuredName": {
                            "firstName": "S.",
                            "lastName": "Sanghavi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Sanghavi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2052349476"
                        ],
                        "name": "Chao Ruan",
                        "slug": "Chao-Ruan",
                        "structuredName": {
                            "firstName": "Chao",
                            "lastName": "Ruan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chao Ruan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 65,
                                "start": 58
                            }
                        ],
                        "text": "Based on Table 1, we can see that the choices of g (U) in [53,56] make U row-sparse via the \u221e,1 and 2,1 norms, respectively."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 53,
                                "start": 46
                            }
                        ],
                        "text": "For V, h(V) makes it sparse via the 1 norm in [53,54] and column-sparse via the 2,1 norm in [55,56], while in [57], h(V) penalizes the complexity of V via the squared Frobenius norm."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 785634,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "895217d527de919dfdfbfeae5362bf5adba984ce",
            "isKey": false,
            "numCitedBy": 355,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "We consider multi-task learning in the setting of multiple linear regression, and where some relevant features could be shared across the tasks. Recent research has studied the use of l1/lq norm block-regularizations with q > 1 for such block-sparse structured problems, establishing strong guarantees on recovery even under high-dimensional scaling where the number of features scale with the number of observations. However, these papers also caution that the performance of such block-regularized methods are very dependent on the extent to which the features are shared across tasks. Indeed they show [8] that if the extent of overlap is less than a threshold, or even if parameter values in the shared features are highly uneven, then block l1/lq regularization could actually perform worse than simple separate elementwise l1 regularization. Since these caveats depend on the unknown true parameters, we might not know when and which method to apply. Even otherwise, we are far away from a realistic multi-task setting: not only do the set of relevant features have to be exactly the same across tasks, but their values have to as well. \n \nHere, we ask the question: can we leverage parameter overlap when it exists, but not pay a penalty when it does not? Indeed, this falls under a more general question of whether we can model such dirty data which may not fall into a single neat structural bracket (all block-sparse, or all low-rank and so on). With the explosion of such dirty high-dimensional data in modern settings, it is vital to develop tools - dirty models - to perform biased statistical estimation tailored to such data. Here, we take a first step, focusing on developing a dirty model for the multiple regression problem. Our method uses a very simple idea: we estimate a superposition of two sets of parameters and regularize them differently. We show both theoretically and empirically, our method strictly and noticeably outperforms both l1 or l1/lq methods, under high-dimensional scaling and over the entire range of possible overlaps (except at boundary cases, where we match the best method)."
            },
            "slug": "A-Dirty-Model-for-Multi-task-Learning-Jalali-Ravikumar",
            "title": {
                "fragments": [],
                "text": "A Dirty Model for Multi-task Learning"
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143626983"
                        ],
                        "name": "B. Bakker",
                        "slug": "B.-Bakker",
                        "structuredName": {
                            "firstName": "Bart",
                            "lastName": "Bakker",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Bakker"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1790356"
                        ],
                        "name": "T. Heskes",
                        "slug": "T.-Heskes",
                        "structuredName": {
                            "firstName": "Tom",
                            "lastName": "Heskes",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Heskes"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 14,
                                "start": 7
                            }
                        ],
                        "text": "Unlike [29,30], which areBayesianmodels, there are several regularized methods [31\u201335] to do task clustering."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 22,
                                "start": 18
                            }
                        ],
                        "text": "1, is proposed in [29] to cluster tasks based on the Gaussian mixture model in terms of model parameters (i."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 10436583,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a43d7b8e5e1bcb7c3fbf82164cfc9d12737176e8",
            "isKey": false,
            "numCitedBy": 594,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "Modeling a collection of similar regression or classification tasks can be improved by making the tasks 'learn from each other'. In machine learning, this subject is approached through 'multitask learning', where parallel tasks are modeled as multiple outputs of the same network. In multilevel analysis this is generally implemented through the mixed-effects linear model where a distinction is made between 'fixed effects', which are the same for all tasks, and 'random effects', which may vary between tasks. In the present article we will adopt a Bayesian approach in which some of the model parameters are shared (the same for all tasks) and others more loosely connected through a joint prior distribution that can be learned from the data. We seek in this way to combine the best parts of both the statistical multilevel approach and the neural network machinery. The standard assumption expressed in both approaches is that each task can learn equally well from any other task. In this article we extend the model by allowing more differentiation in the similarities between tasks. One such extension is to make the prior mean depend on higher-level task characteristics. More unsupervised clustering of tasks is obtained if we go from a single Gaussian prior to a mixture of Gaussians. This can be further generalized to a mixture of experts architecture with the gates depending on task characteristics. All three extensions are demonstrated through application both on an artificial data set and on two real-world problems, one a school problem and the other involving single-copy newspaper sales."
            },
            "slug": "Task-Clustering-and-Gating-for-Bayesian-Multitask-Bakker-Heskes",
            "title": {
                "fragments": [],
                "text": "Task Clustering and Gating for Bayesian Multitask Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A Bayesian approach is adopted in which some of the model parameters are shared and others more loosely connected through a joint prior distribution that can be learned from the data to combine the best parts of both the statistical multilevel approach and the neural network machinery."
            },
            "venue": {
                "fragments": [],
                "text": "J. Mach. Learn. Res."
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3157944"
                        ],
                        "name": "A. Saha",
                        "slug": "A.-Saha",
                        "structuredName": {
                            "firstName": "Avishek",
                            "lastName": "Saha",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Saha"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145593549"
                        ],
                        "name": "Piyush Rai",
                        "slug": "Piyush-Rai",
                        "structuredName": {
                            "firstName": "Piyush",
                            "lastName": "Rai",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Piyush Rai"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1722360"
                        ],
                        "name": "Hal Daum\u00e9",
                        "slug": "Hal-Daum\u00e9",
                        "structuredName": {
                            "firstName": "Hal",
                            "lastName": "Daum\u00e9",
                            "middleNames": [],
                            "suffix": "III"
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hal Daum\u00e9"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1747652"
                        ],
                        "name": "Suresh Venkatasubramanian",
                        "slug": "Suresh-Venkatasubramanian",
                        "structuredName": {
                            "firstName": "Suresh",
                            "lastName": "Venkatasubramanian",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Suresh Venkatasubramanian"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 7,
                                "start": 3
                            }
                        ],
                        "text": "In [79], an online algorithm is proposed for theMTRLmethod [44] by updating model parameters and task covariance together."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 7520138,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4356f269ac8724fd2d468efd64fd897aabd85282",
            "isKey": false,
            "numCitedBy": 127,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose an Online MultiTask Learning (Omtl) framework which simultaneously learns the task weight vectors as well as the task relatedness adaptively from the data. Our work is in contrast with prior work on online multitask learning which assumes fixed task relatedness, a priori. Furthermore, whereas prior work in such settings assume only positively correlated tasks, our framework can capture negative correlations as well. Our proposed framework learns the task relationship matrix by framing the objective function as a Bregman divergence minimization problem for positive definite matrices. Subsequently, we exploit this adaptively learned task-relationship matrix to select the most informative samples in an online multitask active learning setting. Experimental results on a number of real-world datasets and comparisons with numerous baselines establish the efficacy of our proposed approach."
            },
            "slug": "Online-Learning-of-Multiple-Tasks-and-Their-Saha-Rai",
            "title": {
                "fragments": [],
                "text": "Online Learning of Multiple Tasks and Their Relationships"
            },
            "tldr": {
                "abstractSimilarityScore": 70,
                "text": "This work proposes an Online MultiTask Learning (Omtl) framework which simultaneously learns the task weight vectors as well as the task relatedness adaptively from the data, and exploits this adaptively learned task-relationship matrix to select the most informative samples in an online multitask active learning setting."
            },
            "venue": {
                "fragments": [],
                "text": "AISTATS"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3263887"
                        ],
                        "name": "Christian Widmer",
                        "slug": "Christian-Widmer",
                        "structuredName": {
                            "firstName": "Christian",
                            "lastName": "Widmer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christian Widmer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143605658"
                        ],
                        "name": "J. Leiva",
                        "slug": "J.-Leiva",
                        "structuredName": {
                            "firstName": "Jose",
                            "lastName": "Leiva",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Leiva"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1783941"
                        ],
                        "name": "Y. Altun",
                        "slug": "Y.-Altun",
                        "structuredName": {
                            "firstName": "Yasemin",
                            "lastName": "Altun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Altun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2414086"
                        ],
                        "name": "G. R\u00e4tsch",
                        "slug": "G.-R\u00e4tsch",
                        "structuredName": {
                            "firstName": "Gunnar",
                            "lastName": "R\u00e4tsch",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. R\u00e4tsch"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 92,
                                "start": 87
                            }
                        ],
                        "text": "Applications of MTL in bioinformatics and health informatics include organism modeling [101], mechanism identification of response to therapeutic targets [102], cross-platform siRNA efficacy prediction [103], detection of causal genetic markers through association analysis of multiple"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 17022491,
            "fieldsOfStudy": [
                "Computer Science",
                "Biology"
            ],
            "id": "7a38b3ed5c310493a92a5881044e90f689896780",
            "isKey": false,
            "numCitedBy": 74,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "In this work we consider an inference task that biologists are very good at: deciphering biological processes by bringing together knowledge that has been obtained by experiments using various organisms, while respecting the differences and commonalities of these organisms We look at this problem from an sequence analysis point of view, where we aim at solving the same classification task in different organisms We investigate the challenge of combining information from several organisms, whereas we consider the relation between the organisms to be defined by a tree structure derived from their phylogeny Multitask learning, a machine learning technique that recently received considerable attention, considers the problem of learning across tasks that are related to each other We treat each organism as one task and present three novel multitask learning methods to handle situations in which the relationships among tasks can be described by a hierarchy These algorithms are designed for large-scale applications and are therefore applicable to problems with a large number of training examples, which are frequently encountered in sequence analysis We perform experimental analyses on synthetic data sets in order to illustrate the properties of our algorithms Moreover, we consider a problem from genomic sequence analysis, namely splice site recognition, to illustrate the usefulness of our approach We show that intelligently combining data from 15 eukaryotic organisms can indeed significantly improve the prediction performance compared to traditional learning approaches On a broader perspective, we expect that algorithms like the ones presented in this work have the potential to complement and enrich the strategy of homology-based sequence analysis that are currently the quasi-standard in biological sequence analysis."
            },
            "slug": "Leveraging-Sequence-Classification-by-Multitask-Widmer-Leiva",
            "title": {
                "fragments": [],
                "text": "Leveraging Sequence Classification by Taxonomy-Based Multitask Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "It is shown that intelligently combining data from 15 eukaryotic organisms can indeed significantly improve the prediction performance compared to traditional learning approaches, and it is expected that algorithms like the ones presented in this work have the potential to complement and enrich the strategy of homology-based sequence analysis."
            },
            "venue": {
                "fragments": [],
                "text": "RECOMB"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1746914"
                        ],
                        "name": "Sinno Jialin Pan",
                        "slug": "Sinno-Jialin-Pan",
                        "structuredName": {
                            "firstName": "Sinno",
                            "lastName": "Pan",
                            "middleNames": [
                                "Jialin"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sinno Jialin Pan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152290618"
                        ],
                        "name": "Qiang Yang",
                        "slug": "Qiang-Yang",
                        "structuredName": {
                            "firstName": "Qiang",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Qiang Yang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 82,
                                "start": 79
                            }
                        ],
                        "text": "MTL is related to other areas in machine learning, including transfer learning [2],multi-label learning [3] andmulti-output regression, but exhibits different characteristics."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 740063,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a25fbcbbae1e8f79c4360d26aa11a3abf1a11972",
            "isKey": false,
            "numCitedBy": 13493,
            "numCiting": 96,
            "paperAbstract": {
                "fragments": [],
                "text": "A major assumption in many machine learning and data mining algorithms is that the training and future data must be in the same feature space and have the same distribution. However, in many real-world applications, this assumption may not hold. For example, we sometimes have a classification task in one domain of interest, but we only have sufficient training data in another domain of interest, where the latter data may be in a different feature space or follow a different data distribution. In such cases, knowledge transfer, if done successfully, would greatly improve the performance of learning by avoiding much expensive data-labeling efforts. In recent years, transfer learning has emerged as a new learning framework to address this problem. This survey focuses on categorizing and reviewing the current progress on transfer learning for classification, regression, and clustering problems. In this survey, we discuss the relationship between transfer learning and other related machine learning techniques such as domain adaptation, multitask learning and sample selection bias, as well as covariate shift. We also explore some potential future issues in transfer learning research."
            },
            "slug": "A-Survey-on-Transfer-Learning-Pan-Yang",
            "title": {
                "fragments": [],
                "text": "A Survey on Transfer Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "The relationship between transfer learning and other related machine learning techniques such as domain adaptation, multitask learning and sample selection bias, as well as covariate shift are discussed."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Knowledge and Data Engineering"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3254390"
                        ],
                        "name": "A. Lazaric",
                        "slug": "A.-Lazaric",
                        "structuredName": {
                            "firstName": "Alessandro",
                            "lastName": "Lazaric",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Lazaric"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1678622"
                        ],
                        "name": "M. Ghavamzadeh",
                        "slug": "M.-Ghavamzadeh",
                        "structuredName": {
                            "firstName": "Mohammad",
                            "lastName": "Ghavamzadeh",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Ghavamzadeh"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 7,
                                "start": 3
                            }
                        ],
                        "text": "In [71], the reinforcement learning model for each task is a Gaussian process temporaldifference value function model and a hierarchical Bayesian model relates value functions of different tasks."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2988264,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "274f4ad2f9be649c297eba6bffa97540599569df",
            "isKey": false,
            "numCitedBy": 105,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "We consider the problem of multi-task reinforcement learning where the learner is provided with a set of tasks, for which only a small number of samples can be generated for any given policy. As the number of samples may not be enough to learn an accurate evaluation of the policy, it would be necessary to identify classes of tasks with similar structure and to learn them jointly. We consider the case where the tasks share structure in their value functions, and model this by assuming that the value functions are all sampled from a common prior. We adopt the Gaussian process temporal-difference value function model and use a hierarchical Bayesian approach to model the distribution over the value functions. We study two cases, where all the value functions belong to the same class and where they belong to an undefined number of classes. For each case, we present a hierarchical Bayesian model, and derive inference algorithms for (i) joint learning of the value functions, and (ii) efficient transfer of the information gained in (i) to assist learning the value function of a newly observed task."
            },
            "slug": "Bayesian-Multi-Task-Reinforcement-Learning-Lazaric-Ghavamzadeh",
            "title": {
                "fragments": [],
                "text": "Bayesian Multi-Task Reinforcement Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 70,
                "text": "This work considers the problem of multi-task reinforcement learning where the learner is provided with a set of tasks, for which only a small number of samples can be generated for any given policy, and adopts the Gaussian process temporal-difference value function model and uses a hierarchical Bayesian approach to model the distribution over the value functions."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2118044484"
                        ],
                        "name": "Xiao-Lei Zhang",
                        "slug": "Xiao-Lei-Zhang",
                        "structuredName": {
                            "firstName": "Xiao-Lei",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xiao-Lei Zhang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 7,
                                "start": 3
                            }
                        ],
                        "text": "In [62], twomulti-task-clustering methods are proposed."
                    },
                    "intents": []
                }
            ],
            "corpusId": 3140051,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d26553b06792d1d02e553ee5435cb353f1aae441",
            "isKey": false,
            "numCitedBy": 48,
            "numCiting": 74,
            "paperAbstract": {
                "fragments": [],
                "text": "Multitask clustering tries to improve the clustering performance of multiple tasks simultaneously by taking their relationship into account. Most existing multitask clustering algorithms fall into the type of generative clustering, and none are formulated as convex optimization problems. In this paper, we propose two convex Discriminative Multitask Clustering (DMTC) objectives to address the problems. The first one aims to learn a shared feature representation, which can be seen as a technical combination of the convex multitask feature learning and the convex Multiclass Maximum Margin Clustering (M3C). The second one aims to learn the task relationship, which can be seen as a combination of the convex multitask relationship learning and M3C. The objectives of the two algorithms are solved in a uniform procedure by the efficient cutting-plane algorithm and further unified in the Bayesian framework. Experimental results on a toy problem and two benchmark data sets demonstrate the effectiveness of the proposed algorithms."
            },
            "slug": "Convex-Discriminative-Multitask-Clustering-Zhang",
            "title": {
                "fragments": [],
                "text": "Convex Discriminative Multitask Clustering"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "Two convex Discriminative Multitask Clustering (DMTC) objectives to address the problems of multitask clustering are proposed and solved in a uniform procedure by the efficient cutting-plane algorithm and further unified in the Bayesian framework."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716876"
                        ],
                        "name": "O. Dekel",
                        "slug": "O.-Dekel",
                        "structuredName": {
                            "firstName": "Ofer",
                            "lastName": "Dekel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Dekel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144007105"
                        ],
                        "name": "Philip M. Long",
                        "slug": "Philip-M.-Long",
                        "structuredName": {
                            "firstName": "Philip",
                            "lastName": "Long",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Philip M. Long"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1740765"
                        ],
                        "name": "Y. Singer",
                        "slug": "Y.-Singer",
                        "structuredName": {
                            "firstName": "Yoram",
                            "lastName": "Singer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Singer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15173686,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ebe71a231f34dbf7d2cb29e6bc2b51d55d500d9b",
            "isKey": false,
            "numCitedBy": 67,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "We study the problem of learning multiple tasks in parallel within the online learning framework. On each online round, the algorithm receives an instance for each of the parallel tasks and responds by predicting the label of each instance. We consider the case where the predictions made on each round all contribute toward a common goal. The relationship between the various tasks is defined by a global loss function, which evaluates the overall quality of the multiple predictions made on each round. Specifically, each individual prediction is associated with its own loss value, and then these multiple loss values are combined into a single number using the global loss function. We focus on the case where the global loss function belongs to the family of absolute norms, and present several online learning algorithms for the induced problem. We prove worst-case relative loss bounds for all of our algorithms, and demonstrate the effectiveness of our approach on a large-scale multiclass-multilabel text categorization problem."
            },
            "slug": "Online-Learning-of-Multiple-Tasks-with-a-Shared-Dekel-Long",
            "title": {
                "fragments": [],
                "text": "Online Learning of Multiple Tasks with a Shared Loss"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This work focuses on the case where the global loss function belongs to the family of absolute norms, and presents several online learning algorithms for the induced problem, and proves worst-case relative loss bounds for all of the algorithms."
            },
            "venue": {
                "fragments": [],
                "text": "J. Mach. Learn. Res."
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2153690640"
                        ],
                        "name": "Xin Wang",
                        "slug": "Xin-Wang",
                        "structuredName": {
                            "firstName": "Xin",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xin Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38370684"
                        ],
                        "name": "J. Bi",
                        "slug": "J.-Bi",
                        "structuredName": {
                            "firstName": "Jinbo",
                            "lastName": "Bi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Bi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1911562"
                        ],
                        "name": "Shipeng Yu",
                        "slug": "Shipeng-Yu",
                        "structuredName": {
                            "firstName": "Shipeng",
                            "lastName": "Yu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shipeng Yu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1759553"
                        ],
                        "name": "Jiangwen Sun",
                        "slug": "Jiangwen-Sun",
                        "structuredName": {
                            "firstName": "Jiangwen",
                            "lastName": "Sun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jiangwen Sun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1725613"
                        ],
                        "name": "Minghu Song",
                        "slug": "Minghu-Song",
                        "structuredName": {
                            "firstName": "Minghu",
                            "lastName": "Song",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Minghu Song"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 33,
                                "start": 26
                            }
                        ],
                        "text": "This model is extended in [13,14] to more general settings."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2745737,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "26c799de539bb302824cb4a5fc43cdf835261907",
            "isKey": false,
            "numCitedBy": 41,
            "numCiting": 50,
            "paperAbstract": {
                "fragments": [],
                "text": "We investigate a general framework of multiplicative multitask feature learning which decomposes individual task's model parameters into a multiplication of two components. One of the components is used across all tasks and the other component is task-specific. Several previous methods can be proved to be special cases of our framework. We study the theoretical properties of this framework when different regularization conditions are applied to the two decomposed components. We prove that this framework is mathematically equivalent to the widely used multitask feature learning methods that are based on a joint regularization of all model parameters, but with a more general form of regularizers. Further, an analytical formula is derived for the across-task component as related to the task-specific component for all these regularizers, leading to a better understanding of the shrinkage effects of different regularizers. Study of this framework motivates new multitask learning algorithms. We propose two new learning formulations by varying the parameters in the proposed framework. An efficient blockwise coordinate descent algorithm is developed suitable for solving the entire family of formulations with rigorous convergence analysis. Simulation studies have identified the statistical properties of data that would be in favor of the new formulations. Extensive empirical studies on various classification and regression benchmark data sets have revealed the relative advantages of the two new formulations by comparing with the state of the art, which provides instructive insights into the feature learning problem with multiple tasks."
            },
            "slug": "Multiplicative-Multitask-Feature-Learning-Wang-Bi",
            "title": {
                "fragments": [],
                "text": "Multiplicative Multitask Feature Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "This framework is mathematically equivalent to the widely used multitask feature learning methods that are based on a joint regularization of all model parameters, but with a more general form of regularizers, leading to a better understanding of the shrinkage effects of different regularizers."
            },
            "venue": {
                "fragments": [],
                "text": "J. Mach. Learn. Res."
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1762757"
                        ],
                        "name": "Roi Reichart",
                        "slug": "Roi-Reichart",
                        "structuredName": {
                            "firstName": "Roi",
                            "lastName": "Reichart",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Roi Reichart"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3357473"
                        ],
                        "name": "Katrin Tomanek",
                        "slug": "Katrin-Tomanek",
                        "structuredName": {
                            "firstName": "Katrin",
                            "lastName": "Tomanek",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Katrin Tomanek"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1744669"
                        ],
                        "name": "U. Hahn",
                        "slug": "U.-Hahn",
                        "structuredName": {
                            "firstName": "Udo",
                            "lastName": "Hahn",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "U. Hahn"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145009917"
                        ],
                        "name": "A. Rappoport",
                        "slug": "A.-Rappoport",
                        "structuredName": {
                            "firstName": "Ari",
                            "lastName": "Rappoport",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Rappoport"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15889786,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8436ccce5e70bd09127a3adad4fc03159574ee07",
            "isKey": false,
            "numCitedBy": 98,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "We extend the classical single-task active learning (AL) approach. In the multi-task active learning (MTAL) paradigm, we select examples for several annotation tasks rather than for a single one as usually done in the context of AL. We introduce two MTAL metaprotocols, alternating selection and rank combination, and propose a method to implement them in practice. We experiment with a twotask annotation scenario that includes named entity and syntactic parse tree annotations on three different corpora. MTAL outperforms random selection and a stronger baseline, onesided example selection, in which one task is pursued using AL and the selected examples are provided also to the other task."
            },
            "slug": "Multi-Task-Active-Learning-for-Linguistic-Reichart-Tomanek",
            "title": {
                "fragments": [],
                "text": "Multi-Task Active Learning for Linguistic Annotations"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "It is shown that MTAL outperforms random selection and a stronger baseline, onesided example selection, in which one task is pursued using AL and the selected examples are provided also to the other task."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3282196"
                        ],
                        "name": "Abrar H. Abdulnabi",
                        "slug": "Abrar-H.-Abdulnabi",
                        "structuredName": {
                            "firstName": "Abrar",
                            "lastName": "Abdulnabi",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Abrar H. Abdulnabi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2096527"
                        ],
                        "name": "G. Wang",
                        "slug": "G.-Wang",
                        "structuredName": {
                            "firstName": "G.",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1697700"
                        ],
                        "name": "Jiwen Lu",
                        "slug": "Jiwen-Lu",
                        "structuredName": {
                            "firstName": "Jiwen",
                            "lastName": "Lu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jiwen Lu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2370507"
                        ],
                        "name": "K. Jia",
                        "slug": "K.-Jia",
                        "structuredName": {
                            "firstName": "Kui",
                            "lastName": "Jia",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Jia"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 262,
                                "start": 258
                            }
                        ],
                        "text": "Applications of MTL based on non-facial images include object categorization [86], image segmentation [89,90], identifying brain imaging predictors [91], saliency detection [92], action recognition [93], scene classification [94], multi-attribute prediction [95], multi-camera person re-identification [96], and immediacy prediction [97]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 12588302,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f69cda1175c3ddf2d4e3f3789a6c743b1059ebb2",
            "isKey": false,
            "numCitedBy": 212,
            "numCiting": 63,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper proposes a joint multi-task learning algorithm to better predict attributes in images using deep convolutional neural networks (CNN). We consider learning binary semantic attributes through a multi-task CNN model, where each CNN will predict one binary attribute. The multi-task learning allows CNN models to simultaneously share visual knowledge among different attribute categories. Each CNN will generate attribute-specific feature representations, and then we apply multi-task learning on the features to predict their attributes. In our multi-task framework, we propose a method to decompose the overall model's parameters into a latent task matrix and combination matrix. Furthermore, under-sampled classifiers can leverage shared statistics from other classifiers to improve their performance. Natural grouping of attributes is applied such that attributes in the same group are encouraged to share more knowledge. Meanwhile, attributes in different groups will generally compete with each other, and consequently share less knowledge. We show the effectiveness of our method on two popular attribute datasets."
            },
            "slug": "Multi-Task-CNN-Model-for-Attribute-Prediction-Abdulnabi-Wang",
            "title": {
                "fragments": [],
                "text": "Multi-Task CNN Model for Attribute Prediction"
            },
            "tldr": {
                "abstractSimilarityScore": 67,
                "text": "A joint multi-task learning algorithm to better predict attributes in images using deep convolutional neural networks (CNN) and a method to decompose the overall model's parameters into a latent task matrix and combination matrix is proposed."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Multimedia"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3113725"
                        ],
                        "name": "V. Zheng",
                        "slug": "V.-Zheng",
                        "structuredName": {
                            "firstName": "Vincent",
                            "lastName": "Zheng",
                            "middleNames": [
                                "Wenchen"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Zheng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1746914"
                        ],
                        "name": "Sinno Jialin Pan",
                        "slug": "Sinno-Jialin-Pan",
                        "structuredName": {
                            "firstName": "Sinno",
                            "lastName": "Pan",
                            "middleNames": [
                                "Jialin"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sinno Jialin Pan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152290618"
                        ],
                        "name": "Qiang Yang",
                        "slug": "Qiang-Yang",
                        "structuredName": {
                            "firstName": "Qiang",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Qiang Yang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1730133"
                        ],
                        "name": "J. J. Pan",
                        "slug": "J.-J.-Pan",
                        "structuredName": {
                            "firstName": "Jeffrey",
                            "lastName": "Pan",
                            "middleNames": [
                                "Junfeng"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. J. Pan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 107,
                                "start": 102
                            }
                        ],
                        "text": "Applications of MTL in ubiquitous computing include stock prediction [126], multi-device localization [127], the inverse dynamics problem for robotics [128,129], estimation of travel costs on road networks [130], travel-time prediction on road networks [131], and traffic-sign recognition [132]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2467509,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e618d29c48500ad84e215ed0be35c776cd59f7bd",
            "isKey": false,
            "numCitedBy": 99,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we propose a latent multi-task learning algorithm to solve the multi-device indoor localization problem. Traditional indoor localization systems often assume that the collected signal data distributions are fixed, and thus the localization model learned on one device can be used on other devices without adaptation. However, by empirically studying the signal variation over different devices, we found this assumption to be invalid in practice. To solve this problem, we treat multiple devices as multiple learning tasks, and propose a multi-task learning algorithm. Different from algorithms assuming that the hypotheses learned from the original data space for related tasks can be similar, we only require the hypotheses learned in a latent feature space are similar. To establish our algorithm, we employ an alternating optimization approach to iteratively learn feature mappings and multi-task regression models for the devices. We apply our latent multi-task learning algorithm to real-world indoor localization data and demonstrate its effectiveness."
            },
            "slug": "Transferring-Multi-device-Localization-Models-using-Zheng-Pan",
            "title": {
                "fragments": [],
                "text": "Transferring Multi-device Localization Models using Latent Multi-task Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 50,
                "text": "A latent multi-task learning algorithm that treats multiple devices as multiple learning tasks, and requires the hypotheses learned in a latent feature space are similar to solve the multi-device indoor localization problem."
            },
            "venue": {
                "fragments": [],
                "text": "AAAI"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39161025"
                        ],
                        "name": "Alon Zweig",
                        "slug": "Alon-Zweig",
                        "structuredName": {
                            "firstName": "Alon",
                            "lastName": "Zweig",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alon Zweig"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1789171"
                        ],
                        "name": "D. Weinshall",
                        "slug": "D.-Weinshall",
                        "structuredName": {
                            "firstName": "Daphna",
                            "lastName": "Weinshall",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Weinshall"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 7,
                                "start": 3
                            }
                        ],
                        "text": "In [59], each component matrix is assumed to be jointly sparse and row-sparse but in different proportions, which are more similar in successive component matrices."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14089568,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bff05119cd30c2c61323861a5e2a28094388427f",
            "isKey": false,
            "numCitedBy": 38,
            "numCiting": 41,
            "paperAbstract": {
                "fragments": [],
                "text": "As the sheer volume of available benchmark datasets increases, the problem of joint learning of classifiers and knowledge-transfer between classifiers, becomes more and more relevant. We present a hierarchical approach which exploits information sharing among different classification tasks, in multitask and multi-class settings. It engages a top-down iterative method, which begins by posing an optimization problem with an incentive for large scale sharing among all classes. This incentive to share is gradually decreased, until there is no sharing and all tasks are considered separately. The method therefore exploits different levels of sharing within a given group of related tasks, without having to make hard decisions about the grouping of tasks. In order to deal with large scale problems, with many tasks and many classes, we extend our batch approach to an online setting and provide regret analysis of the algorithm. We tested our approach extensively on synthetic and real datasets, showing significant improvement over baseline and state-of-the-art methods."
            },
            "slug": "Hierarchical-Regularization-Cascade-for-Joint-Zweig-Weinshall",
            "title": {
                "fragments": [],
                "text": "Hierarchical Regularization Cascade for Joint Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This work presents a hierarchical approach which exploits information sharing among different classification tasks, in multitask and multi-class settings, by engaging a top-down iterative method which begins by posing an optimization problem with an incentive for large scale sharing among all classes."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1730609"
                        ],
                        "name": "O. Chapelle",
                        "slug": "O.-Chapelle",
                        "structuredName": {
                            "firstName": "Olivier",
                            "lastName": "Chapelle",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Chapelle"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2248631"
                        ],
                        "name": "Pannagadatta K. Shivaswamy",
                        "slug": "Pannagadatta-K.-Shivaswamy",
                        "structuredName": {
                            "firstName": "Pannagadatta",
                            "lastName": "Shivaswamy",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Pannagadatta K. Shivaswamy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1792519"
                        ],
                        "name": "Srinivas Vadrevu",
                        "slug": "Srinivas-Vadrevu",
                        "structuredName": {
                            "firstName": "Srinivas",
                            "lastName": "Vadrevu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Srinivas Vadrevu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7446832"
                        ],
                        "name": "Kilian Q. Weinberger",
                        "slug": "Kilian-Q.-Weinberger",
                        "structuredName": {
                            "firstName": "Kilian",
                            "lastName": "Weinberger",
                            "middleNames": [
                                "Q."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kilian Q. Weinberger"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2910574"
                        ],
                        "name": "Ya Zhang",
                        "slug": "Ya-Zhang",
                        "structuredName": {
                            "firstName": "Ya",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ya Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2409063"
                        ],
                        "name": "B. Tseng",
                        "slug": "B.-Tseng",
                        "structuredName": {
                            "firstName": "Belle",
                            "lastName": "Tseng",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Tseng"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7554099,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8a4cd5b32504b4e5ea0f02836abe70e27e5b334f",
            "isKey": false,
            "numCitedBy": 103,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we propose a novel algorithm for multi-task learning with boosted decision trees. We learn several different learning tasks with a joint model, explicitly addressing the specifics of each learning task with task-specific parameters and the commonalities between them through shared parameters. This enables implicit data sharing and regularization. We evaluate our learning method on web-search ranking data sets from several countries. Here, multitask learning is particularly helpful as data sets from different countries vary largely in size because of the cost of editorial judgments. Our experiments validate that learning various tasks jointly can lead to significant improvements in performance with surprising reliability."
            },
            "slug": "Multi-task-learning-for-boosting-with-application-Chapelle-Shivaswamy",
            "title": {
                "fragments": [],
                "text": "Multi-task learning for boosting with application to web search ranking"
            },
            "tldr": {
                "abstractSimilarityScore": 91,
                "text": "A novel algorithm for multi-task learning with boosted decision trees that learns several different learning tasks with a joint model, explicitly addressing the specifics of each learning task with task-specific parameters and the commonalities between them through shared parameters."
            },
            "venue": {
                "fragments": [],
                "text": "KDD"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2939803"
                        ],
                        "name": "Ronan Collobert",
                        "slug": "Ronan-Collobert",
                        "structuredName": {
                            "firstName": "Ronan",
                            "lastName": "Collobert",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ronan Collobert"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145183709"
                        ],
                        "name": "J. Weston",
                        "slug": "J.-Weston",
                        "structuredName": {
                            "firstName": "Jason",
                            "lastName": "Weston",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Weston"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 139,
                                "start": 134
                            }
                        ],
                        "text": "part-of-speech tagging, chunking, named entity recognition, semantic role labeling, language modeling and semantically related words) [116], multi-domain sentiment classification [117], multidomain dialog state tracking [21], machine translation [118], syntactic parsing [118], and microblog analysis [119,120]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2617020,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "57458bc1cffe5caa45a885af986d70f723f406b4",
            "isKey": false,
            "numCitedBy": 5024,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a single convolutional neural network architecture that, given a sentence, outputs a host of language processing predictions: part-of-speech tags, chunks, named entity tags, semantic roles, semantically similar words and the likelihood that the sentence makes sense (grammatically and semantically) using a language model. The entire network is trained jointly on all these tasks using weight-sharing, an instance of multitask learning. All the tasks use labeled data except the language model which is learnt from unlabeled text and represents a novel form of semi-supervised learning for the shared tasks. We show how both multitask learning and semi-supervised learning improve the generalization of the shared tasks, resulting in state-of-the-art-performance."
            },
            "slug": "A-unified-architecture-for-natural-language-deep-Collobert-Weston",
            "title": {
                "fragments": [],
                "text": "A unified architecture for natural language processing: deep neural networks with multitask learning"
            },
            "tldr": {
                "abstractSimilarityScore": 93,
                "text": "This work describes a single convolutional neural network architecture that, given a sentence, outputs a host of language processing predictions: part-of-speech tags, chunks, named entity tags, semantic roles, semantically similar words and the likelihood that the sentence makes sense using a language model."
            },
            "venue": {
                "fragments": [],
                "text": "ICML '08"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2115844592"
                        ],
                        "name": "Xiao-Tong Yuan",
                        "slug": "Xiao-Tong-Yuan",
                        "structuredName": {
                            "firstName": "Xiao-Tong",
                            "lastName": "Yuan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xiao-Tong Yuan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143653681"
                        ],
                        "name": "Shuicheng Yan",
                        "slug": "Shuicheng-Yan",
                        "structuredName": {
                            "firstName": "Shuicheng",
                            "lastName": "Yan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shuicheng Yan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 154,
                                "start": 150
                            }
                        ],
                        "text": "Specifically, applications of MTL based on facial images include face verification [84], personalized age estimation [85], multi-cue face recognition [86], head-pose estimation [22,87], facial landmark detection [18], and facial image rotation [88]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 81,
                                "start": 77
                            }
                        ],
                        "text": "Applications of MTL based on non-facial images include object categorization [86], image segmentation [89,90], identifying brain imaging predictors [91], saliency detection [92], action recognition [93], scene classification [94], multi-attribute prediction [95], multi-camera person re-identification [96], and immediacy prediction [97]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 15853656,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8b0f43a9eb75d97fc7d9d78bdf983813fb07bd1e",
            "isKey": false,
            "numCitedBy": 315,
            "numCiting": 64,
            "paperAbstract": {
                "fragments": [],
                "text": "We address the problem of computing joint sparse representation of visual signal across multiple kernel-based representations. Such a problem arises naturally in supervised visual recognition applications where one aims to reconstruct a test sample with multiple features from as few training subjects as possible. We cast the linear version of this problem into a multi-task joint covariate selection model [15], which can be very efficiently optimized via ker-nelizable accelerated proximal gradient method. Furthermore, two kernel-view extensions of this method are provided to handle the situations where descriptors and similarity functions are in the form of kernel matrices. We then investigate into two applications of our algorithm to feature combination: 1) fusing gray-level and LBP features for face recognition, and 2) combining multiple kernels for object categorization. Experimental results on challenging real-world datasets show that the feature combination capability of our proposed algorithm is competitive to the state-of-the-art multiple kernel learning methods."
            },
            "slug": "Visual-classification-with-multi-task-joint-sparse-Yuan-Yan",
            "title": {
                "fragments": [],
                "text": "Visual classification with multi-task joint sparse representation"
            },
            "tldr": {
                "abstractSimilarityScore": 37,
                "text": "Experimental results on challenging real-world datasets show that the feature combination capability of the proposed algorithm is competitive to the state-of-the-art multiple kernel learning methods."
            },
            "venue": {
                "fragments": [],
                "text": "2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3038681"
                        ],
                        "name": "Giovanni Cavallanti",
                        "slug": "Giovanni-Cavallanti",
                        "structuredName": {
                            "firstName": "Giovanni",
                            "lastName": "Cavallanti",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Giovanni Cavallanti"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1388387856"
                        ],
                        "name": "N. Cesa-Bianchi",
                        "slug": "N.-Cesa-Bianchi",
                        "structuredName": {
                            "firstName": "Nicol\u00f2",
                            "lastName": "Cesa-Bianchi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Cesa-Bianchi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1895207"
                        ],
                        "name": "C. Gentile",
                        "slug": "C.-Gentile",
                        "structuredName": {
                            "firstName": "Claudio",
                            "lastName": "Gentile",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Gentile"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 7,
                                "start": 3
                            }
                        ],
                        "text": "In [77], online MTL algorithms, which adopt perceptrons as a basic model and measure task relations based on shared geometric structures"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1443517,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bd121bc3b54f847579fd0560f422a1241a03d579",
            "isKey": false,
            "numCitedBy": 184,
            "numCiting": 63,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce new Perceptron-based algorithms for the online multitask binary classification problem. Under suitable regularity conditions, our algorithms are shown to improve on their baselines by a factor proportional to the number of tasks. We achieve these improvements using various types of regularization that bias our algorithms towards specific notions of task relatedness. More specifically, similarity among tasks is either measured in terms of the geometric closeness of the task reference vectors or as a function of the dimension of their spanned subspace. In addition to adapting to the online setting a mix of known techniques, such as the multitask kernels of Evgeniou et al., our analysis also introduces a matrix-based multitask extension of the p-norm Perceptron, which is used to implement spectral co-regularization. Experiments on real-world data sets complement and support our theoretical findings."
            },
            "slug": "Linear-Algorithms-for-Online-Multitask-Cavallanti-Cesa-Bianchi",
            "title": {
                "fragments": [],
                "text": "Linear Algorithms for Online Multitask Classification"
            },
            "tldr": {
                "abstractSimilarityScore": 72,
                "text": "Under suitable regularity conditions, new Perceptron-based algorithms for the online multitask binary classification problem are shown to improve on their baselines by a factor proportional to the number of tasks."
            },
            "venue": {
                "fragments": [],
                "text": "COLT"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108153586"
                        ],
                        "name": "Wenlu Zhang",
                        "slug": "Wenlu-Zhang",
                        "structuredName": {
                            "firstName": "Wenlu",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wenlu Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8806594"
                        ],
                        "name": "Rongjian Li",
                        "slug": "Rongjian-Li",
                        "structuredName": {
                            "firstName": "Rongjian",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Rongjian Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144514329"
                        ],
                        "name": "Tao Zeng",
                        "slug": "Tao-Zeng",
                        "structuredName": {
                            "firstName": "Tao",
                            "lastName": "Zeng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tao Zeng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2112590875"
                        ],
                        "name": "Qian Sun",
                        "slug": "Qian-Sun",
                        "structuredName": {
                            "firstName": "Qian",
                            "lastName": "Sun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Qian Sun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2110208881"
                        ],
                        "name": "Sudhir Kumar",
                        "slug": "Sudhir-Kumar",
                        "structuredName": {
                            "firstName": "Sudhir",
                            "lastName": "Kumar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sudhir Kumar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144030870"
                        ],
                        "name": "Jieping Ye",
                        "slug": "Jieping-Ye",
                        "structuredName": {
                            "firstName": "Jieping",
                            "lastName": "Ye",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jieping Ye"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1743600"
                        ],
                        "name": "Shuiwang Ji",
                        "slug": "Shuiwang-Ji",
                        "structuredName": {
                            "firstName": "Shuiwang",
                            "lastName": "Ji",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shuiwang Ji"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 540,
                                "start": 536
                            }
                        ],
                        "text": "populations [104], construction of personalized brain\u2013computer interfaces [105], MHC-I binding prediction [106], splice-site prediction [106], protein subcellular location prediction [107], Alzheimer\u2019s disease assessment scale cognitive subscale [108], prediction of cognitive outcomes from neuroimaging measures in Alzheimer\u2019s disease [109], identification of longitudinal phenotypic markers for Alzheimer\u2019s disease progression prediction [110], prioritization of disease genes [111], biological image analysis based on natural images [20], survival analysis [112], and multiple genetic trait prediction [113]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 11206415,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a39bd32c9cbeff1abf6419adc697b584a7f69b78",
            "isKey": false,
            "numCitedBy": 131,
            "numCiting": 41,
            "paperAbstract": {
                "fragments": [],
                "text": "A central theme in learning from image data is to develop appropriate representations for the specific task at hand. Thus, a practical challenge is to determine what features are appropriate for specific tasks. For example, in the study of gene expression patterns in Drosophila, texture features were particularly effective for determining the developmental stages from in situ hybridization images. Such image representation is however not suitable for controlled vocabulary term annotation. Here, we developed feature extraction methods to generate hierarchical representations for ISH images. Our approach is based on the deep convolutional neural networks that can act on image pixels directly. To make the extracted features generic, the models were trained using a natural image set with millions of labeled examples. These models were transferred to the ISH image domain. To account for the differences between the source and target domains, we proposed a partial transfer learning scheme in which only part of the source model is transferred. We employed multi-task learning method to fine-tune the pre-trained models with labeled ISH images. Results showed that feature representations computed by deep models based on transfer and multi-task learning significantly outperformed other methods for annotating gene expression patterns at different stage ranges."
            },
            "slug": "Deep-Model-Based-Transfer-and-Multi-Task-Learning-Zhang-Li",
            "title": {
                "fragments": [],
                "text": "Deep Model Based Transfer and Multi-Task Learning for Biological Image Analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "Deep models based on transfer and multi-task learning significantly outperformed other methods for annotating gene expression patterns at different stage ranges and a partial transfer learning scheme was proposed."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Big Data"
            },
            "year": 2020
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145487992"
                        ],
                        "name": "Jiayu Zhou",
                        "slug": "Jiayu-Zhou",
                        "structuredName": {
                            "firstName": "Jiayu",
                            "lastName": "Zhou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jiayu Zhou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46201072"
                        ],
                        "name": "Lei Yuan",
                        "slug": "Lei-Yuan",
                        "structuredName": {
                            "firstName": "Lei",
                            "lastName": "Yuan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lei Yuan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39497343"
                        ],
                        "name": "Jun Liu",
                        "slug": "Jun-Liu",
                        "structuredName": {
                            "firstName": "Jun",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jun Liu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144030870"
                        ],
                        "name": "Jieping Ye",
                        "slug": "Jieping-Ye",
                        "structuredName": {
                            "firstName": "Jieping",
                            "lastName": "Ye",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jieping Ye"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 251,
                                "start": 246
                            }
                        ],
                        "text": "populations [104], construction of personalized brain\u2013computer interfaces [105], MHC-I binding prediction [106], splice-site prediction [106], protein subcellular location prediction [107], Alzheimer\u2019s disease assessment scale cognitive subscale [108], prediction of cognitive outcomes from neuroimaging measures in Alzheimer\u2019s disease [109], identification of longitudinal phenotypic markers for Alzheimer\u2019s disease progression prediction [110], prioritization of disease genes [111], biological image analysis based on natural images [20], survival analysis [112], and multiple genetic trait prediction [113]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 207189668,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "aec60f3368b4a31b9d9fc9d948e0c05c87f6d335",
            "isKey": false,
            "numCitedBy": 223,
            "numCiting": 42,
            "paperAbstract": {
                "fragments": [],
                "text": "Alzheimer's Disease (AD), the most common type of dementia, is a severe neurodegenerative disorder. Identifying markers that can track the progress of the disease has recently received increasing attentions in AD research. A definitive diagnosis of AD requires autopsy confirmation, thus many clinical/cognitive measures including Mini Mental State Examination (MMSE) and Alzheimer's Disease Assessment Scale cognitive subscale (ADAS-Cog) have been designed to evaluate the cognitive status of the patients and used as important criteria for clinical diagnosis of probable AD. In this paper, we propose a multi-task learning formulation for predicting the disease progression measured by the cognitive scores and selecting markers predictive of the progression. Specifically, we formulate the prediction problem as a multi-task regression problem by considering the prediction at each time point as a task. We capture the intrinsic relatedness among different tasks by a temporal group Lasso regularizer. The regularizer consists of two components including an L2,1-norm penalty on the regression weight vectors, which ensures that a small subset of features will be selected for the regression models at all time points, and a temporal smoothness term which ensures a small deviation between two regression models at successive time points. We have performed extensive evaluations using various types of data at the baseline from the Alzheimer's Disease Neuroimaging Initiative (ADNI) database for predicting the future MMSE and ADAS-Cog scores. Our experimental studies demonstrate the effectiveness of the proposed algorithm for capturing the progression trend and the cross-sectional group differences of AD severity. Results also show that most markers selected by the proposed algorithm are consistent with findings from existing cross-sectional studies."
            },
            "slug": "A-multi-task-learning-formulation-for-predicting-Zhou-Yuan",
            "title": {
                "fragments": [],
                "text": "A multi-task learning formulation for predicting disease progression"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "This paper proposes a multi-task learning formulation for predicting the disease progression measured by the cognitive scores and selecting markers predictive of the progression and shows that most markers selected by the proposed algorithm are consistent with findings from existing cross-sectional studies."
            },
            "venue": {
                "fragments": [],
                "text": "KDD"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2110342116"
                        ],
                        "name": "Tsuyoshi Kato",
                        "slug": "Tsuyoshi-Kato",
                        "structuredName": {
                            "firstName": "Tsuyoshi",
                            "lastName": "Kato",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tsuyoshi Kato"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2785830"
                        ],
                        "name": "H. Kashima",
                        "slug": "H.-Kashima",
                        "structuredName": {
                            "firstName": "Hisashi",
                            "lastName": "Kashima",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Kashima"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "67154907"
                        ],
                        "name": "Masashi Sugiyama",
                        "slug": "Masashi-Sugiyama",
                        "structuredName": {
                            "firstName": "Masashi",
                            "lastName": "Sugiyama",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Masashi Sugiyama"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1699299"
                        ],
                        "name": "K. Asai",
                        "slug": "K.-Asai",
                        "structuredName": {
                            "firstName": "Kiyoshi",
                            "lastName": "Asai",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Asai"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 7655632,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3e8ff54f8c863a3e9bfca7fb53aa2df0ee4d0619",
            "isKey": false,
            "numCitedBy": 42,
            "numCiting": 62,
            "paperAbstract": {
                "fragments": [],
                "text": "When we have several related tasks, solving them simultaneously has been shown to be more effective than solving them individually. This approach is called multitask learning (MTL). In this paper, we propose a novel MTL algorithm. Our method controls the relatedness among the tasks locally, so all pairs of related tasks are guaranteed to have similar solutions. We apply the above idea to support vector machines and show that the optimization problem can be cast as a second-order cone program, which is convex and can be solved efficiently. The usefulness of our approach is demonstrated in ordinal regression, link prediction, and collaborative filtering, each of which can be formulated as a structured multitask problem."
            },
            "slug": "Conic-Programming-for-Multitask-Learning-Kato-Kashima",
            "title": {
                "fragments": [],
                "text": "Conic Programming for Multitask Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "This paper applies the above idea to support vector machines and shows that the optimization problem can be cast as a second-order cone program, which is convex and can be solved efficiently."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Knowledge and Data Engineering"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2802529"
                        ],
                        "name": "Maksim Lapin",
                        "slug": "Maksim-Lapin",
                        "structuredName": {
                            "firstName": "Maksim",
                            "lastName": "Lapin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Maksim Lapin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48920094"
                        ],
                        "name": "B. Schiele",
                        "slug": "B.-Schiele",
                        "structuredName": {
                            "firstName": "Bernt",
                            "lastName": "Schiele",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Schiele"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143610806"
                        ],
                        "name": "Matthias Hein",
                        "slug": "Matthias-Hein",
                        "structuredName": {
                            "firstName": "Matthias",
                            "lastName": "Hein",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Matthias Hein"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 229,
                                "start": 225
                            }
                        ],
                        "text": "Applications of MTL based on non-facial images include object categorization [86], image segmentation [89,90], identifying brain imaging predictors [91], saliency detection [92], action recognition [93], scene classification [94], multi-attribute prediction [95], multi-camera person re-identification [96], and immediacy prediction [97]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 6497284,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6f649fea1c02c18e237d5cfa73314f882ac5af53",
            "isKey": false,
            "numCitedBy": 55,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "The underlying idea of multitask learning is that learning tasks jointly is better than learning each task individually. In particular, if only a few training examples are available for each task, sharing a jointly trained representation improves classification performance. In this paper, we propose a novel multitask learning method that learns a low-dimensional representation jointly with the corresponding classifiers, which are then able to profit from the latent inter-class correlations. Our method scales with respect to the original feature dimension and can be used with high-dimensional image descriptors such as the Fisher Vector. Furthermore, it consistently outperforms the current state of the art on the SUN397 scene classification benchmark with varying amounts of training data."
            },
            "slug": "Scalable-Multitask-Representation-Learning-for-Lapin-Schiele",
            "title": {
                "fragments": [],
                "text": "Scalable Multitask Representation Learning for Scene Classification"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "This paper proposes a novel multitask learning method that learns a low-dimensional representation jointly with the corresponding classifiers, which is then able to profit from the latent inter-class correlations."
            },
            "venue": {
                "fragments": [],
                "text": "2014 IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2113253801"
                        ],
                        "name": "Hua Wang",
                        "slug": "Hua-Wang",
                        "structuredName": {
                            "firstName": "Hua",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hua Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144962210"
                        ],
                        "name": "F. Nie",
                        "slug": "F.-Nie",
                        "structuredName": {
                            "firstName": "Feiping",
                            "lastName": "Nie",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Nie"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1748032"
                        ],
                        "name": "Heng Huang",
                        "slug": "Heng-Huang",
                        "structuredName": {
                            "firstName": "Heng",
                            "lastName": "Huang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Heng Huang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2678448"
                        ],
                        "name": "S. Risacher",
                        "slug": "S.-Risacher",
                        "structuredName": {
                            "firstName": "Shannon",
                            "lastName": "Risacher",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Risacher"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1737469"
                        ],
                        "name": "C. Ding",
                        "slug": "C.-Ding",
                        "structuredName": {
                            "firstName": "C.",
                            "lastName": "Ding",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Ding"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7992909"
                        ],
                        "name": "A. Saykin",
                        "slug": "A.-Saykin",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Saykin",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Saykin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144779870"
                        ],
                        "name": "Li Shen",
                        "slug": "Li-Shen",
                        "structuredName": {
                            "firstName": "Li",
                            "lastName": "Shen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Li Shen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 152,
                                "start": 148
                            }
                        ],
                        "text": "Applications of MTL based on non-facial images include object categorization [86], image segmentation [89,90], identifying brain imaging predictors [91], saliency detection [92], action recognition [93], scene classification [94], multi-attribute prediction [95], multi-camera person re-identification [96], and immediacy prediction [97]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 7512176,
            "fieldsOfStudy": [
                "Psychology",
                "Computer Science"
            ],
            "id": "ed89f5d136d299e46b89f7f18c9c10ba7c5335db",
            "isKey": false,
            "numCitedBy": 129,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "Alzheimer's disease (AD) is a neurodegenerative disorder characterized by progressive impairment of memory and other cognitive functions, which makes regression analysis a suitable model to study whether neuroimaging measures can help predict memory performance and track the progression of AD. Existing memory performance prediction methods via regression, however, do not take into account either the interconnected structures within imaging data or those among memory scores, which inevitably restricts their predictive capabilities. To bridge this gap, we propose a novel Sparse Multi-tAsk Regression and feaTure selection (SMART) method to jointly analyze all the imaging and clinical data under a single regression framework and with shared underlying sparse representations. Two convex regularizations are combined and used in the model to enable sparsity as well as facilitate multi-task learning. The effectiveness of the proposed method is demonstrated by both clearly improved prediction performances in all empirical test cases and a compact set of selected RAVLT-relevant MRI predictors that accord with prior studies."
            },
            "slug": "Sparse-multi-task-regression-and-feature-selection-Wang-Nie",
            "title": {
                "fragments": [],
                "text": "Sparse multi-task regression and feature selection to identify brain imaging predictors for memory performance"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A novel Sparse Multi-tAsk Regression and feaTure selection (SMART) method is proposed to jointly analyze all the imaging and clinical data under a single regression framework and with shared underlying sparse representations to enable sparsity as well as facilitate multi-task learning."
            },
            "venue": {
                "fragments": [],
                "text": "2011 International Conference on Computer Vision"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716876"
                        ],
                        "name": "O. Dekel",
                        "slug": "O.-Dekel",
                        "structuredName": {
                            "firstName": "Ofer",
                            "lastName": "Dekel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Dekel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144007105"
                        ],
                        "name": "Philip M. Long",
                        "slug": "Philip-M.-Long",
                        "structuredName": {
                            "firstName": "Philip",
                            "lastName": "Long",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Philip M. Long"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1740765"
                        ],
                        "name": "Y. Singer",
                        "slug": "Y.-Singer",
                        "structuredName": {
                            "firstName": "Yoram",
                            "lastName": "Singer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Singer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 24,
                                "start": 17
                            }
                        ],
                        "text": "Specifically, in [74,75], where different tasks are assumed to have a common goal, a global loss function, a combination of individual losses on each task, measures the relations between tasks, and by using absolute norms for the global loss function, several online MTL algorithms are proposed."
                    },
                    "intents": []
                }
            ],
            "corpusId": 14925373,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e71a2201cc771be0e10264dc19598ebd2145894f",
            "isKey": false,
            "numCitedBy": 69,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "We study the problem of online learning of multiple tasks in parallel. On each online round, the algorithm receives an instance and makes a prediction for each one of the parallel tasks. We consider the case where these tasks all contribute toward a common goal. We capture the relationship between the tasks by using a single global loss function to evaluate the quality of the multiple predictions made on each round. Specifically, each individual prediction is associated with its own individual loss, and then these loss values are combined using a global loss function. We present several families of online algorithms which can use any absolute norm as a global loss function. We prove worst-case relative loss bounds for all of our algorithms."
            },
            "slug": "Online-Multitask-Learning-Dekel-Long",
            "title": {
                "fragments": [],
                "text": "Online Multitask Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "Several families of online algorithms are presented which can use any absolute norm as a global loss function and are proved to prove worst-case relative loss bounds for all of the algorithms."
            },
            "venue": {
                "fragments": [],
                "text": "COLT"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1755694"
                        ],
                        "name": "G. Lugosi",
                        "slug": "G.-Lugosi",
                        "structuredName": {
                            "firstName": "G\u00e1bor",
                            "lastName": "Lugosi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Lugosi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2660689"
                        ],
                        "name": "O. Papaspiliopoulos",
                        "slug": "O.-Papaspiliopoulos",
                        "structuredName": {
                            "firstName": "Omiros",
                            "lastName": "Papaspiliopoulos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Papaspiliopoulos"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1806997"
                        ],
                        "name": "Gilles Stoltz",
                        "slug": "Gilles-Stoltz",
                        "structuredName": {
                            "firstName": "Gilles",
                            "lastName": "Stoltz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Gilles Stoltz"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 7,
                                "start": 3
                            }
                        ],
                        "text": "In [76], the proposed online MTL algorithms model task relations by placing constraints on actions taken for all the tasks."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 9321596,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "405684b758c02dcc8341cbd746efb4667f8a1dab",
            "isKey": false,
            "numCitedBy": 48,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "We discuss multi-task online learning when a decision maker has to deal simultaneously with M tasks. The tasks are related, which is modeled by imposing that the M-tuple of actions taken by the decision maker needs to satisfy certain constraints. We give natural examples of such restrictions and then discuss a general class of tractable constraints, for which we introduce computationally efficient ways of selecting actions, essentially by reducing to an on-line shortest path problem. We briefly discuss \"tracking\" and \"bandit\" versions of the problem and extend the model in various ways, including non-additive global losses and uncountably infinite sets of tasks."
            },
            "slug": "Online-Multi-task-Learning-with-Hard-Constraints-Lugosi-Papaspiliopoulos",
            "title": {
                "fragments": [],
                "text": "Online Multi-task Learning with Hard Constraints"
            },
            "tldr": {
                "abstractSimilarityScore": 37,
                "text": "A general class of tractable constraints is discussed, for which computationally efficient ways of selecting actions are introduced, essentially by reducing to an on-line shortest path problem."
            },
            "venue": {
                "fragments": [],
                "text": "COLT"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1388574404"
                        ],
                        "name": "D. Hern\u00e1ndez-Lobato",
                        "slug": "D.-Hern\u00e1ndez-Lobato",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Hern\u00e1ndez-Lobato",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Hern\u00e1ndez-Lobato"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1388574431"
                        ],
                        "name": "Jos\u00e9 Miguel Hern\u00e1ndez-Lobato",
                        "slug": "Jos\u00e9-Miguel-Hern\u00e1ndez-Lobato",
                        "structuredName": {
                            "firstName": "Jos\u00e9 Miguel",
                            "lastName": "Hern\u00e1ndez-Lobato",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jos\u00e9 Miguel Hern\u00e1ndez-Lobato"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1744700"
                        ],
                        "name": "Zoubin Ghahramani",
                        "slug": "Zoubin-Ghahramani",
                        "structuredName": {
                            "firstName": "Zoubin",
                            "lastName": "Ghahramani",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zoubin Ghahramani"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 36,
                                "start": 32
                            }
                        ],
                        "text": "The difference between [16] and [17] is that in [16], the horseshoeprior is generalized to learn feature covariance, while in [17], the horseshoe prior is used as a basic prior and the whole model is to identify outlier tasks in a way different from [15]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 10,
                                "start": 3
                            }
                        ],
                        "text": "In [16,17], the horseshoe prior is utilized to select features for MTL."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 12181059,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "51d270ccfd598415e25034660f774c061bfcbea1",
            "isKey": false,
            "numCitedBy": 37,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "Multi-task feature selection methods often make the hypothesis that learning tasks share relevant and irrelevant features. However, this hypothesis may be too restrictive in practice. For example, there may be a few tasks with specific relevant and irrelevant features (outlier tasks). Similarly, a few of the features may be relevant for only some of the tasks (outlier features). To account for this, we propose a model for multitask feature selection based on a robust prior distribution that introduces a set of binary latent variables to identify outlier tasks and outlier features. Expectation propagation can be used for efficient approximate inference under the proposed prior. Several experiments show that a model based on the new robust prior provides better predictive performance than other benchmark methods."
            },
            "slug": "A-Probabilistic-Model-for-Dirty-Multi-task-Feature-Hern\u00e1ndez-Lobato-Hern\u00e1ndez-Lobato",
            "title": {
                "fragments": [],
                "text": "A Probabilistic Model for Dirty Multi-task Feature Selection"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "A model for multitask feature selection based on a robust prior distribution that introduces a set of binary latent variables to identify outlier tasks and outlier features and provides better predictive performance than other benchmark methods is proposed."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48075945"
                        ],
                        "name": "Dan He",
                        "slug": "Dan-He",
                        "structuredName": {
                            "firstName": "Dan",
                            "lastName": "He",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dan He"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34978852"
                        ],
                        "name": "D. Kuhn",
                        "slug": "D.-Kuhn",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Kuhn",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Kuhn"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1718465"
                        ],
                        "name": "L. Parida",
                        "slug": "L.-Parida",
                        "structuredName": {
                            "firstName": "Laxmi",
                            "lastName": "Parida",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Parida"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 610,
                                "start": 605
                            }
                        ],
                        "text": "populations [104], construction of personalized brain\u2013computer interfaces [105], MHC-I binding prediction [106], splice-site prediction [106], protein subcellular location prediction [107], Alzheimer\u2019s disease assessment scale cognitive subscale [108], prediction of cognitive outcomes from neuroimaging measures in Alzheimer\u2019s disease [109], identification of longitudinal phenotypic markers for Alzheimer\u2019s disease progression prediction [110], prioritization of disease genes [111], biological image analysis based on natural images [20], survival analysis [112], and multiple genetic trait prediction [113]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 4401155,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8a761e8dc6a7fde7171298255bd93a183162fbaf",
            "isKey": false,
            "numCitedBy": 43,
            "numCiting": 42,
            "paperAbstract": {
                "fragments": [],
                "text": "Given a set of biallelic molecular markers, such as SNPs, with genotype values encoded numerically on a collection of plant, animal or human samples, the goal of genetic trait prediction is to predict the quantitative trait values by simultaneously modeling all marker effects. Genetic trait prediction is usually represented as linear regression models. In many cases, for the same set of samples and markers, multiple traits are observed. Some of these traits might be correlated with each other. Therefore, modeling all the multiple traits together may improve the prediction accuracy. In this work, we view the multitrait prediction problem from a machine learning angle: as either a multitask learning problem or a multiple output regression problem, depending on whether different traits share the same genotype matrix or not. We then adapted multitask learning algorithms and multiple output regression algorithms to solve the multitrait prediction problem. We proposed a few strategies to improve the least square error of the prediction from these algorithms. Our experiments show that modeling multiple traits together could improve the prediction accuracy for correlated traits. Availability and implementation: The programs we used are either public or directly from the referred authors, such as MALSAR (http://www.public.asu.edu/~jye02/Software/MALSAR/) package. The Avocado data set has not been published yet and is available upon request. Contact: dhe@us.ibm.com"
            },
            "slug": "Novel-applications-of-multitask-learning-and-output-He-Kuhn",
            "title": {
                "fragments": [],
                "text": "Novel applications of multitask learning and multiple output regression to multiple genetic trait prediction"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "The multitrait prediction problem was viewed from a machine learning angle: as either a multitask learning problem or a multiple output regression problem, depending on whether different traits share the same genotype matrix or not, and a few strategies to improve the least square error of the prediction from these algorithms were proposed."
            },
            "venue": {
                "fragments": [],
                "text": "Bioinform."
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145233587"
                        ],
                        "name": "Xiao Lu",
                        "slug": "Xiao-Lu",
                        "structuredName": {
                            "firstName": "Xiao",
                            "lastName": "Lu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xiao Lu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2119048509"
                        ],
                        "name": "Yaonan Wang",
                        "slug": "Yaonan-Wang",
                        "structuredName": {
                            "firstName": "Yaonan",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yaonan Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2086919"
                        ],
                        "name": "Xuanyu Zhou",
                        "slug": "Xuanyu-Zhou",
                        "structuredName": {
                            "firstName": "Xuanyu",
                            "lastName": "Zhou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xuanyu Zhou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2109512396"
                        ],
                        "name": "Zhenjun Zhang",
                        "slug": "Zhenjun-Zhang",
                        "structuredName": {
                            "firstName": "Zhenjun",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zhenjun Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2817492"
                        ],
                        "name": "Zhigang Ling",
                        "slug": "Zhigang-Ling",
                        "structuredName": {
                            "firstName": "Zhigang",
                            "lastName": "Ling",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zhigang Ling"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 18887428,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "151f8482da59b2d0ffb6f6892dc107771b435665",
            "isKey": false,
            "numCitedBy": 23,
            "numCiting": 46,
            "paperAbstract": {
                "fragments": [],
                "text": "Traffic sign recognition is a rather challenging task for intelligent transportation systems since signs in different subsets, e.g., speed limit signs, prohibition signs, and mandatory signs, are very different from each other in color or shape, whereas they share some similarities to the ones in the same subset. Therefore, it is important to integrate different modalities of visual features, such as color and shape, and select discriminative features for better sign description; in addition, it benefits to explore the correlations between the classes of traffic signs to learn the classifiers jointly to improve the generalization performance. In this paper, we propose Multi- Modal tree-structure embedded Multi-Task Learning called  $\\text{M}^{2}$- tMTL to select discriminative visual features both between and within modalities, as well as the correlated features shared by similar classification tasks. Our method simultaneously introduces two structured sparsity-induced norms into a least squares regression. One of the norms can be used not only to select modality of features but also to conduct within-modality feature selection. Moreover, the hierarchical correlations among the classification tasks are well represented by a tree structure, and therefore, the tree-structure sparsity-induced norm is used for learning the regression coefficients jointly to boost the performance of multi-class traffic sign recognition. Alternating direction method of multipliers (ADMM) is used to efficiently solve the proposed model with guaranteed convergence. Extensive experiments on public benchmark data sets demonstrate that the proposed algorithm leads to a quite interpretable model, and it has better or competitive performance with several state-of-the-art methods but with less computational and memory cost."
            },
            "slug": "Traffic-Sign-Recognition-via-Multi-Modal-Embedded-Lu-Wang",
            "title": {
                "fragments": [],
                "text": "Traffic Sign Recognition via Multi-Modal Tree-Structure Embedded Multi-Task Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The tree-structure sparsity-induced norm is used for learning the regression coefficients jointly to boost the performance of multi-class traffic sign recognition and Alternating direction method of multipliers (ADMM) is used to efficiently solve the proposed model with guaranteed convergence."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Intelligent Transportation Systems"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144009046"
                        ],
                        "name": "Andreas Maurer",
                        "slug": "Andreas-Maurer",
                        "structuredName": {
                            "firstName": "Andreas",
                            "lastName": "Maurer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andreas Maurer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1704699"
                        ],
                        "name": "M. Pontil",
                        "slug": "M.-Pontil",
                        "structuredName": {
                            "firstName": "Massimiliano",
                            "lastName": "Pontil",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Pontil"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1403031665"
                        ],
                        "name": "B. Romera-Paredes",
                        "slug": "B.-Romera-Paredes",
                        "structuredName": {
                            "firstName": "Bernardino",
                            "lastName": "Romera-Paredes",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Romera-Paredes"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 185,
                                "start": 182
                            }
                        ],
                        "text": "Unlike multi-layer feedforward neural networks, which are based on neural networks, the multitask feature learning (MTFL) method [5,6] and the multi-task sparse coding (MTSC) method [7] are formulated under the regularization framework by first transforming data instances as x\u0302j = Uxj and then learning a linear function as f i (xj ) = (ai )T x\u0302j + bi ."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 7,
                                "start": 0
                            }
                        ],
                        "text": "[7,134] for the feature transform approach, [135] for the feature selection approach, [24,135\u2013138] for the lowrank approach, [136] for the task-relation learning approach, and [138] for the dirty approach."
                    },
                    "intents": []
                }
            ],
            "corpusId": 12324861,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ccc4d817204c67edea259d7fccdfafb60bf8943b",
            "isKey": false,
            "numCitedBy": 165,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "We investigate the use of sparse coding and dictionary learning in the context of multitask and transfer learning. The central assumption of our learning method is that the tasks parameters are well approximated by sparse linear combinations of the atoms of a dictionary on a high or infinite dimensional space. This assumption, together with the large quantity of available data in the multitask and transfer learning settings, allows a principled choice of the dictionary. We provide bounds on the generalization error of this approach, for both settings. Numerical experiments on one synthetic and two real datasets show the advantage of our method over single task learning, a previous method based on orthogonal and dense representation of the tasks and a related method learning task grouping."
            },
            "slug": "Sparse-coding-for-multitask-and-transfer-learning-Maurer-Pontil",
            "title": {
                "fragments": [],
                "text": "Sparse coding for multitask and transfer learning"
            },
            "tldr": {
                "abstractSimilarityScore": 53,
                "text": "Numerical experiments show the advantage of the use of sparse coding and dictionary learning over single task learning, a previous method based on orthogonal and dense representation of the tasks and a related method learning task grouping."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2533906"
                        ],
                        "name": "G. Obozinski",
                        "slug": "G.-Obozinski",
                        "structuredName": {
                            "firstName": "Guillaume",
                            "lastName": "Obozinski",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Obozinski"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685978"
                        ],
                        "name": "B. Taskar",
                        "slug": "B.-Taskar",
                        "structuredName": {
                            "firstName": "Ben",
                            "lastName": "Taskar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Taskar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1453240859"
                        ],
                        "name": "Michael I. Jordan",
                        "slug": "Michael-I.-Jordan",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Jordan",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael I. Jordan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 94,
                                "start": 89
                            }
                        ],
                        "text": "Concrete instances of the p, q regularization include the 2,1 regularization proposed in [8,9] and the \u221e,1 regularization proposed in [10]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 173,
                                "start": 170
                            }
                        ],
                        "text": "In [72], the value functions in different tasks are assumed to share sparse parameters and it applies the multi-task feature selection method with the 2,1 regularization [8] and the MTFL method [5] to learn all the value functions simultaneously."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14655047,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "71977913bf322052cb84346dc0061ae68470f556",
            "isKey": false,
            "numCitedBy": 293,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "We address the problem of joint feature selection across a group of related classification or regression tasks. We propose a novel type of joint regularization of the model parameters in order to couple feature selection across tasks. Intuitively, we extend the `1 regularization for single-task estimation to the multi-task setting. By penalizing the sum of `2-norms of the blocks of coefficients associated with each feature across different tasks, we encourage multiple predictors to have similar parameter sparsity patterns. To fit parameters under this regularization, we propose a blockwise boosting scheme that follows the regularization path. The algorithm introduces and updates simultaneously the coefficients associated with one feature in all tasks. We show empirically that this approach outperforms independent `1-based feature selection on several datasets."
            },
            "slug": "Multi-task-feature-selection-Obozinski-Taskar",
            "title": {
                "fragments": [],
                "text": "Multi-task feature selection"
            },
            "tldr": {
                "abstractSimilarityScore": 56,
                "text": "This work proposes a novel type of joint regularization of the model parameters in order to couple feature selection across tasks and shows empirically that this approach outperforms independent `1-based feature selection on several datasets."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "30561807"
                        ],
                        "name": "Edwin V. Bonilla",
                        "slug": "Edwin-V.-Bonilla",
                        "structuredName": {
                            "firstName": "Edwin",
                            "lastName": "Bonilla",
                            "middleNames": [
                                "V."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Edwin V. Bonilla"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1890071"
                        ],
                        "name": "K. M. A. Chai",
                        "slug": "K.-M.-A.-Chai",
                        "structuredName": {
                            "firstName": "Kian",
                            "lastName": "Chai",
                            "middleNames": [
                                "Ming",
                                "Adam"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. M. A. Chai"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145715698"
                        ],
                        "name": "Christopher K. I. Williams",
                        "slug": "Christopher-K.-I.-Williams",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Williams",
                            "middleNames": [
                                "K.",
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christopher K. I. Williams"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 49,
                                "start": 45
                            }
                        ],
                        "text": "A multi-task Gaussian process is proposed in [42] to define a prior on f i j , the functional value corresponding to xj , as f \u223c N (0, ), where f = ( f 1 1 , ."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 10790217,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "10d10df314c1b58f5c83629e73a35185876cd4e2",
            "isKey": false,
            "numCitedBy": 889,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we investigate multi-task learning in the context of Gaussian Processes (GP). We propose a model that learns a shared covariance function on input-dependent features and a \"free-form\" covariance matrix over tasks. This allows for good flexibility when modelling inter-task dependencies while avoiding the need for large amounts of data for training. We show that under the assumption of noise-free observations and a block design, predictions for a given task only depend on its target values and therefore a cancellation of inter-task transfer occurs. We evaluate the benefits of our model on two practical applications: a compiler performance prediction problem and an exam score prediction task. Additionally, we make use of GP approximations and properties of our model in order to provide scalability to large data sets."
            },
            "slug": "Multi-task-Gaussian-Process-Prediction-Bonilla-Chai",
            "title": {
                "fragments": [],
                "text": "Multi-task Gaussian Process Prediction"
            },
            "tldr": {
                "abstractSimilarityScore": 59,
                "text": "A model that learns a shared covariance function on input-dependent features and a \"free-form\" covariance matrix over tasks allows for good flexibility when modelling inter-task dependencies while avoiding the need for large amounts of data for training."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1739816"
                        ],
                        "name": "D. Yeung",
                        "slug": "D.-Yeung",
                        "structuredName": {
                            "firstName": "Dit-Yan",
                            "lastName": "Yeung",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Yeung"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46867608"
                        ],
                        "name": "Yu Zhang",
                        "slug": "Yu-Zhang",
                        "structuredName": {
                            "firstName": "Yu",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yu Zhang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1263753,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4754347ac79234c19bc5b0132a0d80f567623eb3",
            "isKey": false,
            "numCitedBy": 17,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "In this chapter, dedicated to Dit-Yan\u2019s mentor and friend George Bekey on the occasion of his 80th birthday, we investigate for the first time the feasibility of applying the multi-task learning (or called transfer learning) approach to the learning of inverse dynamics. Due to the difficulties of modeling the dynamics completely and accurately and solving the dynamics equations analytically to obtain the control variables, the machine learning approach has been regarded as a viable alternative to the robotic control problem. In particular, we learn the inverse model from measured data as a regression problem and solve it using a nonparametric Bayesian kernel approach called Gaussian process regression (GPR). Instead of solving the regression tasks for different degrees of freedom (DOFs) separately and independently, the central thesis of this work is that modeling the inter-task dependencies explicitly and allowing adaptive transfer of knowledge between different tasks can make the learning problem much easier. Specifically, based on data from a 7-DOF robot arm, we demonstrate that the learning accuracy can often be significantly increased when the multi-task learning approach is adopted. 1 Appreciation and Dedication When Dit-Yan arrived at the University of Southern California (USC) in the mid 1980s, he was planning to do theoretical research on the models of computation, possibly including computational and mathematical models for human intelligence. Robotics was initially not in his mind. Shortly afterwards he learned of the interestDit-Yan Yeung, Professor Department of Computer Science and Engineering, Hong Kong University of Science and Technology, Clear Water Bay, Hong Kong, China, e-mail: dyyeung@cse.ust.hk Yu Zhang, PhD student Department of Computer Science and Engineering, Hong Kong University of Science and Technology, Clear Water Bay, Hong Kong, China, e-mail: zhangyu@cse.ust.hk"
            },
            "slug": "Learning-Inverse-Dynamics-by-Gaussian-process-under-Yeung-Zhang",
            "title": {
                "fragments": [],
                "text": "Learning Inverse Dynamics by Gaussian process Begrression under the Multi-Task Learning Framework"
            },
            "tldr": {
                "abstractSimilarityScore": 98,
                "text": "This chapter, dedicated to Dit-Yan\u2019s mentor and friend George Bekey on the occasion of his 80th birthday, investigates for the first time the feasibility of applying the multi-task learning (or called transfer learning) approach to the learning of inverse dynamics."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46867608"
                        ],
                        "name": "Yu Zhang",
                        "slug": "Yu-Zhang",
                        "structuredName": {
                            "firstName": "Yu",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yu Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1739816"
                        ],
                        "name": "D. Yeung",
                        "slug": "D.-Yeung",
                        "structuredName": {
                            "firstName": "Dit-Yan",
                            "lastName": "Yeung",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Yeung"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 88,
                                "start": 84
                            }
                        ],
                        "text": "The MTRL method is generalized to multi-task boosting [46] and multi-label learning [47], where each label is treated as a task, and extended to learn sparse task relations in [48]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 15557175,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "296e5d360d02814e5e3e980109bc9b4b2d42f867",
            "isKey": false,
            "numCitedBy": 53,
            "numCiting": 40,
            "paperAbstract": {
                "fragments": [],
                "text": "Multilabel learning problems are commonly found in many applications. A characteristic shared by many multilabel learning problems is that some labels have significant correlations between them. In this article, we propose a novel multilabel learning method, called MultiLabel Relationship Learning (MLRL), which extends the conventional support vector machine by explicitly learning and utilizing the relationships between labels. Specifically, we model the label relationships using a label covariance matrix and use it to define a new regularization term for the optimization problem. MLRL learns the model parameters and the label covariance matrix simultaneously based on a unified convex formulation. To solve the convex optimization problem, we use an alternating method in which each subproblem can be solved efficiently. The relationship between MLRL and two widely used maximum margin methods for multilabel learning is investigated. Moreover, we also propose a semisupervised extension of MLRL, called SSMLRL, to demonstrate how to make use of unlabeled data to help learn the label covariance matrix. Through experiments conducted on some multilabel applications, we find that MLRL not only gives higher classification accuracy but also has better interpretability as revealed by the label covariance matrix."
            },
            "slug": "Multilabel-relationship-learning-Zhang-Yeung",
            "title": {
                "fragments": [],
                "text": "Multilabel relationship learning"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "Through experiments conducted on some multilabel applications, it is found that MLRL not only gives higher classification accuracy but also has better interpretability as revealed by the label covariance matrix."
            },
            "venue": {
                "fragments": [],
                "text": "TKDD"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144009046"
                        ],
                        "name": "Andreas Maurer",
                        "slug": "Andreas-Maurer",
                        "structuredName": {
                            "firstName": "Andreas",
                            "lastName": "Maurer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andreas Maurer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 7,
                                "start": 0
                            }
                        ],
                        "text": "[7,134] for the feature transform approach, [135] for the feature selection approach, [24,135\u2013138] for the lowrank approach, [136] for the task-relation learning approach, and [138] for the dirty approach."
                    },
                    "intents": []
                }
            ],
            "corpusId": 8161215,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "39da323f5a34b59226e7a7a9038d3ae3438f29db",
            "isKey": false,
            "numCitedBy": 146,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "We give dimension-free and data-dependent bounds for linear multi-task learning where a common linear operator is chosen to preprocess data for a vector of task specific linear-thresholding classifiers. The complexity penalty of multi-task learning is bounded by a simple expression involving the margins of the task-specific classifiers, the Hilbert-Schmidt norm of the selected preprocessor and the Hilbert-Schmidt norm of the covariance operator for the total mixture of all task distributions, or, alternatively, the Frobenius norm of the total Gramian matrix for the data-dependent version. The results can be compared to state-of-the-art results on linear single-task learning."
            },
            "slug": "Bounds-for-Linear-Multi-Task-Learning-Maurer",
            "title": {
                "fragments": [],
                "text": "Bounds for Linear Multi-Task Learning"
            },
            "venue": {
                "fragments": [],
                "text": "J. Mach. Learn. Res."
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2075305855"
                        ],
                        "name": "Jing Wan",
                        "slug": "Jing-Wan",
                        "structuredName": {
                            "firstName": "Jing",
                            "lastName": "Wan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jing Wan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1791667"
                        ],
                        "name": "Zhilin Zhang",
                        "slug": "Zhilin-Zhang",
                        "structuredName": {
                            "firstName": "Zhilin",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zhilin Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3325036"
                        ],
                        "name": "Jingwen Yan",
                        "slug": "Jingwen-Yan",
                        "structuredName": {
                            "firstName": "Jingwen",
                            "lastName": "Yan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jingwen Yan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2149200146"
                        ],
                        "name": "Taiyong Li",
                        "slug": "Taiyong-Li",
                        "structuredName": {
                            "firstName": "Taiyong",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Taiyong Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144876925"
                        ],
                        "name": "B. Rao",
                        "slug": "B.-Rao",
                        "structuredName": {
                            "firstName": "Bhaskar",
                            "lastName": "Rao",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Rao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35147194"
                        ],
                        "name": "S. Fang",
                        "slug": "S.-Fang",
                        "structuredName": {
                            "firstName": "Shiaofen",
                            "lastName": "Fang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Fang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "15319264"
                        ],
                        "name": "Sungeun Kim",
                        "slug": "Sungeun-Kim",
                        "structuredName": {
                            "firstName": "Sungeun",
                            "lastName": "Kim",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sungeun Kim"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2678448"
                        ],
                        "name": "S. Risacher",
                        "slug": "S.-Risacher",
                        "structuredName": {
                            "firstName": "Shannon",
                            "lastName": "Risacher",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Risacher"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7992909"
                        ],
                        "name": "A. Saykin",
                        "slug": "A.-Saykin",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Saykin",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Saykin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144779870"
                        ],
                        "name": "Li Shen",
                        "slug": "Li-Shen",
                        "structuredName": {
                            "firstName": "Li",
                            "lastName": "Shen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Li Shen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 341,
                                "start": 336
                            }
                        ],
                        "text": "populations [104], construction of personalized brain\u2013computer interfaces [105], MHC-I binding prediction [106], splice-site prediction [106], protein subcellular location prediction [107], Alzheimer\u2019s disease assessment scale cognitive subscale [108], prediction of cognitive outcomes from neuroimaging measures in Alzheimer\u2019s disease [109], identification of longitudinal phenotypic markers for Alzheimer\u2019s disease progression prediction [110], prioritization of disease genes [111], biological image analysis based on natural images [20], survival analysis [112], and multiple genetic trait prediction [113]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 807912,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "34303d530a6315c798cc5231af271e3118f2a36d",
            "isKey": false,
            "numCitedBy": 68,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "Alzheimer's disease (AD) is the most common form of dementia that causes progressive impairment of memory and other cognitive functions. Multivariate regression models have been studied in AD for revealing relationships between neuroimaging measures and cognitive scores to understand how structural changes in brain can influence cognitive status. Existing regression methods, however, do not explicitly model dependence relation among multiple scores derived from a single cognitive test. It has been found that such dependence can deteriorate the performance of these methods. To overcome this limitation, we propose an efficient sparse Bayesian multi-task learning algorithm, which adaptively learns and exploits the dependence to achieve improved prediction performance. The proposed algorithm is applied to a real world neuroimaging study in AD to predict cognitive performance using MRI scans. The effectiveness of the proposed algorithm is demonstrated by its superior prediction performance over multiple state-of-the-art competing methods and accurate identification of compact sets of cognition-relevant imaging biomarkers that are consistent with prior knowledge."
            },
            "slug": "Sparse-Bayesian-multi-task-learning-for-predicting-Wan-Zhang",
            "title": {
                "fragments": [],
                "text": "Sparse Bayesian multi-task learning for predicting cognitive outcomes from neuroimaging measures in Alzheimer's disease"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "An efficient sparse Bayesian multi-task learning algorithm is proposed, which adaptively learns and exploits the dependence among multiple scores derived from a single cognitive test to achieve improved prediction performance in AD."
            },
            "venue": {
                "fragments": [],
                "text": "2012 IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3350185"
                        ],
                        "name": "Congyan Lang",
                        "slug": "Congyan-Lang",
                        "structuredName": {
                            "firstName": "Congyan",
                            "lastName": "Lang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Congyan Lang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1990768"
                        ],
                        "name": "Guangcan Liu",
                        "slug": "Guangcan-Liu",
                        "structuredName": {
                            "firstName": "Guangcan",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Guangcan Liu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1740321"
                        ],
                        "name": "Jian Yu",
                        "slug": "Jian-Yu",
                        "structuredName": {
                            "firstName": "Jian",
                            "lastName": "Yu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jian Yu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143653681"
                        ],
                        "name": "Shuicheng Yan",
                        "slug": "Shuicheng-Yan",
                        "structuredName": {
                            "firstName": "Shuicheng",
                            "lastName": "Yan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shuicheng Yan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 177,
                                "start": 173
                            }
                        ],
                        "text": "Applications of MTL based on non-facial images include object categorization [86], image segmentation [89,90], identifying brain imaging predictors [91], saliency detection [92], action recognition [93], scene classification [94], multi-attribute prediction [95], multi-camera person re-identification [96], and immediacy prediction [97]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 18375016,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2d3ab8986c5cdc8d21923101ee30cae5ccbf0f35",
            "isKey": false,
            "numCitedBy": 190,
            "numCiting": 64,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper addresses the problem of detecting salient areas within natural images. We shall mainly study the problem under unsupervised setting, i.e., saliency detection without learning from labeled images. A solution of multitask sparsity pursuit is proposed to integrate multiple types of features for detecting saliency collaboratively. Given an image described by multiple features, its saliency map is inferred by seeking the consistently sparse elements from the joint decompositions of multiple-feature matrices into pairs of low-rank and sparse matrices. The inference process is formulated as a constrained nuclear norm and as an \u21132,1 -norm minimization problem, which is convex and can be solved efficiently with an augmented Lagrange multiplier method. Compared with previous methods, which usually make use of multiple features by combining the saliency maps obtained from individual features, the proposed method seamlessly integrates multiple features to produce jointly the saliency map with a single inference step and thus produces more accurate and reliable results. In addition to the unsupervised setting, the proposed method can be also generalized to incorporate the top-down priors obtained from supervised environment. Extensive experiments well validate its superiority over other state-of-the-art methods."
            },
            "slug": "Saliency-Detection-by-Multitask-Sparsity-Pursuit-Lang-Liu",
            "title": {
                "fragments": [],
                "text": "Saliency Detection by Multitask Sparsity Pursuit"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A solution of multitask sparsity pursuit is proposed to integrate multiple types of features for detecting saliency collaboratively to produce jointly the saliency map with a single inference step and thus produces more accurate and reliable results."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Image Processing"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2758425"
                        ],
                        "name": "Zhizheng Wu",
                        "slug": "Zhizheng-Wu",
                        "structuredName": {
                            "firstName": "Zhizheng",
                            "lastName": "Wu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zhizheng Wu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1401922561"
                        ],
                        "name": "Cassia Valentini-Botinhao",
                        "slug": "Cassia-Valentini-Botinhao",
                        "structuredName": {
                            "firstName": "Cassia",
                            "lastName": "Valentini-Botinhao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Cassia Valentini-Botinhao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1720858"
                        ],
                        "name": "O. Watts",
                        "slug": "O.-Watts",
                        "structuredName": {
                            "firstName": "Oliver",
                            "lastName": "Watts",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Watts"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144783569"
                        ],
                        "name": "Simon King",
                        "slug": "Simon-King",
                        "structuredName": {
                            "firstName": "Simon",
                            "lastName": "King",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Simon King"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 64,
                                "start": 55
                            }
                        ],
                        "text": "Applications of MTL in speech include speech synthesis [114,115] and those for natural language processing include joint learning of six NLP tasks (i."
                    },
                    "intents": []
                }
            ],
            "corpusId": 12016916,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "461d9a7dce9cabf1943e2ec43cb328223f963129",
            "isKey": false,
            "numCitedBy": 248,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "Deep neural networks (DNNs) use a cascade of hidden representations to enable the learning of complex mappings from input to output features. They are able to learn the complex mapping from text-based linguistic features to speech acoustic features, and so perform text-to-speech synthesis. Recent results suggest that DNNs can produce more natural synthetic speech than conventional HMM-based statistical parametric systems. In this paper, we show that the hidden representation used within a DNN can be improved through the use of Multi-Task Learning, and that stacking multiple frames of hidden layer activations (stacked bottleneck features) also leads to improvements. Experimental results confirmed the effectiveness of the proposed methods, and in listening tests we find that stacked bottleneck features in particular offer a significant improvement over both a baseline DNN and a benchmark HMM system."
            },
            "slug": "Deep-neural-networks-employing-Multi-Task-Learning-Wu-Valentini-Botinhao",
            "title": {
                "fragments": [],
                "text": "Deep neural networks employing Multi-Task Learning and stacked bottleneck features for speech synthesis"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "It is shown that the hidden representation used within a DNN can be improved through the use of Multi-Task Learning, and that stacking multiple frames of hidden layer activations (stacked bottleneck features) also leads to improvements."
            },
            "venue": {
                "fragments": [],
                "text": "2015 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2117857570"
                        ],
                        "name": "Yan Yan",
                        "slug": "Yan-Yan",
                        "structuredName": {
                            "firstName": "Yan",
                            "lastName": "Yan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yan Yan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40811261"
                        ],
                        "name": "E. Ricci",
                        "slug": "E.-Ricci",
                        "structuredName": {
                            "firstName": "Elisa",
                            "lastName": "Ricci",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Ricci"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1742936"
                        ],
                        "name": "Subramanian Ramanathan",
                        "slug": "Subramanian-Ramanathan",
                        "structuredName": {
                            "firstName": "Subramanian",
                            "lastName": "Ramanathan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Subramanian Ramanathan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1717522"
                        ],
                        "name": "O. Lanz",
                        "slug": "O.-Lanz",
                        "structuredName": {
                            "firstName": "Oswald",
                            "lastName": "Lanz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Lanz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1703601"
                        ],
                        "name": "N. Sebe",
                        "slug": "N.-Sebe",
                        "structuredName": {
                            "firstName": "N.",
                            "lastName": "Sebe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Sebe"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 184,
                                "start": 177
                            }
                        ],
                        "text": "Specifically, applications of MTL based on facial images include face verification [84], personalized age estimation [85], multi-cue face recognition [86], head-pose estimation [22,87], facial landmark detection [18], and facial image rotation [88]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 3975366,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0e8b72542d768cb65adc902aed6cc9fa0574dc3d",
            "isKey": false,
            "numCitedBy": 116,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a novel Multi-Task Learning framework (FEGA-MTL) for classifying the head pose of a person who moves freely in an environment monitored by multiple, large field-of-view surveillance cameras. As the target (person) moves, distortions in facial appearance owing to camera perspective and scale severely impede performance of traditional head pose classification methods. FEGA-MTL operates on a dense uniform spatial grid and learns appearance relationships across partitions as well as partition-specific appearance variations for a given head pose to build region-specific classifiers. Guided by two graphs which a-priori model appearance similarity among (i) grid partitions based on camera geometry and (ii) head pose classes, the learner efficiently clusters appearance wise related grid partitions to derive the optimal partitioning. For pose classification, upon determining the target's position using a person tracker, the appropriate region specific classifier is invoked. Experiments confirm that FEGA-MTL achieves state-of-the-art classification with few training data."
            },
            "slug": "No-Matter-Where-You-Are:-Flexible-Graph-Guided-for-Yan-Ricci",
            "title": {
                "fragments": [],
                "text": "No Matter Where You Are: Flexible Graph-Guided Multi-task Learning for Multi-view Head Pose Classification under Target Motion"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "A novel Multi-Task Learning framework that achieves state-of-the-art classification with few training data, FEGA-MTL operates on a dense uniform spatial grid and learns appearance relationships across partitions as well as partition-specific appearance variations for a given head pose to build region-specific classifiers."
            },
            "venue": {
                "fragments": [],
                "text": "2013 IEEE International Conference on Computer Vision"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38738792"
                        ],
                        "name": "Zhibin Hong",
                        "slug": "Zhibin-Hong",
                        "structuredName": {
                            "firstName": "Zhibin",
                            "lastName": "Hong",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zhibin Hong"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50994312"
                        ],
                        "name": "Xue Mei",
                        "slug": "Xue-Mei",
                        "structuredName": {
                            "firstName": "Xue",
                            "lastName": "Mei",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xue Mei"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2353770"
                        ],
                        "name": "D. Prokhorov",
                        "slug": "D.-Prokhorov",
                        "structuredName": {
                            "firstName": "Danil",
                            "lastName": "Prokhorov",
                            "middleNames": [
                                "V."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Prokhorov"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143719920"
                        ],
                        "name": "D. Tao",
                        "slug": "D.-Tao",
                        "structuredName": {
                            "firstName": "Dacheng",
                            "lastName": "Tao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Tao"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15273400,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "70fe671527d1405027c0446eed07468739c7984d",
            "isKey": false,
            "numCitedBy": 149,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": "Combining multiple observation views has proven beneficial for tracking. In this paper, we cast tracking as a novel multi-task multi-view sparse learning problem and exploit the cues from multiple views including various types of visual features, such as intensity, color, and edge, where each feature observation can be sparsely represented by a linear combination of atoms from an adaptive feature dictionary. The proposed method is integrated in a particle filter framework where every view in each particle is regarded as an individual task. We jointly consider the underlying relationship between tasks across different views and different particles, and tackle it in a unified robust multi-task formulation. In addition, to capture the frequently emerging outlier tasks, we decompose the representation matrix to two collaborative components which enable a more robust and accurate approximation. We show that the proposed formulation can be efficiently solved using the Accelerated Proximal Gradient method with a small number of closed-form updates. The presented tracker is implemented using four types of features and is tested on numerous benchmark video sequences. Both the qualitative and quantitative results demonstrate the superior performance of the proposed approach compared to several state-of-the-art trackers."
            },
            "slug": "Tracking-via-Robust-Multi-task-Multi-view-Joint-Hong-Mei",
            "title": {
                "fragments": [],
                "text": "Tracking via Robust Multi-task Multi-view Joint Sparse Representation"
            },
            "tldr": {
                "abstractSimilarityScore": 76,
                "text": "This paper cast tracking as a novel multi-task multi-view sparse learning problem and exploit the cues from multiple views including various types of visual features, such as intensity, color, and edge, where each feature observation can be sparsely represented by a linear combination of atoms from an adaptive feature dictionary."
            },
            "venue": {
                "fragments": [],
                "text": "2013 IEEE International Conference on Computer Vision"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3166516"
                        ],
                        "name": "Emilio Parisotto",
                        "slug": "Emilio-Parisotto",
                        "structuredName": {
                            "firstName": "Emilio",
                            "lastName": "Parisotto",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Emilio Parisotto"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2503659"
                        ],
                        "name": "Jimmy Ba",
                        "slug": "Jimmy-Ba",
                        "structuredName": {
                            "firstName": "Jimmy",
                            "lastName": "Ba",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jimmy Ba"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145124475"
                        ],
                        "name": "R. Salakhutdinov",
                        "slug": "R.-Salakhutdinov",
                        "structuredName": {
                            "firstName": "Ruslan",
                            "lastName": "Salakhutdinov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Salakhutdinov"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 7,
                                "start": 3
                            }
                        ],
                        "text": "In [73], an actor\u2013mimic method, which is a combination of deep reinforcement learning andmodel compression techniques, is proposed to learn policy networks for multiple tasks."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 8241258,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1def5d3711ebd1d86787b1ed57c91832c5ddc90b",
            "isKey": false,
            "numCitedBy": 440,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "The ability to act in multiple environments and transfer previous knowledge to new situations can be considered a critical aspect of any intelligent agent. Towards this goal, we define a novel method of multitask and transfer learning that enables an autonomous agent to learn how to behave in multiple tasks simultaneously, and then generalize its knowledge to new domains. This method, termed \"Actor-Mimic\", exploits the use of deep reinforcement learning and model compression techniques to train a single policy network that learns how to act in a set of distinct tasks by using the guidance of several expert teachers. We then show that the representations learnt by the deep policy network are capable of generalizing to new tasks with no prior expert guidance, speeding up learning in novel environments. Although our method can in general be applied to a wide range of problems, we use Atari games as a testing environment to demonstrate these methods."
            },
            "slug": "Actor-Mimic:-Deep-Multitask-and-Transfer-Learning-Parisotto-Ba",
            "title": {
                "fragments": [],
                "text": "Actor-Mimic: Deep Multitask and Transfer Reinforcement Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This work defines a novel method of multitask and transfer learning that enables an autonomous agent to learn how to behave in multiple tasks simultaneously, and then generalize its knowledge to new domains, and uses Atari games as a testing environment to demonstrate these methods."
            },
            "venue": {
                "fragments": [],
                "text": "ICLR"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2055922779"
                        ],
                        "name": "Bin Cheng",
                        "slug": "Bin-Cheng",
                        "structuredName": {
                            "firstName": "Bin",
                            "lastName": "Cheng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bin Cheng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1990768"
                        ],
                        "name": "Guangcan Liu",
                        "slug": "Guangcan-Liu",
                        "structuredName": {
                            "firstName": "Guangcan",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Guangcan Liu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688516"
                        ],
                        "name": "Jingdong Wang",
                        "slug": "Jingdong-Wang",
                        "structuredName": {
                            "firstName": "Jingdong",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jingdong Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2109669984"
                        ],
                        "name": "Zhongyang Huang",
                        "slug": "Zhongyang-Huang",
                        "structuredName": {
                            "firstName": "Zhongyang",
                            "lastName": "Huang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zhongyang Huang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143653681"
                        ],
                        "name": "Shuicheng Yan",
                        "slug": "Shuicheng-Yan",
                        "structuredName": {
                            "firstName": "Shuicheng",
                            "lastName": "Yan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shuicheng Yan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 109,
                                "start": 102
                            }
                        ],
                        "text": "Applications of MTL based on non-facial images include object categorization [86], image segmentation [89,90], identifying brain imaging predictors [91], saliency detection [92], action recognition [93], scene classification [94], multi-attribute prediction [95], multi-camera person re-identification [96], and immediacy prediction [97]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 11210730,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1e342cbce99cb2cb5fe0c3ad24458f5423262763",
            "isKey": false,
            "numCitedBy": 203,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper investigates how to boost region-based image segmentation by pursuing a new solution to fuse multiple types of image features. A collaborative image segmentation framework, called multi-task low-rank affinity pursuit, is presented for such a purpose. Given an image described with multiple types of features, we aim at inferring a unified affinity matrix that implicitly encodes the segmentation of the image. This is achieved by seeking the sparsity-consistent low-rank affinities from the joint decompositions of multiple feature matrices into pairs of sparse and low-rank matrices, the latter of which is expressed as the production of the image feature matrix and its corresponding image affinity matrix. The inference process is formulated as a constrained nuclear norm and \u21132;1-norm minimization problem, which is convex and can be solved efficiently with the Augmented Lagrange Multiplier method. Compared to previous methods, which are usually based on a single type of features, the proposed method seamlessly integrates multiple types of features to jointly produce the affinity matrix within a single inference step, and produces more accurate and reliable segmentation results. Experiments on the MSRC dataset and Berkeley segmentation dataset well validate the superiority of using multiple features over single feature and also the superiority of our method over conventional methods for feature fusion. Moreover, our method is shown to be very competitive while comparing to other state-of-the-art methods."
            },
            "slug": "Multi-task-low-rank-affinity-pursuit-for-image-Cheng-Liu",
            "title": {
                "fragments": [],
                "text": "Multi-task low-rank affinity pursuit for image segmentation"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "Compared to previous methods, which are usually based on a single type of features, the proposed method seamlessly integrates multiple types of features to jointly produce the affinity matrix within a single inference step, and produces more accurate and reliable segmentation results."
            },
            "venue": {
                "fragments": [],
                "text": "2011 International Conference on Computer Vision"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [],
                        "name": "Hui Li",
                        "slug": "Hui-Li",
                        "structuredName": {
                            "firstName": "Hui",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hui Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2585822"
                        ],
                        "name": "X. Liao",
                        "slug": "X.-Liao",
                        "structuredName": {
                            "firstName": "X.",
                            "lastName": "Liao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "X. Liao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145006560"
                        ],
                        "name": "L. Carin",
                        "slug": "L.-Carin",
                        "structuredName": {
                            "firstName": "Lawrence",
                            "lastName": "Carin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Carin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 7,
                                "start": 3
                            }
                        ],
                        "text": "In [70], each task is characterized via a regionalized policy and a Dirichlet process is used to cluster tasks."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 92569,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d5b5ca31260ec10b2c1f59d3dd3aa1d987a8a76f",
            "isKey": false,
            "numCitedBy": 91,
            "numCiting": 66,
            "paperAbstract": {
                "fragments": [],
                "text": "We consider the problem of multi-task reinforcement learning (MTRL) in multiple partially observable stochastic environments. We introduce the regionalized policy representation (RPR) to characterize the agent's behavior in each environment. The RPR is a parametric model of the conditional distribution over current actions given the history of past actions and observations; the agent's choice of actions is directly based on this conditional distribution, without an intervening model to characterize the environment itself. We propose off-policy batch algorithms to learn the parameters of the RPRs, using episodic data collected when following a behavior policy, and show their linkage to policy iteration. We employ the Dirichlet process as a nonparametric prior over the RPRs across multiple environments. The intrinsic clustering property of the Dirichlet process imposes sharing of episodes among similar environments, which effectively reduces the number of episodes required for learning a good policy in each environment, when data sharing is appropriate. The number of distinct RPRs and the associated clusters (the sharing patterns) are automatically discovered by exploiting the episodic data as well as the nonparametric nature of the Dirichlet process. We demonstrate the effectiveness of the proposed RPR as well as the RPR-based MTRL framework on various problems, including grid-world navigation and multi-aspect target classification. The experimental results show that the RPR is a competitive reinforcement learning algorithm in partially observable domains, and the MTRL consistently achieves better performance than single task reinforcement learning."
            },
            "slug": "Multi-task-Reinforcement-Learning-in-Partially-Li-Liao",
            "title": {
                "fragments": [],
                "text": "Multi-task Reinforcement Learning in Partially Observable Stochastic Environments"
            },
            "tldr": {
                "abstractSimilarityScore": 54,
                "text": "The experimental results show that the proposed RPR is a competitive reinforcement learning algorithm in partially observable domains, and the MTRL consistently achieves better performance than single task reinforcement learning."
            },
            "venue": {
                "fragments": [],
                "text": "J. Mach. Learn. Res."
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3310253"
                        ],
                        "name": "Aiqing Huang",
                        "slug": "Aiqing-Huang",
                        "structuredName": {
                            "firstName": "Aiqing",
                            "lastName": "Huang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Aiqing Huang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2230211"
                        ],
                        "name": "Linli Xu",
                        "slug": "Linli-Xu",
                        "structuredName": {
                            "firstName": "Linli",
                            "lastName": "Xu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Linli Xu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2110452068"
                        ],
                        "name": "Yitan Li",
                        "slug": "Yitan-Li",
                        "structuredName": {
                            "firstName": "Yitan",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yitan Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144378760"
                        ],
                        "name": "Enhong Chen",
                        "slug": "Enhong-Chen",
                        "structuredName": {
                            "firstName": "Enhong",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Enhong Chen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 258,
                                "start": 253
                            }
                        ],
                        "text": "Applications of MTL in ubiquitous computing include stock prediction [126], multi-device localization [127], the inverse dynamics problem for robotics [128,129], estimation of travel costs on road networks [130], travel-time prediction on road networks [131], and traffic-sign recognition [132]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 13823309,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "199b705508c68d875a88ae3ab5be5911f536d30b",
            "isKey": false,
            "numCitedBy": 9,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "Trajectory regression, which aims to predict the travel time of arbitrary trajectories on road networks, attracts significant attention in various applications of traffic systems these years. In this paper, we tackle this problem with a multitask learning (MTL) framework. To take the temporal nature of the problem into consideration, we divide the regression problem into a set of sub-tasks of distinct time periods, then the problem can be treated in a multi-task learning framework. Further, we propose a novel regularization term in which we exploit the block sparse structure to augment the robustness of the model. In addition, we incorporate the spatial smoothness over road links and thus achieve a spatial-temporal framework. An accelerated proximal algorithm is adopted to solve the convex but non-smooth problem, which will converge to the global optimum. Experiments on both synthetic and real data sets demonstrate the effectiveness of the proposed method."
            },
            "slug": "Robust-Dynamic-Trajectory-Regression-on-Road-A-Huang-Xu",
            "title": {
                "fragments": [],
                "text": "Robust Dynamic Trajectory Regression on Road Networks: A Multi-task Learning Framework"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This paper proposes a novel regularization term in which the block sparse structure is exploited to augment the robustness of the model and incorporate the spatial smoothness over road links and thus achieve a spatial-temporal framework."
            },
            "venue": {
                "fragments": [],
                "text": "2014 IEEE International Conference on Data Mining"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1907582"
                        ],
                        "name": "Tianzhu Zhang",
                        "slug": "Tianzhu-Zhang",
                        "structuredName": {
                            "firstName": "Tianzhu",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tianzhu Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2931652"
                        ],
                        "name": "Bernard Ghanem",
                        "slug": "Bernard-Ghanem",
                        "structuredName": {
                            "firstName": "Bernard",
                            "lastName": "Ghanem",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bernard Ghanem"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2705801"
                        ],
                        "name": "Si Liu",
                        "slug": "Si-Liu",
                        "structuredName": {
                            "firstName": "Si",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Si Liu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145237406"
                        ],
                        "name": "N. Ahuja",
                        "slug": "N.-Ahuja",
                        "structuredName": {
                            "firstName": "Narendra",
                            "lastName": "Ahuja",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Ahuja"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 17100949,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "935e307ab4e2860d49d00fe2fe73f20d8a4a582b",
            "isKey": false,
            "numCitedBy": 693,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we formulate object tracking in a particle filter framework as a multi-task sparse learning problem, which we denote as Multi-Task Tracking (MTT). Since we model particles as linear combinations of dictionary templates that are updated dynamically, learning the representation of each particle is considered a single task in MTT. By employing popular sparsity-inducing \u2113p, q mixed norms (p \u2208 {2, \u221e} and q = 1), we regularize the representation problem to enforce joint sparsity and learn the particle representations together. As compared to previous methods that handle particles independently, our results demonstrate that mining the interdependencies between particles improves tracking performance and overall computational complexity. Interestingly, we show that the popular L1 tracker [15] is a special case of our MTT formulation (denoted as the L11 tracker) when p = q = 1. The learning problem can be efficiently solved using an Accelerated Proximal Gradient (APG) method that yields a sequence of closed form updates. As such, MTT is computationally attractive. We test our proposed approach on challenging sequences involving heavy occlusion, drastic illumination changes, and large pose variations. Experimental results show that MTT methods consistently outperform state-of-the-art trackers."
            },
            "slug": "Robust-visual-tracking-via-multi-task-sparse-Zhang-Ghanem",
            "title": {
                "fragments": [],
                "text": "Robust visual tracking via multi-task sparse learning"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "Experimental results show that MTT methods consistently outperform state-of-the-art trackers and mining the interdependencies between particles improves tracking performance and overall computational complexity."
            },
            "venue": {
                "fragments": [],
                "text": "2012 IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2153910406"
                        ],
                        "name": "Yi Zhang",
                        "slug": "Yi-Zhang",
                        "structuredName": {
                            "firstName": "Yi",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yi Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1753432"
                        ],
                        "name": "J. Schneider",
                        "slug": "J.-Schneider",
                        "structuredName": {
                            "firstName": "Jeff",
                            "lastName": "Schneider",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Schneider"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 54,
                                "start": 50
                            }
                        ],
                        "text": "A model similar to the MTRL method is proposed in [49] by assigning a prior on W as W \u223c MN (0, 1, 2), and it learns the sparse inverse of 1 and 2."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 12705903,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "744785be39435883b65d8badcb423e1584a3fabf",
            "isKey": false,
            "numCitedBy": 125,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we propose a matrix-variate normal penalty with sparse inverse co-variances to couple multiple tasks. Learning multiple (parametric) models can be viewed as estimating a matrix of parameters, where rows and columns of the matrix correspond to tasks and features, respectively. Following the matrix-variate normal density, we design a penalty that decomposes the full covariance of matrix elements into the Kronecker product of row covariance and column covariance, which characterizes both task relatedness and feature representation. Several recently proposed methods are variants of the special cases of this formulation. To address the overfitting issue and select meaningful task and feature structures, we include sparse covariance selection into our matrix-normal regularization via l1 penalties on task and feature inverse covariances. We empirically study the proposed method and compare with related models in two real-world problems: detecting landmines in multiple fields and recognizing faces between different subjects. Experimental results show that the proposed framework provides an effective and flexible way to model various different structures of multiple tasks."
            },
            "slug": "Learning-Multiple-Tasks-with-a-Sparse-Matrix-Normal-Zhang-Schneider",
            "title": {
                "fragments": [],
                "text": "Learning Multiple Tasks with a Sparse Matrix-Normal Penalty"
            },
            "tldr": {
                "abstractSimilarityScore": 60,
                "text": "A matrix-variate normal penalty with sparse inverse co-variances to couple multiple tasks and includes sparse covariance selection into the matrix-normal regularization via l1 penalties on task and feature inverse covariance to address the overfitting issue."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145927745"
                        ],
                        "name": "Liang Zhao",
                        "slug": "Liang-Zhao",
                        "structuredName": {
                            "firstName": "Liang",
                            "lastName": "Zhao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Liang Zhao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2112590875"
                        ],
                        "name": "Qian Sun",
                        "slug": "Qian-Sun",
                        "structuredName": {
                            "firstName": "Qian",
                            "lastName": "Sun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Qian Sun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144030870"
                        ],
                        "name": "Jieping Ye",
                        "slug": "Jieping-Ye",
                        "structuredName": {
                            "firstName": "Jieping",
                            "lastName": "Ye",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jieping Ye"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1399870469"
                        ],
                        "name": "Feng Chen",
                        "slug": "Feng-Chen",
                        "structuredName": {
                            "firstName": "Feng",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Feng Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1752590"
                        ],
                        "name": "Chang-Tien Lu",
                        "slug": "Chang-Tien-Lu",
                        "structuredName": {
                            "firstName": "Chang-Tien",
                            "lastName": "Lu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chang-Tien Lu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48651437"
                        ],
                        "name": "Naren Ramakrishnan",
                        "slug": "Naren-Ramakrishnan",
                        "structuredName": {
                            "firstName": "Naren",
                            "lastName": "Ramakrishnan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Naren Ramakrishnan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 310,
                                "start": 301
                            }
                        ],
                        "text": "part-of-speech tagging, chunking, named entity recognition, semantic role labeling, language modeling and semantically related words) [116], multi-domain sentiment classification [117], multidomain dialog state tracking [21], machine translation [118], syntactic parsing [118], and microblog analysis [119,120]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 3363959,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "de7c6a77780b6b6f0695286ebba18b3c25bd717b",
            "isKey": false,
            "numCitedBy": 122,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": "Spatial event forecasting from social media is an important problem but encounters critical challenges, such as dynamic patterns of features (keywords) and geographic heterogeneity (e.g., spatial correlations, imbalanced samples, and different populations in different locations). Most existing approaches (e.g., LASSO regression, dynamic query expansion, and burst detection) are designed to address some of these challenges, but not all of them. This paper proposes a novel multi-task learning framework which aims to concurrently address all the challenges. Specifically, given a collection of locations (e.g., cities), we propose to build forecasting models for all locations simultaneously by extracting and utilizing appropriate shared information that effectively increases the sample size for each location, thus improving the forecasting performance. We combine both static features derived from a predefined vocabulary by domain experts and dynamic features generated from dynamic query expansion in a multi-task feature learning framework; we investigate different strategies to balance homogeneity and diversity between static and dynamic terms. Efficient algorithms based on Iterative Group Hard Thresholding are developed to achieve efficient and effective model training and prediction. Extensive experimental evaluations on Twitter data from four different countries in Latin America demonstrated the effectiveness of our proposed approach."
            },
            "slug": "Multi-Task-Learning-for-Spatio-Temporal-Event-Zhao-Sun",
            "title": {
                "fragments": [],
                "text": "Multi-Task Learning for Spatio-Temporal Event Forecasting"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This paper proposes a novel multi-task learning framework which aims to concurrently address all the challenges of spatial event forecasting from social media by extracting and utilizing appropriate shared information that effectively increases the sample size for each location, thus improving the forecasting performance."
            },
            "venue": {
                "fragments": [],
                "text": "KDD"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145927745"
                        ],
                        "name": "Liang Zhao",
                        "slug": "Liang-Zhao",
                        "structuredName": {
                            "firstName": "Liang",
                            "lastName": "Zhao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Liang Zhao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2112590875"
                        ],
                        "name": "Qian Sun",
                        "slug": "Qian-Sun",
                        "structuredName": {
                            "firstName": "Qian",
                            "lastName": "Sun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Qian Sun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144030870"
                        ],
                        "name": "Jieping Ye",
                        "slug": "Jieping-Ye",
                        "structuredName": {
                            "firstName": "Jieping",
                            "lastName": "Ye",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jieping Ye"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2650184"
                        ],
                        "name": "F. Chen",
                        "slug": "F.-Chen",
                        "structuredName": {
                            "firstName": "F.",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1752590"
                        ],
                        "name": "Chang-Tien Lu",
                        "slug": "Chang-Tien-Lu",
                        "structuredName": {
                            "firstName": "Chang-Tien",
                            "lastName": "Lu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chang-Tien Lu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1755938"
                        ],
                        "name": "Naren Ramakrishnan",
                        "slug": "Naren-Ramakrishnan",
                        "structuredName": {
                            "firstName": "Naren",
                            "lastName": "Ramakrishnan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Naren Ramakrishnan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 310,
                                "start": 301
                            }
                        ],
                        "text": "part-of-speech tagging, chunking, named entity recognition, semantic role labeling, language modeling and semantically related words) [116], multi-domain sentiment classification [117], multidomain dialog state tracking [21], machine translation [118], syntactic parsing [118], and microblog analysis [119,120]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 3444868,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "76fff291ba525e2ca2895b924293e43069a3e1d5",
            "isKey": false,
            "numCitedBy": 28,
            "numCiting": 43,
            "paperAbstract": {
                "fragments": [],
                "text": "Spatial event forecasting from social media is potentially extremely useful but suffers from critical challenges, such as the dynamic patterns of features (keywords) and geographic heterogeneity (e.g., spatial correlations, imbalanced samples, and different populations in different locations). Most existing approaches (e.g., LASSO regression, dynamic query expansion, and burst detection) address some, but not all, of these challenges. Here, we propose a novel multi-task learning framework that aims to concurrently address all the challenges involved. Specifically, given a collection of locations (e.g., cities), forecasting models are built for all the locations simultaneously by extracting and utilizing appropriate shared information that effectively increases the sample size for each location, thus improving the forecasting performance. The new model combines both static features derived from a predefined vocabulary by domain experts and dynamic features generated from dynamic query expansion in a multi-task feature learning framework. Different strategies to balance homogeneity and diversity between static and dynamic terms are also investigated. And, efficient algorithms based on Iterative Group Hard Thresholding are developed to achieve efficient and effective model training and prediction. Extensive experimental evaluations on Twitter data from civil unrest and influenza outbreak datasets demonstrate the effectiveness and efficiency of our proposed approach."
            },
            "slug": "Feature-Constrained-Multi-Task-Learning-Models-for-Zhao-Sun",
            "title": {
                "fragments": [],
                "text": "Feature Constrained Multi-Task Learning Models for Spatiotemporal Event Forecasting"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A novel multi-task learning framework is proposed that aims to concurrently address all the challenges involved in spatial event forecasting from social media and combines both static features derived from a predefined vocabulary by domain experts and dynamic features generated from dynamic query expansion in a multi- task feature learning framework."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Knowledge and Data Engineering"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1907582"
                        ],
                        "name": "Tianzhu Zhang",
                        "slug": "Tianzhu-Zhang",
                        "structuredName": {
                            "firstName": "Tianzhu",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tianzhu Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2931652"
                        ],
                        "name": "Bernard Ghanem",
                        "slug": "Bernard-Ghanem",
                        "structuredName": {
                            "firstName": "Bernard",
                            "lastName": "Ghanem",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bernard Ghanem"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2705801"
                        ],
                        "name": "Si Liu",
                        "slug": "Si-Liu",
                        "structuredName": {
                            "firstName": "Si",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Si Liu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145237406"
                        ],
                        "name": "N. Ahuja",
                        "slug": "N.-Ahuja",
                        "structuredName": {
                            "firstName": "Narendra",
                            "lastName": "Ahuja",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Ahuja"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6604534,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c39f634edc2318a4b288bd29cf3880505e4ae711",
            "isKey": false,
            "numCitedBy": 408,
            "numCiting": 52,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we formulate object tracking in a particle filter framework as a structured multi-task sparse learning problem, which we denote as Structured Multi-Task Tracking (S-MTT). Since we model particles as linear combinations of dictionary templates that are updated dynamically, learning the representation of each particle is considered a single task in Multi-Task Tracking (MTT). By employing popular sparsity-inducing $$\\ell _{p,q}$$ mixed norms $$(\\text{ specifically} p\\in \\{2,\\infty \\}$$ and $$q=1),$$ we regularize the representation problem to enforce joint sparsity and learn the particle representations together. As compared to previous methods that handle particles independently, our results demonstrate that mining the interdependencies between particles improves tracking performance and overall computational complexity. Interestingly, we show that the popular $$L_1$$ tracker\u00a0(Mei and Ling, IEEE Trans Pattern Anal Mach Intel 33(11):2259\u20132272, 2011) is a special case of our MTT formulation (denoted as the $$L_{11}$$ tracker) when $$p=q=1.$$ Under the MTT framework, some of the tasks (particle representations) are often more closely related and more likely to share common relevant covariates than other tasks. Therefore, we extend the MTT framework to take into account pairwise structural correlations between particles (e.g. spatial smoothness of representation) and denote the novel framework as S-MTT. The problem of learning the regularized sparse representation in MTT and S-MTT can be solved efficiently using an Accelerated Proximal Gradient (APG) method that yields a sequence of closed form updates. As such, S-MTT and MTT are computationally attractive. We test our proposed approach on challenging sequences involving heavy occlusion, drastic illumination changes, and large pose variations. Experimental results show that S-MTT is much better than MTT, and both methods consistently outperform state-of-the-art trackers."
            },
            "slug": "Robust-Visual-Tracking-via-Structured-Multi-Task-Zhang-Ghanem",
            "title": {
                "fragments": [],
                "text": "Robust Visual Tracking via Structured Multi-Task Sparse Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "The results demonstrate that mining the interdependencies between particles improves tracking performance and overall computational complexity, and both methods consistently outperform state-of-the-art trackers."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3152448"
                        ],
                        "name": "Zhanpeng Zhang",
                        "slug": "Zhanpeng-Zhang",
                        "structuredName": {
                            "firstName": "Zhanpeng",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zhanpeng Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47571885"
                        ],
                        "name": "Ping Luo",
                        "slug": "Ping-Luo",
                        "structuredName": {
                            "firstName": "Ping",
                            "lastName": "Luo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ping Luo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1717179"
                        ],
                        "name": "Chen Change Loy",
                        "slug": "Chen-Change-Loy",
                        "structuredName": {
                            "firstName": "Chen",
                            "lastName": "Loy",
                            "middleNames": [
                                "Change"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chen Change Loy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50295995"
                        ],
                        "name": "Xiaoou Tang",
                        "slug": "Xiaoou-Tang",
                        "structuredName": {
                            "firstName": "Xiaoou",
                            "lastName": "Tang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xiaoou Tang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 216,
                                "start": 212
                            }
                        ],
                        "text": "Specifically, applications of MTL based on facial images include face verification [84], personalized age estimation [85], multi-cue face recognition [86], head-pose estimation [22,87], facial landmark detection [18], and facial image rotation [88]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14181993,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f500b1a7df00f67c417673e0538d86abb8a333fa",
            "isKey": false,
            "numCitedBy": 1179,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "Facial landmark detection has long been impeded by the problems of occlusion and pose variation. Instead of treating the detection task as a single and independent problem, we investigate the possibility of improving detection robustness through multi-task learning. Specifically, we wish to optimize facial landmark detection together with heterogeneous but subtly correlated tasks, e.g. head pose estimation and facial attribute inference. This is non-trivial since different tasks have different learning difficulties and convergence rates. To address this problem, we formulate a novel tasks-constrained deep model, with task-wise early stopping to facilitate learning convergence. Extensive evaluations show that the proposed task-constrained learning (i) outperforms existing methods, especially in dealing with faces with severe occlusion and pose variation, and (ii) reduces model complexity drastically compared to the state-of-the-art method based on cascaded deep model [21]."
            },
            "slug": "Facial-Landmark-Detection-by-Deep-Multi-task-Zhang-Luo",
            "title": {
                "fragments": [],
                "text": "Facial Landmark Detection by Deep Multi-task Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "A novel tasks-constrained deep model is formulated, with task-wise early stopping to facilitate learning convergence and reduces model complexity drastically compared to the state-of-the-art method based on cascaded deep model."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152657579"
                        ],
                        "name": "A. Barzilai",
                        "slug": "A.-Barzilai",
                        "structuredName": {
                            "firstName": "Aviad",
                            "lastName": "Barzilai",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Barzilai"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1693407"
                        ],
                        "name": "K. Crammer",
                        "slug": "K.-Crammer",
                        "structuredName": {
                            "firstName": "Koby",
                            "lastName": "Crammer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Crammer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 18,
                                "start": 11
                            }
                        ],
                        "text": "Both works [33,35] decomposeW asW = LS where columns in L consist of basis parameter vectors in different clusters and S contains combination coefficients."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 193,
                                "start": 189
                            }
                        ],
                        "text": "Specifically, the method in [33] aims to identify overlapping task clusters where each task can belong tomultiple clusters and hence it learns a sparse S via the 1 regularization, while in [35], each task lies in only one cluster and hence the 2 norm of each column in the 0/1 matrix S is enforced to be 1."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14236561,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9dd4bc90c6eea47a0aa912c1ad797879cbf67e66",
            "isKey": false,
            "numCitedBy": 43,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "We consider the problem of multi-task learning in which tasks belong to hidden clusters. We formulate the learning problem as a novel convex optimization problem in which linear classiers are combinations of (a small number of) some basis. Our formulation jointly learns both the basis and the linear combination. We propose a scalable optimization algorithm for nding the optimal solution. Our new methods outperform existing stateof-the-art methods on multi-task sentiment classication tasks."
            },
            "slug": "Convex-Multi-Task-Learning-by-Clustering-Barzilai-Crammer",
            "title": {
                "fragments": [],
                "text": "Convex Multi-Task Learning by Clustering"
            },
            "tldr": {
                "abstractSimilarityScore": 83,
                "text": "This work considers the problem of multi-task learning in which tasks belong to hidden clusters as a novel convex optimization problem in which linear classiers are combinations of (a small number of) some basis."
            },
            "venue": {
                "fragments": [],
                "text": "AISTATS"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144056302"
                        ],
                        "name": "A. Wilson",
                        "slug": "A.-Wilson",
                        "structuredName": {
                            "firstName": "Aaron",
                            "lastName": "Wilson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Wilson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145841336"
                        ],
                        "name": "Alan Fern",
                        "slug": "Alan-Fern",
                        "structuredName": {
                            "firstName": "Alan",
                            "lastName": "Fern",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alan Fern"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145527877"
                        ],
                        "name": "Soumya Ray",
                        "slug": "Soumya-Ray",
                        "structuredName": {
                            "firstName": "Soumya",
                            "lastName": "Ray",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Soumya Ray"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1729906"
                        ],
                        "name": "Prasad Tadepalli",
                        "slug": "Prasad-Tadepalli",
                        "structuredName": {
                            "firstName": "Prasad",
                            "lastName": "Tadepalli",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Prasad Tadepalli"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6225453,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ab19a482195f4299f96b98e4eb15cb3ad4753f3b",
            "isKey": false,
            "numCitedBy": 286,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "We consider the problem of multi-task reinforcement learning, where the agent needs to solve a sequence of Markov Decision Processes (MDPs) chosen randomly from a fixed but unknown distribution. We model the distribution over MDPs using a hierarchical Bayesian infinite mixture model. For each novel MDP, we use the previously learned distribution as an informed prior for modelbased Bayesian reinforcement learning. The hierarchical Bayesian framework provides a strong prior that allows us to rapidly infer the characteristics of new environments based on previous environments, while the use of a nonparametric model allows us to quickly adapt to environments we have not encountered before. In addition, the use of infinite mixtures allows for the model to automatically learn the number of underlying MDP components. We evaluate our approach and show that it leads to significant speedups in convergence to an optimal policy after observing only a small number of tasks."
            },
            "slug": "Multi-task-reinforcement-learning:-a-hierarchical-Wilson-Fern",
            "title": {
                "fragments": [],
                "text": "Multi-task reinforcement learning: a hierarchical Bayesian approach"
            },
            "tldr": {
                "abstractSimilarityScore": 83,
                "text": "This work considers the problem of multi-task reinforcement learning, where the agent needs to solve a sequence of Markov Decision Processes chosen randomly from a fixed but unknown distribution, using a hierarchical Bayesian infinite mixture model."
            },
            "venue": {
                "fragments": [],
                "text": "ICML '07"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2152885669"
                        ],
                        "name": "Yan Li",
                        "slug": "Yan-Li",
                        "structuredName": {
                            "firstName": "Yan",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yan Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2146041866"
                        ],
                        "name": "Jie Wang",
                        "slug": "Jie-Wang",
                        "structuredName": {
                            "firstName": "Jie",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jie Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144030870"
                        ],
                        "name": "Jieping Ye",
                        "slug": "Jieping-Ye",
                        "structuredName": {
                            "firstName": "Jieping",
                            "lastName": "Ye",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jieping Ye"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144417522"
                        ],
                        "name": "C. Reddy",
                        "slug": "C.-Reddy",
                        "structuredName": {
                            "firstName": "Chandan",
                            "lastName": "Reddy",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Reddy"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 565,
                                "start": 560
                            }
                        ],
                        "text": "populations [104], construction of personalized brain\u2013computer interfaces [105], MHC-I binding prediction [106], splice-site prediction [106], protein subcellular location prediction [107], Alzheimer\u2019s disease assessment scale cognitive subscale [108], prediction of cognitive outcomes from neuroimaging measures in Alzheimer\u2019s disease [109], identification of longitudinal phenotypic markers for Alzheimer\u2019s disease progression prediction [110], prioritization of disease genes [111], biological image analysis based on natural images [20], survival analysis [112], and multiple genetic trait prediction [113]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 12178207,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "92893d0dff8dbe091c12029bf77a68192891295a",
            "isKey": false,
            "numCitedBy": 88,
            "numCiting": 41,
            "paperAbstract": {
                "fragments": [],
                "text": "Predicting the occurrence of a particular event of interest at future time points is the primary goal of survival analysis. The presence of incomplete observations due to time limitations or loss of data traces is known as censoring which brings unique challenges in this domain and differentiates survival analysis from other standard regression methods. The popularly used survival analysis methods such as Cox proportional hazard model and parametric survival regression suffer from some strict assumptions and hypotheses that are not realistic in most of the real-world applications. To overcome the weaknesses of these two types of methods, in this paper, we reformulate the survival analysis problem as a multi-task learning problem and propose a new multi-task learning based formulation to predict the survival time by estimating the survival status at each time interval during the study duration. We propose an indicator matrix to enable the multi-task learning algorithm to handle censored instances and incorporate some of the important characteristics of survival problems such as non-negative non-increasing list structure into our model through max-heap projection. We employ the L2,1-norm penalty which enables the model to learn a shared representation across related tasks and hence select important features and alleviate over-fitting in high-dimensional feature spaces; thus, reducing the prediction error of each task. To efficiently handle the two non-smooth constraints, in this paper, we propose an optimization method which employs Alternating Direction Method of Multipliers (ADMM) algorithm to solve the proposed multi-task learning problem. We demonstrate the performance of the proposed method using real-world microarray gene expression high-dimensional benchmark datasets and show that our method outperforms state-of-the-art methods."
            },
            "slug": "A-Multi-Task-Learning-Formulation-for-Survival-Li-Wang",
            "title": {
                "fragments": [],
                "text": "A Multi-Task Learning Formulation for Survival Analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "An optimization method which employs Alternating Direction Method of Multipliers (ADMM) algorithm to solve the proposed multi-task learning problem and demonstrates the performance of the proposed method using real-world microarray gene expression high-dimensional benchmark datasets and shows that it outperforms state-of-the-art methods."
            },
            "venue": {
                "fragments": [],
                "text": "KDD"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3086498"
                        ],
                        "name": "Jiangchuan Zheng",
                        "slug": "Jiangchuan-Zheng",
                        "structuredName": {
                            "firstName": "Jiangchuan",
                            "lastName": "Zheng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jiangchuan Zheng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1726587"
                        ],
                        "name": "L. Ni",
                        "slug": "L.-Ni",
                        "structuredName": {
                            "firstName": "Lionel",
                            "lastName": "Ni",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Ni"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 211,
                                "start": 206
                            }
                        ],
                        "text": "Applications of MTL in ubiquitous computing include stock prediction [126], multi-device localization [127], the inverse dynamics problem for robotics [128,129], estimation of travel costs on road networks [130], travel-time prediction on road networks [131], and traffic-sign recognition [132]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 8857932,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4c9ecc72ded229ca344f043db45b275d8bdf4c67",
            "isKey": false,
            "numCitedBy": 79,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "\n \n Road travel costs are important knowledge hidden in large-scale GPS trajectory data sets, the discovery of which can benefit many applications such as intelligent route planning and automatic driving navigation. While there are previous studies which tackled this task by modeling it as a regression problem with spatial smoothness taken into account, they unreasonably assumed that the latent cost of each road remains unchanged over time. Other works on route planning and recommendation that have considered temporal factors simply assumed that the temporal dynamics be known in advance as a parametric function over time, which is not faithful to reality. To overcome these limitations, in this paper, we propose an extension to a previous static trajectory regression framework by learning the temporal dynamics of road travel costs in an innovative non-parametric manner which can effectively overcome the temporal sparsity problem. In particular, we unify multiple different trajectory regression problems in a multi-task framework by introducing a novel cross-task regularization which encourages temporal smoothness on the change of road travel costs. We then propose an efficient block coordinate descent method to solve the resulting problem by exploiting its separable structures and prove its convergence to global optimum. Experiments conducted on both synthetic and real data sets demonstrate the effectiveness of our method and its improved accuracy on travel time prediction.\n \n"
            },
            "slug": "Time-Dependent-Trajectory-Regression-on-Road-via-Zheng-Ni",
            "title": {
                "fragments": [],
                "text": "Time-Dependent Trajectory Regression on Road Networks via Multi-Task Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This paper unify multiple different trajectory regression problems in a multi-task framework by introducing a novel cross-task regularization which encourages temporal smoothness on the change of road travel costs and proposes an efficient block coordinate descent method to solve the resulting problem."
            },
            "venue": {
                "fragments": [],
                "text": "AAAI"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31843833"
                        ],
                        "name": "Xiaogang Wang",
                        "slug": "Xiaogang-Wang",
                        "structuredName": {
                            "firstName": "Xiaogang",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xiaogang Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2109292017"
                        ],
                        "name": "Cha Zhang",
                        "slug": "Cha-Zhang",
                        "structuredName": {
                            "firstName": "Cha",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Cha Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "51064498"
                        ],
                        "name": "Zhengyou Zhang",
                        "slug": "Zhengyou-Zhang",
                        "structuredName": {
                            "firstName": "Zhengyou",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zhengyou Zhang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 87,
                                "start": 83
                            }
                        ],
                        "text": "Specifically, applications of MTL based on facial images include face verification [84], personalized age estimation [85], multi-cue face recognition [86], head-pose estimation [22,87], facial landmark detection [18], and facial image rotation [88]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 4229525,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "993a1c4a3ef53b234c094a13f010e75021401db3",
            "isKey": false,
            "numCitedBy": 53,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "Face verification has many potential applications including filtering and ranking image/video search results on celebrities. Since these images/videos are taken under uncontrolled environments, the problem is very challenging due to dramatic lighting and pose variations, low resolutions, compression artifacts, etc. In addition, the available number of training images for each celebrity may be limited, hence learning individual classifiers for each person may cause overfitting. In this paper, we propose two ideas to meet the above challenges. First, we propose to use individual bins, instead of whole histograms, of Local Binary Patterns (LBP) as features for learning, which yields significant performance improvements and computation reduction in our experiments. Second, we present a novel Multi-Task Learning (MTL) framework, called Boosted MTL, for face verification with limited training data. It jointly learns classifiers for multiple people by sharing a few boosting classifiers in order to avoid overfitting. The effectiveness of Boosted MTL and LBP bin features is verified with a large number of celebrity images/videos from the web."
            },
            "slug": "Boosted-multi-task-learning-for-face-verification-Wang-Zhang",
            "title": {
                "fragments": [],
                "text": "Boosted multi-task learning for face verification with applications to web image and video search"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "A novel Multi-Task Learning (MTL) framework is presented, called Boosted MTL, for face verification with limited training data that jointly learns classifiers for multiple people by sharing a few boosting classifiers in order to avoid overfitting."
            },
            "venue": {
                "fragments": [],
                "text": "2009 IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46867608"
                        ],
                        "name": "Yu Zhang",
                        "slug": "Yu-Zhang",
                        "structuredName": {
                            "firstName": "Yu",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yu Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1739816"
                        ],
                        "name": "D. Yeung",
                        "slug": "D.-Yeung",
                        "structuredName": {
                            "firstName": "Dit-Yan",
                            "lastName": "Yeung",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Yeung"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 121,
                                "start": 117
                            }
                        ],
                        "text": "Specifically, applications of MTL based on facial images include face verification [84], personalized age estimation [85], multi-cue face recognition [86], head-pose estimation [22,87], facial landmark detection [18], and facial image rotation [88]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 4831004,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8000c4f278e9af4d087c0d0895fff7012c5e3d78",
            "isKey": false,
            "numCitedBy": 195,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "Automatic age estimation from facial images has aroused research interests in recent years due to its promising potential for some computer vision applications. Among the methods proposed to date, personalized age estimation methods generally outperform global age estimation methods by learning a separate age estimator for each person in the training data set. However, since typical age databases only contain very limited training data for each person, training a separate age estimator using only training data for that person runs a high risk of overfitting the data and hence the prediction performance is limited. In this paper, we propose a novel approach to age estimation by formulating the problem as a multi-task learning problem. Based on a variant of the Gaussian process (GP) called warped Gaussian process (WGP), we propose a multi-task extension called multi-task warped Gaussian process (MTWGP). Age estimation is formulated as a multi-task regression problem in which each learning task refers to estimation of the age function for each person. While MTWGP models common features shared by different tasks (persons), it also allows task-specific (person-specific) features to be learned automatically. Moreover, unlike previous age estimation methods which need to specify the form of the regression functions or determine many parameters in the functions using inefficient methods such as cross validation, the form of the regression functions in MTWGP is implicitly defined by the kernel function and all its model parameters can be learned from data automatically. We have conducted experiments on two publicly available age databases, FG-NET and MORPH. The experimental results are very promising in showing that MTWGP compares favorably with state-of-the-art age estimation methods."
            },
            "slug": "Multi-task-warped-Gaussian-process-for-personalized-Zhang-Yeung",
            "title": {
                "fragments": [],
                "text": "Multi-task warped Gaussian process for personalized age estimation"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "This paper proposes a novel approach to age estimation by formulating the problem as a multi-task learning problem called multi- task warped Gaussian process (MTWGP), and shows that MTWGP compares favorably with state-of-the-art age estimation methods."
            },
            "venue": {
                "fragments": [],
                "text": "2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144217477"
                        ],
                        "name": "Qian Xu",
                        "slug": "Qian-Xu",
                        "structuredName": {
                            "firstName": "Qian",
                            "lastName": "Xu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Qian Xu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1746914"
                        ],
                        "name": "Sinno Jialin Pan",
                        "slug": "Sinno-Jialin-Pan",
                        "structuredName": {
                            "firstName": "Sinno",
                            "lastName": "Pan",
                            "middleNames": [
                                "Jialin"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sinno Jialin Pan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48419278"
                        ],
                        "name": "H. Xue",
                        "slug": "H.-Xue",
                        "structuredName": {
                            "firstName": "Hong",
                            "lastName": "Xue",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Xue"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152290618"
                        ],
                        "name": "Qiang Yang",
                        "slug": "Qiang-Yang",
                        "structuredName": {
                            "firstName": "Qiang",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Qiang Yang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 188,
                                "start": 183
                            }
                        ],
                        "text": "populations [104], construction of personalized brain\u2013computer interfaces [105], MHC-I binding prediction [106], splice-site prediction [106], protein subcellular location prediction [107], Alzheimer\u2019s disease assessment scale cognitive subscale [108], prediction of cognitive outcomes from neuroimaging measures in Alzheimer\u2019s disease [109], identification of longitudinal phenotypic markers for Alzheimer\u2019s disease progression prediction [110], prioritization of disease genes [111], biological image analysis based on natural images [20], survival analysis [112], and multiple genetic trait prediction [113]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 17904590,
            "fieldsOfStudy": [
                "Computer Science",
                "Biology"
            ],
            "id": "575c013828525bfb11c6b8e337827d2fecdb646c",
            "isKey": false,
            "numCitedBy": 72,
            "numCiting": 77,
            "paperAbstract": {
                "fragments": [],
                "text": "Protein subcellular localization is concerned with predicting the location of a protein within a cell using computational methods. The location information can indicate key functionalities of proteins. Thus, accurate prediction of subcellular localizations of proteins can help the prediction of protein functions and genome annotations, as well as the identification of drug targets. Machine learning methods such as Support Vector Machines (SVMs) have been used in the past for the problem of protein subcellular localization, but have been shown to suffer from a lack of annotated training data in each species under study. To overcome this data sparsity problem, we observe that because some of the organisms may be related to each other, there may be some commonalities across different organisms that can be discovered and used to help boost the data in each localization task. In this paper, we formulate protein subcellular localization problem as one of multitask learning across different organisms. We adapt and compare two specializations of the multitask learning algorithms on 20 different organisms. Our experimental results show that multitask learning performs much better than the traditional single-task methods. Among the different multitask learning methods, we found that the multitask kernels and supertype kernels under multitask learning that share parameters perform slightly better than multitask learning by sharing latent features. The most significant improvement in terms of localization accuracy is about 25 percent. We find that if the organisms are very different or are remotely related from a biological point of view, then jointly training the multiple models cannot lead to significant improvement. However, if they are closely related biologically, the multitask learning can do much better than individual learning."
            },
            "slug": "Multitask-Learning-for-Protein-Subcellular-Location-Xu-Pan",
            "title": {
                "fragments": [],
                "text": "Multitask Learning for Protein Subcellular Location Prediction"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This paper adapt and compare two specializations of the multitask learning algorithms on 20 different organisms, and finds that if the organisms are very different or are remotely related from a biological point of view, then jointly training the multiple models cannot lead to significant improvement, however, if they are closely related biologically, the multitasking can do much better than individual learning."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE/ACM Transactions on Computational Biology and Bioinformatics"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143629707"
                        ],
                        "name": "Amr Ahmed",
                        "slug": "Amr-Ahmed",
                        "structuredName": {
                            "firstName": "Amr",
                            "lastName": "Ahmed",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Amr Ahmed"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144756842"
                        ],
                        "name": "M. Aly",
                        "slug": "M.-Aly",
                        "structuredName": {
                            "firstName": "Mohamed",
                            "lastName": "Aly",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Aly"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2512591"
                        ],
                        "name": "Abhimanyu Das",
                        "slug": "Abhimanyu-Das",
                        "structuredName": {
                            "firstName": "Abhimanyu",
                            "lastName": "Das",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Abhimanyu Das"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46234526"
                        ],
                        "name": "Alex Smola",
                        "slug": "Alex-Smola",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Smola",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alex Smola"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2925865"
                        ],
                        "name": "T. Anastasakos",
                        "slug": "T.-Anastasakos",
                        "structuredName": {
                            "firstName": "Tasos",
                            "lastName": "Anastasakos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Anastasakos"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 174,
                                "start": 169
                            }
                        ],
                        "text": "Web applications based on MTL include learning to rank in web searches [121], web search ranking [122], multi-domain collaborative filtering [123], behavioral targeting [124], and conversion maximization in display advertising [125]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 7478146,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "210681f867f28da1b08c003f160f5543522556a2",
            "isKey": false,
            "numCitedBy": 9,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "A typical behavioral targeting system optimizing purchase activities, called conversions, faces two main challenges: the web-scale amounts of user histories to process on a daily basis, and the relative sparsity of conversions. In this paper, we try to address these challenges through feature selection. We formulate a multi-task (or group) feature-selection problem among a set of related tasks (sharing a common set of features), namely advertising campaigns. We apply a group-sparse penalty consisting of a combination of an l1 and l2 penalty and an associated fast optimization algorithm for distributed parameter estimation. Our algorithm relies on a variant of the well known Fast Iterative Thresholding Algorithm (FISTA), a closed-form solution for mixed norm programming and a distributed subgradient oracle. To efficiently handle web-scale user histories, we present a distributed inference algorithm for the problem that scales to billions of instances and millions of attributes. We show the superiority of our algorithm in terms of both sparsity and ROC performance over baseline feature selection methods (both single-task -regularization and multi-task mutual-information gain)."
            },
            "slug": "Web-scale-multi-task-feature-selection-for-Ahmed-Aly",
            "title": {
                "fragments": [],
                "text": "Web-scale multi-task feature selection for behavioral targeting"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This paper forms a multi-task (or group) feature-selection problem among a set of related tasks (sharing a common set of features), namely advertising campaigns, and applies a group-sparse penalty consisting of a combination of an l1 and l2 penalty and an associated fast optimization algorithm for distributed parameter estimation."
            },
            "venue": {
                "fragments": [],
                "text": "CIKM"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2704747"
                        ],
                        "name": "S. Bickel",
                        "slug": "S.-Bickel",
                        "structuredName": {
                            "firstName": "Steffen",
                            "lastName": "Bickel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Bickel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685405"
                        ],
                        "name": "Jasmina Bogojeska",
                        "slug": "Jasmina-Bogojeska",
                        "structuredName": {
                            "firstName": "Jasmina",
                            "lastName": "Bogojeska",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jasmina Bogojeska"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49370597"
                        ],
                        "name": "Thomas Lengauer",
                        "slug": "Thomas-Lengauer",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Lengauer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thomas Lengauer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751348"
                        ],
                        "name": "T. Scheffer",
                        "slug": "T.-Scheffer",
                        "structuredName": {
                            "firstName": "Tobias",
                            "lastName": "Scheffer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Scheffer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9801408,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7c675c7461a098eb86aeab7e1ddecd99107dd38b",
            "isKey": false,
            "numCitedBy": 194,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "We address the problem of learning classifiers for a large number of tasks. We derive a solution that produces resampling weights which match the pool of all examples to the target distribution of any given task. Our work is motivated by the problem of predicting the outcome of a therapy attempt for a patient who carries an HIV virus with a set of observed genetic properties. Such predictions need to be made for hundreds of possible combinations of drugs, some of which use similar biochemical mechanisms. Multi-task learning enables us to make predictions even for drug combinations with few or no training examples and substantially improves the overall prediction accuracy."
            },
            "slug": "Multi-task-learning-for-HIV-therapy-screening-Bickel-Bogojeska",
            "title": {
                "fragments": [],
                "text": "Multi-task learning for HIV therapy screening"
            },
            "tldr": {
                "abstractSimilarityScore": 67,
                "text": "This work derives a solution that produces resampling weights which match the pool of all examples to the target distribution of any given task, and substantially improves the overall prediction accuracy."
            },
            "venue": {
                "fragments": [],
                "text": "ICML '08"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3249661"
                        ],
                        "name": "Junho Yim",
                        "slug": "Junho-Yim",
                        "structuredName": {
                            "firstName": "Junho",
                            "lastName": "Yim",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Junho Yim"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1800903"
                        ],
                        "name": "Heechul Jung",
                        "slug": "Heechul-Jung",
                        "structuredName": {
                            "firstName": "Heechul",
                            "lastName": "Jung",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Heechul Jung"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1757573"
                        ],
                        "name": "ByungIn Yoo",
                        "slug": "ByungIn-Yoo",
                        "structuredName": {
                            "firstName": "ByungIn",
                            "lastName": "Yoo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "ByungIn Yoo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "36995891"
                        ],
                        "name": "Changkyu Choi",
                        "slug": "Changkyu-Choi",
                        "structuredName": {
                            "firstName": "Changkyu",
                            "lastName": "Choi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Changkyu Choi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1737525"
                        ],
                        "name": "Du-sik Park",
                        "slug": "Du-sik-Park",
                        "structuredName": {
                            "firstName": "Du-sik",
                            "lastName": "Park",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Du-sik Park"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1769295"
                        ],
                        "name": "Junmo Kim",
                        "slug": "Junmo-Kim",
                        "structuredName": {
                            "firstName": "Junmo",
                            "lastName": "Kim",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Junmo Kim"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 248,
                                "start": 244
                            }
                        ],
                        "text": "Specifically, applications of MTL based on facial images include face verification [84], personalized age estimation [85], multi-cue face recognition [86], head-pose estimation [22,87], facial landmark detection [18], and facial image rotation [88]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15990980,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5e2b918f2dee17cb79d692e10aa2103ca9129e2c",
            "isKey": false,
            "numCitedBy": 191,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "Face recognition under viewpoint and illumination changes is a difficult problem, so many researchers have tried to solve this problem by producing the pose- and illumination- invariant feature. Zhu et al. [26] changed all arbitrary pose and illumination images to the frontal view image to use for the invariant feature. In this scheme, preserving identity while rotating pose image is a crucial issue. This paper proposes a new deep architecture based on a novel type of multitask learning, which can achieve superior performance in rotating to a target-pose face image from an arbitrary pose and illumination image while preserving identity. The target pose can be controlled by the user's intention. This novel type of multi-task model significantly improves identity preservation over the single task model. By using all the synthesized controlled pose images, called Controlled Pose Image (CPI), for the pose-illumination-invariant feature and voting among the multiple face recognition results, we clearly outperform the state-of-the-art algorithms by more than 4~6% on the MultiPIE dataset."
            },
            "slug": "Rotating-your-face-using-multi-task-deep-neural-Yim-Jung",
            "title": {
                "fragments": [],
                "text": "Rotating your face using multi-task deep neural network"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "A new deep architecture based on a novel type of multitask learning, which can achieve superior performance in rotating to a target-pose face image from an arbitrary pose and illumination image while preserving identity is proposed."
            },
            "venue": {
                "fragments": [],
                "text": "2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2638781"
                        ],
                        "name": "Fantine Mordelet",
                        "slug": "Fantine-Mordelet",
                        "structuredName": {
                            "firstName": "Fantine",
                            "lastName": "Mordelet",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Fantine Mordelet"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152303545"
                        ],
                        "name": "Jean-Philippe Vert",
                        "slug": "Jean-Philippe-Vert",
                        "structuredName": {
                            "firstName": "Jean-Philippe",
                            "lastName": "Vert",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jean-Philippe Vert"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 484,
                                "start": 479
                            }
                        ],
                        "text": "populations [104], construction of personalized brain\u2013computer interfaces [105], MHC-I binding prediction [106], splice-site prediction [106], protein subcellular location prediction [107], Alzheimer\u2019s disease assessment scale cognitive subscale [108], prediction of cognitive outcomes from neuroimaging measures in Alzheimer\u2019s disease [109], identification of longitudinal phenotypic markers for Alzheimer\u2019s disease progression prediction [110], prioritization of disease genes [111], biological image analysis based on natural images [20], survival analysis [112], and multiple genetic trait prediction [113]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 10072141,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "6d5f63978ba7a954f13f9c78a4afe6fdd303ca31",
            "isKey": false,
            "numCitedBy": 140,
            "numCiting": 40,
            "paperAbstract": {
                "fragments": [],
                "text": "BackgroundElucidating the genetic basis of human diseases is a central goal of genetics and molecular biology. While traditional linkage analysis and modern high-throughput techniques often provide long lists of tens or hundreds of disease gene candidates, the identification of disease genes among the candidates remains time-consuming and expensive. Efficient computational methods are therefore needed to prioritize genes within the list of candidates, by exploiting the wealth of information available about the genes in various databases.ResultsWe propose ProDiGe, a novel algorithm for Prioritization of Disease Genes. ProDiGe implements a novel machine learning strategy based on learning from positive and unlabeled examples, which allows to integrate various sources of information about the genes, to share information about known disease genes across diseases, and to perform genome-wide searches for new disease genes. Experiments on real data show that ProDiGe outperforms state-of-the-art methods for the prioritization of genes in human diseases.ConclusionsProDiGe implements a new machine learning paradigm for gene prioritization, which could help the identification of new disease genes. It is freely available at http://cbio.ensmp.fr/prodige."
            },
            "slug": "ProDiGe:-Prioritization-Of-Disease-Genes-with-from-Mordelet-Vert",
            "title": {
                "fragments": [],
                "text": "ProDiGe: Prioritization Of Disease Genes with multitask machine learning from positive and unlabeled examples"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "ProDiGe implements a new machine learning paradigm for gene prioritization, which could help the identification of new disease genes, and outperforms state-of-the-art methods for the prioritization of genes in human diseases."
            },
            "venue": {
                "fragments": [],
                "text": "BMC Bioinformatics"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "147862501"
                        ],
                        "name": "Qiong Hu",
                        "slug": "Qiong-Hu",
                        "structuredName": {
                            "firstName": "Qiong",
                            "lastName": "Hu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Qiong Hu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2758425"
                        ],
                        "name": "Zhizheng Wu",
                        "slug": "Zhizheng-Wu",
                        "structuredName": {
                            "firstName": "Zhizheng",
                            "lastName": "Wu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zhizheng Wu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144181051"
                        ],
                        "name": "Korin Richmond",
                        "slug": "Korin-Richmond",
                        "structuredName": {
                            "firstName": "Korin",
                            "lastName": "Richmond",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Korin Richmond"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716857"
                        ],
                        "name": "J. Yamagishi",
                        "slug": "J.-Yamagishi",
                        "structuredName": {
                            "firstName": "Junichi",
                            "lastName": "Yamagishi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Yamagishi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3101750"
                        ],
                        "name": "Y. Stylianou",
                        "slug": "Y.-Stylianou",
                        "structuredName": {
                            "firstName": "Yannis",
                            "lastName": "Stylianou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Stylianou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145981206"
                        ],
                        "name": "R. Maia",
                        "slug": "R.-Maia",
                        "structuredName": {
                            "firstName": "Ranniery",
                            "lastName": "Maia",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Maia"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 64,
                                "start": 55
                            }
                        ],
                        "text": "Applications of MTL in speech include speech synthesis [114,115] and those for natural language processing include joint learning of six NLP tasks (i."
                    },
                    "intents": []
                }
            ],
            "corpusId": 18230220,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5e729f3b1275fcd0d3b117b4a2d45c6eecfac7f5",
            "isKey": false,
            "numCitedBy": 37,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "It has recently been shown that deep neural networks (DNN) can improve the quality of statistical parametric speech synthesis (SPSS) when using a source-filter vocoder. Our own previous work has furthermore shown that a dynamic sinusoidal model (DSM) is also highly suited to DNN-based SPSS, whereby sinusoids may either be used themselves as a \u201cdirect parameterisation\u201d (DIR), or they may be encoded using an \u201cintermediate spectral parameterisation\u201d (INT). The approach in that work was effectively to replace a decision tree with a neural network. However, waveform parameterisation and synthesis steps that have been developed to suit HMMs may not fully exploit DNN capabilities. Here, in contrast, we investigate ways to combine INT and DIR at the levels of both DNN modelling and waveform generation. For DNN training, we propose to use multi-task learning to model cepstra (from INT) and log amplitudes (from DIR) as primary and secondary tasks. Our results show combining these improves modelling accuracy for both tasks. Next, during synthesis, instead of discarding parameters from the second task, a fusion method using harmonic amplitudes derived from both tasks is applied. Preference tests show the proposed method gives improved performance, and that this applies to synthesising both with and without global variance parameters."
            },
            "slug": "Fusion-of-multiple-parameterisations-for-DNN-based-Hu-Wu",
            "title": {
                "fragments": [],
                "text": "Fusion of multiple parameterisations for DNN-based sinusoidal speech synthesis with multi-task learning"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "This work investigates ways to combine INT and DIR at the levels of both DNN modelling and waveform generation and proposes to use multi-task learning to model cepstra and log amplitudes as primary and secondary tasks for DNN training."
            },
            "venue": {
                "fragments": [],
                "text": "INTERSPEECH"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144695232"
                        ],
                        "name": "S. Kakade",
                        "slug": "S.-Kakade",
                        "structuredName": {
                            "firstName": "Sham",
                            "lastName": "Kakade",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Kakade"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1389955537"
                        ],
                        "name": "S. Shalev-Shwartz",
                        "slug": "S.-Shalev-Shwartz",
                        "structuredName": {
                            "firstName": "Shai",
                            "lastName": "Shalev-Shwartz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Shalev-Shwartz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3064914"
                        ],
                        "name": "Ambuj Tewari",
                        "slug": "Ambuj-Tewari",
                        "structuredName": {
                            "firstName": "Ambuj",
                            "lastName": "Tewari",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ambuj Tewari"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 49,
                                "start": 44
                            }
                        ],
                        "text": "[7,134] for the feature transform approach, [135] for the feature selection approach, [24,135\u2013138] for the lowrank approach, [136] for the task-relation learning approach, and [138] for the dirty approach."
                    },
                    "intents": []
                }
            ],
            "corpusId": 8477893,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "52087aa2426a1dea55e41982b2dc7b6956483885",
            "isKey": false,
            "numCitedBy": 184,
            "numCiting": 44,
            "paperAbstract": {
                "fragments": [],
                "text": "There is growing body of learning problems for which it is natural to organize the parameters into a matrix. As a result, it becomes easy to impose sophisticated prior knowledge by appropriately regularizing the parameters under some matrix norm. This work describes and analyzes a systematic method for constructing such matrix-based regularization techniques. In particular, we focus on how the underlying statistical properties of a given problem can help us decide which regularization function is appropriate. \n \nOur methodology is based on a known duality phenomenon: a function is strongly convex with respect to some norm if and only if its conjugate function is strongly smooth with respect to the dual norm. This result has already been found to be a key component in deriving and analyzing several learning algorithms. We demonstrate the potential of this framework by deriving novel generalization and regret bounds for multi-task learning, multi-class learning, and multiple kernel learning."
            },
            "slug": "Regularization-Techniques-for-Learning-with-Kakade-Shalev-Shwartz",
            "title": {
                "fragments": [],
                "text": "Regularization Techniques for Learning with Matrices"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This work describes and analyzes a systematic method for constructing matrix-based regularization techniques and demonstrates the potential of this framework by deriving novel generalization and regret bounds for multi-task learning, multi-class learning, and multiple kernel learning."
            },
            "venue": {
                "fragments": [],
                "text": "J. Mach. Learn. Res."
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2158519077"
                        ],
                        "name": "Kai Zhang",
                        "slug": "Kai-Zhang",
                        "structuredName": {
                            "firstName": "Kai",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kai Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144146923"
                        ],
                        "name": "J. Gray",
                        "slug": "J.-Gray",
                        "structuredName": {
                            "firstName": "Joe",
                            "lastName": "Gray",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Gray"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35170576"
                        ],
                        "name": "B. Parvin",
                        "slug": "B.-Parvin",
                        "structuredName": {
                            "firstName": "Bahram",
                            "lastName": "Parvin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Parvin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 159,
                                "start": 154
                            }
                        ],
                        "text": "Applications of MTL in bioinformatics and health informatics include organism modeling [101], mechanism identification of response to therapeutic targets [102], cross-platform siRNA efficacy prediction [103], detection of causal genetic markers through association analysis of multiple"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 6335519,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "8bc9cf18ee1abc45c9b284d5a77b09e3348d483d",
            "isKey": false,
            "numCitedBy": 58,
            "numCiting": 40,
            "paperAbstract": {
                "fragments": [],
                "text": "Motivation: Molecular association of phenotypic responses is an important step in hypothesis generation and for initiating design of new experiments. Current practices for associating gene expression data with multidimensional phenotypic data are typically (i) performed one-to-one, i.e. each gene is examined independently with a phenotypic index and (ii) tested with one stress condition at a time, i.e. different perturbations are analyzed separately. As a result, the complex coordination among the genes responsible for a phenotypic profile is potentially lost. More importantly, univariate analysis can potentially hide new insights into common mechanism of response. Results: In this article, we propose a sparse, multitask regression model together with co-clustering analysis to explore the intrinsic grouping in associating the gene expression with phenotypic signatures. The global structure of association is captured by learning an intrinsic template that is shared among experimental conditions, with local perturbations introduced to integrate effects of therapeutic agents. We demonstrate the performance of our approach on both synthetic and experimental data. Synthetic data reveal that the multi-task regression has a superior reduction in the regression error when compared with traditional L1-and L2-regularized regression. On the other hand, experiments with cell cycle inhibitors over a panel of 14 breast cancer cell lines demonstrate the relevance of the computed molecular predictors with the cell cycle machinery, as well as the identification of hidden variables that are not captured by the baseline regression analysis. Accordingly, the system has identified CLCA2 as a hidden transcript and as a common mechanism of response for two therapeutic agents of CI-1040 and Iressa, which are currently in clinical use. Contact: b_parvin@lbl.gov"
            },
            "slug": "Sparse-multitask-regression-for-identifying-common-Zhang-Gray",
            "title": {
                "fragments": [],
                "text": "Sparse multitask regression for identifying common mechanism of response to therapeutic targets"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "A sparse, multitask regression model together with co-clustering analysis is proposed to explore the intrinsic grouping in associating the gene expression with phenotypic signatures and has identified CLCA2 as a hidden transcript and as a common mechanism of response for two therapeutic agents of CI-1040 and Iressa, which are currently in clinical use."
            },
            "venue": {
                "fragments": [],
                "text": "Bioinform."
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2113253801"
                        ],
                        "name": "Hua Wang",
                        "slug": "Hua-Wang",
                        "structuredName": {
                            "firstName": "Hua",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hua Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144962210"
                        ],
                        "name": "F. Nie",
                        "slug": "F.-Nie",
                        "structuredName": {
                            "firstName": "Feiping",
                            "lastName": "Nie",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Nie"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1748032"
                        ],
                        "name": "Heng Huang",
                        "slug": "Heng-Huang",
                        "structuredName": {
                            "firstName": "Heng",
                            "lastName": "Huang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Heng Huang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3325036"
                        ],
                        "name": "Jingwen Yan",
                        "slug": "Jingwen-Yan",
                        "structuredName": {
                            "firstName": "Jingwen",
                            "lastName": "Yan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jingwen Yan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "15319264"
                        ],
                        "name": "Sungeun Kim",
                        "slug": "Sungeun-Kim",
                        "structuredName": {
                            "firstName": "Sungeun",
                            "lastName": "Kim",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sungeun Kim"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2678448"
                        ],
                        "name": "S. Risacher",
                        "slug": "S.-Risacher",
                        "structuredName": {
                            "firstName": "Shannon",
                            "lastName": "Risacher",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Risacher"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7992909"
                        ],
                        "name": "A. Saykin",
                        "slug": "A.-Saykin",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Saykin",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Saykin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144779870"
                        ],
                        "name": "Li Shen",
                        "slug": "Li-Shen",
                        "structuredName": {
                            "firstName": "Li",
                            "lastName": "Shen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Li Shen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 445,
                                "start": 440
                            }
                        ],
                        "text": "populations [104], construction of personalized brain\u2013computer interfaces [105], MHC-I binding prediction [106], splice-site prediction [106], protein subcellular location prediction [107], Alzheimer\u2019s disease assessment scale cognitive subscale [108], prediction of cognitive outcomes from neuroimaging measures in Alzheimer\u2019s disease [109], identification of longitudinal phenotypic markers for Alzheimer\u2019s disease progression prediction [110], prioritization of disease genes [111], biological image analysis based on natural images [20], survival analysis [112], and multiple genetic trait prediction [113]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1296677,
            "fieldsOfStudy": [
                "Psychology",
                "Biology"
            ],
            "id": "ec5914697d1629f96952273d16a3e1fc633e5e1e",
            "isKey": false,
            "numCitedBy": 72,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "Alzheimer's disease (AD) is a neurodegenerative disorder characterized by progressive impairment of memory and other cognitive functions. Regression analysis has been studied to relate neuroimaging measures to cognitive status. However, whether these measures have further predictive power to infer a trajectory of cognitive performance over time is still an under-explored but important topic in AD research. We propose a novel high-order multi-task learning model to address this issue. The proposed model explores the temporal correlations existing in imaging and cognitive data by structured sparsity-inducing norms. The sparsity of the model enables the selection of a small number of imaging measures while maintaining high prediction accuracy. The empirical studies, using the longitudinal imaging and cognitive data of the ADNI cohort, have yielded promising results."
            },
            "slug": "High-Order-Multi-Task-Feature-Learning-to-Identify-Wang-Nie",
            "title": {
                "fragments": [],
                "text": "High-Order Multi-Task Feature Learning to Identify Longitudinal Phenotypic Markers for Alzheimer's Disease Progression Prediction"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A novel high-order multi-task learning model is proposed that explores the temporal correlations existing in imaging and cognitive data by structured sparsity-inducing norms and enables the selection of a small number of imaging measures while maintaining high prediction accuracy."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47392513"
                        ],
                        "name": "Jonathan Baxter",
                        "slug": "Jonathan-Baxter",
                        "structuredName": {
                            "firstName": "Jonathan",
                            "lastName": "Baxter",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jonathan Baxter"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 55,
                                "start": 50
                            }
                        ],
                        "text": "Thefirst generalizationbound forMTL is derived in [133] for a general MTL model."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 9803204,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "727e1e16ede6eaad241bad11c525da07b154c688",
            "isKey": false,
            "numCitedBy": 972,
            "numCiting": 85,
            "paperAbstract": {
                "fragments": [],
                "text": "A major problem in machine learning is that of inductive bias: how to choose a learner's hypothesis space so that it is large enough to contain a solution to the problem being learnt, yet small enough to ensure reliable generalization from reasonably-sized training sets. Typically such bias is supplied by hand through the skill and insights of experts. In this paper a model for automatically learning bias is investigated. The central assumption of the model is that the learner is embedded within an environment of related learning tasks. Within such an environment the learner can sample from multiple tasks, and hence it can search for a hypothesis space that contains good solutions to many of the problems in the environment. Under certain restrictions on the set of all hypothesis spaces available to the learner, we show that a hypothesis space that performs well on a sufficiently large number of training tasks will also perform well when learning novel tasks in the same environment. Explicit bounds are also derived demonstrating that learning multiple tasks within an environment of related tasks can potentially give much better generalization than learning a single task."
            },
            "slug": "A-Model-of-Inductive-Bias-Learning-Baxter",
            "title": {
                "fragments": [],
                "text": "A Model of Inductive Bias Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "Under certain restrictions on the set of all hypothesis spaces available to the learner, it is shown that a hypothesis space that performs well on a sufficiently large number of training tasks will also perform well when learning novel tasks in the same environment."
            },
            "venue": {
                "fragments": [],
                "text": "J. Artif. Intell. Res."
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145422145"
                        ],
                        "name": "Chi Su",
                        "slug": "Chi-Su",
                        "structuredName": {
                            "firstName": "Chi",
                            "lastName": "Su",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chi Su"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49341950"
                        ],
                        "name": "Fan Yang",
                        "slug": "Fan-Yang",
                        "structuredName": {
                            "firstName": "Fan",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Fan Yang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1776581"
                        ],
                        "name": "Shiliang Zhang",
                        "slug": "Shiliang-Zhang",
                        "structuredName": {
                            "firstName": "Shiliang",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shiliang Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144876831"
                        ],
                        "name": "Q. Tian",
                        "slug": "Q.-Tian",
                        "structuredName": {
                            "firstName": "Qi",
                            "lastName": "Tian",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Q. Tian"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1693428"
                        ],
                        "name": "L. Davis",
                        "slug": "L.-Davis",
                        "structuredName": {
                            "firstName": "Larry",
                            "lastName": "Davis",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Davis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2153576035"
                        ],
                        "name": "Wen Gao",
                        "slug": "Wen-Gao",
                        "structuredName": {
                            "firstName": "Wen",
                            "lastName": "Gao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wen Gao"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 306,
                                "start": 302
                            }
                        ],
                        "text": "Applications of MTL based on non-facial images include object categorization [86], image segmentation [89,90], identifying brain imaging predictors [91], saliency detection [92], action recognition [93], scene classification [94], multi-attribute prediction [95], multi-camera person re-identification [96], and immediacy prediction [97]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 13377293,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "97fa3a6a56b5e762d20b5a4b8b6c80949c7cda71",
            "isKey": false,
            "numCitedBy": 181,
            "numCiting": 54,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a novel Multi-Task Learning with Low Rank Attribute Embedding (MTL-LORAE) framework for person re-identification. Re-identifications from multiple cameras are regarded as related tasks to exploit shared information to improve re-identification accuracy. Both low level features and semantic/data-driven attributes are utilized. Since attributes are generally correlated, we introduce a low rank attribute embedding into the MTL formulation to embed original binary attributes to a continuous attribute space, where incorrect and incomplete attributes are rectified and recovered to better describe people. The learning objective function consists of a quadratic loss regarding class labels and an attribute embedding error, which is solved by an alternating optimization procedure. Experiments on three person re-identification datasets have demonstrated that MTL-LORAE outperforms existing approaches by a large margin and produces state-of-the-art results."
            },
            "slug": "Multi-Task-Learning-with-Low-Rank-Attribute-for-Su-Yang",
            "title": {
                "fragments": [],
                "text": "Multi-Task Learning with Low Rank Attribute Embedding for Person Re-Identification"
            },
            "tldr": {
                "abstractSimilarityScore": 73,
                "text": "A novel Multi-Task Learning with Low Rank Attribute Embedding (MTL-LORAE) framework for person re-identification that outperforms existing approaches by a large margin and produces state-of-the-art results."
            },
            "venue": {
                "fragments": [],
                "text": "2015 IEEE International Conference on Computer Vision (ICCV)"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1944369"
                        ],
                        "name": "Sijin Li",
                        "slug": "Sijin-Li",
                        "structuredName": {
                            "firstName": "Sijin",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sijin Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31476320"
                        ],
                        "name": "Zhi-Qiang Liu",
                        "slug": "Zhi-Qiang-Liu",
                        "structuredName": {
                            "firstName": "Zhi-Qiang",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zhi-Qiang Liu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3651407"
                        ],
                        "name": "Antoni B. Chan",
                        "slug": "Antoni-B.-Chan",
                        "structuredName": {
                            "firstName": "Antoni",
                            "lastName": "Chan",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Antoni B. Chan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 184,
                                "start": 177
                            }
                        ],
                        "text": "Specifically, applications of MTL based on facial images include face verification [84], personalized age estimation [85], multi-cue face recognition [86], head-pose estimation [22,87], facial landmark detection [18], and facial image rotation [88]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 12423853,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f5578e38ae78ecf4f1892d4c3d30367b9390dd6f",
            "isKey": false,
            "numCitedBy": 195,
            "numCiting": 42,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a heterogeneous multi-task learning framework for human pose estimation from monocular images using a deep convolutional neural network. In particular, we simultaneously learn a human pose regressor and sliding-window body-part and joint-point detectors in a deep network architecture. We show that including the detection tasks helps to regularize the network, directing it to converge to a good solution. We report competitive and state-of-art results on several datasets. We also empirically show that the learned neurons in the middle layer of our network are tuned to localized body parts."
            },
            "slug": "Heterogeneous-Multi-task-Learning-for-Human-Pose-Li-Liu",
            "title": {
                "fragments": [],
                "text": "Heterogeneous Multi-task Learning for Human Pose Estimation with Deep Convolutional Neural Network"
            },
            "tldr": {
                "abstractSimilarityScore": 70,
                "text": "A heterogeneous multi-task learning framework for human pose estimation from monocular images using a deep convolutional neural network and it is shown that including the detection tasks helps to regularize the network, directing it to converge to a good solution."
            },
            "venue": {
                "fragments": [],
                "text": "2014 IEEE Conference on Computer Vision and Pattern Recognition Workshops"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46867608"
                        ],
                        "name": "Yu Zhang",
                        "slug": "Yu-Zhang",
                        "structuredName": {
                            "firstName": "Yu",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yu Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144948990"
                        ],
                        "name": "Bin Cao",
                        "slug": "Bin-Cao",
                        "structuredName": {
                            "firstName": "Bin",
                            "lastName": "Cao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bin Cao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1739816"
                        ],
                        "name": "D. Yeung",
                        "slug": "D.-Yeung",
                        "structuredName": {
                            "firstName": "Dit-Yan",
                            "lastName": "Yeung",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Yeung"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 146,
                                "start": 141
                            }
                        ],
                        "text": "Web applications based on MTL include learning to rank in web searches [121], web search ranking [122], multi-domain collaborative filtering [123], behavioral targeting [124], and conversion maximization in display advertising [125]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 1025328,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "93ac8d0782392cd450d25f45539d8a5c5274ada2",
            "isKey": false,
            "numCitedBy": 161,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "Collaborative filtering is an effective recommendation approach in which the preference of a user on an item is predicted based on the preferences of other users with similar interests. A big challenge in using collaborative filtering methods is the data sparsity problem which often arises because each user typically only rates very few items and hence the rating matrix is extremely sparse. In this paper, we address this problem by considering multiple collaborative filtering tasks in different domains simultaneously and exploiting the relationships between domains. We refer to it as a multi-domain collaborative filtering (MCF) problem. To solve the MCF problem, we propose a probabilistic framework which uses probabilistic matrix factorization to model the rating problem in each domain and allows the knowledge to be adaptively transferred across different domains by automatically learning the correlation between domains. We also introduce the link function for different domains to correct their biases. Experiments conducted on several real-world applications demonstrate the effectiveness of our methods when compared with some representative methods."
            },
            "slug": "Multi-Domain-Collaborative-Filtering-Zhang-Cao",
            "title": {
                "fragments": [],
                "text": "Multi-Domain Collaborative Filtering"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "A Probabilistic framework is proposed which uses probabilistic matrix factorization to model the rating problem in each domain and allows the knowledge to be adaptively transferred across different domains by automatically learning the correlation between domains."
            },
            "venue": {
                "fragments": [],
                "text": "UAI"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1809306"
                        ],
                        "name": "Jialei Wang",
                        "slug": "Jialei-Wang",
                        "structuredName": {
                            "firstName": "Jialei",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jialei Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1682383"
                        ],
                        "name": "M. Kolar",
                        "slug": "M.-Kolar",
                        "structuredName": {
                            "firstName": "Mladen",
                            "lastName": "Kolar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Kolar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1706280"
                        ],
                        "name": "Nathan Srebro",
                        "slug": "Nathan-Srebro",
                        "structuredName": {
                            "firstName": "Nathan",
                            "lastName": "Srebro",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nathan Srebro"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 7,
                                "start": 3
                            }
                        ],
                        "text": "In [83], a distributed algorithm is proposed based on a debiased lasso model and by learning one task in a machine, this algorithm achieves efficient communications."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 18945188,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bfc6d423a6d8f639698f071c8bce7e21d75acf6f",
            "isKey": false,
            "numCitedBy": 54,
            "numCiting": 44,
            "paperAbstract": {
                "fragments": [],
                "text": "We consider the problem of distributed multitask learning, where each machine learns a separate, but related, task. Specifically, each machine learns a linear predictor in high-dimensional space, where all tasks share the same small support. We present a communication-efficient estimator based on the debiased lasso and show that it is comparable with the optimal centralized method."
            },
            "slug": "Distributed-Multi-Task-Learning-Wang-Kolar",
            "title": {
                "fragments": [],
                "text": "Distributed Multi-Task Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A communication-efficient estimator based on the debiased lasso is presented and it is shown that it is comparable with the optimal centralized method."
            },
            "venue": {
                "fragments": [],
                "text": "AISTATS"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49957601"
                        ],
                        "name": "Han Liu",
                        "slug": "Han-Liu",
                        "structuredName": {
                            "firstName": "Han",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Han Liu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1752252"
                        ],
                        "name": "Mark Palatucci",
                        "slug": "Mark-Palatucci",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Palatucci",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mark Palatucci"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2151810108"
                        ],
                        "name": "Jian Zhang",
                        "slug": "Jian-Zhang",
                        "structuredName": {
                            "firstName": "Jian",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jian Zhang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 138,
                                "start": 134
                            }
                        ],
                        "text": "Concrete instances of the p, q regularization include the 2,1 regularization proposed in [8,9] and the \u221e,1 regularization proposed in [10]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 12936969,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4a673270c0307abafdbbfd07de02e9e12fc283ad",
            "isKey": false,
            "numCitedBy": 221,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "We develop a cyclical blockwise coordinate descent algorithm for the multi-task Lasso that efficiently solves problems with thousands of features and tasks. The main result shows that a closed-form Winsorization operator can be obtained for the sup-norm penalized least squares regression. This allows the algorithm to find solutions to very large-scale problems far more efficiently than existing methods. This result complements the pioneering work of Friedman, et al. (2007) for the single-task Lasso. As a case study, we use the multi-task Lasso as a variable selector to discover a semantic basis for predicting human neural activation. The learned solution outperforms the standard basis for this task on the majority of test participants, while requiring far fewer assumptions about cognitive neuroscience. We demonstrate how this learned basis can yield insights into how the brain represents the meanings of words."
            },
            "slug": "Blockwise-coordinate-descent-procedures-for-the-to-Liu-Palatucci",
            "title": {
                "fragments": [],
                "text": "Blockwise coordinate descent procedures for the multi-task lasso, with applications to neural semantic basis discovery"
            },
            "tldr": {
                "abstractSimilarityScore": 91,
                "text": "A cyclical blockwise coordinate descent algorithm for the multi-task Lasso that efficiently solves problems with thousands of features and tasks and shows that a closed-form Winsorization operator can be obtained for the sup-norm penalized least squares regression."
            },
            "venue": {
                "fragments": [],
                "text": "ICML '09"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2533906"
                        ],
                        "name": "G. Obozinski",
                        "slug": "G.-Obozinski",
                        "structuredName": {
                            "firstName": "Guillaume",
                            "lastName": "Obozinski",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Obozinski"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685978"
                        ],
                        "name": "B. Taskar",
                        "slug": "B.-Taskar",
                        "structuredName": {
                            "firstName": "Ben",
                            "lastName": "Taskar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Taskar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694621"
                        ],
                        "name": "Michael I. Jordan",
                        "slug": "Michael-I.-Jordan",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Jordan",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael I. Jordan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 94,
                                "start": 89
                            }
                        ],
                        "text": "Concrete instances of the p, q regularization include the 2,1 regularization proposed in [8,9] and the \u221e,1 regularization proposed in [10]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6998485,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "3f4f6a261f0536c3c9b4e023f34186897a7a4887",
            "isKey": false,
            "numCitedBy": 512,
            "numCiting": 47,
            "paperAbstract": {
                "fragments": [],
                "text": "We address the problem of recovering a common set of covariates that are relevant simultaneously to several classification problems. By penalizing the sum of \u21132 norms of the blocks of coefficients associated with each covariate across different classification problems, similar sparsity patterns in all models are encouraged. To take computational advantage of the sparsity of solutions at high regularization levels, we propose a blockwise path-following scheme that approximately traces the regularization path. As the regularization coefficient decreases, the algorithm maintains and updates concurrently a growing set of covariates that are simultaneously active for all problems. We also show how to use random projections to extend this approach to the problem of joint subspace selection, where multiple predictors are found in a common low-dimensional subspace. We present theoretical results showing that this random projection approach converges to the solution yielded by trace-norm regularization. Finally, we present a variety of experimental results exploring joint covariate selection and joint subspace selection, comparing the path-following approach to competing algorithms in terms of prediction accuracy and running time."
            },
            "slug": "Joint-covariate-selection-and-joint-subspace-for-Obozinski-Taskar",
            "title": {
                "fragments": [],
                "text": "Joint covariate selection and joint subspace selection for multiple classification problems"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A blockwise path-following scheme that approximately traces the regularization path and theoretical results showing that this random projection approach converges to the solution yielded by trace-norm regularization are presented."
            },
            "venue": {
                "fragments": [],
                "text": "Stat. Comput."
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2051301"
                        ],
                        "name": "Ting Kei Pong",
                        "slug": "Ting-Kei-Pong",
                        "structuredName": {
                            "firstName": "Ting",
                            "lastName": "Pong",
                            "middleNames": [
                                "Kei"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ting Kei Pong"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1682823"
                        ],
                        "name": "P. Tseng",
                        "slug": "P.-Tseng",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Tseng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Tseng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1743600"
                        ],
                        "name": "Shuiwang Ji",
                        "slug": "Shuiwang-Ji",
                        "structuredName": {
                            "firstName": "Shuiwang",
                            "lastName": "Ji",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shuiwang Ji"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144030870"
                        ],
                        "name": "Jieping Ye",
                        "slug": "Jieping-Ye",
                        "structuredName": {
                            "firstName": "Jieping",
                            "lastName": "Ye",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jieping Ye"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 219,
                                "start": 215
                            }
                        ],
                        "text": "Based on the analysis in optimization, regularizing with the trace norm, which is defined as \u2016W\u2016S(1) = \u2211min(m,d) i=1 \u03bci (W), can make a matrix low-rank and hence trace-norm regularization is widely used in MTL with [26] as a representative work."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1433599,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "50925dae14ccda9be1ab1108961caf8d17065ba6",
            "isKey": false,
            "numCitedBy": 209,
            "numCiting": 69,
            "paperAbstract": {
                "fragments": [],
                "text": "We consider a recently proposed optimization formulation of multi-task learning based on trace norm regularized least squares. While this problem may be formulated as a semidefinite program (SDP), its size is beyond general SDP solvers. Previous solution approaches apply proximal gradient methods to solve the primal problem. We derive new primal and dual reformulations of this problem, including a reduced dual formulation that involves minimizing a convex quadratic function over an operator-norm ball in matrix space. This reduced dual problem may be solved by gradient-projection methods, with each projection involving a singular value decomposition. The dual approach is compared with existing approaches and its practical effectiveness is illustrated on simulations and an application to gene expression pattern analysis."
            },
            "slug": "Trace-Norm-Regularization:-Reformulations,-and-Pong-Tseng",
            "title": {
                "fragments": [],
                "text": "Trace Norm Regularization: Reformulations, Algorithms, and Multi-Task Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This work derives new primal and dual reformulations of the primal problem of multi-task learning, including a reduced dual formulation that involves minimizing a convex quadratic function over an operator-norm ball in matrix space."
            },
            "venue": {
                "fragments": [],
                "text": "SIAM J. Optim."
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145611269"
                        ],
                        "name": "A. Lozano",
                        "slug": "A.-Lozano",
                        "structuredName": {
                            "firstName": "Aur\u00e9lie",
                            "lastName": "Lozano",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Lozano"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1782475"
                        ],
                        "name": "G. Swirszcz",
                        "slug": "G.-Swirszcz",
                        "structuredName": {
                            "firstName": "Grzegorz",
                            "lastName": "Swirszcz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Swirszcz"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 20,
                                "start": 16
                            }
                        ],
                        "text": "For example, in [12], a multi-level lasso is proposed by decomposingwji, the (j, i)th entry inW, asw j i = \u03b8 j \u0175 j i ."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 18061125,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8d8aa22affe4225ca51ec460463b8fb6b5f505a4",
            "isKey": false,
            "numCitedBy": 86,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a flexible formulation for variable selection in multi-task regression to allow for discrepancies in the estimated sparsity patterns accross the multiple tasks, while leveraging the common structure among them. Our approach is based on an intuitive decomposition of the regression coe_cients into a product between a component that is common to all tasks and another component that captures task-specificity. This decomposition yields the Multi-level Lasso objective that can be solved efficiently via alternating optimization. The analysis of the \"orthonormal design\" case reveals some interesting insights on the nature of the shrinkage performed by our method, compared to that of related work. Theoretical guarantees are provided on the consistency of Multi-level Lasso. Simulations and empirical study of micro-array data further demonstrate the value of our framework."
            },
            "slug": "Multi-level-Lasso-for-Sparse-Multi-task-Regression-Lozano-Swirszcz",
            "title": {
                "fragments": [],
                "text": "Multi-level Lasso for Sparse Multi-task Regression"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The approach is based on an intuitive decomposition of the regression coe_cients into a product between a component that is common to all tasks and another component that captures task-specificity that yields the Multi-level Lasso objective."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2117994655"
                        ],
                        "name": "Wu Liu",
                        "slug": "Wu-Liu",
                        "structuredName": {
                            "firstName": "Wu",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wu Liu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144025741"
                        ],
                        "name": "Tao Mei",
                        "slug": "Tao-Mei",
                        "structuredName": {
                            "firstName": "Tao",
                            "lastName": "Mei",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tao Mei"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1699819"
                        ],
                        "name": "Yongdong Zhang",
                        "slug": "Yongdong-Zhang",
                        "structuredName": {
                            "firstName": "Yongdong",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yongdong Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2054192576"
                        ],
                        "name": "Cherry Che",
                        "slug": "Cherry-Che",
                        "structuredName": {
                            "firstName": "Cherry",
                            "lastName": "Che",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Cherry Che"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "33642939"
                        ],
                        "name": "Jiebo Luo",
                        "slug": "Jiebo-Luo",
                        "structuredName": {
                            "firstName": "Jiebo",
                            "lastName": "Luo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jiebo Luo"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14495525,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "562fbe1f8b8a77fbeb2adea42476752246b610e7",
            "isKey": false,
            "numCitedBy": 188,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "Given the tremendous growth of online videos, video thumbnail, as the common visualization form of video content, is becoming increasingly important to influence user's browsing and searching experience. However, conventional methods for video thumbnail selection often fail to produce satisfying results as they ignore the side semantic information (e.g., title, description, and query) associated with the video. As a result, the selected thumbnail cannot always represent video semantics and the click-through rate is adversely affected even when the retrieved videos are relevant. In this paper, we have developed a multi-task deep visual-semantic embedding model, which can automatically select query-dependent video thumbnails according to both visual and side information. Different from most existing methods, the proposed approach employs the deep visual-semantic embedding model to directly compute the similarity between the query and video thumbnails by mapping them into a common latent semantic space, where even unseen query-thumbnail pairs can be correctly matched. In particular, we train the embedding model by exploring the large-scale and freely accessible click-through video and image data, as well as employing a multi-task learning strategy to holistically exploit the query-thumbnail relevance from these two highly related datasets. Finally, a thumbnail is selected by fusing both the representative and query relevance scores. The evaluations on 1,000 query-thumbnail dataset labeled by 191 workers in Amazon Mechanical Turk have demonstrated the effectiveness of our proposed method."
            },
            "slug": "Multi-task-deep-visual-semantic-embedding-for-video-Liu-Mei",
            "title": {
                "fragments": [],
                "text": "Multi-task deep visual-semantic embedding for video thumbnail selection"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "A multi-task deep visual-semantic embedding model is developed that can automatically select query-dependent video thumbnails according to both visual and side information and is demonstrated to be effective on 1,000 query-thumbnail dataset labeled by 191 workers in Amazon Mechanical Turk."
            },
            "venue": {
                "fragments": [],
                "text": "2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1890071"
                        ],
                        "name": "K. M. A. Chai",
                        "slug": "K.-M.-A.-Chai",
                        "structuredName": {
                            "firstName": "Kian",
                            "lastName": "Chai",
                            "middleNames": [
                                "Ming",
                                "Adam"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. M. A. Chai"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145715698"
                        ],
                        "name": "Christopher K. I. Williams",
                        "slug": "Christopher-K.-I.-Williams",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Williams",
                            "middleNames": [
                                "K.",
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christopher K. I. Williams"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1702279"
                        ],
                        "name": "Stefan Klanke",
                        "slug": "Stefan-Klanke",
                        "structuredName": {
                            "firstName": "Stefan",
                            "lastName": "Klanke",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Stefan Klanke"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144575699"
                        ],
                        "name": "S. Vijayakumar",
                        "slug": "S.-Vijayakumar",
                        "structuredName": {
                            "firstName": "Sethu",
                            "lastName": "Vijayakumar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Vijayakumar"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 10603157,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "af7ee0ca9c48a799ee2f9c4fb2b3f52a6f5d8c0c",
            "isKey": false,
            "numCitedBy": 99,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "The inverse dynamics problem for a robotic manipulator is to compute the torques needed at the joints to drive it along a given trajectory; it is beneficial to be able to learn this function for adaptive control. A robotic manipulator will often need to be controlled while holding different loads in its end effector, giving rise to a multi-task learning problem. By placing independent Gaussian process priors over the latent functions of the inverse dynamics, we obtain a multi-task Gaussian process prior for handling multiple loads, where the inter-task similarity depends on the underlying inertial parameters. Experiments demonstrate that this multi-task formulation is effective in sharing information among the various loads, and generally improves performance over either learning only on single tasks or pooling the data over all tasks."
            },
            "slug": "Multi-task-Gaussian-Process-Learning-of-Robot-Chai-Williams",
            "title": {
                "fragments": [],
                "text": "Multi-task Gaussian Process Learning of Robot Inverse Dynamics"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "A multi-task Gaussian process prior for handling multiple loads, where the inter-task similarity depends on the underlying inertial parameters, and generally improves performance over either learning only on single tasks or pooling the data over all tasks."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2118892339"
                        ],
                        "name": "Qi Liu",
                        "slug": "Qi-Liu",
                        "structuredName": {
                            "firstName": "Qi",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Qi Liu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144217477"
                        ],
                        "name": "Qian Xu",
                        "slug": "Qian-Xu",
                        "structuredName": {
                            "firstName": "Qian",
                            "lastName": "Xu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Qian Xu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3113725"
                        ],
                        "name": "V. Zheng",
                        "slug": "V.-Zheng",
                        "structuredName": {
                            "firstName": "Vincent",
                            "lastName": "Zheng",
                            "middleNames": [
                                "Wenchen"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Zheng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48419278"
                        ],
                        "name": "H. Xue",
                        "slug": "H.-Xue",
                        "structuredName": {
                            "firstName": "Hong",
                            "lastName": "Xue",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Xue"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144572864"
                        ],
                        "name": "Z. Cao",
                        "slug": "Z.-Cao",
                        "structuredName": {
                            "firstName": "Zhi-Wei",
                            "lastName": "Cao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Z. Cao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152290618"
                        ],
                        "name": "Qiang Yang",
                        "slug": "Qiang-Yang",
                        "structuredName": {
                            "firstName": "Qiang",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Qiang Yang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 15417560,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "13ff7fc7241d33a9e65a4dd6a6f40ec498e37959",
            "isKey": false,
            "numCitedBy": 77,
            "numCiting": 70,
            "paperAbstract": {
                "fragments": [],
                "text": "BackgroundGene silencing using exogenous small interfering RNAs (siRNAs) is now a widespread molecular tool for gene functional study and new-drug target identification. The key mechanism in this technique is to design efficient siRNAs that incorporated into the RNA-induced silencing complexes (RISC) to bind and interact with the mRNA targets to repress their translations to proteins. Although considerable progress has been made in the computational analysis of siRNA binding efficacy, few joint analysis of different RNAi experiments conducted under different experimental scenarios has been done in research so far, while the joint analysis is an important issue in cross-platform siRNA efficacy prediction. A collective analysis of RNAi mechanisms for different datasets and experimental conditions can often provide new clues on the design of potent siRNAs.ResultsAn elegant multi-task learning paradigm for cross-platform siRNA efficacy prediction is proposed. Experimental studies were performed on a large dataset of siRNA sequences which encompass several RNAi experiments recently conducted by different research groups. By using our multi-task learning method, the synergy among different experiments is exploited and an efficient multi-task predictor for siRNA efficacy prediction is obtained. The 19 most popular biological features for siRNA according to their jointly importance in multi-task learning were ranked. Furthermore, the hypothesis is validated out that the siRNA binding efficacy on different messenger RNAs(mRNAs) have different conditional distribution, thus the multi-task learning can be conducted by viewing tasks at an \"mRNA\"-level rather than at the \"experiment\"-level. Such distribution diversity derived from siRNAs bound to different mRNAs help indicate that the properties of target mRNA have important implications on the siRNA binding efficacy.ConclusionsThe knowledge gained from our study provides useful insights on how to analyze various cross-platform RNAi data for uncovering of their complex mechanism."
            },
            "slug": "Multi-task-learning-for-cross-platform-siRNA-an-Liu-Xu",
            "title": {
                "fragments": [],
                "text": "Multi-task learning for cross-platform siRNA efficacy prediction: an in-silico study"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "The hypothesis is validated out that the siRNA binding efficacy on different messenger RNAs(mRNAs) have different conditional distribution, thus the multi-task learning can be conducted by viewing tasks at an \"mRNA\"-level rather than at the \"experiment\"-level, and this provides useful insights on how to analyze various cross-platform RNAi data for uncovering of their complex mechanism."
            },
            "venue": {
                "fragments": [],
                "text": "BMC Bioinformatics"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2056598734"
                        ],
                        "name": "Xiao Chu",
                        "slug": "Xiao-Chu",
                        "structuredName": {
                            "firstName": "Xiao",
                            "lastName": "Chu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xiao Chu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3001348"
                        ],
                        "name": "Wanli Ouyang",
                        "slug": "Wanli-Ouyang",
                        "structuredName": {
                            "firstName": "Wanli",
                            "lastName": "Ouyang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wanli Ouyang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2150081208"
                        ],
                        "name": "Wei Yang",
                        "slug": "Wei-Yang",
                        "structuredName": {
                            "firstName": "Wei",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wei Yang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31843833"
                        ],
                        "name": "Xiaogang Wang",
                        "slug": "Xiaogang-Wang",
                        "structuredName": {
                            "firstName": "Xiaogang",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xiaogang Wang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 337,
                                "start": 333
                            }
                        ],
                        "text": "Applications of MTL based on non-facial images include object categorization [86], image segmentation [89,90], identifying brain imaging predictors [91], saliency detection [92], action recognition [93], scene classification [94], multi-attribute prediction [95], multi-camera person re-identification [96], and immediacy prediction [97]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 4277597,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1e3df3ca8feab0b36fd293fe689f93bb2aaac591",
            "isKey": false,
            "numCitedBy": 47,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we propose to predict immediacy for interacting persons from still images. A complete immediacy set includes interactions, relative distance, body leaning direction and standing orientation. These measures are found to be related to the attitude, social relationship, social interaction, action, nationality, and religion of the communicators. A large-scale dataset with 10,000 images is constructed, in which all the immediacy measures and the human poses are annotated. We propose a rich set of immediacy representations that help to predict immediacy from imperfect 1-person and 2-person pose estimation results. A multi-task deep recurrent neural network is constructed to take the proposed rich immediacy representation as input and learn the complex relationship among immediacy predictions multiple steps of refinement. The effectiveness of the proposed approach is proved through extensive experiments on the large scale dataset."
            },
            "slug": "Multi-task-Recurrent-Neural-Network-for-Immediacy-Chu-Ouyang",
            "title": {
                "fragments": [],
                "text": "Multi-task Recurrent Neural Network for Immediacy Prediction"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "A rich set of immediacy representations are proposed that help to predict immediacy from imperfect 1-person and 2- person pose estimation results and a multi-task deep recurrent neural network is constructed to learn the complex relationship among immediacy predictions multiple steps of refinement."
            },
            "venue": {
                "fragments": [],
                "text": "2015 IEEE International Conference on Computer Vision (ICCV)"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2397264"
                        ],
                        "name": "Fangzhao Wu",
                        "slug": "Fangzhao-Wu",
                        "structuredName": {
                            "firstName": "Fangzhao",
                            "lastName": "Wu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Fangzhao Wu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1731776"
                        ],
                        "name": "Yongfeng Huang",
                        "slug": "Yongfeng-Huang",
                        "structuredName": {
                            "firstName": "Yongfeng",
                            "lastName": "Huang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yongfeng Huang"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 184,
                                "start": 179
                            }
                        ],
                        "text": "part-of-speech tagging, chunking, named entity recognition, semantic role labeling, language modeling and semantically related words) [116], multi-domain sentiment classification [117], multidomain dialog state tracking [21], machine translation [118], syntactic parsing [118], and microblog analysis [119,120]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2286247,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3376343c71747852803ca50ff2dd5fc8a314abe4",
            "isKey": false,
            "numCitedBy": 42,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "Sentiment classification is a hot research topic in both industrial and academic fields. The mainstream sentiment classification methods are based on machine learning and treat sentiment classification as a text classification problem. However, sentiment classification is widely recognized as a highly domain-dependent task. The sentiment classifier trained in one domain may not perform well in another domain. A simple solution to this problem is training a domain-specific sentiment classifier for each domain. However, it is difficult to label enough data for every domain since they are in a large quantity. In addition, this method omits the sentiment information in other domains. In this paper, we propose to train sentiment classifiers for multiple domains in a collaborative way based on multi-task learning. Specifically, we decompose the sentiment classifier in each domain into two components, a general one and a domain-specific one. The general sentiment classifier can capture the global sentiment information and is trained across various domains to obtain better generalization ability. The domain-specific sentiment classifier is trained using the labeled data in one domain to capture the domain-specific sentiment information. In addition, we explore two kinds of relations between domains, one based on textual content and the other one based on sentiment word distribution. We build a domain similarity graph using domain relations and encode it into our approach as regularization over the domain-specific sentiment classifiers. Besides, we incorporate the sentiment knowledge extracted from sentiment lexicons to help train the general sentiment classifier more accurately. Moreover, we introduce an accelerated optimization algorithm to train the sentiment classifiers efficiently. Experimental results on two benchmark sentiment datasets show that our method can outperform baseline methods significantly and consistently."
            },
            "slug": "Collaborative-Multi-domain-Sentiment-Classification-Wu-Huang",
            "title": {
                "fragments": [],
                "text": "Collaborative Multi-domain Sentiment Classification"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "This paper proposes to train sentiment classifiers for multiple domains in a collaborative way based on multi-task learning and decomposes the sentiment classifier in each domain into two components, a general one and a domain-specific one."
            },
            "venue": {
                "fragments": [],
                "text": "2015 IEEE International Conference on Data Mining"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3334541"
                        ],
                        "name": "N. Mrksic",
                        "slug": "N.-Mrksic",
                        "structuredName": {
                            "firstName": "Nikola",
                            "lastName": "Mrksic",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Mrksic"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8311581"
                        ],
                        "name": "Diarmuid \u00d3 S\u00e9aghdha",
                        "slug": "Diarmuid-\u00d3-S\u00e9aghdha",
                        "structuredName": {
                            "firstName": "Diarmuid",
                            "lastName": "S\u00e9aghdha",
                            "middleNames": [
                                "\u00d3"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Diarmuid \u00d3 S\u00e9aghdha"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145462220"
                        ],
                        "name": "Blaise Thomson",
                        "slug": "Blaise-Thomson",
                        "structuredName": {
                            "firstName": "Blaise",
                            "lastName": "Thomson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Blaise Thomson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1768624"
                        ],
                        "name": "Milica Gasic",
                        "slug": "Milica-Gasic",
                        "structuredName": {
                            "firstName": "Milica",
                            "lastName": "Gasic",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Milica Gasic"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2131709"
                        ],
                        "name": "Pei-hao Su",
                        "slug": "Pei-hao-Su",
                        "structuredName": {
                            "firstName": "Pei-hao",
                            "lastName": "Su",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Pei-hao Su"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "92480907"
                        ],
                        "name": "David Vandyke",
                        "slug": "David-Vandyke",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Vandyke",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David Vandyke"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144256365"
                        ],
                        "name": "Tsung-Hsien Wen",
                        "slug": "Tsung-Hsien-Wen",
                        "structuredName": {
                            "firstName": "Tsung-Hsien",
                            "lastName": "Wen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tsung-Hsien Wen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145259603"
                        ],
                        "name": "S. Young",
                        "slug": "S.-Young",
                        "structuredName": {
                            "firstName": "Steve",
                            "lastName": "Young",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Young"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7597872,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3499f7a92d6b0fd6fb5993f2e663c3413fb9f119",
            "isKey": false,
            "numCitedBy": 166,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "Dialog state tracking is a key component of many modern dialog systems, most of which are designed with a single, well-defined domain in mind. This paper shows that dialog data drawn from different dialog domains can be used to train a general belief tracking model which can operate across all of these domains, exhibiting superior performance to each of the domain-specific models. We propose a training procedure which uses out-of-domain data to initialise belief tracking models for entirely new domains. This procedure leads to improvements in belief tracking performance regardless of the amount of in-domain data available for training the model."
            },
            "slug": "Multi-domain-Dialog-State-Tracking-using-Recurrent-Mrksic-S\u00e9aghdha",
            "title": {
                "fragments": [],
                "text": "Multi-domain Dialog State Tracking using Recurrent Neural Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This paper shows that dialog data drawn from different dialog domains can be used to train a general belief tracking model which can operate across all of these domains, exhibiting superior performance to each of the domain-specific models."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143629707"
                        ],
                        "name": "Amr Ahmed",
                        "slug": "Amr-Ahmed",
                        "structuredName": {
                            "firstName": "Amr",
                            "lastName": "Ahmed",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Amr Ahmed"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2512591"
                        ],
                        "name": "Abhimanyu Das",
                        "slug": "Abhimanyu-Das",
                        "structuredName": {
                            "firstName": "Abhimanyu",
                            "lastName": "Das",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Abhimanyu Das"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46234526"
                        ],
                        "name": "Alex Smola",
                        "slug": "Alex-Smola",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Smola",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alex Smola"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 232,
                                "start": 227
                            }
                        ],
                        "text": "Web applications based on MTL include learning to rank in web searches [121], web search ranking [122], multi-domain collaborative filtering [123], behavioral targeting [124], and conversion maximization in display advertising [125]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 12696223,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b76d59223e4ba58495bbec2a459d9bcf53ef41a6",
            "isKey": false,
            "numCitedBy": 38,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "Many estimation tasks come in groups and hierarchies of related problems. In this paper we propose a hierarchical model and a scalable algorithm to perform inference for multitask learning. It infers task correlation and subtask structure in a joint sparse setting. Implementation is achieved by a distributed subgradient oracle and the successive application of prox-operators pertaining to groups and subgroups of variables. We apply this algorithm to conversion optimization in display advertising. Experimental results on over 1TB data for up to 1 billion observations and 1 million attributes show that the algorithm provides significantly better prediction accuracy while simultaneously beingefficiently scalable by distributed parameter synchronization."
            },
            "slug": "Scalable-hierarchical-multitask-learning-algorithms-Ahmed-Das",
            "title": {
                "fragments": [],
                "text": "Scalable hierarchical multitask learning algorithms for conversion optimization in display advertising"
            },
            "tldr": {
                "abstractSimilarityScore": 58,
                "text": "A hierarchical model and a scalable algorithm to perform inference for multitask learning that infers task correlation and subtask structure in a joint sparse setting and is applied to conversion optimization in display advertising."
            },
            "venue": {
                "fragments": [],
                "text": "WSDM"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1748853"
                        ],
                        "name": "Kriti Puniyani",
                        "slug": "Kriti-Puniyani",
                        "structuredName": {
                            "firstName": "Kriti",
                            "lastName": "Puniyani",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kriti Puniyani"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1692950"
                        ],
                        "name": "Seyoung Kim",
                        "slug": "Seyoung-Kim",
                        "structuredName": {
                            "firstName": "Seyoung",
                            "lastName": "Kim",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Seyoung Kim"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143977260"
                        ],
                        "name": "E. Xing",
                        "slug": "E.-Xing",
                        "structuredName": {
                            "firstName": "Eric",
                            "lastName": "Xing",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Xing"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 17,
                                "start": 12
                            }
                        ],
                        "text": "populations [104], construction of personalized brain\u2013computer interfaces [105], MHC-I binding prediction [106], splice-site prediction [106], protein subcellular location prediction [107], Alzheimer\u2019s disease assessment scale cognitive subscale [108], prediction of cognitive outcomes from neuroimaging measures in Alzheimer\u2019s disease [109], identification of longitudinal phenotypic markers for Alzheimer\u2019s disease progression prediction [110], prioritization of disease genes [111], biological image analysis based on natural images [20], survival analysis [112], and multiple genetic trait prediction [113]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1254593,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1d37069eac644a55dced0d900ae8b4040317a94f",
            "isKey": false,
            "numCitedBy": 71,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "Motivation: Population heterogeneity through admixing of different founder populations can produce spurious associations in genome- wide association studies that are linked to the population structure rather than the phenotype. Since samples from the same population generally co-evolve, different populations may or may not share the same genetic underpinnings for the seemingly common phenotype. Our goal is to develop a unified framework for detecting causal genetic markers through a joint association analysis of multiple populations. Results: Based on a multi-task regression principle, we present a multi-population group lasso algorithm using L1/L2-regularized regression for joint association analysis of multiple populations that are stratified either via population survey or computational estimation. Our algorithm combines information from genetic markers across populations, to identify causal markers. It also implicitly accounts for correlations between the genetic markers, thus enabling better control over false positive rates. Joint analysis across populations enables the detection of weak associations common to all populations with greater power than in a separate analysis of each population. At the same time, the regression-based framework allows causal alleles that are unique to a subset of the populations to be correctly identified. We demonstrate the effectiveness of our method on HapMap-simulated and lactase persistence datasets, where we significantly outperform state of the art methods, with greater power for detecting weak associations and reduced spurious associations. Availability: Software will be available at http://www.sailing.cs.cmu.edu/ Contact: epxing@cs.cmu.edu"
            },
            "slug": "Multi-population-GWA-mapping-via-multi-task-Puniyani-Kim",
            "title": {
                "fragments": [],
                "text": "Multi-population GWA mapping via multi-task regularized regression"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "A multi-population group lasso algorithm using L1/L2-regularized regression for joint association analysis of multiple populations that are stratified either via population survey or computational estimation, which demonstrates the effectiveness of the method on HapMap-simulated and lactase persistence datasets."
            },
            "venue": {
                "fragments": [],
                "text": "Bioinform."
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2068120771"
                        ],
                        "name": "Qi An",
                        "slug": "Qi-An",
                        "structuredName": {
                            "firstName": "Qi",
                            "lastName": "An",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Qi An"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108714551"
                        ],
                        "name": "Chunping Wang",
                        "slug": "Chunping-Wang",
                        "structuredName": {
                            "firstName": "Chunping",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chunping Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1885380"
                        ],
                        "name": "Ivo D. Shterev",
                        "slug": "Ivo-D.-Shterev",
                        "structuredName": {
                            "firstName": "Ivo",
                            "lastName": "Shterev",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ivo D. Shterev"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2113761871"
                        ],
                        "name": "Eric Wang",
                        "slug": "Eric-Wang",
                        "structuredName": {
                            "firstName": "Eric",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Eric Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145006560"
                        ],
                        "name": "L. Carin",
                        "slug": "L.-Carin",
                        "structuredName": {
                            "firstName": "Lawrence",
                            "lastName": "Carin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Carin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39775017"
                        ],
                        "name": "D. Dunson",
                        "slug": "D.-Dunson",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Dunson",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Dunson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 109,
                                "start": 102
                            }
                        ],
                        "text": "Applications of MTL based on non-facial images include object categorization [86], image segmentation [89,90], identifying brain imaging predictors [91], saliency detection [92], action recognition [93], scene classification [94], multi-attribute prediction [95], multi-camera person re-identification [96], and immediacy prediction [97]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 14713434,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e9f04bf98e58ad3b1c50e61fd185fc1d10c4aa12",
            "isKey": false,
            "numCitedBy": 39,
            "numCiting": 45,
            "paperAbstract": {
                "fragments": [],
                "text": "The kernel stick-breaking process (KSBP) is employed to segment general imagery, imposing the condition that patches (small blocks of pixels) that are spatially proximate are more likely to be associated with the same cluster (segment). The number of clusters is not set a priori and is inferred from the hierarchical Bayesian model. Further, KSBP is integrated with a shared Dirichlet process prior to simultaneously model multiple images, inferring their inter-relationships. This latter application may be useful for sorting and learning relationships between multiple images. The Bayesian inference algorithm is based on a hybrid of variational Bayesian analysis and local sampling. In addition to providing details on the model and associated inference framework, example results are presented for several image-analysis problems."
            },
            "slug": "Hierarchical-kernel-stick-breaking-process-for-An-Wang",
            "title": {
                "fragments": [],
                "text": "Hierarchical kernel stick-breaking process for multi-task image analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 91,
                "text": "The kernel stick-breaking process is employed to segment general imagery, imposing the condition that patches that are spatially proximate are more likely to be associated with the same cluster (segment) and the number of clusters is not set a priori and is inferred from the hierarchical Bayesian model."
            },
            "venue": {
                "fragments": [],
                "text": "ICML '08"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2864754"
                        ],
                        "name": "J. Ghosn",
                        "slug": "J.-Ghosn",
                        "structuredName": {
                            "firstName": "Joumana",
                            "lastName": "Ghosn",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Ghosn"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751762"
                        ],
                        "name": "Yoshua Bengio",
                        "slug": "Yoshua-Bengio",
                        "structuredName": {
                            "firstName": "Yoshua",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoshua Bengio"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 74,
                                "start": 69
                            }
                        ],
                        "text": "Applications of MTL in ubiquitous computing include stock prediction [126], multi-device localization [127], the inverse dynamics problem for robotics [128,129], estimation of travel costs on road networks [130], travel-time prediction on road networks [131], and traffic-sign recognition [132]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5501409,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e5d26994a2ed3b7657dbefde26fc7eb929d62b16",
            "isKey": false,
            "numCitedBy": 81,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "Artificial Neural Networks can be used to predict future returns of stocks in order to take financial decisions. Should one build a separate network for each stock or share the same network for all the stocks? In this paper we also explore other alternatives, in which some layers are shared and others are not shared. When the prediction of future returns for different stocks are viewed as different tasks, sharing some parameters across stocks is a form of multi-task learning. In a series of experiments with Canadian stocks, we obtain yearly returns that are more than 14% above various benchmarks."
            },
            "slug": "Multi-Task-Learning-for-Stock-Selection-Ghosn-Bengio",
            "title": {
                "fragments": [],
                "text": "Multi-Task Learning for Stock Selection"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This paper obtains yearly returns that are more than 14% above various benchmarks with Canadian stocks and explores other alternatives, in which some layers are shared and others are not shared."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1704699"
                        ],
                        "name": "M. Pontil",
                        "slug": "M.-Pontil",
                        "structuredName": {
                            "firstName": "Massimiliano",
                            "lastName": "Pontil",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Pontil"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144009046"
                        ],
                        "name": "Andreas Maurer",
                        "slug": "Andreas-Maurer",
                        "structuredName": {
                            "firstName": "Andreas",
                            "lastName": "Maurer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andreas Maurer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 602348,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "472aa8f66bb5709a772954d2f26992a53c591b76",
            "isKey": false,
            "numCitedBy": 99,
            "numCiting": 44,
            "paperAbstract": {
                "fragments": [],
                "text": "Trace norm regularization is a popular method of multitask learning. We give excess risk bounds with explicit dependence on the number of tasks, the number of examples per task and properties of the data distribution. The bounds are independent of the dimension of the input space, which may be infinite as in the case of reproducing kernel Hilbert spaces. A byproduct of the proof are bounds on the expected norm of sums of random positive semidefinite matrices with subexponential moments."
            },
            "slug": "Excess-risk-bounds-for-multitask-learning-with-norm-Pontil-Maurer",
            "title": {
                "fragments": [],
                "text": "Excess risk bounds for multitask learning with trace norm regularization"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "A byproduct of the proof are bounds on the expected norm of sums of random positive semidefinite matrices with subexponential moments."
            },
            "venue": {
                "fragments": [],
                "text": "COLT"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144009046"
                        ],
                        "name": "Andreas Maurer",
                        "slug": "Andreas-Maurer",
                        "structuredName": {
                            "firstName": "Andreas",
                            "lastName": "Maurer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andreas Maurer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 130,
                                "start": 125
                            }
                        ],
                        "text": "[7,134] for the feature transform approach, [135] for the feature selection approach, [24,135\u2013138] for the lowrank approach, [136] for the task-relation learning approach, and [138] for the dirty approach."
                    },
                    "intents": []
                }
            ],
            "corpusId": 7983965,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "2d50bcfe2b87d667222a88c4a908cc6827c3cefe",
            "isKey": false,
            "numCitedBy": 65,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "Bounds are given for the empirical and expected Rademacher complexity of classes of linear transformations from a Hilbert space H to a finite dimensional space. The results imply generalization guarantees for graph regularization and multi-task subspace learning."
            },
            "slug": "The-Rademacher-Complexity-of-Linear-Transformation-Maurer",
            "title": {
                "fragments": [],
                "text": "The Rademacher Complexity of Linear Transformation Classes"
            },
            "tldr": {
                "abstractSimilarityScore": 95,
                "text": "Bounds are given for the empirical and expected Rademacher complexity of classes of linear transformations from a Hilbert space H to a finite dimensional space and imply generalization guarantees for graph regularization and multi-task subspace learning."
            },
            "venue": {
                "fragments": [],
                "text": "COLT"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108513551"
                        ],
                        "name": "Jianhui Chen",
                        "slug": "Jianhui-Chen",
                        "structuredName": {
                            "firstName": "Jianhui",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jianhui Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40478933"
                        ],
                        "name": "Ji Liu",
                        "slug": "Ji-Liu",
                        "structuredName": {
                            "firstName": "Ji",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ji Liu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144030870"
                        ],
                        "name": "Jieping Ye",
                        "slug": "Jieping-Ye",
                        "structuredName": {
                            "firstName": "Jieping",
                            "lastName": "Ye",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jieping Ye"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 31,
                                "start": 24
                            }
                        ],
                        "text": "The choices of g (U) in [54,55] enforce U to be low-rank via the trace norm as the regularizer and constraint, respectively."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[54] g (U) = { 0, if \u2016U\u2016S(1) \u2264 \u03bb1 +\u221e, otherwise."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 53,
                                "start": 46
                            }
                        ],
                        "text": "For V, h(V) makes it sparse via the 1 norm in [53,54] and column-sparse via the 2,1 norm in [55,56], while in [57], h(V) penalizes the complexity of V via the squared Frobenius norm."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6395450,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "08fc246f446d1d1920cc9fbca8115ebe4ab167dd",
            "isKey": false,
            "numCitedBy": 140,
            "numCiting": 76,
            "paperAbstract": {
                "fragments": [],
                "text": "We consider the problem of learning incoherent sparse and low-rank patterns from multiple tasks. Our approach is based on a linear multitask learning formulation, in which the sparse and low-rank patterns are induced by a cardinality regularization term and a low-rank constraint, respectively. This formulation is nonconvex; we convert it into its convex surrogate, which can be routinely solved via semidefinite programming for small-size problems. We propose employing the general projected gradient scheme to efficiently solve such a convex surrogate; however, in the optimization formulation, the objective function is nondifferentiable and the feasible domain is nontrivial. We present the procedures for computing the projected gradient and ensuring the global convergence of the projected gradient scheme. The computation of the projected gradient involves a constrained optimization problem; we show that the optimal solution to such a problem can be obtained via solving an unconstrained optimization subproblem and a Euclidean projection subproblem. We also present two projected gradient algorithms and analyze their rates of convergence in detail. In addition, we illustrate the use of the presented projected gradient algorithms for the proposed multitask learning formulation using the least squares loss. Experimental results on a collection of real-world data sets demonstrate the effectiveness of the proposed multitask learning formulation and the efficiency of the proposed projected gradient algorithms."
            },
            "slug": "Learning-Incoherent-Sparse-and-Low-Rank-Patterns-Chen-Liu",
            "title": {
                "fragments": [],
                "text": "Learning Incoherent Sparse and Low-Rank Patterns from Multiple Tasks"
            },
            "tldr": {
                "abstractSimilarityScore": 64,
                "text": "This work considers the problem of learning incoherent sparse and low-rank patterns from multiple tasks and proposes employing the general projected gradient scheme to efficiently solve such a convex surrogate."
            },
            "venue": {
                "fragments": [],
                "text": "TKDD"
            },
            "year": 2012
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 79,
                                "start": 74
                            }
                        ],
                        "text": "populations [104], construction of personalized brain\u2013computer interfaces [105], MHC-I binding prediction [106], splice-site prediction [106], protein subcellular location prediction [107], Alzheimer\u2019s disease assessment scale cognitive subscale [108], prediction of cognitive outcomes from neuroimaging measures in Alzheimer\u2019s disease [109], identification of longitudinal phenotypic markers for Alzheimer\u2019s disease progression prediction [110], prioritization of disease genes [111], biological image analysis based on natural images [20], survival analysis [112], and multiple genetic trait prediction [113]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Multitask learning for braincomputer interfaces"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 13th International Conference on Artificial Intelligence and Statistics"
            },
            "year": 2010
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Robust visual tracking via structured multitask sparse learning"
            },
            "venue": {
                "fragments": [],
                "text": "Int J Comput Vis"
            },
            "year": 2013
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 24,
                                "start": 17
                            }
                        ],
                        "text": "Specifically, in [74,75], where different tasks are assumed to have a common goal, a global loss function, a combination of individual losses on each task, measures the relations between tasks, and by using absolute norms for the global loss function, several online MTL algorithms are proposed."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Online learning ofmultiple taskswith a shared loss"
            },
            "venue": {
                "fragments": [],
                "text": "J Mach Learn Res"
            },
            "year": 2007
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 294,
                                "start": 289
                            }
                        ],
                        "text": "Applications of MTL in ubiquitous computing include stock prediction [126], multi-device localization [127], the inverse dynamics problem for robotics [128,129], estimation of travel costs on road networks [130], travel-time prediction on road networks [131], and traffic-sign recognition [132]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Traffic sign recognition via multi-modal treestructure embedded multi-task learning"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans Intell Transport Syst 2017;"
            },
            "year": 2017
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 45,
                                "start": 42
                            }
                        ],
                        "text": "In these cases, multi-task learning (MTL) [1] is a good recipe by exploiting useful information fromother related learning tasks to help alleviate this data sparsity problem."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 72,
                                "start": 69
                            }
                        ],
                        "text": "A representative model is the multi-layer feedforward neural network [1] and an example of a multi-layer feedforward neural network is shown in Fig."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Multitask learning.Mach Learn"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 160,
                                "start": 151
                            }
                        ],
                        "text": "Applications of MTL in ubiquitous computing include stock prediction [126], multi-device localization [127], the inverse dynamics problem for robotics [128,129], estimation of travel costs on road networks [130], travel-time prediction on road networks [131], and traffic-sign recognition [132]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Learning inverse dynamics by Gaussian process regression under themulti-task learning framework. In: The Path to Autonomous Robots"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2009
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 134,
                                "start": 129
                            }
                        ],
                        "text": "Unlike multi-layer feedforward neural networks, which are based on neural networks, the multitask feature learning (MTFL) method [5,6] and the multi-task sparse coding (MTSC) method [7] are formulated under the regularization framework by first transforming data instances as x\u0302j = Uxj and then learning a linear function as f i (xj ) = (ai )T x\u0302j + bi ."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Convexmulti-task feature learning.Mach Learn"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2008
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 54,
                                "start": 48
                            }
                        ],
                        "text": "These twomethods extend theMTFLand MTRL methods [5,44], two models in the MTSL setting, to the clustering scenario and the formulations in the proposed two multi-task-clustering methods are almost identical to those in the MTFL and MTRL methods, with the only difference being"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 197,
                                "start": 194
                            }
                        ],
                        "text": "In [72], the value functions in different tasks are assumed to share sparse parameters and it applies the multi-task feature selection method with the 2,1 regularization [8] and the MTFL method [5] to learn all the value functions simultaneously."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 134,
                                "start": 129
                            }
                        ],
                        "text": "Unlike multi-layer feedforward neural networks, which are based on neural networks, the multitask feature learning (MTFL) method [5,6] and the multi-task sparse coding (MTSC) method [7] are formulated under the regularization framework by first transforming data instances as x\u0302j = Uxj and then learning a linear function as f i (xj ) = (ai )T x\u0302j + bi ."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "M.Multi-task feature learning"
            },
            "venue": {
                "fragments": [],
                "text": "In:Advances in Neural Information Processing Systems"
            },
            "year": 2006
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 62,
            "methodology": 49
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 144,
        "totalPages": 15
    },
    "page_url": "https://www.semanticscholar.org/paper/An-Overview-of-Multi-task-Learning-Zhang-Yang/cd49acefc8d51e324aa562e5337e1c2aff067053?sort=total-citations"
}