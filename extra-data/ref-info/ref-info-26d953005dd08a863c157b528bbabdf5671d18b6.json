{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2157745208"
                        ],
                        "name": "Jung-Fu Cheng",
                        "slug": "Jung-Fu-Cheng",
                        "structuredName": {
                            "firstName": "Jung-Fu",
                            "lastName": "Cheng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jung-Fu Cheng"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "7, which is a loopy Bayesian network appropriate for the turbo decoding problem.9"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 67443274,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bbb60ad08cfc228ee546846c2b164e0695974148",
            "isKey": false,
            "numCitedBy": 25,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Though coding theory suggests long error correcting codes chosen at random perform close to the optimum, the problem of designing good codes has traditionally been attacked by developing codes with a lot of structure, which lends itself to feasible decoders. The challenge to find practical decoders for long random codes has not been seriously considered until the recent introduction of turbo codes in 1993. This methodology of multi-stage iterative decoding with exchange of soft information, applied to codes with pseudo-random structure, has provided a whole new approach to construct good codes and to decode them with low complexity. This thesis examines the theoretical ground as well as the design and implementation details of these iterative decoding techniques. The methodology is first applied to parallel concatenated unit-memory convolutional codes and generalized concatenated convolutional codes to demonstrate its power and the general design principle. We then show that, by representing these coding systems with appropriate Bayesian belief networks, all the ad hoc algorithms can be derived from a general statistical inference belief propagation algorithm. A class of new binary codes based on low-density generator matrices is proposed to eliminate the arbitrariness and unnecessary constraints in turbo coding we have recognized from this Bayesian network viewpoint. Contrary to the turbo decoding paradigm where sequential processing is accomplished by very powerful central units, the decoding algorithm for the new code is highly parallel and distributive. We also apply these codes to M-ary modulations using multilevel coding techniques to achieve higher spectral efficiency. In all cases, we have constructed systems with flexible error protection capability and performance within 1$\\sim$dB of the channel capacity."
            },
            "slug": "Iterative-decoding-Cheng",
            "title": {
                "fragments": [],
                "text": "Iterative decoding"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A class of new binary codes based on low-density generator matrices is proposed to eliminate the arbitrariness and unnecessary constraints in turbo coding, and all the ad hoc algorithms can be derived from a general statistical inference belief propagation algorithm."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2157745208"
                        ],
                        "name": "Jung-Fu Cheng",
                        "slug": "Jung-Fu-Cheng",
                        "structuredName": {
                            "firstName": "Jung-Fu",
                            "lastName": "Cheng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jung-Fu Cheng"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "7, which is a loopy Bayesian network appropriate for the turbo decoding problem.9"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 118564459,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c7219fb888c7e4587b106c104e467862debd6c70",
            "isKey": false,
            "numCitedBy": 3,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "The methodology of multi-stage iterative decoding with exchange of soft information has previously been applied to a wide range of error-controlling codes with remarkable success, including parallel/serial concatenated convolutional/block codes (Berrou et al., 1993) and generalized concatenated convolutional codes (Cheng). A theoretical explanation of this decoding mechanism has been proposed (MacKay et al.) via the belief propagation algorithm (BPA) (Pearl 1988). It is shown that, by representing a turbo code with a Bayesian belief network, the application of BPA directly leads to the turbo decoding algorithm. In fact, it is argued that the decoding algorithms for all the aforementioned variations of the turbo coding construction as well as a wide range of low-density parity check codes can be explained by this principle. The author goes on to discuss low density generator matrix codes."
            },
            "slug": "On-the-construction-of-efficient-multilevel-coded-Cheng",
            "title": {
                "fragments": [],
                "text": "On the construction of efficient multilevel coded modulations"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "It is argued that the decoding algorithms for all the aforementioned variations of the turbo coding construction as well as a wide range of low-density parity check codes can be explained by this principle."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IEEE International Symposium on Information Theory"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153477694"
                        ],
                        "name": "P. Robertson",
                        "slug": "P.-Robertson",
                        "structuredName": {
                            "firstName": "Patrick",
                            "lastName": "Robertson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Robertson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 94,
                                "start": 90
                            }
                        ],
                        "text": "(This notation will also prove useful in Section V, where we shall use it to describe Pearl\u2019s algorithm\u2014see Table I, line 6.)"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 17339208,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6b2ab06f46cdab4a9abf7dd84172cedf29062bcc",
            "isKey": false,
            "numCitedBy": 326,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "A coding scheme (turbo codes) was proposed, that achieves almost reliable data communication at signal-to-noise ratios very close to the Shannon-limit. We show that the associated iterative decoder can be formulated in a simpler fashion by passing information from one decoder to the next using log-likelihood ratios as opposed to channel values that need to be normalized. Also no heuristically determined correction parameters are necessary for stable decoding. In addition, we can reduce the average number of iterations needed for the same BER performance by determining when further iterations achieve no more benefit. Furthermore, it seems that the trellis-termination problem appears non-trivial and we give a pragmatic suboptimal solution. We investigate different block sizes and also a hybrid scheme that performs extremely well with less computations. A drawback of the codes has been discovered: the BER curves show a flattening at higher signal-to-noise ratios, this is due to the small minimum distance of the whole code. By analyzing the interleaver used in the encoder we can calculate approximations to the BER at high SNRs. Finally, by careful interleaver manipulation the minimum distance of the code can be increased and the error-coefficient for the remaining small distance events can be further reduced. Furthermore, we have investigated the influence of the interleaver length on the SNR needed to achieve a certain BER. Simulations confirm both the analytical approximation to the BER as well as the method for interleaver design which yields a marked improvement at higher SNR."
            },
            "slug": "Illuminating-the-structure-of-code-and-decoder-of-Robertson",
            "title": {
                "fragments": [],
                "text": "Illuminating the structure of code and decoder of parallel concatenated recursive systematic (turbo) codes"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "It is shown that the associated iterative decoder can be formulated in a simpler fashion by passing information from one decoder to the next using log-likelihood ratios as opposed to channel values that need to be normalized for stable decoding."
            },
            "venue": {
                "fragments": [],
                "text": "1994 IEEE GLOBECOM. Communications: The Global Bridge"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1889982"
                        ],
                        "name": "F. Kschischang",
                        "slug": "F.-Kschischang",
                        "structuredName": {
                            "firstName": "Frank",
                            "lastName": "Kschischang",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Kschischang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1749650"
                        ],
                        "name": "B. Frey",
                        "slug": "B.-Frey",
                        "structuredName": {
                            "firstName": "Brendan",
                            "lastName": "Frey",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Frey"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6522238,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bbd45449e1cdadbf1f0c06a9510b5ac247cb70b9",
            "isKey": false,
            "numCitedBy": 425,
            "numCiting": 45,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a unified graphical model framework for describing compound codes and deriving iterative decoding algorithms. After reviewing a variety of graphical models (Markov random fields, Tanner graphs, and Bayesian networks), we derive a general distributed marginalization algorithm for functions described by factor graphs. From this general algorithm, Pearl's (1986) belief propagation algorithm is easily derived as a special case. We point out that iterative decoding algorithms for various codes, including \"turbo decoding\" of parallel-concatenated convolutional codes, may be viewed as probability propagation in a graphical model of the code. We focus on Bayesian network descriptions of codes, which give a natural input/state/output/channel description of a code and channel, and we indicate how iterative decoders can be developed for parallel-and serially concatenated coding systems, product codes, and low-density parity-check codes."
            },
            "slug": "Iterative-Decoding-of-Compound-Codes-by-Probability-Kschischang-Frey",
            "title": {
                "fragments": [],
                "text": "Iterative Decoding of Compound Codes by Probability Propagation in Graphical Models"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "It is pointed out that iterative decoding algorithms for various codes, including \"turbo decoding\" of parallel-concatenated convolutional codes, may be viewed as probability propagation in a graphical model of the code."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE J. Sel. Areas Commun."
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3231485"
                        ],
                        "name": "S. Aji",
                        "slug": "S.-Aji",
                        "structuredName": {
                            "firstName": "Srinivas",
                            "lastName": "Aji",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Aji"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1723150"
                        ],
                        "name": "R. McEliece",
                        "slug": "R.-McEliece",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "McEliece",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. McEliece"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 134,
                                "start": 131
                            }
                        ],
                        "text": ") Finally, having noticed the similarity between the Gallager\u2013Tanner\u2013Wiberg algorithm and Pearl\u2019s algorithm, Aji and McEliece [1], [2], relying heavily on the post-Pearl improvements and simplifications in the BP algorithm [29], [30], [52], [58], [59] have devised a simple algorithm for distributing information on a graph that is a simultaneous generalization of both algorithms, and which includes several other classic algorithms, including Viterbi\u2019s algorithm (which is already subsumed by Wiberg\u2019s algorithm in \u201cmin-sum\u201d form) and the FFT."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 11355291,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0e8933300a20f3d799dc9f19e352967f41d8efcc",
            "isKey": false,
            "numCitedBy": 773,
            "numCiting": 43,
            "paperAbstract": {
                "fragments": [],
                "text": "We discuss a general message passing algorithm, which we call the generalized distributive law (GDL). The GDL is a synthesis of the work of many authors in information theory, digital communications, signal processing, statistics, and artificial intelligence. It includes as special cases the Baum-Welch algorithm, the fast Fourier transform (FFT) on any finite Abelian group, the Gallager-Tanner-Wiberg decoding algorithm, Viterbi's algorithm, the BCJR algorithm, Pearl's \"belief propagation\" algorithm, the Shafer-Shenoy probability propagation algorithm, and the turbo decoding algorithm. Although this algorithm is guaranteed to give exact answers only in certain cases (the \"junction tree\" condition), unfortunately not including the cases of GTW with cycles or turbo decoding, there is much experimental evidence, and a few theorems, suggesting that it often works approximately even when it is not supposed to."
            },
            "slug": "The-generalized-distributive-law-Aji-McEliece",
            "title": {
                "fragments": [],
                "text": "The generalized distributive law"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "Although this algorithm is guaranteed to give exact answers only in certain cases (the \"junction tree\" condition), unfortunately not including the cases of GTW with cycles or turbo decoding, there is much experimental evidence, and a few theorems, suggesting that it often works approximately even when it is not supposed to."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Inf. Theory"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2718299"
                        ],
                        "name": "N. Wiberg",
                        "slug": "N.-Wiberg",
                        "structuredName": {
                            "firstName": "Niclas",
                            "lastName": "Wiberg",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Wiberg"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 95,
                                "start": 91
                            }
                        ],
                        "text": "7 The forward\u2013backward algorithm has a long and convoluted history that merits the attention of a science historian."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 154,
                                "start": 150
                            }
                        ],
                        "text": "\u2026node (i.e., it has no parents), and since we are assuming that the prior distribution on the \u2019s is independent and uniform, by line 3 in Table II, the quantity is permanently set as follows:\npermanent (6.1)\nSince the \u2019s are \u201cdirect evidence\u201d nodes (i.e., evidence nodes which have only one parent),\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "7, which is a loopy Bayesian network appropriate for the turbo decoding problem.9"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 115168171,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "eb44d50bce92b4ce2c0ea53bd8ede95f628ee3cb",
            "isKey": true,
            "numCitedBy": 1007,
            "numCiting": 52,
            "paperAbstract": {
                "fragments": [],
                "text": "Iterative decoding techniques have become a viable alternative for constructing high performance coding systems. In particular, the recent success of turbo codes indicates that performance close to the Shannon limit may be achieved. In this thesis, it is showed that many iterative decoding algorithms are special cases of two generic algorithms, the min-sum and sum-product algorithms, which also include non-iterative algorithms such as Viterbi decoding. The min-sum and sum-product algorithms are developed and presented as generalized trellis algorithms, where the time axis of the trellis is replaced by an arbitrary graph, the \u201cTanner graph\u201d. With cycle-free Tanner graphs, the resulting decoding algorithms (e.g., Viterbi decoding) are maximum-likelihood but suffer from an exponentially increasing complexity. Iterative decoding occurs when the Tanner graph has cycles (e.g., turbo codes); the resulting algorithms are in general suboptimal, but significant complexity reductions are possible compared to the cycle-free case. Several performance estimates for iterative decoding are developed, including a generalization of the union bound used with Viterbi decoding and a characterization of errors that are uncorrectable after infinitely many decoding iterations."
            },
            "slug": "Codes-and-Decoding-on-General-Graphs-Wiberg",
            "title": {
                "fragments": [],
                "text": "Codes and Decoding on General Graphs"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "It is showed that many iterative decoding algorithms are special cases of two generic algorithms, the min-sum and sum-product algorithms, which also include non-iterative algorithms such as Viterbi decoding."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3637824"
                        ],
                        "name": "R. M. Tanner",
                        "slug": "R.-M.-Tanner",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Tanner",
                            "middleNames": [
                                "Michael"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. M. Tanner"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 27,
                                "start": 23
                            }
                        ],
                        "text": "Let us now verify the entries in Table III."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "7, which is a loopy Bayesian network appropriate for the turbo decoding problem.9"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 754232,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "157218bae792b6ef550dfd0f73e688d83d98b3d7",
            "isKey": false,
            "numCitedBy": 2971,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "A method is described for constructing long error-correcting codes from one or more shorter error-correcting codes, referred to as subcodes, and a bipartite graph. A graph is shown which specifies carefully chosen subsets of the digits of the new codes that must be codewords in one of the shorter subcodes. Lower bounds to the rate and the minimum distance of the new code are derived in terms of the parameters of the graph and the subeodes. Both the encoders and decoders proposed are shown to take advantage of the code's explicit decomposition into subcodes to decompose and simplify the associated computational processes. Bounds on the performance of two specific decoding algorithms are established, and the asymptotic growth of the complexity of decoding for two types of codes and decoders is analyzed. The proposed decoders are able to make effective use of probabilistic information supplied by the channel receiver, e.g., reliability information, without greatly increasing the number of computations required. It is shown that choosing a transmission order for the digits that is appropriate for the graph and the subcodes can give the code excellent burst-error correction abilities. The construction principles"
            },
            "slug": "A-recursive-approach-to-low-complexity-codes-Tanner",
            "title": {
                "fragments": [],
                "text": "A recursive approach to low complexity codes"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "It is shown that choosing a transmission order for the digits that is appropriate for the graph and the subcodes can give the code excellent burst-error correction abilities."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Inf. Theory"
            },
            "year": 1981
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46404423"
                        ],
                        "name": "J. Hagenauer",
                        "slug": "J.-Hagenauer",
                        "structuredName": {
                            "firstName": "Joachim",
                            "lastName": "Hagenauer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Hagenauer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2549634"
                        ],
                        "name": "E. Offer",
                        "slug": "E.-Offer",
                        "structuredName": {
                            "firstName": "Elke",
                            "lastName": "Offer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Offer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38915382"
                        ],
                        "name": "L. Papke",
                        "slug": "L.-Papke",
                        "structuredName": {
                            "firstName": "Lutz",
                            "lastName": "Papke",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Papke"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "7, which is a loopy Bayesian network appropriate for the turbo decoding problem.9"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14954804,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d7b350b6d469ac30c02f10aa4e62f77f79c0106b",
            "isKey": false,
            "numCitedBy": 2523,
            "numCiting": 44,
            "paperAbstract": {
                "fragments": [],
                "text": "Iterative decoding of two-dimensional systematic convolutional codes has been termed \"turbo\" (de)coding. Using log-likelihood algebra, we show that any decoder can be used which accepts soft inputs-including a priori values-and delivers soft outputs that can be split into three terms: the soft channel and a priori inputs, and the extrinsic value. The extrinsic value is used as an a priori value for the next iteration. Decoding algorithms in the log-likelihood domain are given not only for convolutional codes but also for any linear binary systematic block code. The iteration is controlled by a stop criterion derived from cross entropy, which results in a minimal number of iterations. Optimal and suboptimal decoders with reduced complexity are presented. Simulation results show that very simple component codes are sufficient, block codes are appropriate for high rates and convolutional codes for lower rates less than 2/3. Any combination of block and convolutional component codes is possible. Several interleaving techniques are described. At a bit error rate (BER) of 10/sup -4/ the performance is slightly above or around the bounds given by the cutoff rate for reasonably simple block/convolutional component codes, interleaver sizes less than 1000 and for three to six iterations."
            },
            "slug": "Iterative-decoding-of-binary-block-and-codes-Hagenauer-Offer",
            "title": {
                "fragments": [],
                "text": "Iterative decoding of binary block and convolutional codes"
            },
            "tldr": {
                "abstractSimilarityScore": 56,
                "text": "Using log-likelihood algebra, it is shown that any decoder can be used which accepts soft inputs-including a priori values-and delivers soft outputs that can be split into three terms: the soft channel and aPriori inputs, and the extrinsic value."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Inf. Theory"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2081245302"
                        ],
                        "name": "CodesDavid",
                        "slug": "CodesDavid",
                        "structuredName": {
                            "firstName": "",
                            "lastName": "CodesDavid",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "CodesDavid"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1410246062"
                        ],
                        "name": "C. J.",
                        "slug": "C.-J.",
                        "structuredName": {
                            "firstName": "C.",
                            "lastName": "J.",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. J."
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2087926458"
                        ],
                        "name": "MacKayCavendish",
                        "slug": "MacKayCavendish",
                        "structuredName": {
                            "firstName": "",
                            "lastName": "MacKayCavendish",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "MacKayCavendish"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "7, which is a loopy Bayesian network appropriate for the turbo decoding problem.9"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1478845,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "27b1996dc57dd04f22a4b3aee4d0364855db4675",
            "isKey": false,
            "numCitedBy": 347,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "We report the empirical performance of Gallager\u2019s low density parity check codes on Gaussian channels. We show that performance substantially better than that of standard convolutional and concatenated codes can be achieved; indeed the performance is almost as close to the Shannon limit as that of Turbo codes. A linear code may be described in terms of a generator matrix G or in terms of a parity check matrix H, which satisfies Hx = 0 for all codewords x. In 1962, Gallager reported work on binary codes defined in terms of low density parity check matrices (abbreviated \u2018GL codes\u2019) [5, 6]. The matrix H was defined in a non-systematic form; each column of H had a small weight (e.g., 3) and the weight per row was also uniform; the matrix H was constructed at random subject to these constraints. Gallager proved distance properties of these codes and described a probability-based decoding algorithm with promising empirical performance. However it appears that GL codes have been generally forgotten, the assumption perhaps being that concatenated codes [4] were superior for practical purposes (R.G. Gallager, personal communication). During our work on MN codes [8] we realised that it is possible to create \u2018good\u2019 codes from very sparse random matrices, and to decode them (even beyond their minimum distance) using approximate probabilistic algorithms. We eventually reinvented Gallager\u2019s decoding algorithm and GL codes. In this paper we report the empirical performance of these codes on Gaussian channels. We have proved theoretical properties of GL codes (essentially, that the channel coding theorem holds for them) elsewhere [9]. GL codes can also be defined over GF (q). We are currently implementing this generalization. We created sparse random parity check matrices in the following ways. Construction 1A. An M by N matrix (M rows, N columns) is created at random with weight per column t (e.g., t = 3), and weight per row as uniform as possible, and overlap between any two columns no greater than 1. (The weight of a column is the number of non-zero elements; the overlap between two columns is their inner product.)"
            },
            "slug": "Near-Shannon-Limit-Performance-of-Low-Density-Check-CodesDavid-C.",
            "title": {
                "fragments": [],
                "text": "Near Shannon Limit Performance of Low Density Parity Check Codes"
            },
            "tldr": {
                "abstractSimilarityScore": 52,
                "text": "It is shown that performance substantially better than that of standard convolutional and concatenated codes can be achieved; indeed the performance is almost as close to the Shannon limit as that of Turbo codes."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2718299"
                        ],
                        "name": "N. Wiberg",
                        "slug": "N.-Wiberg",
                        "structuredName": {
                            "firstName": "Niclas",
                            "lastName": "Wiberg",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Wiberg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143681410"
                        ],
                        "name": "H. Loeliger",
                        "slug": "H.-Loeliger",
                        "structuredName": {
                            "firstName": "Hans-Andrea",
                            "lastName": "Loeliger",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Loeliger"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7715701"
                        ],
                        "name": "R. Koetter",
                        "slug": "R.-Koetter",
                        "structuredName": {
                            "firstName": "Ralf",
                            "lastName": "Koetter",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Koetter"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 148,
                                "start": 144
                            }
                        ],
                        "text": "\u2026is permanently set as follows:\npermanent (6.1)\nSince the \u2019s are \u201cdirect evidence\u201d nodes (i.e., evidence nodes which have only one parent), by line 6 of Table II, the message that sends the is permanently set as follows:\npermanent (6.2)\nSince the nodes and are not evidence nodes, by line 6 of\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 36630145,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "848822f6c3446842730587cb4373a53f69e38720",
            "isKey": true,
            "numCitedBy": 350,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "Until recently, most known decoding procedures for error-correcting codes were based either on algebraically calculating the error pattern or on some sort of tree or trellis search. With the advent of turbo coding, a third decoding principle has finally had its breakthrough: iterative decoding. With respect to Viterbi decoding, a code is most naturally described by means of a trellis diagram. The main thesis of the present paper is that, with respect to iterative decoding, the natural way of describing a code is by means of a Tanner graph, which may be viewed as a generalized trellis. More precisely, it is the \"time axis\" of a trellis that is generalized to a Tanner graph."
            },
            "slug": "Codes-and-iterative-decoding-on-general-graphs-Wiberg-Loeliger",
            "title": {
                "fragments": [],
                "text": "Codes and iterative decoding on general graphs"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "The main thesis of the present paper is that, with respect to iterative decoding, the natural way of describing a code is by means of a Tanner graph, which may be viewed as a generalized trellis."
            },
            "venue": {
                "fragments": [],
                "text": "Eur. Trans. Telecommun."
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145500689"
                        ],
                        "name": "A. Viterbi",
                        "slug": "A.-Viterbi",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Viterbi",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Viterbi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 150,
                                "start": 146
                            }
                        ],
                        "text": "\u2026that the prior distribution on the \u2019s is independent and uniform, by line 3 in Table II, the quantity is permanently set as follows:\npermanent (6.1)\nSince the \u2019s are \u201cdirect evidence\u201d nodes (i.e., evidence nodes which have only one parent), by line 6 of Table II, the message that sends the is\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15843983,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "145c0b53514b02bdc3dadfb2e1cea124f2abd99b",
            "isKey": true,
            "numCitedBy": 5209,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "The probability of error in decoding an optimal convolutional code transmitted over a memoryless channel is bounded from above and below as a function of the constraint length of the code. For all but pathological channels the bounds are asymptotically (exponentially) tight for rates above R_{0} , the computational cutoff rate of sequential decoding. As a function of constraint length the performance of optimal convolutional codes is shown to be superior to that of block codes of the same length, the relative improvement increasing with rate. The upper bound is obtained for a specific probabilistic nonsequential decoding algorithm which is shown to be asymptotically optimum for rates above R_{0} and whose performance bears certain similarities to that of sequential decoding algorithms."
            },
            "slug": "Error-bounds-for-convolutional-codes-and-an-optimum-Viterbi",
            "title": {
                "fragments": [],
                "text": "Error bounds for convolutional codes and an asymptotically optimum decoding algorithm"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The upper bound is obtained for a specific probabilistic nonsequential decoding algorithm which is shown to be asymptotically optimum for rates above R_{0} and whose performance bears certain similarities to that of sequential decoding algorithms."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Inf. Theory"
            },
            "year": 1967
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "30050592"
                        ],
                        "name": "S. Benedetto",
                        "slug": "S.-Benedetto",
                        "structuredName": {
                            "firstName": "Sergio",
                            "lastName": "Benedetto",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Benedetto"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1714533"
                        ],
                        "name": "G. Montorsi",
                        "slug": "G.-Montorsi",
                        "structuredName": {
                            "firstName": "Guido",
                            "lastName": "Montorsi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Montorsi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 100,
                                "start": 97
                            }
                        ],
                        "text": "Many of the structural properties of turbo codes have now been put on a firm theoretical footing [7], [18], [20], [21], [27], [45], and several innovative variations on the turbo theme have appeared [5], [8], [9], [12], [27], [48]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 3755089,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "987e42dcea7ff80daef4dda421b71e69a8f59a8d",
            "isKey": false,
            "numCitedBy": 1227,
            "numCiting": 48,
            "paperAbstract": {
                "fragments": [],
                "text": "A parallel concatenated coding scheme consists of two simple constituent systematic encoders linked by an interleaver. The input bits to the first encoder are scrambled by the interleaver before entering the second encoder. The codeword of the parallel concatenated code consists of the input bits to the first encoder followed by the parity check bits of both encoders. This construction can be generalized to any number of constituent codes. Parallel concatenated schemes employing two convolutional codes as constituent codes, in connection with an iterative decoding algorithm of complexity comparable to that of the constituent codes, have been previously shown to yield remarkable coding gains close to theoretical limits. They have been named, and are known as, \"turbo codes\". We propose a method to evaluate an upper bound to the bit error probability of a parallel concatenated coding scheme averaged over all interleavers of a given length. The analytical bounding technique is then used to shed some light on some crucial questions, which have been floating around in the communications community since the proposal of turbo codes."
            },
            "slug": "Unveiling-turbo-codes:-some-results-on-parallel-Benedetto-Montorsi",
            "title": {
                "fragments": [],
                "text": "Unveiling turbo codes: some results on parallel concatenated coding schemes"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A method to evaluate an upper bound to the bit error probability of a parallel concatenated coding scheme averaged over all interleavers of a given length is proposed and used to shed some light on some crucial questions which have been floating around in the communications community since the proposal of turbo codes."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Inf. Theory"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "30050592"
                        ],
                        "name": "S. Benedetto",
                        "slug": "S.-Benedetto",
                        "structuredName": {
                            "firstName": "Sergio",
                            "lastName": "Benedetto",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Benedetto"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3127159"
                        ],
                        "name": "D. Divsalar",
                        "slug": "D.-Divsalar",
                        "structuredName": {
                            "firstName": "Dariush",
                            "lastName": "Divsalar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Divsalar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1714533"
                        ],
                        "name": "G. Montorsi",
                        "slug": "G.-Montorsi",
                        "structuredName": {
                            "firstName": "Guido",
                            "lastName": "Montorsi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Montorsi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2714946"
                        ],
                        "name": "F. Pollara",
                        "slug": "F.-Pollara",
                        "structuredName": {
                            "firstName": "Fabrizio",
                            "lastName": "Pollara",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Pollara"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "7, which is a loopy Bayesian network appropriate for the turbo decoding problem.9"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7268800,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4bd5620343045e1f23cd5b2c387da2087004d708",
            "isKey": false,
            "numCitedBy": 995,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": "A serially concatenated code with interleaver consists of the cascade of an outer encoder, an interleaver permuting the outer codewords bits, and an inner encoder whose input words are the permuted outer codewords. The construction can be generalized to h cascaded encoders separated by h-1 interleavers. We obtain upper bounds to the average maximum-likelihood bit error probability of serially concatenated block and convolutional coding schemes. Then, we derive design guidelines for the outer and inner encoders that maximize the interleaver gain and the asymptotic slope of the error probability curves. Finally, we propose a new, low-complexity iterative decoding algorithm. Throughout the paper, extensive comparisons with parallel concatenated convolutional codes known as \"turbo codes\" are performed, showing that the new scheme can offer superior performance."
            },
            "slug": "Serial-Concatenation-of-Interleaved-Codes:-Design,-Benedetto-Divsalar",
            "title": {
                "fragments": [],
                "text": "Serial Concatenation of Interleaved Codes: Performance Analysis, Design, and Iterative Decoding"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "Comparisons with parallel concatenated convolutional codes known as \"turbo codes\" are performed, showing that the new scheme can offer superior performance and a new, low-complexity iterative decoding algorithm is proposed."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Inf. Theory"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144572614"
                        ],
                        "name": "D. Mackay",
                        "slug": "D.-Mackay",
                        "structuredName": {
                            "firstName": "D.",
                            "lastName": "Mackay",
                            "middleNames": [
                                "J.",
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Mackay"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "paper that motivated this one, is that of MacKay and Neal [37]. See also [ 38 ] and [39].)"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 16406992,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "01c3188460d25219433c2dc28629d61b18970d54",
            "isKey": false,
            "numCitedBy": 2319,
            "numCiting": 85,
            "paperAbstract": {
                "fragments": [],
                "text": "We report theoretical and empirical properties of Gallager's (1963) low density parity check codes on Gaussian channels. It can be proved that, given an optimal decoder, these codes asymptotically approach the Shannon limit. With a practical 'belief propagation' decoder, performance substantially better than that of standard convolutional and concatenated codes can be achieved; indeed the performance is almost as close to the Shannon limit as that of turbo codes."
            },
            "slug": "Good-error-correcting-codes-based-on-very-sparse-Mackay",
            "title": {
                "fragments": [],
                "text": "Good Error-Correcting Codes Based on Very Sparse Matrices"
            },
            "tldr": {
                "abstractSimilarityScore": 58,
                "text": "It can be proved that, given an optimal decoder, Gallager's low density parity check codes asymptotically approach the Shannon limit."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Inf. Theory"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3127159"
                        ],
                        "name": "D. Divsalar",
                        "slug": "D.-Divsalar",
                        "structuredName": {
                            "firstName": "Dariush",
                            "lastName": "Divsalar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Divsalar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2714946"
                        ],
                        "name": "F. Pollara",
                        "slug": "F.-Pollara",
                        "structuredName": {
                            "firstName": "Fabrizio",
                            "lastName": "Pollara",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Pollara"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 106,
                                "start": 102
                            }
                        ],
                        "text": "Many of the structural properties of turbo codes have now been put on a firm theoretical footing [7], [18], [20], [21], [27], [45], and several innovative variations on the turbo theme have appeared [5], [8], [9], [12], [27], [48]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 63,
                                "start": 59
                            }
                        ],
                        "text": "[10], but which was perhaps explained more lucidly in [3], [18], or [50]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 36171742,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4f06255973f48509498e97b94e4bd034facc0add",
            "isKey": false,
            "numCitedBy": 123,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "Turbo codes were recently proposed by Berrou, Glavieux, and Thitimajshima [2], and it has been claimed these codes achieve near-Shannon-limit error correction performance with relatively simple component codes and large interleavers. A required Eb=No of 0.7 dB was reported for ab it error rate of 10 i 5 , using a rate 1/2 turbo code [2]. However, some important details that are necessary to reproduce these results were omitted. This article conflrms the accuracy of these claims, and presents a complete description of an encoder/decoder pair that could be suitable for deep-space applications, where lower rate codes can be used. We describe a new simple method for trellis termination, analyze the efiect of interleaver choice on the weight distribution of the code, and introduce the use of unequal rate component codes, which yields better performance."
            },
            "slug": "Turbo-codes-for-deep-space-communications-Divsalar-Pollara",
            "title": {
                "fragments": [],
                "text": "Turbo codes for deep-space communications"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A new simple method for trellis termination is described, the efiect of interleaver choice on the weight distribution of the code is analyzed, and the use of unequal rate component codes is introduced, which yields better performance."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1770859"
                        ],
                        "name": "R. Gallager",
                        "slug": "R.-Gallager",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Gallager",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Gallager"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "7, which is a loopy Bayesian network appropriate for the turbo decoding problem.9"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 115,
                                "start": 113
                            }
                        ],
                        "text": "7 (NODES ARE ACTIVATED IN THE ORDER SHOWN IN THE FIRST COLUMN)\ninformation symbols will be\nin agreement with (3.8)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 12709402,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "206f827fad201506c315d40c1469b41a45141893",
            "isKey": true,
            "numCitedBy": 10568,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "A low-density parity-check code is a code specified by a parity-check matrix with the following properties: each column contains a small fixed number j \\geq 3 of l's and each row contains a small fixed number k > j of l's. The typical minimum distance of these codes increases linearly with block length for a fixed rate and fixed j . When used with maximum likelihood decoding on a sufficiently quiet binary-input symmetric channel, the typical probability of decoding error decreases exponentially with block length for a fixed rate and fixed j . A simple but nonoptimum decoding scheme operating directly from the channel a posteriori probabilities is described. Both the equipment complexity and the data-handling capacity in bits per second of this decoder increase approximately linearly with block length. For j > 3 and a sufficiently low rate, the probability of error using this decoder on a binary symmetric channel is shown to decrease at least exponentially with a root of the block length. Some experimental results show that the actual probability of decoding error is much smaller than this theoretical bound."
            },
            "slug": "Low-density-parity-check-codes-Gallager",
            "title": {
                "fragments": [],
                "text": "Low-density parity-check codes"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "A simple but nonoptimum decoding scheme operating directly from the channel a posteriori probabilities is described and the probability of error using this decoder on a binary symmetric channel is shown to decrease at least exponentially with a root of the block length."
            },
            "venue": {
                "fragments": [],
                "text": "IRE Trans. Inf. Theory"
            },
            "year": 1962
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144766259"
                        ],
                        "name": "L. P\u00e9rez",
                        "slug": "L.-P\u00e9rez",
                        "structuredName": {
                            "firstName": "Lance",
                            "lastName": "P\u00e9rez",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. P\u00e9rez"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2073287729"
                        ],
                        "name": "J. Seghers",
                        "slug": "J.-Seghers",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Seghers",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Seghers"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1690091"
                        ],
                        "name": "D. Costello",
                        "slug": "D.-Costello",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Costello",
                            "middleNames": [
                                "J."
                            ],
                            "suffix": "Jr."
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Costello"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 130,
                                "start": 126
                            }
                        ],
                        "text": "Many of the structural properties of turbo codes have now been put on a firm theoretical footing [7], [18], [20], [21], [27], [45], and several innovative variations on the turbo theme have appeared [5], [8], [9], [12], [27], [48]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 16385869,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2d4b54df0c7e36737eb107d0a87c159c2c59c557",
            "isKey": false,
            "numCitedBy": 511,
            "numCiting": 67,
            "paperAbstract": {
                "fragments": [],
                "text": "The performance of turbo codes is addressed by examining the code's distance spectrum. The \"error floor\" that occurs at moderate signal-to-noise ratios is shown to be a consequence of the relatively low free distance of the code. It is also shown that the \"error floor\" can be lowered by increasing the size of the interleaver without changing the free distance of the code. Alternatively, the free distance of the code may be increased by using primitive feedback polynomials. The excellent performance of turbo codes at low signal-to-noise ratios is explained in terms of the distance spectrum. The interleaver in the turbo encoder is shown to reduce the number of low-weight codewords through a process called \"spectral thinning.\" This thinned distance spectrum results in the free distance asymptote being the dominant performance parameter for low and moderate signal-to-noise ratios."
            },
            "slug": "A-distance-spectrum-interpretation-of-turbo-codes-P\u00e9rez-Seghers",
            "title": {
                "fragments": [],
                "text": "A distance spectrum interpretation of turbo codes"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "The interleaver in the turbo encoder is shown to reduce the number of low-weight codewords through a process called \"spectral thinning,\" which results in the free distance asymptote being the dominant performance parameter for low and moderate signal-to-noise ratios."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Inf. Theory"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144766259"
                        ],
                        "name": "L. P\u00e9rez",
                        "slug": "L.-P\u00e9rez",
                        "structuredName": {
                            "firstName": "Lance",
                            "lastName": "P\u00e9rez",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. P\u00e9rez"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2080295134"
                        ],
                        "name": "Beat Keusch",
                        "slug": "Beat-Keusch",
                        "structuredName": {
                            "firstName": "Beat",
                            "lastName": "Keusch",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Beat Keusch"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2509207"
                        ],
                        "name": "J. Sayir",
                        "slug": "J.-Sayir",
                        "structuredName": {
                            "firstName": "Jossy",
                            "lastName": "Sayir",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Sayir"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "7, which is a loopy Bayesian network appropriate for the turbo decoding problem.9"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 18630357,
            "fieldsOfStudy": [
                "Business",
                "Computer Science"
            ],
            "id": "8de2bda698148b0123951508e424329e06cf9843",
            "isKey": false,
            "numCitedBy": 15,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "It is the goal of this project to explain the performance of Turbo Codes. An algorithm for determining the free distance of Turbo Codes is proposed and applied to a few examples. The origin of the error oor is explained. The method of random interleaving is corrected and extended to punctured Turbo Codes. The distance spectrum of Turbo Codes is investigated using random interleaving. A theory is developed that explains the performance of Turbo Codes. The decoding complexity of Turbo Codes is reviewed. Constituent encoder optimization and interleaver design are discussed. Chapter 1: Introduction to Turbo Codes introduces the Turbo Code's performance and the Turbo Coding scheme. Chapter 2: The Free Distance of Turbo Codes presents an algorithm to calculate the free distance of a Turbo Code. This algorithm is applied to a few examples. The origin of the error oor is identi ed. The problem of interleaver design for optimal free distance is formalized. Chapter 3: The Distance Spectrum of Turbo Codes explains how the distance spectrum determines the Turbo Code's performance. In a rst analysis, the in uence of the interleaver on the distance spectrum is shown. The method of random interleaving is corrected and extended to punctured Turbo Codes. Theoretical results are derived that show how the distance spectrum changes as the interleaver size increases. A theory is proposed that relates the Turbo Code's performance to its distance spectrum. Chapter 4: The Decoding Complexity of Turbo Codes reviews the decoding complexity. The decoding complexity of a Turbo Code is compared to the decoding complexity of a convolutional code with Viterbi decoding. Chapter 5: Improvements for Turbo Codes discusses constituent encoder selection and interleaver design. The good performance of Turbo Codes with maximum cycle length constituent encoders is explained. Chapter 6: The Relation Between Turbo Codes and Product Codes Chapter 7: Conclusions"
            },
            "slug": "On-the-Free-Distance-of-TURBO-Codes-and-Related-P\u00e9rez-Keusch",
            "title": {
                "fragments": [],
                "text": "On the Free Distance of TURBO Codes and Related Product Codes"
            },
            "tldr": {
                "abstractSimilarityScore": 70,
                "text": "The goal of this project to explain the performance of Turbo Codes is to propose and apply an algorithm for determining the free distance of a Turbo Code and develop a theory that relates the Turbo Code's performance to its distance spectrum."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144146190"
                        ],
                        "name": "R. Pyndiah",
                        "slug": "R.-Pyndiah",
                        "structuredName": {
                            "firstName": "Ramesh",
                            "lastName": "Pyndiah",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Pyndiah"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1870588"
                        ],
                        "name": "A. Glavieux",
                        "slug": "A.-Glavieux",
                        "structuredName": {
                            "firstName": "Alain",
                            "lastName": "Glavieux",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Glavieux"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2176336"
                        ],
                        "name": "A. Picart",
                        "slug": "A.-Picart",
                        "structuredName": {
                            "firstName": "Annie",
                            "lastName": "Picart",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Picart"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2071891918"
                        ],
                        "name": "S. Jacq",
                        "slug": "S.-Jacq",
                        "structuredName": {
                            "firstName": "S.",
                            "lastName": "Jacq",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Jacq"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 54164682,
            "fieldsOfStudy": [
                "Computer Science",
                "Business"
            ],
            "id": "7b84b0f0ec563e7ed8c7f50b43c84c43b43b2ea7",
            "isKey": false,
            "numCitedBy": 308,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "A new iterative decoding algorithm for product codes (block) based on soft decoding and soft decision output of the component codes is described in the paper. Monte Carlo simulations of the bit error rate (BER) after decoding using this new algorithm for different product codes indicate coding gains of up to 8 dB. This new coding scheme is attractive for digital transmission systems requiring powerful coding schemes with a high code rate (R>0.8). In the paper the authors compare their coding scheme with one of the best coding schemes, the \"turbo-codes\", in terms of BER performance."
            },
            "slug": "Near-optimum-decoding-of-product-codes-Pyndiah-Glavieux",
            "title": {
                "fragments": [],
                "text": "Near optimum decoding of product codes"
            },
            "tldr": {
                "abstractSimilarityScore": 77,
                "text": "A new iterative decoding algorithm for product codes (block) based on soft decoding and soft decision output of the component codes is described in the paper, attractive for digital transmission systems requiring powerful coding schemes with a high code rate."
            },
            "venue": {
                "fragments": [],
                "text": "1994 IEEE GLOBECOM. Communications: The Global Bridge"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48603452"
                        ],
                        "name": "G. Solomon",
                        "slug": "G.-Solomon",
                        "structuredName": {
                            "firstName": "Gustave",
                            "lastName": "Solomon",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Solomon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1399845611"
                        ],
                        "name": "Van Tilborg",
                        "slug": "Van-Tilborg",
                        "structuredName": {
                            "firstName": "Van",
                            "lastName": "Tilborg",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Van Tilborg"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 123,
                                "start": 119
                            }
                        ],
                        "text": "\u201cTail-Biting\u201d Convolutional Codes: The class of \u201ctailbiting\u201d convolutional codes introduced by Solomon and van Tilborg [56] is a natural candidate for BP decoding."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 54034347,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "07c5f5c66b92212efa65f1f5d3dad882cf31cee8",
            "isKey": false,
            "numCitedBy": 199,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "Convolutional codes of any rate and any constraint length give rise to a sequence of quasi-cyclic codes. Conversely, any quasi-cyclic code may be convolutionally encoded. Among the quasi-cyclic codes are the quadratic residue codes, Reed\u2013Solomon codes and optimal BCH codes. The constraint length K for the convolutional encoding of many of these codes (Golay, (48, 24) OR, etc.) turns out to be surprisingly small. Thus using the soft decoding techniques for convolutional decoding we now have a new maximum likelihood decoding algorithm for many block codes. Conversely an optimal quasi-cyclic code will yield a convolutional encoding with optimal local properties and therefore with good infinite convolutional coding properties."
            },
            "slug": "A-Connection-Between-Block-and-Convolutional-Codes-Solomon-Tilborg",
            "title": {
                "fragments": [],
                "text": "A Connection Between Block and Convolutional Codes"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "Using the soft decoding techniques for convolutional decoding the authors now have a new maximum likelihood decoding algorithm for many block codes that will yield an optimal quasi-cyclic code with optimal local properties and therefore with good infinite Convolutional coding properties."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1979
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2157745208"
                        ],
                        "name": "Jung-Fu Cheng",
                        "slug": "Jung-Fu-Cheng",
                        "structuredName": {
                            "firstName": "Jung-Fu",
                            "lastName": "Cheng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jung-Fu Cheng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1723150"
                        ],
                        "name": "R. McEliece",
                        "slug": "R.-McEliece",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "McEliece",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. McEliece"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 218,
                                "start": 214
                            }
                        ],
                        "text": "Many of the structural properties of turbo codes have now been put on a firm theoretical footing [7], [18], [20], [21], [27], [45], and several innovative variations on the turbo theme have appeared [5], [8], [9], [12], [27], [48]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 16458740,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f537f5790140bb5d524a9b5a12d17248e270e3fb",
            "isKey": false,
            "numCitedBy": 14,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "Several parallel concatenated coding schemes (turbo codes) based on multimemory (MM) convolutional codes (more specifically, a (2,1,4,7) code) were proposed to achieve near Shannon-limit error correction performance with reasonable decoding complexity. On the other hand, in many cases of interest, unit-memory (UM) codes have been demonstrated to have larger free distances than the MM codes with the same rate and the same number of memory elements. New turbo codes based on the (8, 4, 3, 8) UM Hamming code are developed and shown to possess better performance potential in some senses. The standard turbo decoding algorithms, however, do not appear to achieve this potential."
            },
            "slug": "Unit-memory-Hamming-turbo-codes-Cheng-McEliece",
            "title": {
                "fragments": [],
                "text": "Unit-memory Hamming turbo codes"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "New turbo codes based on the (8, 4, 3, 8) UM Hamming code are developed and shown to possess better performance potential in some senses, whereas the standard turbo decoding algorithms do not appear to achieve this potential."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of 1995 IEEE International Symposium on Information Theory"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1833925"
                        ],
                        "name": "C. Berrou",
                        "slug": "C.-Berrou",
                        "structuredName": {
                            "firstName": "Claude",
                            "lastName": "Berrou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Berrou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1870588"
                        ],
                        "name": "A. Glavieux",
                        "slug": "A.-Glavieux",
                        "structuredName": {
                            "firstName": "Alain",
                            "lastName": "Glavieux",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Glavieux"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2952051"
                        ],
                        "name": "P. Thitimajshima",
                        "slug": "P.-Thitimajshima",
                        "structuredName": {
                            "firstName": "Punya",
                            "lastName": "Thitimajshima",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Thitimajshima"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 17770377,
            "fieldsOfStudy": [
                "Computer Science",
                "Business"
            ],
            "id": "3ba9baa534a8ea39a31c69e72ada959aaa6a4dc1",
            "isKey": false,
            "numCitedBy": 8239,
            "numCiting": 2,
            "paperAbstract": {
                "fragments": [],
                "text": "A new class of convolutional codes called turbo-codes, whose performances in terms of bit error rate (BER) are close to the Shannon limit, is discussed. The turbo-code encoder is built using a parallel concatenation of two recursive systematic convolutional codes, and the associated decoder, using a feedback decoding rule, is implemented as P pipelined identical elementary decoders.<<ETX>>"
            },
            "slug": "Near-Shannon-limit-error-correcting-coding-and-1-Berrou-Glavieux",
            "title": {
                "fragments": [],
                "text": "Near Shannon limit error-correcting coding and decoding: Turbo-codes. 1"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "A new class of convolutional codes called turbo-codes, whose performances in terms of bit error rate (BER) are close to the Shannon limit, is discussed."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of ICC '93 - IEEE International Conference on Communications"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3127159"
                        ],
                        "name": "D. Divsalar",
                        "slug": "D.-Divsalar",
                        "structuredName": {
                            "firstName": "Dariush",
                            "lastName": "Divsalar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Divsalar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2222408"
                        ],
                        "name": "S. Dolinar",
                        "slug": "S.-Dolinar",
                        "structuredName": {
                            "firstName": "Samuel",
                            "lastName": "Dolinar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Dolinar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2714946"
                        ],
                        "name": "F. Pollara",
                        "slug": "F.-Pollara",
                        "structuredName": {
                            "firstName": "Fabrizio",
                            "lastName": "Pollara",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Pollara"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1723150"
                        ],
                        "name": "R. McEliece",
                        "slug": "R.-McEliece",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "McEliece",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. McEliece"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 112,
                                "start": 108
                            }
                        ],
                        "text": "Many of the structural properties of turbo codes have now been put on a firm theoretical footing [7], [18], [20], [21], [27], [45], and several innovative variations on the turbo theme have appeared [5], [8], [9], [12], [27], [48]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 18630507,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d44b78825a06efcb912d007abafdd8ca52c9a516",
            "isKey": false,
            "numCitedBy": 235,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "In this article we apply transfer function bounding techniques to obtain upper bounds on the bit-error rate for maximum likelihood decoding of turbo codes constructed with random permutations. These techniques are applied to two turbo codes with constraint length 3 and later extended to other codes. The performance predicted by these bounds is compared with simulation results. The bounds are useful in estimating the 'error floor' that is difficult to measure by simulation, and they provide insight on how to lower this floor. More refined bounds are needed for accurate performance measures at lower signal-to-noise ratios."
            },
            "slug": "Transfer-function-bounds-on-the-performance-of-Divsalar-Dolinar",
            "title": {
                "fragments": [],
                "text": "Transfer function bounds on the performance of turbo codes Pasadena"
            },
            "tldr": {
                "abstractSimilarityScore": 77,
                "text": "Transfer function bounding techniques are applied to obtain upper bounds on the bit-error rate for maximum likelihood decoding of turbo codes constructed with random permutations to help estimate the 'error floor' that is difficult to measure by simulation."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2176336"
                        ],
                        "name": "A. Picart",
                        "slug": "A.-Picart",
                        "structuredName": {
                            "firstName": "Annie",
                            "lastName": "Picart",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Picart"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144146190"
                        ],
                        "name": "R. Pyndiah",
                        "slug": "R.-Pyndiah",
                        "structuredName": {
                            "firstName": "Ramesh",
                            "lastName": "Pyndiah",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Pyndiah"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "7, which is a loopy Bayesian network appropriate for the turbo decoding problem.9"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 62371977,
            "fieldsOfStudy": [
                "Business",
                "Computer Science"
            ],
            "id": "094652d0e8875621e46e93baf54ccad756a94a41",
            "isKey": false,
            "numCitedBy": 8,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "A powerful coding scheme based on multilevel coding and using a product code on the first partitioning level is proposed. The multistage decoder takes advantage of the iterative decoding of the product code to achieve a high coding gain. This coding scheme is compared to the one using the product code in a pragmatic approach with a Gray mapping. Results show that in the range of high bit error rates (BER greater than 10/sup -7/, a product code having a high code rate (R>0.8) associated with a Gray mapping is the best solution. For high transmission rate applications, in which the required BER is lower than 10/sup -7/, multilevel coding with a turbo-decoded product code is the recommended solution."
            },
            "slug": "Performance-of-turbo-decoded-product-codes-used-in-Picart-Pyndiah",
            "title": {
                "fragments": [],
                "text": "Performance of turbo-decoded product codes used in multilevel coding"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "Results show that in the range of high bit error rates (BER greater than 10/sup -7/, a product code having a high code rate associated with a Gray mapping is the best solution."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of ICC/SUPERCOMM '96 - International Conference on Communications"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2696176"
                        ],
                        "name": "L. Bahl",
                        "slug": "L.-Bahl",
                        "structuredName": {
                            "firstName": "Lalit",
                            "lastName": "Bahl",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Bahl"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144716964"
                        ],
                        "name": "J. Cocke",
                        "slug": "J.-Cocke",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Cocke",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Cocke"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2472759"
                        ],
                        "name": "F. Jelinek",
                        "slug": "F.-Jelinek",
                        "structuredName": {
                            "firstName": "Frederick",
                            "lastName": "Jelinek",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Jelinek"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "16512130"
                        ],
                        "name": "J. Raviv",
                        "slug": "J.-Raviv",
                        "structuredName": {
                            "firstName": "Josef",
                            "lastName": "Raviv",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Raviv"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "To do so, we take and define a kernel as\n2 We assume that \u201cadjacent\u201d takes precedence over \u201ccircle\u201d in order to minimize the use of parentheses.\nwhere the codeword fragment is a deterministic function of Then Lemma 2.2 can be summarized as follows:\n(2.9)\nwhere and"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 54,
                                "start": 51
                            }
                        ],
                        "text": "5 We have already used upper case X\u2019s to denote codeword components, for example, (2.1)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 152,
                                "start": 149
                            }
                        ],
                        "text": "\u2026the \u2019s is independent and uniform, by line 3 in Table II, the quantity is permanently set as follows:\npermanent (6.1)\nSince the \u2019s are \u201cdirect evidence\u201d nodes (i.e., evidence nodes which have only one parent), by line 6 of Table II, the message that sends the is permanently set as\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 28594190,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b51c6a5610be2c5648d1476b6f70e8037e0e8cb8",
            "isKey": true,
            "numCitedBy": 6485,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "The general problem of estimating the a posteriori probabilities of the states and transitions of a Markov source observed through a discrete memoryless channel is considered. The decoding of linear block and convolutional codes to minimize symbol error probability is shown to be a special case of this problem. An optimal decoding algorithm is derived."
            },
            "slug": "Optimal-decoding-of-linear-codes-for-minimizing-Bahl-Cocke",
            "title": {
                "fragments": [],
                "text": "Optimal decoding of linear codes for minimizing symbol error rate (Corresp.)"
            },
            "tldr": {
                "abstractSimilarityScore": 87,
                "text": "The general problem of estimating the a posteriori probabilities of the states and transitions of a Markov source observed through a discrete memoryless channel is considered and an optimal decoding algorithm is derived."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Inf. Theory"
            },
            "year": 1974
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1719613"
                        ],
                        "name": "S. E. Shimony",
                        "slug": "S.-E.-Shimony",
                        "structuredName": {
                            "firstName": "S.",
                            "lastName": "Shimony",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. E. Shimony"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "However, since it is the object of this paper to study the decoding algorithm without regard to the resulting performance, we shall not discuss the constructive aspect of turbo codes further."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 13405361,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "96a5867d0b9b997108633ff3da314edf69b0122c",
            "isKey": false,
            "numCitedBy": 394,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Finding-MAPs-for-Belief-Networks-is-NP-Hard-Shimony",
            "title": {
                "fragments": [],
                "text": "Finding MAPs for Belief Networks is NP-Hard"
            },
            "venue": {
                "fragments": [],
                "text": "Artif. Intell."
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3127159"
                        ],
                        "name": "D. Divsalar",
                        "slug": "D.-Divsalar",
                        "structuredName": {
                            "firstName": "Dariush",
                            "lastName": "Divsalar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Divsalar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2714946"
                        ],
                        "name": "F. Pollara",
                        "slug": "F.-Pollara",
                        "structuredName": {
                            "firstName": "Fabrizio",
                            "lastName": "Pollara",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Pollara"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "7, which is a loopy Bayesian network appropriate for the turbo decoding problem.9"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 55595184,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "64e7badd52b7841ebc25d09e6b38e6d7dbea5f38",
            "isKey": false,
            "numCitedBy": 233,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "In this article, we introduce multiple turbo codes and a suitable decoder structure derived from an approximation to the maximum a posteriori probability (MAP) decision rule, which is substantially difierent from the decoder for two-code-based encoders. We analyze the efiect of interleaver choice on the weight distribution of the code, and we describe simulation results on the improved performance of these new codes."
            },
            "slug": "Multiple-turbo-codes-for-deep-space-communications-Divsalar-Pollara",
            "title": {
                "fragments": [],
                "text": "Multiple turbo codes for deep-space communications"
            },
            "tldr": {
                "abstractSimilarityScore": 98,
                "text": "This article introduces multiple turbo codes and a suitable decoder structure derived from an approximation to the maximum a posteriori probability (MAP) decision rule, which is substantially different from the decoder for two-code-based encoders."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2367457"
                        ],
                        "name": "M. Sipser",
                        "slug": "M.-Sipser",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Sipser",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Sipser"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2417095"
                        ],
                        "name": "D. Spielman",
                        "slug": "D.-Spielman",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Spielman",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Spielman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "7, which is a loopy Bayesian network appropriate for the turbo decoding problem.9"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14358941,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "42ebe9fa7943a2677ae271c0da6ded78f1fdea9f",
            "isKey": false,
            "numCitedBy": 468,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a new class of asymptotically good, linear error-correcting codes based upon expander graphs. These codes have linear time sequential decoding algorithms, logarithmic time parallel decoding algorithms with a linear number of processors, and are simple to understand. We present both randomized and explicit constructions for some of these codes. Experimental results demonstrate the extremely good performance of the randomly chosen codes.<<ETX>>"
            },
            "slug": "Expander-codes-Sipser-Spielman",
            "title": {
                "fragments": [],
                "text": "Expander codes"
            },
            "tldr": {
                "abstractSimilarityScore": 93,
                "text": "A new class of asymptotically good, linear error-correcting codes based upon expander graphs, which have linear time sequential decoding algorithms, logarithmic time parallel decoding algorithms with a linear number of processors, and are simple to understand are presented."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings 35th Annual Symposium on Foundations of Computer Science"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50860274"
                        ],
                        "name": "Padhraic Smyth",
                        "slug": "Padhraic-Smyth",
                        "structuredName": {
                            "firstName": "Padhraic",
                            "lastName": "Smyth",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Padhraic Smyth"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48099028"
                        ],
                        "name": "D. Heckerman",
                        "slug": "D.-Heckerman",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Heckerman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Heckerman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694621"
                        ],
                        "name": "Michael I. Jordan",
                        "slug": "Michael-I.-Jordan",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Jordan",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael I. Jordan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 10043879,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e0999dc17b35c0d893974f03d98293f71f27698b",
            "isKey": false,
            "numCitedBy": 327,
            "numCiting": 87,
            "paperAbstract": {
                "fragments": [],
                "text": "Graphical techniques for modeling the dependencies of random variables have been explored in a variety of different areas, including statistics, statistical physics, artificial intelligence, speech recognition, image processing, and genetics. Formalisms for manipulating these models have been developed relatively independently in these research communities. In this paper we explore hidden Markov models (HMMs) and related structures within the general framework of probabilistic independence networks (PINs). The paper presents a self-contained review of the basic principles of PINs. It is shown that the well-known forward-backward (F-B) and Viterbi algorithms for HMMs are special cases of more general inference algorithms for arbitrary PINs. Furthermore, the existence of inference and estimation algorithms for more general graphical models provides a set of analysis tools for HMM practitioners who wish to explore a richer class of HMM structures. Examples of relatively complex models to handle sensor fusion and coarticulation in speech recognition are introduced and treated within the graphical model framework to illustrate the advantages of the general approach."
            },
            "slug": "Probabilistic-Independence-Networks-for-Hidden-Smyth-Heckerman",
            "title": {
                "fragments": [],
                "text": "Probabilistic Independence Networks for Hidden Markov Probability Models"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "It is shown that the well-known forward-backward and Viterbi algorithms for HMMs are special cases of more general inference algorithms for arbitrary PINs and the existence of inference and estimation algorithms for more general graphical models provides a set of analysis tools for HMM practitioners who wish to explore a richer class of HMM structures."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "92032001"
                        ],
                        "name": "R. Chang",
                        "slug": "R.-Chang",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Chang",
                            "middleNames": [
                                "Pang",
                                "Heng"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Chang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2058321160"
                        ],
                        "name": "J. Hancock",
                        "slug": "J.-Hancock",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Hancock",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Hancock"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 221,
                                "start": 217
                            }
                        ],
                        "text": "\u2026the a posteriori or conditional probabilities for all\nThe brute force approach to computing is to sum over all of the terms of which do not involve either\n4 As we shall see in Section IV, the BCJR algorithm itself, and the many variations of it, are themselves special cases of Pearl\u2019s algorithm."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 206729000,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c55a5f24234c131c37dd3c9c7560699175edf084",
            "isKey": false,
            "numCitedBy": 153,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper is concerned with m -ary communication channels (m \\geq 2) having intersymbol interference between L time periods (L \\geq 2) . Receiver structures are developed for making jointly optimum (minimum probability of error) decisions about L consecutive symbols on the basis of the complete message received. The decision statistics are computed by a sequential procedure, and the number of computations increases only linearly with the message length. The method can be applied to the general problem of making decisions about the states of a discrete-state Markov information source which is observable only through a channel with additive Gaussian or non-Gaussian noise."
            },
            "slug": "On-receiver-structures-for-channels-having-memory-Chang-Hancock",
            "title": {
                "fragments": [],
                "text": "On receiver structures for channels having memory"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "Receiver structures are developed for making jointly optimum decisions about L consecutive symbols on the basis of the complete message received and the decision statistics are computed by a sequential procedure, and the number of computations increases only linearly with the message length."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Inf. Theory"
            },
            "year": 1966
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1726406"
                        ],
                        "name": "G. Cooper",
                        "slug": "G.-Cooper",
                        "structuredName": {
                            "firstName": "Gregory",
                            "lastName": "Cooper",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Cooper"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "However, since it is the object of this paper to study the decoding algorithm without regard to the resulting performance, we shall not discuss the constructive aspect of turbo codes further."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 43363498,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ed5324bb3a19f0dcc2e90e482c06373b934fc28c",
            "isKey": false,
            "numCitedBy": 2047,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "The-Computational-Complexity-of-Probabilistic-Using-Cooper",
            "title": {
                "fragments": [],
                "text": "The Computational Complexity of Probabilistic Inference Using Bayesian Belief Networks"
            },
            "venue": {
                "fragments": [],
                "text": "Artif. Intell."
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2417095"
                        ],
                        "name": "D. Spielman",
                        "slug": "D.-Spielman",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Spielman",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Spielman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "7, which is a loopy Bayesian network appropriate for the turbo decoding problem.9"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2029658,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bdf1a72765e0841ac18329d7b9bf8d0d9331be4c",
            "isKey": false,
            "numCitedBy": 311,
            "numCiting": 96,
            "paperAbstract": {
                "fragments": [],
                "text": "Ab,stract-We present a new class of asymptotically good, linear error-correcting codes. These codes can be both encoded and decoded in linear time. They can also be encoded by logarithmicdepth circuits of linear size and decoded by logarithmic depth circuits of size 0 (n log n) . We present both randomized and explicit constructions of these codes. Zndex Terms- Asymptotically good error-correcting code, linear-time, expander graph, superconcentrators."
            },
            "slug": "Linear-time-encodable-and-decodable-codes-Spielman",
            "title": {
                "fragments": [],
                "text": "Linear-time encodable and decodable error-correcting codes"
            },
            "tldr": {
                "abstractSimilarityScore": 73,
                "text": "This work presents a new class of asymptotically good, linear error-correcting codes that can be both encoded and decoded in linear time and presents both randomized and explicit constructions of these codes."
            },
            "venue": {
                "fragments": [],
                "text": "STOC '95"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "102376680"
                        ],
                        "name": "I. Yoscovich",
                        "slug": "I.-Yoscovich",
                        "structuredName": {
                            "firstName": "I.",
                            "lastName": "Yoscovich",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Yoscovich"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1717477"
                        ],
                        "name": "J. Snyders",
                        "slug": "J.-Snyders",
                        "structuredName": {
                            "firstName": "Jakov",
                            "lastName": "Snyders",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Snyders"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 118,
                                "start": 114
                            }
                        ],
                        "text": "Many of the structural properties of turbo codes have now been put on a firm theoretical footing [7], [18], [20], [21], [27], [45], and several innovative variations on the turbo theme have appeared [5], [8], [9], [12], [27], [48]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 120627757,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "16a8ffca4683ba905de6560231646955fad06a26",
            "isKey": false,
            "numCitedBy": 30,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "An expression for the Hamming weight of the (L+1)th order output of a constituent encoder is derived. This expression enables the determination of the inputs that produce outputs of finite weight. It also facilitates the calculation of the (L+1)th order effective free distance (i.e., minimum output weight) d/sub L+1/ of the encoder. Expressions and bounds for d/sub L+1/ and in particular for d/sub 2/ and d/sub 3/ are presented."
            },
            "slug": "On-the-effective-free-distance-of-turbo-codes-Yoscovich-Snyders",
            "title": {
                "fragments": [],
                "text": "On the effective free distance of turbo codes"
            },
            "tldr": {
                "abstractSimilarityScore": 74,
                "text": "An expression for the Hamming weight of the (L+1)th order output of a constituent encoder is derived and facilitates the calculation of the minimum output weight d/sub L+1/ of the encoder."
            },
            "venue": {
                "fragments": [],
                "text": "1998 Information Theory Workshop (Cat. No.98EX131)"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1895150"
                        ],
                        "name": "P. Dagum",
                        "slug": "P.-Dagum",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Dagum",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Dagum"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145881044"
                        ],
                        "name": "M. Luby",
                        "slug": "M.-Luby",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Luby",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Luby"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "However, since it is the object of this paper to study the decoding algorithm without regard to the resulting performance, we shall not discuss the constructive aspect of turbo codes further."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 19786563,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7ffa848789d790527448fb3acdfce57e7f4b4641",
            "isKey": false,
            "numCitedBy": 738,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Approximating-Probabilistic-Inference-in-Bayesian-Dagum-Luby",
            "title": {
                "fragments": [],
                "text": "Approximating Probabilistic Inference in Bayesian Belief Networks is NP-Hard"
            },
            "venue": {
                "fragments": [],
                "text": "Artif. Intell."
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145430701"
                        ],
                        "name": "J. Pearl",
                        "slug": "J.-Pearl",
                        "structuredName": {
                            "firstName": "Judea",
                            "lastName": "Pearl",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Pearl"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 13723620,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bb0419bccc2244ed33c9c42341f342511262daa3",
            "isKey": false,
            "numCitedBy": 2148,
            "numCiting": 53,
            "paperAbstract": {
                "fragments": [],
                "text": "Belief networks are directed acyclic graphs in which the nodes represent propositions (or variables), the arcs signify direct dependencies between the linked propositions, and the strengths of these dependencies are quantified by conditional probabilities. A network of this sort can be used to represent the generic knowledge of a domain expert, and it turns into a computational architecture if the links are used not merely for storing factual knowledge but also for directing and activating the data flow in the computations which manipulate this knowledge. The first part of the paper deals with the task of fusing and propagating the impacts of new information through the networks in such a way that, when equilibrium is reached, each proposition will be assigned a measure of belief consistent with the axioms of probability theory. It is shown that if the network is singly connected (e.g. tree-structured), then probabilities can be updated by local propagation in an isomorphic network of parallel and autonomous processors and that the impact of new information can be imparted to all propositions in time proportional to the longest path in the network. The second part of the paper deals with the problem of finding a tree-structured representation for a collection of probabilistically coupled propositions using auxiliary (dummy) variables, colloquially called \"hidden causes.\" It is shown that if such a tree-structured representation exists, then it is possible to uniquely uncover the topology of the tree by observing pairwise dependencies among the available propositions (i.e., the leaves of the tree). The entire tree structure, including the strengths of all internal relationships, can be reconstructed in time proportional to n log n, where n is the number of leaves."
            },
            "slug": "Fusion,-Propagation,-and-Structuring-in-Belief-Pearl",
            "title": {
                "fragments": [],
                "text": "Fusion, Propagation, and Structuring in Belief Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "It is shown that if the network is singly connected (e.g. tree-structured), then probabilities can be updated by local propagation in an isomorphic network of parallel and autonomous processors and that the impact of new information can be imparted to all propositions in time proportional to the longest path in the network."
            },
            "venue": {
                "fragments": [],
                "text": "Artif. Intell."
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "30050592"
                        ],
                        "name": "S. Benedetto",
                        "slug": "S.-Benedetto",
                        "structuredName": {
                            "firstName": "Sergio",
                            "lastName": "Benedetto",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Benedetto"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1714533"
                        ],
                        "name": "G. Montorsi",
                        "slug": "G.-Montorsi",
                        "structuredName": {
                            "firstName": "Guido",
                            "lastName": "Montorsi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Montorsi"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "7, which is a loopy Bayesian network appropriate for the turbo decoding problem.9"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 3041978,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c64f5af23218570f3745e25f3682db3d91b16e56",
            "isKey": false,
            "numCitedBy": 133,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": "Parallel concatenated coding schemes employing convolutional codes as constituent codes linked by an interleaver have been proposed in the literature as \u2018turbo codes\u2019. They yield very good performance in connection with simple suboptimum decoding algorithms. The authors propose an alternative scheme consisting in the serial concatenation of block or convolutional codes and evaluate its average performance in terms of bit error probability."
            },
            "slug": "Serial-concatenation-of-block-and-convolutional-Benedetto-Montorsi",
            "title": {
                "fragments": [],
                "text": "Serial concatenation of block and convolutional codes"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "The authors propose an alternative scheme consisting in the serial concatenation of block or convolutional codes and evaluate its average performance in terms of bit error probability."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "102981024"
                        ],
                        "name": "A. Poritz",
                        "slug": "A.-Poritz",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Poritz",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Poritz"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 143,
                                "start": 139
                            }
                        ],
                        "text": "It appeared explicitly as an algorithm for tracking the states of a Markov chain in the early 1970\u2019s [40], [4] (see also the survey papers [47] and [49])."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 62479678,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a6627d8efde3ed55e34ccee059eb6cdac99bb2fe",
            "isKey": false,
            "numCitedBy": 304,
            "numCiting": 56,
            "paperAbstract": {
                "fragments": [],
                "text": "Hidden Markov modeling is a probabilistic technique for the study of time series. Hidden Markov theory permits modeling with any of the classical probability distributions. The costs of implementation are linear in the length of data. Models can be nested to reflect hierarchical sources of knowledge. These and other desirable features have made hidden Markov methods increasingly attractive for problems in language, speech and signal processing. The basic ideas are introduced by elementary examples in the spirit of the Polya urn models. The main tool in hidden Markov modeling is the Baum-Welch (or forward-backward) algorithm for maximum likelihood estimation of the model parameters. This iterative algorithm is discussed both from an intuitive point of view as an exercise in the art of counting and from a formal point of view via the information-theoretic Q-function. Selected examples drawn from the literature illustrate how the Baum-Welch technique places a rich variety of computational models at the disposal of the researcher.<<ETX>>"
            },
            "slug": "Hidden-Markov-models:-a-guided-tour-Poritz",
            "title": {
                "fragments": [],
                "text": "Hidden Markov models: a guided tour"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "The main tool in hidden Markov modeling is the Baum-Welch algorithm for maximum likelihood estimation of the model parameters, which is discussed both from an intuitive point of view as an exercise in the art of counting and from a formalpoint of view via the information-theoretic Q-function."
            },
            "venue": {
                "fragments": [],
                "text": "ICASSP-88., International Conference on Acoustics, Speech, and Signal Processing"
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144572614"
                        ],
                        "name": "D. Mackay",
                        "slug": "D.-Mackay",
                        "structuredName": {
                            "firstName": "D.",
                            "lastName": "Mackay",
                            "middleNames": [
                                "J.",
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Mackay"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 17285553,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f9ae39a71308a0bfe12fd5c1ba13165547be3cbd",
            "isKey": false,
            "numCitedBy": 494,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a new family of error-correcting codes for the binary symmetric channel. These codes are designed to encode a sparse source, and are defined in terms of very sparse invertible matrices, in such a way that the decoder can treat the signal and the noise symmetrically. The decoding problem involves only very sparse matrices and sparse vectors, and so is a promising candidate for practical decoding."
            },
            "slug": "Good-Codes-Based-on-Very-Sparse-Matrices-Mackay",
            "title": {
                "fragments": [],
                "text": "Good Codes Based on Very Sparse Matrices"
            },
            "tldr": {
                "abstractSimilarityScore": 92,
                "text": "A new family of error-correcting codes for the binary symmetric channel is presented, designed to encode a sparse source, and are defined in terms of very sparse invertible matrices, in such a way that the decoder can treat the signal and the noise symmetrically."
            },
            "venue": {
                "fragments": [],
                "text": "IMACC"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2031175"
                        ],
                        "name": "G. Ungerboeck",
                        "slug": "G.-Ungerboeck",
                        "structuredName": {
                            "firstName": "Gottfried",
                            "lastName": "Ungerboeck",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Ungerboeck"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 96,
                                "start": 92
                            }
                        ],
                        "text": "We use upper case X\u2019s here to denote arbitrary random variables, and hope no confusion will occur.\nor To simplify notation, we assume and Then we have\n(4.1)\nIf can assume different values, then computing the sum in (4.1) for each possible value of requires additions, which is impractical unless and\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 111056961,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bac0c503fa18496ad3dd33375a0cbdbca812fbab",
            "isKey": true,
            "numCitedBy": 40,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "A maximum a posteriori probability (MAP) approach is used to derive the optimal equalizer for binary signals transmitted at a constant rate over a dispersive and noisy channel. The optimal equalizer is shown to consist of a matched filter followed by a very complex nonlinear transversal filter. Various approximations are made to simplify the transversal filter. Thus the optimal linear equalizer and two suboptimal nonlinear equalizers are obtained. The performance characteristics of these equalizers are compared in terms of eye patterns and error probabilities. These investigations exhibit a clear superiority of the nonlinear equalizers. Up to a certain peak distortion, intersymbol interference can be eliminated by nonlinear equalization With negligible noise enhancement. The error probability then closely approaches the error probability in the case of noninterfering signals."
            },
            "slug": "Nonlinear-Equalization-of-Binary-Signals-in-Noise-Ungerboeck",
            "title": {
                "fragments": [],
                "text": "Nonlinear Equalization of Binary Signals in Gaussian Noise"
            },
            "tldr": {
                "abstractSimilarityScore": 88,
                "text": "A maximum a posteriori probability (MAP) approach is used to derive the optimal equalizer for binary signals transmitted at a constant rate over a dispersive and noisy channel and two suboptimal nonlinear equalizers are obtained."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1971
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144572614"
                        ],
                        "name": "D. Mackay",
                        "slug": "D.-Mackay",
                        "structuredName": {
                            "firstName": "D.",
                            "lastName": "Mackay",
                            "middleNames": [
                                "J.",
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Mackay"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "7, which is a loopy Bayesian network appropriate for the turbo decoding problem.9"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2805117,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "74396ba995e90adeda85ecd379fb5d36d5c461af",
            "isKey": false,
            "numCitedBy": 17,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper studies the task of inferring a binary vector s given noisy observations of the binary vector t=As modulo 2, where A is an M\u00d7N binary matrix. This task arises in correlation attack on a class of stream ciphers and in the decoding of error correcting codes."
            },
            "slug": "A-Free-Energy-Minimization-Framework-for-Inference-Mackay",
            "title": {
                "fragments": [],
                "text": "A Free Energy Minimization Framework for Inference Problems in modulo 2 Arithmetic"
            },
            "tldr": {
                "abstractSimilarityScore": 97,
                "text": "This paper studies the task of inferring a binary vector given noisy observations of the binary vector t=As modulo 2, where A is an M\u00d7N binary matrix, which arises in correlation attack on a class of stream ciphers and in the decoding of error correcting codes."
            },
            "venue": {
                "fragments": [],
                "text": "FSE"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145430701"
                        ],
                        "name": "J. Pearl",
                        "slug": "J.-Pearl",
                        "structuredName": {
                            "firstName": "Judea",
                            "lastName": "Pearl",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Pearl"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "However, since it is the object of this paper to study the decoding algorithm without regard to the resulting performance, we shall not discuss the constructive aspect of turbo codes further."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 150,
                                "start": 146
                            }
                        ],
                        "text": "D. J. C. MacKay is with the Cavendish Laboratory, Department of Physics, Darwin College, Cambridge University, Cambridge CB3 OHE U.K.\nJ.-F. Cheng is with Salomon Brothers Inc., New York, NY 10048 USA."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 32583695,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "70ef29e6f0ce082bb8a47fd85b9bfb7cc0f20c93",
            "isKey": false,
            "numCitedBy": 18218,
            "numCiting": 230,
            "paperAbstract": {
                "fragments": [],
                "text": "From the Publisher: \nProbabilistic Reasoning in Intelligent Systems is a complete andaccessible account of the theoretical foundations and computational methods that underlie plausible reasoning under uncertainty. The author provides a coherent explication of probability as a language for reasoning with partial belief and offers a unifying perspective on other AI approaches to uncertainty, such as the Dempster-Shafer formalism, truth maintenance systems, and nonmonotonic logic. The author distinguishes syntactic and semantic approaches to uncertainty\u0097and offers techniques, based on belief networks, that provide a mechanism for making semantics-based systems operational. Specifically, network-propagation techniques serve as a mechanism for combining the theoretical coherence of probability theory with modern demands of reasoning-systems technology: modular declarative inputs, conceptually meaningful inferences, and parallel distributed computation. Application areas include diagnosis, forecasting, image interpretation, multi-sensor fusion, decision support systems, plan recognition, planning, speech recognition\u0097in short, almost every task requiring that conclusions be drawn from uncertain clues and incomplete information. \nProbabilistic Reasoning in Intelligent Systems will be of special interest to scholars and researchers in AI, decision theory, statistics, logic, philosophy, cognitive psychology, and the management sciences. Professionals in the areas of knowledge-based systems, operations research, engineering, and statistics will find theoretical and computational tools of immediate practical use. The book can also be used as an excellent text for graduate-level courses in AI, operations research, or applied probability."
            },
            "slug": "Probabilistic-reasoning-in-intelligent-systems-of-Pearl",
            "title": {
                "fragments": [],
                "text": "Probabilistic reasoning in intelligent systems - networks of plausible inference"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The author provides a coherent explication of probability as a language for reasoning with partial belief and offers a unifying perspective on other AI approaches to uncertainty, such as the Dempster-Shafer formalism, truth maintenance systems, and nonmonotonic logic."
            },
            "venue": {
                "fragments": [],
                "text": "Morgan Kaufmann series in representation and reasoning"
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3231485"
                        ],
                        "name": "S. Aji",
                        "slug": "S.-Aji",
                        "structuredName": {
                            "firstName": "Srinivas",
                            "lastName": "Aji",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Aji"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1723150"
                        ],
                        "name": "R. McEliece",
                        "slug": "R.-McEliece",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "McEliece",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. McEliece"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 98,
                                "start": 95
                            }
                        ],
                        "text": "Now, we simultaneously activate the nodes Since is a source node, it is not necessary to evaluate or the messages."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 41359839,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "61e625eb3ab78a2e00e941a85ed41e342d110e7c",
            "isKey": false,
            "numCitedBy": 16,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a general \"message-passing\" algorithm for distributing information in a graph. This algorithm may help us to understand the approximate correctness of both the Gallager-Tanner-Wiberg algorithm, and the turbo-decoding algorithm."
            },
            "slug": "A-general-algorithm-for-distributing-information-in-Aji-McEliece",
            "title": {
                "fragments": [],
                "text": "A general algorithm for distributing information in a graph"
            },
            "tldr": {
                "abstractSimilarityScore": 89,
                "text": "A general \"message-passing\" algorithm for distributing information in a graph that may help to understand the approximate correctness of both the Gallager-Tanner-Wiberg algorithm, and the turbo-decoding algorithm."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IEEE International Symposium on Information Theory"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145500409"
                        ],
                        "name": "G. Shafer",
                        "slug": "G.-Shafer",
                        "structuredName": {
                            "firstName": "Glenn",
                            "lastName": "Shafer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Shafer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1707788"
                        ],
                        "name": "P. P. Shenoy",
                        "slug": "P.-P.-Shenoy",
                        "structuredName": {
                            "firstName": "Prakash",
                            "lastName": "Shenoy",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. P. Shenoy"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 239,
                                "start": 235
                            }
                        ],
                        "text": ") Finally, having noticed the similarity between the Gallager\u2013Tanner\u2013Wiberg algorithm and Pearl\u2019s algorithm, Aji and McEliece [1], [2], relying heavily on the post-Pearl improvements and simplifications in the BP algorithm [29], [30], [52], [58], [59] have devised a simple algorithm for distributing information on a graph that is a simultaneous generalization of both algorithms, and which includes several other classic algorithms, including Viterbi\u2019s algorithm (which is already subsumed by Wiberg\u2019s algorithm in \u201cmin-sum\u201d form) and the FFT."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 535323,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "ac789d8e373cbb3260b2881d66fe00789adf291f",
            "isKey": false,
            "numCitedBy": 264,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we give a simple account of local computation of marginal probabilities when the joint probability distribution is given in factored form and the sets of variables involved in the factors form a hypertree. Previous expositions of such local computation have emphasized conditional probability. We believe this emphasis is misplaced. What is essential to local computation is a factorization. It is not essential that this factorization be interpreted in terms of conditional probabilities. The account given here avoids the divisions required by conditional probabilities and generalizes readily to alternative measures of subjective probability, such as Dempster-Shafer or Spohnian belief functions."
            },
            "slug": "Probability-propagation-Shafer-Shenoy",
            "title": {
                "fragments": [],
                "text": "Probability propagation"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The account given here avoids the divisions required by conditional probabilities and generalizes readily to alternative measures of subjective probability, such as Dempster-Shafer or Spohnian belief functions."
            },
            "venue": {
                "fragments": [],
                "text": "Annals of Mathematics and Artificial Intelligence"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143771578"
                        ],
                        "name": "A. Barbulescu",
                        "slug": "A.-Barbulescu",
                        "structuredName": {
                            "firstName": "Adrian",
                            "lastName": "Barbulescu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Barbulescu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "101708260"
                        ],
                        "name": "S. Pietrobon",
                        "slug": "S.-Pietrobon",
                        "structuredName": {
                            "firstName": "S.",
                            "lastName": "Pietrobon",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Pietrobon"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 202,
                                "start": 199
                            }
                        ],
                        "text": "Many of the structural properties of turbo codes have now been put on a firm theoretical footing [7], [18], [20], [21], [27], [45], and several innovative variations on the turbo theme have appeared [5], [8], [9], [12], [27], [48]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 59076443,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ef1a32376fb8148523dca5804abea50de2fefb2b",
            "isKey": false,
            "numCitedBy": 28,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "A new bandwidth efficient interleaver is described for turbo codes when used to decode short frames of data using the MAP algorithm. Applications in rate compatible turbo codes and encryption are presented."
            },
            "slug": "Interleaver-design-for-three-dimensional-turbo-Barbulescu-Pietrobon",
            "title": {
                "fragments": [],
                "text": "Interleaver design for three dimensional turbo codes"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "A new bandwidth efficient interleaver is described for turbo codes when used to decode short frames of data using the MAP algorithm."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of 1995 IEEE International Symposium on Information Theory"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2050895"
                        ],
                        "name": "S. Lauritzen",
                        "slug": "S.-Lauritzen",
                        "structuredName": {
                            "firstName": "Steffen",
                            "lastName": "Lauritzen",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Lauritzen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48616434"
                        ],
                        "name": "D. Spiegelhalter",
                        "slug": "D.-Spiegelhalter",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Spiegelhalter",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Spiegelhalter"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 74,
                                "start": 70
                            }
                        ],
                        "text": "The idea behind the \u201cBayesian belief network\u201d approach [28], [51] to this inference problem is to exploit any \u201cpartial independencies\u201d which may exist among the \u2019s to simplify belief updating."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 58792451,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "0a3767909649cf31d32e087693d93171af28ebe0",
            "isKey": false,
            "numCitedBy": 4303,
            "numCiting": 126,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Local-computations-with-probabilities-on-graphical-Lauritzen-Spiegelhalter",
            "title": {
                "fragments": [],
                "text": "Local computations with probabilities on graphical structures and their application to expert systems"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2050895"
                        ],
                        "name": "S. Lauritzen",
                        "slug": "S.-Lauritzen",
                        "structuredName": {
                            "firstName": "Steffen",
                            "lastName": "Lauritzen",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Lauritzen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144845491"
                        ],
                        "name": "A. Dawid",
                        "slug": "A.-Dawid",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Dawid",
                            "middleNames": [
                                "Philip"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Dawid"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144238498"
                        ],
                        "name": "B. N. Larsen",
                        "slug": "B.-N.-Larsen",
                        "structuredName": {
                            "firstName": "B.",
                            "lastName": "Larsen",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. N. Larsen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "74208271"
                        ],
                        "name": "H.-G. Leimer",
                        "slug": "H.-G.-Leimer",
                        "structuredName": {
                            "firstName": "H.-G.",
                            "lastName": "Leimer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H.-G. Leimer"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 138,
                                "start": 134
                            }
                        ],
                        "text": "2, in which the individual codes and are indeed relatively weak (but have a low-complexity decoding algorithm), in such a way that that the overall code is very powerful."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 20450895,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "f78884604e3fb89b1fb24d2a9403191dc9e63bd3",
            "isKey": false,
            "numCitedBy": 572,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "We investigate directed Markov fields over finite graphs without positivity assumptions on the densities involved. A criterion for conditional independence of two groups of variables given a third is given and named as the directed, global Markov property. We give a simple proof of the fact that the directed, local Markov property and directed, global Markov property are equivalent and \u2013 in the case of absolute continuity w. r. t. a product measure \u2013 equivalent to the recursive factorization of densities. It is argued that our criterion is easy to use, it is sharper than that given by Kiiveri, Speed, and Carlin and equivalent to that of Pearl. It follows that our criterion cannot be sharpened."
            },
            "slug": "Independence-properties-of-directed-markov-fields-Lauritzen-Dawid",
            "title": {
                "fragments": [],
                "text": "Independence properties of directed markov fields"
            },
            "tldr": {
                "abstractSimilarityScore": 55,
                "text": "A criterion for conditional independence of two groups of variables given a third is given and named as the directed, global Markov property and it is argued that this criterion is easy to use, it is sharper than that given by Kiiveri, Speed, and Carlin and equivalent to that of Pearl."
            },
            "venue": {
                "fragments": [],
                "text": "Networks"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2932960"
                        ],
                        "name": "Ross D. Shachter",
                        "slug": "Ross-D.-Shachter",
                        "structuredName": {
                            "firstName": "Ross",
                            "lastName": "Shachter",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ross D. Shachter"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 161,
                                "start": 157
                            }
                        ],
                        "text": "Theorem 3.1: If the components of are assumed to be independent, with for\nthen\nif is odd\nif is even (3.10)\nProof: We consider the case odd, the proof for even being essentially the same."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 207241260,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1eb1583c2d2f7f075075cc54b0ef1640d2b7da4b",
            "isKey": true,
            "numCitedBy": 559,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "An influence diagram is a network representation for probabilistic and decision analysis models. The nodes correspond to variables which can be constants, uncertain quantities, decisions, or objectives. The arcs reveal the probabilistic dependence of the uncertain quantities and the information available at the time of the decisions. The detailed data about the variables are stored within the nodes, so the diagram graph is compact and focuses attention on the relationships among the variables. Influence diagrams are effective communication tools and recent developments also allow them to be used for analysis. We develop algorithms to address questions of inference within a probabilistic model represented as an influence diagram. We use the conditional independence implied by the diagram's structure to determine the information needed to solve a given problem. When there is enough information we can solve it, exploiting that conditional independence. These same results are applied to problems of decision analysis. This methodology allows the construction of computer tools to maintain and evaluate complex models."
            },
            "slug": "Probabilistic-Inference-and-Influence-Diagrams-Shachter",
            "title": {
                "fragments": [],
                "text": "Probabilistic Inference and Influence Diagrams"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This work develops algorithms to address questions of inference within a probabilistic model represented as an influence diagram and uses the conditional independence implied by the diagram's structure to determine the information needed to solve a given problem."
            },
            "venue": {
                "fragments": [],
                "text": "Oper. Res."
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145430701"
                        ],
                        "name": "J. Pearl",
                        "slug": "J.-Pearl",
                        "structuredName": {
                            "firstName": "Judea",
                            "lastName": "Pearl",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Pearl"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "However, since it is the object of this paper to study the decoding algorithm without regard to the resulting performance, we shall not discuss the constructive aspect of turbo codes further."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14936636,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "99485775cce4c1afa7361a7fcbd3c9d362309554",
            "isKey": false,
            "numCitedBy": 886,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents generalizations of Bayes likelihood-ratio updating rule which facilitate an asynchronous propagation of the impacts of new beliefs and/or new evidence in hierarchically organized inference structures with multi-hypotheses variables. The computational scheme proposed specifies a set of belief parameters, communication messages and updating rules which guarantee that the diffusion of updated beliefs is accomplished in a single pass and complies with the tenets of Bayes calculus."
            },
            "slug": "Reverend-Bayes-on-Inference-Engines:-A-Distributed-Pearl",
            "title": {
                "fragments": [],
                "text": "Reverend Bayes on Inference Engines: A Distributed Hierarchical Approach"
            },
            "tldr": {
                "abstractSimilarityScore": 92,
                "text": "Generalizations of Bayes likelihood-ratio updating rule are presented which facilitate an asynchronous propagation of the impacts of new beliefs and/or new evidence in hierarchically organized inference structures with multi-hypotheses variables."
            },
            "venue": {
                "fragments": [],
                "text": "AAAI"
            },
            "year": 1982
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48616434"
                        ],
                        "name": "D. Spiegelhalter",
                        "slug": "D.-Spiegelhalter",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Spiegelhalter",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Spiegelhalter"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144845491"
                        ],
                        "name": "A. Dawid",
                        "slug": "A.-Dawid",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Dawid",
                            "middleNames": [
                                "Philip"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Dawid"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2050895"
                        ],
                        "name": "S. Lauritzen",
                        "slug": "S.-Lauritzen",
                        "structuredName": {
                            "firstName": "Steffen",
                            "lastName": "Lauritzen",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Lauritzen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34631309"
                        ],
                        "name": "R. Cowell",
                        "slug": "R.-Cowell",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Cowell",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Cowell"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 105,
                                "start": 101
                            }
                        ],
                        "text": "By line 2 of Table I\n(6.4)\nby (6.2) and (6.3)\n(6.5)\nSimilarly, by line 5 of Table I\n(6.6)\nby (6.1) and (6.5)\n(6.7)\nIn vector notation, (6.7) is equivalent to\nwhich appears in line 2 of Table III."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 86367536,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6acd45949c2b167928211c562c8d9c445651f1ef",
            "isKey": true,
            "numCitedBy": 777,
            "numCiting": 113,
            "paperAbstract": {
                "fragments": [],
                "text": "We review recent developments in applying Bayesian probabilistic and statistical ideas to expert systems. Using a real, moderately complex, medical example we illustrate how qualitative and quantitative knowledge can be represented within a directed graphical model, generally known as a belief network in this context. Exact probabilistic inference on individual cases is possible using a general propagation procedure. When data on a series of cases are available, Bayesian statistical techniques can be used for updating the original subjective quantitative inputs, and we present a sets of diagnostics for identifying conflicts between the data and the prior specification. A model comparison procedure is explored, and a number of links made with mainstream statistical methods. Details are given on the use of Dirichlet prior distributions for learning about parameters and the process of transforming the original graphical model to a junction tree as the basis for efficient computation."
            },
            "slug": "Bayesian-analysis-in-expert-systems-Spiegelhalter-Dawid",
            "title": {
                "fragments": [],
                "text": "Bayesian analysis in expert systems"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "Using a real, moderately complex, medical example, it is illustrated how qualitative and quantitative knowledge can be represented within a directed graphical model, generally known as a belief network in this context."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48616434"
                        ],
                        "name": "D. Spiegelhalter",
                        "slug": "D.-Spiegelhalter",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Spiegelhalter",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Spiegelhalter"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2050895"
                        ],
                        "name": "S. Lauritzen",
                        "slug": "S.-Lauritzen",
                        "structuredName": {
                            "firstName": "Steffen",
                            "lastName": "Lauritzen",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Lauritzen"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 99,
                                "start": 95
                            }
                        ],
                        "text": "By line 2 of Table I\n(6.4)\nby (6.2) and (6.3)\n(6.5)\nSimilarly, by line 5 of Table I\n(6.6)\nby (6.1) and (6.5)\n(6.7)\nIn vector notation, (6.7) is equivalent to\nwhich appears in line 2 of Table III."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 10739577,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "dcce2a3564685657c23d1afa00155c03560e76ac",
            "isKey": true,
            "numCitedBy": 615,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "A directed acyclic graph or influence diagram is frequently used as a representation for qualitative knowledge in some domains in which expert system techniques have been applied, and conditional probability tables on appropriate sets of variables form the quantitative part of the accumulated experience. It is shown how one can introduce imprecision into such probabilities as a data base of cases accumulates. By exploiting the graphical structure, the updating can be performed locally, either approximately or exactly, and the setup makes it possible to take advantage of a range of well-established statistical techniques. As examples we discuss discrete models, models based on Dirichlet distributions and models of the logistic regression type."
            },
            "slug": "Sequential-updating-of-conditional-probabilities-on-Spiegelhalter-Lauritzen",
            "title": {
                "fragments": [],
                "text": "Sequential updating of conditional probabilities on directed graphical structures"
            },
            "tldr": {
                "abstractSimilarityScore": 37,
                "text": "It is shown how one can introduce imprecision into such probabilities as a data base of cases accumulates and how to take advantage of a range of well-established statistical techniques."
            },
            "venue": {
                "fragments": [],
                "text": "Networks"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145980949"
                        ],
                        "name": "S. Verd\u00fa",
                        "slug": "S.-Verd\u00fa",
                        "structuredName": {
                            "firstName": "Sergio",
                            "lastName": "Verd\u00fa",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Verd\u00fa"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40228025"
                        ],
                        "name": "V. Poor",
                        "slug": "V.-Poor",
                        "structuredName": {
                            "firstName": "Vincent",
                            "lastName": "Poor",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Poor"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 152,
                                "start": 148
                            }
                        ],
                        "text": "\u2026X\u2019s here to denote arbitrary random variables, and hope no confusion will occur.\nor To simplify notation, we assume and Then we have\n(4.1)\nIf can assume different values, then computing the sum in (4.1) for each possible value of requires additions, which is impractical unless and the \u2019s are\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 121014287,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "0a0a5b8eff2a7039b867045bbb58392751d3e4d1",
            "isKey": true,
            "numCitedBy": 88,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "The unifying purpose of the abstract dynamic programming models is to find sufficient conditions on the recursive definition of the objective function that guarantee the validity of the dynamic programming iteration. This paper presents backward, forward, and backward-forward models that weaken previous sufficient conditions and that include, but are not restricted to, optimization problems. The backward-forward model is devoted to the simultaneous solution of a collection of interrelated sequential problems based on the independent computation of a cost-to-arrive function and a cost-to-go function. Several extremization and nonextremization problems illustrate the applicability of the proposed models."
            },
            "slug": "Abstract-dynamic-programming-models-under-Verd\u00fa-Poor",
            "title": {
                "fragments": [],
                "text": "Abstract dynamic programming models under commutativity conditions"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712517"
                        ],
                        "name": "L. Rabiner",
                        "slug": "L.-Rabiner",
                        "structuredName": {
                            "firstName": "Lawrence",
                            "lastName": "Rabiner",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Rabiner"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 7,
                                "start": 3
                            }
                        ],
                        "text": "We use upper case X\u2019s here to denote arbitrary random variables, and hope no confusion will occur.\nor To simplify notation, we assume and Then we have\n(4.1)\nIf can assume different values, then computing the sum in (4.1) for each possible value of requires additions, which is impractical unless and\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 13618539,
            "fieldsOfStudy": [
                "Geology"
            ],
            "id": "8fe2ea0a67954f1380b3387e3262f1cdb9f9b3e5",
            "isKey": true,
            "numCitedBy": 24804,
            "numCiting": 98,
            "paperAbstract": {
                "fragments": [],
                "text": "The fabric comprises a novel type of netting which will have particular utility in screening out mosquitoes and like insects and pests. The fabric is defined of voids having depth as well as width and length. The fabric is usable as a material from which to form clothing for wear, or bed coverings, or sleeping bags, etc., besides use simply as a netting."
            },
            "slug": "A-Tutorial-on-Hidden-Markov-Models-and-Selected-Rabiner",
            "title": {
                "fragments": [],
                "text": "A Tutorial on Hidden Markov Models and Selected Applications"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "The fabric comprises a novel type of netting which will have particular utility in screening out mosquitoes and like insects and pests."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1989
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 89,
                                "start": 85
                            }
                        ],
                        "text": "More generally, the partial independencies can be described by a directed acyclic graph, or DAG."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 55,
                                "start": 51
                            }
                        ],
                        "text": "We assume that the codeword is transmitted over a noisy channel with transition probabilities and received as where is the portion of corresponding to the systematic part of the codeword and is the portion corresponding to the codeword fragment We assume further that the channel is memoryless,\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 100,
                                "start": 96
                            }
                        ],
                        "text": "With the same setup as in Section II, suppose we have two systematic encodings of\nOne way to combine and into a single code is via the mapping\nwhich is called the parallel concatenation of and or the turbo code formed by combining and\nOnce again, we assume that the codeword is transmitted through a\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 88,
                                "start": 84
                            }
                        ],
                        "text": "(This notation will also prove useful in Section V, where we shall use it to describe Pearl\u2019s algorithm\u2014see Table I, line 6.)"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Near Shannon limit error-correcting coding: Turbo codes"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. 1993 Int. Conf. Commun"
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 81,
                                "start": 77
                            }
                        ],
                        "text": "By line 2 of Table I\n(6.4)\nby (6.2) and (6.3)\n(6.5)\nSimilarly, by line 5 of Table I\n(6.6)\nby (6.1) and (6.5)\n(6.7)\nIn vector notation, (6.7) is equivalent to\nwhich appears in line 2 of Table III."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Bayesian updating in recursive graphical models by local computations"
            },
            "venue": {
                "fragments": [],
                "text": "Computational Statist. Quart"
            },
            "year": 1990
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 111,
                                "start": 107
                            }
                        ],
                        "text": "To do so, we take and define a kernel as\n2 We assume that \u201cadjacent\u201d takes precedence over \u201ccircle\u201d in order to minimize the use of parentheses.\nwhere the codeword fragment is a deterministic function of Then Lemma 2.2 can be summarized as follows:\n(2.9)\nwhere and"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 24,
                                "start": 20
                            }
                        ],
                        "text": "Let\nbe a function mapping into In other words, is a vector of real-valued functions, and if\nthen\nNow, suppose that is a real-valued function defined on the set which we call a kernel."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The turbo decision algorithm"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. 33rd Allerton Conf. Commun., Contr., Computing"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 49,
                                "start": 45
                            }
                        ],
                        "text": "5 We have already used upper case X\u2019s to denote codeword components, for example, (2.1)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "bit decoding of convolutional codes"
            },
            "venue": {
                "fragments": [],
                "text": "Abstr. Papers"
            },
            "year": 1972
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39361090"
                        ],
                        "name": "L. Baum",
                        "slug": "L.-Baum",
                        "structuredName": {
                            "firstName": "Leonard",
                            "lastName": "Baum",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Baum"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "101775270"
                        ],
                        "name": "T. Petrie",
                        "slug": "T.-Petrie",
                        "structuredName": {
                            "firstName": "Ted",
                            "lastName": "Petrie",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Petrie"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 214,
                                "start": 211
                            }
                        ],
                        "text": "\u2026the a posteriori or conditional probabilities for all\nThe brute force approach to computing is to sum over all of the terms of which do not involve either\n4 As we shall see in Section IV, the BCJR algorithm itself, and the many variations of it, are themselves special cases of Pearl\u2019s algorithm."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 120208815,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "603bdbb17ba1f909280405a076455ac4f878fbf3",
            "isKey": false,
            "numCitedBy": 2773,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Statistical-Inference-for-Probabilistic-Functions-Baum-Petrie",
            "title": {
                "fragments": [],
                "text": "Statistical Inference for Probabilistic Functions of Finite State Markov Chains"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1966
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "corpusId": 62282319,
            "fieldsOfStudy": [],
            "id": "d87a423334afb20747c367b2d907069d7f3b4ed2",
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The viterbi algorithm"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1973
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "102278025"
                        ],
                        "name": "Ross Kindermann",
                        "slug": "Ross-Kindermann",
                        "structuredName": {
                            "firstName": "Ross",
                            "lastName": "Kindermann",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ross Kindermann"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34296841"
                        ],
                        "name": "J. Snell",
                        "slug": "J.-Snell",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Snell",
                            "middleNames": [
                                "Laurie"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Snell"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 144,
                                "start": 140
                            }
                        ],
                        "text": "2, in which the individual codes and are indeed relatively weak (but have a low-complexity decoding algorithm), in such a way that that the overall code is very powerful."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 117120661,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "870234e41be333eb8ab128cbd1ca1623838b8d7f",
            "isKey": false,
            "numCitedBy": 1314,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Markov-Random-Fields-and-Their-Applications-Kindermann-Snell",
            "title": {
                "fragments": [],
                "text": "Markov Random Fields and Their Applications"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1980
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "However, since it is the object of this paper to study the decoding algorithm without regard to the resulting performance, we shall not discuss the constructive aspect of turbo codes further."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A computational model for combined causal and diagnostic reasoning in inference systems"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. 8th Int. Joint Conf. AI (IJCAI83)"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "7, which is a loopy Bayesian network appropriate for the turbo decoding problem.9"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Near capacity codecs for the Gaussian channel based on lowdensity generator matrices"
            },
            "venue": {
                "fragments": [],
                "text": "Near capacity codecs for the Gaussian channel based on lowdensity generator matrices"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 105,
                                "start": 101
                            }
                        ],
                        "text": "It appeared explicitly as an algorithm for tracking the states of a Markov chain in the early 1970\u2019s [40], [4] (see also the survey papers [47] and [49])."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "M.A.P. bit decoding of convolutional codes"
            },
            "venue": {
                "fragments": [],
                "text": "Abstr. Papers, 1972 IEEE Int. Symp. Inform. Theory, Asilomar, CA, Jan. 1972, p. 90."
            },
            "year": 1972
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 99,
                                "start": 96
                            }
                        ],
                        "text": "(This notation will also prove useful in Section V, where we shall use it to describe Pearl\u2019s algorithm\u2014see Table I, line 6.)"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The TURBO coding scheme, \" unpublished manuscript distributed at"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Int. Symp. Inform. Theory"
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 57,
                                "start": 54
                            }
                        ],
                        "text": "[10], but which was perhaps explained more lucidly in [3], [18], or [50]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 57,
                                "start": 54
                            }
                        ],
                        "text": "The celebrated \u201cturbo decoding algorithm\u201d [10], [50], [3] is an iterative approximation to the optimal beliefs in (3."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The TURBO coding scheme"
            },
            "venue": {
                "fragments": [],
                "text": "unpublished manuscript distributed at 1994 IEEE Int. Symp. Inform. Theory, Trondheim, Norway, June 1994."
            },
            "year": 1994
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 50,
            "methodology": 10
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 64,
        "totalPages": 7
    },
    "page_url": "https://www.semanticscholar.org/paper/Turbo-Decoding-as-an-Instance-of-Pearl's-\"Belief-McEliece-Mackay/26d953005dd08a863c157b528bbabdf5671d18b6?sort=total-citations"
}