{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2544946"
                        ],
                        "name": "K. Seymore",
                        "slug": "K.-Seymore",
                        "structuredName": {
                            "firstName": "Kristie",
                            "lastName": "Seymore",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Seymore"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "88507334"
                        ],
                        "name": "R. Rosenfeld",
                        "slug": "R.-Rosenfeld",
                        "structuredName": {
                            "firstName": "Roni",
                            "lastName": "Rosenfeld",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Rosenfeld"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 160,
                                "start": 146
                            }
                        ],
                        "text": "Experimental results show that this technique finds HMM models that almost always out-perform a fixed model, and have superior average performance across tasks."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 69,
                                "start": 50
                            }
                        ],
                        "text": "Furthermore, human intuitions do not always correspond to structures that make the best use of HMM potential."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1300961,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a36835241b44cda9253d86ddaf67f84ffc1d9a89",
            "isKey": false,
            "numCitedBy": 470,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "Statistical machine learning techniques, while well proven in fields such as speech recognition, are just beginning to be applied to the information extraction domain. We explore the use of hidden Markov models for information extraction tasks, specifically focusing on how to learn model structure from data and how to make the best use of labeled and unlabeled data. We show that a manually-constructed model that contains multiple states per extraction field outperforms a model with one state per field, and discuss strategies for learning the model structure automatically from data. We also demonstrate that the use of distantly-labeled data to set model parameters provides a significant improvement in extraction accuracy. Our models are applied to the task of extracting important fields from the headers of computer science research papers, and achieve an extraction accuracy of 92.9%."
            },
            "slug": "Learning-Hidden-Markov-Model-Structure-for-Seymore-Rosenfeld",
            "title": {
                "fragments": [],
                "text": "Learning Hidden Markov Model Structure for Information Extraction"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "It is demonstrated that a manually-constructed model that contains multiple states per extraction field outperforms a model with one state per field, and the use of distantly-labeled data to set model parameters provides a significant improvement in extraction accuracy."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1789644"
                        ],
                        "name": "T. Leek",
                        "slug": "T.-Leek",
                        "structuredName": {
                            "firstName": "Tim",
                            "lastName": "Leek",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Leek"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 154,
                                "start": 145
                            }
                        ],
                        "text": "Introduction The Internet makes available a tremendous amount of text that has been generated for human consumption; unfortunately, this information is not easily manipulated or analyzed by computers."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 408,
                                "start": 404
                            }
                        ],
                        "text": "HMMs have been applied successfully to many sub-domains of information extraction: the named entity extraction task (Bikel et al. 1997); to the task of recovering the sequence of a set of entities occurring in close proximity (dense extraction) (Seymoreet al. 1999); as well as thesparse extraction task, in which the object is to extract relevant phrases from documents containing much irrelevant text (Leek 1997; Freitag and McCallum 1999)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 270,
                                "start": 261
                            }
                        ],
                        "text": "\u2026task of recovering the sequence of a set of entities occurring in close proximity (dense extraction) (Seymoreet al. 1999); as well as thesparse extraction task, in which the object is to extract relevant phrases from documents containing much irrelevant text (Leek 1997; Freitag and McCallum 1999)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 27,
                                "start": 18
                            }
                        ],
                        "text": "The HMMs in Leek (Leek 1997) are carefully designed\u2014both state-transition structure and emission distributions\u2014to model the syntactic constraints of the particular extraction problem."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 15,
                                "start": 11
                            }
                        ],
                        "text": "Timothy R. Leek."
                    },
                    "intents": []
                }
            ],
            "corpusId": 59798638,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c11fb8460b4e2e8cf76cc3abe1dc3eaf153b67d9",
            "isKey": true,
            "numCitedBy": 137,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "OF THE THESIS Information Extraction Using Hidden Markov Models by Timothy Robert Leek Master of Science in Computer Science University of California, San Diego, 1997 Professor Charles Peter Elkan, Chair This thesis shows how to design and tune a hidden Markov model to extract factual information from a corpus of machine-readable English prose. In particular, the thesis presents a HMM that classi es and parses natural language assertions about genes being located at particular positions on chromosomes. The facts extracted by this HMM can be inserted into biological databases. The HMM is trained on a small set of sentence fragments chosen from the collected scienti c abstracts in the OMIM (On-Line Mendelian Inheritance in Man) database and judged to contain the target binary relationship between gene names and gene locations. Given a novel sentence, all contiguous fragments are ranked by log-odds score, i.e. the log of the ratio of the probability of the fragment according to the target HMM to that according to a \\null\" HMM trained on all OMIM sentences. The most probable path through the HMM gives bindings for the annotations with precision as high as 80%. In contrast with traditional natural language processing methods, this stochastic approach makes no use either of part-of-speech taggers or dictionaries, instead employing non-emitting states to assemble modules roughly corresponding to noun, verb, and prepostional phrases. Algorithms for reestimating parameters for HMMs with non-emitting states are presented in detail. The ability to tolerate new words and recognize a wide variety of syntactic forms arises from the judicious use of \\gap\" states. v Chapter I Good Facts Are Hard to Find Finding facts in English prose is a task that humans are good at and computers are bad at. However, humans cannot stand to spend more than a few minutes at a time occupied with such drudgery. In this respect, nding facts is unlike a host of the other jobs computers are currently hopeless at, like telling a joke, riding a bike, and cooking a dinner. While there is no pressing need for computers to be good at those things, it is already of paramount importance that computers be pro cient at nding information with precision in the proliferating archives of electronic text available on the Internet and elsewhere. The state of the art in information retrieval technology is of limited use in this application. Standard boolean searching, vectorbased approaches and latent semantic indexing are geared more toward open-ended exploration than toward the targeted, detailed subsentence processing necessary for the fact nding or information extraction task. Since these approaches discard syntax, a large class of targets, in which the relationships between groups of words are important, must be fundamentally beyond them. The critical noun and verb groups of a fact can only be found by doing some kind of parsing. Information extraction is in most cases what people really want to do when they rst set about searching text, i.e. before they lower their sights to correspond to available tools. But this does not mean that nothing less than full-blown NLP (natural language processing) will satisfy. There are many real-world text searching 1 2 tasks that absolutely require syntactic information and yet are restricted enough to be tractable. An historian might want to locate passages in the Virginia colony records mentioning the \\event\" of a slave running away. The words slave, run, and away, all very common words, and their various synonyms used in an unconstrained search would return much dross. To nd this fact with precision we need to place constraints upon the arrangement of the words in the sentence; we need to limit the search with syntax. For instance, one might require that when two groups of words corresponding to slave and run appear in a sentence, that the slave is in fact the one doing the running. Similar examples of what we call fact searching are commonplace in most domains. A market analyst might want to scan the Wall Street Journal and pick out all mentions of corporate management changes. And a geneticist would be thrilled to be able to tease out of scienti c abstracts facts mapping genes to speci c locations on chromosomes. Historically, the eld of information extraction has employed discrete manipulations in order to process sentences into the critical noun and verb groups. An incoming sentence is tagged for part-of-speech and then handed o to a scaled-down parser or DFA (deterministic nite automaton) which uses local syntax to decide if the elements of a fact are present and to divide the sentence up into logical elements. Recent advances in statistical natural language processing have been applied to this problem but typically only in an ancillary role, e.g. in constructing dictionaries [17] and tagging words for part-of-speech [4]. The main processing engine remains combinatorial in avor. Systems like FASTUS [8] and CIRCUS [14] do surprisingly well, considering the di culty of the task, achieving precision and recall of better than 80%. But they require hand-built grammars or dictionaries of extraction patterns in order to attain this level of performance. A notable exception is the LIEP [9] system which learns to generalize extraction patterns from training examples. We have chosen to pursue a uni ed stochastic approach to the information extraction task, modeling sentence fragments containing the target fact with a hidden Markov model (HMM) which we use both to decide if a candidate sentence fragment 3 contains the fact and also to identify the important elements or slot llers in the fact. An HMM trained to recognize a small set of representative sentence fragments di ers radically from a DFA or discrete pattern matcher designed for the same task in that it outputs a probability. Unlike a DFA, an HMM will accept any sequence of words with non-zero probability. The probability it computes (after some corrections for sentence length and background frequencies of words) varies gracefully between the extremes of predicting extremely low probability for sequences that tend not to contain the fact to predicting high probability for ones that tend to contain it. There is no need, if we use an HMM to nd and process facts, to employ heuristics in order to rank and choose between competing explanations for a sentence; symbolic approaches often do so [9]. The probability the HMM computes is meaningful information we can use directly to reason about candidate facts in principled ways that submit to analysis. The HMM is a very compact and exible representation for the information extraction task which seems to be less reliant upon human engineering and prior knowledge than non-probabilistic approaches. This thesis will discuss our e orts to construct a model for a binary relationship between gene names and gene locations, as found in a variety of syntactic forms in scienti c abstracts. The model is structured hierarchically: at the top level states are collected into modules corresponding to noun or verb groups, whereas at the bottom level, in some cases, states function entirely deterministically, employing DFAs to recognize commonly occurring patterns. The HMM consists of only 64 states with an average of 3 transitions each, and explicitly mentions less than 150 words. When deploying the model to nd facts in novel sentences, no attempt is made to tag for part-of-speech. \\Gap\" states, which assign emission probability according to word frequency in the entire corpus, permit the HMM to recognize disconnected segments of a fact and tolerate new words. Unknown words, if they appear in the right local context, are accepted by the HMM essentially without penalty. So while the list of words likely to participate in forming a gene name or gene location is long and populated by words both common and rare to the corpus our approach is competent at correctly identifying even unknown words as 4 long as they appear anked by other words that serve to index the fact well. The accuracy of this HMM approach to information extraction, in the context of the gene name|location fact, is on par with symbolic approaches. This thesis is organized as follows. We begin with a description of the gene name|location information extraction task. Next, we present the modular HMM architecture constructed for this task, motivating our choice of null or background model and demonstrating the discriminatory power it adds to this approach. A brief technical discussion comes next, of the precise formulae used to reestimate parameters for an HMM with non-emitting states. Then we provide implementation and optimization details, followed by training and testing performance. We conclude with some remarks on the use of prior knowledge and ideas for future work. Chapter II Automatic Annotation Generation We consider the question of nding facts in unrestricted prose in the context of lling in slots in a database of facts about genes. The slots in the database correspond to biological entities. These are described by single words or simple phrases, three examples of which might be the name of a gene, some speci cation of its location, and some list of diseases in which it is known to be involved. An example pair of acceptable entries is SLOT ENTRY Gene Name: (The gene encoding BARK2) Gene Location: (mouse chromosome 5) which we might nd buried in a sentence like The gene encoding BARK2 mapped to mouse chromosome 5, whereas that encoding BARK1 was localized to mouse chromosome 19. This is valuable information that is available nowhere except in the published literature. Specialized databases like SwissProt and GenBank do not contain these kinds of associations. So there is interest in developing automated systems for lling in these slots. In order to populate these slots, we must locate and correctly analyze binary (or perhaps even ternary and higher) relations between likely ele"
            },
            "slug": "Information-Extraction-Using-Hidden-Markov-Models-Leek",
            "title": {
                "fragments": [],
                "text": "Information Extraction Using Hidden Markov Models"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This thesis shows how to design and tune a hidden Markov model to extract factual information from a corpus of machine-readable English prose and presents a HMM that classifies and parses natural language assertions about genes being located at particular positions on chromosomes."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145325640"
                        ],
                        "name": "P. Lockwood",
                        "slug": "P.-Lockwood",
                        "structuredName": {
                            "firstName": "Philip",
                            "lastName": "Lockwood",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Lockwood"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47759189"
                        ],
                        "name": "M. Blanchet",
                        "slug": "M.-Blanchet",
                        "structuredName": {
                            "firstName": "Marc",
                            "lastName": "Blanchet",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Blanchet"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 117,
                                "start": 91
                            }
                        ],
                        "text": "Unfortunately the approach of building structures by hand does not scale to large corpora and is difficult to follow in practice."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 161,
                                "start": 135
                            }
                        ],
                        "text": "The idea of automatic structure selection for HMMs is not new (Stolcke and Omohundro 1994; Carrasco and Oncina 1994; Vaskoet al. 1997; Lockwood and Blanchet 1993), and it has been applied to the problem of dense extraction (Seymoreet al. 1999)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 49,
                                "start": 23
                            }
                        ],
                        "text": "Lockwood and Blanchet (Lockwood and Blanchet 1993) propose a method that applies incremental patches to a circuit-free model for speech processing."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 33,
                                "start": 25
                            }
                        ],
                        "text": "Philip Lockwood and Marc Blanchet."
                    },
                    "intents": []
                }
            ],
            "corpusId": 57374089,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ef93d44ad1df8a5c417b3f74c9b2f96169f2873e",
            "isKey": true,
            "numCitedBy": 15,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "The DIHMM algorithm performs a robust estimation of the HMM topology and parameters. It allows a better control of the speech variability within each state of the HMM, yielding enhanced estimates. The DIHMM parameters (number of states, structure of the Gaussian mixture density functions, transition matrix) are obtained from the training data via probabilistic grammatical inference techniques welded in a Viterbi-like training framework. Experimental results on various databases indicate a global improvement of the recognition rates in adverse environments; the results averaged on three databases show an increase of 12.8% on raw data and 2.4% when using NSS (nonlinear spectral subtraction).<<ETX>>"
            },
            "slug": "An-algorithm-for-the-dynamic-inference-of-hidden-Lockwood-Blanchet",
            "title": {
                "fragments": [],
                "text": "An algorithm for the dynamic inference of hidden Markov models (DIHMM)"
            },
            "tldr": {
                "abstractSimilarityScore": 64,
                "text": "The DIHMM algorithm performs a robust estimation of the HMM topology and parameters, yielding enhanced estimates that indicate a global improvement of the recognition rates in adverse environments."
            },
            "venue": {
                "fragments": [],
                "text": "1993 IEEE International Conference on Acoustics, Speech, and Signal Processing"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2657884"
                        ],
                        "name": "M. Cal\u00ed",
                        "slug": "M.-Cal\u00ed",
                        "structuredName": {
                            "firstName": "Marco",
                            "lastName": "Cal\u00ed",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Cal\u00ed"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 16,
                                "start": 10
                            }
                        ],
                        "text": "Rafael C. Carrasco and Jose Oncina."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 19,
                                "start": 13
                            }
                        ],
                        "text": "In Rafael C. Carrasco and Jose Oncina, editors,G ammatical Inference and Applications: Second International Colloquium, ICGI-94."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 195,
                                "start": 189
                            }
                        ],
                        "text": "Closely related are the state merging algorithms that have been investigated for some years in the field of grammatical inference, particularly those involving stochastic regular grammars (Carrasco and Oncina 1994)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 108,
                                "start": 97
                            }
                        ],
                        "text": "The idea of automatic structure selection for HMMs is not new (Stolcke and Omohundro 1994; Carrasco and Oncina 1994; Vaskoet al. 1997; Lockwood and Blanchet 1993), and it has been applied to the problem of dense extraction (Seymoreet al. 1999)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 8126183,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6958e58fcaf3f45572bc4e7cf7d45798f0cad175",
            "isKey": true,
            "numCitedBy": 112,
            "numCiting": 129,
            "paperAbstract": {
                "fragments": [],
                "text": "The recent growth of online information available in the form of natural language documents creates a greater need for computing systems with the ability to process those documents to simplify access to the information. One type of processing appropriate for many tasks is information extraction, a type of text skimming that retrieves speci c types of information from text. Although information extraction systems have existed for two decades, these systems have generally been built by hand and contain domain speci c information, making them di cult to port to other domains. A few researchers have begun to apply machine learning to information extraction tasks, but most of this work has involved applying learning to pieces of a much larger system. This paper presents a novel rule representation speci c to natural language and a learning system, Rapier, which learns information extraction rules. Rapier takes pairs of documents and lled templates indicating the information to be extracted and learns patterns to extract llers for the slots in the template. This proposal presents initial results on a small corpus of computer-related job postings with a preliminary version of Rapier. Future research will involve several enhancements to Rapier as well as more thorough testing on several domains and extension to additional natural language processing tasks. We intend to extend the rule representation and algorithm to allow for more types of constraints than are currently supported. We also plan to incorporate active learning, or sample selection, methods, speci cally query by committee, into Rapier. These methods have the potential to substantially reduce the amount of annotation required. We will explore the issue of distinguishing relevant and irrelevant messages, since currently Rapier only extracts from the any messages given to it, assuming that all are relevant. We also intend to run much larger tests with Rapier on multiple domains including the terrorism domain from the third and fourth Message Uncderstanding Conferences, which will allow comparison against other systems. Finally, we plan to demonstrate the generality of Rapier`s representation and algorithm by applying it to other natural language processing tasks such as word sense disambiguation."
            },
            "slug": "Relational-learning-techniques-for-natural-language-Cal\u00ed",
            "title": {
                "fragments": [],
                "text": "Relational learning techniques for natural language information extraction"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A novel rule representation speci c to natural language and a learning system, Rapier, which learns information extraction rules, and initial results on a small corpus of computer-related job postings with a preliminary version of Rapier are presented."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1967815"
                        ],
                        "name": "M. E. Califf",
                        "slug": "M.-E.-Califf",
                        "structuredName": {
                            "firstName": "Mary",
                            "lastName": "Califf",
                            "middleNames": [
                                "Elaine"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. E. Califf"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1797655"
                        ],
                        "name": "R. Mooney",
                        "slug": "R.-Mooney",
                        "structuredName": {
                            "firstName": "Raymond",
                            "lastName": "Mooney",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Mooney"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 60554742,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "494030430c01b6b407c4f1d831b4a74d40a23fda",
            "isKey": false,
            "numCitedBy": 38,
            "numCiting": 1,
            "paperAbstract": {
                "fragments": [],
                "text": "The recent growth of online information available in the form of natural language documents creates a greater need for computing systems with the ability to process those documents to simplify access to the information. One type of processing appropriate for many tasks is information extraction, a type of text skimming that retrieves specific types of information from text. Although information extraction systems have existed for two decades, these systems have generally been built by hand and contain domain specific information, making them difficult to port to other domains. A few researchers have begun to apply machine learning to information extraction tasks, but most of this work has involved applying learning to pieces of a much larger system. This dissertation presents a novel rule representation specific to natural language and a relational learning system, R scAPIER, which learns information extraction rules. R scAPIER takes pairs of documents and filled templates indicating the information to be extracted and learns pattern-matching rules to extract fillers for the slots in the template. The system is tested on several domains, showing its ability to learn rules for different tasks. R scAPIER's performance is compared to a propositional learning system for information extraction, demonstrating the superiority of relational learning for some information extraction tasks. \nBecause one difficulty in using machine learning to develop natural language processing systems is the necessity of providing annotated examples to supervised learning systems, this dissertation also describes an attempt to reduce the number of examples R scAPIER requires by employing a form of active learning. Experimental results show that the number of examples required to achieve a given level of performance can be significantly reduced by this method."
            },
            "slug": "Relational-learning-techniques-for-natural-language-Califf-Mooney",
            "title": {
                "fragments": [],
                "text": "Relational learning techniques for natural language information extraction"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "Experimental results show that the number of examples required to achieve a given level of performance can be significantly reduced by this method, demonstrating the superiority of relational learning for some information extraction tasks."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1758106"
                        ],
                        "name": "Dayne Freitag",
                        "slug": "Dayne-Freitag",
                        "structuredName": {
                            "firstName": "Dayne",
                            "lastName": "Freitag",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dayne Freitag"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 219,
                                "start": 207
                            }
                        ],
                        "text": "The learned structures give higher accuracy than previously attained using hand-built models, and also outperform SRV and Rapier, two state-of-the-art information extraction systems that employ ILP methods (Freitag 1998; Califf 1998)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 39,
                                "start": 31
                            }
                        ],
                        "text": "Andreas Stolcke and Stephen M. Omohundro."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 141,
                                "start": 129
                            }
                        ],
                        "text": "We compare structure learning with four other approaches, two rule-learning approaches previously reported in the literature\u2014SRV (Freitag 1998) and Rapier (Califf 1998)\u2014and two static HMM models."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 95,
                                "start": 83
                            }
                        ],
                        "text": "The idea of automatic structure selection for HMMs is not new (Stolcke and Omohundro 1994; Carrasco and Oncina 1994; Vaskoet al. 1997; Lockwood and Blanchet 1993), and it has been applied to the problem of dense extraction (Seymoreet al. 1999)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 20,
                                "start": 12
                            }
                        ],
                        "text": "Stolcke and Omohundro (Stolcke and Omohundro 1994) propose a state-merging approach which begins with a large,\nmaximally specific topology and iteratively merges pairs of states."
                    },
                    "intents": []
                }
            ],
            "corpusId": 8125917,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "dd7cee21074ea6b346011d7463f7387ad9bfcc2a",
            "isKey": false,
            "numCitedBy": 313,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "Because the World Wide Web consists primarily of text, information extraction is central to any effort that would use the Web as a resource for knowledge discovery. We show how information extraction can be cast as a standard machine learning problem, and argue for the suitability of relational learning in solving it. The implementation of a general-purpose relational learner for information extraction, SRV, is described. In contrast with earlier learning systems for information extraction, SRV makes no assumptions about document structure and the kinds of information available for use in learning extraction patterns. Instead, structural and other information is supplied as input in the form of an extensible token-oriented feature set. We demonstrate the effectiveness of this approach by adapting SRV for use in learning extraction rules for a domain consisting of university course and research project pages sampled from the Web. Making SRV Web-ready only involves adding several simple HTML-specific features to its basic feature set."
            },
            "slug": "Information-Extraction-from-HTML:-Application-of-a-Freitag",
            "title": {
                "fragments": [],
                "text": "Information Extraction from HTML: Application of a General Machine Learning Approach"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This work shows how information extraction can be cast as a standard machine learning problem, and argues for the suitability of relational learning in solving it, and the implementation of a general-purpose relational learner for information extraction, SRV."
            },
            "venue": {
                "fragments": [],
                "text": "AAAI/IAAI"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1798578"
                        ],
                        "name": "Rafael C. Carrasco",
                        "slug": "Rafael-C.-Carrasco",
                        "structuredName": {
                            "firstName": "Rafael",
                            "lastName": "Carrasco",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Rafael C. Carrasco"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1788910"
                        ],
                        "name": "J. Oncina",
                        "slug": "J.-Oncina",
                        "structuredName": {
                            "firstName": "Jos\u00e9",
                            "lastName": "Oncina",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Oncina"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 42327422,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "aaaee4a7f71f030536d67aa801dd07f2532838ee",
            "isKey": false,
            "numCitedBy": 388,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a new algorithm which allows for the identification of any stochastic deterministic regular language as well as the determination of the probabilities of the strings in the language. The algorithm builds the prefix tree acceptor from the sample set and merges systematically equivalent states. Experimentally, it proves very fast and the time needed grows only linearly with the size of the sample set."
            },
            "slug": "Learning-Stochastic-Regular-Grammars-by-Means-of-a-Carrasco-Oncina",
            "title": {
                "fragments": [],
                "text": "Learning Stochastic Regular Grammars by Means of a State Merging Method"
            },
            "tldr": {
                "abstractSimilarityScore": 94,
                "text": "A new algorithm is proposed which allows for the identification of any stochastic deterministic regular language as well as the determination of the probabilities of the strings in the language."
            },
            "venue": {
                "fragments": [],
                "text": "ICGI"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "37259377"
                        ],
                        "name": "R. Vasko",
                        "slug": "R.-Vasko",
                        "structuredName": {
                            "firstName": "Raymond",
                            "lastName": "Vasko",
                            "middleNames": [
                                "C."
                            ],
                            "suffix": "Jr."
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Vasko"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1402969335"
                        ],
                        "name": "A. El-Jaroudi",
                        "slug": "A.-El-Jaroudi",
                        "structuredName": {
                            "firstName": "Amro",
                            "lastName": "El-Jaroudi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. El-Jaroudi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3031917"
                        ],
                        "name": "J. R. Boston",
                        "slug": "J.-R.-Boston",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Boston",
                            "middleNames": [
                                "Robert"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. R. Boston"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34577764"
                        ],
                        "name": "T. Rudy",
                        "slug": "T.-Rudy",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Rudy",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Rudy"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 89,
                                "start": 72
                            }
                        ],
                        "text": "Unfortunately the approach of building structures by hand does not scale to large corpora and is difficult to follow in practice."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 30,
                                "start": 13
                            }
                        ],
                        "text": "Vaskoet al. (Vasko et al. 1997) describe a method which begins with a fully-connected structure and iteratively deletes transitions."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 123397081,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ebbb1a912e5fbe31bb8e25cf065c1d5989637f9f",
            "isKey": false,
            "numCitedBy": 5,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "Hidden Markov modeling (HMM) provides a probabilistic framework for modeling time series of multivariate observations. An HMM describes the dynamic behavior of the observations in terms of movement among the states of a finite-state machine. We have developed an algorithm that estimates the topology of an HMM for a given set of time series data. Our algorithm iteratively removes states and state transitions from a large general HMM topology and selects the topology estimate based on a likelihood criterion and a heuristic evaluation of complexity. The goal of our approach is to allow the data to reveal their own dynamic structure without external assumptions concerning the number of states or the pattern of transitions. In this paper, we describe the algorithm and apply it to estimate the dynamic structure of human body motion data from a repetitive lifting task. The estimated topology for low back pain patients was different from the topology for a control subject group. The body motions of patients tend not to change over the task, but the body motions of control subjects change systematically."
            },
            "slug": "Hidden-Markov-model-topology-estimation-to-the-of-Vasko-El-Jaroudi",
            "title": {
                "fragments": [],
                "text": "Hidden Markov model topology estimation to characterize the dynamic structure of repetitive lifting data"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "An algorithm that estimates the topology of an HMM for a given set of time series data is developed and applied to estimate the dynamic structure of human body motion data from a repetitive lifting task."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 19th Annual International Conference of the IEEE Engineering in Medicine and Biology Society. 'Magnificent Milestones and Emerging Opportunities in Medical Engineering' (Cat. No.97CH36136)"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2023469"
                        ],
                        "name": "D. Bikel",
                        "slug": "D.-Bikel",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Bikel",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Bikel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "123937952"
                        ],
                        "name": "Scott Miller",
                        "slug": "Scott-Miller",
                        "structuredName": {
                            "firstName": "Scott",
                            "lastName": "Miller",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Scott Miller"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35442155"
                        ],
                        "name": "R. Schwartz",
                        "slug": "R.-Schwartz",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Schwartz",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Schwartz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1732071"
                        ],
                        "name": "R. Weischedel",
                        "slug": "R.-Weischedel",
                        "structuredName": {
                            "firstName": "Ralph",
                            "lastName": "Weischedel",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Weischedel"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 33,
                                "start": 16
                            }
                        ],
                        "text": "Experimental results show that this technique finds HMM models that almost always out-perform a fixed model, and have superior average performance across tasks."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 129,
                                "start": 117
                            }
                        ],
                        "text": "HMMs have been applied successfully to many sub-domains of information extraction: the named entity extraction task (Bikel et al. 1997); to the task of recovering the sequence of a set of entities occurring in close proximity (dense extraction) (Seymoreet al. 1999); as well as thesparse extraction task, in which the object is to extract relevant phrases from documents containing much irrelevant text (Leek 1997; Freitag and McCallum 1999)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 134,
                                "start": 117
                            }
                        ],
                        "text": "HMMs have been applied successfully to many sub-domains of information extraction: the named entity extraction task (Bikel et al. 1997); to the task of recovering the sequence of a set of entities occurring in close proximity (dense extraction) (Seymoreet al. 1999); as well as thesparse extraction\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 31,
                                "start": 14
                            }
                        ],
                        "text": "Bikel et al. (Bikel et al. 1997) applies HMMs to the named entity recognition problem, the problem of identifying text fragments that signify particular types of entities, such as people or organizations, without regard to their role in the document."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 115174,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e9292ba3230f01b9f6990362fdf06783b9347bf6",
            "isKey": true,
            "numCitedBy": 919,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a statistical, learned approach to finding names and other nonrecursive entities in text (as per the MUC-6 definition of the NE task), using a variant of the standard hidden Markov model. We present our justification for the problem and our approach, a detailed discussion of the model itself and finally the successful results of this new approach."
            },
            "slug": "Nymble:-a-High-Performance-Learning-Name-finder-Bikel-Miller",
            "title": {
                "fragments": [],
                "text": "Nymble: a High-Performance Learning Name-finder"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "This paper presents a statistical, learned approach to finding names and other nonrecursive entities in text (as per the MUC-6 definition of the NE task), using a variant of the standard hidden Markov model."
            },
            "venue": {
                "fragments": [],
                "text": "ANLP"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712517"
                        ],
                        "name": "L. Rabiner",
                        "slug": "L.-Rabiner",
                        "structuredName": {
                            "firstName": "Lawrence",
                            "lastName": "Rabiner",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Rabiner"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 13618539,
            "fieldsOfStudy": [
                "Geology"
            ],
            "id": "8fe2ea0a67954f1380b3387e3262f1cdb9f9b3e5",
            "isKey": false,
            "numCitedBy": 24804,
            "numCiting": 98,
            "paperAbstract": {
                "fragments": [],
                "text": "The fabric comprises a novel type of netting which will have particular utility in screening out mosquitoes and like insects and pests. The fabric is defined of voids having depth as well as width and length. The fabric is usable as a material from which to form clothing for wear, or bed coverings, or sleeping bags, etc., besides use simply as a netting."
            },
            "slug": "A-Tutorial-on-Hidden-Markov-Models-and-Selected-Rabiner",
            "title": {
                "fragments": [],
                "text": "A Tutorial on Hidden Markov Models and Selected Applications"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "The fabric comprises a novel type of netting which will have particular utility in screening out mosquitoes and like insects and pests."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1989
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 435,
                                "start": 415
                            }
                        ],
                        "text": "HMMs have been applied successfully to many sub-domains of information extraction: the named entity extraction task (Bikel et al. 1997); to the task of recovering the sequence of a set of entities occurring in close proximity (dense extraction) (Seymoreet al. 1999); as well as thesparse extraction task, in which the object is to extract relevant phrases from documents containing much irrelevant text (Leek 1997; Freitag and McCallum 1999)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 32,
                                "start": 24
                            }
                        ],
                        "text": "Kristie Seymore, Andrew McCallum, and Ronald Rosenfeld."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 185,
                                "start": 160
                            }
                        ],
                        "text": "Rather than smoothing simply against the uniform distribution, the results in this paper build on work in using shrinkage with HMMs for information extraction (Freitag and McCallum 1999)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 73,
                                "start": 48
                            }
                        ],
                        "text": "The approach described in Freitag and McCallum (Freitag and McCallum 1999) addresses the same problem as in this work\u2014training one HMM per extraction task\u2014but involves manually constructed models."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 297,
                                "start": 272
                            }
                        ],
                        "text": "\u2026task of recovering the sequence of a set of entities occurring in close proximity (dense extraction) (Seymoreet al. 1999); as well as thesparse extraction task, in which the object is to extract relevant phrases from documents containing much irrelevant text (Leek 1997; Freitag and McCallum 1999)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 134,
                                "start": 109
                            }
                        ],
                        "text": "Space limitations prevent a full description of our shrinkage implementation here; see Freitag and McCallum (Freitag and McCallum 1999) for the details."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 42,
                                "start": 34
                            }
                        ],
                        "text": "Dayne Freitag and Andrew Kachites McCallum."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Information extraction using hmms and shrinkage. In Papers from the AAAI-99 Workshop on Machine Learning for Information Extration"
            },
            "venue": {
                "fragments": [],
                "text": "AAAI Technical Report WS-99-11"
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 44,
                                "start": 18
                            }
                        ],
                        "text": "Unfortunately the approach of building structures by hand does not scale to large corpora and is difficult to follow in practice."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 49,
                                "start": 23
                            }
                        ],
                        "text": "Stolcke and Omohundro (Stolcke and Omohundro 1994) propose a state-merging approach which begins with a large,\nmaximally specific topology and iteratively merges pairs of states."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 89,
                                "start": 63
                            }
                        ],
                        "text": "The idea of automatic structure selection for HMMs is not new (Stolcke and Omohundro 1994; Carrasco and Oncina 1994; Vaskoet al. 1997; Lockwood and Blanchet 1993), and it has been applied to the problem of dense extraction (Seymoreet al. 1999)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 40,
                                "start": 31
                            }
                        ],
                        "text": "Andreas Stolcke and Stephen M. Omohundro."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Best-first model merging for hidden Markov induction"
            },
            "venue": {
                "fragments": [],
                "text": "Best-first model merging for hidden Markov induction"
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Informa - tion extraction using hmms and shrinkage"
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Inference and Applications: Second International Colloquium, ICGI-94"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Information extraction using hmms and shrinkage"
            },
            "venue": {
                "fragments": [],
                "text": "Papers from the AAAI-99 Workshop on Machine Learning for Information Extration"
            },
            "year": 1999
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 9,
            "methodology": 7,
            "result": 1
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 15,
        "totalPages": 2
    },
    "page_url": "https://www.semanticscholar.org/paper/Information-Extraction-with-HMM-Structures-Learned-Freitag-McCallum/02c8a0bc8bab9920e6615cfacf1df2ab3f2b1f68?sort=total-citations"
}