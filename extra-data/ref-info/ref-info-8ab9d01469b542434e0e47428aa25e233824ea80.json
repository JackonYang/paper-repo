{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2930640"
                        ],
                        "name": "P. Welinder",
                        "slug": "P.-Welinder",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Welinder",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Welinder"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3251767"
                        ],
                        "name": "Steve Branson",
                        "slug": "Steve-Branson",
                        "structuredName": {
                            "firstName": "Steve",
                            "lastName": "Branson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Steve Branson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50172592"
                        ],
                        "name": "Serge J. Belongie",
                        "slug": "Serge-J.-Belongie",
                        "structuredName": {
                            "firstName": "Serge",
                            "lastName": "Belongie",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Serge J. Belongie"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1690922"
                        ],
                        "name": "P. Perona",
                        "slug": "P.-Perona",
                        "structuredName": {
                            "firstName": "Pietro",
                            "lastName": "Perona",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Perona"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 85,
                                "start": 63
                            }
                        ],
                        "text": "While the problem of acquiring one label has been well studied [20, 9, 22, 19, 16, 5], to our knowledge the challenge of largescale multi-label annotation has not been addressed before."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 137,
                                "start": 125
                            }
                        ],
                        "text": "A growing body of work has studied how to estimate worker quality [9], how to combine results from multiple noisy annotators [20, 22, 19], how to model the trade-off between quality and cost [5], how to merge machine and human intelligence [10], as well as how to select the next best item to label [16]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 16484321,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c2e250b4b49a9aa04b68dfd40dc69b022b1f8b3d",
            "isKey": false,
            "numCitedBy": 782,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "Distributing labeling tasks among hundreds or thousands of annotators is an increasingly important method for annotating large datasets. We present a method for estimating the underlying value (e.g. the class) of each image from (noisy) annotations provided by multiple annotators. Our method is based on a model of the image formation and annotation process. Each image has different characteristics that are represented in an abstract Euclidean space. Each annotator is modeled as a multidimensional entity with variables representing competence, expertise and bias. This allows the model to discover and represent groups of annotators that have different sets of skills and knowledge, as well as groups of images that differ qualitatively. We find that our model predicts ground truth labels on both synthetic and real data more accurately than state of the art methods. Experiments also show that our model, starting from a set of binary labels, may discover rich information, such as different \"schools of thought\" amongst the annotators, and can group together images belonging to separate categories."
            },
            "slug": "The-Multidimensional-Wisdom-of-Crowds-Welinder-Branson",
            "title": {
                "fragments": [],
                "text": "The Multidimensional Wisdom of Crowds"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "A method for estimating the underlying value of each image from (noisy) annotations provided by multiple annotators, based on a model of the image formation and annotation process, which predicts ground truth labels on both synthetic and real data more accurately than state of the art methods."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153302678"
                        ],
                        "name": "Jia Deng",
                        "slug": "Jia-Deng",
                        "structuredName": {
                            "firstName": "Jia",
                            "lastName": "Deng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jia Deng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144847596"
                        ],
                        "name": "Wei Dong",
                        "slug": "Wei-Dong",
                        "structuredName": {
                            "firstName": "Wei",
                            "lastName": "Dong",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wei Dong"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2166511"
                        ],
                        "name": "R. Socher",
                        "slug": "R.-Socher",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Socher",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Socher"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2040091191"
                        ],
                        "name": "Li-Jia Li",
                        "slug": "Li-Jia-Li",
                        "structuredName": {
                            "firstName": "Li-Jia",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Li-Jia Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "94451829"
                        ],
                        "name": "K. Li",
                        "slug": "K.-Li",
                        "structuredName": {
                            "firstName": "K.",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48004138"
                        ],
                        "name": "Li Fei-Fei",
                        "slug": "Li-Fei-Fei",
                        "structuredName": {
                            "firstName": "Li",
                            "lastName": "Fei-Fei",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Li Fei-Fei"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 57246310,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1b47265245e8db53a553049dcb27ed3e495fd625",
            "isKey": false,
            "numCitedBy": 27402,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "The explosion of image data on the Internet has the potential to foster more sophisticated and robust models and algorithms to index, retrieve, organize and interact with images and multimedia data. But exactly how such data can be harnessed and organized remains a critical problem. We introduce here a new database called \u201cImageNet\u201d, a large-scale ontology of images built upon the backbone of the WordNet structure. ImageNet aims to populate the majority of the 80,000 synsets of WordNet with an average of 500-1000 clean and full resolution images. This will result in tens of millions of annotated images organized by the semantic hierarchy of WordNet. This paper offers a detailed analysis of ImageNet in its current state: 12 subtrees with 5247 synsets and 3.2 million images in total. We show that ImageNet is much larger in scale and diversity and much more accurate than the current image datasets. Constructing such a large-scale database is a challenging task. We describe the data collection scheme with Amazon Mechanical Turk. Lastly, we illustrate the usefulness of ImageNet through three simple applications in object recognition, image classification and automatic object clustering. We hope that the scale, accuracy, diversity and hierarchical structure of ImageNet can offer unparalleled opportunities to researchers in the computer vision community and beyond."
            },
            "slug": "ImageNet:-A-large-scale-hierarchical-image-database-Deng-Dong",
            "title": {
                "fragments": [],
                "text": "ImageNet: A large-scale hierarchical image database"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A new database called \u201cImageNet\u201d is introduced, a large-scale ontology of images built upon the backbone of the WordNet structure, much larger in scale and diversity and much more accurate than the current image datasets."
            },
            "venue": {
                "fragments": [],
                "text": "CVPR"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2858764"
                        ],
                        "name": "V. Sheng",
                        "slug": "V.-Sheng",
                        "structuredName": {
                            "firstName": "Victor",
                            "lastName": "Sheng",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Sheng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1752722"
                        ],
                        "name": "F. Provost",
                        "slug": "F.-Provost",
                        "structuredName": {
                            "firstName": "Foster",
                            "lastName": "Provost",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Provost"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2942126"
                        ],
                        "name": "Panagiotis G. Ipeirotis",
                        "slug": "Panagiotis-G.-Ipeirotis",
                        "structuredName": {
                            "firstName": "Panagiotis",
                            "lastName": "Ipeirotis",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Panagiotis G. Ipeirotis"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 85,
                                "start": 63
                            }
                        ],
                        "text": "While the problem of acquiring one label has been well studied [20, 9, 22, 19, 16, 5], to our knowledge the challenge of largescale multi-label annotation has not been addressed before."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 303,
                                "start": 299
                            }
                        ],
                        "text": "A growing body of work has studied how to estimate worker quality [9], how to combine results from multiple noisy annotators [20, 22, 19], how to model the trade-off between quality and cost [5], how to merge machine and human intelligence [10], as well as how to select the next best item to label [16]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 279332,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a3f853572e12b51c4c227590168c95b7cd0ca666",
            "isKey": false,
            "numCitedBy": 1112,
            "numCiting": 41,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper addresses the repeated acquisition of labels for data items when the labeling is imperfect. We examine the improvement (or lack thereof) in data quality via repeated labeling, and focus especially on the improvement of training labels for supervised induction. With the outsourcing of small tasks becoming easier, for example via Rent-A-Coder or Amazon's Mechanical Turk, it often is possible to obtain less-than-expert labeling at low cost. With low-cost labeling, preparing the unlabeled part of the data can become considerably more expensive than labeling. We present repeated-labeling strategies of increasing complexity, and show several main results. (i) Repeated-labeling can improve label quality and model quality, but not always. (ii) When labels are noisy, repeated labeling can be preferable to single labeling even in the traditional setting where labels are not particularly cheap. (iii) As soon as the cost of processing the unlabeled data is not free, even the simple strategy of labeling everything multiple times can give considerable advantage. (iv) Repeatedly labeling a carefully chosen set of points is generally preferable, and we present a robust technique that combines different notions of uncertainty to select data points for which quality should be improved. The bottom line: the results show clearly that when labeling is not perfect, selective acquisition of multiple labels is a strategy that data miners should have in their repertoire; for certain label-quality/cost regimes, the benefit is substantial."
            },
            "slug": "Get-another-label-improving-data-quality-and-data-Sheng-Provost",
            "title": {
                "fragments": [],
                "text": "Get another label? improving data quality and data mining using multiple, noisy labelers"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "The results show clearly that when labeling is not perfect, selective acquisition of multiple labels is a strategy that data miners should have in their repertoire; for certain label-quality/cost regimes, the benefit is substantial."
            },
            "venue": {
                "fragments": [],
                "text": "KDD"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2699105"
                        ],
                        "name": "Jonathan Bragg",
                        "slug": "Jonathan-Bragg",
                        "structuredName": {
                            "firstName": "Jonathan",
                            "lastName": "Bragg",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jonathan Bragg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2674444"
                        ],
                        "name": "Mausam",
                        "slug": "Mausam",
                        "structuredName": {
                            "firstName": "",
                            "lastName": "Mausam",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mausam"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1780531"
                        ],
                        "name": "Daniel S. Weld",
                        "slug": "Daniel-S.-Weld",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Weld",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Daniel S. Weld"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 82,
                                "start": 79
                            }
                        ],
                        "text": "Our work also draws on research on multi-label classification in crowdsourcing [3]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 11974604,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "23a7d71726abbdccdea368bc6e43aecb3c970620",
            "isKey": false,
            "numCitedBy": 135,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "Recent work has introduced CASCADE, an algorithm for creating a globally-consistent taxonomy by crowdsourcing microwork from many individuals, each of whom may see only a tiny fraction of the data (Chilton et al. 2013). While CASCADE needs only unskilled labor and produces taxonomies whose quality approaches that of human experts, it uses significantly more labor than experts. This paper presents DELUGE, an improved workflow that produces taxonomies with comparable quality using significantly less crowd labor. Specifically, our method for crowdsourcing multi-label classification optimizes CASCADE\u2019s most costly step (categorization) using less than 10% of the labor required by the original approach. DELUGE\u2019s savings come from the use of decision theory and machine learning, which allow it to pose microtasks that aim to maximize information gain."
            },
            "slug": "Crowdsourcing-Multi-Label-Classification-for-Bragg-Mausam",
            "title": {
                "fragments": [],
                "text": "Crowdsourcing Multi-Label Classification for Taxonomy Creation"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This paper presents DELUGE, an improved workflow that produces taxonomies with comparable quality using significantly less crowd labor and optimizes CASCADE\u2019s most costly step (categorization) using less than 10% of the labor required by the original approach."
            },
            "venue": {
                "fragments": [],
                "text": "HCOMP"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143973061"
                        ],
                        "name": "J. Whitehill",
                        "slug": "J.-Whitehill",
                        "structuredName": {
                            "firstName": "Jacob",
                            "lastName": "Whitehill",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Whitehill"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "12114845"
                        ],
                        "name": "P. Ruvolo",
                        "slug": "P.-Ruvolo",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Ruvolo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Ruvolo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "4072965"
                        ],
                        "name": "Tingfan Wu",
                        "slug": "Tingfan-Wu",
                        "structuredName": {
                            "firstName": "Tingfan",
                            "lastName": "Wu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tingfan Wu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153807404"
                        ],
                        "name": "J. Bergsma",
                        "slug": "J.-Bergsma",
                        "structuredName": {
                            "firstName": "Jacob",
                            "lastName": "Bergsma",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Bergsma"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1741200"
                        ],
                        "name": "J. Movellan",
                        "slug": "J.-Movellan",
                        "structuredName": {
                            "firstName": "Javier",
                            "lastName": "Movellan",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Movellan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2332622,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6953420c593842697dd09bc2cf7ffbbaf67a6e8e",
            "isKey": false,
            "numCitedBy": 1040,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "Modern machine learning-based approaches to computer vision require very large databases of hand labeled images. Some contemporary vision systems already require on the order of millions of images for training (e.g., Omron face detector [9]). New Internet-based services allow for a large number of labelers to collaborate around the world at very low cost. However, using these services brings interesting theoretical and practical challenges: (1) The labelers may have wide ranging levels of expertise which are unknown a priori, and in some cases may be adversarial; (2) images may vary in their level of difficulty; and (3) multiple labels for the same image must be combined to provide an estimate of the actual label of the image. Probabilistic approaches provide a principled way to approach these problems. In this paper we present a probabilistic model and use it to simultaneously infer the label of each image, the expertise of each labeler, and the difficulty of each image. On both simulated and real data, we demonstrate that the model outperforms the commonly used \"Majority Vote\" heuristic for inferring image labels, and is robust to both noisy and adversarial labelers."
            },
            "slug": "Whose-Vote-Should-Count-More:-Optimal-Integration-Whitehill-Ruvolo",
            "title": {
                "fragments": [],
                "text": "Whose Vote Should Count More: Optimal Integration of Labels from Labelers of Unknown Expertise"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "A probabilistic model is presented and it is demonstrated that the model outperforms the commonly used \"Majority Vote\" heuristic for inferring image labels, and is robust to both noisy and adversarial labelers."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1735221"
                        ],
                        "name": "N. Ueda",
                        "slug": "N.-Ueda",
                        "structuredName": {
                            "firstName": "Naonori",
                            "lastName": "Ueda",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Ueda"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1727070"
                        ],
                        "name": "Kazumi Saito",
                        "slug": "Kazumi-Saito",
                        "structuredName": {
                            "firstName": "Kazumi",
                            "lastName": "Saito",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kazumi Saito"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 312,
                                "start": 308
                            }
                        ],
                        "text": "This technique is important in multiple domains, such as labeling actions in videos [11], news article topics [15], functional classes of genes [8], musical attributes or emotions in songs [12], semantic classes of scenes [2], product categories customers are likely to buy [21], and categories of web pages [18]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7323448,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d5388a48970e0fbea9dfcb23b607578e95537da6",
            "isKey": false,
            "numCitedBy": 349,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose probabilistic generative models, called parametric mixture models (PMMs), for multiclass, multi-labeled text categorization problem. Conventionally, the binary classification approach has been employed, in which whether or not text belongs to a category is judged by the binary classifier for every category. In contrast, our approach can simultaneously detect multiple categories of text using PMMs. We derive efficient learning and prediction algorithms for PMMs. We also empirically show that our method could significantly outperform the conventional binary methods when applied to multi-labeled text categorization using real World Wide Web pages."
            },
            "slug": "Parametric-Mixture-Models-for-Multi-Labeled-Text-Ueda-Saito",
            "title": {
                "fragments": [],
                "text": "Parametric Mixture Models for Multi-Labeled Text"
            },
            "tldr": {
                "abstractSimilarityScore": 60,
                "text": "It is shown that the proposed probabilistic generative models, called parametric mixture models (PMMs), could significantly outperform the conventional binary methods when applied to multi-labeled text categorization using real World Wide Web pages."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143991676"
                        ],
                        "name": "I. Laptev",
                        "slug": "I.-Laptev",
                        "structuredName": {
                            "firstName": "Ivan",
                            "lastName": "Laptev",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Laptev"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3502855"
                        ],
                        "name": "Marcin Marszalek",
                        "slug": "Marcin-Marszalek",
                        "structuredName": {
                            "firstName": "Marcin",
                            "lastName": "Marszalek",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Marcin Marszalek"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2462253"
                        ],
                        "name": "C. Schmid",
                        "slug": "C.-Schmid",
                        "structuredName": {
                            "firstName": "Cordelia",
                            "lastName": "Schmid",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Schmid"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3261451"
                        ],
                        "name": "Benjamin Rozenfeld",
                        "slug": "Benjamin-Rozenfeld",
                        "structuredName": {
                            "firstName": "Benjamin",
                            "lastName": "Rozenfeld",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Benjamin Rozenfeld"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 88,
                                "start": 84
                            }
                        ],
                        "text": "This technique is important in multiple domains, such as labeling actions in videos [11], news article topics [15], functional classes of genes [8], musical attributes or emotions in songs [12], semantic classes of scenes [2], product categories customers are likely to buy [21], and categories of web pages [18]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 12365014,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0f86767732f76f478d5845f2e59f99ba106e9265",
            "isKey": false,
            "numCitedBy": 3595,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "The aim of this paper is to address recognition of natural human actions in diverse and realistic video settings. This challenging but important subject has mostly been ignored in the past due to several problems one of which is the lack of realistic and annotated video datasets. Our first contribution is to address this limitation and to investigate the use of movie scripts for automatic annotation of human actions in videos. We evaluate alternative methods for action retrieval from scripts and show benefits of a text-based classifier. Using the retrieved action samples for visual learning, we next turn to the problem of action classification in video. We present a new method for video classification that builds upon and extends several recent ideas including local space-time features, space-time pyramids and multi-channel non-linear SVMs. The method is shown to improve state-of-the-art results on the standard KTH action dataset by achieving 91.8% accuracy. Given the inherent problem of noisy labels in automatic annotation, we particularly investigate and show high tolerance of our method to annotation errors in the training set. We finally apply the method to learning and classifying challenging action classes in movies and show promising results."
            },
            "slug": "Learning-realistic-human-actions-from-movies-Laptev-Marszalek",
            "title": {
                "fragments": [],
                "text": "Learning realistic human actions from movies"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A new method for video classification that builds upon and extends several recent ideas including local space-time features,space-time pyramids and multi-channel non-linear SVMs is presented and shown to improve state-of-the-art results on the standard KTH action dataset."
            },
            "venue": {
                "fragments": [],
                "text": "2008 IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1840551"
                        ],
                        "name": "M. Boutell",
                        "slug": "M.-Boutell",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Boutell",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Boutell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "33642939"
                        ],
                        "name": "Jiebo Luo",
                        "slug": "Jiebo-Luo",
                        "structuredName": {
                            "firstName": "Jiebo",
                            "lastName": "Luo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jiebo Luo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2111112811"
                        ],
                        "name": "Xipeng Shen",
                        "slug": "Xipeng-Shen",
                        "structuredName": {
                            "firstName": "Xipeng",
                            "lastName": "Shen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xipeng Shen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48726084"
                        ],
                        "name": "Christopher M. Brown",
                        "slug": "Christopher-M.-Brown",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Brown",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christopher M. Brown"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 225,
                                "start": 222
                            }
                        ],
                        "text": "This technique is important in multiple domains, such as labeling actions in videos [11], news article topics [15], functional classes of genes [8], musical attributes or emotions in songs [12], semantic classes of scenes [2], product categories customers are likely to buy [21], and categories of web pages [18]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 9404152,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "896b9c1551b7ffa347baed144582ec3b5d88f703",
            "isKey": false,
            "numCitedBy": 1923,
            "numCiting": 43,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Learning-multi-label-scene-classification-Boutell-Luo",
            "title": {
                "fragments": [],
                "text": "Learning multi-label scene classification"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit."
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2942126"
                        ],
                        "name": "Panagiotis G. Ipeirotis",
                        "slug": "Panagiotis-G.-Ipeirotis",
                        "structuredName": {
                            "firstName": "Panagiotis",
                            "lastName": "Ipeirotis",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Panagiotis G. Ipeirotis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1752722"
                        ],
                        "name": "F. Provost",
                        "slug": "F.-Provost",
                        "structuredName": {
                            "firstName": "Foster",
                            "lastName": "Provost",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Provost"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2152453484"
                        ],
                        "name": "Jing Wang",
                        "slug": "Jing-Wang",
                        "structuredName": {
                            "firstName": "Jing",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jing Wang"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 85,
                                "start": 63
                            }
                        ],
                        "text": "While the problem of acquiring one label has been well studied [20, 9, 22, 19, 16, 5], to our knowledge the challenge of largescale multi-label annotation has not been addressed before."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 69,
                                "start": 66
                            }
                        ],
                        "text": "A growing body of work has studied how to estimate worker quality [9], how to combine results from multiple noisy annotators [20, 22, 19], how to model the trade-off between quality and cost [5], how to merge machine and human intelligence [10], as well as how to select the next best item to label [16]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14888472,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8d4594b4d4827f44b57863376d54536112b7aaca",
            "isKey": false,
            "numCitedBy": 1005,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "Crowdsourcing services, such as Amazon Mechanical Turk, allow for easy distribution of small tasks to a large number of workers. Unfortunately, since manually verifying the quality of the submitted results is hard, malicious workers often take advantage of the verification difficulty and submit answers of low quality. Currently, most requesters rely on redundancy to identify the correct answers. However, redundancy is not a panacea. Massive redundancy is expensive, increasing significantly the cost of crowdsourced solutions. Therefore, we need techniques that will accurately estimate the quality of the workers, allowing for the rejection and blocking of the low-performing workers and spammers.\n However, existing techniques cannot separate the true (unrecoverable) error rate from the (recoverable) biases that some workers exhibit. This lack of separation leads to incorrect assessments of a worker's quality. We present algorithms that improve the existing state-of-the-art techniques, enabling the separation of bias and error. Our algorithm generates a scalar score representing the inherent quality of each worker. We illustrate how to incorporate cost-sensitive classification errors in the overall framework and how to seamlessly integrate unsupervised and supervised techniques for inferring the quality of the workers. We present experimental results demonstrating the performance of the proposed algorithm under a variety of settings."
            },
            "slug": "Quality-management-on-Amazon-Mechanical-Turk-Ipeirotis-Provost",
            "title": {
                "fragments": [],
                "text": "Quality management on Amazon Mechanical Turk"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "This work presents algorithms that improve the existing state-of-the-art techniques, enabling the separation of bias and error, and illustrates how to incorporate cost-sensitive classification errors in the overall framework and how to seamlessly integrate unsupervised and supervised techniques for inferring the quality of the workers."
            },
            "venue": {
                "fragments": [],
                "text": "HCOMP '10"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1766703"
                        ],
                        "name": "A. Elisseeff",
                        "slug": "A.-Elisseeff",
                        "structuredName": {
                            "firstName": "Andr\u00e9",
                            "lastName": "Elisseeff",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Elisseeff"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145183709"
                        ],
                        "name": "J. Weston",
                        "slug": "J.-Weston",
                        "structuredName": {
                            "firstName": "Jason",
                            "lastName": "Weston",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Weston"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 147,
                                "start": 144
                            }
                        ],
                        "text": "This technique is important in multiple domains, such as labeling actions in videos [11], news article topics [15], functional classes of genes [8], musical attributes or emotions in songs [12], semantic classes of scenes [2], product categories customers are likely to buy [21], and categories of web pages [18]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1976599,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "30b2a3422332a76663110beae4bfc4d74763f4a0",
            "isKey": false,
            "numCitedBy": 1246,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "This article presents a Support Vector Machine (SVM) like learning system to handle multi-label problems. Such problems are usually decomposed into many two-class problems but the expressive power of such a system can be weak [5, 7]. We explore a new direct approach. It is based on a large margin ranking system that shares a lot of common properties with SVMs. We tested it on a Yeast gene functional classification problem with positive results."
            },
            "slug": "A-kernel-method-for-multi-labelled-classification-Elisseeff-Weston",
            "title": {
                "fragments": [],
                "text": "A kernel method for multi-labelled classification"
            },
            "tldr": {
                "abstractSimilarityScore": 71,
                "text": "This article presents a Support Vector Machine like learning system to handle multi-label problems, based on a large margin ranking system that shares a lot of common properties with SVMs."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "24982365"
                        ],
                        "name": "Dengyong Zhou",
                        "slug": "Dengyong-Zhou",
                        "structuredName": {
                            "firstName": "Dengyong",
                            "lastName": "Zhou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dengyong Zhou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144189092"
                        ],
                        "name": "John C. Platt",
                        "slug": "John-C.-Platt",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Platt",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "John C. Platt"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8611534"
                        ],
                        "name": "S. Basu",
                        "slug": "S.-Basu",
                        "structuredName": {
                            "firstName": "Sumit",
                            "lastName": "Basu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Basu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145469202"
                        ],
                        "name": "Yi Mao",
                        "slug": "Yi-Mao",
                        "structuredName": {
                            "firstName": "Yi",
                            "lastName": "Mao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yi Mao"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 85,
                                "start": 63
                            }
                        ],
                        "text": "While the problem of acquiring one label has been well studied [20, 9, 22, 19, 16, 5], to our knowledge the challenge of largescale multi-label annotation has not been addressed before."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 137,
                                "start": 125
                            }
                        ],
                        "text": "A growing body of work has studied how to estimate worker quality [9], how to combine results from multiple noisy annotators [20, 22, 19], how to model the trade-off between quality and cost [5], how to merge machine and human intelligence [10], as well as how to select the next best item to label [16]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15908955,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b2eef3c281b15461f141035aa9a778062b5723fd",
            "isKey": false,
            "numCitedBy": 333,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "An important way to make large training sets is to gather noisy labels from crowds of nonexperts. We propose a minimax entropy principle to improve the quality of these labels. Our method assumes that labels are generated by a probability distribution over workers, items, and labels. By maximizing the entropy of this distribution, the method naturally infers item confusability and worker expertise. We infer the ground truth by minimizing the entropy of this distribution, which we show minimizes the Kullback-Leibler (KL) divergence between the probability distribution and the unknown truth. We show that a simple coordinate descent scheme can optimize minimax entropy. Empirically, our results are substantially better than previously published methods for the same problem."
            },
            "slug": "Learning-from-the-Wisdom-of-Crowds-by-Minimax-Zhou-Platt",
            "title": {
                "fragments": [],
                "text": "Learning from the Wisdom of Crowds by Minimax Entropy"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "This work proposes a minimax entropy principle to improve the quality of noisy labels from crowds of nonexperts, and shows that a simple coordinate descent scheme can optimize minimAX entropy."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716301"
                        ],
                        "name": "R. Schapire",
                        "slug": "R.-Schapire",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Schapire",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Schapire"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1740765"
                        ],
                        "name": "Y. Singer",
                        "slug": "Y.-Singer",
                        "structuredName": {
                            "firstName": "Yoram",
                            "lastName": "Singer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Singer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 114,
                                "start": 110
                            }
                        ],
                        "text": "This technique is important in multiple domains, such as labeling actions in videos [11], news article topics [15], functional classes of genes [8], musical attributes or emotions in songs [12], semantic classes of scenes [2], product categories customers are likely to buy [21], and categories of web pages [18]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2185716,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e7a07c3aaef303850e5a1fcc81bb44f6d2db6696",
            "isKey": false,
            "numCitedBy": 2272,
            "numCiting": 85,
            "paperAbstract": {
                "fragments": [],
                "text": "This work focuses on algorithms which learn from examples to perform multiclass text and speech categorization tasks. Our approach is based on a new and improved family of boosting algorithms. We describe in detail an implementation, called BoosTexter, of the new boosting algorithms for text categorization tasks. We present results comparing the performance of BoosTexter and a number of other text-categorization algorithms on a variety of tasks. We conclude by describing the application of our system to automatic call-type identification from unconstrained spoken customer responses."
            },
            "slug": "BoosTexter:-A-Boosting-based-System-for-Text-Schapire-Singer",
            "title": {
                "fragments": [],
                "text": "BoosTexter: A Boosting-based System for Text Categorization"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "This work describes in detail an implementation, called BoosTexter, of the new boosting algorithms for text categorization tasks, and presents results comparing the performance of Boos Texter and a number of other text-categorization algorithms on a variety of tasks."
            },
            "venue": {
                "fragments": [],
                "text": "Machine Learning"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39971338"
                        ],
                        "name": "Thomas L. Dean",
                        "slug": "Thomas-L.-Dean",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Dean",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thomas L. Dean"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3154722"
                        ],
                        "name": "Mark A. Ruzon",
                        "slug": "Mark-A.-Ruzon",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Ruzon",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mark A. Ruzon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2060304831"
                        ],
                        "name": "Mark E. Segal",
                        "slug": "Mark-E.-Segal",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Segal",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mark E. Segal"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1789737"
                        ],
                        "name": "Jonathon Shlens",
                        "slug": "Jonathon-Shlens",
                        "structuredName": {
                            "firstName": "Jonathon",
                            "lastName": "Shlens",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jonathon Shlens"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2259154"
                        ],
                        "name": "Sudheendra Vijayanarasimhan",
                        "slug": "Sudheendra-Vijayanarasimhan",
                        "structuredName": {
                            "firstName": "Sudheendra",
                            "lastName": "Vijayanarasimhan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sudheendra Vijayanarasimhan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1842163"
                        ],
                        "name": "J. Yagnik",
                        "slug": "J.-Yagnik",
                        "structuredName": {
                            "firstName": "Jay",
                            "lastName": "Yagnik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Yagnik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 139,
                                "start": 136
                            }
                        ],
                        "text": "of images for training and evaluation [7] and are interested in determining the presence of 10,000 or even up to 100,000 object classes [6]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2568065,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "774f67303ea4a3a94874f08cf9a9dacc69b40782",
            "isKey": false,
            "numCitedBy": 341,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "Many object detection systems are constrained by the time required to convolve a target image with a bank of filters that code for different aspects of an object's appearance, such as the presence of component parts. We exploit locality-sensitive hashing to replace the dot-product kernel operator in the convolution with a fixed number of hash-table probes that effectively sample all of the filter responses in time independent of the size of the filter bank. To show the effectiveness of the technique, we apply it to evaluate 100,000 deformable-part models requiring over a million (part) filters on multiple scales of a target image in less than 20 seconds using a single multi-core processor with 20GB of RAM. This represents a speed-up of approximately 20,000 times - four orders of magnitude - when compared with performing the convolutions explicitly on the same hardware. While mean average precision over the full set of 100,000 object classes is around 0.16 due in large part to the challenges in gathering training data and collecting ground truth for so many classes, we achieve a mAP of at least 0.20 on a third of the classes and 0.30 or better on about 20% of the classes."
            },
            "slug": "Fast,-Accurate-Detection-of-100,000-Object-Classes-Dean-Ruzon",
            "title": {
                "fragments": [],
                "text": "Fast, Accurate Detection of 100,000 Object Classes on a Single Machine"
            },
            "venue": {
                "fragments": [],
                "text": "2013 IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3251767"
                        ],
                        "name": "Steve Branson",
                        "slug": "Steve-Branson",
                        "structuredName": {
                            "firstName": "Steve",
                            "lastName": "Branson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Steve Branson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2367820"
                        ],
                        "name": "C. Wah",
                        "slug": "C.-Wah",
                        "structuredName": {
                            "firstName": "Catherine",
                            "lastName": "Wah",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Wah"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3302320"
                        ],
                        "name": "Florian Schroff",
                        "slug": "Florian-Schroff",
                        "structuredName": {
                            "firstName": "Florian",
                            "lastName": "Schroff",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Florian Schroff"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2490700"
                        ],
                        "name": "Boris Babenko",
                        "slug": "Boris-Babenko",
                        "structuredName": {
                            "firstName": "Boris",
                            "lastName": "Babenko",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Boris Babenko"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2930640"
                        ],
                        "name": "P. Welinder",
                        "slug": "P.-Welinder",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Welinder",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Welinder"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1690922"
                        ],
                        "name": "P. Perona",
                        "slug": "P.-Perona",
                        "structuredName": {
                            "firstName": "Pietro",
                            "lastName": "Perona",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Perona"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50172592"
                        ],
                        "name": "Serge J. Belongie",
                        "slug": "Serge-J.-Belongie",
                        "structuredName": {
                            "firstName": "Serge",
                            "lastName": "Belongie",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Serge J. Belongie"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 70,
                                "start": 67
                            }
                        ],
                        "text": "study how to select questions for multi-class image classification [4]; this is a special case of our setting where only one class can be present in an image."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 16647912,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cd3219fb608ea4ef5103c115e0afd308f851d89a",
            "isKey": false,
            "numCitedBy": 452,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "We present an interactive, hybrid human-computer method for object classification. The method applies to classes of objects that are recognizable by people with appropriate expertise (e.g., animal species or airplane model), but not (in general) by people without such expertise. It can be seen as a visual version of the 20 questions game, where questions based on simple visual attributes are posed interactively. The goal is to identify the true class while minimizing the number of questions asked, using the visual content of the image. We introduce a general framework for incorporating almost any off-the-shelf multi-class object recognition algorithm into the visual 20 questions game, and provide methodologies to account for imperfect user responses and unreliable computer vision algorithms. We evaluate our methods on Birds-200, a difficult dataset of 200 tightly-related bird species, and on the Animals With Attributes dataset. Our results demonstrate that incorporating user input drives up recognition accuracy to levels that are good enough for practical applications, while at the same time, computer vision reduces the amount of human interaction required."
            },
            "slug": "Visual-Recognition-with-Humans-in-the-Loop-Branson-Wah",
            "title": {
                "fragments": [],
                "text": "Visual Recognition with Humans in the Loop"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The results demonstrate that incorporating user input drives up recognition accuracy to levels that are good enough for practical applications, while at the same time, computer vision reduces the amount of human interaction required."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1783184"
                        ],
                        "name": "Ece Kamar",
                        "slug": "Ece-Kamar",
                        "structuredName": {
                            "firstName": "Ece",
                            "lastName": "Kamar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ece Kamar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "21748312"
                        ],
                        "name": "Severin Hacker",
                        "slug": "Severin-Hacker",
                        "structuredName": {
                            "firstName": "Severin",
                            "lastName": "Hacker",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Severin Hacker"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145479841"
                        ],
                        "name": "E. Horvitz",
                        "slug": "E.-Horvitz",
                        "structuredName": {
                            "firstName": "Eric",
                            "lastName": "Horvitz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Horvitz"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 244,
                                "start": 240
                            }
                        ],
                        "text": "A growing body of work has studied how to estimate worker quality [9], how to combine results from multiple noisy annotators [20, 22, 19], how to model the trade-off between quality and cost [5], how to merge machine and human intelligence [10], as well as how to select the next best item to label [16]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6950702,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "57619d0962814f38a447fe9e26e8bcc74b5fc1bb",
            "isKey": false,
            "numCitedBy": 359,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "We show how machine learning and inference can be harnessed to leverage the complementary strengths of humans and computational agents to solve crowdsourcing tasks. We construct a set of Bayesian predictive models from data and describe how the models operate within an overall crowd-sourcing architecture that combines the efforts of people and machine vision on the task of classifying celestial bodies defined within a citizens' science project named Galaxy Zoo. We show how learned probabilistic models can be used to fuse human and machine contributions and to predict the behaviors of workers. We employ multiple inferences in concert to guide decisions on hiring and routing workers to tasks so as to maximize the efficiency of large-scale crowdsourcing processes based on expected utility."
            },
            "slug": "Combining-human-and-machine-intelligence-in-Kamar-Hacker",
            "title": {
                "fragments": [],
                "text": "Combining human and machine intelligence in large-scale crowdsourcing"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A set of Bayesian predictive models from data are constructed and described how the models operate within an overall crowd-sourcing architecture that combines the efforts of people and machine vision on the task of classifying celestial bodies defined within a citizens' science project named Galaxy Zoo."
            },
            "venue": {
                "fragments": [],
                "text": "AAMAS"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2065774063"
                        ],
                        "name": "P. Dai",
                        "slug": "P.-Dai",
                        "structuredName": {
                            "firstName": "Peng",
                            "lastName": "Dai",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Dai"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2674444"
                        ],
                        "name": "Mausam",
                        "slug": "Mausam",
                        "structuredName": {
                            "firstName": "",
                            "lastName": "Mausam",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mausam"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1780531"
                        ],
                        "name": "Daniel S. Weld",
                        "slug": "Daniel-S.-Weld",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Weld",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Daniel S. Weld"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 85,
                                "start": 63
                            }
                        ],
                        "text": "While the problem of acquiring one label has been well studied [20, 9, 22, 19, 16, 5], to our knowledge the challenge of largescale multi-label annotation has not been addressed before."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 194,
                                "start": 191
                            }
                        ],
                        "text": "A growing body of work has studied how to estimate worker quality [9], how to combine results from multiple noisy annotators [20, 22, 19], how to model the trade-off between quality and cost [5], how to merge machine and human intelligence [10], as well as how to select the next best item to label [16]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 8730278,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "18b1885f41c8e88ce7093ed437cb3e980ae82650",
            "isKey": false,
            "numCitedBy": 160,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "Crowd-sourcing is a recent framework in which human intelligence tasks are outsourced to a crowd of unknown people (\"workers\") as an open call (e.g., on Amazon's Mechanical Turk). Crowd-sourcing has become immensely popular with hoards of employers (\"requesters\"), who use it to solve a wide variety of jobs, such as dictation transcription, content screening, etc. In order to achieve quality results, requesters often subdivide a large task into a chain of bite-sized subtasks that are combined into a complex, iterative workflow in which workers check and improve each other's results. This paper raises an exciting question for AI \u2014 could an autonomous agent control these workflows without human intervention, yielding better results than today's state of the art, a fixed control program? \n \nWe describe a planner, TURKONTROL, that formulates workflow control as a decision-theoretic optimization problem, trading off the implicit quality of a solution artifact against the cost for workers to achieve it. We lay the mathematical framework to govern the various decisions at each point in a popular class of workflows. Based on our analysis we implement the workflow control algorithm and present experiments demonstrating that TURKONTROL obtains much higher utilities than popular fixed policies."
            },
            "slug": "Decision-Theoretic-Control-of-Crowd-Sourced-Dai-Mausam",
            "title": {
                "fragments": [],
                "text": "Decision-Theoretic Control of Crowd-Sourced Workflows"
            },
            "tldr": {
                "abstractSimilarityScore": 37,
                "text": "A planner is described, TURKONTROL, that formulates workflow control as a decision-theoretic optimization problem, trading off the implicit quality of a solution artifact against the cost for workers to achieve it."
            },
            "venue": {
                "fragments": [],
                "text": "AAAI"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48155668"
                        ],
                        "name": "Greg Little",
                        "slug": "Greg-Little",
                        "structuredName": {
                            "firstName": "Greg",
                            "lastName": "Little",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Greg Little"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6449475,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c3ed842935f30c18ff85d68a22be7db4e0d4bbbd",
            "isKey": false,
            "numCitedBy": 281,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "Mechanical Turk (MTurk) is an increasingly popular web service for paying people small rewards to do human computation tasks. Current uses of MTurk typically post independent parallel tasks. I am exploring an alternative iterative paradigm, in which workers build on or evaluate each other's work. Part of my proposal is a toolkit called TurKit which facilitates deployment of iterative tasks on MTurk. I want to explore using this technology as a new form of end-user programming, where end-users are writing \u201cprograms\u201d that are really instructions executed by humans on MTurk."
            },
            "slug": "TurKit:-Tools-for-iterative-tasks-on-mechanical-Little",
            "title": {
                "fragments": [],
                "text": "TurKit: Tools for iterative tasks on mechanical turk"
            },
            "tldr": {
                "abstractSimilarityScore": 37,
                "text": "Part of the proposal is a toolkit called TurKit which facilitates deployment of iterative tasks on MTurk, an alternative iterative paradigm, in which workers build on or evaluate each other's work."
            },
            "venue": {
                "fragments": [],
                "text": "2009 IEEE Symposium on Visual Languages and Human-Centric Computing (VL/HCC)"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1721801"
                        ],
                        "name": "C. Fellbaum",
                        "slug": "C.-Fellbaum",
                        "structuredName": {
                            "firstName": "Christiane",
                            "lastName": "Fellbaum",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Fellbaum"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5958691,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d87ceda3042f781c341ac17109d1e94a717f5f60",
            "isKey": false,
            "numCitedBy": 13573,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "Part 1 The lexical database: nouns in WordNet, George A. Miller modifiers in WordNet, Katherine J. Miller a semantic network of English verbs, Christiane Fellbaum design and implementation of the WordNet lexical database and searching software, Randee I. Tengi. Part 2: automated discovery of WordNet relations, Marti A. Hearst representing verb alterations in WordNet, Karen T. Kohl et al the formalization of WordNet by methods of relational concept analysis, Uta E. Priss. Part 3 Applications of WordNet: building semantic concordances, Shari Landes et al performance and confidence in a semantic annotation task, Christiane Fellbaum et al WordNet and class-based probabilities, Philip Resnik combining local context and WordNet similarity for word sense identification, Claudia Leacock and Martin Chodorow using WordNet for text retrieval, Ellen M. Voorhees lexical chains as representations of context for the detection and correction of malapropisms, Graeme Hirst and David St-Onge temporal indexing through lexical chaining, Reem Al-Halimi and Rick Kazman COLOR-X - using knowledge from WordNet for conceptual modelling, J.F.M. Burg and R.P. van de Riet knowledge processing on an extended WordNet, Sanda M. Harabagiu and Dan I Moldovan appendix - obtaining and using WordNet."
            },
            "slug": "WordNet-:-an-electronic-lexical-database-Fellbaum",
            "title": {
                "fragments": [],
                "text": "WordNet : an electronic lexical database"
            },
            "tldr": {
                "abstractSimilarityScore": 65,
                "text": "The lexical database: nouns in WordNet, Katherine J. Miller a semantic network of English verbs, and applications of WordNet: building semantic concordances are presented."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1744846"
                        ],
                        "name": "Jeffrey P. Bigham",
                        "slug": "Jeffrey-P.-Bigham",
                        "structuredName": {
                            "firstName": "Jeffrey",
                            "lastName": "Bigham",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jeffrey P. Bigham"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712587"
                        ],
                        "name": "C. Jayant",
                        "slug": "C.-Jayant",
                        "structuredName": {
                            "firstName": "Chandrika",
                            "lastName": "Jayant",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Jayant"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1737220"
                        ],
                        "name": "H. Ji",
                        "slug": "H.-Ji",
                        "structuredName": {
                            "firstName": "Hanjie",
                            "lastName": "Ji",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Ji"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48155668"
                        ],
                        "name": "Greg Little",
                        "slug": "Greg-Little",
                        "structuredName": {
                            "firstName": "Greg",
                            "lastName": "Little",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Greg Little"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144360239"
                        ],
                        "name": "Andrew Miller",
                        "slug": "Andrew-Miller",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Miller",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Miller"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152160465"
                        ],
                        "name": "Rob Miller",
                        "slug": "Rob-Miller",
                        "structuredName": {
                            "firstName": "Rob",
                            "lastName": "Miller",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Rob Miller"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152160465"
                        ],
                        "name": "Rob Miller",
                        "slug": "Rob-Miller",
                        "structuredName": {
                            "firstName": "Rob",
                            "lastName": "Miller",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Rob Miller"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1715819"
                        ],
                        "name": "Aubrey Tatarowicz",
                        "slug": "Aubrey-Tatarowicz",
                        "structuredName": {
                            "firstName": "Aubrey",
                            "lastName": "Tatarowicz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Aubrey Tatarowicz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "37929982"
                        ],
                        "name": "B. White",
                        "slug": "B.-White",
                        "structuredName": {
                            "firstName": "Brandyn",
                            "lastName": "White",
                            "middleNames": [
                                "Allen"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. White"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144289340"
                        ],
                        "name": "Samuel White",
                        "slug": "Samuel-White",
                        "structuredName": {
                            "firstName": "Samuel",
                            "lastName": "White",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Samuel White"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2059814276"
                        ],
                        "name": "Tom Yeh",
                        "slug": "Tom-Yeh",
                        "structuredName": {
                            "firstName": "Tom",
                            "lastName": "Yeh",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tom Yeh"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 52804681,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8a960ea40fe7b32a1ee702a84f64ec1de5c3e7fe",
            "isKey": false,
            "numCitedBy": 533,
            "numCiting": 40,
            "paperAbstract": {
                "fragments": [],
                "text": "The lack of access to visual information like text labels, icons, and colors can cause frustration and decrease independence for blind people. Current access technology uses automatic approaches to address some problems in this space, but the technology is error-prone, limited in scope, and quite expensive. In this paper, we introduce VizWiz, a talking application for mobile phones that offers a new alternative to answering visual questions in nearly real-time - asking multiple people on the web. To support answering questions quickly, we introduce a general approach for intelligently recruiting human workers in advance called quikTurkit so that workers are available when new questions arrive. A field deployment with 11 blind participants illustrates that blind people can effectively use VizWiz to cheaply answer questions in their everyday lives, highlighting issues that automatic approaches will need to address to be useful. Finally, we illustrate the potential of using VizWiz as part of the participatory design of advanced tools by using it to build and evaluate VizWiz::LocateIt, an interactive mobile tool that helps blind people solve general visual search problems."
            },
            "slug": "VizWiz:-nearly-real-time-answers-to-visual-Bigham-Jayant",
            "title": {
                "fragments": [],
                "text": "VizWiz: nearly real-time answers to visual questions"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "VizWiz is introduced, a talking application for mobile phones that offers a new alternative to answering visual questions in nearly real-time - asking multiple people on the web to support answering questions quickly."
            },
            "venue": {
                "fragments": [],
                "text": "UIST"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1744846"
                        ],
                        "name": "Jeffrey P. Bigham",
                        "slug": "Jeffrey-P.-Bigham",
                        "structuredName": {
                            "firstName": "Jeffrey",
                            "lastName": "Bigham",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jeffrey P. Bigham"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712587"
                        ],
                        "name": "C. Jayant",
                        "slug": "C.-Jayant",
                        "structuredName": {
                            "firstName": "Chandrika",
                            "lastName": "Jayant",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Jayant"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1737220"
                        ],
                        "name": "H. Ji",
                        "slug": "H.-Ji",
                        "structuredName": {
                            "firstName": "Hanjie",
                            "lastName": "Ji",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Ji"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48155668"
                        ],
                        "name": "Greg Little",
                        "slug": "Greg-Little",
                        "structuredName": {
                            "firstName": "Greg",
                            "lastName": "Little",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Greg Little"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144360239"
                        ],
                        "name": "Andrew Miller",
                        "slug": "Andrew-Miller",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Miller",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Miller"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152160465"
                        ],
                        "name": "Rob Miller",
                        "slug": "Rob-Miller",
                        "structuredName": {
                            "firstName": "Rob",
                            "lastName": "Miller",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Rob Miller"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1715819"
                        ],
                        "name": "Aubrey Tatarowicz",
                        "slug": "Aubrey-Tatarowicz",
                        "structuredName": {
                            "firstName": "Aubrey",
                            "lastName": "Tatarowicz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Aubrey Tatarowicz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "37929982"
                        ],
                        "name": "B. White",
                        "slug": "B.-White",
                        "structuredName": {
                            "firstName": "Brandyn",
                            "lastName": "White",
                            "middleNames": [
                                "Allen"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. White"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144289340"
                        ],
                        "name": "Samuel White",
                        "slug": "Samuel-White",
                        "structuredName": {
                            "firstName": "Samuel",
                            "lastName": "White",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Samuel White"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2059814276"
                        ],
                        "name": "Tom Yeh",
                        "slug": "Tom-Yeh",
                        "structuredName": {
                            "firstName": "Tom",
                            "lastName": "Yeh",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tom Yeh"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 10,
                                "start": 7
                            }
                        ],
                        "text": "VizWiz [1] labels the presence of objects in images to help blind users."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 207179082,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e0c668d1da866617ccfeee910d13eb14fa340bea",
            "isKey": false,
            "numCitedBy": 288,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "Visual information pervades our environment. Vision is used to decide everything from what we want to eat at a restaurant and which bus route to take to whether our clothes match and how long until the milk expires. Individually, the inability to interpret such visual information is a nuisance for blind people who often have effective, if inefficient, work-arounds to overcome them. Collectively, however, they can make blind people less independent. Specialized technology addresses some problems in this space, but automatic approaches cannot yet answer the vast majority of visual questions that blind people may have. VizWiz addresses this shortcoming by using the Internet connections and cameras on existing smartphones to connect blind people and their questions to remote paid workers' answers. VizWiz is designed to have low latency and low cost, making it both competitive with expensive automatic solutions and much more versatile."
            },
            "slug": "VizWiz:-nearly-real-time-answers-to-visual-Bigham-Jayant",
            "title": {
                "fragments": [],
                "text": "VizWiz: nearly real-time answers to visual questions"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "VizWiz uses the Internet connections and cameras on existing smartphones to connect blind people and their questions to remote paid workers' answers, making it both competitive with expensive automatic solutions and much more versatile."
            },
            "venue": {
                "fragments": [],
                "text": "W4A"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38853744"
                        ],
                        "name": "Yi Zhang",
                        "slug": "Yi-Zhang",
                        "structuredName": {
                            "firstName": "Yi",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yi Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1691727"
                        ],
                        "name": "S. Burer",
                        "slug": "S.-Burer",
                        "structuredName": {
                            "firstName": "Samuel",
                            "lastName": "Burer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Burer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2562282"
                        ],
                        "name": "W. N. Street",
                        "slug": "W.-N.-Street",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Street",
                            "middleNames": [
                                "Nick"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. N. Street"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 278,
                                "start": 274
                            }
                        ],
                        "text": "This technique is important in multiple domains, such as labeling actions in videos [11], news article topics [15], functional classes of genes [8], musical attributes or emotions in songs [12], semantic classes of scenes [2], product categories customers are likely to buy [21], and categories of web pages [18]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 3187495,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3f99c19bfd65cc16ff9518f2240b620cf0d2064f",
            "isKey": false,
            "numCitedBy": 279,
            "numCiting": 53,
            "paperAbstract": {
                "fragments": [],
                "text": "An ensemble is a group of learning models that jointly solve a problem. However, the ensembles generated by existing techniques are sometimes unnecessarily large, which can lead to extra memory usage, computational costs, and occasional decreases in effectiveness. The purpose of ensemble pruning is to search for a good subset of ensemble members that performs as well as, or better than, the original ensemble. This subset selection problem is a combinatorial optimization problem and thus finding the exact optimal solution is computationally prohibitive. Various heuristic methods have been developed to obtain an approximate solution. However, most of the existing heuristics use simple greedy search as the optimization method, which lacks either theoretical or empirical quality guarantees. In this paper, the ensemble subset selection problem is formulated as a quadratic integer programming problem. By applying semi-definite programming (SDP) as a solution technique, we are able to get better approximate solutions. Computational experiments show that this SDP-based pruning algorithm outperforms other heuristics in the literature. Its application in a classifier-sharing study also demonstrates the effectiveness of the method."
            },
            "slug": "Ensemble-Pruning-Via-Semi-definite-Programming-Zhang-Burer",
            "title": {
                "fragments": [],
                "text": "Ensemble Pruning Via Semi-definite Programming"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "By applying semi-definite programming (SDP) as a solution technique, the ensemble subset selection problem is formulated as a quadratic integer programming problem and the SDP-based pruning algorithm outperforms other heuristics in the literature."
            },
            "venue": {
                "fragments": [],
                "text": "J. Mach. Learn. Res."
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39393021"
                        ],
                        "name": "Jon Noronha",
                        "slug": "Jon-Noronha",
                        "structuredName": {
                            "firstName": "Jon",
                            "lastName": "Noronha",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jon Noronha"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3023163"
                        ],
                        "name": "Eric Hysen",
                        "slug": "Eric-Hysen",
                        "structuredName": {
                            "firstName": "Eric",
                            "lastName": "Hysen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Eric Hysen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3162562"
                        ],
                        "name": "Haoqi Zhang",
                        "slug": "Haoqi-Zhang",
                        "structuredName": {
                            "firstName": "Haoqi",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Haoqi Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1770992"
                        ],
                        "name": "Krzysztof Z Gajos",
                        "slug": "Krzysztof-Z-Gajos",
                        "structuredName": {
                            "firstName": "Krzysztof",
                            "lastName": "Gajos",
                            "middleNames": [
                                "Z"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Krzysztof Z Gajos"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 13618819,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "632ffa1766498ba20a5e00138a891ba11520d35c",
            "isKey": false,
            "numCitedBy": 276,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce PlateMate, a system that allows users to take photos of their meals and receive estimates of food intake and composition. Accurate awareness of this information can help people monitor their progress towards dieting goals, but current methods for food logging via self-reporting, expert observation, or algorithmic analysis are time-consuming, expensive, or inaccurate. PlateMate crowdsources nutritional analysis from photographs using Amazon Mechanical Turk, automatically coordinating untrained workers to estimate a meal's calories, fat, carbohydrates, and protein. We present the Management framework for crowdsourcing complex tasks, which supports PlateMate's nutrition analysis workflow. Results of our evaluations show that PlateMate is nearly as accurate as a trained dietitian and easier to use for most users than traditional self-reporting."
            },
            "slug": "Platemate:-crowdsourcing-nutritional-analysis-from-Noronha-Hysen",
            "title": {
                "fragments": [],
                "text": "Platemate: crowdsourcing nutritional analysis from food photographs"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "Results of the evaluations show that PlateMate is nearly as accurate as a trained dietitian and easier to use for most users than traditional self-reporting."
            },
            "venue": {
                "fragments": [],
                "text": "UIST"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145879842"
                        ],
                        "name": "Michael S. Bernstein",
                        "slug": "Michael-S.-Bernstein",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Bernstein",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael S. Bernstein"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145671153"
                        ],
                        "name": "Joel Brandt",
                        "slug": "Joel-Brandt",
                        "structuredName": {
                            "firstName": "Joel",
                            "lastName": "Brandt",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Joel Brandt"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152160465"
                        ],
                        "name": "Rob Miller",
                        "slug": "Rob-Miller",
                        "structuredName": {
                            "firstName": "Rob",
                            "lastName": "Miller",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Rob Miller"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1743286"
                        ],
                        "name": "D. Karger",
                        "slug": "D.-Karger",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Karger",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Karger"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6921166,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4874157301f8d21dbe7acb304fe2fb2081bb4435",
            "isKey": false,
            "numCitedBy": 343,
            "numCiting": 42,
            "paperAbstract": {
                "fragments": [],
                "text": "Interactive systems must respond to user input within seconds. Therefore, to create realtime crowd-powered interfaces, we need to dramatically lower crowd latency. In this paper, we introduce the use of synchronous crowds for on-demand, realtime crowdsourcing. With synchronous crowds, systems can dynamically adapt tasks by leveraging the fact that workers are present at the same time. We develop techniques that recruit synchronous crowds in two seconds and use them to execute complex search tasks in ten seconds. The first technique, the retainer model, pays workers a small wage to wait and respond quickly when asked. We offer empirically derived guidelines for a retainer system that is low-cost and produces on-demand crowds in two seconds. Our second technique, rapid refinement, observes early signs of agreement in synchronous crowds and dynamically narrows the search space to focus on promising directions. This approach produces results that, on average, are of more reliable quality and arrive faster than the fastest crowd member working alone. To explore benefits and limitations of these techniques for interaction, we present three applications: Adrenaline, a crowd-powered camera where workers quickly filter a short video down to the best single moment for a photo; and Puppeteer and A|B, which examine creative generation tasks, communication with workers, and low-latency voting."
            },
            "slug": "Crowds-in-two-seconds:-enabling-realtime-interfaces-Bernstein-Brandt",
            "title": {
                "fragments": [],
                "text": "Crowds in two seconds: enabling realtime crowd-powered interfaces"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "This paper develops techniques that recruit synchronous crowds in two seconds and use them to execute complex search tasks in ten seconds, and offers empirically derived guidelines for a retainer system that is low-cost and produces on-demand crowds inTwo seconds."
            },
            "venue": {
                "fragments": [],
                "text": "UIST"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50289773"
                        ],
                        "name": "Tao Li",
                        "slug": "Tao-Li",
                        "structuredName": {
                            "firstName": "Tao",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tao Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144669577"
                        ],
                        "name": "M. Ogihara",
                        "slug": "M.-Ogihara",
                        "structuredName": {
                            "firstName": "Mitsunori",
                            "lastName": "Ogihara",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Ogihara"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 193,
                                "start": 189
                            }
                        ],
                        "text": "This technique is important in multiple domains, such as labeling actions in videos [11], news article topics [15], functional classes of genes [8], musical attributes or emotions in songs [12], semantic classes of scenes [2], product categories customers are likely to buy [21], and categories of web pages [18]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7621113,
            "fieldsOfStudy": [
                "Art",
                "Computer Science"
            ],
            "id": "b8d4e264a040ea6b2fbeabc51028f55cee0170de",
            "isKey": false,
            "numCitedBy": 312,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "Music is not only for entertainment and for pleasure, but has been used for a wide range of purposes due to its social and physiological effects. Traditionally musical information has been retrieved and/or classified based on standard reference information, such as the name of the composer and the title of the work etc. These basic pieces information will remain essential, but information retrieval based on these are far from satisfactory. Huron points out that since the preeminent functions of music are social and psychological, the most useful characterization would be based on four types of information: the style, emotion, genre, and similarity [Huron,2000]."
            },
            "slug": "Detecting-emotion-in-music-Li-Ogihara",
            "title": {
                "fragments": [],
                "text": "Detecting emotion in music"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "Since the preeminent functions of music are social and psychological, the most useful characterization would be based on four types of information: the style, emotion, genre, and similarity."
            },
            "venue": {
                "fragments": [],
                "text": "ISMIR"
            },
            "year": 2003
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "corpusId": 57882390,
            "fieldsOfStudy": [],
            "id": "f647923b9c2e535aba292e52c60182cfdc1c93c6",
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Speed of processing in the human visual system"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "2 Actual queries are longer and include detailed definitions"
            },
            "venue": {
                "fragments": [],
                "text": "2 Actual queries are longer and include detailed definitions"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Actual queries are longer and include detailed definitions"
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 17
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 27,
        "totalPages": 3
    },
    "page_url": "https://www.semanticscholar.org/paper/Scalable-multi-label-annotation-Deng-Russakovsky/8ab9d01469b542434e0e47428aa25e233824ea80?sort=total-citations"
}