{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1864000"
                        ],
                        "name": "E. Guevara",
                        "slug": "E.-Guevara",
                        "structuredName": {
                            "firstName": "Emiliano",
                            "lastName": "Guevara",
                            "middleNames": [
                                "Ra\u00fal"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Guevara"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 17414711,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "96fa75d886643fa1621cc30f4f55c0a22c2e49d5",
            "isKey": false,
            "numCitedBy": 141,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we explore the computational modelling of compositionality in distributional models of semantics. In particular, we model the semantic composition of pairs of adjacent English Adjectives and Nouns from the British National Corpus. We build a vector-based semantic space from a lemmatised version of the BNC, where the most frequent A-N lemma pairs are treated as single tokens. We then extrapolate three different models of compositionality: a simple additive model, a pointwise-multiplicative model and a Partial Least Squares Regression (PLSR) model. We propose two evaluation methods for the implemented models. Our study leads to the conclusion that regression-based models of compositionality generally out-perform additive and multiplicative approaches, and also show a number of advantages that make them very promising for future research."
            },
            "slug": "A-Regression-Model-of-Adjective-Noun-in-Semantics-Guevara",
            "title": {
                "fragments": [],
                "text": "A Regression Model of Adjective-Noun Compositionality in Distributional Semantics"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "This study leads to the conclusion that regression-based models of compositionality generally out-perform additive and multiplicative approaches, and also show a number of advantages that make them very promising for future research."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3025325"
                        ],
                        "name": "W. Kintsch",
                        "slug": "W.-Kintsch",
                        "structuredName": {
                            "firstName": "Walter",
                            "lastName": "Kintsch",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Kintsch"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 191,
                                "start": 129
                            }
                        ],
                        "text": "common approach to composition in the earlier literature, typically with the scalar weights set to 1 or to normalizing constants (Foltz et al., 1998; Kintsch, 2001; Landauer and Dumais, 1997)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 219322170,
            "fieldsOfStudy": [
                "Philosophy"
            ],
            "id": "040a6d4542111c1b6161533aa0818c0b025505a0",
            "isKey": false,
            "numCitedBy": 562,
            "numCiting": 57,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Predication-Kintsch",
            "title": {
                "fragments": [],
                "text": "Predication"
            },
            "venue": {
                "fragments": [],
                "text": "Cogn. Sci."
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153584694"
                        ],
                        "name": "R. Rapp",
                        "slug": "R.-Rapp",
                        "structuredName": {
                            "firstName": "Reinhard",
                            "lastName": "Rapp",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Rapp"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 111,
                                "start": 57
                            }
                        ],
                        "text": "lem, it often improves the quality of the semantic space (Landauer and Dumais, 1997; Rapp, 2003; Sch\u00fctze, 1997)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1171753,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b62fce4fc3476e36545acff0a4d0627326959a53",
            "isKey": false,
            "numCitedBy": 141,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "In machine translation, information on word ambiguities is usually provided by the lexicographers who construct the lexicon. In this paper we propose an automatic method for word sense induction, i.e. for the discovery of a set of sense descriptors to a given ambiguous word. The approach is based on the statistics of the distributional similarity between the words in a corpus. Our algorithm works as follows: The 20 strongest first-order associations to the ambiguous word are considered as sense descriptor candidates. All pairs of these candidates are ranked according to the following two criteria: First, the two words in a pair should be as dissimilar as possible. Second, although being dissimilar their co-occurrence vectors should add up to the co-occurrence vector of the ambiguous word scaled by two. Both conditions together have the effect that preference is given to pairs whose co-occurring words are complementary. For best results, our implementation uses singular value decomposition, entropy-based weights, and second-order similarity metrics."
            },
            "slug": "Word-sense-discovery-based-on-sense-descriptor-Rapp",
            "title": {
                "fragments": [],
                "text": "Word sense discovery based on sense descriptor dissimilarity"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This paper proposes an automatic method for word sense induction, i.e. for the discovery of a set of sense descriptors to a given ambiguous word, based on the statistics of the distributional similarity between the words in a corpus."
            },
            "venue": {
                "fragments": [],
                "text": "MTSUMMIT"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1708114"
                        ],
                        "name": "Katrin Erk",
                        "slug": "Katrin-Erk",
                        "structuredName": {
                            "firstName": "Katrin",
                            "lastName": "Erk",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Katrin Erk"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1708581"
                        ],
                        "name": "Sebastian Pad\u00f3",
                        "slug": "Sebastian-Pad\u00f3",
                        "structuredName": {
                            "firstName": "Sebastian",
                            "lastName": "Pad\u00f3",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sebastian Pad\u00f3"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1588782,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cb9cc883bdd08d58feee5c7da01acff6fdb4ad78",
            "isKey": false,
            "numCitedBy": 387,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": "We address the task of computing vector space representations for the meaning of word occurrences, which can vary widely according to context. This task is a crucial step towards a robust, vector-based compositional account of sentence meaning. We argue that existing models for this task do not take syntactic structure sufficiently into account. \n \nWe present a novel structured vector space model that addresses these issues by incorporating the selectional preferences for words' argument positions. This makes it possible to integrate syntax into the computation of word meaning in context. In addition, the model performs at and above the state of the art for modeling the contextual adequacy of paraphrases."
            },
            "slug": "A-Structured-Vector-Space-Model-for-Word-Meaning-in-Erk-Pad\u00f3",
            "title": {
                "fragments": [],
                "text": "A Structured Vector Space Model for Word Meaning in Context"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A novel structured vector space model is presented that makes it possible to integrate syntax into the computation of word meaning in context and performs at and above the state of the art for modeling the contextual adequacy of paraphrases."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144523372"
                        ],
                        "name": "S. Clark",
                        "slug": "S.-Clark",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Clark",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Clark"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50419262"
                        ],
                        "name": "S. Pulman",
                        "slug": "S.-Pulman",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Pulman",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Pulman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2280191,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "73e897104540642698321c106cc9c35af369fe12",
            "isKey": false,
            "numCitedBy": 144,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "The are two main approaches to the representation of meaning in Computational Linguistics: a symbolic approach and a distributional approach. This paper considers the fundamental question of how these approaches might be combined. The proposal is to adapt a method from the Cognitive Science literature, in which symbolic and connectionist representations are combined using tensor products. Possible applications of this method for language processing are described. Finally, a potentially fruitful link between Quantum Mechanics, Computational Linguistics, and other related areas such as Information Retrieval and Machine Learning, is proposed."
            },
            "slug": "Combining-Symbolic-and-Distributional-Models-of-Clark-Pulman",
            "title": {
                "fragments": [],
                "text": "Combining Symbolic and Distributional Models of Meaning"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A method is to be adapted from the Cognitive Science literature, in which symbolic and connectionist representations are combined using tensor products, to adapt a method for language processing."
            },
            "venue": {
                "fragments": [],
                "text": "AAAI Spring Symposium: Quantum Interaction"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2036336"
                        ],
                        "name": "P. Foltz",
                        "slug": "P.-Foltz",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Foltz",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Foltz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3025325"
                        ],
                        "name": "W. Kintsch",
                        "slug": "W.-Kintsch",
                        "structuredName": {
                            "firstName": "Walter",
                            "lastName": "Kintsch",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Kintsch"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1836606"
                        ],
                        "name": "T. Landauer",
                        "slug": "T.-Landauer",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Landauer",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Landauer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 194,
                                "start": 176
                            }
                        ],
                        "text": "Their simplified additive model p = \u03b1u+\u03b2v was a common approach to composition in the earlier literature, typically with the scalar weights set to 1 or to normalizing constants (Foltz et al., 1998; Kintsch, 2001; Landauer and Dumais, 1997)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 191,
                                "start": 129
                            }
                        ],
                        "text": "common approach to composition in the earlier literature, typically with the scalar weights set to 1 or to normalizing constants (Foltz et al., 1998; Kintsch, 2001; Landauer and Dumais, 1997)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 62729021,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c4732c036d0b00d435bcd41ae904a9e936e4f683",
            "isKey": false,
            "numCitedBy": 793,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "Latent Semantic Analysis (LSA) is used as a technique for measuring the coherence of texts. By comparing the vectors for 2 adjoining segments of text in a high\u2010dimensional semantic space, the method provides a characterization of the degree of semantic relatedness between the segments. We illustrate the approach for predicting coherence through reanalyzing sets of texts from 2 studies that manipulated the coherence of texts and assessed readers\u2019 comprehension. The results indicate that the method is able to predict the effect of text coherence on comprehension and is more effective than simple term\u2010term overlap measures. In this manner, LSA can be applied as an automated method that produces coherence predictions similar to propositional modeling. We describe additional studies investigating the application of LSA to analyzing discourse structure and examine the potential of LSA as a psychological model of coherence effects in text comprehension."
            },
            "slug": "The-Measurement-of-Textual-Coherence-with-Latent-Foltz-Kintsch",
            "title": {
                "fragments": [],
                "text": "The Measurement of Textual Coherence with Latent Semantic Analysis."
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "The approach for predicting coherence through reanalyzing sets of texts from 2 studies that manipulated the coherence of texts and assessed readers\u2019 comprehension indicates that the method is able to predict the effect of text coherence on comprehension and is more effective than simple term\u2010term overlap measures."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1689647"
                        ],
                        "name": "Peter D. Turney",
                        "slug": "Peter-D.-Turney",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Turney",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Peter D. Turney"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1990190"
                        ],
                        "name": "P. Pantel",
                        "slug": "P.-Pantel",
                        "structuredName": {
                            "firstName": "Patrick",
                            "lastName": "Pantel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Pantel"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 244,
                                "start": 203
                            }
                        ],
                        "text": "An influential approach for representing the meaning of a word in NLP is to treat it as a vector that codes the pattern of co-occurrence of that word with other expressions in a large corpus of language (Sahlgren, 2006; Turney and Pantel, 2010)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1500900,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3a0e788268fafb23ab20da0e98bb578b06830f7d",
            "isKey": false,
            "numCitedBy": 2724,
            "numCiting": 208,
            "paperAbstract": {
                "fragments": [],
                "text": "Computers understand very little of the meaning of human language. This profoundly limits our ability to give instructions to computers, the ability of computers to explain their actions to us, and the ability of computers to analyse and process text. Vector space models (VSMs) of semantics are beginning to address these limits. This paper surveys the use of VSMs for semantic processing of text. We organize the literature on VSMs according to the structure of the matrix in a VSM. There are currently three broad classes of VSMs, based on term-document, word-context, and pair-pattern matrices, yielding three classes of applications. We survey a broad range of applications in these three categories and we take a detailed look at a specific open source project in each category. Our goal in this survey is to show the breadth of applications of VSMs for semantics, to provide a new perspective on VSMs for those who are already familiar with the area, and to provide pointers into the literature for those who are less familiar with the field."
            },
            "slug": "From-Frequency-to-Meaning:-Vector-Space-Models-of-Turney-Pantel",
            "title": {
                "fragments": [],
                "text": "From Frequency to Meaning: Vector Space Models of Semantics"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "The goal in this survey is to show the breadth of applications of VSMs for semantics, to provide a new perspective on VSMs, and to provide pointers into the literature for those who are less familiar with the field."
            },
            "venue": {
                "fragments": [],
                "text": "J. Artif. Intell. Res."
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1689109"
                        ],
                        "name": "Magnus Sahlgren",
                        "slug": "Magnus-Sahlgren",
                        "structuredName": {
                            "firstName": "Magnus",
                            "lastName": "Sahlgren",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Magnus Sahlgren"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2078819344"
                        ],
                        "name": "Anders Holst",
                        "slug": "Anders-Holst",
                        "structuredName": {
                            "firstName": "Anders",
                            "lastName": "Holst",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Anders Holst"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3298207"
                        ],
                        "name": "P. Kanerva",
                        "slug": "P.-Kanerva",
                        "structuredName": {
                            "firstName": "Pentti",
                            "lastName": "Kanerva",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Kanerva"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 200,
                                "start": 152
                            }
                        ],
                        "text": "semantics encompasses various related topics, some of them not of direct interest here, such as how to encode word order information in context vectors (Jones and Mewhort, 2007; Sahlgren et al., 2008) or sophisticated composition methods based on tensor products, quantum logic, etc."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 170,
                                "start": 149
                            }
                        ],
                        "text": "\u2026related topics, some of them not of direct interest here, such as how to\nencode word order information in context vectors (Jones and Mewhort, 2007; Sahlgren et al., 2008) or sophisticated composition methods based on tensor products, quantum logic, etc., that have not yet been empirically tested\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 17182082,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "673b15746dd4ba0e70f038cf52f56dae1faeb744",
            "isKey": false,
            "numCitedBy": 175,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "We show that sequence information can be encoded into high-dimensional fixed-width vectors using permutations of coordinates. Computational models of language often represent words with high-dimensional semantic vectors compiled from word-use statistics. A word's semantic vector usually encodes the contexts in which the word appears in a large body of text but ignores word order. However, word order often signals a word's grammatical role in a sentence and thus tells of the word's meaning. Jones and Mewhort (2007) show that word order can be included in the semantic vectors using holographic reduced representation and convolution. We show here that the order information can be captured also by permuting of vector coordinates, thus providing a general and computationally light alternative to convolution."
            },
            "slug": "Permutations-as-a-means-to-encode-order-in-word-Sahlgren-Holst",
            "title": {
                "fragments": [],
                "text": "Permutations as a means to encode order in word space"
            },
            "tldr": {
                "abstractSimilarityScore": 75,
                "text": "It is shown that sequence information can be encoded into high-dimensional fixed-width vectors using permutations of coordinates, thus providing a general and computationally light alternative to convolution."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2111327888"
                        ],
                        "name": "Michael N. Jones",
                        "slug": "Michael-N.-Jones",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Jones",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael N. Jones"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1821878"
                        ],
                        "name": "D. Mewhort",
                        "slug": "D.-Mewhort",
                        "structuredName": {
                            "firstName": "Douglas",
                            "lastName": "Mewhort",
                            "middleNames": [
                                "J.",
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Mewhort"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 200,
                                "start": 152
                            }
                        ],
                        "text": "semantics encompasses various related topics, some of them not of direct interest here, such as how to encode word order information in context vectors (Jones and Mewhort, 2007; Sahlgren et al., 2008) or sophisticated composition methods based on tensor products, quantum logic, etc."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7819391,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "d3cf28ab36ff7f7601a55c1e832736b2473a07f0",
            "isKey": false,
            "numCitedBy": 576,
            "numCiting": 164,
            "paperAbstract": {
                "fragments": [],
                "text": "The authors present a computational model that builds a holographic lexicon representing both word meaning and word order from unsupervised experience with natural language. The model uses simple convolution and superposition mechanisms (cf. B. B. Murdock, 1982) to learn distributed holographic representations for words. The structure of the resulting lexicon can account for empirical data from classic experiments studying semantic typicality, categorization, priming, and semantic constraint in sentence completions. Furthermore, order information can be retrieved from the holographic representations, allowing the model to account for limited word transitions without the need for built-in transition rules. The model demonstrates that a broad range of psychological data can be accounted for directly from the structure of lexical representations learned in this way, without the need for complexity to be built into either the processing mechanisms or the representations. The holographic representations are an appropriate knowledge representation to be used by higher order models of language comprehension, relieving the complexity required at the higher level."
            },
            "slug": "Representing-word-meaning-and-order-information-in-Jones-Mewhort",
            "title": {
                "fragments": [],
                "text": "Representing word meaning and order information in a composite holographic lexicon."
            },
            "tldr": {
                "abstractSimilarityScore": 63,
                "text": "A computational model that builds a holographic lexicon representing both word meaning and word order from unsupervised experience with natural language demonstrates that a broad range of psychological data can be accounted for directly from the structure of lexical representations learned in this way, without the need for complexity to be built into either the processing mechanisms or the representations."
            },
            "venue": {
                "fragments": [],
                "text": "Psychological review"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34902160"
                        ],
                        "name": "Jeff Mitchell",
                        "slug": "Jeff-Mitchell",
                        "structuredName": {
                            "firstName": "Jeff",
                            "lastName": "Mitchell",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jeff Mitchell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1747893"
                        ],
                        "name": "Mirella Lapata",
                        "slug": "Mirella-Lapata",
                        "structuredName": {
                            "firstName": "Mirella",
                            "lastName": "Lapata",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mirella Lapata"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 18597583,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b5d67d1dc671bce42a9daac0c3605adb3fcfc697",
            "isKey": false,
            "numCitedBy": 730,
            "numCiting": 133,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper proposes a framework for representing the meaning of phrases and sentences in vector space. Central to our approach is vector composition which we operationalize in terms of additive and multiplicative functions. Under this framework, we introduce a wide range of composition models which we evaluate empirically on a sentence similarity task. Experimental results demonstrate that the multiplicative models are superior to the additive alternatives when compared against human judgments."
            },
            "slug": "Vector-based-Models-of-Semantic-Composition-Mitchell-Lapata",
            "title": {
                "fragments": [],
                "text": "Vector-based Models of Semantic Composition"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "Under this framework, a wide range of composition models are introduced which are evaluated empirically on a sentence similarity task and demonstrate that the multiplicative models are superior to the additive alternatives when compared against human judgments."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1836606"
                        ],
                        "name": "T. Landauer",
                        "slug": "T.-Landauer",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Landauer",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Landauer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1728602"
                        ],
                        "name": "S. Dumais",
                        "slug": "S.-Dumais",
                        "structuredName": {
                            "firstName": "Susan",
                            "lastName": "Dumais",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Dumais"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1144461,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "68dd4b89ce1407372a29d05ca9e4e1a2e0513617",
            "isKey": false,
            "numCitedBy": 5788,
            "numCiting": 210,
            "paperAbstract": {
                "fragments": [],
                "text": "How do people know as much as they do with as little information as they get? The problem takes many forms; learning vocabulary from text is an especially dramatic and convenient case for research. A new general theory of acquired similarity and knowledge representation, latent semantic analysis (LSA), is presented and used to successfully simulate such learning and several other psycholinguistic phenomena. By inducing global knowledge indirectly from local co-occurrence data in a large body of representative text, LSA acquired knowledge about the full vocabulary of English at a comparable rate to schoolchildren. LSA uses no prior linguistic or perceptual similarity knowledge; it is based solely on a general mathematical learning method that achieves powerful inductive effects by extracting the right number of dimensions (e.g., 300) to represent objects and contexts. Relations to other theories, phenomena, and problems are sketched."
            },
            "slug": "A-Solution-to-Plato's-Problem:-The-Latent-Semantic-Landauer-Dumais",
            "title": {
                "fragments": [],
                "text": "A Solution to Plato's Problem: The Latent Semantic Analysis Theory of Acquisition, Induction, and Representation of Knowledge."
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "A new general theory of acquired similarity and knowledge representation, latent semantic analysis (LSA), is presented and used to successfully simulate such learning and several other psycholinguistic phenomena."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1802811"
                        ],
                        "name": "D. Widdows",
                        "slug": "D.-Widdows",
                        "structuredName": {
                            "firstName": "Dominic",
                            "lastName": "Widdows",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Widdows"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 12044606,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7c69a90236f1c57348de858918c554a9420f1521",
            "isKey": false,
            "numCitedBy": 118,
            "numCiting": 42,
            "paperAbstract": {
                "fragments": [],
                "text": "Semantic vector models have proven their worth in a number of natural language applications whose goals can be accomplished by modelling individual semantic concepts and measuring similarities between them. By comparison, the area of semantic compositionality in these models has so far remained underdeveloped. This will be a crucial hurdle for semantic vector models: in order to play a fuller part in the modelling of human language, these models will need some way of modelling the way in which single concepts are put together to form more complex conceptual structures. This paper explores some of the opportunities for using vector product operations to model compositional phenomena in natural language. These vector operations are all well-known and used in mathematics and physics, particularly in quantum mechanics. Instead of designing new vector composition operators, this paper gathers a list of existing operators, and a list of typical composition operations in natural language, and describes two small experiments that begin to investigate the use of certain vector operators to model certain"
            },
            "slug": "Semantic-Vector-Products:-Some-Initial-Widdows",
            "title": {
                "fragments": [],
                "text": "Semantic Vector Products: Some Initial Investigations"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This paper gathers a list of existing operators, an list of typical composition operations in natural language, and describes two small experiments that begin to investigate the use of certain vector operators to model certain compositional phenomena innatural language."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47709773"
                        ],
                        "name": "H. Rubenstein",
                        "slug": "H.-Rubenstein",
                        "structuredName": {
                            "firstName": "Herbert",
                            "lastName": "Rubenstein",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Rubenstein"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1898344"
                        ],
                        "name": "J. Goodenough",
                        "slug": "J.-Goodenough",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Goodenough",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Goodenough"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 93,
                                "start": 60
                            }
                        ],
                        "text": "dently validated on a standard similarity judgment data-set (Rubenstein and Goodenough, 1965), obtaining similar (and state-of-the-art-range) Pearson correlations of vector cosines and human judgments in both the original (r = ."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 18309234,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "7ef3ac14cdb484aaa2b039850093febd5cf73a21",
            "isKey": false,
            "numCitedBy": 1460,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "Experimentol corroboration was obtained for the hypothesis that the proportion of words common to the contexts of word A and to the contexts of word B is a function of the degree to which A and B are similar in meaning. The tests were carried out for variously defined contexts. The shapes of the functions, however, indicate that similarity of context is reliable as criterion only for detecting pairs of words that are very similar in meaning."
            },
            "slug": "Contextual-correlates-of-synonymy-Rubenstein-Goodenough",
            "title": {
                "fragments": [],
                "text": "Contextual correlates of synonymy"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The shapes of the functions indicate that similarity of context is reliable as criterion only for detecting pairs of words that are very similar in meaning."
            },
            "venue": {
                "fragments": [],
                "text": "CACM"
            },
            "year": 1965
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1708114"
                        ],
                        "name": "Katrin Erk",
                        "slug": "Katrin-Erk",
                        "structuredName": {
                            "firstName": "Katrin",
                            "lastName": "Erk",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Katrin Erk"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1708581"
                        ],
                        "name": "Sebastian Pad\u00f3",
                        "slug": "Sebastian-Pad\u00f3",
                        "structuredName": {
                            "firstName": "Sebastian",
                            "lastName": "Pad\u00f3",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sebastian Pad\u00f3"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8394214,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1ea92d57e3b7d79d5a11d347a23a9f9330d9c838",
            "isKey": false,
            "numCitedBy": 44,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "The appropriateness of paraphrases for words depends often on context: \"grab\" can replace \"catch\" in \"catch a ball\", but not in \"catch a cold\". Structured Vector Space (SVS) (Erk and Pado, 2008) is a model that computes word meaning in context in order to assess the appropriateness of such paraphrases. This paper investigates \"best-practice\" parameter settings for SVS, and it presents a method to obtain large datasets for paraphrase assessment from corpora with WSD annotation."
            },
            "slug": "Paraphrase-Assessment-in-Structured-Vector-Space:-Erk-Pad\u00f3",
            "title": {
                "fragments": [],
                "text": "Paraphrase Assessment in Structured Vector Space: Exploring Parameters and Datasets"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This paper investigates \"best-practice\" parameter settings for SVS, and it presents a method to obtain large datasets for paraphrase assessment from corpora with WSD annotation."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34902160"
                        ],
                        "name": "Jeff Mitchell",
                        "slug": "Jeff-Mitchell",
                        "structuredName": {
                            "firstName": "Jeff",
                            "lastName": "Mitchell",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jeff Mitchell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1747893"
                        ],
                        "name": "Mirella Lapata",
                        "slug": "Mirella-Lapata",
                        "structuredName": {
                            "firstName": "Mirella",
                            "lastName": "Lapata",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mirella Lapata"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 147,
                                "start": 120
                            }
                        ],
                        "text": "The multiplicative approach also performs best (but only by a small margin) in a later application to language modeling (Mitchell and Lapata, 2009)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5741058,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e420f393bc23839a65a1a32778026bb6eae25fa2",
            "isKey": false,
            "numCitedBy": 86,
            "numCiting": 42,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we propose a novel statistical language model to capture long-range semantic dependencies. Specifically, we apply the concept of semantic composition to the problem of constructing predictive history representations for upcoming words. We also examine the influence of the underlying semantic space on the composition task by comparing spatial semantic representations against topic-based ones. The composition models yield reductions in perplexity when combined with a standard n-gram language model over the n-gram model alone. We also obtain perplexity reductions when integrating our models with a structured language model."
            },
            "slug": "Language-Models-Based-on-Semantic-Composition-Mitchell-Lapata",
            "title": {
                "fragments": [],
                "text": "Language Models Based on Semantic Composition"
            },
            "tldr": {
                "abstractSimilarityScore": 83,
                "text": "A novel statistical language model is proposed to capture long-range semantic dependencies by applying the concept of semantic composition to the problem of constructing predictive history representations for upcoming words."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143730547"
                        ],
                        "name": "S. Rudolph",
                        "slug": "S.-Rudolph",
                        "structuredName": {
                            "firstName": "Sebastian",
                            "lastName": "Rudolph",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Rudolph"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48394537"
                        ],
                        "name": "Eugenie Giesbrecht",
                        "slug": "Eugenie-Giesbrecht",
                        "structuredName": {
                            "firstName": "Eugenie",
                            "lastName": "Giesbrecht",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Eugenie Giesbrecht"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2678583,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d9269fd1efeb87000d346cc8514dec3fc6ec01d6",
            "isKey": false,
            "numCitedBy": 57,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose CMSMs, a novel type of generic compositional models for syntactic and semantic aspects of natural language, based on matrix multiplication. We argue for the structural and cognitive plausibility of this model and show that it is able to cover and combine various common compositional NLP approaches ranging from statistical word space models to symbolic grammar formalisms."
            },
            "slug": "Compositional-Matrix-Space-Models-of-Language-Rudolph-Giesbrecht",
            "title": {
                "fragments": [],
                "text": "Compositional Matrix-Space Models of Language"
            },
            "tldr": {
                "abstractSimilarityScore": 71,
                "text": "CMSMs, a novel type of generic compositional models for syntactic and semantic aspects of natural language, based on matrix multiplication is proposed and it is shown that it is able to cover and combine various common compositional NLP approaches."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1399974318"
                        ],
                        "name": "Ying Zhao",
                        "slug": "Ying-Zhao",
                        "structuredName": {
                            "firstName": "Ying",
                            "lastName": "Zhao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ying Zhao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50877490"
                        ],
                        "name": "G. Karypis",
                        "slug": "G.-Karypis",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Karypis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Karypis"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 74,
                                "start": 50
                            }
                        ],
                        "text": "Cluster quality is evaluated by percentage purity (Zhao and Karypis, 2003)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 58154,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a40f670c985e45e973337284fcb4fd44fe5858fb",
            "isKey": false,
            "numCitedBy": 565,
            "numCiting": 88,
            "paperAbstract": {
                "fragments": [],
                "text": "In recent years, we have witnessed a tremendous growth in the volume of text documents available on the Internet, digital libraries, news sources, and company-wide intranets. This has led to an increased interest in developing methods that can help users to effectively navigate, summarize, and organize this information with the ultimate goal of helping them to find what they are looking for. Fast and high-quality document clustering algorithms play an important role towards this goal as they have been shown to provide both an intuitive navigation/browsing mechanism by organizing large amounts of information into a small number of meaningful clusters as well as to greatly improve the retrieval performance either via cluster-driven dimensionality reduction, term-weighting, or query expansion. This ever-increasing importance of document clustering and the expanded range of its applications led to the development of a number of new and novel algorithms with different complexity-quality trade-offs. Among them, a class of clustering algorithms that have relatively low computational requirements are those that treat the clustering problem as an optimization process which seeks to maximize or minimize a particular clustering criterion function defined over the entire clustering solution. The focus of this paper is to evaluate the performance of different criterion functions for the problem of clustering documents. Our study involves a total of seven different criterion functions, three of which are introduced in this paper and four that have been proposed in the past. Our evaluation consists of both a comprehensive experimental evaluation involving fifteen different datasets, as well as an analysis of the characteristics of the various criterion functions and their effect on the clusters they produce. Our experimental results show that there are a set of criterion functions that consistently outperform the rest, and that some of the newly proposed criterion functions lead to the best overall results. Our theoretical analysis of the criterion function shows that their relative performance depends on (i) the degree to which they can correctly operate when the clusters are of different tightness, and (ii) the degree to which they can lead to reasonably balanced clusters."
            },
            "slug": "Criterion-Functions-for-Document-Clustering-\u2217-and-Zhao-Karypis",
            "title": {
                "fragments": [],
                "text": "Criterion Functions for Document Clustering \u2217 Experiments and Analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This study involves a total of seven different criterion functions, three of which are introduced in this paper and four that have been proposed in the past, and involves both a comprehensive experimental evaluation and an analysis of the characteristics of the various criterion functions and their effect on the clusters they produce."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1748557"
                        ],
                        "name": "P. Smolensky",
                        "slug": "P.-Smolensky",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Smolensky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Smolensky"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 207507745,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "24484e1105bd28acbf0184c94ac9833511328087",
            "isKey": false,
            "numCitedBy": 435,
            "numCiting": 61,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Tensor-Product-Variable-Binding-and-the-of-Symbolic-Smolensky",
            "title": {
                "fragments": [],
                "text": "Tensor Product Variable Binding and the Representation of Symbolic Structures in Connectionist Systems"
            },
            "venue": {
                "fragments": [],
                "text": "Artif. Intell."
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144599392"
                        ],
                        "name": "I. D. Melamed",
                        "slug": "I.-D.-Melamed",
                        "structuredName": {
                            "firstName": "I.",
                            "lastName": "Melamed",
                            "middleNames": [
                                "Dan"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. D. Melamed"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49404233"
                        ],
                        "name": "Hang Li",
                        "slug": "Hang-Li",
                        "structuredName": {
                            "firstName": "Hang",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hang Li"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 53745863,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "e3b32677a976f5a3d6b7837f6fb0aae8041bc9cf",
            "isKey": false,
            "numCitedBy": 23,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Review-of-Ambiguity-resolution-in-language-and-by-Melamed-Li",
            "title": {
                "fragments": [],
                "text": "Review of Ambiguity resolution in language learning: computational and cognitive models by Hinrich Sch\u00fctze. CSLI Publications 1997."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2400157"
                        ],
                        "name": "M. Kenward",
                        "slug": "M.-Kenward",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Kenward",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Kenward"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 19878149,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "75f8a4d7ed6a0f32fa098cac967de247938d9ce5",
            "isKey": false,
            "numCitedBy": 14161,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "15 Empirical Bayes Method, 2nd edition J.S. Maritz and T. Lwin (1989) Symmetric Multivariate and Related Distributions K.-T. Fang, S. Kotz and K. Ng (1989) Ieneralized Linear Models, 2nd edition P. McCullagh and J.A. Neider (1989) 38 Cyclic Designs J.A. John (1987) 39 Analog Estimation Methods in Econometrics C.F. Manski (1988) 40 Subset Selection in Regression A.J. Miller (1990) 41 Analysis of Repeated Measures M. Crowder and D .J. Hand (1990) 42 Statistical Reasoning with Imprecise Probabilities P. Walley (1990) ~3 Generalized Additive Models T.J. Hastie and R.J. Tibshirani (1990) lnspection Errors for Attributes in Quality Control N.L. Johnson, S. Kotz and x. Wu (1991) \u00b75 The Analysis of Contingency Tables, 2nd edition B.S. Everitt (1992) 46 The Analysis of Quantal Response Data B.f.T. Morgan (1992) 47 Longitudinal Data with Serial Correlation: A State-Space Approach R.H. Jones (1993) : Differential Geometry and Statistics M.K. Murray and f. W. Rice (1993) 49 Markov Models and Optimization M.H.A. Davies (1993) 50 Chaos and Networks: Statistical and Probabilistic Aspects Edited by O. Barndorff-Nielsen et al. (1993) Number Theoretic Methods in Statistics K.-T. Fang and W. Yuan (1993) 2 Inference and Asymptotics O. Barndorff-Nielsen and D.R. Cox (1993) ;3 Practical Risk Theory for Actuaries C.D. Daykin, T. Pentikainen and M. Pesonen (1993) 54 Statistical Concepts and Applications in Medicine f. Aitchison and I.f. Lauder (1994) 55 Predictive Inference S. Geisser (1993) 56 Model-Free Curve Estimation M. Tarter and M. Lock (1993) 57 An Introduction to the Bootstrap B. Efron and R . Tibshirani (1993) (Full details concerning this series are available from the Publishers.) An Introduction to the Bootstrap"
            },
            "slug": "An-Introduction-to-the-Bootstrap-Kenward",
            "title": {
                "fragments": [],
                "text": "An Introduction to the Bootstrap"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50877490"
                        ],
                        "name": "G. Karypis",
                        "slug": "G.-Karypis",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Karypis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Karypis"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 49,
                                "start": 34
                            }
                        ],
                        "text": "We cluster with the CLUTO toolkit (Karypis, 2003), using the repeated bisections with global optimization"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 59820993,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "345807c4b360d4bb1f04792bb279bf0487e6f33e",
            "isKey": false,
            "numCitedBy": 587,
            "numCiting": 1,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract : Clustering algorithms divide data into meaningful or useful groups, called clusters, such that the intra-cluster similarity is maximized and the inter-cluster similarity is minimized. These discovered clusters can be used to explain the characteristics of the underlying data distribution and thus serve as the foundation for various data mining and analysis techniques. The applications of clustering include characterization of different customer groups based upon purchasing patterns, categorization of documents on the World Wide Web, grouping of genes and proteins that have similar functionality, grouping of spatial locations prone to earth quakes from seismological data, etc. CLUTO is a software package for clustering low and high dimensional datasets and for analyzing the characteristics of the various clusters."
            },
            "slug": "CLUTO-A-Clustering-Toolkit-Karypis",
            "title": {
                "fragments": [],
                "text": "CLUTO - A Clustering Toolkit"
            },
            "tldr": {
                "abstractSimilarityScore": 95,
                "text": "Clustering algorithms divide data into meaningful or useful groups, called clusters, such that the intra-cluster similarity is maximized and the inter-clusters similarity is minimized."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40360495"
                        ],
                        "name": "Helmut Schmid",
                        "slug": "Helmut-Schmid",
                        "structuredName": {
                            "firstName": "Helmut",
                            "lastName": "Schmid",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Helmut Schmid"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 82,
                                "start": 72
                            }
                        ],
                        "text": "This concatenated corpus, tokenized, POS-tagged and lemmatized with the TreeTagger (Schmid, 1995), contains about 2.83 billion tokens (excluding punctuation, digits, etc.)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 97,
                                "start": 83
                            }
                        ],
                        "text": "This concatenated corpus, tokenized, POS-tagged and lemmatized with the TreeTagger (Schmid, 1995), contains about 2."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 17286912,
            "fieldsOfStudy": [
                "Education"
            ],
            "id": "343d2492caa5265467884d7c172c658a680b7d3d",
            "isKey": true,
            "numCitedBy": 930,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "Work on part-of-speech tagging has concentrated on English in the past, since a lot of manually tagged training material is available for English and results can be compared to those of other researchers. It was assumed that methods which have been developed for English would work for other languages as well.1"
            },
            "slug": "Improvements-in-Part-of-Speech-Tagging-with-an-to-Schmid",
            "title": {
                "fragments": [],
                "text": "Improvements in Part-of-Speech Tagging with an Application to German"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This paper presents a meta-modelling system that automates the very labor-intensive and therefore time-heavy and expensive process of manually tagging part-of-speech content in a variety of languages."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48959839"
                        ],
                        "name": "R. Montague",
                        "slug": "R.-Montague",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Montague",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Montague"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 144783805,
            "fieldsOfStudy": [
                "Art"
            ],
            "id": "93b5b54dfe08fbd4a03de1493d5e3790ed375bac",
            "isKey": false,
            "numCitedBy": 959,
            "numCiting": 1,
            "paperAbstract": {
                "fragments": [],
                "text": "Getting the books formal philosophy selected papers of richard montague now is not type of challenging means. You could not solitary going later than ebook buildup or library or borrowing from your friends to approach them. This is an agreed easy means to specifically get lead by online. This online broadcast formal philosophy selected papers of richard montague can be one of the options to accompany you as soon as having supplementary time."
            },
            "slug": "Formal-philosophy;-selected-papers-of-Richard-Montague",
            "title": {
                "fragments": [],
                "text": "Formal philosophy; selected papers of Richard Montague"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1974
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2331407"
                        ],
                        "name": "Bj\u00f8rn-Helge Mevik",
                        "slug": "Bj\u00f8rn-Helge-Mevik",
                        "structuredName": {
                            "firstName": "Bj\u00f8rn-Helge",
                            "lastName": "Mevik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bj\u00f8rn-Helge Mevik"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2436721"
                        ],
                        "name": "R. Wehrens",
                        "slug": "R.-Wehrens",
                        "structuredName": {
                            "firstName": "Ron",
                            "lastName": "Wehrens",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Wehrens"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 151,
                                "start": 126
                            }
                        ],
                        "text": "We estimate the coefficients using (multivariate) partial least squares regression (PLSR) as implemented in the R pls package (Mevik and Wehrens, 2007)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2372046,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "391e9281618610426b9fb406a2d611cca0b5a200",
            "isKey": false,
            "numCitedBy": 1516,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "The pls package implements principal component regression (PCR) and partial least squares regression (PLSR) in R (R Development Core Team 2006b), and is freely available from the Comprehensive R Archive Network (CRAN), licensed under the GNU General Public License (GPL). The user interface is modelled after the traditional formula interface, as exemplified by lm. This was done so that people used to R would not have to learn yet another interface, and also because we believe the formula interface is a good way of working interactively with models. It thus has methods for generic functions like predict, update and coef. It also has more specialised functions like scores, loadings and RMSEP, and a exible crossvalidation system. Visual inspection and assessment is important in chemometrics, and the pls package has a number of plot functions for plotting scores, loadings, predictions, coefficients and RMSEP estimates. The package implements PCR and several algorithms for PLSR. The design is modular, so that it should be easy to use the underlying algorithms in other functions. It is our hope that the package will serve well both for interactive data analysis and as a building block for other functions or packages using PLSR or PCR. We will here describe the package and how it is used for data analysis, as well as how it can be used as a part of other packages. Also included is a section about formulas and data frames, for people not used to the R modelling idioms."
            },
            "slug": "The-pls-Package:-Principal-Component-and-Partial-in-Mevik-Wehrens",
            "title": {
                "fragments": [],
                "text": "The pls Package: Principal Component and Partial Least Squares Regression in R"
            },
            "tldr": {
                "abstractSimilarityScore": 87,
                "text": "The pls package implements principal component regression (PCR) and partial least squares regression (PLSR) in R and is freely available from the Comprehensive R Archive Network (CRAN), licensed under the GNU General Public License (GPL)."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145938212"
                        ],
                        "name": "H. Kamp",
                        "slug": "H.-Kamp",
                        "structuredName": {
                            "firstName": "Hans",
                            "lastName": "Kamp",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Kamp"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 127,
                                "start": 84
                            }
                        ],
                        "text": "However, the intersective method of combination is well-known to fail in many cases (Kamp, 1975; Montague, 1970a; Siegel, 1976): for instance, a fake gun is not a gun."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 115907968,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "d7689bea78120d1eb2efbc09506d9ae98452d59e",
            "isKey": false,
            "numCitedBy": 461,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "A solids-agitating insert for double-ended, invertible tanks including flexible X-members the ends of which are flexed together for insertion through one end-aperture of the tank and retained in the tank when the ends are allowed to spring outwardly within the tank."
            },
            "slug": "Two-Theories-of-Adjectives-Kamp",
            "title": {
                "fragments": [],
                "text": "Two Theories of Adjectives"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "A solids-agitating insert for double-ended, invertible tanks including flexible X-members the ends of which are flexed together for insertion through one end-aperture of the tank and retained in the tank when the ends are allowed to spring outwardly within the tank."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1975
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "102157754"
                        ],
                        "name": "G. Frege",
                        "slug": "G.-Frege",
                        "structuredName": {
                            "firstName": "Gottlob",
                            "lastName": "Frege",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Frege"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 31,
                                "start": 4
                            }
                        ],
                        "text": "ity (Frege, 1892; Partee, 2004), that crucial property of natural language which allows speakers to derive the meaning of a complex linguistic constituent from the meaning of its immediate syntactic subconstituents."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 170163815,
            "fieldsOfStudy": [
                "Philosophy"
            ],
            "id": "d7667992907417ee46c7a5ff541006cf6e6a7748",
            "isKey": false,
            "numCitedBy": 1706,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Die Gleichheit fordert das Nachdenken heraus durch Fragen, die sich daran knupfen und nicht ganz leicht zu beantworten sind. Ist sie eine Beziehung? eine Beziehung zwischen Gegenstanden? oder zwischen Namen oder Zeichen fur Gegenstande? Das letzte hatte ich in meiner Begriffsschrift angenommen. Die Grunde, die dafur zu sprechen scheinen, sind folgende: a=a und a=b sind offenbar Satze von verschiedenem Erkenntniswerte: a=a gilt a priori und ist nach Kant analytisch zu nennen, wahrend Satze von der Form a=b oft sehr wertvolle Erweiterungen unserer Erkenntnis enthalten und a priori nicht immer zu begrunden sind. Die Entdeckung, das nicht jeden Morgen eine neue Sonne aufgeht, sondern immer dieselbe, ist wohl eine der folgenreichsten in der Astronomie gewesen. Noch jetzt ist die Wiedererkennung eines kleinen Planeten oder eines Kometen\nnicht immer etwas Selbstverstandliches."
            },
            "slug": "\u00dcber-Sinn-und-Bedeutung-Frege",
            "title": {
                "fragments": [],
                "text": "\u00dcber Sinn und Bedeutung"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1892
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, pages 1183\u20131193, MIT, Massachusetts, USA, 9-11 October 2010. c\u00a92010 Association for Computational Linguistics"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 205,
                                "start": 192
                            }
                        ],
                        "text": "This approach to semantics (sometimes called distributional semantics) naturally captures word clustering, scales well to large lexicons and doesn\u2019t require words to be manually disambiguated (Schu\u0308tze, 1997)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 248,
                                "start": 235
                            }
                        ],
                        "text": "\u2026electronic), colors (white, black, red, green) positive evaluation (nice, excellent, important, appropriate), temporal (old, recent, new, young, current), modal (necessary, possible), plus some common abstract antonymous pairs (difficult, easy, good, bad, special, general, different, common)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 201,
                                "start": 188
                            }
                        ],
                        "text": "Applying SVD is independently justified because, besides mitigating the dimensionality problem, it often improves the quality of the semantic space (Landauer and Dumais, 1997; Rapp, 2003; Schu\u0308tze, 1997)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Ambiguity Resolution in Natural Language Learning. CSLI"
            },
            "venue": {
                "fragments": [],
                "text": "Ambiguity Resolution in Natural Language Learning. CSLI"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 168,
                                "start": 149
                            }
                        ],
                        "text": "\u2026estimation, this technique is more robust against over-training by effectively using a smaller number of orthogonal \u201clatent\u201d variables as predictors (Hastie et al., 2009, Section 3.4), and it exploits the multivariate nature of the problem (different regressions for each AN vector dimension to be\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The Elements of Statistical Learning, 2nd ed"
            },
            "venue": {
                "fragments": [],
                "text": "Springer, New York."
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "14956436"
                        ],
                        "name": "L. Dezs\u00f6",
                        "slug": "L.-Dezs\u00f6",
                        "structuredName": {
                            "firstName": "L\u00e1szl\u00f3",
                            "lastName": "Dezs\u00f6",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Dezs\u00f6"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 201904046,
            "fieldsOfStudy": [
                "Education"
            ],
            "id": "e69e5953905b9b9ded4c07f0505ed401ec39babf",
            "isKey": false,
            "numCitedBy": 704,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Universal-Grammar-Dezs\u00f6",
            "title": {
                "fragments": [],
                "text": "Universal Grammar"
            },
            "venue": {
                "fragments": [],
                "text": "Certainty in Action"
            },
            "year": 2021
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39340971"
                        ],
                        "name": "B. Partee",
                        "slug": "B.-Partee",
                        "structuredName": {
                            "firstName": "Barbara",
                            "lastName": "Partee",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Partee"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 160,
                                "start": 148
                            }
                        ],
                        "text": "\u2026it has been limited to the level of content words (nouns, adjectives, verbs), and it hasn\u2019t tackled in a general way compositionality (Frege, 1892; Partee, 2004), that crucial property of natural language which allows speakers to derive the meaning of a complex linguistic constituent\nfrom the\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 124676946,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cfe99696be15b4edc86650f19b478a32ba48d344",
            "isKey": false,
            "numCitedBy": 119,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Compositionality-in-Formal-Semantics-Partee",
            "title": {
                "fragments": [],
                "text": "Compositionality in Formal Semantics"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48959839"
                        ],
                        "name": "R. Montague",
                        "slug": "R.-Montague",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Montague",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Montague"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 127,
                                "start": 84
                            }
                        ],
                        "text": "However, the intersective method of combination is well-known to fail in many cases (Kamp, 1975; Montague, 1970a; Siegel, 1976): for instance, a fake gun is not a gun."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 60562957,
            "fieldsOfStudy": [
                "Education"
            ],
            "id": "1b5ad278a01a2c91f35c4c86fbbffc09d6fe2d72",
            "isKey": false,
            "numCitedBy": 699,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "ENGLISH-AS-A-FORMAL-LANGUAGE-Montague",
            "title": {
                "fragments": [],
                "text": "ENGLISH AS A FORMAL LANGUAGE"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1975
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "37398710"
                        ],
                        "name": "M. Siegel",
                        "slug": "M.-Siegel",
                        "structuredName": {
                            "firstName": "Muffy",
                            "lastName": "Siegel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Siegel"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 127,
                                "start": 84
                            }
                        ],
                        "text": "However, the intersective method of combination is well-known to fail in many cases (Kamp, 1975; Montague, 1970a; Siegel, 1976): for instance, a fake gun is not a gun."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 118899145,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9ab5df8a882a239c53b05ec866b24780e55b4677",
            "isKey": false,
            "numCitedBy": 167,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Capturing-the-adjective-Siegel",
            "title": {
                "fragments": [],
                "text": "Capturing the adjective"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1976
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1784682"
                        ],
                        "name": "T. Hastie",
                        "slug": "T.-Hastie",
                        "structuredName": {
                            "firstName": "Trevor",
                            "lastName": "Hastie",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Hastie"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1761784"
                        ],
                        "name": "R. Tibshirani",
                        "slug": "R.-Tibshirani",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Tibshirani",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Tibshirani"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3056361"
                        ],
                        "name": "J. Friedman",
                        "slug": "J.-Friedman",
                        "structuredName": {
                            "firstName": "Jerome",
                            "lastName": "Friedman",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Friedman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 58068920,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "44d71e0ec9f68d8eb802b9ab1dde8368efeac42e",
            "isKey": false,
            "numCitedBy": 12335,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "The-Elements-of-Statistical-Learning-Hastie-Tibshirani",
            "title": {
                "fragments": [],
                "text": "The Elements of Statistical Learning"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2001
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 209,
                                "start": 196
                            }
                        ],
                        "text": "Their simplified additive model p = \u03b1u+\u03b2v was a common approach to composition in the earlier literature, typically with the scalar weights set to 1 or to normalizing constants (Foltz et al., 1998; Kintsch, 2001; Landauer and Dumais, 1997)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 219,
                                "start": 205
                            }
                        ],
                        "text": "\u2026but focus on the nature of input vectors, suggesting that when a verb is composed with a noun, the noun component is given by an average of verbs that the noun is typically object of (along similar lines,\nKintsch (2001) also focused on composite input vectors, within an additive framework)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Predication. Cognitive Science"
            },
            "venue": {
                "fragments": [],
                "text": "Predication. Cognitive Science"
            },
            "year": 2001
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 218,
                                "start": 204
                            }
                        ],
                        "text": "An influential approach for representing the meaning of a word in NLP is to treat it as a vector that codes the pattern of co-occurrence of that word with other expressions in a large corpus of language (Sahlgren, 2006; Turney and Pantel, 2010)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The Word-Space Model. Dissertation"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2006
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The Statistics of Word Cooccurrences"
            },
            "venue": {
                "fragments": [],
                "text": "Dissertation, Stuttgart University."
            },
            "year": 2005
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The proper treatment of quantification in English"
            },
            "venue": {
                "fragments": [],
                "text": "K.J.J. Hintikka, editor, Approaches to Natural Language, pages 221\u2013242. Reidel, Dordrecht. Reprinted in Thomason (1974)."
            },
            "year": 1973
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "\u00dcber sinn und bedeutung. Zeitschrift fuer Philosophie un philosophische Kritik"
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 244,
                                "start": 203
                            }
                        ],
                        "text": "An influential approach for representing the meaning of a word in NLP is to treat it as a vector that codes the pattern of co-occurrence of that word with other expressions in a large corpus of language (Sahlgren, 2006; Turney and Pantel, 2010)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The Word-Space Model"
            },
            "venue": {
                "fragments": [],
                "text": "Dissertation, Stockholm University."
            },
            "year": 2006
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 111,
                                "start": 57
                            }
                        ],
                        "text": "lem, it often improves the quality of the semantic space (Landauer and Dumais, 1997; Rapp, 2003; Sch\u00fctze, 1997)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 207,
                                "start": 192
                            }
                        ],
                        "text": "This approach to semantics (sometimes called distributional semantics) naturally captures word clustering, scales well to large lexicons and doesn\u2019t require words to be manually disambiguated (Sch\u00fctze, 1997)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Ambiguity Resolution in Natural Language Learning"
            },
            "venue": {
                "fragments": [],
                "text": "CSLI, Stanford, CA."
            },
            "year": 1997
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 15,
            "methodology": 10
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 40,
        "totalPages": 4
    },
    "page_url": "https://www.semanticscholar.org/paper/Nouns-are-Vectors,-Adjectives-are-Matrices:-in-Baroni-Zamparelli/37efe2ef1b9d27cc598361a8013ec888a6f7c4d8?sort=total-citations"
}