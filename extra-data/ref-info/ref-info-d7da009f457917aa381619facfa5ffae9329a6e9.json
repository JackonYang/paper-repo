{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3323275"
                        ],
                        "name": "Kishore Papineni",
                        "slug": "Kishore-Papineni",
                        "structuredName": {
                            "firstName": "Kishore",
                            "lastName": "Papineni",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kishore Papineni"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1781292"
                        ],
                        "name": "S. Roukos",
                        "slug": "S.-Roukos",
                        "structuredName": {
                            "firstName": "Salim",
                            "lastName": "Roukos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Roukos"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144582029"
                        ],
                        "name": "T. Ward",
                        "slug": "T.-Ward",
                        "structuredName": {
                            "firstName": "Todd",
                            "lastName": "Ward",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Ward"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2070868732"
                        ],
                        "name": "John Henderson",
                        "slug": "John-Henderson",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Henderson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "John Henderson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145220512"
                        ],
                        "name": "F. Reeder",
                        "slug": "F.-Reeder",
                        "structuredName": {
                            "firstName": "Florence",
                            "lastName": "Reeder",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Reeder"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 266,
                                "start": 243
                            }
                        ],
                        "text": "Our belief is reinforced by a recent statistical analysis of BLEU\u2019s correlation with human judgment for translation into English from four quite different languages (Arabic, Chinese, French, Spanish) representing 3 different language families (Papineni et al., 2002)! BLEU\u2019s strength is that it correlates highly with human judg-"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 264,
                                "start": 243
                            }
                        ],
                        "text": "Our belief is reinforced by a recent statistical analysis of BLEU\u2019s correlation with human judgment for translation into English from four quite different languages (Arabic, Chinese, French, Spanish) representing 3 different language families (Papineni et al., 2002)!"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 30564351,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3d4e0cdf981747af1d5c687e3c8238f791f95733",
            "isKey": false,
            "numCitedBy": 58,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe two metrics for automatic evaluation of machine translation quality. These metrics, BLEU and NEE, are compared to human judgment of quality of translation of Arabic, Chinese, French, and Spanish documents into English."
            },
            "slug": "Corpus-based-comprehensive-and-diagnostic-MT-and-Papineni-Roukos",
            "title": {
                "fragments": [],
                "text": "Corpus-based comprehensive and diagnostic MT evaluation: initial Arabic, Chinese, French, and Spanish results"
            },
            "tldr": {
                "abstractSimilarityScore": 87,
                "text": "Two metrics for automatic evaluation of machine translation quality, BLEU and NEE, are compared to human judgment of quality of translation of Arabic, Chinese, French, and Spanish documents into English."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145887086"
                        ],
                        "name": "J. S. White",
                        "slug": "J.-S.-White",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "White",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. S. White"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1405346911"
                        ],
                        "name": "T. O'Connell",
                        "slug": "T.-O'Connell",
                        "structuredName": {
                            "firstName": "Theresa",
                            "lastName": "O'Connell",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. O'Connell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1409984588"
                        ],
                        "name": "Francis E. O'Mara",
                        "slug": "Francis-E.-O'Mara",
                        "structuredName": {
                            "firstName": "Francis",
                            "lastName": "O'Mara",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Francis E. O'Mara"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 180,
                                "start": 156
                            }
                        ],
                        "text": "Human evaluations of machine translation (MT) weigh many aspects of translation, including adequacy, fidelity , and fluency of the translation (Hovy, 1999; White and O\u2019Connell, 1994)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1937617,
            "fieldsOfStudy": [
                "Business"
            ],
            "id": "bf45f9e578cb4b43a2604d6149553ae8cfee3016",
            "isKey": false,
            "numCitedBy": 232,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "The ARPA MT Evaluation methodology effort is intended to provide a basis for measuring and thereby facilitating the progress of MT systems of the ARPAsponsored research program. The evaluation methodologies have the further goal of being useful for identifying the context of that progress among developed, production MT systems in use today. Since 1991, the evaluations have evolved as we have discovered more about what properties are valuable to measure, what properties are not, and what elements of the tests/evaluations can be adjusted to enhance significance of the results while still remaining relatively portable. This paper describes this evolutionary process, along with measurements of the most recent MT evaluation (January 1994) and the current evaluation process now underway."
            },
            "slug": "The-ARPA-MT-Evaluation-Methodologies:-Evolution,-White-O'Connell",
            "title": {
                "fragments": [],
                "text": "The ARPA MT Evaluation Methodologies: Evolution, Lessons, and Future Approaches"
            },
            "tldr": {
                "abstractSimilarityScore": 54,
                "text": "This paper describes this evolutionary process, along with measurements of the most recent MT evaluation (January 1994) and the current evaluation process now underway, which is intended to provide a basis for measuring and thereby facilitating the progress of MT systems of the ARPAsponsored research program."
            },
            "venue": {
                "fragments": [],
                "text": "AMTA"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "118284425"
                        ],
                        "name": "James R. Child",
                        "slug": "James-R.-Child",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Child",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "James R. Child"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 67170890,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "682cdcae291aee14bfc49a038b65c7f7701212ae",
            "isKey": false,
            "numCitedBy": 31,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Proficiency-and-Performance-in-Language-Testing.-Child",
            "title": {
                "fragments": [],
                "text": "Proficiency and Performance in Language Testing."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 103,
                                "start": 90
                            }
                        ],
                        "text": "A comprehensive catalog of MT evaluation techniques and their rich literature is given by Reeder (2001)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Additional mt-eval references International Standards for Language Engineering, Evaluation Working Group"
            },
            "venue": {
                "fragments": [],
                "text": "Additional mt-eval references International Standards for Language Engineering, Evaluation Working Group"
            },
            "year": 2001
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 93,
                                "start": 81
                            }
                        ],
                        "text": "For the most part, these various human evaluation approaches are quite expensive (Hovy, 1999)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 182,
                                "start": 143
                            }
                        ],
                        "text": "Human evaluations of machine translation (MT) weigh many aspects of translation, including adequacy, fidelity , and fluency of the translation (Hovy, 1999; White and O\u2019Connell, 1994)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Toward finely differentiated evaluation metrics for machine translation"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Eagles Workshop on Standards and Evaluation, Pisa, Italy."
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Additional mt-eval references"
            },
            "venue": {
                "fragments": [],
                "text": "Technical report, International Standards for Language Engineering, Evaluation Working Group. http://isscowww.unige.ch/projects/isle/taxonomy2/"
            },
            "year": 2001
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 3,
            "methodology": 1
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 6,
        "totalPages": 1
    },
    "page_url": "https://www.semanticscholar.org/paper/Bleu:-a-Method-for-Automatic-Evaluation-of-Machine-Papineni-Roukos/d7da009f457917aa381619facfa5ffae9329a6e9?sort=total-citations"
}