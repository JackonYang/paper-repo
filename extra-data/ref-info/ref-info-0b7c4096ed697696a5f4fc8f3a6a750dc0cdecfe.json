{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145459057"
                        ],
                        "name": "Y. Rui",
                        "slug": "Y.-Rui",
                        "structuredName": {
                            "firstName": "Yong",
                            "lastName": "Rui",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Rui"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153652752"
                        ],
                        "name": "Thomas S. Huang",
                        "slug": "Thomas-S.-Huang",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Huang",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thomas S. Huang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1401302503"
                        ],
                        "name": "Michael Ortega-Binderberger",
                        "slug": "Michael-Ortega-Binderberger",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Ortega-Binderberger",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael Ortega-Binderberger"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144156242"
                        ],
                        "name": "S. Mehrotra",
                        "slug": "S.-Mehrotra",
                        "structuredName": {
                            "firstName": "Sharad",
                            "lastName": "Mehrotra",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Mehrotra"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 3888393,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "460c7b1c0d13a403b3a25a31a86692bb0443002b",
            "isKey": false,
            "numCitedBy": 2027,
            "numCiting": 67,
            "paperAbstract": {
                "fragments": [],
                "text": "Content-based image retrieval (CBIR) has become one of the most active research areas in the past few years. Many visual feature representations have been explored and many systems built. While these research efforts establish the basis of CBIR, the usefulness of the proposed approaches is limited. Specifically, these efforts have relatively ignored two distinct characteristics of CBIR systems: (1) the gap between high-level concepts and low-level features, and (2) the subjectivity of human perception of visual content. This paper proposes a relevance feedback based interactive retrieval approach, which effectively takes into account the above two characteristics in CBIR. During the retrieval process, the user's high-level query and perception subjectivity are captured by dynamically updated weights based on the user's feedback. The experimental results over more than 70000 images show that the proposed approach greatly reduces the user's effort of composing a query, and captures the user's information need more precisely."
            },
            "slug": "Relevance-feedback:-a-power-tool-for-interactive-Rui-Huang",
            "title": {
                "fragments": [],
                "text": "Relevance feedback: a power tool for interactive content-based image retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A relevance feedback based interactive retrieval approach that effectively takes into account the subjectivity of human perception of visual content and the gap between high-level concepts and low-level features in CBIR."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Circuits Syst. Video Technol."
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38388395"
                        ],
                        "name": "N. Howe",
                        "slug": "N.-Howe",
                        "structuredName": {
                            "firstName": "Nicholas",
                            "lastName": "Howe",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Howe"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1713089"
                        ],
                        "name": "D. Huttenlocher",
                        "slug": "D.-Huttenlocher",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Huttenlocher",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Huttenlocher"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15894886,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b2b718fc99c0c4875e96e2b0ccd9f47c684b8997",
            "isKey": false,
            "numCitedBy": 28,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper examines the problem of image retrieval from large, heterogeneous image databases. We present a technique that fulfils several needs identified by surveying recent research in the field. This technique fairly integrates a diverse and expandable set of image properties (for example, color, texture, and location) in a retrieval framework, and allows end-users substantial control over their use. We propose a novel set of evaluation methods in addition to applying established tests for image retrieval; our technique proves competitive with state-of-the-art methods in these tests and does better on certain tasks. Furthermore, it improves on many standard image retrieval algorithms by supporting queries based on subsections of images. For certain queries this capability significantly increases the relevance of the images retrieved, and further expands the user's control over the retrieval process."
            },
            "slug": "Integrating-color,-texture,-and-geometry-for-image-Howe-Huttenlocher",
            "title": {
                "fragments": [],
                "text": "Integrating color, texture, and geometry for image retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This technique fairly integrates a diverse and expandable set of image properties in a retrieval framework, and allows end-users substantial control over their use, and improves on many standard image retrieval algorithms by supporting queries based on subsections of images."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings IEEE Conference on Computer Vision and Pattern Recognition. CVPR 2000 (Cat. No.PR00662)"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695527"
                        ],
                        "name": "T. Gevers",
                        "slug": "T.-Gevers",
                        "structuredName": {
                            "firstName": "Theo",
                            "lastName": "Gevers",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Gevers"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144638781"
                        ],
                        "name": "A. Smeulders",
                        "slug": "A.-Smeulders",
                        "structuredName": {
                            "firstName": "Arnold",
                            "lastName": "Smeulders",
                            "middleNames": [
                                "W.",
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Smeulders"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8167770,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "33abd0c54463f41359d771ab817699ea9a16715f",
            "isKey": false,
            "numCitedBy": 93,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Content-based-image-retrieval-by-color-indexing-Gevers-Smeulders",
            "title": {
                "fragments": [],
                "text": "Content-based image retrieval by viewpoint-invariant color indexing"
            },
            "venue": {
                "fragments": [],
                "text": "Image Vis. Comput."
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145295484"
                        ],
                        "name": "Anil K. Jain",
                        "slug": "Anil-K.-Jain",
                        "structuredName": {
                            "firstName": "Anil",
                            "lastName": "Jain",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Anil K. Jain"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2277853"
                        ],
                        "name": "A. Vailaya",
                        "slug": "A.-Vailaya",
                        "structuredName": {
                            "firstName": "Aditya",
                            "lastName": "Vailaya",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Vailaya"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 2825720,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "836f91accc7242e85313c24c9be3bfd42c013f3d",
            "isKey": false,
            "numCitedBy": 1060,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Image-retrieval-using-color-and-shape-Jain-Vailaya",
            "title": {
                "fragments": [],
                "text": "Image retrieval using color and shape"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit."
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1739867"
                        ],
                        "name": "R. Veltkamp",
                        "slug": "R.-Veltkamp",
                        "structuredName": {
                            "firstName": "Remco",
                            "lastName": "Veltkamp",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Veltkamp"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1921784"
                        ],
                        "name": "M. Hagedoorn",
                        "slug": "M.-Hagedoorn",
                        "structuredName": {
                            "firstName": "Michiel",
                            "lastName": "Hagedoorn",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Hagedoorn"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 39932777,
            "fieldsOfStudy": [
                "Computer Science",
                "Art"
            ],
            "id": "3903efd2e310224ae987c0d43809650e0177d0bc",
            "isKey": false,
            "numCitedBy": 647,
            "numCiting": 70,
            "paperAbstract": {
                "fragments": [],
                "text": "Large image databases are used in an extraordinary number of multimedia applications in fields such as entertainment, business, art, engineering, and science. Retrieving images by their content, as opposed to external features, has become an important operation. A fundamental ingredient for content-based image retrieval is the technique used for comparing images. There are two general methods for image comparison: intensity based (color and texture) and geometry based (shape). A recent user survey about cognition aspects of image retrieval shows that users are more interested in retrieval by shape than by color and texture [62]. However, retrieval by shape is still considered one of the most difficult aspects of content-based search. Indeed, systems such as IBM\u2019s Query By Image Content, QBIC [57], perhaps one of the most advanced image retrieval systems to date, is relatively successful in retrieving by color and texture, but performs poorly when searching on shape. A similar behavior is exhibited in the new Alta Vista photo finder [10]."
            },
            "slug": "State-of-the-Art-in-Shape-Matching-Veltkamp-Hagedoorn",
            "title": {
                "fragments": [],
                "text": "State of the Art in Shape Matching"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A recent user survey about cognition aspects of image retrieval shows that users are more interested in retrieval by shape than by color and texture, and systems such as IBM\u2019s Query By Image Content, QBIC, is relatively successful in retrieving by colors, but performs poorly when searching on shape."
            },
            "venue": {
                "fragments": [],
                "text": "Principles of Visual Information Retrieval"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1952510"
                        ],
                        "name": "B. Mehtre",
                        "slug": "B.-Mehtre",
                        "structuredName": {
                            "firstName": "Babu",
                            "lastName": "Mehtre",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Mehtre"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1744045"
                        ],
                        "name": "M. Kankanhalli",
                        "slug": "M.-Kankanhalli",
                        "structuredName": {
                            "firstName": "M.",
                            "lastName": "Kankanhalli",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Kankanhalli"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2386036"
                        ],
                        "name": "W. F. Lee",
                        "slug": "W.-F.-Lee",
                        "structuredName": {
                            "firstName": "Wing",
                            "lastName": "Lee",
                            "middleNames": [
                                "Foon"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. F. Lee"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 6901546,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fc1459db48efe205eb37db853a02698d4f640b76",
            "isKey": false,
            "numCitedBy": 450,
            "numCiting": 70,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Shape-Measures-for-Content-Based-Image-Retrieval:-A-Mehtre-Kankanhalli",
            "title": {
                "fragments": [],
                "text": "Shape Measures for Content Based Image Retrieval: A Comparison"
            },
            "venue": {
                "fragments": [],
                "text": "Inf. Process. Manag."
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1748081"
                        ],
                        "name": "R. Srihari",
                        "slug": "R.-Srihari",
                        "structuredName": {
                            "firstName": "Rohini",
                            "lastName": "Srihari",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Srihari"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 10324615,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "171d580de976b3d4393b48b66271d1512420cc7b",
            "isKey": false,
            "numCitedBy": 211,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "The interaction of textual and photographic information in an integrated text/image database environment is being explored. Specifically, our research group has developed an automatic indexing system for captioned pictures of people; the indexing information and other textual information is subsequently used in a content-based image retrieval system. Our approach presents an alternative to traditional face identification systems; it goes beyond a superficial combination of existing text-based and image-based approaches to information retrieval. By understanding the caption accompanying a picture, we can extract information that is useful both for retrieving the picture and for identifying the faces shown. In designing a pictorial database system, two major issues are (1) the amount and type of processing required when inserting new pictures into the database and (2) efficient retrieval schemes for query processing. Our research has focused on developing a computational model for understanding pictures based on accompanying descriptive text. Understanding a picture can be informally defined as the process of identifying relevant people and objects. Several current vision systems employ the idea of top-down control in picture understanding. We carry the notion of top-down control one step further, exploiting not only general context but also picture-specific context. >"
            },
            "slug": "Automatic-Indexing-and-Content-Based-Retrieval-of-Srihari",
            "title": {
                "fragments": [],
                "text": "Automatic Indexing and Content-Based Retrieval of Captioned Images"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The research group has developed an automatic indexing system for captioned pictures of people; the indexing information and other textual information is subsequently used in a content-based image retrieval system."
            },
            "venue": {
                "fragments": [],
                "text": "Computer"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2969789"
                        ],
                        "name": "C. Carson",
                        "slug": "C.-Carson",
                        "structuredName": {
                            "firstName": "Chad",
                            "lastName": "Carson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Carson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50172592"
                        ],
                        "name": "Serge J. Belongie",
                        "slug": "Serge-J.-Belongie",
                        "structuredName": {
                            "firstName": "Serge",
                            "lastName": "Belongie",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Serge J. Belongie"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143942875"
                        ],
                        "name": "H. Greenspan",
                        "slug": "H.-Greenspan",
                        "structuredName": {
                            "firstName": "Hayit",
                            "lastName": "Greenspan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Greenspan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153652147"
                        ],
                        "name": "J. Malik",
                        "slug": "J.-Malik",
                        "structuredName": {
                            "firstName": "Jitendra",
                            "lastName": "Malik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Malik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7047950,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "913beb8d70383bacaf7f0133d9a88ca592542af7",
            "isKey": false,
            "numCitedBy": 323,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "Retrieving images from large and varied collections using image content as a key is a challenging and important problem. In this paper, we present a new image representation which provides a transformation from the raw pixel data to a small set of localized coherent regions in color and texture space. This so-called &ldquo;blobworld&rdquo; representation is based on segmentation using the expectation-maximization algorithm on combined color and texture features. The texture features we use for the segmentation arise from a new approach to texture description and scale selection. We describe a system that uses the blobworld representation to retrieve images. An important and unique aspect of the system is that, in the context of similarity-based querying, the user is allowed to view the internal representation of the submitted image and the query results. Similar systems do not offer the user this view into the workings of the system; consequently, the outcome of many queries on these systems can be quite inexplicable, despite the availability of knobs for adjusting the similarity metric"
            },
            "slug": "Region-based-image-querying-Carson-Belongie",
            "title": {
                "fragments": [],
                "text": "Region-based image querying"
            },
            "tldr": {
                "abstractSimilarityScore": 50,
                "text": "A new image representation is presented which provides a transformation from the raw pixel data to a small set of localized coherent regions in color and texture space based on segmentation using the expectation-maximization algorithm on combined color andtexture features."
            },
            "venue": {
                "fragments": [],
                "text": "1997 Proceedings IEEE Workshop on Content-Based Access of Image and Video Libraries"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144053687"
                        ],
                        "name": "A. Mojsilovic",
                        "slug": "A.-Mojsilovic",
                        "structuredName": {
                            "firstName": "Aleksandra",
                            "lastName": "Mojsilovic",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Mojsilovic"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2442915"
                        ],
                        "name": "J. Kovacevic",
                        "slug": "J.-Kovacevic",
                        "structuredName": {
                            "firstName": "Jelena",
                            "lastName": "Kovacevic",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Kovacevic"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2152179732"
                        ],
                        "name": "Jianying Hu",
                        "slug": "Jianying-Hu",
                        "structuredName": {
                            "firstName": "Jianying",
                            "lastName": "Hu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jianying Hu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2700579"
                        ],
                        "name": "R. Safranek",
                        "slug": "R.-Safranek",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Safranek",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Safranek"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144113439"
                        ],
                        "name": "S. Ganapathy",
                        "slug": "S.-Ganapathy",
                        "structuredName": {
                            "firstName": "S.",
                            "lastName": "Ganapathy",
                            "middleNames": [
                                "Kicha"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Ganapathy"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2516719,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d79cb416a142e9795e4e986a228a734f78ac830f",
            "isKey": false,
            "numCitedBy": 217,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "While it is recognized that images are described through color, texture and shapes of objects in the scene, general image understanding is still difficult. Thus, to perform image retrieval in a human-like manner one has to choose a specific domain, understand how users achieve similarity within that domain and then build a system that duplicates human performance. Since color and texture are fundamental aspects of human perception we propose a set of techniques for retrieval of color patterns. To determine how humans judge similarity of color patterns we performed a subjective study. Based on the results of the study five most relevant visual categories for the perception of pattern similarity were identified. We also determined the hierarchy of rules governing the use of these categories. Based on these results we designed a system which accepts one or more texture images as input, and depending on the query, produces a set of choices that follow human behavior in pattern matching. Processing steps in our model follow those of the human visual system, resulting in perceptually based features and distance measures. As expected, search results closely correlate with human choices."
            },
            "slug": "Matching-and-retrieval-based-on-the-vocabulary-and-Mojsilovic-Kovacevic",
            "title": {
                "fragments": [],
                "text": "Matching and retrieval based on the vocabulary and grammar of color patterns"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "A system which accepts one or more texture images as input, and depending on the query, produces a set of choices that follow human behavior in pattern matching, resulting in perceptually based features and distance measures."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Image Process."
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145295484"
                        ],
                        "name": "Anil K. Jain",
                        "slug": "Anil-K.-Jain",
                        "structuredName": {
                            "firstName": "Anil",
                            "lastName": "Jain",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Anil K. Jain"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2277853"
                        ],
                        "name": "A. Vailaya",
                        "slug": "A.-Vailaya",
                        "structuredName": {
                            "firstName": "Aditya",
                            "lastName": "Vailaya",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Vailaya"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 14646055,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d9d25ecb12e3f11d5cfd93b4c9d0950ecec22666",
            "isKey": false,
            "numCitedBy": 449,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Shape-Based-Retrieval:-A-Case-Study-With-Trademark-Jain-Vailaya",
            "title": {
                "fragments": [],
                "text": "Shape-Based Retrieval: A Case Study With Trademark Image Databases"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit."
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2110551799"
                        ],
                        "name": "Chih-Cheng Hsu",
                        "slug": "Chih-Cheng-Hsu",
                        "structuredName": {
                            "firstName": "Chih-Cheng",
                            "lastName": "Hsu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chih-Cheng Hsu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1724907"
                        ],
                        "name": "W. Chu",
                        "slug": "W.-Chu",
                        "structuredName": {
                            "firstName": "Wesley",
                            "lastName": "Chu",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Chu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1743681"
                        ],
                        "name": "R. Taira",
                        "slug": "R.-Taira",
                        "structuredName": {
                            "firstName": "Ricky",
                            "lastName": "Taira",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Taira"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 1883138,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8fcf6474c3cee763b75a2c82faae3195c6ee8a9e",
            "isKey": false,
            "numCitedBy": 95,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "A knowledge based approach is introduced for retrieving images by content. It supports the answering of conceptual image queries involving similar-to predicates, spatial semantic operators, and references to conceptual terms. Interested objects in the images are represented by contours segmented from images. Image content such as shapes and spatial relationships are derived from object contours according to domain specific image knowledge. A three layered model is proposed for integrating image representations, extracted image features, and image semantics. With such a model, images can be retrieved based on the features and content specified in the queries. The knowledge based query processing is based on a query relaxation technique. The image features are classified by an automatic clustering algorithm and represented by Type Abstraction Hierarchies (TAHs) for knowledge based query processing. Since the features selected for TAH generation are based on context and user profile, and the TAHs can be generated automatically by a clustering algorithm from the feature database, our proposed image retrieval approach is scalable and context sensitive. The performance of the proposed knowledge based query processing is also discussed."
            },
            "slug": "A-Knowledge-Based-Approach-for-Retrieving-Images-by-Hsu-Chu",
            "title": {
                "fragments": [],
                "text": "A Knowledge-Based Approach for Retrieving Images by Content"
            },
            "tldr": {
                "abstractSimilarityScore": 92,
                "text": "A knowledge based approach for retrieving images by content supports the answering of conceptual image queries involving similar-to predicates, spatial semantic operators, and references to conceptual terms."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Knowl. Data Eng."
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1699559"
                        ],
                        "name": "N. Vasconcelos",
                        "slug": "N.-Vasconcelos",
                        "structuredName": {
                            "firstName": "Nuno",
                            "lastName": "Vasconcelos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Vasconcelos"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1808594"
                        ],
                        "name": "A. Lippman",
                        "slug": "A.-Lippman",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Lippman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Lippman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 3037471,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "43b294c251401728d0c731288664dbf3f08cf7fc",
            "isKey": false,
            "numCitedBy": 120,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "The design of an effective architecture for content-based retrieval from visual libraries requires careful consideration of the interplay between feature selection, feature representation, and similarity metric. We present a solution where all the modules strive to optimize the same performance criteria: the probability of retrieval error. This solution consists of a Bayesian retrieval criteria (shown to generalize the most prevalent similarity metrics in current use) and an embedded mixture representation over a multiresolution feature space (shown to provide a good trade-off between retrieval accuracy, invariance, perceptual relevance of similarity, and complexity). The new representation extends standard models (histogram and Gaussian) by providing simultaneous support for high-dimensional features and multi-modal densities and performs well on color texture, and generic image databases."
            },
            "slug": "A-probabilistic-architecture-for-content-based-Vasconcelos-Lippman",
            "title": {
                "fragments": [],
                "text": "A probabilistic architecture for content-based image retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "A solution where all the modules strive to optimize the same performance criteria: the probability of retrieval error is presented, which consists of a Bayesian retrieval criteria and an embedded mixture representation over a multiresolution feature space."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings IEEE Conference on Computer Vision and Pattern Recognition. CVPR 2000 (Cat. No.PR00662)"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144638781"
                        ],
                        "name": "A. Smeulders",
                        "slug": "A.-Smeulders",
                        "structuredName": {
                            "firstName": "Arnold",
                            "lastName": "Smeulders",
                            "middleNames": [
                                "W.",
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Smeulders"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695527"
                        ],
                        "name": "T. Gevers",
                        "slug": "T.-Gevers",
                        "structuredName": {
                            "firstName": "Theo",
                            "lastName": "Gevers",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Gevers"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1720149"
                        ],
                        "name": "J. Geusebroek",
                        "slug": "J.-Geusebroek",
                        "structuredName": {
                            "firstName": "Jan-Mark",
                            "lastName": "Geusebroek",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Geusebroek"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1717056"
                        ],
                        "name": "M. Worring",
                        "slug": "M.-Worring",
                        "structuredName": {
                            "firstName": "Marcel",
                            "lastName": "Worring",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Worring"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 11642120,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d0fd577a8968e00c52eb0afc925132eea75cfec4",
            "isKey": false,
            "numCitedBy": 1,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "The paper discusses the role of invariance in content-based image retrieval, and discusses future directions. In the repertoire of images under consideration, a narrow domain is a set of images containing a limited variety in the object's appearances. In a narrow domain, the recording circumstances typically are similar or standardized over the whole domain. On the other end of the spectrum is a broad domain with a large variety in recording circumstances and appearances. The sensory gap between the object in the world and the information captured from a recording causes unwanted variance in the description of an object. We list conditions of variance, and we review some of features which are invariant under these conditions."
            },
            "slug": "Invariance-in-content-based-retrieval-Smeulders-Gevers",
            "title": {
                "fragments": [],
                "text": "Invariance in content-based retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 65,
                "text": "The role of invariance in content-based image retrieval is discussed, and some of features which are invariant under these conditions are reviewed."
            },
            "venue": {
                "fragments": [],
                "text": "2000 IEEE International Conference on Multimedia and Expo. ICME2000. Proceedings. Latest Advances in the Fast Changing World of Multimedia (Cat. No.00TH8532)"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695527"
                        ],
                        "name": "T. Gevers",
                        "slug": "T.-Gevers",
                        "structuredName": {
                            "firstName": "Theo",
                            "lastName": "Gevers",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Gevers"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144638781"
                        ],
                        "name": "A. Smeulders",
                        "slug": "A.-Smeulders",
                        "structuredName": {
                            "firstName": "Arnold",
                            "lastName": "Smeulders",
                            "middleNames": [
                                "W.",
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Smeulders"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2350432,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9da15b932df57a8f959471ebc977d620efb18cc1",
            "isKey": false,
            "numCitedBy": 575,
            "numCiting": 46,
            "paperAbstract": {
                "fragments": [],
                "text": "We aim at combining color and shape invariants for indexing and retrieving images. To this end, color models are proposed independent of the object geometry, object pose, and illumination. From these color models, color invariant edges are derived from which shape invariant features are computed. Computational methods are described to combine the color and shape invariants into a unified high-dimensional invariant feature set for discriminatory object retrieval. Experiments have been conducted on a database consisting of 500 images taken from multicolored man-made objects in real world scenes. From the theoretical and experimental results it is concluded that object retrieval based on composite color and shape invariant features provides excellent retrieval accuracy. Object retrieval based on color invariants provides very high retrieval accuracy whereas object retrieval based entirely on shape invariants yields poor discriminative power. Furthermore, the image retrieval scheme is highly robust to partial occlusion, object clutter and a change in the object's pose. Finally, the image retrieval scheme is integrated into the PicToSeek system on-line at http://www.wins.uva.nl/research/isis/PicToSeek/ for searching images on the World Wide Web."
            },
            "slug": "PicToSeek:-combining-color-and-shape-invariant-for-Gevers-Smeulders",
            "title": {
                "fragments": [],
                "text": "PicToSeek: combining color and shape invariant features for image retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "It is concluded that object retrieval based on composite color and shape invariant features provides excellent retrieval accuracy and the image retrieval scheme is highly robust to partial occlusion, object clutter and a change in the object's pose."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Image Process."
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3115530"
                        ],
                        "name": "J. Corridoni",
                        "slug": "J.-Corridoni",
                        "structuredName": {
                            "firstName": "Jacopo",
                            "lastName": "Corridoni",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Corridoni"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8196487"
                        ],
                        "name": "A. Bimbo",
                        "slug": "A.-Bimbo",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Bimbo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Bimbo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1767957"
                        ],
                        "name": "P. Pala",
                        "slug": "P.-Pala",
                        "structuredName": {
                            "firstName": "Pietro",
                            "lastName": "Pala",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Pala"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 1221672,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "efd0cd01302b67847578ceb295a476c034a45c48",
            "isKey": false,
            "numCitedBy": 93,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract. The development of a system supporting querying of image databases by color content tackles a major design choice about properties of colors which are referenced within user queries. On the one hand, low-level properties directly reflect numerical features and concepts tied to the machine representation of color information. On the other hand, high-level properties address concepts such as the perceptual quality of colors and the sensations that they convey. Color-induced sensations include warmth, accordance or contrast, harmony, excitement, depression, anguish, etc. In other words, they refer to the semantics of color usage. In particular, paintings are an example where the message is contained more in the high-level color qualities and spatial arrangements than in the physical properties of colors. Starting from this observation, Johannes Itten introduced a formalism to analyze the use of color in art and the effects that this induces on the user's psyche. In this paper, we present a system which translates the Itten theory into a formal language that expresses the semantics associated with the combination of chromatic properties of color images. The system exploits a competitive learning technique to segment images into regions with homogeneous colors. Fuzzy sets are used to represent low-level region properties such as hue, saturation, luminance, warmth, size and position. A formal language and a set of model-checking rules are implemented to define semantic clauses and verify the degree of truth by which they hold over an image."
            },
            "slug": "Image-retrieval-by-color-semantics-Corridoni-Bimbo",
            "title": {
                "fragments": [],
                "text": "Image retrieval by color semantics"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A system which translates the Itten theory into a formal language that expresses the semantics associated with the combination of chromatic properties of color images and exploits a competitive learning technique to segment images into regions with homogeneous colors."
            },
            "venue": {
                "fragments": [],
                "text": "Multimedia Systems"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145459057"
                        ],
                        "name": "Y. Rui",
                        "slug": "Y.-Rui",
                        "structuredName": {
                            "firstName": "Yong",
                            "lastName": "Rui",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Rui"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153652752"
                        ],
                        "name": "Thomas S. Huang",
                        "slug": "Thomas-S.-Huang",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Huang",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thomas S. Huang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9546964"
                        ],
                        "name": "Shih-Fu Chang",
                        "slug": "Shih-Fu-Chang",
                        "structuredName": {
                            "firstName": "Shih-Fu",
                            "lastName": "Chang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shih-Fu Chang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2910032,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6fa15f525a9814247ecd7cd93636f278d6d9ab3b",
            "isKey": false,
            "numCitedBy": 2521,
            "numCiting": 220,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper provides a comprehensive survey of the technical achievements in the research area of image retrieval, especially content-based image retrieval, an area that has been so active and prosperous in the past few years. The survey includes 100+ papers covering the research aspects of image feature representation and extraction, multidimensional indexing, and system design, three of the fundamental bases of content-based image retrieval. Furthermore, based on the state-of-the-art technology available now and the demand from real-world applications, open research issues are identified and future promising research directions are suggested."
            },
            "slug": "Image-Retrieval:-Current-Techniques,-Promising-and-Rui-Huang",
            "title": {
                "fragments": [],
                "text": "Image Retrieval: Current Techniques, Promising Directions, and Open Issues"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "The survey includes 100+ papers covering the research aspects of image feature representation and extraction, multidimensional indexing, and system design, three of the fundamental bases of content-based image retrieval."
            },
            "venue": {
                "fragments": [],
                "text": "J. Vis. Commun. Image Represent."
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1767957"
                        ],
                        "name": "P. Pala",
                        "slug": "P.-Pala",
                        "structuredName": {
                            "firstName": "Pietro",
                            "lastName": "Pala",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Pala"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1747647"
                        ],
                        "name": "S. Santini",
                        "slug": "S.-Santini",
                        "structuredName": {
                            "firstName": "Simone",
                            "lastName": "Santini",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Santini"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 17283038,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f7d0d38d6c3bd4c06fe8dc36a53553b8e633a564",
            "isKey": false,
            "numCitedBy": 50,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Image-retrieval-by-shape-and-texture-Pala-Santini",
            "title": {
                "fragments": [],
                "text": "Image retrieval by shape and texture"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit."
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1703041"
                        ],
                        "name": "C. Fuh",
                        "slug": "C.-Fuh",
                        "structuredName": {
                            "firstName": "Chiou-Shann",
                            "lastName": "Fuh",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Fuh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2107233048"
                        ],
                        "name": "S. Cho",
                        "slug": "S.-Cho",
                        "structuredName": {
                            "firstName": "Shun-Wen",
                            "lastName": "Cho",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Cho"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2227094"
                        ],
                        "name": "K. Essig",
                        "slug": "K.-Essig",
                        "structuredName": {
                            "firstName": "Kai",
                            "lastName": "Essig",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Essig"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 24335770,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "80255ea197577fb6d8e70120e78b4da445f5a22b",
            "isKey": false,
            "numCitedBy": 110,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "In this work, we propose a model of a content-based image retrieval system by using the new idea of combining a color segmentation with relationship trees and a corresponding tree-matching method. We retain the hierarchical relationship of the regions in an image during segmentation. Using the information of the relationships and features of the regions, we can represent the desired objects in images more accurately. In retrieval, we compare not only region features but also region relationships."
            },
            "slug": "Hierarchical-color-image-region-segmentation-for-Fuh-Cho",
            "title": {
                "fragments": [],
                "text": "Hierarchical color image region segmentation for content-based image retrieval system"
            },
            "tldr": {
                "abstractSimilarityScore": 91,
                "text": "A model of a content-based image retrieval system by using the new idea of combining a color segmentation with relationship trees and a corresponding tree-matching method to retain the hierarchical relationship of the regions in an image during segmentation is proposed."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Image Process."
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144977655"
                        ],
                        "name": "Hsin-Chih Lin",
                        "slug": "Hsin-Chih-Lin",
                        "structuredName": {
                            "firstName": "Hsin-Chih",
                            "lastName": "Lin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hsin-Chih Lin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2151977472"
                        ],
                        "name": "Ling-Ling Wang",
                        "slug": "Ling-Ling-Wang",
                        "structuredName": {
                            "firstName": "Ling-Ling",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ling-Ling Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "70599738"
                        ],
                        "name": "Shin-Nine Yang",
                        "slug": "Shin-Nine-Yang",
                        "structuredName": {
                            "firstName": "Shin-Nine",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shin-Nine Yang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15157320,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f5164e9348e9d48fc0855573d6c450d57644ffc5",
            "isKey": false,
            "numCitedBy": 72,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "A new approach to retrieving images from a color image database is proposed in this paper. Each image in the database is represented by a pseudo two-dimensional hidden Markov model (2D PHMM), where both the chromatic and spatial information about the image could be adequately involved. In addition, a pictorial querying method is used, by which the users can paint only rough contents of the desired images if their information concerning the desired images is not crisp. The use of the flexible querying mechanism and 2D PHMMs eliminates the drawbacks of utilizing textual descriptions to retrieve images. Furthermore, effective statistical matching between the query picture and each image in the database can be achieved. The probability of the query picture generated by each 2D PHMM is just considered as the matching score between the query and the corresponding image. The images which best satisfy the query can thus be retrieved. Promising experimental results show the feasibility and effectiveness of the proposed approach."
            },
            "slug": "Color-image-retrieval-based-on-hidden-Markov-models-Lin-Wang",
            "title": {
                "fragments": [],
                "text": "Color image retrieval based on hidden Markov models"
            },
            "tldr": {
                "abstractSimilarityScore": 90,
                "text": "A new approach to retrieving images from a color image database is proposed, where each image is represented by a pseudo two-dimensional hidden Markov model (2D PHMM), where both the chromatic and spatial information about the image could be adequately involved."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Image Process."
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2170732251"
                        ],
                        "name": "Fang Liu",
                        "slug": "Fang-Liu",
                        "structuredName": {
                            "firstName": "Fang",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Fang Liu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1719389"
                        ],
                        "name": "Rosalind W. Picard",
                        "slug": "Rosalind-W.-Picard",
                        "structuredName": {
                            "firstName": "Rosalind",
                            "lastName": "Picard",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Rosalind W. Picard"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 2675336,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b0df54adafa6eb7743e75d5cf0d7d92c1c1eaa72",
            "isKey": false,
            "numCitedBy": 685,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "One of the fundamental challenges in pattern recognition is choosing a set of features appropriate to a class of problems. In applications such as database retrieval, it is important that image features used in pattern comparison provide good measures of image perceptual similarities. We present an image model with a new set of features that address the challenge of perceptual similarity. The model is based on the 2D Wold decomposition of homogeneous random fields. The three resulting mutually orthogonal subfields have perceptual properties which can be described as \"periodicity,\" \"directionality,\" and \"randomness,\" approximating what are indicated to be the three most important dimensions of human texture perception. The method presented improves upon earlier Wold-based models in its tolerance to a variety of local inhomogeneities which arise in natural textures and its invariance under image transformation such as rotation. An image retrieval algorithm based on the new texture model is presented. Different types of image features are aggregated for similarity comparison by using a Bayesian probabilistic approach. The, effectiveness of the Wold model at retrieving perceptually similar natural textures is demonstrated in comparison to that of two other well-known pattern recognition methods. The Wold model appears to offer a perceptually more satisfying measure of pattern similarity while exceeding the performance of these other methods by traditional pattern recognition criteria. Examples of natural scene Wold texture modeling are also presented."
            },
            "slug": "Periodicity,-Directionality,-and-Randomness:-Wold-Liu-Picard",
            "title": {
                "fragments": [],
                "text": "Periodicity, Directionality, and Randomness: Wold Features for Image Modeling and Retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "The Wold model appears to offer a perceptually more satisfying measure of pattern similarity while exceeding the performance of these other methods by traditional pattern recognition criteria."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8196487"
                        ],
                        "name": "A. Bimbo",
                        "slug": "A.-Bimbo",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Bimbo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Bimbo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1767957"
                        ],
                        "name": "P. Pala",
                        "slug": "P.-Pala",
                        "structuredName": {
                            "firstName": "Pietro",
                            "lastName": "Pala",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Pala"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1608216,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e6182e4e462fd25ac6e1744415b481d422c861b2",
            "isKey": false,
            "numCitedBy": 474,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "Effective image retrieval by content from database requires that visual image properties are used instead of textual labels to properly index and recover pictorial data. Retrieval by shape similarity, given a user-sketched template is particularly challenging, owing to the difficulty to derive a similarity measure that closely conforms to the common perception of similarity by humans. In this paper, we present a technique which is based on elastic matching of sketched templates over the shapes in the images to evaluate similarity ranks. The degree of matching achieved and the elastic deformation energy spent by the sketch to achieve such a match are used to derive a measure of similarity between the sketch and the images in the database and to rank images to be displayed. The elastic matching is integrated with arrangements to provide scale invariance and take into account spatial relationships between objects in multi-object queries. Examples from a prototype system are expounded with considerations about the effectiveness of the approach and comparative performance analysis."
            },
            "slug": "Visual-Image-Retrieval-by-Elastic-Matching-of-User-Bimbo-Pala",
            "title": {
                "fragments": [],
                "text": "Visual Image Retrieval by Elastic Matching of User Sketches"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A technique which is based on elastic matching of sketched templates over the shapes in the images to evaluate similarity ranks and is integrated with arrangements to provide scale invariance and take into account spatial relationships between objects in multi-object queries."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145934140"
                        ],
                        "name": "Toshikazu Kato",
                        "slug": "Toshikazu-Kato",
                        "structuredName": {
                            "firstName": "Toshikazu",
                            "lastName": "Kato",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Toshikazu Kato"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145375983"
                        ],
                        "name": "T. Kurita",
                        "slug": "T.-Kurita",
                        "structuredName": {
                            "firstName": "Takio",
                            "lastName": "Kurita",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kurita"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1809629"
                        ],
                        "name": "N. Otsu",
                        "slug": "N.-Otsu",
                        "structuredName": {
                            "firstName": "Nobuyuki",
                            "lastName": "Otsu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Otsu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2055529881"
                        ],
                        "name": "Keiji Hirata",
                        "slug": "Keiji-Hirata",
                        "structuredName": {
                            "firstName": "Keiji",
                            "lastName": "Hirata",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Keiji Hirata"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 60539750,
            "fieldsOfStudy": [
                "Computer Science",
                "Art"
            ],
            "id": "fdf2c1986afd802f1163b6c08895eb11ed1e1877",
            "isKey": false,
            "numCitedBy": 219,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "Gives a basic idea and its fundamental algorithms of the visual interface for image database systems. The QVE (Query by Visual Example) accepts a sketch roughly drawn by a user to retrieve the original image and the similar images. The system evaluates the similarity between the rough sketch, i.e. a visual example, and each of the image data in the database automatically. The QVE interface is implemented and examined on an experimental electronic art gallery called ART MUSEUM. This paper also gives some experimental results and a current evaluation. The algorithms are quite effective for content based image retrieval.<<ETX>>"
            },
            "slug": "A-sketch-retrieval-method-for-full-color-image-by-Kato-Kurita",
            "title": {
                "fragments": [],
                "text": "A sketch retrieval method for full color image database-query by visual example"
            },
            "tldr": {
                "abstractSimilarityScore": 57,
                "text": "The QVE (Query by Visual Example) accepts a sketch roughly drawn by a user to retrieve the original image and the similar images and evaluates the similarity between the rough sketch and each of the image data in the database automatically."
            },
            "venue": {
                "fragments": [],
                "text": "[1992] Proceedings. 11th IAPR International Conference on Pattern Recognition"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1717060"
                        ],
                        "name": "D. Androutsos",
                        "slug": "D.-Androutsos",
                        "structuredName": {
                            "firstName": "Dimitrios",
                            "lastName": "Androutsos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Androutsos"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1705037"
                        ],
                        "name": "K. Plataniotis",
                        "slug": "K.-Plataniotis",
                        "structuredName": {
                            "firstName": "Konstantinos",
                            "lastName": "Plataniotis",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Plataniotis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1707519"
                        ],
                        "name": "A. Venetsanopoulos",
                        "slug": "A.-Venetsanopoulos",
                        "structuredName": {
                            "firstName": "Anastasios",
                            "lastName": "Venetsanopoulos",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Venetsanopoulos"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15770632,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c8b881faf626f88cfff4e4642f967fcffc8252ce",
            "isKey": false,
            "numCitedBy": 127,
            "numCiting": 41,
            "paperAbstract": {
                "fragments": [],
                "text": "Color is the characteristic which is most used for image indexing and retrieval. Due to its simplicity, the color histogram remains the most commonly used method for this task. However, the lack of good perceptual histogram similarity measures, the global color content of histograms, and the erroneous retrieval results due to gamma nonlinearity, call for improved methods. We present a new scheme which implements a recursive HSV-space segmentation technique to identify perceptually prominent color areas. The average color vector of these extracted areas are then used to build the image indices, requiring very little storage. Our retrieval is performed by implementing a combination distance measure, based on the vector angle between two vectors. Our system provides accurate retrieval results and high retrieval rate. It allows for queries based on single or multiple colors and, in addition, it allows for certain colors to be excluded in the query. This flexibility is due to our distance measure and the multidimensional query space in which the retrieval ranking of the database images is determined. Furthermore, our scheme proves to be very resistant to gamma nonlinearity providing robust retrieval results for a wide range of gamma nonlinearity values, which proves to be of great importance since, in general, the image acquisition source is unknown."
            },
            "slug": "A-Novel-Vector-Based-Approach-to-Color-Image-Using-Androutsos-Plataniotis",
            "title": {
                "fragments": [],
                "text": "A Novel Vector-Based Approach to Color Image Retrieval Using a Vector Angular-Based Distance Measure"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A new scheme which implements a recursive HSV-space segmentation technique to identify perceptually prominent color areas, providing robust retrieval results for a wide range of gamma nonlinearity values, which proves to be of great importance since, in general, the image acquisition source is unknown."
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Vis. Image Underst."
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712991"
                        ],
                        "name": "M. Flickner",
                        "slug": "M.-Flickner",
                        "structuredName": {
                            "firstName": "Myron",
                            "lastName": "Flickner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Flickner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733393"
                        ],
                        "name": "H. Sawhney",
                        "slug": "H.-Sawhney",
                        "structuredName": {
                            "firstName": "Harpreet",
                            "lastName": "Sawhney",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Sawhney"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152883679"
                        ],
                        "name": "J. Ashley",
                        "slug": "J.-Ashley",
                        "structuredName": {
                            "firstName": "Jonathan",
                            "lastName": "Ashley",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Ashley"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1391129943"
                        ],
                        "name": "Qian Huang",
                        "slug": "Qian-Huang",
                        "structuredName": {
                            "firstName": "Qian",
                            "lastName": "Huang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Qian Huang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1786444"
                        ],
                        "name": "B. Dom",
                        "slug": "B.-Dom",
                        "structuredName": {
                            "firstName": "Byron",
                            "lastName": "Dom",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Dom"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2087139"
                        ],
                        "name": "M. Gorkani",
                        "slug": "M.-Gorkani",
                        "structuredName": {
                            "firstName": "Monika",
                            "lastName": "Gorkani",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Gorkani"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39311329"
                        ],
                        "name": "J. Hafner",
                        "slug": "J.-Hafner",
                        "structuredName": {
                            "firstName": "Jim",
                            "lastName": "Hafner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Hafner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2499047"
                        ],
                        "name": "Denis Lee",
                        "slug": "Denis-Lee",
                        "structuredName": {
                            "firstName": "Denis",
                            "lastName": "Lee",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Denis Lee"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143867341"
                        ],
                        "name": "D. Petkovic",
                        "slug": "D.-Petkovic",
                        "structuredName": {
                            "firstName": "Dragutin",
                            "lastName": "Petkovic",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Petkovic"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144028064"
                        ],
                        "name": "David Steele",
                        "slug": "David-Steele",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Steele",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David Steele"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "70341848"
                        ],
                        "name": "P. Yanker",
                        "slug": "P.-Yanker",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Yanker",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Yanker"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 110716,
            "fieldsOfStudy": [
                "Computer Science",
                "Art"
            ],
            "id": "dc139f901c869f80b54b41f89d5b7f35c7dfa3c7",
            "isKey": false,
            "numCitedBy": 4258,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "Research on ways to extend and improve query methods for image databases is widespread. We have developed the QBIC (Query by Image Content) system to explore content-based retrieval methods. QBIC allows queries on large image and video databases based on example images, user-constructed sketches and drawings, selected color and texture patterns, camera and object motion, and other graphical information. Two key properties of QBIC are (1) its use of image and video content-computable properties of color, texture, shape and motion of images, videos and their objects-in the queries, and (2) its graphical query language, in which queries are posed by drawing, selecting and other graphical means. This article describes the QBIC system and demonstrates its query capabilities. QBIC technology is part of several IBM products. >"
            },
            "slug": "Query-by-Image-and-Video-Content:-The-QBIC-System-Flickner-Sawhney",
            "title": {
                "fragments": [],
                "text": "Query by Image and Video Content: The QBIC System"
            },
            "tldr": {
                "abstractSimilarityScore": 50,
                "text": "The QBIC system is described and its query capabilities are demonstrated, which allows queries on large image and video databases based on example images, user-constructed sketches and drawings, selected color and texture patterns, camera and object motion, and other graphical information."
            },
            "venue": {
                "fragments": [],
                "text": "Computer"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2146496"
                        ],
                        "name": "J. Vendrig",
                        "slug": "J.-Vendrig",
                        "structuredName": {
                            "firstName": "Jeroen",
                            "lastName": "Vendrig",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Vendrig"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1717056"
                        ],
                        "name": "M. Worring",
                        "slug": "M.-Worring",
                        "structuredName": {
                            "firstName": "Marcel",
                            "lastName": "Worring",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Worring"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144638781"
                        ],
                        "name": "A. Smeulders",
                        "slug": "A.-Smeulders",
                        "structuredName": {
                            "firstName": "Arnold",
                            "lastName": "Smeulders",
                            "middleNames": [
                                "W.",
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Smeulders"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 17411488,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f4d244c1e884384b2e0e7072944ee6f00c5525cd",
            "isKey": false,
            "numCitedBy": 34,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "In current image retrieval systems the user refines his query by selecting example images from a relevance ranking. Since the top ranked images are all similar, user feedback often results in rearrangement of the presented images only. The Filter Image Browsing method provides better incorporation of user interaction in the retrieval process, because it is based on differences between images rather than similarities. Filter Image Browsing presents overviews of the database to users and lets them iteratively zoom in on parts of the image collection. In contrast to many papers where a new system is just introduced, we performed an extensive evaluation of the methods presented using a user simulation. Results for a database containing 10,000 images show that Filter Image Browsing requires less effort from the user. The implementation of Filter Image Browsing in the ImageRETRO system is accessible via the Web."
            },
            "slug": "Filter-Image-Browsing-Exploiting-Interaction-in-Vendrig-Worring",
            "title": {
                "fragments": [],
                "text": "Filter Image Browsing - Exploiting Interaction in Image Retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "An extensive evaluation of the methods presented using a user simulation shows that Filter Image Browsing requires less effort from the user."
            },
            "venue": {
                "fragments": [],
                "text": "VISUAL"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "115835876"
                        ],
                        "name": "G. Gimel'farb",
                        "slug": "G.-Gimel'farb",
                        "structuredName": {
                            "firstName": "Georgy",
                            "lastName": "Gimel'farb",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Gimel'farb"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145295484"
                        ],
                        "name": "Anil K. Jain",
                        "slug": "Anil-K.-Jain",
                        "structuredName": {
                            "firstName": "Anil",
                            "lastName": "Jain",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Anil K. Jain"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 38997491,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "389eb24c5e7452e6cbec7506f6560f3a1dca372a",
            "isKey": false,
            "numCitedBy": 108,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "On-retrieving-textured-images-from-an-image-Gimel'farb-Jain",
            "title": {
                "fragments": [],
                "text": "On retrieving textured images from an image database"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit."
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1749590"
                        ],
                        "name": "S. Sclaroff",
                        "slug": "S.-Sclaroff",
                        "structuredName": {
                            "firstName": "Stan",
                            "lastName": "Sclaroff",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Sclaroff"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9127836"
                        ],
                        "name": "M. L. Cascia",
                        "slug": "M.-L.-Cascia",
                        "structuredName": {
                            "firstName": "Marco",
                            "lastName": "Cascia",
                            "middleNames": [
                                "La"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. L. Cascia"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2098229"
                        ],
                        "name": "S. Sethi",
                        "slug": "S.-Sethi",
                        "structuredName": {
                            "firstName": "Saratendu",
                            "lastName": "Sethi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Sethi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2588636"
                        ],
                        "name": "L. Taycher",
                        "slug": "L.-Taycher",
                        "structuredName": {
                            "firstName": "Leonid",
                            "lastName": "Taycher",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Taycher"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 14892542,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bda2a1fbde273f7fc53cfd6de5d1ccdc1693d210",
            "isKey": false,
            "numCitedBy": 162,
            "numCiting": 67,
            "paperAbstract": {
                "fragments": [],
                "text": "A system is proposed that combines textual and visual statistics in a single index vector for content-based search of a WWW image database. Textual statistics are captured in vector form using latent semantic indexing based on text in the containing HTML document. Visual statistics are captured in vector form using color and orientation histograms. By using an integrated approach, it becomes possible to take advantage of possible statistical couplings between the content of the document (latent semantic content) and the contents of images (visual statistics). The combined approach allows improved performance in conducting content-based search. Search performance experiments are reported for a database containing 350,000 images collected from the WWW."
            },
            "slug": "Unifying-Textual-and-Visual-Cues-for-Content-Based-Sclaroff-Cascia",
            "title": {
                "fragments": [],
                "text": "Unifying Textual and Visual Cues for Content-Based Image Retrieval on the World Wide Web"
            },
            "tldr": {
                "abstractSimilarityScore": 81,
                "text": "A system is proposed that combines textual and visual statistics in a single index vector for content- based search of a WWW image database and allows improved performance in conducting content-based search."
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Vis. Image Underst."
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47088868"
                        ],
                        "name": "Joshua R. Smith",
                        "slug": "Joshua-R.-Smith",
                        "structuredName": {
                            "firstName": "Joshua",
                            "lastName": "Smith",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Joshua R. Smith"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9546964"
                        ],
                        "name": "Shih-Fu Chang",
                        "slug": "Shih-Fu-Chang",
                        "structuredName": {
                            "firstName": "Shih-Fu",
                            "lastName": "Chang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shih-Fu Chang"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 16418860,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3e9e0cf8587dedbef0d161db736dedc76e6c4f36",
            "isKey": false,
            "numCitedBy": 130,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract. We present a new system for querying for images by regions and their spatial and feature attributes. The system enables the user to find the images that contain arrangements of regions similar to those diagrammed in a query image. By indexing the attributes of regions, such as sizes, locations and visual features, a wide variety of complex joint spatial and feature queries are efficiently computed. In order to demonstrate the utility of the system, we develop a process for the extracting color regions from photographic images. We demonstrate that integrated spatial and feature querying using color regions improves image search capabilities over non-spatial content-based image retrieval methods."
            },
            "slug": "Integrated-spatial-and-feature-image-query-Smith-Chang",
            "title": {
                "fragments": [],
                "text": "Integrated spatial and feature image query"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "It is demonstrated that integrated spatial and feature querying using color regions improves image search capabilities over non-spatial content-based image retrieval methods."
            },
            "venue": {
                "fragments": [],
                "text": "Multimedia Systems"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1704728"
                        ],
                        "name": "T. Tuytelaars",
                        "slug": "T.-Tuytelaars",
                        "structuredName": {
                            "firstName": "Tinne",
                            "lastName": "Tuytelaars",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Tuytelaars"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1681236"
                        ],
                        "name": "L. Gool",
                        "slug": "L.-Gool",
                        "structuredName": {
                            "firstName": "Luc",
                            "lastName": "Gool",
                            "middleNames": [
                                "Van"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Gool"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 22188121,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "979089260419884b43cfeb3b23df23b6a7734f9f",
            "isKey": false,
            "numCitedBy": 239,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "This contribution develops a new technique for content-based image retrieval. Where most existing image retrieval systems mainly focus on color and color distribution or texture, we classify the images based on local invariants. These features represent the image in a very compact way and allow fast comparison and feature matching with images in the database. Using local features makes the system robust to occlusions and changes in the background. Using invariants makes it robust to changes in viewpoint and illumination."
            },
            "slug": "Content-Based-Image-Retrieval-Based-on-Local-Tuytelaars-Gool",
            "title": {
                "fragments": [],
                "text": "Content-Based Image Retrieval Based on Local Affinely Invariant Regions"
            },
            "tldr": {
                "abstractSimilarityScore": 60,
                "text": "This contribution develops a new technique for content-based image retrieval that classify the images based on local invariants that represent the image in a very compact way and allow fast comparison and feature matching with images in the database."
            },
            "venue": {
                "fragments": [],
                "text": "VISUAL"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1765960"
                        ],
                        "name": "J. Assfalg",
                        "slug": "J.-Assfalg",
                        "structuredName": {
                            "firstName": "J\u00fcrgen",
                            "lastName": "Assfalg",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Assfalg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8196487"
                        ],
                        "name": "A. Bimbo",
                        "slug": "A.-Bimbo",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Bimbo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Bimbo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1767957"
                        ],
                        "name": "P. Pala",
                        "slug": "P.-Pala",
                        "structuredName": {
                            "firstName": "Pietro",
                            "lastName": "Pala",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Pala"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 43070859,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "41cc24b305e6c8999a5b805f2edc74140147edf6",
            "isKey": false,
            "numCitedBy": 28,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "Query specification for content based image retrieval is typically accomplished through query-by-example paradigms, such as query-by-image and query-by-sketch. In some cases query-by-sketch can be difficult because of lack of sketching abilities, difficulty to detect distinguishing image features. Therefore, querying is performed through the query-by-image paradigm. However, this paradigm often fails since a single sample image rarely includes all and only the characterizing elements the user is looking for. The paper presents a system that supports query-by-image using multiple image examples, both positive and negative. The system also enables editing of examples so as to disregard those image features that are not relevant to the query."
            },
            "slug": "Using-multiple-examples-for-content-based-image-Assfalg-Bimbo",
            "title": {
                "fragments": [],
                "text": "Using multiple examples for content-based image retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "The paper presents a system that supports query-by-image using multiple image examples, both positive and negative, and enables editing of examples so as to disregard those image features that are not relevant to the query."
            },
            "venue": {
                "fragments": [],
                "text": "2000 IEEE International Conference on Multimedia and Expo. ICME2000. Proceedings. Latest Advances in the Fast Changing World of Multimedia (Cat. No.00TH8532)"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47088868"
                        ],
                        "name": "Joshua R. Smith",
                        "slug": "Joshua-R.-Smith",
                        "structuredName": {
                            "firstName": "Joshua",
                            "lastName": "Smith",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Joshua R. Smith"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 60535699,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c2d2d45d66f82514084f6c3999300e7d8a22f289",
            "isKey": false,
            "numCitedBy": 137,
            "numCiting": 3,
            "paperAbstract": {
                "fragments": [],
                "text": "One of the most significant problems in content-based image retrieval results from the lack of a common test-bed for researchers. Although many published articles report on content-based retrieval results using color photographs, there has been little effort in establishing a benchmark set of images and queries. Doing so would have many benefits in advancing the technology and utility of content-based image retrieval systems. We address the growing need for establishing a common content-based image retrieval test-bed."
            },
            "slug": "Image-retrieval-evaluation-Smith",
            "title": {
                "fragments": [],
                "text": "Image retrieval evaluation"
            },
            "tldr": {
                "abstractSimilarityScore": 50,
                "text": "This work addresses the growing need for establishing a common content-based image retrieval test-bed and establishes a benchmark set of images and queries for this type of retrieval."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings. IEEE Workshop on Content-Based Access of Image and Video Libraries (Cat. No.98EX173)"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3174044"
                        ],
                        "name": "L. H. Armitage",
                        "slug": "L.-H.-Armitage",
                        "structuredName": {
                            "firstName": "Linda",
                            "lastName": "Armitage",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. H. Armitage"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2137152"
                        ],
                        "name": "P. Enser",
                        "slug": "P.-Enser",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Enser",
                            "middleNames": [
                                "G.",
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Enser"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 45350741,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "316440b3a78715902ebdf9a433867143c70f1b85",
            "isKey": false,
            "numCitedBy": 279,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes a project in which an analysis was undertaken of user queries addressed to seven libraries which manage archives of widely varying still and moving image material. The sampling procedure is described, in which queries obtained from each library were broadly categorised by image content, identification and accessibility. Attention is focused on the image content requests, for which a categorisation based on facet analysis is developed. The analytical tool which is used for this purpose is based on a schema already well established for the analysis of levels of meaning in images. The project demonstrates the possibility of formulating a general categorisation of requests which seek widely different still and moving image material. The paper concludes with observations on the potential value of embedding such a schema within the user interface of unmediated-query visual information retrieval systems."
            },
            "slug": "Analysis-of-user-need-in-image-archives-Armitage-Enser",
            "title": {
                "fragments": [],
                "text": "Analysis of user need in image archives"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "The project demonstrates the possibility of formulating a general categorisation of requests which seek widely different still and moving image material, and the potential value of embedding such a schema within the user interface of unmediated-query visual information retrieval systems."
            },
            "venue": {
                "fragments": [],
                "text": "J. Inf. Sci."
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1852020"
                        ],
                        "name": "N. Yazdani",
                        "slug": "N.-Yazdani",
                        "structuredName": {
                            "firstName": "Nasser",
                            "lastName": "Yazdani",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Yazdani"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695700"
                        ],
                        "name": "Z. M. \u00d6zsoyoglu",
                        "slug": "Z.-M.-\u00d6zsoyoglu",
                        "structuredName": {
                            "firstName": "Z.",
                            "lastName": "\u00d6zsoyoglu",
                            "middleNames": [
                                "Meral"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Z. M. \u00d6zsoyoglu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2421251"
                        ],
                        "name": "G. \u00d6zsoyoglu",
                        "slug": "G.-\u00d6zsoyoglu",
                        "structuredName": {
                            "firstName": "Gultekin",
                            "lastName": "\u00d6zsoyoglu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. \u00d6zsoyoglu"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 19287909,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "18c22dca6c7b5d750947f01c28063051bbbe7d9d",
            "isKey": false,
            "numCitedBy": 16,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a data-driven method for efficient retrieval of objects as well as similar shapes with a given query object in the spatial database environment. The idea is to find some features from the image object in order to build an index search structure. For the sake of similarity matching among shapes, the features must be invariant to rotation, translation and scaling. We propose a set of generic features that are invariant to these transformations. Each feature in the feature vector is associated with a weight based on the application, which is used in the search process. Any multidimensional point access method can then be used to build an index. In this paper, a variant of the K-D-B tree is used to construct the index structure. Finally, we define a similarity measure to find objects similar to a given query object, and discuss how similarity queries can be processed using the index structure.<<ETX>>"
            },
            "slug": "A-framework-for-feature-based-indexing-for-spatial-Yazdani-\u00d6zsoyoglu",
            "title": {
                "fragments": [],
                "text": "A framework for feature-based indexing for spatial databases"
            },
            "tldr": {
                "abstractSimilarityScore": 79,
                "text": "This paper proposes a data-driven method for efficient retrieval of objects as well as similar shapes with a given query object in the spatial database environment, using a variant of the K-D-B tree to construct the index structure."
            },
            "venue": {
                "fragments": [],
                "text": "Seventh International Working Conference on Scientific and Statistical Database Management"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2081718"
                        ],
                        "name": "M. Stricker",
                        "slug": "M.-Stricker",
                        "structuredName": {
                            "firstName": "Markus",
                            "lastName": "Stricker",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Stricker"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35473334"
                        ],
                        "name": "Markus Orengo",
                        "slug": "Markus-Orengo",
                        "structuredName": {
                            "firstName": "Markus",
                            "lastName": "Orengo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Markus Orengo"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 16156344,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1c6d4081ea1e1c13afabdc9870e6e27d75facaa0",
            "isKey": false,
            "numCitedBy": 1968,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe two new color indexing techniques. The first one is a more robust version of the commonly used color histogram indexing. In the index we store the cumulative color histograms. The L1-, L2-, L(infinity )-distance between two cumulative color histograms can be used to define a similarity measure of these two color distributions. We show that this method produces slightly better results than color histogram methods, but it is significantly more robust with respect to the quantization parameter of the histograms. The second technique is an example of a new approach to color indexing. Instead of storing the complete color distributions, the index contains only their dominant features. We implement this approach by storing the first three moments of each color channel of an image in the index, i.e., for a HSV image we store only 9 floating point numbers per image. The similarity function which is used for the retrieval is a weighted sum of the absolute differences between corresponding moments. Our tests clearly demonstrate that a retrieval based on this technique produces better results and runs faster than the histogram-based methods."
            },
            "slug": "Similarity-of-color-images-Stricker-Orengo",
            "title": {
                "fragments": [],
                "text": "Similarity of color images"
            },
            "tldr": {
                "abstractSimilarityScore": 64,
                "text": "Two new color indexing techniques are described, one of which is a more robust version of the commonly used color histogram indexing and the other which is an example of a new approach tocolor indexing that contains only their dominant features."
            },
            "venue": {
                "fragments": [],
                "text": "Electronic Imaging"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "10251113"
                        ],
                        "name": "C. Jacobs",
                        "slug": "C.-Jacobs",
                        "structuredName": {
                            "firstName": "Charles",
                            "lastName": "Jacobs",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Jacobs"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "37737599"
                        ],
                        "name": "A. Finkelstein",
                        "slug": "A.-Finkelstein",
                        "structuredName": {
                            "firstName": "Adam",
                            "lastName": "Finkelstein",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Finkelstein"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1745260"
                        ],
                        "name": "D. Salesin",
                        "slug": "D.-Salesin",
                        "structuredName": {
                            "firstName": "D.",
                            "lastName": "Salesin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Salesin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7884491,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7e9bd47e9fa53e8719aba15e4367096317d45f74",
            "isKey": false,
            "numCitedBy": 835,
            "numCiting": 67,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a method for searching in an image database using a query image that is similar to the intended target. The query image may be a hand-drawn sketch or a (potentially low-quality) scan of the image to be retrieved. Our searching algorithm makes use of multiresolution wavelet decompositions of the query and database images. The coefficients of these decompositions are distilled into small \u201csignatures\u201d for each image. We introduce an \u201cimage querying metric\u201d that operates on these signatures. This metric essentially compares how many significant wavelet coefficients the query has in common with potential targets. The metric includes parameters that can be tuned, using a statistical analysis, to accommodate the kinds of image distortions found in different types of image queries. The resulting algorithm is simple, requires very little storage overhead for the database of signatures, and is fast enough to be performed on a database of 20,000 images at interactive rates (on standard desktop machines) as a query is sketched. Our experiments with hundreds of queries in databases of 1000 and 20,000 images show dramatic improvement, in both speed and success rate, over using a conventional L1, L2, or color histogram norm. CR"
            },
            "slug": "Fast-multiresolution-image-querying-Jacobs-Finkelstein",
            "title": {
                "fragments": [],
                "text": "Fast multiresolution image querying"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "An \u201cimage querying metric\u201d is introduced that operates on how many significant wavelet coefficients the query has in common with potential targets, and includes parameters that can be tuned, using a statistical analysis, to accommodate the kinds of image distortions found in different types of image queries."
            },
            "venue": {
                "fragments": [],
                "text": "SIGGRAPH"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1719385"
                        ],
                        "name": "H. Samet",
                        "slug": "H.-Samet",
                        "structuredName": {
                            "firstName": "Hanan",
                            "lastName": "Samet",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Samet"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1696998"
                        ],
                        "name": "A. Soffer",
                        "slug": "A.-Soffer",
                        "structuredName": {
                            "firstName": "Aya",
                            "lastName": "Soffer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Soffer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1496886,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ad8d680932a5994a66af0844349431b42fd7dcfe",
            "isKey": false,
            "numCitedBy": 83,
            "numCiting": 41,
            "paperAbstract": {
                "fragments": [],
                "text": "A system named MARCO (denoting map retrieval by content) that is used for the acquisition, storage, indexing, and retrieval of map images is presented. The input to MARCO are raster images of separate map layers and raster images of map composites. A legend-driven map interpretation system converts map layer images from their physical representation to their logical representation. This logical representation is then used to automatically index both the composite and the layer images. Methods for incorporating logical and physical layer images as well as composite images into the framework of a relational database management system are described. Indices are constructed on both the contextual and the spatial data thereby enabling efficient retrieval of layer and composite images based on contextual as well as spatial specifications. Example queries and query processing strategies using these indices are described. The user interface is demonstrated via the execution of an example query. Results of an experimental study on a large amount of data are presented. The system is evaluated in terms of accuracy and in terms of query execution time."
            },
            "slug": "MARCO:-MAp-Retrieval-by-COntent-Samet-Soffer",
            "title": {
                "fragments": [],
                "text": "MARCO: MAp Retrieval by COntent"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "Methods for incorporating logical and physical layer images as well as composite images into the framework of a relational database management system are described and results of an experimental study on a large amount of data are presented."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35107741"
                        ],
                        "name": "Fang-Jung Hsu",
                        "slug": "Fang-Jung-Hsu",
                        "structuredName": {
                            "firstName": "Fang-Jung",
                            "lastName": "Hsu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Fang-Jung Hsu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733135"
                        ],
                        "name": "Suh-Yin Lee",
                        "slug": "Suh-Yin-Lee",
                        "structuredName": {
                            "firstName": "Suh-Yin",
                            "lastName": "Lee",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Suh-Yin Lee"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1771750"
                        ],
                        "name": "B. Lin",
                        "slug": "B.-Lin",
                        "structuredName": {
                            "firstName": "Bao-Shuh",
                            "lastName": "Lin",
                            "middleNames": [
                                "Paul"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Lin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 36697315,
            "fieldsOfStudy": [
                "Computer Science",
                "Environmental Science"
            ],
            "id": "63d591bf87d4fa9de49ae22fd498fd1f9a0f637a",
            "isKey": false,
            "numCitedBy": 9,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "The image retrieval based on spatial content is an attracting task in many image database applications. The 2D strings provide a natural way of constructing spatial indexing for images and support effective picture query. Nevertheless, the 2D string is deficient in describing the spatial knowledge of nonzero sized objects with overlapping. In this paper, we use an ordered labeled tree, a 2D C-tree, to be the spatial representation for images and propose the tree-matching algorithm for similarity retrieval. The distance between 2D C-trees is used to measure the similarity of images. The proposed tree comparison algorithm is also modified to compute the partial tree distance for subpicture query. Experimental results for verifying the effectiveness of similarity retrieval by 2D C-trees matching are presented."
            },
            "slug": "Similarity-Retrieval-by-2D-C-Trees-Matching-in-Hsu-Lee",
            "title": {
                "fragments": [],
                "text": "Similarity Retrieval by 2D C-Trees Matching in Image Databases"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "An ordered labeled tree, a 2D C-tree, is used to be the spatial representation for images and the tree-matching algorithm for similarity retrieval is proposed and Experimental results for verifying the effectiveness of similarity retrieval by 2 D C-trees matching are presented."
            },
            "venue": {
                "fragments": [],
                "text": "J. Vis. Commun. Image Represent."
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1790094"
                        ],
                        "name": "Martin Leissler",
                        "slug": "Martin-Leissler",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "Leissler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Martin Leissler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1799848"
                        ],
                        "name": "M. Hemmje",
                        "slug": "M.-Hemmje",
                        "structuredName": {
                            "firstName": "Matthias",
                            "lastName": "Hemmje",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Hemmje"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1720826"
                        ],
                        "name": "E. Neuhold",
                        "slug": "E.-Neuhold",
                        "structuredName": {
                            "firstName": "Erich",
                            "lastName": "Neuhold",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Neuhold"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 18885964,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b24aab592a3a6e96c0ee2ea13e2bc404dda45248",
            "isKey": false,
            "numCitedBy": 10,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "Supporting image-retrieval dialogues between naive users and information systems is a non-trivial task. Although a wide variety of experimental and prototypical image retrieval engines is available, most of them lack appropriate support for end-user oriented front ends. We have decided to illustrate the possible advantages of a tight coupling between interactive 3D information visualization systems and image retrieval systems based on database management systems by deriving requirements from a characteristic application scenario. By means of an \"interactive 3D gallery\" scenario, the paper provides an overview of the requirements, components, and architecture of a general database-driven 3D information visualization system on the basis of an RDBMS and VRML. The given approach supports loading time as well as runtime database access in various forms. It reflects the overall conceptual framework of our activities in this highly dynamic area of research and forms a basis for many other applications where information objects have to be visualized for interacting users or user groups."
            },
            "slug": "Supporting-Image-Retrieval-by-Database-Driven-3D-Leissler-Hemmje",
            "title": {
                "fragments": [],
                "text": "Supporting Image-Retrieval by Database Driven Interactive 3D Information-Visualization"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "The paper provides an overview of the requirements, components, and architecture of a general database-driven 3D information visualization system on the basis of an RDBMS and VRML and illustrates the possible advantages of a tight coupling between interactive 3D Information visualization systems and image retrieval systems based on database management systems."
            },
            "venue": {
                "fragments": [],
                "text": "VISUAL"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2137152"
                        ],
                        "name": "P. Enser",
                        "slug": "P.-Enser",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Enser",
                            "middleNames": [
                                "G.",
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Enser"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 206393711,
            "fieldsOfStudy": [
                "Art"
            ],
            "id": "ef94d01afd7e972fa0ad8401c91e5ccd792e89f2",
            "isKey": false,
            "numCitedBy": 155,
            "numCiting": 128,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper surveys theoretical and practical issues associated with a particular type of information retrieval problem, namely that where the information need is pictorial. The paper is contextualised by the notion of a visually stimulated society, in which the ease of record creation and transmission in the visual medium is contrasted with the difficulty of gaining effective subject access to the world's stores of such records. The technological developments which, in casting the visual image in electronic form, have contributed so significantly to its availability are reviewed briefly, as a prelude to the main thrust of the paper. Concentrating on still and moving pictorial forms of the visual image, the paper dwells on issues related to the subject indexing of pictorial material and discusses four models of pictorial information retrieval corresponding with permutations of the verbal and visual modes for the representation of picture content and of information need."
            },
            "slug": "Progress-in-Documentation-Pictorial-Information-Enser",
            "title": {
                "fragments": [],
                "text": "Progress in Documentation Pictorial Information Retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 70,
                "text": "This paper surveys theoretical and practical issues associated with a particular type of information retrieval problem, namely that where the information need is pictorial, and discusses four models of pictorial information retrieval corresponding with permutations of the verbal and visual modes for the representation of picture content and of information need."
            },
            "venue": {
                "fragments": [],
                "text": "J. Documentation"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2995060"
                        ],
                        "name": "D. Swets",
                        "slug": "D.-Swets",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Swets",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Swets"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145926447"
                        ],
                        "name": "J. Weng",
                        "slug": "J.-Weng",
                        "structuredName": {
                            "firstName": "Juyang",
                            "lastName": "Weng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Weng"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7728397,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "06443af802e91e64ab85b6c100d939ce62ec1840",
            "isKey": false,
            "numCitedBy": 121,
            "numCiting": 97,
            "paperAbstract": {
                "fragments": [],
                "text": "A self-organizing framework for object recognition is described. We describe a hierarchical database structure for image retrieval. The self-organizing hierarchical optimal subspace learning and inference framework (SHOSLIF) system uses the theories of optimal linear projection for optimal feature derivation and a hierarchical structure to achieve logarithmic retrieval complexity. A space-tessellation tree is generated using the most expressive features (MEF) and most discriminating features (MDF) at each level of the tree. The major characteristics of the analysis include: (1) avoiding the limitation of global linear features by deriving a recursively better-fitted set of features for each of the recursively subdivided sets of training samples; (2) generating a smaller tree whose cell boundaries separate the samples along the class boundaries better than the principal component analysis, thereby giving a better generalization capability (i.e., better recognition rate in a disjoint test); (3) accelerating the retrieval using a tree structure for data pruning, utilizing a different set of discriminant features at each level of the tree. We allow for perturbations in the size and position of objects in the images through learning. We demonstrate the technique on a large image database of widely varying real-world objects taken in natural settings, and show the applicability of the approach for variability in position, size, and 3D orientation. This paper concentrates on the hierarchical partitioning of the feature spaces."
            },
            "slug": "Hierarchical-Discriminant-Analysis-for-Image-Swets-Weng",
            "title": {
                "fragments": [],
                "text": "Hierarchical Discriminant Analysis for Image Retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "The self-organizing hierarchical optimal subspace learning and inference framework (SHOSLIF) system uses the theories of optimal linear projection for optimal feature derivation and a hierarchical structure to achieve logarithmic retrieval complexity."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39319377"
                        ],
                        "name": "Yu Zhong",
                        "slug": "Yu-Zhong",
                        "structuredName": {
                            "firstName": "Yu",
                            "lastName": "Zhong",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yu Zhong"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145211604"
                        ],
                        "name": "K. Karu",
                        "slug": "K.-Karu",
                        "structuredName": {
                            "firstName": "Kalle",
                            "lastName": "Karu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Karu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145295484"
                        ],
                        "name": "Anil K. Jain",
                        "slug": "Anil-K.-Jain",
                        "structuredName": {
                            "firstName": "Anil",
                            "lastName": "Jain",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Anil K. Jain"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 30,
                                "start": 25
                            }
                        ],
                        "text": "Also, the application of geometric description derived from scale space theory\nwill reveal viewpoint and scene independent salient point sets, thus opening the way to similarity of images on a few most informative regions or points."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 29853292,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6a4af75831ed098d9fea02507f36cdbc38852fe6",
            "isKey": false,
            "numCitedBy": 181,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "There is a substantial interest in retrieving images from a large database using the textual information contained in the images. An algorithm which will automatically locate the textual regions in the input image will facilitate this task; the optical character recognizer can then be applied to only those regions of the image which contain text. We present a method for automatically locating text in complex color images. The algorithm first finds the approximate locations of text lines using horizontal spatial variance, and then extracts text components in these boxes using color segmentation. The proposed method has been used to locate text in compact disc (CD) and book cover images, as well as in the images of traffic scenes captured by a video camera. Initial results are encouraging and suggest that these algorithms can be used in image retrieval applications."
            },
            "slug": "Locating-text-in-complex-color-images-Zhong-Karu",
            "title": {
                "fragments": [],
                "text": "Locating text in complex color images"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The proposed algorithm has been used to locate text in compact disc and book cover images, as well as in the images of traffic scenes captured by a video camera, and initial results suggest that these algorithms can be used in image retrieval applications."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of 3rd International Conference on Document Analysis and Recognition"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "120670284"
                        ],
                        "name": "Chung-Sheng Li",
                        "slug": "Chung-Sheng-Li",
                        "structuredName": {
                            "firstName": "Chung-Sheng",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chung-Sheng Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2879453"
                        ],
                        "name": "V. Castelli",
                        "slug": "V.-Castelli",
                        "structuredName": {
                            "firstName": "Vittorio",
                            "lastName": "Castelli",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Castelli"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 43691165,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f257933edcb2de66e11f3f9b09cb8a6c0a8a4c5a",
            "isKey": false,
            "numCitedBy": 55,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, the performance of similarity retrieval from satellite image databases by using different sets of spatial and transformed-based texture features is evaluated and compared. A benchmark consisting of 37 satellite image clips from various satellite instruments is devised for the experiments. We show that although the proposed feature set perform only slightly better with the Brodatz set, its performance is far superior for the satellite images. The result indicates that more than 25% of the benchmark patterns can be retrieved with more than 80% accuracy by using normalized Euclidean distance. In contrast, less than 10% of the patterns are retrieved with more than 80% accuracy by using transformed-based feature sets (such as those based on Gabor filter or quadrature mirror filter (QMF))."
            },
            "slug": "Deriving-texture-feature-set-for-content-based-of-Li-Castelli",
            "title": {
                "fragments": [],
                "text": "Deriving texture feature set for content-based retrieval of satellite image database"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "Although the proposed feature set perform only slightly better with the Brodatz set, its performance is far superior for the satellite images, indicating that more than 25% of the benchmark patterns can be retrieved with more than 80% accuracy by using normalized Euclidean distance."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of International Conference on Image Processing"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38416504"
                        ],
                        "name": "S. Aksoy",
                        "slug": "S.-Aksoy",
                        "structuredName": {
                            "firstName": "Selim",
                            "lastName": "Aksoy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Aksoy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1710238"
                        ],
                        "name": "R. Haralick",
                        "slug": "R.-Haralick",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Haralick",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Haralick"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 3364647,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8051e46a73719e3171cdec5dfa9c3a18be36d560",
            "isKey": false,
            "numCitedBy": 55,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "Image retrieval algorithms are generally based on the assumption that visually similar images are located close to each other in the feature space. Since the feature vectors usually exist in a very high dimensional space, a parametric characterization of their distribution is impossible, so non-parametric approaches, like the k-nearest neighbor search, are used for retrieval. This paper introduces a graph-theoretic approach for image retrieval by formulating the database search as a graph clustering problem by using a constraint that retrieved images should be consistent with each other (close in the feature space) as well as being individually similar (close) to the query image. The experiments that compare retrieval precision with and without clustering showed an average precision of 0.76 after clustering, which is an improvement by 5.56% over the average precision before clustering."
            },
            "slug": "Graph-theoretic-clustering-for-image-grouping-and-Aksoy-Haralick",
            "title": {
                "fragments": [],
                "text": "Graph-theoretic clustering for image grouping and retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "A graph-theoretic approach for image retrieval is introduced by formulating the database search as a graph clustering problem by using a constraint that retrieved images should be consistent with each other (close in the feature space) as well as being individually similar to the query image."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149)"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2698725"
                        ],
                        "name": "Christophe Meilhac",
                        "slug": "Christophe-Meilhac",
                        "structuredName": {
                            "firstName": "Christophe",
                            "lastName": "Meilhac",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christophe Meilhac"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1983127"
                        ],
                        "name": "C. Nastar",
                        "slug": "C.-Nastar",
                        "structuredName": {
                            "firstName": "Chahab",
                            "lastName": "Nastar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Nastar"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 17661871,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "28a34d76bafd29ca32b3fa44b8949321d63bfd70",
            "isKey": false,
            "numCitedBy": 130,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a sound framework for relevance feedback in content based image retrieval. The modeling is based on non parametric density estimation of relevant and non relevant items and Bayesian inference. This theory has been successfully applied to benchmark image databases, quantitatively demonstrating its performance for target search, selective control of precision and recall in category search, and improvement of retrieval effectiveness. The paper is illustrated with several experiments and retrieval results on real world data."
            },
            "slug": "Relevance-feedback-and-category-search-in-image-Meilhac-Nastar",
            "title": {
                "fragments": [],
                "text": "Relevance feedback and category search in image databases"
            },
            "tldr": {
                "abstractSimilarityScore": 88,
                "text": "A sound framework for relevance feedback in content based image retrieval is presented, based on non parametric density estimation of relevant and non relevant items and Bayesian inference."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings IEEE International Conference on Multimedia Computing and Systems"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38912099"
                        ],
                        "name": "A. Rao",
                        "slug": "A.-Rao",
                        "structuredName": {
                            "firstName": "Aibing",
                            "lastName": "Rao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Rao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1748081"
                        ],
                        "name": "R. Srihari",
                        "slug": "R.-Srihari",
                        "structuredName": {
                            "firstName": "Rohini",
                            "lastName": "Srihari",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Srihari"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1720488"
                        ],
                        "name": "Zhongfei Zhang",
                        "slug": "Zhongfei-Zhang",
                        "structuredName": {
                            "firstName": "Zhongfei",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zhongfei Zhang"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 14806188,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "16af90298529b68ba96c968139b2078bec8c3d34",
            "isKey": false,
            "numCitedBy": 49,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "Spatial distribution of color is very important for refining color histograms use din indexing and retrieving color images. Existing histogram refinement techniques are based on the spatial distribution of a single color or color pair. In this paper, the concept of spatial distribution of a subset of colors, which is defined as the occurrence of different geometric configurations of the color set, is used to provide new clues for refining traditional color histogram. The concept is a unification of some existing techniques such as color density maps, color correlogram and color tuples. Experimental results demonstrate that triangular geometric histogram, on e of the simplest special cases of geometric histograms, which is defined as the occurrence of a list of isosceles right triangles of different side lengths of color triples, is more desirable than existing techniques for content-based image retrieval, especially when the database in question consists of on-line color images which are extremely heterogenous in terms of the content of images, camera types, lighting conditions and so on."
            },
            "slug": "Geometric-histogram:-a-distribution-of-geometric-of-Rao-Srihari",
            "title": {
                "fragments": [],
                "text": "Geometric histogram: a distribution of geometric configurations of color subsets"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "Experimental results demonstrate that triangular geometric histogram, one of the simplest special cases of geometric histograms, is more desirable than existing techniques for content-based image retrieval, especially when the database in question consists of on-line color images which are extremely heterogenous in terms of the content of images, camera types, lighting conditions and so on."
            },
            "venue": {
                "fragments": [],
                "text": "Electronic Imaging"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3181308"
                        ],
                        "name": "Qing-Long Zhang",
                        "slug": "Qing-Long-Zhang",
                        "structuredName": {
                            "firstName": "Qing-Long",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Qing-Long Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1679040"
                        ],
                        "name": "Shi-Kuo Chang",
                        "slug": "Shi-Kuo-Chang",
                        "structuredName": {
                            "firstName": "Shi-Kuo",
                            "lastName": "Chang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shi-Kuo Chang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145032830"
                        ],
                        "name": "S. Yau",
                        "slug": "S.-Yau",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Yau",
                            "middleNames": [
                                "S.-T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Yau"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 7666026,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "144b660a725af2c56254fe5a66508819da9980d9",
            "isKey": false,
            "numCitedBy": 15,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract In this paper we propose a unified iconic indexing, the generalized combined 2D string representation, for images in image databases. Each 2D image is modelled as a generalized extended pseudo-symbolic picture, which has the GEP-2D string representation. We present an efficient algorithm to generate the GEP-2D string representation for each 2D image. We also show how to maintain the complete information about the absolute spatial relationships in the image. Our proposed iconic indexing combines both the GEP-2D string representation and the usual 2D string representation to capture absolute and relative spatial relationships in the image. The result is better representation of spatial relationships in image databases. These results extend our earlier work on a large class of 2D scenes, the extended pseudo-symbolic pictures. Picture retrieval by generalized combined 2D strings is discussed. Our approach can also be easily formulated for 3D images."
            },
            "slug": "A-Unified-Approach-to-Iconic-Indexing,-Retrieval,-Zhang-Chang",
            "title": {
                "fragments": [],
                "text": "A Unified Approach to Iconic Indexing, Retrieval, and Maintenance of Spatial Relationships in Image Databases"
            },
            "tldr": {
                "abstractSimilarityScore": 50,
                "text": "This paper presents an efficient algorithm to generate the GEP-2D string representation for each 2D image, and shows how to maintain the complete information about the absolute spatial relationships in the image."
            },
            "venue": {
                "fragments": [],
                "text": "J. Vis. Commun. Image Represent."
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50118130"
                        ],
                        "name": "Ying Wu",
                        "slug": "Ying-Wu",
                        "structuredName": {
                            "firstName": "Ying",
                            "lastName": "Wu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ying Wu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144876831"
                        ],
                        "name": "Q. Tian",
                        "slug": "Q.-Tian",
                        "structuredName": {
                            "firstName": "Qi",
                            "lastName": "Tian",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Q. Tian"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153652752"
                        ],
                        "name": "Thomas S. Huang",
                        "slug": "Thomas-S.-Huang",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Huang",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thomas S. Huang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 3725761,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0743e7624ce2bef071f35cf8605c0d296c95d293",
            "isKey": false,
            "numCitedBy": 194,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "In many vision applications, the practice of supervised learning faces several difficulties, one of which is that insufficient labeled training data result in poor generalization. In image retrieval, we have very few labeled images from query and relevance feedback so that it is hard to automatically weight image features and select similarity metrics for image classification. This paper investigates the possibility of including an unlabeled data set to make up the insufficiency of labeled data. Different from most current research in image retrieval, the proposed approach tries to cast image retrieval as a transductive learning problem, in which the generalization of an image classifier is only defined on a set of images such as the given image database. Formulating this transductive problem in a probabilistic framework the proposed algorithm, Discriminant EM (D-EM) not only estimates the parameters of a generative model but also finds a linear transformation to relax the assumption of probabilistic structure of data distributions as well as select good features automatically. Our experiments show that D-EM has a satisfactory performance in image retrieval applications. D-EM algorithm has the potential to many other applications."
            },
            "slug": "Discriminant-EM-algorithm-with-application-to-image-Wu-Tian",
            "title": {
                "fragments": [],
                "text": "Discriminant-EM algorithm with application to image retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The possibility of including an unlabeled data set to make up the insufficiency of labeled data is investigated and the proposed algorithm, Discriminant EM (D-EM) not only estimates the parameters of a generative model but also finds a linear transformation to relax the assumption of probabilistic structure of data distributions as well as select good features automatically."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings IEEE Conference on Computer Vision and Pattern Recognition. CVPR 2000 (Cat. No.PR00662)"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50591689"
                        ],
                        "name": "B. S. Manjunath",
                        "slug": "B.-S.-Manjunath",
                        "structuredName": {
                            "firstName": "B.",
                            "lastName": "Manjunath",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. S. Manjunath"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712167"
                        ],
                        "name": "Wei-Ying Ma",
                        "slug": "Wei-Ying-Ma",
                        "structuredName": {
                            "firstName": "Wei-Ying",
                            "lastName": "Ma",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wei-Ying Ma"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15171942,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2989b07819dfd279222a3755d3b7862f1a1a7f53",
            "isKey": false,
            "numCitedBy": 4175,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "Image content based retrieval is emerging as an important research area with application to digital libraries and multimedia databases. The focus of this paper is on the image processing aspects and in particular using texture information for browsing and retrieval of large image data. We propose the use of Gabor wavelet features for texture analysis and provide a comprehensive experimental evaluation. Comparisons with other multiresolution texture features using the Brodatz texture database indicate that the Gabor features provide the best pattern retrieval accuracy. An application to browsing large air photos is illustrated."
            },
            "slug": "Texture-Features-for-Browsing-and-Retrieval-of-Data-Manjunath-Ma",
            "title": {
                "fragments": [],
                "text": "Texture Features for Browsing and Retrieval of Image Data"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "Comparisons with other multiresolution texture features using the Brodatz texture database indicate that the Gabor features provide the best pattern retrieval accuracy."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2869141"
                        ],
                        "name": "F. Ennesser",
                        "slug": "F.-Ennesser",
                        "structuredName": {
                            "firstName": "Fran\u00e7ois",
                            "lastName": "Ennesser",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Ennesser"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3463966"
                        ],
                        "name": "G. Medioni",
                        "slug": "G.-Medioni",
                        "structuredName": {
                            "firstName": "G\u00e9rard",
                            "lastName": "Medioni",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Medioni"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 131,
                                "start": 127
                            }
                        ],
                        "text": "Many wavelet transforms are generated by groups of dilations or dilations and rotations that have been said to have some semantic correspondent."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 9688224,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c7cb3b96aba81b123278627d03c1f60eafa0bed0",
            "isKey": false,
            "numCitedBy": 105,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "A method is presented to locate an object in a color image, or more precisely, to select a set of likely locations for the object. The model is assumed to be of known color, which permits the use of color-space processing. A new method is presented, which exploits more information than the previous backprojection algorithm of Swain and Ballard at a competitive complexity. The new algorithm is based on matching local histograms with the model, instead of directly replacing pixels with a confidence that they belong to the object. It is proved that a simple version of this algorithm degenerates into backprojection in the worst case. The authors show how to estimate the scale of the model. The use of co-occurrence histograms is proposed to deal with cases where important color variations can be expected.<<ETX>>"
            },
            "slug": "Finding-Waldo,-or-focus-of-attention-using-local-Ennesser-Medioni",
            "title": {
                "fragments": [],
                "text": "Finding Waldo, or focus of attention using local color information"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "A new method is presented, which exploits more information than the previous backprojection algorithm of Swain and Ballard at a competitive complexity, based on matching local histograms with the model, instead of directly replacing pixels with a confidence that they belong to the object."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1795727"
                        ],
                        "name": "Lance M. Kaplan",
                        "slug": "Lance-M.-Kaplan",
                        "structuredName": {
                            "firstName": "Lance",
                            "lastName": "Kaplan",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lance M. Kaplan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2912757"
                        ],
                        "name": "R. Murenzi",
                        "slug": "R.-Murenzi",
                        "structuredName": {
                            "firstName": "Romain",
                            "lastName": "Murenzi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Murenzi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1697423"
                        ],
                        "name": "K. Namuduri",
                        "slug": "K.-Namuduri",
                        "structuredName": {
                            "firstName": "Kamesh",
                            "lastName": "Namuduri",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Namuduri"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 34701111,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "94ce07f7838452c04c9093a69d2b7a1e80bcb00f",
            "isKey": false,
            "numCitedBy": 93,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": "The increase in the number of multimedia databases consisting of images has created a need for a quick method to search these databases for a particular type of image. An image retrieval system will output images from the database similar to the query image in terms of shape, color, and texture. For the scope of our work, we study the performance of multiscale Hurst parameters as texture features for database image retrieval over a database consisting of homogeneous textures. These extended Hurst features represent a generalization of the Hurst parameter for fractional Brownian motion (fBm) where the extended parameters quantize the texture roughness of an image at various scales. We compare the retrieval performance of the extended parameters against traditional Hurst features and features obtained from the Gabor wavelet. Gabor wavelets have previously been suggested for image retrieval applications because they can be tuned to obtain texture information for a number of different scales and orientations. In our experiments, we form a database combining textures from the Bonn, Brodatz, and MIT VisTex databases. Over the hybrid database, the extended fractal features were able to retrieve a higher percentage of similar textures than the Gabor features. Furthermore, the fractal features are faster to compute than the Gabor features."
            },
            "slug": "Fast-texture-database-retrieval-using-extended-Kaplan-Murenzi",
            "title": {
                "fragments": [],
                "text": "Fast texture database retrieval using extended fractal features"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This work studies the performance of multiscale Hurst parameters as texture features for database image retrieval over a database consisting of homogeneous textures and compares the retrieval performance of the extended parameters against traditional Hurst features and features obtained from the Gabor wavelet."
            },
            "venue": {
                "fragments": [],
                "text": "Electronic Imaging"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3260570"
                        ],
                        "name": "Virginia E. Ogle",
                        "slug": "Virginia-E.-Ogle",
                        "structuredName": {
                            "firstName": "Virginia",
                            "lastName": "Ogle",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Virginia E. Ogle"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145345023"
                        ],
                        "name": "M. Stonebraker",
                        "slug": "M.-Stonebraker",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Stonebraker",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Stonebraker"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 11195120,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c17ee327e563536f8adaf214eb6d3bde33b73dd6",
            "isKey": false,
            "numCitedBy": 818,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "Selecting from a large, expanding collection of images requires carefully chosen search criteria. We present an approach that integrates a relational database retrieval system with a color analysis technique. The Chabot project was initiated at our university to study storage and retrieval of a vast collection of digitized images. These images are from the State of California Department of Water Resources. The goal was to integrate a relational database retrieval system with content analysis techniques that would give our querying system a better method for handling images. Our simple color analysis method, if used in conjunction with other search criteria, improves our ability to retrieve images efficiently. The best result is obtained when text-based search criteria are combined with content-based criteria and when a coarse granularity is used for content analysis. >"
            },
            "slug": "Chabot:-Retrieval-from-a-Relational-Database-of-Ogle-Stonebraker",
            "title": {
                "fragments": [],
                "text": "Chabot: Retrieval from a Relational Database of Images"
            },
            "tldr": {
                "abstractSimilarityScore": 56,
                "text": "This work presents an approach that integrates a relational database retrieval system with a color analysis technique, and shows how a coarse granularity is used for content analysis improves the ability to retrieve images efficiently."
            },
            "venue": {
                "fragments": [],
                "text": "Computer"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2462253"
                        ],
                        "name": "C. Schmid",
                        "slug": "C.-Schmid",
                        "structuredName": {
                            "firstName": "Cordelia",
                            "lastName": "Schmid",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Schmid"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145299933"
                        ],
                        "name": "R. Mohr",
                        "slug": "R.-Mohr",
                        "structuredName": {
                            "firstName": "Roger",
                            "lastName": "Mohr",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Mohr"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 325871,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "49fcd806450d947e56c82ef2b438ad9c484069dc",
            "isKey": false,
            "numCitedBy": 1792,
            "numCiting": 61,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper addresses the problem of retrieving images from large image databases. The method is based on local grayvalue invariants which are computed at automatically detected interest points. A voting algorithm and semilocal constraints make retrieval possible. Indexing allows for efficient retrieval from a database of more than 1,000 images. Experimental results show correct retrieval in the case of partial visibility, similarity transformations, extraneous features, and small perspective deformations."
            },
            "slug": "Local-Grayvalue-Invariants-for-Image-Retrieval-Schmid-Mohr",
            "title": {
                "fragments": [],
                "text": "Local Grayvalue Invariants for Image Retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 82,
                "text": "This paper addresses the problem of retrieving images from large image databases with a method based on local grayvalue invariants which are computed at automatically detected interest points and allows for efficient retrieval from a database of more than 1,000 images."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31841558"
                        ],
                        "name": "G. Pass",
                        "slug": "G.-Pass",
                        "structuredName": {
                            "firstName": "Greg",
                            "lastName": "Pass",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Pass"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2984143"
                        ],
                        "name": "R. Zabih",
                        "slug": "R.-Zabih",
                        "structuredName": {
                            "firstName": "Ramin",
                            "lastName": "Zabih",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Zabih"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9023078,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "27249e97daeebf374b41d5a01fd65c7b7f148f8d",
            "isKey": false,
            "numCitedBy": 263,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract. Color histograms are widely used for content-based image retrieval due to their efficiency and robustness. However, a color histogram only records an image's overall color composition, so images with very different appearances can have similar color histograms. This problem is especially critical in large image databases, where many images have similar color histograms. In this paper, we propose an alternative to color histograms called a joint histogram, which incorporates additional information without sacrificing the robustness of color histograms. We create a joint histogram by selecting a set of local pixel features and constructing a multidimensional histogram. Each entry in a joint histogram contains the number of pixels in the image that are described by a particular combination of feature values. We describe a number of different joint histograms, and evaluate their performance for image retrieval on a database with over 210,000 images. On our benchmarks, joint histograms outperform color histograms by an order of magnitude."
            },
            "slug": "Comparing-images-using-joint-histograms-Pass-Zabih",
            "title": {
                "fragments": [],
                "text": "Comparing images using joint histograms"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This paper creates a joint histogram by selecting a set of local pixel features and constructing a multidimensional histogram, which incorporates additional information without sacrificing the robustness of color histograms."
            },
            "venue": {
                "fragments": [],
                "text": "Multimedia Systems"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2853573"
                        ],
                        "name": "D. Sharvit",
                        "slug": "D.-Sharvit",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Sharvit",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Sharvit"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2113351148"
                        ],
                        "name": "J. Chan",
                        "slug": "J.-Chan",
                        "structuredName": {
                            "firstName": "Jacky",
                            "lastName": "Chan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Chan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144846057"
                        ],
                        "name": "H. Tek",
                        "slug": "H.-Tek",
                        "structuredName": {
                            "firstName": "H\u00fcseyin",
                            "lastName": "Tek",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Tek"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1715265"
                        ],
                        "name": "B. Kimia",
                        "slug": "B.-Kimia",
                        "structuredName": {
                            "firstName": "Benjamin",
                            "lastName": "Kimia",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Kimia"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 18113743,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bdfb0d5e7840fcb7d096c67465f1405c4e82d2d4",
            "isKey": false,
            "numCitedBy": 313,
            "numCiting": 62,
            "paperAbstract": {
                "fragments": [],
                "text": "The use of shape as a cue for indexing in pictorial databases has been traditionally based on global invariant statistics and deformable templates, on the one hand, and local edge correlation on the other. This paper proposes an intermediate approach based on a characterization of the symmetry in edge maps. The use of symmetry matching as a joint correlation measure between pairs of edge elements further constrains the comparison of edge maps. In addition, a natural organization of groups of symmetry into a hierarchy leads to a graph-based representation of relational structure of components of shape that allows for deformations by changing attributes of this relational graph. A graduate assignment graph matching algorithm is used to match symmetry structure in images to stored prototypes or sketches. The results of matching sketches and grey-scale images against a small database consisting of a variety of fish, planes, tools, etc., are depicted."
            },
            "slug": "Symmetry-based-indexing-of-image-databases-Sharvit-Chan",
            "title": {
                "fragments": [],
                "text": "Symmetry-Based Indexing of Image Databases"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "An intermediate approach based on a characterization of the symmetry in edge maps is proposed, which leads to a graph-based representation of relational structure of components of shape that allows for deformations by changing attributes of this relational graph."
            },
            "venue": {
                "fragments": [],
                "text": "J. Vis. Commun. Image Represent."
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144154559"
                        ],
                        "name": "C. Shyu",
                        "slug": "C.-Shyu",
                        "structuredName": {
                            "firstName": "C.",
                            "lastName": "Shyu",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Shyu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1729374"
                        ],
                        "name": "C. Brodley",
                        "slug": "C.-Brodley",
                        "structuredName": {
                            "firstName": "Carla",
                            "lastName": "Brodley",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Brodley"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1703247"
                        ],
                        "name": "A. Kak",
                        "slug": "A.-Kak",
                        "structuredName": {
                            "firstName": "Avinash",
                            "lastName": "Kak",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Kak"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "14037223"
                        ],
                        "name": "A. Kosaka",
                        "slug": "A.-Kosaka",
                        "structuredName": {
                            "firstName": "Akio",
                            "lastName": "Kosaka",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Kosaka"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2910630"
                        ],
                        "name": "A. Aisen",
                        "slug": "A.-Aisen",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Aisen",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Aisen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34560543"
                        ],
                        "name": "L. S. Broderick",
                        "slug": "L.-S.-Broderick",
                        "structuredName": {
                            "firstName": "Lynn",
                            "lastName": "Broderick",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. S. Broderick"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 10310350,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6157f52af50a826d6cf62e636efb0f3c7f982160",
            "isKey": false,
            "numCitedBy": 410,
            "numCiting": 43,
            "paperAbstract": {
                "fragments": [],
                "text": "It is now recognized in many domains that content-based image retrieval from a database of images cannot be carried out by using completely automated approaches. One such domain is medical radiology for which the clinically useful information in an image typically consists of gray level variations in highly localized regions of the image. Currently, it is not possible to extract these regions by automatic image segmentation techniques. To address this problem, we have implemented a human-in-the-loop (a physician-in-the-loop, more specifically) approach in which the human delineates the pathology bearing regions (PBR) and a set of anatomical landmarks in the image when the image is entered into the database. To the regions thus marked, our approach applies low-level computer vision and image processing algorithms to extract attributes related to the variations in gray scale, texture, shape, etc. In addition, the system records attributes that capture relational information such as the position of a PBR with respect to certain anatomical landmarks. An overall multidimensional index is assigned to each image based on these attribute values."
            },
            "slug": "ASSERT:-A-Physician-in-the-Loop-Content-Based-for-Shyu-Brodley",
            "title": {
                "fragments": [],
                "text": "ASSERT: A Physician-in-the-Loop Content-Based Retrieval System for HRCT Image Databases"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "A human-in-the-loop approach in which the human delineates the pathology bearing regions (PBR) and a set of anatomical landmarks in the image when the image is entered into the database is implemented."
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Vis. Image Underst."
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1749590"
                        ],
                        "name": "S. Sclaroff",
                        "slug": "S.-Sclaroff",
                        "structuredName": {
                            "firstName": "Stan",
                            "lastName": "Sclaroff",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Sclaroff"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2588636"
                        ],
                        "name": "L. Taycher",
                        "slug": "L.-Taycher",
                        "structuredName": {
                            "firstName": "Leonid",
                            "lastName": "Taycher",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Taycher"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "114316817"
                        ],
                        "name": "M. La Cascia",
                        "slug": "M.-La-Cascia",
                        "structuredName": {
                            "firstName": "Marco",
                            "lastName": "La Cascia",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. La Cascia"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 390026,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "454ed50b0f42225c6c2be3fb5e22bc1c775a109f",
            "isKey": false,
            "numCitedBy": 380,
            "numCiting": 42,
            "paperAbstract": {
                "fragments": [],
                "text": "ImageRover is a search-by-image-content navigation tool for the World Wide Web (WWW). To gather images expediently, the image collection subsystem utilizes a distributed fleet of WWW robots running on different computers. The image robots gather information about the images they find, computing the appropriate image decompositions and indices, and store this extracted information in vector form for searches based on image content. At search time, users can iteratively guide the search through the selection of relevant examples. Search performance is made efficient through the use of an approximate, optimized k-d tree algorithm. The system employs a novel relevance feedback algorithm that selects the distance metrics that are appropriate for a particular query"
            },
            "slug": "ImageRover:-a-content-based-image-browser-for-the-Sclaroff-Taycher",
            "title": {
                "fragments": [],
                "text": "ImageRover: a content-based image browser for the World Wide Web"
            },
            "tldr": {
                "abstractSimilarityScore": 60,
                "text": "ImageRover is a search-by-image-content navigation tool for the World Wide Web that utilizes a distributed fleet of WWW robots to gather images expediently and employs a novel relevance feedback algorithm that selects the distance metrics that are appropriate for a particular query."
            },
            "venue": {
                "fragments": [],
                "text": "1997 Proceedings IEEE Workshop on Content-Based Access of Image and Video Libraries"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2209714"
                        ],
                        "name": "Linhui Jia",
                        "slug": "Linhui-Jia",
                        "structuredName": {
                            "firstName": "Linhui",
                            "lastName": "Jia",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Linhui Jia"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35793629"
                        ],
                        "name": "L. Kitchen",
                        "slug": "L.-Kitchen",
                        "structuredName": {
                            "firstName": "Leslie",
                            "lastName": "Kitchen",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Kitchen"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 20684019,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1bcadf7a903a58ec379e839ffefdfa531a341a85",
            "isKey": false,
            "numCitedBy": 34,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes an efficient and effective image similarity calculation method for object-based image comparison at the level of object classes. It uses probabilistic-prediction voting based on the predicted class distribution of each segment of the contour of an object in an image to determine the class of the object. The C4.5 inductive learning algorithm is used to predict the class distribution of object-contour segments. This method is invariant to rotation, scaling and translation of objects. Experimental results show that the method is effective and efficient. It can be used for object-based image retrieval."
            },
            "slug": "Object-based-image-similarity-computation-using-of-Jia-Kitchen",
            "title": {
                "fragments": [],
                "text": "Object-based image similarity computation using inductive learning of contour-segment relations"
            },
            "tldr": {
                "abstractSimilarityScore": 93,
                "text": "An efficient and effective image similarity calculation method for object-based image comparison at the level of object classes that uses probabilistic-prediction voting based on the predicted class distribution of each segment of the contour of an object in an image to determine the class of the object."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Image Process."
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2838104"
                        ],
                        "name": "T. Papathomas",
                        "slug": "T.-Papathomas",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Papathomas",
                            "middleNames": [
                                "V."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Papathomas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1927222"
                        ],
                        "name": "Tiffany E. Conway",
                        "slug": "Tiffany-E.-Conway",
                        "structuredName": {
                            "firstName": "Tiffany",
                            "lastName": "Conway",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tiffany E. Conway"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716933"
                        ],
                        "name": "I. Cox",
                        "slug": "I.-Cox",
                        "structuredName": {
                            "firstName": "Ingemar",
                            "lastName": "Cox",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Cox"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2864754"
                        ],
                        "name": "J. Ghosn",
                        "slug": "J.-Ghosn",
                        "structuredName": {
                            "firstName": "Joumana",
                            "lastName": "Ghosn",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Ghosn"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1692121"
                        ],
                        "name": "Matthew L. Miller",
                        "slug": "Matthew-L.-Miller",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Miller",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Matthew L. Miller"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "52626911"
                        ],
                        "name": "T. Minka",
                        "slug": "T.-Minka",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Minka",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Minka"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3203897"
                        ],
                        "name": "P. Yianilos",
                        "slug": "P.-Yianilos",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Yianilos",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Yianilos"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 17393414,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "4ba1a102ff84385c8e3ed02cfdc4aea041131a22",
            "isKey": false,
            "numCitedBy": 40,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe psychophysical experiments conducted to study PicHunter, a content-based image retrieval (CBIR) system. Experiment 1 studies the importance of using (a) semantic information, (2) memory of earlier input and (3) relative, rather than absolute, judgements of image similarity. The target testing paradigm is used in which a user must search for an image identical to a target. We find that the best performance comes from a version of PicHunter that uses only semantic cues, with memory and relative similarity judgements. Second best is use of both pictorial and semantic cues, with memory and relative similarity judgements. Most reports of CBIR systems provide only qualitative measures of performance based on how similar retrieved images are to a target. Experiment 2 puts PicHunter into this context with a more rigorous test. We first establish a baseline for our database by measuring the time required to find an image that is similar to a target when the images are presented in random order. Although PicHunter's performance is measurably better than this, the test is weak because even random presentation of images yields reasonably short search times. This casts doubt on the strength of results given in other reports where no baseline is established."
            },
            "slug": "Psychophysical-studies-of-the-performance-of-an-Papathomas-Conway",
            "title": {
                "fragments": [],
                "text": "Psychophysical studies of the performance of an image database retrieval system"
            },
            "tldr": {
                "abstractSimilarityScore": 67,
                "text": "Psychophysical experiments conducted to study PicHunter, a content-based image retrieval (CBIR) system, find that the best performance comes from a version of PicHunter that uses only semantic cues, with memory and relative similarity judgements."
            },
            "venue": {
                "fragments": [],
                "text": "Electronic Imaging"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2110604335"
                        ],
                        "name": "Markus Weber",
                        "slug": "Markus-Weber",
                        "structuredName": {
                            "firstName": "Markus",
                            "lastName": "Weber",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Markus Weber"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1678311"
                        ],
                        "name": "M. Welling",
                        "slug": "M.-Welling",
                        "structuredName": {
                            "firstName": "Max",
                            "lastName": "Welling",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Welling"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1690922"
                        ],
                        "name": "P. Perona",
                        "slug": "P.-Perona",
                        "structuredName": {
                            "firstName": "Pietro",
                            "lastName": "Perona",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Perona"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1061324,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "472ff211d18aa2ca2b65b69d86499430ad287499",
            "isKey": false,
            "numCitedBy": 289,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a method to learn heterogeneous models of object classes for visual recognition. The training images contain a preponderance of clutter and learning is unsupervised. Our models represent objects as probabilistic constellations of rigid parts (features). The variability within a class is represented by a join probability density function on the shape of the constellation and the appearance of the parts. Our method automatically identifies distinctive features in the training set. The set of model parameters is then learned using expectation maximization. When trained on different, unlabeled and unsegmented views of a class of objects, each component of the mixture model can adapt to represent a subset of the views. Similarly, different component models can also \"specialize\" on sub-classes of an object class. Experiments on images of human heads, leaves from different species of trees, and motor-cars demonstrate that the method works well over a wide variety of objects."
            },
            "slug": "Towards-automatic-discovery-of-object-categories-Weber-Welling",
            "title": {
                "fragments": [],
                "text": "Towards automatic discovery of object categories"
            },
            "tldr": {
                "abstractSimilarityScore": 65,
                "text": "A method to learn heterogeneous models of object classes for visual recognition that automatically identifies distinctive features in the training set and learns the set of model parameters using expectation maximization."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings IEEE Conference on Computer Vision and Pattern Recognition. CVPR 2000 (Cat. No.PR00662)"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2055718517"
                        ],
                        "name": "J. Cullen",
                        "slug": "J.-Cullen",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Cullen",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Cullen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694191"
                        ],
                        "name": "J. Hull",
                        "slug": "J.-Hull",
                        "structuredName": {
                            "firstName": "Jonathan",
                            "lastName": "Hull",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Hull"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3108177"
                        ],
                        "name": "P. Hart",
                        "slug": "P.-Hart",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Hart",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Hart"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 11847492,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bf35ae1a26238e104fd8e4bffa4b26dc350228f1",
            "isKey": false,
            "numCitedBy": 55,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "A system is presented that uses texture to retrieve and browse images stored in a large document image database. A method of graphically generating a candidate search image is used that shows the visual layout and content of a target document. All images similar to this candidate are returned for the purpose of browsing or further query. The system is accessed using a World Wide Web (Web) browser. Applications include the retrieval and browsing of document images including newspapers, fares and business letters."
            },
            "slug": "Document-image-database-retrieval-and-browsing-Cullen-Hull",
            "title": {
                "fragments": [],
                "text": "Document image database retrieval and browsing using texture analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 70,
                "text": "A system is presented that uses texture to retrieve and browse images stored in a large document image database for the retrieval and browsing of document images including newspapers, fares and business letters."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Fourth International Conference on Document Analysis and Recognition"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716933"
                        ],
                        "name": "I. Cox",
                        "slug": "I.-Cox",
                        "structuredName": {
                            "firstName": "Ingemar",
                            "lastName": "Cox",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Cox"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1692121"
                        ],
                        "name": "Matthew L. Miller",
                        "slug": "Matthew-L.-Miller",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Miller",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Matthew L. Miller"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "52626911"
                        ],
                        "name": "T. Minka",
                        "slug": "T.-Minka",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Minka",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Minka"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2838104"
                        ],
                        "name": "T. Papathomas",
                        "slug": "T.-Papathomas",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Papathomas",
                            "middleNames": [
                                "V."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Papathomas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3203897"
                        ],
                        "name": "P. Yianilos",
                        "slug": "P.-Yianilos",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Yianilos",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Yianilos"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 550483,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a60d352b1477fb9cd650510e3185104d82596221",
            "isKey": false,
            "numCitedBy": 809,
            "numCiting": 89,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents the theory, design principles, implementation and performance results of PicHunter, a prototype content-based image retrieval (CBIR) system. In addition, this document presents the rationale, design and results of psychophysical experiments that were conducted to address some key issues that arose during PicHunter's development. The PicHunter project makes four primary contributions to research on CBIR. First, PicHunter represents a simple instance of a general Bayesian framework which we describe for using relevance feedback to direct a search. With an explicit model of what users would do, given the target image they want, PicHunter uses Bayes's rule to predict the target they want, given their actions. This is done via a probability distribution over possible image targets, rather than by refining a query. Second, an entropy-minimizing display algorithm is described that attempts to maximize the information obtained from a user at each iteration of the search. Third, PicHunter makes use of hidden annotation rather than a possibly inaccurate/inconsistent annotation structure that the user must learn and make queries in. Finally, PicHunter introduces two experimental paradigms to quantitatively evaluate the performance of the system, and psychophysical experiments are presented that support the theoretical claims."
            },
            "slug": "The-Bayesian-image-retrieval-system,-PicHunter:-and-Cox-Miller",
            "title": {
                "fragments": [],
                "text": "The Bayesian image retrieval system, PicHunter: theory, implementation, and psychophysical experiments"
            },
            "tldr": {
                "abstractSimilarityScore": 63,
                "text": "The theory, design principles, implementation and performance results of PicHunter are presented, two experimental paradigms to quantitatively evaluate the performance of the system are introduced, and psychophysical experiments are presented that support the theoretical claims."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Image Process."
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47088868"
                        ],
                        "name": "Joshua R. Smith",
                        "slug": "Joshua-R.-Smith",
                        "structuredName": {
                            "firstName": "Joshua",
                            "lastName": "Smith",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Joshua R. Smith"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9546964"
                        ],
                        "name": "Shih-Fu Chang",
                        "slug": "Shih-Fu-Chang",
                        "structuredName": {
                            "firstName": "Shih-Fu",
                            "lastName": "Chang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shih-Fu Chang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 11444786,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "067e9d528b4d9f56a2fd8324cee6389e5e138295",
            "isKey": false,
            "numCitedBy": 269,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "Digital image and video libraries require new algorithms for the automated extraction and indexing of salient image features. Texture features provide one important cue for the visual perception and discrimination of image content. We propose a new approach for automated content extraction that allows for efficient database searching using texture features. The algorithm automatically extracts texture regions from image spatial-frequency data which are represented by binary texture feature vectors. We demonstrate that the binary texture features provide excellent performance in image query response time while providing highly effective texture discriminability, accuracy in spatial localization and capability for extraction from compressed data representations. We present the binary texture feature extraction and indexing technique and examine searching by texture on a database of 500 images."
            },
            "slug": "Automated-binary-texture-feature-sets-for-image-Smith-Chang",
            "title": {
                "fragments": [],
                "text": "Automated binary texture feature sets for image retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "It is demonstrated that the binary texture features provide excellent performance in image query response time while providing highly effective texture discriminability, accuracy in spatial localization and capability for extraction from compressed data representations."
            },
            "venue": {
                "fragments": [],
                "text": "1996 IEEE International Conference on Acoustics, Speech, and Signal Processing Conference Proceedings"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1764131"
                        ],
                        "name": "R. Mehrotra",
                        "slug": "R.-Mehrotra",
                        "structuredName": {
                            "firstName": "Rajiv",
                            "lastName": "Mehrotra",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Mehrotra"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50476996"
                        ],
                        "name": "James E. Gary",
                        "slug": "James-E.-Gary",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Gary",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "James E. Gary"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 42769186,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3ef7073a8db6dd706e432785564393871f38353e",
            "isKey": false,
            "numCitedBy": 348,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "Addresses the problem of similar-shape retrieval, where shapes or images in a shape database that satisfy specified shape-similarity constraints with respect to the query shape or image must be retrieved from the database. In its simplest form, the similar-shape retrieval problem can be stated as, \"retrieve or select all shapes or images that are visually similar to the query shape or the query image's shape\". We focus on databases of 2D shapes-or equivalently, databases of images of flat or almost flat objects. (We use the terms \"object\" and \"shape\" interchangeably). Two common types of 2D objects are rigid objects, which have a single rigid component called a link, and articulated objects, which have two or more rigid components joined by movable (rotating or sliding) joints. An ideal similar-shape retrieval technique must be general enough to handle images of articulated as well as rigid objects. It must be flexible enough to handle simple query images, which have isolated shapes, and complex query images, which have partially visible, overlapping or touching objects. We discuss the central issues in similar-shape retrieval and explain how these issues are resolved in a shape retrieval scheme called FIBSSR (Feature Index-Based Similar-Shape Retrieval). This new similar-shape retrieval system effectively models real-world applications. >"
            },
            "slug": "Similar-Shape-Retrieval-in-Shape-Data-Management-Mehrotra-Gary",
            "title": {
                "fragments": [],
                "text": "Similar-Shape Retrieval in Shape Data Management"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "This work discusses the central issues in similar-shape retrieval and explains how these issues are resolved in a shape retrieval scheme called FIBSSR (Feature Index-Based Similar-Shape Retrieval)."
            },
            "venue": {
                "fragments": [],
                "text": "Computer"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1398595158"
                        ],
                        "name": "R. Rodr\u00edguez-S\u00e1nchez",
                        "slug": "R.-Rodr\u00edguez-S\u00e1nchez",
                        "structuredName": {
                            "firstName": "Rosa",
                            "lastName": "Rodr\u00edguez-S\u00e1nchez",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Rodr\u00edguez-S\u00e1nchez"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153399482"
                        ],
                        "name": "Jos\u00e9 A. Garc\u00eda",
                        "slug": "Jos\u00e9-A.-Garc\u00eda",
                        "structuredName": {
                            "firstName": "Jos\u00e9",
                            "lastName": "Garc\u00eda",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jos\u00e9 A. Garc\u00eda"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "89524080"
                        ],
                        "name": "J. Fern\u00e1ndez-Valdivia",
                        "slug": "J.-Fern\u00e1ndez-Valdivia",
                        "structuredName": {
                            "firstName": "Joaqu\u00edn",
                            "lastName": "Fern\u00e1ndez-Valdivia",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Fern\u00e1ndez-Valdivia"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1398290502"
                        ],
                        "name": "Xos\u00e9 R. Fern\u00e1ndez-Vidal",
                        "slug": "Xos\u00e9-R.-Fern\u00e1ndez-Vidal",
                        "structuredName": {
                            "firstName": "Xos\u00e9",
                            "lastName": "Fern\u00e1ndez-Vidal",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xos\u00e9 R. Fern\u00e1ndez-Vidal"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 11188597,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d973952eeb852a15cc5738ef396b1cc384390f04",
            "isKey": false,
            "numCitedBy": 43,
            "numCiting": 66,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes a system for the automatically learned partitioning of visual patterns in 2D images, based on sophisticated band-pass filtering with fixed scale and orientation sensitivity. The visual patterns are defined as the features which have the highest degree of alignment in the statistical structure across different frequency bands. The analysis reorganizes the image according to an invariance constraint in statistical structure and consists of three stages: pre-attentive stage, integration stage, and learning stage. The first stage takes the input image and performs filtering with log-Gabor filters. Based on their responses, activated filters which are selectively sensitive to patterns in the image are short listed. In the integration stage, common grounds between several activated sensors are explored. The filtered responses are analyzed through a family of statistics. For any given two activated filters, a distance between them is derived via distances between their statistics. The third stage performs cluster partitioning for learning the subspace of log-Gabor filters needed to partition the image data. The clustering is based on a dissimilarity measure intended to highlight scale and orientation invariance of the responses. The technique is illustrated on real and simulated data sets. Finally, this paper presents a computational visual distinctness measure computed from the image representational model based on visual patterns. Experiments are performed to investigate its relation to distinctness as measured by human observers."
            },
            "slug": "The-RGFF-Representational-Model:-A-System-for-the-Rodr\u00edguez-S\u00e1nchez-Garc\u00eda",
            "title": {
                "fragments": [],
                "text": "The RGFF Representational Model: A System for the Automatically Learned Partitioning of 'Visual Patterns' in Digital Images"
            },
            "tldr": {
                "abstractSimilarityScore": 50,
                "text": "A computational visual distinctness measure computed from the image representational model based on visual patterns is presented, based on a dissimilarity measure intended to highlight scale and orientation invariance of the responses."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2687076"
                        ],
                        "name": "A. Hiroike",
                        "slug": "A.-Hiroike",
                        "structuredName": {
                            "firstName": "Atsushi",
                            "lastName": "Hiroike",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Hiroike"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38247623"
                        ],
                        "name": "Y. Musha",
                        "slug": "Y.-Musha",
                        "structuredName": {
                            "firstName": "Yoshinori",
                            "lastName": "Musha",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Musha"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143993575"
                        ],
                        "name": "A. Sugimoto",
                        "slug": "A.-Sugimoto",
                        "structuredName": {
                            "firstName": "Akihiro",
                            "lastName": "Sugimoto",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Sugimoto"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2333082"
                        ],
                        "name": "Y. Mori",
                        "slug": "Y.-Mori",
                        "structuredName": {
                            "firstName": "Yasuhide",
                            "lastName": "Mori",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Mori"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 31319373,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "30e33e5b7dff88002fd221c66278c5b29291fd11",
            "isKey": false,
            "numCitedBy": 37,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "We have developed a user interface for similarity-based image retrieval, where the distribution of retrieved data in a high-dimensional feature space is represented as a dynamical scatter diagram of thumbnail images in a 3-dimensional visualization space and similarities between data are represented as sizes in the 3-dimensional space. Coordinate systems in the visualization space are obtained by statistical calculations on the distribution of feature vectors of retrieved images. Our system provides some different transformations from a high-dimensional feature space to a 3-dimensional space that give different coordinate systems to the visualization space. By changing the coordinates automatically at some intervals, a spatial-temporal pattern of the distribution of images is generated. Furthermore a hierarchical coordinate system that consists of some local coordinate systems based on key images can be defined in the visualization space. These methods can represent a large number of retrieved results in a way that users can grasp intuitively."
            },
            "slug": "Visualization-of-Information-Spaces-to-Retrieve-and-Hiroike-Musha",
            "title": {
                "fragments": [],
                "text": "Visualization of Information Spaces to Retrieve and Browse Image Data"
            },
            "tldr": {
                "abstractSimilarityScore": 94,
                "text": "A user interface for similarity-based image retrieval, where the distribution of retrieved data in a high-dimensional feature space is represented as a dynamical scatter diagram of thumbnail images in a 3-dimensional visualization space and similarities between data are represented as sizes in the3-dimensional space."
            },
            "venue": {
                "fragments": [],
                "text": "VISUAL"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2277853"
                        ],
                        "name": "A. Vailaya",
                        "slug": "A.-Vailaya",
                        "structuredName": {
                            "firstName": "Aditya",
                            "lastName": "Vailaya",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Vailaya"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34659351"
                        ],
                        "name": "M\u00e1rio A. T. Figueiredo",
                        "slug": "M\u00e1rio-A.-T.-Figueiredo",
                        "structuredName": {
                            "firstName": "M\u00e1rio",
                            "lastName": "Figueiredo",
                            "middleNames": [
                                "A.",
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M\u00e1rio A. T. Figueiredo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145295484"
                        ],
                        "name": "Anil K. Jain",
                        "slug": "Anil-K.-Jain",
                        "structuredName": {
                            "firstName": "Anil",
                            "lastName": "Jain",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Anil K. Jain"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108698841"
                        ],
                        "name": "HongJiang Zhang",
                        "slug": "HongJiang-Zhang",
                        "structuredName": {
                            "firstName": "HongJiang",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "HongJiang Zhang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8262367,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d01805e377a90563292322cdce31828ccde40ba5",
            "isKey": false,
            "numCitedBy": 189,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": "Grouping images into (semantically) meaningful categories using low level visual features is a challenging and important problem in content based image retrieval. Using binary Bayesian classifiers, we attempt to capture high level concepts from low level image features under the constraint that the test image does belong to one of the classes of interest. Specifically, we consider the hierarchical classification of vacation images; at the highest level, images are classified into indoor/outdoor classes, outdoor images are further classified into city/landscape classes, and finally, a subset of landscape images is classified into sunset, forest, and mountain classes. We demonstrate that a small codebook (the optimal size of codebook is selected using a modified MDL criterion) extracted from a vector quantizer can be used to estimate the class-conditional densities of the observed features needed for the Bayesian methodology. On a database of 6931 vacation photographs, our system achieved an accuracy of 90.5% for indoor vs. outdoor classification, 95.3% for city vs. landscape classification, 96.6% for sunset vs. forest and mountain classification, and 95.5% for forest vs. mountain classification. We further develop a learning paradigm to incrementally train the classifiers as additional training samples become available and also show preliminary results for feature size reduction using clustering techniques."
            },
            "slug": "Content-based-hierarchical-classification-of-images-Vailaya-Figueiredo",
            "title": {
                "fragments": [],
                "text": "Content-based hierarchical classification of vacation images"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A learning paradigm to incrementally train the classifiers as additional training samples become available is developed and preliminary results for feature size reduction using clustering techniques are shown."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings IEEE International Conference on Multimedia Computing and Systems"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49326902"
                        ],
                        "name": "D. Slater",
                        "slug": "D.-Slater",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Slater",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Slater"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144644545"
                        ],
                        "name": "G. Healey",
                        "slug": "G.-Healey",
                        "structuredName": {
                            "firstName": "Glenn",
                            "lastName": "Healey",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Healey"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 51,
                                "start": 46
                            }
                        ],
                        "text": "The model has been used in image retrieval in [158], while keeping access to their location in the image by back-projection [169]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 32,
                                "start": 27
                            }
                        ],
                        "text": "The scheme was improved in [158] by using algebraic invariants."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 38875737,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8ccc8ab68720396b6646e649d6d1d12ebcce9a7a",
            "isKey": false,
            "numCitedBy": 137,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "Traditional approaches to three dimensional object recognition exploit the relationship between three dimensional object geometry and two dimensional image geometry. The capability of object recognition systems can be improved by also incorporating information about the color of object surfaces. Using physical models for image formation, the authors derive invariants of local color pixel distributions that are independent of viewpoint and the configuration, intensity, and spectral content of the scene illumination. These invariants capture information about the distribution of spectral reflectance which is intrinsic to a surface and thereby provide substantial discriminatory power for identifying a wide range of surfaces including many textured surfaces. These invariants can be computed efficiently from color image regions without requiring any form of segmentation. The authors have implemented an object recognition system that indexes into a database of models using the invariants and that uses associated geometric information for hypothesis verification and pose estimation. The approach to recognition is based on the computation of local invariants and is therefore relatively insensitive to occlusion. The authors present several examples demonstrating the system's ability to recognize model objects in cluttered scenes independent of object configuration and scene illumination. The discriminatory power of the invariants has been demonstrated by the system's ability to process a large set of regions over complex scenes without generating false hypotheses."
            },
            "slug": "The-Illumination-Invariant-Recognition-of-3D-Using-Slater-Healey",
            "title": {
                "fragments": [],
                "text": "The Illumination-Invariant Recognition of 3D Objects Using Local Color Invariants"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "An object recognition system is implemented that indexes into a database of models using the invariants and that uses associated geometric information for hypothesis verification and pose estimation, and is therefore relatively insensitive to occlusion."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3266794"
                        ],
                        "name": "E. Pauwels",
                        "slug": "E.-Pauwels",
                        "structuredName": {
                            "firstName": "Eric",
                            "lastName": "Pauwels",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Pauwels"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1932191"
                        ],
                        "name": "Greet Frederix",
                        "slug": "Greet-Frederix",
                        "structuredName": {
                            "firstName": "Greet",
                            "lastName": "Frederix",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Greet Frederix"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 15627823,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "408528be868eb95878dbe1f9c9f52a216d5d240b",
            "isKey": false,
            "numCitedBy": 149,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "A major problem in content-based image retrieval (CBIR) is the unsupervised identification of perceptually salient regions in images. We contend that this problem can be tackled by mapping the pixels into various feature-spaces, whereupon they are subjected to a grouping algorithm. In this paper we develop a robust and versatile nonparametric clustering algorithm that is able to handle the unbalanced and highly irregular clusters encountered in such CBIR applications. The strength of our approach lies not so much in the clustering itself, but rather in the definition and use of two cluster-validity indices that are independent of the cluster topology. By combining them, an optimal clustering can be identified, and experiments confirm that the associated clusters do, indeed, correspond to perceptually salient image regions."
            },
            "slug": "Finding-Salient-Regions-in-Images:-Nonparametric-Pauwels-Frederix",
            "title": {
                "fragments": [],
                "text": "Finding Salient Regions in Images: Nonparametric Clustering for Image Segmentation and Grouping"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "This paper develops a robust and versatile nonparametric clustering algorithm that is able to handle the unbalanced and highly irregular clusters encountered in such CBIR applications."
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Vis. Image Underst."
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1808205"
                        ],
                        "name": "G. Ciocca",
                        "slug": "G.-Ciocca",
                        "structuredName": {
                            "firstName": "Gianluigi",
                            "lastName": "Ciocca",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Ciocca"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143940718"
                        ],
                        "name": "R. Schettini",
                        "slug": "R.-Schettini",
                        "structuredName": {
                            "firstName": "Raimondo",
                            "lastName": "Schettini",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Schettini"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 28767461,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c9becac5c75e8deab9bfc06bb64b0d3c3e830a61",
            "isKey": false,
            "numCitedBy": 44,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "The paper describes a new relevance feedback mechanism that evaluates the distribution of the features of images judged relevant or not relevant by the user, and dynamically updates both the similarity measure and query in order to accurately represent the user's particular information needs. Experimental results are reported to demonstrate the effectiveness of this mechanism."
            },
            "slug": "Using-a-Relevance-Feedback-Mechanism-to-Improve-Ciocca-Schettini",
            "title": {
                "fragments": [],
                "text": "Using a Relevance Feedback Mechanism to Improve Content-Based Image Retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 93,
                "text": "A new relevance feedback mechanism is described that evaluates the distribution of the features of images judged relevant or not relevant by the user, and dynamically updates both the similarity measure and query in order to accurately represent the user's particular information needs."
            },
            "venue": {
                "fragments": [],
                "text": "VISUAL"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1747647"
                        ],
                        "name": "S. Santini",
                        "slug": "S.-Santini",
                        "structuredName": {
                            "firstName": "Simone",
                            "lastName": "Santini",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Santini"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1722619"
                        ],
                        "name": "Amarnath Gupta",
                        "slug": "Amarnath-Gupta",
                        "structuredName": {
                            "firstName": "Amarnath",
                            "lastName": "Gupta",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Amarnath Gupta"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144938740"
                        ],
                        "name": "R. Jain",
                        "slug": "R.-Jain",
                        "structuredName": {
                            "firstName": "Ramesh",
                            "lastName": "Jain",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Jain"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 17115672,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "054ff24ce8c15b31530b8149519d81b68ad7354a",
            "isKey": false,
            "numCitedBy": 230,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we briefly discuss some aspects of image semantics and the role that it plays for the design of image databases. We argue that images don't have an intrinsic meaning, but that they are endowed with a meaning by placing them in the context of other images and by the user interaction. From this observation, we conclude that, in an image, database users should be allowed to manipulate not only the individual images, but also the relation between them. We present an interface model based on the manipulation of configurations of images."
            },
            "slug": "Emergent-Semantics-through-Interaction-in-Image-Santini-Gupta",
            "title": {
                "fragments": [],
                "text": "Emergent Semantics through Interaction in Image Databases"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "It is argued that images don't have an intrinsic meaning, but that they are endowed with a meaning by placing them in the context of other images and by the user interaction."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Knowl. Data Eng."
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "121140068"
                        ],
                        "name": "R. Zhao",
                        "slug": "R.-Zhao",
                        "structuredName": {
                            "firstName": "Rong",
                            "lastName": "Zhao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Zhao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145160149"
                        ],
                        "name": "W. Grosky",
                        "slug": "W.-Grosky",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Grosky",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Grosky"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5663313,
            "fieldsOfStudy": [
                "Economics",
                "Computer Science",
                "Education"
            ],
            "id": "4833410f84d8ad37bba857dd98a9077ccf88f64a",
            "isKey": false,
            "numCitedBy": 53,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "We present the results of a project that seeks to transform low-level features to a higher level of meaning. This project concerns a technique, latent semantic analysis (LSA), which has been used for full-text retrieval for many years. In this environment, LSA determines clusters of co-occurring keywords, sometimes, called concepts, so that a query which uses a particular keyword can then retrieve documents perhaps not containing this keyword, but containing other keywords from the same cluster. We examine the use of this technique for content-based image retrieval, using two different approaches to image feature representation."
            },
            "slug": "From-features-to-semantics:-some-preliminary-Zhao-Grosky",
            "title": {
                "fragments": [],
                "text": "From features to semantics: some preliminary results"
            },
            "tldr": {
                "abstractSimilarityScore": 79,
                "text": "The results of a project that seeks to transform low-level features to a higher level of meaning, using latent semantic analysis (LSA), which has been used for full-text retrieval for many years, are presented."
            },
            "venue": {
                "fragments": [],
                "text": "2000 IEEE International Conference on Multimedia and Expo. ICME2000. Proceedings. Latest Advances in the Fast Changing World of Multimedia (Cat. No.00TH8532)"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144112511"
                        ],
                        "name": "Ronald Fagin",
                        "slug": "Ronald-Fagin",
                        "structuredName": {
                            "firstName": "Ronald",
                            "lastName": "Fagin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ronald Fagin"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 28200118,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7b290ed077e7ff0cc1d93de359344e1cced34ebd",
            "isKey": false,
            "numCitedBy": 818,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "In a traditional database system, the result of a query is a set of values (those values that satisfy the query). In other data servers, such as a system with queries based on image content, or many text retrieval systems, the result of a query is a sorted list. For example, in the case of a system with queries based on image content, the query might ask for objects that are a particular shade of red, and the result of the query would be a sorted list of objects in the database, sorted by how well the color of the object matches that given in the query. A multimedia system must somehow synthesize both types of queries (those whose result is a set and those whose result is a sorted list) in a consistent manner. In this paper we discuss the solution adopted by Garlic, a multimedia information system being developed at the IBM Almaden Research Center. This solution is based on \u201cgraded\u201d (or \u201cfuzzy\u201d) sets. Issues of efficient query evaluation in a multimedia system are very different from those in a traditional database system. This is because the multimedia system receives answers to subqueries from various subsystems, which can be accessed only in limited ways. For the important class of queries that are conjunctions of atomic queries (where each atomic query might be evaluated by a different subsystem), the naive algorithm must retrieve a number of elements that is linear in the database size. In contrast, in this paper an algorithm is given, which has been implemented in Garlic, such that if the conjuncts are independent, then with arbitrarily high probability, the total number of elements retrieved in evaluating the query is sublinear in the database size (in the case of two conjuncts, it is of the order of the square root of the database size). It is also shown that for such queries, the algorithm is optimal. The matching upper and lower bounds are robust, in the sense that they hold under almost any reasonable rule (including the standard min rule of fuzzy logic) for evaluating the conjunction. Finally, we find a query that is provably hard, in the sense that the naive linear algorithm is essentially optimal."
            },
            "slug": "Combining-Fuzzy-Information-from-Multiple-Systems-Fagin",
            "title": {
                "fragments": [],
                "text": "Combining Fuzzy Information from Multiple Systems"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "An algorithm is given, which has been implemented in Garlic, such that if the conjuncts are independent, then with arbitrarily high probability, the total number of elements retrieved in evaluating the query is sublinear in the database size."
            },
            "venue": {
                "fragments": [],
                "text": "J. Comput. Syst. Sci."
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "52626911"
                        ],
                        "name": "T. Minka",
                        "slug": "T.-Minka",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Minka",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Minka"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1719389"
                        ],
                        "name": "Rosalind W. Picard",
                        "slug": "Rosalind-W.-Picard",
                        "structuredName": {
                            "firstName": "Rosalind",
                            "lastName": "Picard",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Rosalind W. Picard"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 28597667,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "85881e5e636412751e9e35eb76868e1a6a71d9c7",
            "isKey": false,
            "numCitedBy": 242,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "Digital library access is driven by features, but the relevance of a feature for a query is not always obvious. This paper describes an approach for integrating a large number of context-dependent features into a semi-automated tool. Instead of requiring universal similarity measures or manual selection of relevant features, the approach provides a learning algorithm for selecting and combining groupings of the data, where groupings can be induced by highly specialized features. The selection process is guided by positive and negative examples from the user. The inherent combinatorics of using multiple features is reduced by a multistage grouping generation, weighting, and collection process. The stages closest to the user are trained fastest and slowly propagate their adaptations back to earlier stages. The weighting stage adapts the collection stage's search space across uses, so that, in later interactions, good groupings are found given few examples from the user."
            },
            "slug": "Interactive-learning-with-a-\"Society-of-Models\"-Minka-Picard",
            "title": {
                "fragments": [],
                "text": "Interactive learning with a \"society of models\""
            },
            "tldr": {
                "abstractSimilarityScore": 56,
                "text": "This paper describes an approach for integrating a large number of context-dependent features into a semi-automated tool that provides a learning algorithm for selecting and combining groupings of the data, where groupings can be induced by highly specialized features."
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit."
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1702392"
                        ],
                        "name": "C. Faloutsos",
                        "slug": "C.-Faloutsos",
                        "structuredName": {
                            "firstName": "Christos",
                            "lastName": "Faloutsos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Faloutsos"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2457943"
                        ],
                        "name": "King-Ip Lin",
                        "slug": "King-Ip-Lin",
                        "structuredName": {
                            "firstName": "King-Ip",
                            "lastName": "Lin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "King-Ip Lin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1387511,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d86648cb3ec497347d6e918116003b0e42910694",
            "isKey": false,
            "numCitedBy": 1170,
            "numCiting": 92,
            "paperAbstract": {
                "fragments": [],
                "text": "A very promising idea for fast searching in traditional and multimedia databases is to map objects into points in k-d space, using k feature-extraction functions, provided by a domain expert [25]. Thus, we can subsequently use highly fine-tuned spatial access methods (SAMs), to answer several types of queries, including the 'Query By Example' type (which translates to a range query); the 'all pairs' query (which translates to a spatial join [8]); the nearest-neighbor or best-match query, etc.However, designing feature extraction functions can be hard. It is relatively easier for a domain expert to assess the similarity/distance of two objects. Given only the distance information though, it is not obvious how to map objects into points.This is exactly the topic of this paper. We describe a fast algorithm to map objects into points in some k-dimensional space (k is user-defined), such that the dis-similarities are preserved. There are two benefits from this mapping: (a) efficient retrieval, in conjunction with a SAM, as discussed before and (b) visualization and data-mining: the objects can now be plotted as points in 2-d or 3-d space, revealing potential clusters, correlations among attributes and other regularities that data-mining is looking for.We introduce an older method from pattern recognition, namely, Multi-Dimensional Scaling (MDS) [51]; although unsuitable for indexing, we use it as yardstick for our method. Then, we propose a much faster algorithm to solve the problem in hand, while in addition it allows for indexing. Experiments on real and synthetic data indeed show that the proposed algorithm is significantly faster than MDS, (being linear, as opposed to quadratic, on the database size N), while it manages to preserve distances and the overall structure of the data-set."
            },
            "slug": "FastMap:-a-fast-algorithm-for-indexing,-data-mining-Faloutsos-Lin",
            "title": {
                "fragments": [],
                "text": "FastMap: a fast algorithm for indexing, data-mining and visualization of traditional and multimedia datasets"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A fast algorithm to map objects into points in some k-dimensional space (k is user-defined), such that the dis-similarities are preserved, and this method is introduced from pattern recognition, namely, Multi-Dimensional Scaling (MDS)."
            },
            "venue": {
                "fragments": [],
                "text": "SIGMOD '95"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1728108"
                        ],
                        "name": "M. Mirmehdi",
                        "slug": "M.-Mirmehdi",
                        "structuredName": {
                            "firstName": "Majid",
                            "lastName": "Mirmehdi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Mirmehdi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144877016"
                        ],
                        "name": "M. Petrou",
                        "slug": "M.-Petrou",
                        "structuredName": {
                            "firstName": "Maria",
                            "lastName": "Petrou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Petrou"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 29672783,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ca5256a9915ca462a18c08852e14172400d953f9",
            "isKey": false,
            "numCitedBy": 230,
            "numCiting": 40,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes an approach to perceptual segmentation of color image textures. A multiscale representation of the texture image, generated by a multiband smoothing algorithm based on human psychophysical measurements of color appearance is used as the input. Initial segmentation is achieved by applying a clustering algorithm to the image at the coarsest level of smoothing. The segmented clusters are then restructured in order to isolate core clusters, i.e., patches in which the pixels are definitely associated with the same region. The image pixels representing the core clusters are used to form 3D color histograms which are then used for probabilistic assignment of all other pixels to the core clusters to form larger clusters and categorise the rest of the image. The process of setting up color histograms and probabilistic reassignment of the pixels to the clusters is then propagated through finer levels of smoothing until a full segmentation is achieved at the highest level of resolution."
            },
            "slug": "Segmentation-of-Color-Textures-Mirmehdi-Petrou",
            "title": {
                "fragments": [],
                "text": "Segmentation of Color Textures"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The process of setting up color histograms and probabilistic reassignment of the pixels to the clusters is then propagated through finer levels of smoothing until a full segmentation is achieved at the highest level of resolution."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2073965041"
                        ],
                        "name": "G. Bucci",
                        "slug": "G.-Bucci",
                        "structuredName": {
                            "firstName": "G.",
                            "lastName": "Bucci",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Bucci"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143824814"
                        ],
                        "name": "S. Cagnoni",
                        "slug": "S.-Cagnoni",
                        "structuredName": {
                            "firstName": "Stefano",
                            "lastName": "Cagnoni",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Cagnoni"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7575775"
                        ],
                        "name": "R. de Dominicis",
                        "slug": "R.-de-Dominicis",
                        "structuredName": {
                            "firstName": "R.",
                            "lastName": "de Dominicis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. de Dominicis"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 7341633,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c211d8caedfa82d209a878b931c8eaaf633d066e",
            "isKey": false,
            "numCitedBy": 32,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Integrating-content-based-retrieval-in-a-medical-Bucci-Cagnoni",
            "title": {
                "fragments": [],
                "text": "Integrating content-based retrieval in a medical image reference database."
            },
            "venue": {
                "fragments": [],
                "text": "Computerized medical imaging and graphics : the official journal of the Computerized Medical Imaging Society"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2121009"
                        ],
                        "name": "J. Puzicha",
                        "slug": "J.-Puzicha",
                        "structuredName": {
                            "firstName": "Jan",
                            "lastName": "Puzicha",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Puzicha"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143936663"
                        ],
                        "name": "Thomas Hofmann",
                        "slug": "Thomas-Hofmann",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Hofmann",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thomas Hofmann"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1682548"
                        ],
                        "name": "J. Buhmann",
                        "slug": "J.-Buhmann",
                        "structuredName": {
                            "firstName": "Joachim",
                            "lastName": "Buhmann",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Buhmann"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 6050914,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1a7cee3ce1db1d62e93f74a6e01b22e63f5a90d1",
            "isKey": false,
            "numCitedBy": 301,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we propose and examine non-parametric statistical tests to define similarity and homogeneity measures for textures. The statistical tests are applied to the coefficients of images filtered by a multi-scale Gabor filter bank. We demonstrate that these similarity measures are useful for both, texture based image retrieval and for unsupervised texture segmentation, and hence offer a unified approach to these closely related tasks. We present results on Brodatz-like micro-textures and a collection of real-word images."
            },
            "slug": "Non-parametric-similarity-measures-for-unsupervised-Puzicha-Hofmann",
            "title": {
                "fragments": [],
                "text": "Non-parametric similarity measures for unsupervised texture segmentation and image retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 67,
                "text": "This paper proposes and examines non-parametric statistical tests to define similarity and homogeneity measures for textures and demonstrates that these similarity measures are useful for both, texture based image retrieval and for unsupervised texture segmentation, and hence offer a unified approach to these closely related tasks."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2522582"
                        ],
                        "name": "F. Idris",
                        "slug": "F.-Idris",
                        "structuredName": {
                            "firstName": "Fayez",
                            "lastName": "Idris",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Idris"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1743991"
                        ],
                        "name": "S. Panchanathan",
                        "slug": "S.-Panchanathan",
                        "structuredName": {
                            "firstName": "Sethuraman",
                            "lastName": "Panchanathan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Panchanathan"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 121613331,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "72b9d3e974e4b34fde65391097c3ff9b786309de",
            "isKey": false,
            "numCitedBy": 27,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we propose a new technique based on wavelet vector quantization for the storage and retrieval of compressed images. Here, the images are first decomposed using wavelet transform followed by vector quantization of the transform coefficients. We note that similar images map to similar labels. Hence, the labels corresponding to an image constitute a feature vector which is used as an index to store and retrieve the image. In addition, the lowest resolution subimages resulting from the wavelet decomposition serve as visual icons for browsing purposes. The proposed technique provide fast access to the compressed images in the database has a lower cost for computing and storing the indices compared to other techniques reported in the literature."
            },
            "slug": "Image-indexing-using-wavelet-vector-quantization-Idris-Panchanathan",
            "title": {
                "fragments": [],
                "text": "Image indexing using wavelet vector quantization"
            },
            "tldr": {
                "abstractSimilarityScore": 68,
                "text": "A new technique based on wavelet vector quantization for the storage and retrieval of compressed images that has a lower cost for computing and storing the indices compared to other techniques reported in the literature."
            },
            "venue": {
                "fragments": [],
                "text": "Other Conferences"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2987811"
                        ],
                        "name": "M. Swain",
                        "slug": "M.-Swain",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Swain",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Swain"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6444803,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fbd9f02552b83219b3fd6386bfa80a42b40d4446",
            "isKey": false,
            "numCitedBy": 31,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "The proliferation of multimedia on the World Wide Web has led to the introduction of Web search engines for images, video and audio. On the Web, multimedia is typically embedded within documents that provide a wealth of indexing information. Harsh computational constraints imposed by the economics of advertising-supported searches restrict the complexity of analysis that can be performed at query time and users may be unwilling to do much more than type a keyword or two to input a query. Therefore, the primary sources of information for indexing multimedia documents are text cues extracted from HTML pages and multimedia document headers. Off-line analysis of the content of multimedia documents can be successfully employed in Web search engines when combined with these other information sources. Content analysis can be used to categorize and summarize multimedia, in addition to providing cues for finding similar documents."
            },
            "slug": "Searching-for-multimedia-on-the-World-Wide-Web-Swain",
            "title": {
                "fragments": [],
                "text": "Searching for multimedia on the World Wide Web"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "Off-line analysis of the content of multimedia documents can be successfully employed in Web search engines when combined with other information sources, including HTML pages and multimedia document headers."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings IEEE International Conference on Multimedia Computing and Systems"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1691993"
                        ],
                        "name": "E. Riloff",
                        "slug": "E.-Riloff",
                        "structuredName": {
                            "firstName": "Ellen",
                            "lastName": "Riloff",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Riloff"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34889892"
                        ],
                        "name": "L. Hollaar",
                        "slug": "L.-Hollaar",
                        "structuredName": {
                            "firstName": "Lee",
                            "lastName": "Hollaar",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Hollaar"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 6759135,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "63c9913ea275c2cb116db2b02899abd77b8a3657",
            "isKey": false,
            "numCitedBy": 42,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "The goal of a traditional information retrieval (IR) system is to search an information repository, such as a text database, and retrieve documents that are potentially relevant to a query. Since query-based IR systems must operate in real time, they must be able to search large volumes of text quickly and efficiently. Other information-retrieval applications, such as text categorization, text routing, and text filtering, are also becoming increasingly important. These applications are generally concerned with long-term information needs, where a topic is expected to be of interest for an extended period of time. Text categorization systems assign predefined category labels to texts. For example, a text categorization system for computer science might use categories such as operating systems, programming languages, artificial intelligence, or information retrieval. Text routing systems typically accept a set of user profiles and automatically classify texts so that relevant texts can be routed to appropriate users [Harman 1994]. Text filtering systems accept a list of topics that are, or are not, of interest and allow only texts that satisfy the filter to pass through to the user [Belkin and Croft 1992]. Text categorization systems are typically applied to static databases, while text routing and text filtering systems are usually applied to incoming data streams. Information-retrieval systems must grapple with all of the ambiguities and idiosyncrasies inherent in natural language, such as synonymy (e.g., \u201cstart\u201d, \u201cbegin\u201d, and \u201cinitiate\u201d have essentially the same meaning) and polysemy (e.g., \u201cshot\u201d has many different meanings, including the act of shooting, an injection, a quantity of liquor, a photograph, pellets, or an attempt). Phrases also require special attention because multiword expressions often have a composite meaning different from the individual words. For example, a \u201chot dog\u201d does not usually refer to a warm canine, and an \u201coperating system\u201d does not usually refer to a system that is simply operating. Most information-retrieval systems preprocess a document collection into an inverted file that allows the system to determine quickly which words appear in each document. Stopword lists are commonly used to remove highly frequent words, such as \u201cthe\u201d and \u201cof,\u201d under the assumption that they don\u2019t contribute much to the meaning of a text. Stemming algorithms are sometimes used to reduce a word to its root form so that different morphological variations will match [Frakes and Baeza-Yates 1992]. An alternative text-representation scheme uses superimposed codewords to produce a fixed-length vector from the binary representations of words. The fixed-length vector is especially useful for parallel and hardware systems, but this method can sometimes hallucinate words that don\u2019t actually appear in the original document. Traditional information-retrieval methods retrieve documents by searching for relevant words or phrases. Most commercial IR systems allow the user to define a query using keywords and standard Boolean operators. These systems retrieve documents that precisely match the query. The vector-space model [Salton"
            },
            "slug": "Text-databases-and-information-retrieval-Riloff-Hollaar",
            "title": {
                "fragments": [],
                "text": "Text databases and information retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 78,
                "text": "The goal of a traditional information retrieval (IR) system is to search an information repository, such as a text database, and retrieve documents that are potentially relevant to a query, and other information-retrieval applications are also becoming increasingly important."
            },
            "venue": {
                "fragments": [],
                "text": "CSUR"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1745416"
                        ],
                        "name": "H. Tagare",
                        "slug": "H.-Tagare",
                        "structuredName": {
                            "firstName": "Hemant",
                            "lastName": "Tagare",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Tagare"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144674005"
                        ],
                        "name": "F. Vos",
                        "slug": "F.-Vos",
                        "structuredName": {
                            "firstName": "Frans",
                            "lastName": "Vos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Vos"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2855937"
                        ],
                        "name": "C. Jaffe",
                        "slug": "C.-Jaffe",
                        "structuredName": {
                            "firstName": "Conrade",
                            "lastName": "Jaffe",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Jaffe"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145947161"
                        ],
                        "name": "J. Duncan",
                        "slug": "J.-Duncan",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Duncan",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Duncan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 12541831,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "efa92ac080227e50a9e181b6e972ff24d76e157e",
            "isKey": false,
            "numCitedBy": 49,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": "Medical tomographic images are formed by the intersection of the image plane and an object. As the image plane changes, different parts of the object come in view or drop out of view. However, for small changes of the image plane, most parts continue to remain visible and their qualitative embedding in the image remains similar. Therefore, similarity of part embeddings can be used to infer similarity of image planes. Part embeddings are useful features for other vision applications as well. In view of this, a spatial relation called \"arrangement\" is proposed to describe part embeddings. The relation describes how each part is surrounded by its neighbors. Further, a metric for arrangements is formulated by expressing arrangements in terms of the Voronoi diagram of the parts. Arrangements and their metric are used to retrieve images by image plane similarity in a cardiac magnetic resonance image database. Experiments with the database are reported which (1) validate the observation that similarity of image planes can be inferred from similarity of part embeddings, and (2) compare the performance of arrangement based image retrieval with that of expert radiologists. >"
            },
            "slug": "Arrangement:-A-Spatial-Relation-Between-Parts-for-Tagare-Vos",
            "title": {
                "fragments": [],
                "text": "Arrangement: A Spatial Relation Between Parts for Evaluating Similarity of Tomographic Section"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "Experiments are reported which validate the observation that similarity of image planes can be inferred from similarity of part embeddings, and compare the performance of arrangement based image retrieval with that of expert radiologists."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9546964"
                        ],
                        "name": "Shih-Fu Chang",
                        "slug": "Shih-Fu-Chang",
                        "structuredName": {
                            "firstName": "Shih-Fu",
                            "lastName": "Chang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shih-Fu Chang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47088868"
                        ],
                        "name": "Joshua R. Smith",
                        "slug": "Joshua-R.-Smith",
                        "structuredName": {
                            "firstName": "Joshua",
                            "lastName": "Smith",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Joshua R. Smith"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2424352"
                        ],
                        "name": "M. Beigi",
                        "slug": "M.-Beigi",
                        "structuredName": {
                            "firstName": "Mandis",
                            "lastName": "Beigi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Beigi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143761956"
                        ],
                        "name": "A. Benitez",
                        "slug": "A.-Benitez",
                        "structuredName": {
                            "firstName": "Ana",
                            "lastName": "Benitez",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Benitez"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5601548,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "72341893ede4bcb44dd8344d562798c5eb6adace",
            "isKey": false,
            "numCitedBy": 243,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "Digital images and video are becoming an integral part of human communications. The ease of capturing and creating digital images has caused most on-line information sources look more \u201cvisual\u201d. We use more and more visual content in expressing ideas, reporting, education, and entertainment. With the tremendous amount of visual information becoming on-line, how does one find visual information from distributed repositories efficiently, at least to the same extent as that of existing information retrieval systems. With the growing number of on-line users, how does one design a system with performance scalable to a large extent?"
            },
            "slug": "Visual-information-retrieval-from-large-distributed-Chang-Smith",
            "title": {
                "fragments": [],
                "text": "Visual information retrieval from large distributed online repositories"
            },
            "venue": {
                "fragments": [],
                "text": "CACM"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144644545"
                        ],
                        "name": "G. Healey",
                        "slug": "G.-Healey",
                        "structuredName": {
                            "firstName": "Glenn",
                            "lastName": "Healey",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Healey"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49326902"
                        ],
                        "name": "D. Slater",
                        "slug": "D.-Slater",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Slater",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Slater"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 31466689,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "77061b55da05bbc4e984f0cf975cc06275af80ee",
            "isKey": false,
            "numCitedBy": 54,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "Spatial filters provide a useful and efficient means of analyzing an input color image into components that capture different spatial properties. Representations based on spatial filtering have restricted usefulness for recognition, however, because the output of a spatial filter across an image depends on the scene illumination conditions. We use a physically accurate linear model for spectral reflectance to derive invariants of distributions in spatially filtered color images that do not depend on the scene illumination. These invariants can be used for the illumination-invariant recognition of regions following an arbitrary linear filtering operation. We describe a method for illumination correction based on color distributions and introduce an illumination change consistency constraint that is useful for verifying matches obtained using the invariants. We show, using a set of classification experiments, that the filtered distribution invariants can significantly improve the capability of a recognition system in environments where illumination cannot be controlled."
            },
            "slug": "Computing-illumination-invariant-descriptors-of-Healey-Slater",
            "title": {
                "fragments": [],
                "text": "Computing illumination-invariant descriptors of spatially filtered color image regions"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "It is shown, using a set of classification experiments, that the filtered distribution invariants can significantly improve the capability of a recognition system in environments where illumination cannot be controlled."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Image Process."
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2086066"
                        ],
                        "name": "B. Huet",
                        "slug": "B.-Huet",
                        "structuredName": {
                            "firstName": "Benoit",
                            "lastName": "Huet",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Huet"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1679753"
                        ],
                        "name": "E. Hancock",
                        "slug": "E.-Hancock",
                        "structuredName": {
                            "firstName": "Edwin",
                            "lastName": "Hancock",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Hancock"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9009367,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bbafd826b370a0557f5ddf51bbf0e07eba4cbcc9",
            "isKey": false,
            "numCitedBy": 78,
            "numCiting": 42,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a new compact shape representation for retrieving line-patterns from large databases. The basic idea is to exploit both geometric attributes and structural information to construct a shape histogram. We realize this goal by computing the N-nearest neighbor graph for the lines-segments for each pattern. The edges of the neighborhood graphs are used to gate contributions to a two-dimensional pairwise geometric histogram. Shapes are indexed by searching for the line-pattern that maximizes the cross correlation of the normalized histogram bin-contents. We evaluate the new method on a database containing over 2,500 line-patterns each composed of hundreds of lines."
            },
            "slug": "Line-Pattern-Retrieval-Using-Relational-Histograms-Huet-Hancock",
            "title": {
                "fragments": [],
                "text": "Line Pattern Retrieval Using Relational Histograms"
            },
            "tldr": {
                "abstractSimilarityScore": 73,
                "text": "A new compact shape representation for retrieving line-patterns from large databases by computing the N-nearest neighbor graph for the lines-segments for each pattern by exploiting both geometric attributes and structural information to construct a shape histogram."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1747647"
                        ],
                        "name": "S. Santini",
                        "slug": "S.-Santini",
                        "structuredName": {
                            "firstName": "Simone",
                            "lastName": "Santini",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Santini"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144938740"
                        ],
                        "name": "R. Jain",
                        "slug": "R.-Jain",
                        "structuredName": {
                            "firstName": "Ramesh",
                            "lastName": "Jain",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Jain"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1722619"
                        ],
                        "name": "Amarnath Gupta",
                        "slug": "Amarnath-Gupta",
                        "structuredName": {
                            "firstName": "Amarnath",
                            "lastName": "Gupta",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Amarnath Gupta"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2599908,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "39e219f84c6f9a5cc919e3dc406101872d022c79",
            "isKey": false,
            "numCitedBy": 14,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we discuss image semantics and the repercussions that its correct definition have on the design of image databases. We start by rejecting the simplistic notion that the meaning of an image is a function of the objects that the image contains, and show that meaning can only be defined in the context of a query, and can only be revealed in the context of the whole database."
            },
            "slug": "A-User-Interface-for-Emergent-Sementics-in-Image-Santini-Jain",
            "title": {
                "fragments": [],
                "text": "A User Interface for Emergent Sementics in Image Databases"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "The simplistic notion that the meaning of an image is a function of the objects that the image contains is rejected, and it is shown that meaning can only be defined in the context of a query, and canonly be revealed in thecontext of the whole database."
            },
            "venue": {
                "fragments": [],
                "text": "DS-8"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145564537"
                        ],
                        "name": "Jiri Matas",
                        "slug": "Jiri-Matas",
                        "structuredName": {
                            "firstName": "Jiri",
                            "lastName": "Matas",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jiri Matas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3164095"
                        ],
                        "name": "R. Marik",
                        "slug": "R.-Marik",
                        "structuredName": {
                            "firstName": "Radek",
                            "lastName": "Marik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Marik"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145801638"
                        ],
                        "name": "J. Kittler",
                        "slug": "J.-Kittler",
                        "structuredName": {
                            "firstName": "Josef",
                            "lastName": "Kittler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Kittler"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 11968281,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c50a8a990f3be75b9a52942fa0b03261cf25dfb8",
            "isKey": false,
            "numCitedBy": 80,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "A new representation for objects with multiple colours-the colour adjacency graph (CAG)-is proposed. Each node of the CAG represents a single chromatic component of the image defined as a set of pixels forming a unimodal cluster in the chromatic scattergram. Edges encode information about adjacency of colour components and their reflectance ratio. The CAG is related to both the histogram and region adjacency graph representations. It is shown to be preserving and combining the best features of these two approaches while avoiding their drawbacks. The proposed approach is tested on a range of difficult object recognition and localisation problems involving complex imagery of non-rigid 3D objects under varied viewing conditions with excellent results.<<ETX>>"
            },
            "slug": "On-representation-and-matching-of-multi-coloured-Matas-Marik",
            "title": {
                "fragments": [],
                "text": "On representation and matching of multi-coloured objects"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "The proposed CAG is shown to be preserving and combining the best features of these two approaches while avoiding their drawbacks, and is tested on a range of difficult object recognition and localisation problems involving complex imagery of non-rigid 3D objects under varied viewing conditions with excellent results."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IEEE International Conference on Computer Vision"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144050301"
                        ],
                        "name": "T. Lau",
                        "slug": "T.-Lau",
                        "structuredName": {
                            "firstName": "Tak-Kan",
                            "lastName": "Lau",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Lau"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145310663"
                        ],
                        "name": "Irwin King",
                        "slug": "Irwin-King",
                        "structuredName": {
                            "firstName": "Irwin",
                            "lastName": "King",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Irwin King"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14238351,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f8cdda1de8961deb33c30de513e9bbf011847b43",
            "isKey": false,
            "numCitedBy": 22,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "The fashion, textile, and clothing industry is a main constituent in Hong Kong. In this industry, handling a large amount of images is an important task in various phases, for example, the designing, sourcing, and merchandising phase. We develop an image database system called, Montage for managing and retrieving these visual information efficiently and effectively. Montage is an image database supporting content-based retrieval by color histogram, sketch, texture, and shape. One important feature of Montage is the Open Architecture design which makes the system extensible, customizible, and flexible. There are two aspects of this open architecture design: (1) Open DataBase Connectivity (ODBC) and (2) plug-in framework which we will discuss in more details. Moreover, we describe an experimental Java system enabling internet access to Montage. In the paper, we also present an experiment to evaluate the performance of several query methods."
            },
            "slug": "Montage:-An-Image-Database-for-the-Fashion,-and-in-Lau-King",
            "title": {
                "fragments": [],
                "text": "Montage: An Image Database for the Fashion, Textile, and Clothing Industry in Hong Kong"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "Montage is an image database supporting content-based retrieval by color histogram, sketch, texture, and shape and one important feature of Montage is the Open Architecture design which makes the system extensible, customizible, and flexible."
            },
            "venue": {
                "fragments": [],
                "text": "ACCV"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1686678"
                        ],
                        "name": "L. Latecki",
                        "slug": "L.-Latecki",
                        "structuredName": {
                            "firstName": "Longin",
                            "lastName": "Latecki",
                            "middleNames": [
                                "Jan"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Latecki"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1889149"
                        ],
                        "name": "Rolf Lak\u00e4mper",
                        "slug": "Rolf-Lak\u00e4mper",
                        "structuredName": {
                            "firstName": "Rolf",
                            "lastName": "Lak\u00e4mper",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Rolf Lak\u00e4mper"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 5405348,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f3d5469daca6fc2d302ef48b00ff26e745c923d6",
            "isKey": false,
            "numCitedBy": 16,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "A similarity measure for silhouettes of 2D objects is presented, and its properties are analyzed with respect to retrieval of similar objects in an image database. Our measure profits from a novel approach to subdivision of objects into parts of visual form. To compute our similarity measure, we first establish the best possible correspondence of visual parts, which is based on a correspondence of convex boundary arcs. Then the similarity between correspondence arcs is computed and aggregated. We applied our similarity measure to shape matching of object contours in various image databases and compared it to well-known approaches in the literature. The experimental results justify that our shape matching procedure gives an intuitive shape correspondence and is stable with respect to noise distortions."
            },
            "slug": "Contour-based-shape-similarity-Latecki-Lak\u00e4mper",
            "title": {
                "fragments": [],
                "text": "Contour-based shape similarity"
            },
            "tldr": {
                "abstractSimilarityScore": 85,
                "text": "A similarity measure for silhouettes of 2D objects is presented, and its properties are analyzed with respect to retrieval of similar objects in an image database and compared to well-known approaches in the literature."
            },
            "venue": {
                "fragments": [],
                "text": "Optics & Photonics"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2064843"
                        ],
                        "name": "M. Shneier",
                        "slug": "M.-Shneier",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Shneier",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Shneier"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "92329551"
                        ],
                        "name": "M. Abdel-Mottaleb",
                        "slug": "M.-Abdel-Mottaleb",
                        "structuredName": {
                            "firstName": "Mohamed",
                            "lastName": "Abdel-Mottaleb",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Abdel-Mottaleb"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 38971193,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6c41927779521ed9bedf49d0df5f4086f5b91cd6",
            "isKey": false,
            "numCitedBy": 165,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "We address the problem of retrieving images from a large database using an image as a query. The method is specifically aimed at databases that store images in JPEG format, and works in the compressed domain to create index keys. A key is generated for each image in the database and is matched with the key generated for the query image. The keys are independent of the size of the image. Images that have similar keys are assumed to be similar, but there is no semantic meaning to the similarity."
            },
            "slug": "Exploiting-the-JPEG-Compression-Scheme-for-Image-Shneier-Abdel-Mottaleb",
            "title": {
                "fragments": [],
                "text": "Exploiting the JPEG Compression Scheme for Image Retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 93,
                "text": "This work addresses the problem of retrieving images from a large database using an image as a query, specifically aimed at databases that store images in JPEG format, and works in the compressed domain to create index keys."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1727969"
                        ],
                        "name": "P. Correia",
                        "slug": "P.-Correia",
                        "structuredName": {
                            "firstName": "Paulo",
                            "lastName": "Correia",
                            "middleNames": [
                                "Lobato"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Correia"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152639054"
                        ],
                        "name": "F. Pereira",
                        "slug": "F.-Pereira",
                        "structuredName": {
                            "firstName": "Fernando",
                            "lastName": "Pereira",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Pereira"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 41350813,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "faee65551d1d68fba313804bfee7e53e6b356a88",
            "isKey": false,
            "numCitedBy": 45,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "The-role-of-analysis-in-content-based-video-coding-Correia-Pereira",
            "title": {
                "fragments": [],
                "text": "The role of analysis in content-based video coding and indexing"
            },
            "venue": {
                "fragments": [],
                "text": "Signal Process."
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34767796"
                        ],
                        "name": "M. Mandal",
                        "slug": "M.-Mandal",
                        "structuredName": {
                            "firstName": "Mrinal",
                            "lastName": "Mandal",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Mandal"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2522582"
                        ],
                        "name": "F. Idris",
                        "slug": "F.-Idris",
                        "structuredName": {
                            "firstName": "Fayez",
                            "lastName": "Idris",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Idris"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1743991"
                        ],
                        "name": "S. Panchanathan",
                        "slug": "S.-Panchanathan",
                        "structuredName": {
                            "firstName": "Sethuraman",
                            "lastName": "Panchanathan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Panchanathan"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 15899241,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cfd190750655b46623995da2e7e688d5c6ff3993",
            "isKey": false,
            "numCitedBy": 184,
            "numCiting": 98,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-critical-evaluation-of-image-and-video-indexing-Mandal-Idris",
            "title": {
                "fragments": [],
                "text": "A critical evaluation of image and video indexing techniques in the compressed domain"
            },
            "venue": {
                "fragments": [],
                "text": "Image Vis. Comput."
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2256609"
                        ],
                        "name": "Brian S. Eberman",
                        "slug": "Brian-S.-Eberman",
                        "structuredName": {
                            "firstName": "Brian",
                            "lastName": "Eberman",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Brian S. Eberman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2044070"
                        ],
                        "name": "B. Fidler",
                        "slug": "B.-Fidler",
                        "structuredName": {
                            "firstName": "Blair",
                            "lastName": "Fidler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Fidler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2476171"
                        ],
                        "name": "Bob Iannucci",
                        "slug": "Bob-Iannucci",
                        "structuredName": {
                            "firstName": "Bob",
                            "lastName": "Iannucci",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bob Iannucci"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1947255"
                        ],
                        "name": "C. Joerg",
                        "slug": "C.-Joerg",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Joerg",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Joerg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2069591"
                        ],
                        "name": "L. Kontothanassis",
                        "slug": "L.-Kontothanassis",
                        "structuredName": {
                            "firstName": "Leonidas",
                            "lastName": "Kontothanassis",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Kontothanassis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3031964"
                        ],
                        "name": "D. Kovalcin",
                        "slug": "D.-Kovalcin",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Kovalcin",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Kovalcin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47690405"
                        ],
                        "name": "P. Moreno",
                        "slug": "P.-Moreno",
                        "structuredName": {
                            "firstName": "Pedro",
                            "lastName": "Moreno",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Moreno"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2987811"
                        ],
                        "name": "M. Swain",
                        "slug": "M.-Swain",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Swain",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Swain"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2737370"
                        ],
                        "name": "Jean-Manuel Van Thong",
                        "slug": "Jean-Manuel-Van-Thong",
                        "structuredName": {
                            "firstName": "Jean-Manuel",
                            "lastName": "Thong",
                            "middleNames": [
                                "Van"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jean-Manuel Van Thong"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7621922,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4e0fb6a23f18e0661fb897038519160282c59383",
            "isKey": false,
            "numCitedBy": 8,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "We have developed a system that allows us to index and deliver audio and video over the Internet. The system has been in continuous operation since March 1998 within the company. The design of our system differs from previous systems because 1) the indexing can be based on an annotation stream generated by robust transcript alignment, as well as closed captions, and 2) it is a distributed system that is designed for scalable, high performance, universal access through the World Wide Web. Extensive tests of the system show that it achieves a performance level required for Internet-wide delivery. This paper discusses our approach to the problem, the design requirements, the system architecture, and performance figures. It concludes by showing how the next generation of annotations from speech recognition and computer vision can be incorporated into the system."
            },
            "slug": "Indexing-Multimedia-for-the-Internet-Eberman-Fidler",
            "title": {
                "fragments": [],
                "text": "Indexing Multimedia for the Internet"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The approach to the problem, the design requirements, the system architecture, and performance figures are discussed, and the next generation of annotations from speech recognition and computer vision can be incorporated into the system."
            },
            "venue": {
                "fragments": [],
                "text": "VISUAL"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1749590"
                        ],
                        "name": "S. Sclaroff",
                        "slug": "S.-Sclaroff",
                        "structuredName": {
                            "firstName": "Stan",
                            "lastName": "Sclaroff",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Sclaroff"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 52819137,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f79921d46911b0f1c3fa07bf5334e256d79c850c",
            "isKey": false,
            "numCitedBy": 110,
            "numCiting": 124,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Deformable-prototypes-for-encoding-shape-categories-Sclaroff",
            "title": {
                "fragments": [],
                "text": "Deformable prototypes for encoding shape categories in image databases"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit."
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1890284"
                        ],
                        "name": "F. Mokhtarian",
                        "slug": "F.-Mokhtarian",
                        "structuredName": {
                            "firstName": "Farzin",
                            "lastName": "Mokhtarian",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Mokhtarian"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 16379758,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "abdbc51d06170b26002c694c5a1dd67621ce5986",
            "isKey": false,
            "numCitedBy": 251,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "A complete, fast and practical isolated object recognition system has been developed which is very robust with respect to scale, position and orientation changes of the objects as well as noise and local deformations of shape (due to perspective projection, segmentation errors and non-rigid material used in some objects). The system has been tested on a wide variety of three-dimensional objects with different shapes and material and surface properties. A light-box setup is used to obtain silhouette images which are segmented to obtain the physical boundaries of the objects which are classified as either convex or concave. Convex curves are recognized using their four high-scale curvature extrema points. Curvature scale space (CSS) representations are computed for concave curves. The CSS representation is a multi-scale organization of the natural, invariant features of a curve (curvature zero-crossings or extrema) and useful for very reliable recognition of the correct model since it places no constraints on the shape of objects. A three-stage, coarse-to-fine matching algorithm prunes the search space in stage one by applying the CSS aspect ratio test. The maxima of contours in CSS representations of the surviving models are used for fast CSS matching in stage two. Finally, stage three verifies the best match and resolves any ambiguities by determining the distance between the image and model curves. Transformation parameter optimization is then used to find the best fit of the input object to the correct model. >"
            },
            "slug": "Silhouette-Based-Isolated-Object-Recognition-Scale-Mokhtarian",
            "title": {
                "fragments": [],
                "text": "Silhouette-Based Isolated Object Recognition through Curvature Scale Space"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "A complete, fast and practical isolated object recognition system has been developed which is very robust with respect to scale, position and orientation changes of the objects as well as noise and local deformations of shape (due to perspective projection, segmentation errors and non-rigid material used in some objects)."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1679040"
                        ],
                        "name": "Shi-Kuo Chang",
                        "slug": "Shi-Kuo-Chang",
                        "structuredName": {
                            "firstName": "Shi-Kuo",
                            "lastName": "Chang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shi-Kuo Chang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46891469"
                        ],
                        "name": "A. Hsu",
                        "slug": "A.-Hsu",
                        "structuredName": {
                            "firstName": "Arding",
                            "lastName": "Hsu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Hsu"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 38822583,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ee3deeb9c2f49b27c3fe7c222f153a610c33aa16",
            "isKey": false,
            "numCitedBy": 210,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "A conceptual framework for image information systems is presented. Current research topics are surveyed, and application examples are presented. The design issues for the next generation of active image systems are discussed. It is suggested that the next generation of active image information systems should be designed on the basis of notions of generalized icons and active indexes, resulting in smart images. >"
            },
            "slug": "Image-Information-Systems:-Where-Do-We-Go-From-Here-Chang-Hsu",
            "title": {
                "fragments": [],
                "text": "Image Information Systems: Where Do We Go From Here?"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "It is suggested that the next generation of active image information systems should be designed on the basis of notions of generalized icons and active indexes, resulting in smart images."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Knowl. Data Eng."
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2605432"
                        ],
                        "name": "Toshihiro Kakimoto",
                        "slug": "Toshihiro-Kakimoto",
                        "structuredName": {
                            "firstName": "Toshihiro",
                            "lastName": "Kakimoto",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Toshihiro Kakimoto"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1736726"
                        ],
                        "name": "Y. Kambayashi",
                        "slug": "Y.-Kambayashi",
                        "structuredName": {
                            "firstName": "Yahiko",
                            "lastName": "Kambayashi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Kambayashi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14071459,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "55852a0113436317f123c3614437abd6d760ae1c",
            "isKey": false,
            "numCitedBy": 6,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "In order to get useful information from various kinds of information sources, we first apply a searching process with query statements to retrieve candidate data objects (called a hunting process in this paper) and then apply a browsing process to check the properties of each object in detail by visualizing candidates. In traditional information retrieval systems, the hunting process determines the quality of the result, since there are only a few candidates left for the browsing process. In order to retrieve data from widely distributed digital libraries, the browsing process becomes very important, since the properties of data sources are not known in advance. After getting data from various information sources, a user checks the properties of data in detail using the browsing process. The result can be used to improve the hunting process or for selecting more appropriate visualization parameters. Visualization relationships among data are very important, but will become too time-consuming if the amount of data in the candidate set is large, for example, over one hundred objects. One of the important problems in handling information retrieval from a digital library is to create efficient and powerful visualization mechanisms for the browsing process. One promising way to solve the visualization problem is to map each candidate data object into a location in three-dimensional (3D) space using a proper distance definition. In this paper, we will introduce the functions and organization of a system having a browsing navigator to achieve an efficient browsing process in 3D information search space. This browsing navigator has the following major functions: \u00b61. Selection of features which determine the distance for visualization, in order to generate a uniform distribution of candidate data objects in the resulting space. \u00b62. Calculation of the location of the data objects in 2D space using the selected features. \u00b63. Construction of 3D browsing space by combining 2D spaces, in order to find the required data objects easily. \u00b64. Generation of the oblique views of 3D browsing space and data objects by reducing the overlap of data objects in order to make navigation easy for the user in 3D space. \u00b6Examples of this browsing navigator applied to book data are shown."
            },
            "slug": "Browsing-functions-in-three-dimensional-space-for-Kakimoto-Kambayashi",
            "title": {
                "fragments": [],
                "text": "Browsing functions in three-dimensional space for digital libraries"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "The functions and organization of a system having a browsing navigator are introduced to achieve an efficient browsing process in 3D information search space and the result can be used to improve the hunting process or for selecting more appropriate visualization parameters."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal on Digital Libraries"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2021608"
                        ],
                        "name": "J. Eakins",
                        "slug": "J.-Eakins",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Eakins",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Eakins"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47973629"
                        ],
                        "name": "J. M. Boardman",
                        "slug": "J.-M.-Boardman",
                        "structuredName": {
                            "firstName": "Jago",
                            "lastName": "Boardman",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. M. Boardman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2055069292"
                        ],
                        "name": "M. Graham",
                        "slug": "M.-Graham",
                        "structuredName": {
                            "firstName": "Margaret",
                            "lastName": "Graham",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Graham"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 41599822,
            "fieldsOfStudy": [
                "Art"
            ],
            "id": "8f6b15da665229a2dede0ba1256e922be0ec21d3",
            "isKey": false,
            "numCitedBy": 108,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "The Artisan system retrieves abstract trademark images by shape similarity. It analyzes each image to characterize key shape components, grouping image regions into families that potentially mirror human image perception, and then derives characteristic indexing features from these families and from the image as a whole. We have evaluated the retrieval effectiveness of our prototype system on more than 10,000 images from the UK Trade Marks Registry."
            },
            "slug": "Similarity-Retrieval-of-Trademark-Images-Eakins-Boardman",
            "title": {
                "fragments": [],
                "text": "Similarity Retrieval of Trademark Images"
            },
            "tldr": {
                "abstractSimilarityScore": 77,
                "text": "The Artisan system retrieves abstract trademark images by shape similarity, grouping image regions into families that potentially mirror human image perception, and then derives characteristic indexing features from these families and from the image as a whole."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Multim."
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31617973"
                        ],
                        "name": "Norio Katayama",
                        "slug": "Norio-Katayama",
                        "structuredName": {
                            "firstName": "Norio",
                            "lastName": "Katayama",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Norio Katayama"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1700567"
                        ],
                        "name": "S. Satoh",
                        "slug": "S.-Satoh",
                        "structuredName": {
                            "firstName": "Shin\u2019ichi",
                            "lastName": "Satoh",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Satoh"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2722443,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "35a5d120f3c3af9f20ed7d81c9bc9760c93b2bc0",
            "isKey": false,
            "numCitedBy": 990,
            "numCiting": 55,
            "paperAbstract": {
                "fragments": [],
                "text": "Recently, similarity queries on feature vectors have been widely used to perform content-based retrieval of images. To apply this technique to large databases, it is required to develop multidimensional index structures supporting nearest neighbor queries efficiently. The SS-tree had been proposed for this purpose and is known to outperform other index structures such as the R*-tree and the K-D-B-tree. One of its most important features is that it employs bounding spheres rather than bounding rectangles for the shape of regions. However, we demonstrate in this paper that bounding spheres occupy much larger volume than bounding rectangles with high-dimensional data and that this reduces search efficiency. To overcome this drawback, we propose a new index structure called the SR-tree (Sphere/Rectangle-tree) which integrates bounding spheres and bounding rectangles. A region of the SR-tree is specified by the intersection of a bounding sphere and a bounding rectangle. Incorporating bounding rectangles permits neighborhoods to be partitioned into smaller regions than the SS-tree and improves the disjointness among regions. This enhances the performance on nearest neighbor queries especially for high-dimensional and non-uniform data which can be practical in actual image/video similarity indexing. We include the performance test results the verify this advantage of the SR-tree and show that the SR-tree outperforms both the SS-tree and the R*-tree."
            },
            "slug": "The-SR-tree:-an-index-structure-for-nearest-queries-Katayama-Satoh",
            "title": {
                "fragments": [],
                "text": "The SR-tree: an index structure for high-dimensional nearest neighbor queries"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This paper proposes a new index structure called the SR-tree (Sphere/Rectangle-tree) which integrates bounding spheres and bounding rectangles which enhances the performance on nearest neighbor queries especially for high-dimensional and non-uniform data which can be practical in actual image/video similarity indexing."
            },
            "venue": {
                "fragments": [],
                "text": "SIGMOD '97"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2759584"
                        ],
                        "name": "P. Aigrain",
                        "slug": "P.-Aigrain",
                        "structuredName": {
                            "firstName": "Philippe",
                            "lastName": "Aigrain",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Aigrain"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38188346"
                        ],
                        "name": "Hong-jiang Zhang",
                        "slug": "Hong-jiang-Zhang",
                        "structuredName": {
                            "firstName": "Hong-jiang",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hong-jiang Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143867341"
                        ],
                        "name": "D. Petkovic",
                        "slug": "D.-Petkovic",
                        "structuredName": {
                            "firstName": "Dragutin",
                            "lastName": "Petkovic",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Petkovic"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 62732276,
            "fieldsOfStudy": [
                "Art"
            ],
            "id": "c199e5f1dceb3b62e0df3adecc378e4e0bbe7673",
            "isKey": false,
            "numCitedBy": 373,
            "numCiting": 56,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper reviews a number of recently available techniques in content analysis of visual media and their application to the indexing, retrieval, abstracting, relevance assessment, interactive perception, annotation and re-use of visual documents."
            },
            "slug": "Content-based-representation-and-retrieval-of-A-Aigrain-Zhang",
            "title": {
                "fragments": [],
                "text": "Content-Based Representation and Retrieval of Visual Media: A State-of-the-Art Review"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "This paper reviews a number of recently available techniques in content analysis of visual media and their application to the indexing, retrieval, abstracting, relevance assessment, interactive perception, annotation and re-use of visual documents."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1729390"
                        ],
                        "name": "Euripides G. M. Petrakis",
                        "slug": "Euripides-G.-M.-Petrakis",
                        "structuredName": {
                            "firstName": "Euripides",
                            "lastName": "Petrakis",
                            "middleNames": [
                                "G.",
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Euripides G. M. Petrakis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1702392"
                        ],
                        "name": "C. Faloutsos",
                        "slug": "C.-Faloutsos",
                        "structuredName": {
                            "firstName": "Christos",
                            "lastName": "Faloutsos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Faloutsos"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6565978,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c162829cd2c6c7bdb55bbd2b67b83dc643ad7602",
            "isKey": false,
            "numCitedBy": 314,
            "numCiting": 50,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a method to handle approximate searching by image content in medical image databases. Image content is represented by attributed relational graphs holding features of objects and relationships between objects. The method relies on the assumption that a fixed number of \"labeled\" or \"expected\" objects (e.g., \"heart\", \"lungs\", etc.) are common in all images of a given application domain in addition to a variable number of \"unexpected\" or \"unlabeled\" objects (e.g., \"tumor\", \"hematoma\", etc.). The method can answer queries by example, such as \"find all X-rays that are similar to Smith's X-ray\". The stored images are mapped to points in a multidimensional space and are indexed using state-of-the-art database methods (R-trees). The proposed method has several desirable properties: (a) Database search is approximate, so that all images up to a prespecified degree of similarity (tolerance) are retrieved. (b) It has no \"false dismissals\" (i.e., all images qualifying query selection criteria are retrieved). (c) It is much faster than sequential scanning for searching in the main memory and on the disk (i.e., by up to an order of magnitude), thus scaling-up well for large databases."
            },
            "slug": "Similarity-Searching-in-Medical-Image-Databases-Petrakis-Faloutsos",
            "title": {
                "fragments": [],
                "text": "Similarity Searching in Medical Image Databases"
            },
            "tldr": {
                "abstractSimilarityScore": 60,
                "text": "The proposed method to handle approximate searching by image content in medical image databases has several desirable properties: it is much faster than sequential scanning for searching in the main memory and on the disk, thus scaling-up well for large databases."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Knowl. Data Eng."
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143874948"
                        ],
                        "name": "T. Tan",
                        "slug": "T.-Tan",
                        "structuredName": {
                            "firstName": "Tieniu",
                            "lastName": "Tan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Tan"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 23824412,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7b1e339ecda8704ce28315706ace62fe39d66f29",
            "isKey": false,
            "numCitedBy": 299,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "Concerns the extraction of rotation invariant texture features and the use of such features in script identification from document images. Rotation invariant texture features are computed based on an extension of the popular multi-channel Gabor filtering technique, and their effectiveness is tested with 300 randomly rotated samples of 15 Brodatz textures. These features are then used in an attempt to solve a practical but hitherto mostly overlooked problem in document image processing-the identification of the script of a machine printed document. Automatic script and language recognition is an essential front-end process for the efficient and correct use of OCR and language translation products in a multilingual environment. Six languages (Chinese, English, Greek, Russian, Persian, and Malayalam) are chosen to demonstrate the potential of such a texture-based approach in script identification."
            },
            "slug": "Rotation-Invariant-Texture-Features-and-Their-Use-Tan",
            "title": {
                "fragments": [],
                "text": "Rotation Invariant Texture Features and Their Use in Automatic Script Identification"
            },
            "tldr": {
                "abstractSimilarityScore": 55,
                "text": "Rotation invariant texture features are computed based on an extension of the popular multi-channel Gabor filtering technique, and their effectiveness is tested with 300 randomly rotated samples of 15 Brodatz textures to solve a practical but hitherto mostly overlooked problem in document image processing."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1780935"
                        ],
                        "name": "B. Moghaddam",
                        "slug": "B.-Moghaddam",
                        "structuredName": {
                            "firstName": "Baback",
                            "lastName": "Moghaddam",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Moghaddam"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144994682"
                        ],
                        "name": "A. Pentland",
                        "slug": "A.-Pentland",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Pentland",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Pentland"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 62028678,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2a951a102456decc53429c64cc39acacc73f16a8",
            "isKey": false,
            "numCitedBy": 21,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a new technique for direct visual matching of images for the purposes of face recognition, database search and image retrieval. Specifically, we argue in favor of a probabilistic measure of similarity, in contrast to simpler methods which are based on standard L/sub 2/ norms (e.g., template matching) or subspace-restricted norms (e.g., eigenspace matching). The proposed similarity measure is based on a Bayesian analysis using two mutually-exclusive classes of image variation as encountered in a typical face recognition task. The high-dimensional probability density functions for each respective class are obtained from training data using an eigenspace density estimation technique and subsequently used to compute a similarity measure based on the relevant a posteriori probability, which is used to rank matches in the database. The performance advantage of this probabilistic matching technique over standard nearest-neighbor eigenspace matching is demonstrated using results from ARPA's 1996 \"FERET\" face recognition competition, in which this algorithm was found to be the top performer by a 10% (or better) margin to the other competitors."
            },
            "slug": "Probabilistic-matching-for-face-recognition-Moghaddam-Pentland",
            "title": {
                "fragments": [],
                "text": "Probabilistic matching for face recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 64,
                "text": "A probabilistic matching technique for direct visual matching of images for the purposes of face recognition, database search and image retrieval that is based on a Bayesian analysis using two mutually-exclusive classes of image variation as encountered in a typical face recognition task."
            },
            "venue": {
                "fragments": [],
                "text": "1998 IEEE Southwest Symposium on Image Analysis and Interpretation (Cat. No.98EX165)"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1803621"
                        ],
                        "name": "A. Khotanzad",
                        "slug": "A.-Khotanzad",
                        "structuredName": {
                            "firstName": "Alireza",
                            "lastName": "Khotanzad",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Khotanzad"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3354183"
                        ],
                        "name": "Yaw Hua Hong",
                        "slug": "Yaw-Hua-Hong",
                        "structuredName": {
                            "firstName": "Yaw",
                            "lastName": "Hong",
                            "middleNames": [
                                "Hua"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yaw Hua Hong"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2176918,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "f12b2b698d586e219bfa07a56615d1cefb8557e1",
            "isKey": false,
            "numCitedBy": 2005,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "The problem of rotation-, scale-, and translation-invariant recognition of images is discussed. A set of rotation-invariant features are introduced. They are the magnitudes of a set of orthogonal complex moments of the image known as Zernike moments. Scale and translation invariance are obtained by first normalizing the image with respect to these parameters using its regular geometrical moments. A systematic reconstruction-based method for deciding the highest-order Zernike moments required in a classification problem is developed. The quality of the reconstructed image is examined through its comparison to the original one. The orthogonality property of the Zernike moments, which simplifies the process of image reconstruction, make the suggest feature selection approach practical. Features of each order can also be weighted according to their contribution to the reconstruction process. The superiority of Zernike moment features over regular moments and moment invariants was experimentally verified. >"
            },
            "slug": "Invariant-Image-Recognition-by-Zernike-Moments-Khotanzad-Hong",
            "title": {
                "fragments": [],
                "text": "Invariant Image Recognition by Zernike Moments"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A systematic reconstruction-based method for deciding the highest-order ZERNike moments required in a classification problem is developed and the superiority of Zernike moment features over regular moments and moment invariants was experimentally verified."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751138"
                        ],
                        "name": "C. Gotlieb",
                        "slug": "C.-Gotlieb",
                        "structuredName": {
                            "firstName": "Calvin",
                            "lastName": "Gotlieb",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Gotlieb"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "69472237"
                        ],
                        "name": "Herbert E. Kreyszig",
                        "slug": "Herbert-E.-Kreyszig",
                        "structuredName": {
                            "firstName": "Herbert",
                            "lastName": "Kreyszig",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Herbert E. Kreyszig"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 26852939,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "7884fd2a503873ae425126d4cb29add2a7452d64",
            "isKey": false,
            "numCitedBy": 292,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Texture-descriptors-based-on-co-occurrence-matrices-Gotlieb-Kreyszig",
            "title": {
                "fragments": [],
                "text": "Texture descriptors based on co-occurrence matrices"
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Vis. Graph. Image Process."
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144644545"
                        ],
                        "name": "G. Healey",
                        "slug": "G.-Healey",
                        "structuredName": {
                            "firstName": "Glenn",
                            "lastName": "Healey",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Healey"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 33605371,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "id": "f1d2664f096dc6443b84d40f05f75b2925237030",
            "isKey": false,
            "numCitedBy": 153,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "We develop a method for recognizing color texture independent of rotation, scale, and illumination. Color texture is modeled using spatial correlation functions defined within and between sensor bands. Using a linear model for surface spectral reflectance with the same number of parameters as the number of sensor classes, we show that illumination and geometry changes in the scene correspond to a linear transformation of the correlation functions and a linear transformation of their coordinates. A several step algorithm that includes scale estimation and correlation moment computation is used to achieve the invariance. The key to the method is the new result that illumination, rotation, and scale changes in the scene correspond to a specific transformation of correlation function Zernike moment matrices. These matrices can be estimated from a color image. This relationship is used to derive an efficient algorithm for recognition. The algorithm is substantiated using classification results on over 200 images of color textures obtained under various illumination conditions and geometric configurations."
            },
            "slug": "Using-Zernike-moments-for-the-illumination-and-of-Healey",
            "title": {
                "fragments": [],
                "text": "Using Zernike moments for the illumination and geometry invariant classification of multispectral texture"
            },
            "tldr": {
                "abstractSimilarityScore": 60,
                "text": "A method for recognizing color texture independent of rotation, scale, and illumination is developed, with the new result that illumination, rotation, and scale changes in the scene correspond to a specific transformation of correlation function Zernike moment matrices."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Image Process."
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1747647"
                        ],
                        "name": "S. Santini",
                        "slug": "S.-Santini",
                        "structuredName": {
                            "firstName": "Simone",
                            "lastName": "Santini",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Santini"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 42563652,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "12f946a54447728ac444121dc88d2769e748e32d",
            "isKey": false,
            "numCitedBy": 17,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents some methodological observations on the measurement of performance in Visual Information Retrieval systems. The paper identifies three different types of measures tow of which can be determined with methods inherited from physical and social sciences respectively. The third model is more typical of the design and construction of complicated systems, since it allows us to measure the performance of individual modules before their insertion in a particular application. This paper present some methodologies for the decontextualized evaluation, anchoring them to a case study of evaluation of several subsystems of an image database."
            },
            "slug": "Evaluation-vademecum-for-visual-information-system-Santini",
            "title": {
                "fragments": [],
                "text": "Evaluation vademecum for visual information system"
            },
            "tldr": {
                "abstractSimilarityScore": 53,
                "text": "Some methodologies for the decontextualized evaluation for Visual Information Retrieval systems are presented, anchoring them to a case study of evaluation of several subsystems of an image database."
            },
            "venue": {
                "fragments": [],
                "text": "Electronic Imaging"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2102138"
                        ],
                        "name": "Tolga Bozkaya",
                        "slug": "Tolga-Bozkaya",
                        "structuredName": {
                            "firstName": "Tolga",
                            "lastName": "Bozkaya",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tolga Bozkaya"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695700"
                        ],
                        "name": "Z. M. \u00d6zsoyoglu",
                        "slug": "Z.-M.-\u00d6zsoyoglu",
                        "structuredName": {
                            "firstName": "Z.",
                            "lastName": "\u00d6zsoyoglu",
                            "middleNames": [
                                "Meral"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Z. M. \u00d6zsoyoglu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6292100,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c515a7cb784b8e5a14c6a405c08df19c91637196",
            "isKey": false,
            "numCitedBy": 368,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "In many database applications, one of the common queries is to find approximate matches to a given query item from a collection of data items. For example, given an image database, one may want to retrieve all images that are similar to a given query image. Distance based index structures are proposed for applications where the data domain is high dimensional, or the distance function used to compute distances between data objects is non-Euclidean. In this paper, we introduce a distance based index structure called multi-vantage point (mvp) tree for similarity queries on high-dimensional metric spaces. The mvp-tree uses more than one vantage point to partition the space into spherical cuts at each level. It also utilizes the pre-computed (at construction time) distances between the data points and the vantage points. We have done experiments to compare mvp-trees with vp-trees which have a similar partitioning strategy, but use only one vantage point at each level, and do not make use of the pre-computed distances. Empirical studies show that mvp-tree outperforms the vp-tree 20% to 80% for varying query ranges and different distance distributions."
            },
            "slug": "Distance-based-indexing-for-high-dimensional-metric-Bozkaya-\u00d6zsoyoglu",
            "title": {
                "fragments": [],
                "text": "Distance-based indexing for high-dimensional metric spaces"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This paper introduces a distance based index structure called multi-vantage point (mvp) tree for similarity queries on high-dimensional metric spaces and shows that mvp-tree outperforms the vp-tree 20% to 80% for varying query ranges and different distance distributions."
            },
            "venue": {
                "fragments": [],
                "text": "SIGMOD '97"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1760994"
                        ],
                        "name": "R. Basri",
                        "slug": "R.-Basri",
                        "structuredName": {
                            "firstName": "Ronen",
                            "lastName": "Basri",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Basri"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153159931"
                        ],
                        "name": "Luiz A. Costa",
                        "slug": "Luiz-A.-Costa",
                        "structuredName": {
                            "firstName": "Luiz",
                            "lastName": "Costa",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Luiz A. Costa"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "14489533"
                        ],
                        "name": "D. Geiger",
                        "slug": "D.-Geiger",
                        "structuredName": {
                            "firstName": "D.",
                            "lastName": "Geiger",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Geiger"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34734622"
                        ],
                        "name": "D. Jacobs",
                        "slug": "D.-Jacobs",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Jacobs",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Jacobs"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 16105092,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "723696d3b45dedcc7db4e609dfce04e53202f363",
            "isKey": false,
            "numCitedBy": 194,
            "numCiting": 110,
            "paperAbstract": {
                "fragments": [],
                "text": "Determining the similarity of two shapes is a significant task in both machine and human vision systems that must recognize or classify objects. The exact properties of human shape similarity judgements are not well understood yet, and this task is particularly difficult in domains where the shapes are not related by rigid transformation. In this paper we identify a number of possibly desirable properties of a shape similarity method, and determine the extent to which these properties can be captured by approaches that compare local properties of the contours of the shapes, through elastic matching. Special attention is devoted to objects that possess articulations, i.e. articulated parts. Elastic matching evaluates the similarity of two shapes as the sum of local deformations needed to change one shape into another. We show that similarities of part structure can be captured by such an approach, without the explicit computation of part structure. This may be of importance, since although parts appear to play a significant role in visual recognition, it is difficult to stably determine part structure. We also show novel results about how one can evaluate smooth and polyhedral shapes with the same method. Finally, we describe shape similarity effects that cannot be handled by current approaches."
            },
            "slug": "Determining-the-similarity-of-deformable-shapes-Basri-Costa",
            "title": {
                "fragments": [],
                "text": "Determining the similarity of deformable shapes"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This paper identifies a number of possibly desirable properties of a shape similarity method, and determines the extent to which these properties can be captured by approaches that compare local properties of the contours of the shapes, through elastic matching."
            },
            "venue": {
                "fragments": [],
                "text": "Vision Research"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1932191"
                        ],
                        "name": "Greet Frederix",
                        "slug": "Greet-Frederix",
                        "structuredName": {
                            "firstName": "Greet",
                            "lastName": "Frederix",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Greet Frederix"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2382063"
                        ],
                        "name": "G. Caenen",
                        "slug": "G.-Caenen",
                        "structuredName": {
                            "firstName": "Geert",
                            "lastName": "Caenen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Caenen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3266794"
                        ],
                        "name": "E. Pauwels",
                        "slug": "E.-Pauwels",
                        "structuredName": {
                            "firstName": "Eric",
                            "lastName": "Pauwels",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Pauwels"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 14682893,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "753faa09bbc99943d7f1d7945775a6dd40d161b2",
            "isKey": false,
            "numCitedBy": 21,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "We outline the architecture of a content-based image retrieval (CBIR)-interface that offers the user a graphical tool to create new features by showing (as opposed to telling!) the system what he means. It allows him to interactively classify images by dragging and dropping them into different piles and instructing the interface to come up with features that can mimic this classification. We show how logistic regression and Sammon projection can be used to supervise this search mode."
            },
            "slug": "Panoramic,-adaptive-and-reconfigurable-interface-Frederix-Caenen",
            "title": {
                "fragments": [],
                "text": "Panoramic, adaptive and reconfigurable interface for similarity search"
            },
            "tldr": {
                "abstractSimilarityScore": 95,
                "text": "The architecture of a content-based image retrieval (CBIR)-interface that offers the user a graphical tool to create new features by showing (as opposed to telling!) the system what he means is outlined."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings 2000 International Conference on Image Processing (Cat. No.00CH37101)"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712167"
                        ],
                        "name": "Wei-Ying Ma",
                        "slug": "Wei-Ying-Ma",
                        "structuredName": {
                            "firstName": "Wei-Ying",
                            "lastName": "Ma",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wei-Ying Ma"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50591689"
                        ],
                        "name": "B. S. Manjunath",
                        "slug": "B.-S.-Manjunath",
                        "structuredName": {
                            "firstName": "B.",
                            "lastName": "Manjunath",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. S. Manjunath"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2056985,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "97d9d482881a62253e575ac7ace540181ba55bbf",
            "isKey": false,
            "numCitedBy": 278,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "A novel boundary detection scheme based on \"edge flow\" is proposed in this paper. This scheme utilizes a predictive coding model to identify the direction of change in color and texture at each image location at a given scale, and constructs an edge flow vector. By iteratively propagating the edge flow, the boundaries can be detected at image locations which encounter two opposite directions of flow in the stable state. A user defined image scale is the only significant control parameter that is needed by the algorithm. The scheme facilitates integration of color and texture into a single framework for boundary detection."
            },
            "slug": "Edge-flow:-A-framework-of-boundary-detection-and-Ma-Manjunath",
            "title": {
                "fragments": [],
                "text": "Edge flow: A framework of boundary detection and image segmentation"
            },
            "tldr": {
                "abstractSimilarityScore": 85,
                "text": "A novel boundary detection scheme based on \"edge flow\" that utilizes a predictive coding model to identify the direction of change in color and texture at each image location at a given scale, and constructs an edge flow vector."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3195445"
                        ],
                        "name": "Ronald-Bryan O. Alferez",
                        "slug": "Ronald-Bryan-O.-Alferez",
                        "structuredName": {
                            "firstName": "Ronald-Bryan",
                            "lastName": "Alferez",
                            "middleNames": [
                                "O."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ronald-Bryan O. Alferez"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47904091"
                        ],
                        "name": "Yuan-fang Wang",
                        "slug": "Yuan-fang-Wang",
                        "structuredName": {
                            "firstName": "Yuan-fang",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yuan-fang Wang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 11113191,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "d989954202999f92fd55fc961aa2546228b52650",
            "isKey": false,
            "numCitedBy": 100,
            "numCiting": 70,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose invariant formulations that can potentially be combined into a single system. In particular, we describe a framework for computing invariant features which are insensitive to rigid motion, affine transform, changes of parameterization and scene illumination, perspective transform, and view point change. This is unlike most current research on image invariants which concentrates on either geometric or illumination invariants exclusively. The formulations are widely applicable to many popular basis representations, such as wavelets, short-time Fourier analysis, and splines. Exploiting formulations that examine information about shape and color at different resolution levels, the new approach is neither strictly global nor local. It enables a quasi-localized, hierarchical shape analysis which is rarely found in other known invariant techniques, such as global invariants. Furthermore, it does not require estimating high-order derivatives in computing invariants (unlike local invariants), whence is more robust. We provide results of numerous experiments on both synthetic and real data to demonstrate the validity and flexibility of the proposed framework."
            },
            "slug": "Geometric-and-Illumination-Invariants-for-Object-Alferez-Wang",
            "title": {
                "fragments": [],
                "text": "Geometric and Illumination Invariants for Object Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 66,
                "text": "A framework for computing invariant features which are insensitive to rigid motion, affine transform, changes of parameterization and scene illumination, perspective transform, and view point change is described, unlike most current research on image invariants which concentrates on either geometric or illumination invariants exclusively."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "82910116"
                        ],
                        "name": "H. Murase",
                        "slug": "H.-Murase",
                        "structuredName": {
                            "firstName": "Hiroshi",
                            "lastName": "Murase",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Murase"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1750470"
                        ],
                        "name": "S. Nayar",
                        "slug": "S.-Nayar",
                        "structuredName": {
                            "firstName": "Shree",
                            "lastName": "Nayar",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Nayar"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 61999742,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c5648d1f511a5180cc0bf7af80a42d3dea3a4680",
            "isKey": false,
            "numCitedBy": 322,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "The authors address the problem of automatically learning object models for recognition and pose estimation. In contrast to the traditional approach, they formulate the recognition problem as one of matching visual appearance rather than shape. The appearance of an object in a two-dimensional image depends on its shape, reflectance properties, pose in the scene, and the illumination conditions. While shape and reflectance are intrinsic properties of an object and are constant, pose and illumination vary from scene to scene. They present a new compact representation of object appearance that is parameterized by pose and illumination. They have conducted experiments using several objects with complex appearance characteristics.<<ETX>>"
            },
            "slug": "Learning-and-recognition-of-3D-objects-from-Murase-Nayar",
            "title": {
                "fragments": [],
                "text": "Learning and recognition of 3D objects from appearance"
            },
            "tldr": {
                "abstractSimilarityScore": 68,
                "text": "The authors address the problem of automatically learning object models for recognition and pose estimation as one of matching visual appearance rather than shape and present a new compact representation of object appearance that is parameterized by pose and illumination."
            },
            "venue": {
                "fragments": [],
                "text": "[1993] Proceedings IEEE Workshop on Qualitative Vision"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47246616"
                        ],
                        "name": "R. Brunelli",
                        "slug": "R.-Brunelli",
                        "structuredName": {
                            "firstName": "Roberto",
                            "lastName": "Brunelli",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Brunelli"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1987419"
                        ],
                        "name": "O. Mich",
                        "slug": "O.-Mich",
                        "structuredName": {
                            "firstName": "Ornella",
                            "lastName": "Mich",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Mich"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2389886"
                        ],
                        "name": "C. M. Modena",
                        "slug": "C.-M.-Modena",
                        "structuredName": {
                            "firstName": "Carla",
                            "lastName": "Modena",
                            "middleNames": [
                                "Maria"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. M. Modena"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 46516873,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7a12d8c63d8536fbf20ccecfa68aac5aa09d0d1d",
            "isKey": false,
            "numCitedBy": 280,
            "numCiting": 107,
            "paperAbstract": {
                "fragments": [],
                "text": "Today a considerable amount of video data in multimedia databases requires sophisticated indices for its effective use. Manual indexing is the most effective method to do this, but it is also the slowest and the most expensive. Automated methods have then to be developed. This paper surveys several approaches and algorithms that have been recently proposed to automatically structure audio?visual data, both for annotation and access."
            },
            "slug": "A-Survey-on-the-Automatic-Indexing-of-Video-Data,-Brunelli-Mich",
            "title": {
                "fragments": [],
                "text": "A Survey on the Automatic Indexing of Video Data,"
            },
            "tldr": {
                "abstractSimilarityScore": 37,
                "text": "This paper surveys several approaches and algorithms that have been recently proposed to automatically structure audio?visual data, both for annotation and access."
            },
            "venue": {
                "fragments": [],
                "text": "J. Vis. Commun. Image Represent."
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145295484"
                        ],
                        "name": "Anil K. Jain",
                        "slug": "Anil-K.-Jain",
                        "structuredName": {
                            "firstName": "Anil",
                            "lastName": "Jain",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Anil K. Jain"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1747298"
                        ],
                        "name": "R. Duin",
                        "slug": "R.-Duin",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Duin",
                            "middleNames": [
                                "P.",
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Duin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "4723637"
                        ],
                        "name": "J. Mao",
                        "slug": "J.-Mao",
                        "structuredName": {
                            "firstName": "Jianchang",
                            "lastName": "Mao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Mao"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 192934,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3626f388371b678b2f02f6eefc44fa5abc53ceb3",
            "isKey": false,
            "numCitedBy": 6533,
            "numCiting": 473,
            "paperAbstract": {
                "fragments": [],
                "text": "The primary goal of pattern recognition is supervised or unsupervised classification. Among the various frameworks in which pattern recognition has been traditionally formulated, the statistical approach has been most intensively studied and used in practice. More recently, neural network techniques and methods imported from statistical learning theory have been receiving increasing attention. The design of a recognition system requires careful attention to the following issues: definition of pattern classes, sensing environment, pattern representation, feature extraction and selection, cluster analysis, classifier design and learning, selection of training and test samples, and performance evaluation. In spite of almost 50 years of research and development in this field, the general problem of recognizing complex patterns with arbitrary orientation, location, and scale remains unsolved. New and emerging applications, such as data mining, web searching, retrieval of multimedia data, face recognition, and cursive handwriting recognition, require robust and efficient pattern recognition techniques. The objective of this review paper is to summarize and compare some of the well-known methods used in various stages of a pattern recognition system and identify research topics and applications which are at the forefront of this exciting and challenging field."
            },
            "slug": "Statistical-Pattern-Recognition:-A-Review-Jain-Duin",
            "title": {
                "fragments": [],
                "text": "Statistical Pattern Recognition: A Review"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "The objective of this review paper is to summarize and compare some of the well-known methods used in various stages of a pattern recognition system and identify research topics and applications which are at the forefront of this exciting and challenging field."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1900283"
                        ],
                        "name": "Pierre Martin Tardif",
                        "slug": "Pierre-Martin-Tardif",
                        "structuredName": {
                            "firstName": "Pierre Martin",
                            "lastName": "Tardif",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Pierre Martin Tardif"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1771371"
                        ],
                        "name": "A. Zaccarin",
                        "slug": "A.-Zaccarin",
                        "structuredName": {
                            "firstName": "Andr\u00e9",
                            "lastName": "Zaccarin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Zaccarin"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 121104066,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "81de76e422eb87bc56afad234ed0b7cd1aa6f391",
            "isKey": false,
            "numCitedBy": 11,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "Texture segmentation or modeling plays an important role in image segmentation. In this paper, we investigate multiscale autoregressive representation for texture modeling and segmentation. The proposed algorithm also uses a multiresolution decomposition of an image, and fits an AR model to each image of the multiresolution pyramid. The set of AR coefficient vectors, one at each level, defines a model for a texture and this model is used as a predictor for the segmentation process. AR coefficient vectors are used to generate a prediction of the image pyramid, from which the prediction of the image to model is built. The resulting prediction error is used to discriminate textures in a segmentation algorithm. In the proposed structure, feedback can be included between pyramid levels by adding the prediction error at he previous level to the current level before an AR model fitting. M-AR can therefore be used as a predictor like an AR model. This is different from previous multiscale approaches for which data is used at each scale for the segmentation. Since we do not need to link data from different scales, this simplifies model processing for segmentation. The estimation error of the proposed multiscale AR approach has lower variance than that of an AR model, and is less correlated. Segmentation results also show M-AR to be an improvement to AR modeling."
            },
            "slug": "Multiscale-autoregressive-image-representation-for-Tardif-Zaccarin",
            "title": {
                "fragments": [],
                "text": "Multiscale autoregressive image representation for texture segmentation"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "The estimation error of the proposed multiscale AR approach has lower variance than that of an AR model, and is less correlated, and segmentation results show M-AR to be an improvement to AR modeling."
            },
            "venue": {
                "fragments": [],
                "text": "Electronic Imaging"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1747647"
                        ],
                        "name": "S. Santini",
                        "slug": "S.-Santini",
                        "structuredName": {
                            "firstName": "Simone",
                            "lastName": "Santini",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Santini"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 16388031,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "00f1dbf30760a3b0a61f30075300f06a75230c6d",
            "isKey": false,
            "numCitedBy": 11,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents some methodological observations on the measurement of performance in Visual Information Retrieval (VIR) systems. The paper identifies three different types of measures two of which (Physical Performance and Contextual Evaluation) can be determined with methods inherited from physical and social sciences respectively. The third model (Decontextualized Evaluation) is more typical of the design and construction of complicated systems, since it allows us to measure the performance of individual modules before their insertion in a particular application. This paper presents some methodologies for the decontextualized evaluation, anchoring them to a case studies of evaluation of several subsystems of an image database."
            },
            "slug": "Evaluation-Vademecum-for-Visual-information-Santini",
            "title": {
                "fragments": [],
                "text": "Evaluation Vademecum for Visual information Systems\u2217"
            },
            "tldr": {
                "abstractSimilarityScore": 57,
                "text": "This paper presents some methodologies for the decontextualized evaluation, anchoring them to a case studies of evaluation of several subsystems of an image database."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1722619"
                        ],
                        "name": "Amarnath Gupta",
                        "slug": "Amarnath-Gupta",
                        "structuredName": {
                            "firstName": "Amarnath",
                            "lastName": "Gupta",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Amarnath Gupta"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144938740"
                        ],
                        "name": "R. Jain",
                        "slug": "R.-Jain",
                        "structuredName": {
                            "firstName": "Ramesh",
                            "lastName": "Jain",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Jain"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 15984449,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "45ce9d12be58f15f5a1ff3325a67d57f1f04732e",
            "isKey": false,
            "numCitedBy": 482,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "New updated! The latest book from a very famous author finally comes out. Book of visual information retrieval, as an amazing reference becomes what you need to get. What's for is this book? Are you still thinking for what the book is? Well, this is what you probably will get. You should have made proper choices for your better life. Book, as a source that may involve the facts, opinion, literature, religion, and many others are the great friends to join with."
            },
            "slug": "Visual-information-retrieval-Gupta-Jain",
            "title": {
                "fragments": [],
                "text": "Visual information retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 55,
                "text": "Book of visual information retrieval, as an amazing reference becomes what you need to get, and book, as a source that may involve the facts, opinion, literature, religion, and many others are the great friends to join with."
            },
            "venue": {
                "fragments": [],
                "text": "CACM"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144938740"
                        ],
                        "name": "R. Jain",
                        "slug": "R.-Jain",
                        "structuredName": {
                            "firstName": "Ramesh",
                            "lastName": "Jain",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Jain"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 60531015,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d566de3ef0cf856556a66c622495a69ab1371565",
            "isKey": false,
            "numCitedBy": 36,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "Infoscopes will be the microscopes and telescopes of the information systems of the future. The emergence of information highways and multimedia computing has resulted in exponential growth in the availability of multimedia data. Most information in computers used to be alphanumeric. Increasingly information has been appearing in graphic, image, audio, and video forms. Many approaches are being proposed for storing, retrieving, assimilating, harvesting, and prospecting information from disparate data sources. Infoscopes will allow users to access information independent of the locations and types of data sources and will provide a unified picture of information to a user. Due to their ability to represent information at different levels of abstractions these systems must recover and assimilate information from disparate sources. In this chapter, we discuss requirements of these emerging information systems. We discuss basic architecture and data models for these systems. Finally, we briefly present a few examples of early infoscopes."
            },
            "slug": "Infoscopes:-Multimedia-Information-Systems-Jain",
            "title": {
                "fragments": [],
                "text": "Infoscopes: Multimedia Information Systems"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "This chapter discusses requirements of these emerging information systems, basic architecture and data models for these systems, and briefly presents a few examples of early infoscopes."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2081718"
                        ],
                        "name": "M. Stricker",
                        "slug": "M.-Stricker",
                        "structuredName": {
                            "firstName": "Markus",
                            "lastName": "Stricker",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Stricker"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2987811"
                        ],
                        "name": "M. Swain",
                        "slug": "M.-Swain",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Swain",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Swain"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2611693,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3728e15c52157050b9fca3dac38c2ae229c9d63d",
            "isKey": false,
            "numCitedBy": 148,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "Color histogram matching has been shown to be a promising way of quickly indexing into a large image database. Yet, few experiments have been done to test the method on truly large databases, and even if they were performed, they would give little guidance to a user wondering if the technique would be useful with his or her database. In this paper we define and analyze a measure relevant to extending color histogram indexing to large databases: capacity (how many distinguishable histograms can be stored).<<ETX>>"
            },
            "slug": "The-capacity-of-color-histogram-indexing-Stricker-Swain",
            "title": {
                "fragments": [],
                "text": "The capacity of color histogram indexing"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A measure relevant to extending color histogram indexing to large databases: capacity (how many distinguishable histograms can be stored) is defined and analyzed."
            },
            "venue": {
                "fragments": [],
                "text": "1994 Proceedings of IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1686678"
                        ],
                        "name": "L. Latecki",
                        "slug": "L.-Latecki",
                        "structuredName": {
                            "firstName": "Longin",
                            "lastName": "Latecki",
                            "middleNames": [
                                "Jan"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Latecki"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1889149"
                        ],
                        "name": "Rolf Lak\u00e4mper",
                        "slug": "Rolf-Lak\u00e4mper",
                        "structuredName": {
                            "firstName": "Rolf",
                            "lastName": "Lak\u00e4mper",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Rolf Lak\u00e4mper"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 632458,
            "fieldsOfStudy": [
                "Art"
            ],
            "id": "21d02ff71b8c80c83675ab7767a2c1bcdb546efc",
            "isKey": false,
            "numCitedBy": 399,
            "numCiting": 58,
            "paperAbstract": {
                "fragments": [],
                "text": "We concentrate here on decomposition of 2D objects into meaningfulparts of visual form, orvisual parts. It is a simple observation that convex parts of objects determine visual parts. However, the problem is that many significant visual parts are not convex, since a visual part may have concavities. We solve this problem by identifying convex parts at different stages of a proposed contour evolution method in which significant visual parts will become convex object parts at higher stages of the evolution. We obtain a novel rule for decomposition of 2D objects into visual parts, called the hierarchical convexity rule, which states that visual parts are enclosed by maximal convex (with respect to the object) boundary arcs at different stages of the contour evolution. This rule determines not only parts of boundary curves but directly the visual parts of objects. Moreover, the stages of the evolution hierarchy induce a hierarchical structure of the visual parts. The more advanced the stage of contour evolution, the more significant is the shape contribution of the obtained visual parts."
            },
            "slug": "Convexity-Rule-for-Shape-Decomposition-Based-on-Latecki-Lak\u00e4mper",
            "title": {
                "fragments": [],
                "text": "Convexity Rule for Shape Decomposition Based on Discrete Contour Evolution"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A novel rule is obtained, called the hierarchical convexity rule, which states that visual parts are enclosed by maximal convex (with respect to the object) boundary arcs at different stages of the contour evolution."
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Vis. Image Underst."
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1720149"
                        ],
                        "name": "J. Geusebroek",
                        "slug": "J.-Geusebroek",
                        "structuredName": {
                            "firstName": "Jan-Mark",
                            "lastName": "Geusebroek",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Geusebroek"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144638781"
                        ],
                        "name": "A. Smeulders",
                        "slug": "A.-Smeulders",
                        "structuredName": {
                            "firstName": "Arnold",
                            "lastName": "Smeulders",
                            "middleNames": [
                                "W.",
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Smeulders"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2287885"
                        ],
                        "name": "R. Boomgaard",
                        "slug": "R.-Boomgaard",
                        "structuredName": {
                            "firstName": "Rein",
                            "lastName": "Boomgaard",
                            "middleNames": [
                                "van",
                                "den"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Boomgaard"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1597117,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "fb0668d88721a7eb4244f8071ecc34766301ac88",
            "isKey": false,
            "numCitedBy": 28,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents the measurement of object reflectance from color images. We exploit the Gaussian scale-space paradigm to define framework for the robust measurement of object reflectance from color images. Illumination and geometrical invariant properties are derived from a physical reflectance model based on the Kubelka-Munk theory. Imaging conditions are assumed to be white illumination and matte, dull object or general object, respectively. Invariance is denoted by +, whereas sensitivity to the imaging condition is indicated by -. Invariance, discriminative power and localization accuracy of the color invariants is extensively investigated, showing the invariants to be successful in discounting shadow, illumination intensity, highlights, and noise. Experiments show the different invariants to be highly discriminative while maintaining invariance properties. The presented framework for color measurement is well-founded in physics as well as measurement science. The framework is thoroughly evaluated experimentally. Hence is considered more adequate than existing methods for the measurement of invariant color features."
            },
            "slug": "Measurement-of-color-invariants-Geusebroek-Smeulders",
            "title": {
                "fragments": [],
                "text": "Measurement of color invariants"
            },
            "tldr": {
                "abstractSimilarityScore": 59,
                "text": "The Gaussian scale-space paradigm is exploited to define framework for the robust measurement of object reflectance from color images, showing the invariants to be successful in discounting shadow, illumination intensity, highlights, and noise."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings IEEE Conference on Computer Vision and Pattern Recognition. CVPR 2000 (Cat. No.PR00662)"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1911372"
                        ],
                        "name": "T. Randen",
                        "slug": "T.-Randen",
                        "structuredName": {
                            "firstName": "Trygve",
                            "lastName": "Randen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Randen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31557075"
                        ],
                        "name": "J. H. Hus\u00f8y",
                        "slug": "J.-H.-Hus\u00f8y",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Hus\u00f8y",
                            "middleNames": [
                                "H\u00e5kon"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. H. Hus\u00f8y"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 17026785,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "8c3ae83da4542257971c4033087bcd7eb33465a6",
            "isKey": false,
            "numCitedBy": 1620,
            "numCiting": 50,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we review most major filtering approaches to texture feature extraction and perform a comparative study. Filtering approaches included are Laws masks (1980), ring/wedge filters, dyadic Gabor filter banks, wavelet transforms, wavelet packets and wavelet frames, quadrature mirror filters, discrete cosine transform, eigenfilters, optimized Gabor filters, linear predictors, and optimized finite impulse response filters. The features are computed as the local energy of the filter responses. The effect of the filtering is highlighted, keeping the local energy function and the classification algorithm identical for most approaches. For reference, comparisons with two classical nonfiltering approaches, co-occurrence (statistical) and autoregressive (model based) features, are given. We present a ranking of the tested approaches based on extensive experiments."
            },
            "slug": "Filtering-for-Texture-Classification:-A-Comparative-Randen-Hus\u00f8y",
            "title": {
                "fragments": [],
                "text": "Filtering for Texture Classification: A Comparative Study"
            },
            "tldr": {
                "abstractSimilarityScore": 50,
                "text": "Most major filtering approaches to texture feature extraction are reviewed and a ranking of the tested approaches based on extensive experiments is presented, showing the effect of the filtering is highlighted, keeping the local energy function and the classification algorithm identical for most approaches."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1747647"
                        ],
                        "name": "S. Santini",
                        "slug": "S.-Santini",
                        "structuredName": {
                            "firstName": "Simone",
                            "lastName": "Santini",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Santini"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144938740"
                        ],
                        "name": "R. Jain",
                        "slug": "R.-Jain",
                        "structuredName": {
                            "firstName": "Ramesh",
                            "lastName": "Jain",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Jain"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 11196857,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "838962cef6bf99c2b99afb26dc5d6cf82366ef20",
            "isKey": false,
            "numCitedBy": 821,
            "numCiting": 42,
            "paperAbstract": {
                "fragments": [],
                "text": "With complex multimedia data, we see the emergence of database systems in which the fundamental operation is similarity assessment. Before database issues can be addressed, it is necessary to give a definition of similarity as an operation. We develop a similarity measure, based on fuzzy logic, that exhibits several features that match experimental findings in humans. The model is dubbed fuzzy feature contrast (FFC) and is an extension to a more general domain of the feature contrast model due to Tversky (1977). We show how the FFC model can be used to model similarity assessment from fuzzy judgment of properties, and we address the use of fuzzy measures to deal with dependencies among the properties."
            },
            "slug": "Similarity-Measures-Santini-Jain",
            "title": {
                "fragments": [],
                "text": "Similarity Measures"
            },
            "tldr": {
                "abstractSimilarityScore": 37,
                "text": "A similarity measure is developed, based on fuzzy logic, that exhibits several features that match experimental findings in humans and is an extension to a more general domain of the feature contrast model due to Tversky (1977)."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3205375"
                        ],
                        "name": "T. Lindeberg",
                        "slug": "T.-Lindeberg",
                        "structuredName": {
                            "firstName": "Tony",
                            "lastName": "Lindeberg",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Lindeberg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2270435"
                        ],
                        "name": "J. Eklundh",
                        "slug": "J.-Eklundh",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Eklundh",
                            "middleNames": [
                                "O."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Eklundh"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 39976883,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "0a64959c1e13b88f7279c5cd2f213aa89df611e4",
            "isKey": false,
            "numCitedBy": 48,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Scale-space-primal-sketch:-construction-and-Lindeberg-Eklundh",
            "title": {
                "fragments": [],
                "text": "Scale-space primal sketch: construction and experiments"
            },
            "venue": {
                "fragments": [],
                "text": "Image Vis. Comput."
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "98770778"
                        ],
                        "name": "G. V. D. Heijden",
                        "slug": "G.-V.-D.-Heijden",
                        "structuredName": {
                            "firstName": "Geric",
                            "lastName": "Heijden",
                            "middleNames": [
                                "van",
                                "der"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. V. D. Heijden"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1717056"
                        ],
                        "name": "M. Worring",
                        "slug": "M.-Worring",
                        "structuredName": {
                            "firstName": "Marcel",
                            "lastName": "Worring",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Worring"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 14162527,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "96758e276bbe51d4cf108427d60e50b05437106a",
            "isKey": false,
            "numCitedBy": 6,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "The most intuitive way of retrieving images is on the basis of domain concepts. However, this requires a mapping between the concepts and the content of the image. Such a mapping should be based on a proper visual guideline. We illustrate this with plant variety testing as an application for which such guidelines are available. The methods seem to have general applicability for every application domain where such guidelines can be made."
            },
            "slug": "Domain-Concept-to-Feature-Mapping-for-a-Plant-Image-Heijden-Worring",
            "title": {
                "fragments": [],
                "text": "Domain Concept to Feature Mapping for a Plant Variety Image Database"
            },
            "tldr": {
                "abstractSimilarityScore": 90,
                "text": "The most intuitive way of retrieving images is on the basis of domain concepts, but this requires a mapping between the concepts and the content of the image, which should be based on a proper visual guideline."
            },
            "venue": {
                "fragments": [],
                "text": "Image Databases and Multi-Media Search"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1689798"
                        ],
                        "name": "P. Ciaccia",
                        "slug": "P.-Ciaccia",
                        "structuredName": {
                            "firstName": "Paolo",
                            "lastName": "Ciaccia",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Ciaccia"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1742653"
                        ],
                        "name": "M. Patella",
                        "slug": "M.-Patella",
                        "structuredName": {
                            "firstName": "Marco",
                            "lastName": "Patella",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Patella"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1701332"
                        ],
                        "name": "P. Zezula",
                        "slug": "P.-Zezula",
                        "structuredName": {
                            "firstName": "Pavel",
                            "lastName": "Zezula",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Zezula"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15393774,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7576f59f5b78b9b34f8df872243400df18949b25",
            "isKey": false,
            "numCitedBy": 1852,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "A new access method, called M-tree, is proposed to organize and search large data sets from a generic \u201cmetric space\u201d, i.e. where object proximity is only defined by a distance function satisfying the positivity, symmetry, and triangle inequality postulates. We detail algorithms for insertion of objects and split management, which keep the M-tree always balanced - several heuristic split alternatives are considered and experimentally evaluated. Algorithms for similarity (range and k-nearest neighbors) queries are also described. Results from extensive experimentation with a prototype system are reported, considering as the performance criteria the number of page I/O\u2019s and the number of distance computations. The results demonstrate that the Mtree indeed extends the domain of applicability beyond the traditional vector spaces, performs reasonably well in high-dimensional data spaces, and scales well in case of growing files."
            },
            "slug": "M-tree:-An-Efficient-Access-Method-for-Similarity-Ciaccia-Patella",
            "title": {
                "fragments": [],
                "text": "M-tree: An Efficient Access Method for Similarity Search in Metric Spaces"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "The results demonstrate that the Mtree indeed extends the domain of applicability beyond the traditional vector spaces, performs reasonably well in high-dimensional data spaces, and scales well in case of growing files."
            },
            "venue": {
                "fragments": [],
                "text": "VLDB"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "4723637"
                        ],
                        "name": "J. Mao",
                        "slug": "J.-Mao",
                        "structuredName": {
                            "firstName": "Jianchang",
                            "lastName": "Mao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Mao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145295484"
                        ],
                        "name": "Anil K. Jain",
                        "slug": "Anil-K.-Jain",
                        "structuredName": {
                            "firstName": "Anil",
                            "lastName": "Jain",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Anil K. Jain"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 11686184,
            "fieldsOfStudy": [
                "Mathematics",
                "Environmental Science",
                "Computer Science"
            ],
            "id": "0b1c14ccf1aad87f215bfa5c6678d975d44ffb3a",
            "isKey": false,
            "numCitedBy": 795,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Texture-classification-and-segmentation-using-Mao-Jain",
            "title": {
                "fragments": [],
                "text": "Texture classification and segmentation using multiresolution simultaneous autoregressive models"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit."
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3304188"
                        ],
                        "name": "B. Funt",
                        "slug": "B.-Funt",
                        "structuredName": {
                            "firstName": "Brian",
                            "lastName": "Funt",
                            "middleNames": [
                                "V."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Funt"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1789486"
                        ],
                        "name": "G. Finlayson",
                        "slug": "G.-Finlayson",
                        "structuredName": {
                            "firstName": "Graham",
                            "lastName": "Finlayson",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Finlayson"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 37339880,
            "fieldsOfStudy": [
                "Art"
            ],
            "id": "11c4c7af9938b05b366c93aea70ad4e5075f6148",
            "isKey": false,
            "numCitedBy": 694,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "Objects can be recognized on the basis of their color alone by color indexing, a technique developed by Swain-Ballard (1991) which involves matching color-space histograms. Color indexing fails, however, when the incident illumination varies either spatially or spectrally. Although this limitation might be overcome by preprocessing with a color constancy algorithm, we instead propose histogramming color ratios. Since the ratios of color RGB triples from neighboring locations are relatively insensitive to changes in the incident illumination, this circumvents the need for color constancy preprocessing. Results of tests with the new color-constant-color-indexing algorithm on synthetic and real images show that it works very well even when the illumination varies spatially in its intensity and color. >"
            },
            "slug": "Color-Constant-Color-Indexing-Funt-Finlayson",
            "title": {
                "fragments": [],
                "text": "Color Constant Color Indexing"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "Results of tests with the new color-constant-color-indexing algorithm show that it works very well even when the illumination varies spatially in its intensity and color, which circumvents the need for color constancy preprocessing."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2178243"
                        ],
                        "name": "K. Hirata",
                        "slug": "K.-Hirata",
                        "structuredName": {
                            "firstName": "Kyoji",
                            "lastName": "Hirata",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Hirata"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2107863091"
                        ],
                        "name": "T. Kato",
                        "slug": "T.-Kato",
                        "structuredName": {
                            "firstName": "T.",
                            "lastName": "Kato",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kato"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 59776850,
            "fieldsOfStudy": [
                "Chemistry"
            ],
            "id": "a41f2f48293def0bc1d5fc9567efb073864d45f5",
            "isKey": false,
            "numCitedBy": 45,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "A silicone compound of the formula, WHERE L is selected from secondary amine groups and R10 groups, R1 and R2 are selected from hydrocarbon groups and R3 and R4 are selected from hydrogen, hydrocarbon groups and other amine groups. Further, n is a whole number that varies from 1 to 20 and a is a whole number that varies from 0 to 2. These amino-functional silane compounds may be used as sewage flocculents."
            },
            "slug": "Rough-sketch-based-image-information-retrieval-Hirata-Kato",
            "title": {
                "fragments": [],
                "text": "Rough sketch-based image information retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 77,
                "text": "A silicone compound of the formula, WHERE L is selected from secondary amine groups and R10 groups, R1 and R2 are selected from hydrocarbon groups, and these amino-functional silane compounds may be used as sewage flocculents."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144003778"
                        ],
                        "name": "Kaleem Siddiqi",
                        "slug": "Kaleem-Siddiqi",
                        "structuredName": {
                            "firstName": "Kaleem",
                            "lastName": "Siddiqi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kaleem Siddiqi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1715265"
                        ],
                        "name": "B. Kimia",
                        "slug": "B.-Kimia",
                        "structuredName": {
                            "firstName": "Benjamin",
                            "lastName": "Kimia",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Kimia"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6636041,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "579f9da863bf86c9bfd6330fb127a410b4dc2e9a",
            "isKey": false,
            "numCitedBy": 188,
            "numCiting": 52,
            "paperAbstract": {
                "fragments": [],
                "text": "A proposed general principle of form from function motivates a particular partitioning scheme involving two types of parts, neck-based and limb-based. Neck-based parts arise from narrowings in shape, or the local minima in distance between two points on the boundary, while limb-based parts arise from a pair of negative curvature extrema which have co-circular tangents. Computational support for the limb-based and neck-based parts is presented by showing that they are invariant, robust, stable, and yield a hierarchy of parts. Examples illustrate that the resulting decompositions are robust in the presence of occlusion and noise for a range of man-made and natural objects and that they lead to natural and intuitive parts which can be used for recognition.<<ETX>>"
            },
            "slug": "Parts-of-visual-form:-computational-aspects-Siddiqi-Kimia",
            "title": {
                "fragments": [],
                "text": "Parts of Visual Form: Computational Aspects"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "Computational support for the limb-based and neck-based parts is presented by showing that they are invariant, robust, stable, and yield a hierarchy of parts."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716414"
                        ],
                        "name": "D. Ashlock",
                        "slug": "D.-Ashlock",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Ashlock",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Ashlock"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145193772"
                        ],
                        "name": "J. Davidson",
                        "slug": "J.-Davidson",
                        "structuredName": {
                            "firstName": "Jennifer",
                            "lastName": "Davidson",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Davidson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2967200,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "70289fe695d59ca9e365c18c6c2057686620d6d3",
            "isKey": false,
            "numCitedBy": 13,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we describe a solution to the problem of synthesizing textures. We use a pair of genetic algorithms to create fast one-pass generating algorithms for five black-and-white textures. This is done using only examples of those textures as input. The key to success is the use of a pair of genetic algorithms and a special structure called a foot pattern. The first genetic algorithm locates a foot pattern, a set of pixel locations containing important structural information about the texture, in essence a point of view from which the example texture looks relatively non-random. The foot pattern is a kind of basic texture element or texel. The second genetic algorithm then uses this texel as the core of a fitness function that compares two textures so as to tell when one \"looks like\" the other. With this \"looks like\" fitness function available, the second genetic algorithms synthesizes a non-parametric partially ordered Markov model for the example texture. The genetic algorithms used are themselves quite standard, but their pairing and the fitness functions used yield a breakthrough in black-and-white texture synthesis. Extending these techniques to gray scale and colored textures is possible, but suffers from combinatorial explosion. Suggestions on overcoming the difficulties of such extension appear in the discussion of future work."
            },
            "slug": "Texture-synthesis-with-tandem-genetic-algorithms-Ashlock-Davidson",
            "title": {
                "fragments": [],
                "text": "Texture synthesis with tandem genetic algorithms using nonparametric partially ordered Markov models"
            },
            "tldr": {
                "abstractSimilarityScore": 58,
                "text": "A pair of genetic algorithms are used to create fast one-pass generating algorithms for five black-and-white textures using only examples of those textures as input using a special structure called a foot pattern."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 1999 Congress on Evolutionary Computation-CEC99 (Cat. No. 99TH8406)"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1731893"
                        ],
                        "name": "S. Krishnamachari",
                        "slug": "S.-Krishnamachari",
                        "structuredName": {
                            "firstName": "Santhana",
                            "lastName": "Krishnamachari",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Krishnamachari"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9215658"
                        ],
                        "name": "R. Chellappa",
                        "slug": "R.-Chellappa",
                        "structuredName": {
                            "firstName": "Rama",
                            "lastName": "Chellappa",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Chellappa"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 7225358,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "id": "1feb3fd66e7ede0a5614413ac23913f50a244688",
            "isKey": false,
            "numCitedBy": 270,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents multiresolution models for Gauss-Markov random fields (GMRFs) with applications to texture segmentation. Coarser resolution sample fields are obtained by subsampling the sample field at fine resolution. Although the Markov property is lost under such resolution transformation, coarse resolution non-Markov random fields can be effectively approximated by Markov fields. We present two techniques to estimate the GMRF parameters at coarser resolutions from the fine resolution parameters, one by minimizing the Kullback-Leibler distance and another based on local conditional distribution invariance. We also allude to the fact that different GMRF parameters at the fine resolution can result in the same probability measure after subsampling and present the results for first- and second-order cases. We apply this multiresolution model to texture segmentation. Different texture regions in an image are modeled by GMRFs and the associated parameters are assumed to be known. Parameters at lower resolutions are estimated from the fine resolution parameters. The coarsest resolution data is first segmented and the segmentation results are propagated upward to the finer resolution. We use the iterated conditional mode (ICM) minimization at all resolutions. Our experiments with synthetic, Brodatz texture, and real satellite images show that the multiresolution technique results in a better segmentation and requires lesser computation than the single resolution algorithm."
            },
            "slug": "Multiresolution-Gauss-Markov-random-field-models-Krishnamachari-Chellappa",
            "title": {
                "fragments": [],
                "text": "Multiresolution Gauss-Markov random field models for texture segmentation"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "The experiments with synthetic, Brodatz texture, and real satellite images show that the multiresolution technique results in a better segmentation and requires lesser computation than the single resolution algorithm."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Image Process."
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143836201"
                        ],
                        "name": "D. Joyce",
                        "slug": "D.-Joyce",
                        "structuredName": {
                            "firstName": "Dan",
                            "lastName": "Joyce",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Joyce"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1773066"
                        ],
                        "name": "P. Lewis",
                        "slug": "P.-Lewis",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Lewis",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Lewis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2709391"
                        ],
                        "name": "R. Tansley",
                        "slug": "R.-Tansley",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Tansley",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Tansley"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2620443"
                        ],
                        "name": "M. R. Dobie",
                        "slug": "M.-R.-Dobie",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Dobie",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. R. Dobie"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143786158"
                        ],
                        "name": "W. Hall",
                        "slug": "W.-Hall",
                        "structuredName": {
                            "firstName": "Wendy",
                            "lastName": "Hall",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Hall"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 1186920,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1dd483c6716701f28ab7cf1e68908a609cbd691e",
            "isKey": false,
            "numCitedBy": 26,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": "The purpose of this paper is two-fold. We begin by exploring the emerging trend to view multimedia information in terms of low-level and high-level components; the former being feature-based and the latter the 'semantics' intrinsic to what is portrayed by the media object. Traditionally, this has been viewed by employing analogies with generative linguistics. Recently, a new perceptive based on the semiotic tradition has been alluded to in several papers. We believe this to be a more appropriate approach. From this, we propose an approach for tackling this problem which uses an associative data structure expressing authored information together with intelligent agents acting autonomously over this structure. We then show how neural networks can be used to implement such agents. The agents act as 'vehicles' for bridging the gap between multimedia semantics and concrete expressions of high-level knowledge, but we suggest that traditional neural network techniques for classification are not architecturally adequate."
            },
            "slug": "Semiotics-and-agents-for-integrating-and-navigating-Joyce-Lewis",
            "title": {
                "fragments": [],
                "text": "Semiotics and agents for integrating and navigating through multimedia representations of concepts"
            },
            "tldr": {
                "abstractSimilarityScore": 57,
                "text": "An approach is proposed for tackling the emerging trend to view multimedia information in terms of low-level and high-level components which uses an associative data structure expressing authored information together with intelligent agents acting autonomously over this structure and how neural networks can be used to implement such agents."
            },
            "venue": {
                "fragments": [],
                "text": "Electronic Imaging"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144590225"
                        ],
                        "name": "D. Roth",
                        "slug": "D.-Roth",
                        "structuredName": {
                            "firstName": "Dan",
                            "lastName": "Roth",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Roth"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1715634"
                        ],
                        "name": "Ming-Hsuan Yang",
                        "slug": "Ming-Hsuan-Yang",
                        "structuredName": {
                            "firstName": "Ming-Hsuan",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ming-Hsuan Yang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145237406"
                        ],
                        "name": "N. Ahuja",
                        "slug": "N.-Ahuja",
                        "structuredName": {
                            "firstName": "Narendra",
                            "lastName": "Ahuja",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Ahuja"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 763306,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9b1fea77753b6e1a6126665f87a7ff3837bb87ae",
            "isKey": false,
            "numCitedBy": 168,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "A learning account for the problem of object recognition is developed within the PAC (Probably Approximately Correct) model of learnability. The proposed approach makes no assumptions on the distribution of the observed objects, but quantifies success relative to its past experience. Most importantly, the success of learning an object representation is naturally tied to the ability to represent at as a function of some intermediate representations extracted from the image. We evaluate this approach an a large scale experimental study in which the SNoW learning architecture is used to learn representations for the 100 objects in the Columbia Object Image Database (COIL-100). The SNoW-based method is shown to outperform other methods in terms of recognition rates; its performance degrades gracefully when the training data contains fewer views and in the presence of occlusion noise."
            },
            "slug": "Learning-to-recognize-objects-Roth-Yang",
            "title": {
                "fragments": [],
                "text": "Learning to recognize objects"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "The SNoW-based method is shown to outperform other methods in terms of recognition rates; its performance degrades gracefully when the training data contains fewer views and in the presence of occlusion noise."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings IEEE Conference on Computer Vision and Pattern Recognition. CVPR 2000 (Cat. No.PR00662)"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1734823"
                        ],
                        "name": "Paul L. Rosin",
                        "slug": "Paul-L.-Rosin",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Rosin",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Paul L. Rosin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2384592,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9c7837626367fd5067639604b1b7284db33a123d",
            "isKey": false,
            "numCitedBy": 113,
            "numCiting": 115,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract.Edges are useful features for structural image analysis, but the output of standard edge detectors must be thresholded to remove the many spurious edges. This paper describes experiments with both new and old techniques for: 1. determining edge saliency (as alternatives to gradient magnitude) and 2. automatically determining appropriate edge threshold values. Some examples of edge saliency measures are lifetime, wiggliness, spatial width, and phase congruency. Examples of thresholding techniques use: the Rayleigh distribution to model the edge gradient magnitude histogram, relaxation labelling, and an edge curve \u201clength\u201d\u2013\u201caverage gradient magnitude\u201d feature space.\n"
            },
            "slug": "Edges:-saliency-measures-and-automatic-thresholding-Rosin",
            "title": {
                "fragments": [],
                "text": "Edges: saliency measures and automatic thresholding\n"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This paper describes experiments with both new and old techniques for determining edge saliency (as alternatives to gradient magnitude) and automatically determining appropriate edge threshold values."
            },
            "venue": {
                "fragments": [],
                "text": "Machine Vision and Applications"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145730685"
                        ],
                        "name": "L. Brown",
                        "slug": "L.-Brown",
                        "structuredName": {
                            "firstName": "Leonard",
                            "lastName": "Brown",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Brown"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144099017"
                        ],
                        "name": "L. Gruenwald",
                        "slug": "L.-Gruenwald",
                        "structuredName": {
                            "firstName": "Le",
                            "lastName": "Gruenwald",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Gruenwald"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 10806830,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "106eeb93f64d25debc589ff7f07936cc226d1623",
            "isKey": false,
            "numCitedBy": 27,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "As in conventional database management systems (DBMSs), to allow users to efficiently access and retrieve data objects, a multimedia database management system (MMDBMS) must employ an effective access method such as indexing and hashing. This paper provides a survey of tree-based multidimensional indexing techniques for MMDBMSs that maintain image data represented as feature vectors. These techniques support such data while maintaining desirable characteristics of a B-tree, an index structure most commonly used in traditional DBMSs. In this survey, we provide descriptions of each tree as well as give examples of the different data organization schemes. We also describe the advantages and disadvantages of using each technique. In addition, we provide classifications of the trees using several different properties. These classifications should assist researchers in identifying the strengths and weaknesses of any new indexing technique they develop as well as help users determine the most appropriate data structure for their applications."
            },
            "slug": "Tree-Based-Indexes-for-Image-Data-Brown-Gruenwald",
            "title": {
                "fragments": [],
                "text": "Tree-Based Indexes for Image Data"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This paper provides a survey of tree-based multidimensional indexing techniques for MMDBMSs that maintain image data represented as feature vectors and provides classifications of the trees using several different properties to assist researchers in identifying the strengths and weaknesses of any new indexing technique they develop."
            },
            "venue": {
                "fragments": [],
                "text": "J. Vis. Commun. Image Represent."
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1731570"
                        ],
                        "name": "M. Lew",
                        "slug": "M.-Lew",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Lew",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Lew"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1703601"
                        ],
                        "name": "N. Sebe",
                        "slug": "N.-Sebe",
                        "structuredName": {
                            "firstName": "N.",
                            "lastName": "Sebe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Sebe"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6547420,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "091d08204a23fed1dc751275e7ea62ad6039b8c5",
            "isKey": false,
            "numCitedBy": 8,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "Imagine a professional Web site designer who constantly has to come up with innovative looks for the client's homepages? How does he find the new content? The major search engines such as Hotbot (http://www.hotbot.com) allow us to find text on the Web, but typically have few or no capabilities for finding visual media. In this article we discuss methods for finding visual media on the WWW. The emphasis is on iconic queries which are essentially drag-and-drop visual concepts or simple semantics. We describe our method for finding static feature sets and then describe a novel method called active feature sets, which chooses a feature set based on the context in the image."
            },
            "slug": "Visual-websearching-using-iconic-queries-Lew-Sebe",
            "title": {
                "fragments": [],
                "text": "Visual websearching using iconic queries"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This article describes a method for finding static feature sets and describes a novel method called active feature sets, which chooses a feature set based on the context in the image."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings IEEE Conference on Computer Vision and Pattern Recognition. CVPR 2000 (Cat. No.PR00662)"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2507859"
                        ],
                        "name": "S. Berretti",
                        "slug": "S.-Berretti",
                        "structuredName": {
                            "firstName": "Stefano",
                            "lastName": "Berretti",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Berretti"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "122607748"
                        ],
                        "name": "A. del Bimbo",
                        "slug": "A.-del-Bimbo",
                        "structuredName": {
                            "firstName": "Alberto",
                            "lastName": "del Bimbo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. del Bimbo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1680785"
                        ],
                        "name": "E. Vicario",
                        "slug": "E.-Vicario",
                        "structuredName": {
                            "firstName": "Enrico",
                            "lastName": "Vicario",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Vicario"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 122116519,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "010dbab68672134d69e9847e3d7bdd28d10ee24c",
            "isKey": false,
            "numCitedBy": 8,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "Modeling of image content based on chromatic arrangement includes representation of the spatial relationship between complex sets of pixels. We propose a model of spatial directional relationship between extended sets. This involves the same computational and programming complexity as that of conventional representations based on centroids, but it is able to account for the overall sets of pixels without reducing them to a single representative point or to a bounding rectangle. The gain in effectiveness is evaluated in a user-based comparison with a representation based on mutual centroid orientation."
            },
            "slug": "Modeling-spatial-relationships-between-color-sets-Berretti-Bimbo",
            "title": {
                "fragments": [],
                "text": "Modeling spatial relationships between color sets"
            },
            "tldr": {
                "abstractSimilarityScore": 59,
                "text": "This work proposes a model of spatial directional relationship between extended sets that involves the same computational and programming complexity as that of conventional representations based on centroids, but is able to account for the overall sets of pixels without reducing them to a single representative point or to a bounding rectangle."
            },
            "venue": {
                "fragments": [],
                "text": "2000 Proceedings Workshop on Content-based Access of Image and Video Libraries"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47666658"
                        ],
                        "name": "Hsinchun Chen",
                        "slug": "Hsinchun-Chen",
                        "structuredName": {
                            "firstName": "Hsinchun",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hsinchun Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1783942"
                        ],
                        "name": "B. Schatz",
                        "slug": "B.-Schatz",
                        "structuredName": {
                            "firstName": "Bruce",
                            "lastName": "Schatz",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Schatz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2418260"
                        ],
                        "name": "Tobun Dorbin Ng",
                        "slug": "Tobun-Dorbin-Ng",
                        "structuredName": {
                            "firstName": "Tobun",
                            "lastName": "Ng",
                            "middleNames": [
                                "Dorbin"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tobun Dorbin Ng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2158092341"
                        ],
                        "name": "Joanne Martinez",
                        "slug": "Joanne-Martinez",
                        "structuredName": {
                            "firstName": "Joanne",
                            "lastName": "Martinez",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Joanne Martinez"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35238065"
                        ],
                        "name": "Amy Kirchhoff",
                        "slug": "Amy-Kirchhoff",
                        "structuredName": {
                            "firstName": "Amy",
                            "lastName": "Kirchhoff",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Amy Kirchhoff"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3011683"
                        ],
                        "name": "Chienting Lin",
                        "slug": "Chienting-Lin",
                        "structuredName": {
                            "firstName": "Chienting",
                            "lastName": "Lin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chienting Lin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 12929886,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c717533571491103aa4ca4ab8e046056db918855",
            "isKey": false,
            "numCitedBy": 120,
            "numCiting": 57,
            "paperAbstract": {
                "fragments": [],
                "text": "This research presents preliminary results generated from the semantic retrieval research component of the Illinois Digital Library Initiative (DLI) project. Using a variation of the automatic thesaurus generation techniques, to which we refer to as the concept space approach, we aimed to create graphs of domain-specific concepts (terms) and their weighted co-occurrence relationships for all major engineering domains. Merging these concept spaces and providing traversal paths across different concept spaces could potentially help alleviate the vocabulary (difference) problem evident in large-scale information retrieval. In order to address the scalability issue related to large-scale information retrieval and analysis for the current Illinois DLI project, we conducted experiments using the concept space approach on parallel supercomputers. Our test collection included computer science and electrical engineering abstracts extracted from the INSPEC database. The concept space approach called for extensive textual and statistical analysis (a form of knowledge discovery) based on automatic indexing and co-occurrence analysis algorithms, both previously tested in the biology domain. Initial testing results using a 512-node CM-5 and a 16-processor SGI Power Challenge were promising."
            },
            "slug": "A-Parallel-Computing-Approach-to-Creating-Concept-Chen-Schatz",
            "title": {
                "fragments": [],
                "text": "A Parallel Computing Approach to Creating Engineering Concept Spaces for Semantic Retrieval: The Illinois Digital Library Initiative Project"
            },
            "tldr": {
                "abstractSimilarityScore": 65,
                "text": "Preliminary results generated from the semantic retrieval research component of the Illinois Digital Library Initiative (DLI) project are presented, which aimed to create graphs of domain-specific concepts and their weighted co-occurrence relationships for all major engineering domains."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1768574"
                        ],
                        "name": "P. Yuen",
                        "slug": "P.-Yuen",
                        "structuredName": {
                            "firstName": "Pong",
                            "lastName": "Yuen",
                            "middleNames": [
                                "Chi"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Yuen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1802317"
                        ],
                        "name": "G. Feng",
                        "slug": "G.-Feng",
                        "structuredName": {
                            "firstName": "Guo-Can",
                            "lastName": "Feng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Feng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1726138"
                        ],
                        "name": "D. Dai",
                        "slug": "D.-Dai",
                        "structuredName": {
                            "firstName": "Dao-Qing",
                            "lastName": "Dai",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Dai"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 33243849,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c3540695b8742221c9c33a87a4ca6c3b1dc00dd8",
            "isKey": false,
            "numCitedBy": 6,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "Addresses the speed problem in a human face image retrieval system from a large database. A novel method based on the wavelet transform and principal component analysis (PCA) is developed and presented. The computational load of the proposed method is greatly reduced compared with the original PCA based method. Moreover, the accuracy of the proposed method is improved."
            },
            "slug": "Human-face-image-retrieval-system-for-large-Yuen-Feng",
            "title": {
                "fragments": [],
                "text": "Human face image retrieval system for large database"
            },
            "tldr": {
                "abstractSimilarityScore": 57,
                "text": "A novel method based on the wavelet transform and principal component analysis (PCA) is developed and presented that addresses the speed problem in a human face image retrieval system from a large database."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings. Fourteenth International Conference on Pattern Recognition (Cat. No.98EX170)"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1722325"
                        ],
                        "name": "J. Bonet",
                        "slug": "J.-Bonet",
                        "structuredName": {
                            "firstName": "Jeremy",
                            "lastName": "Bonet",
                            "middleNames": [
                                "S.",
                                "De"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Bonet"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1731948"
                        ],
                        "name": "Paul A. Viola",
                        "slug": "Paul-A.-Viola",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Viola",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Paul A. Viola"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15951006,
            "fieldsOfStudy": [
                "Computer Science",
                "Environmental Science",
                "Mathematics"
            ],
            "id": "0adfcdc1af6ad2f3a118d851533d86a8281206e3",
            "isKey": false,
            "numCitedBy": 116,
            "numCiting": 85,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a technique for using the joint occurrence of local features at multiple resolutions to measure the similarity between texture images. Though superficially similar to a number of \"Gabor\" style techniques, which recognize textures through the extraction of multi-scale feature vectors, our approach is derived from an accurate generative model of texture, which is explicitly multiscale and non-parametric. The resulting recognition procedure is similarly non-parametric, and can model complex non-homogeneous textures. We report results on publicly available texture databases. In addition, experiments indicate that this approach may have sufficient discrimination power to perform target detection in synthetic aperture radar images (SAR)."
            },
            "slug": "Texture-recognition-using-a-non-parametric-model-Bonet-Viola",
            "title": {
                "fragments": [],
                "text": "Texture recognition using a non-parametric multi-scale statistical model"
            },
            "tldr": {
                "abstractSimilarityScore": 71,
                "text": "A technique for using the joint occurrence of local features at multiple resolutions to measure the similarity between texture images, derived from an accurate generative model of texture, which is explicitly multiscale and non-parametric."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings. 1998 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.98CB36231)"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1747801"
                        ],
                        "name": "E. Rivlin",
                        "slug": "E.-Rivlin",
                        "structuredName": {
                            "firstName": "Ehud",
                            "lastName": "Rivlin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Rivlin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143867195"
                        ],
                        "name": "I. Weiss",
                        "slug": "I.-Weiss",
                        "structuredName": {
                            "firstName": "Isaac",
                            "lastName": "Weiss",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Weiss"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 5050286,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "9b3cf3f078b1b9ae1b3eaedb75252d58090a8184",
            "isKey": false,
            "numCitedBy": 100,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "Geometric invariants are shape descriptors that remain unchanged under geometric transformations such as projection or changing the viewpoint. A new method of obtaining local projective and affine invariants is developed and implemented for real images. Being local, the Invariants are much less sensitive to occlusion than global invariants. The invariants' computation is based on a canonical method. This consists of defining a canonical coordinate system by the intrinsic properties of the shape, independently of the given coordinate system. Since this canonical system is independent of the original one, it is invariant and all quantities defined in it are invariant. The method was applied without the use of a curve parameter. This was achieved by fitting an implicit polynomial to an arbitrary curve in a vicinity of each curve point. Several configurations are treated: a general curve without any correspondence and curves with known correspondences of one or two feature points or lines. Experimental results for different 2D objects in 3D space are presented. >"
            },
            "slug": "Local-Invariants-For-Recognition-Rivlin-Weiss",
            "title": {
                "fragments": [],
                "text": "Local Invariants For Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A new method of obtaining local projective and affine invariants is developed and implemented for real images and is much less sensitive to occlusion than global invariants."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2085892105"
                        ],
                        "name": "Irene Rothe",
                        "slug": "Irene-Rothe",
                        "structuredName": {
                            "firstName": "Irene",
                            "lastName": "Rothe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Irene Rothe"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2199123"
                        ],
                        "name": "H. S\u00fc\u00dfe",
                        "slug": "H.-S\u00fc\u00dfe",
                        "structuredName": {
                            "firstName": "Herbert",
                            "lastName": "S\u00fc\u00dfe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. S\u00fc\u00dfe"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40560869"
                        ],
                        "name": "K. Voss",
                        "slug": "K.-Voss",
                        "structuredName": {
                            "firstName": "Klaus",
                            "lastName": "Voss",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Voss"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 21046804,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "310ef2c34d28923f5eab109feb29334d37a0b66d",
            "isKey": false,
            "numCitedBy": 150,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "The determination of invariant characteristics is an important problem in pattern recognition. Many invariants are known, which have been obtained either by normalization or by other methods. This paper shows that the method of normalization is much more general and allows one to derive a lot of sets of invariants from the second list as well. To this end, the normalization method is generalized and is presented in such a way that it is easy to apply, thus unifying and simplifying the determination of invariants. Furthermore, this paper discusses the advantages and disadvantages of the invariants obtained by normalization. Their main advantage is that the normalization process provides us with a standard position of the object. Because of the generality of the method, also new invariants are obtained such as normalized moments more stable than known ones, Legendre descriptors and Zernike descriptors to affine transformations, two-dimensional Fourier descriptors and affine moment invariants obtained by combining Hu's moment invariants and normalized moments."
            },
            "slug": "The-Method-of-Normalization-to-Determine-Invariants-Rothe-S\u00fc\u00dfe",
            "title": {
                "fragments": [],
                "text": "The Method of Normalization to Determine Invariants"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This paper shows that the method of normalization is much more general and allows one to derive a lot of sets of invariants from the second list as well, thus unifying and simplifying the determination of invariant characteristics."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2934283"
                        ],
                        "name": "C. Esperan\u00e7a",
                        "slug": "C.-Esperan\u00e7a",
                        "structuredName": {
                            "firstName": "Claudio",
                            "lastName": "Esperan\u00e7a",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Esperan\u00e7a"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1719385"
                        ],
                        "name": "H. Samet",
                        "slug": "H.-Samet",
                        "structuredName": {
                            "firstName": "Hanan",
                            "lastName": "Samet",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Samet"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8423685,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b134f169fe37a85697dc024575804bd3c43bc35b",
            "isKey": false,
            "numCitedBy": 10,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "A new method termed the vertex representation is presented for approximating the shapes of objects of arbitrary dimensionality d (e.g., 2D, 3D, etc.) with orthogonal (d-1)-dimensional faces using a variable number of vertices. The vertex representation can be viewed as a generalization of boundary codes (i.e., chain codes) to higher dimensions. Techniques are described for using the vertex representation to efficiently perform many operations commonly performed on rasters. The utility of these techniques in image database applications is discussed."
            },
            "slug": "A-differential-code-for-shape-representation-in-Esperan\u00e7a-Samet",
            "title": {
                "fragments": [],
                "text": "A differential code for shape representation in image database applications"
            },
            "tldr": {
                "abstractSimilarityScore": 95,
                "text": "A new method termed the vertex representation is presented for approximating the shapes of objects of arbitrary dimensionality d with orthogonal (d-1)-dimensional faces using a variable number of vertices."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of International Conference on Image Processing"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2055691681"
                        ],
                        "name": "P. Zhu",
                        "slug": "P.-Zhu",
                        "structuredName": {
                            "firstName": "Peng",
                            "lastName": "Zhu",
                            "middleNames": [
                                "Fei"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Zhu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2863224"
                        ],
                        "name": "P. Chirlian",
                        "slug": "P.-Chirlian",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Chirlian",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Chirlian"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 38820796,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "a71e3bc0ad37e8ec1f68bf3281eda89e2edb4e4c",
            "isKey": false,
            "numCitedBy": 150,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we present a nonlinear algorithm for critical point detection (CPD) of 2D digital shapes. The algorithm eliminates the problems arising from curvature approximation and Gaussian filtering in the existing algorithms. Based on the definition of \"critical level,\" we establish a set of criteria for the design of an effective CPD algorithm for the first time. By quantifying the critical level to the modified area confined by three consecutive \"pseudocritical points,\" a simple but very effective algorithm is developed. The comparison of our experimental results with those of many other CPD algorithms shows that the proposed algorithm is superior in that it provides a sequence of figures at every detail level, and each has a smaller integral error than the others with the same number of critical points. The experimental results on shapes with various complexities also show the algorithm is reliable and robust with regard to noise. >"
            },
            "slug": "On-Critical-Point-Detection-of-Digital-Shapes-Zhu-Chirlian",
            "title": {
                "fragments": [],
                "text": "On Critical Point Detection of Digital Shapes"
            },
            "tldr": {
                "abstractSimilarityScore": 59,
                "text": "A nonlinear algorithm for critical point detection (CPD) of 2D digital shapes by quantifying the critical level to the modified area confined by three consecutive \"pseudocritical points\" is developed."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1679040"
                        ],
                        "name": "Shi-Kuo Chang",
                        "slug": "Shi-Kuo-Chang",
                        "structuredName": {
                            "firstName": "Shi-Kuo",
                            "lastName": "Chang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shi-Kuo Chang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2106531491"
                        ],
                        "name": "Q. Shi",
                        "slug": "Q.-Shi",
                        "structuredName": {
                            "firstName": "Qing-Yun",
                            "lastName": "Shi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Q. Shi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2107472893"
                        ],
                        "name": "C. Yan",
                        "slug": "C.-Yan",
                        "structuredName": {
                            "firstName": "C.",
                            "lastName": "Yan",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Yan"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 12115567,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1fdfe67d4c053198be988c5fb24926bcfebebd26",
            "isKey": false,
            "numCitedBy": 698,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we describe a new way of representing a symbolic picture by a two-dimensional string. A picture query can also be specified as a 2-D string. The problem of pictorial information retrieval then becomes a problem of 2-D subsequence matching. We present algorithms for encoding a symbolic picture into its 2-D string representation, reconstructing a picture from its 2-D string representation, and matching a 2-D string with another 2-D string. We also prove the necessary and sufficient conditions to characterize ambiguous pictures for reduced 2-D strings as well as normal 2-D strings. This approach thus allows an efficient and natural way to construct iconic indexes for pictures."
            },
            "slug": "Iconic-Indexing-by-2-D-Strings-Chang-Shi",
            "title": {
                "fragments": [],
                "text": "Iconic Indexing by 2-D Strings"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This approach allows an efficient and natural way to construct iconic indexes for pictures and proves the necessary and sufficient conditions to characterize ambiguous pictures for reduced 2D strings as well as normal 2-D strings."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1780935"
                        ],
                        "name": "B. Moghaddam",
                        "slug": "B.-Moghaddam",
                        "structuredName": {
                            "firstName": "Baback",
                            "lastName": "Moghaddam",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Moghaddam"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1911575"
                        ],
                        "name": "Wasiuddin Wahid",
                        "slug": "Wasiuddin-Wahid",
                        "structuredName": {
                            "firstName": "Wasiuddin",
                            "lastName": "Wahid",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wasiuddin Wahid"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144994682"
                        ],
                        "name": "A. Pentland",
                        "slug": "A.-Pentland",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Pentland",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Pentland"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14026813,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "abafd6362120d01979c77f0fd2a4fab234a4368d",
            "isKey": false,
            "numCitedBy": 316,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a technique for direct visual matching for face recognition and database search, using a probabilistic measure of similarity which is based on a Bayesian analysis of image differences. Specifically we model lure mutually exclusive classes of variation between facial images: intra-personal (variations in appearance of the same individual, due to different expressions or lighting) and extra-personal (variations in appearance due to a difference in identity). The likelihoods for each respective class are learned from training data using eigenspace density estimation and used to compute similarity based on the a posteriori probability of membership in the intra-personal class, and ultimately used to rank matches in the database. The performance advantage of this probabilistic technique over nearest-neighbor eigenface matching is demonstrated using results front ARPA's 1996 \"FERET\" face recognition competition, in which this algorithm was found to be the top performer."
            },
            "slug": "Beyond-eigenfaces:-probabilistic-matching-for-face-Moghaddam-Wahid",
            "title": {
                "fragments": [],
                "text": "Beyond eigenfaces: probabilistic matching for face recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "The performance advantage of this probabilistic technique over nearest-neighbor eigenface matching is demonstrated using results front ARPA's 1996 \"FERET\" face recognition competition, in which this algorithm was found to be the top performer."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings Third IEEE International Conference on Automatic Face and Gesture Recognition"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3203897"
                        ],
                        "name": "P. Yianilos",
                        "slug": "P.-Yianilos",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Yianilos",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Yianilos"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2871061,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8b0d6d2e43a2c6b9e463845b5ebdab4a62236d66",
            "isKey": false,
            "numCitedBy": 1097,
            "numCiting": 58,
            "paperAbstract": {
                "fragments": [],
                "text": "We consider the computational problem of finding nearest neighbors in general metric spaces. Of particular interest are spaces that may not be conveniently embedded or approximated in Euclidian space, or where the dimensionality of a Euclidian representation 1s very high. Also relevant are high-dimensional Euclidian settings in which the distribution of data is in some sense of lower dimension and embedded in the space. The up-tree (vantage point tree) is introduced in several forms, together\u2018 with &&ciated algorithms, as an improved method for these difficult search nroblems. Tree construcI tion executes in O(nlog(n i ) time, and search is under certain circumstances and in the imit, O(log(n)) expected time. The theoretical basis for this approach is developed and the results of several experiments are reported. In Euclidian cases, kd-tree performance is compared."
            },
            "slug": "Data-structures-and-algorithms-for-nearest-neighbor-Yianilos",
            "title": {
                "fragments": [],
                "text": "Data structures and algorithms for nearest neighbor search in general metric spaces"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "The up-tree (vantage point tree) is introduced in several forms, together\u2018 with &&ciated algorithms, as an improved method for these difficult search problems in general metric spaces."
            },
            "venue": {
                "fragments": [],
                "text": "SODA '93"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1789486"
                        ],
                        "name": "G. Finlayson",
                        "slug": "G.-Finlayson",
                        "structuredName": {
                            "firstName": "Graham",
                            "lastName": "Finlayson",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Finlayson"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 38426803,
            "fieldsOfStudy": [
                "Art"
            ],
            "id": "f231b40c40dbbc8b031125a4d81abd6d6d126116",
            "isKey": false,
            "numCitedBy": 315,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "Simple constraints on the sets of possible surface reflectance and illuminants are exploited in a new color constancy algorithm that builds upon Forsyth's (1990) theory of color constancy. Forsyth's method invokes the constraint that the surface colors under a canonical illuminant all fall within an established maximal convex gamut of possible colors. However, the method works only when restrictive conditions are imposed on the world: the illumination must be uniform, the surfaces must be planar, and there can be no specularities. To overcome these restrictions, we modify Forsyth's algorithm so that it works with the colors under a perspective projection (in a chromaticity space). The new algorithm working in perspective is simpler than Forsyth's method and more importantly the restrictions on the illuminant, surface shape and specularities can be relaxed. The algorithm is then extended to include a maximal gamut constraint on a set of illuminants that is analogous to the gamut constraint on surface colors. Tests on real images show that the algorithm provides good color constancy."
            },
            "slug": "Color-in-Perspective-Finlayson",
            "title": {
                "fragments": [],
                "text": "Color in Perspective"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "A new color constancy algorithm is developed that works with the colors under a perspective projection (in a chromaticity space) and is extended to include a maximal gamut constraint on a set of illuminants that is analogous to the gamut constraints on surface colors."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2784291"
                        ],
                        "name": "J. Tatemura",
                        "slug": "J.-Tatemura",
                        "structuredName": {
                            "firstName": "Jun'ichi",
                            "lastName": "Tatemura",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Tatemura"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 31192192,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6af191af46301c3aed0a2af7e2dfa1ffacbb2831",
            "isKey": false,
            "numCitedBy": 6,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose an information visualization technique that uses social and content features complementarily and helps users explore a database for images. Items in the database are laid out in a 2D map according to content similarity. The social filter dynamically shows the relationship between items in the map based on social similarity. We demonstrate an example of visualization applied to our Web graphics recommender system."
            },
            "slug": "Browsing-images-based-on-social-and-content-Tatemura",
            "title": {
                "fragments": [],
                "text": "Browsing images based on social and content similarity"
            },
            "tldr": {
                "abstractSimilarityScore": 75,
                "text": "An information visualization technique that uses social and content features complementarily and helps users explore a database for images and demonstrates an example of visualization applied to the Web graphics recommender system."
            },
            "venue": {
                "fragments": [],
                "text": "2000 IEEE International Conference on Multimedia and Expo. ICME2000. Proceedings. Latest Advances in the Fast Changing World of Multimedia (Cat. No.00TH8532)"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1742373"
                        ],
                        "name": "A. Laine",
                        "slug": "A.-Laine",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Laine",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Laine"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46693153"
                        ],
                        "name": "Jian Fan",
                        "slug": "Jian-Fan",
                        "structuredName": {
                            "firstName": "Jian",
                            "lastName": "Fan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jian Fan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 10248592,
            "fieldsOfStudy": [
                "Environmental Science"
            ],
            "id": "486fc849ca42b18935cbacf20b50d08b5575de70",
            "isKey": false,
            "numCitedBy": 1011,
            "numCiting": 75,
            "paperAbstract": {
                "fragments": [],
                "text": "This correspondence introduces a new approach to characterize textures at multiple scales. The performance of wavelet packet spaces are measured in terms of sensitivity and selectivity for the classification of twenty-five natural textures. Both energy and entropy metrics were computed for each wavelet packet and incorporated into distinct scale space representations, where each wavelet packet (channel) reflected a specific scale and orientation sensitivity. Wavelet packet representations for twenty-five natural textures were classified without error by a simple two-layer network classifier. An analyzing function of large regularity (D/sub 20/) was shown to be slightly more efficient in representation and discrimination than a similar function with fewer vanishing moments (D/sub 6/) In addition, energy representations computed from the standard wavelet decomposition alone (17 features) provided classification without error for the twenty-five textures included in our study. The reliability exhibited by texture signatures based on wavelet packets analysis suggest that the multiresolution properties of such transforms are beneficial for accomplishing segmentation, classification and subtle discrimination of texture. >"
            },
            "slug": "Texture-Classification-by-Wavelet-Packet-Signatures-Laine-Fan",
            "title": {
                "fragments": [],
                "text": "Texture Classification by Wavelet Packet Signatures"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "The reliability exhibited by texture signatures based on wavelet packets analysis suggest that the multiresolution properties of such transforms are beneficial for accomplishing segmentation, classification and subtle discrimination of texture."
            },
            "venue": {
                "fragments": [],
                "text": "MVA"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144430493"
                        ],
                        "name": "Flip R. Korn",
                        "slug": "Flip-R.-Korn",
                        "structuredName": {
                            "firstName": "Flip",
                            "lastName": "Korn",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Flip R. Korn"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "21568414"
                        ],
                        "name": "N. Sidiropoulos",
                        "slug": "N.-Sidiropoulos",
                        "structuredName": {
                            "firstName": "Nicholas",
                            "lastName": "Sidiropoulos",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Sidiropoulos"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1702392"
                        ],
                        "name": "C. Faloutsos",
                        "slug": "C.-Faloutsos",
                        "structuredName": {
                            "firstName": "Christos",
                            "lastName": "Faloutsos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Faloutsos"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1691257"
                        ],
                        "name": "E. Siegel",
                        "slug": "E.-Siegel",
                        "structuredName": {
                            "firstName": "Eliot",
                            "lastName": "Siegel",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Siegel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2382176"
                        ],
                        "name": "Z. Protopapas",
                        "slug": "Z.-Protopapas",
                        "structuredName": {
                            "firstName": "Zenon",
                            "lastName": "Protopapas",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Z. Protopapas"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 117147514,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d7e3322c58ed45495b69b8f495357549c861e7fd",
            "isKey": false,
            "numCitedBy": 1,
            "numCiting": 53,
            "paperAbstract": {
                "fragments": [],
                "text": "We examine the problem of finding similar tumor shapes. The main contribution of this work is the proposal of a natural similarity function for shape matching called the \u2018morphological distance \u2019. This function has two desirable properties: (a) it matches human perception of similarity, as we illustrate with precision/recall experiments; (b) it can be lower-bounded by a set of features, leading to fast indexing for range queries and nearest neighbor queries."
            },
            "slug": "Efficient-and-effective-nearest-neighbor-search-in-Korn-Sidiropoulos",
            "title": {
                "fragments": [],
                "text": "Efficient and effective nearest neighbor search in a medical image database of tumor shapes"
            },
            "tldr": {
                "abstractSimilarityScore": 73,
                "text": "The main contribution of this work is the proposal of a natural similarity function for shape matching called the \u2018morphological distance \u2019, which has two desirable properties: it matches human perception of similarity, and can be lower-bounded by a set of features, leading to fast indexing for range queries and nearest neighbor queries."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48686588"
                        ],
                        "name": "David A. White",
                        "slug": "David-A.-White",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "White",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David A. White"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144938740"
                        ],
                        "name": "R. Jain",
                        "slug": "R.-Jain",
                        "structuredName": {
                            "firstName": "Ramesh",
                            "lastName": "Jain",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Jain"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 17181175,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c865eaeea27a742f16f14c3a45bbaefdd87a8330",
            "isKey": false,
            "numCitedBy": 787,
            "numCiting": 44,
            "paperAbstract": {
                "fragments": [],
                "text": "Efficient indexing of high dimensional feature vectors is important to allow visual information systems and a number other applications to scale up to large databases. We define this problem as \"similarity indexing\" and describe the fundamental types of \"similarity queries\" that we believe should be supported. We also propose a new dynamic structure for similarity indexing called the similarity search tree or SS-tree. In nearly every test we performed on high dimensional data, we found that this structure performed better than the R*-tree. Our tests also show that the SS-tree is much better suited for approximate queries than the R*-tree."
            },
            "slug": "Similarity-indexing-with-the-SS-tree-White-Jain",
            "title": {
                "fragments": [],
                "text": "Similarity indexing with the SS-tree"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This work describes the fundamental types of \"similarity queries\" that should be supported and proposes a new dynamic structure for similarity indexing called the similarity search tree or SS-tree, which performs better than the R*-tree in nearly every test."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Twelfth International Conference on Data Engineering"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1780935"
                        ],
                        "name": "B. Moghaddam",
                        "slug": "B.-Moghaddam",
                        "structuredName": {
                            "firstName": "Baback",
                            "lastName": "Moghaddam",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Moghaddam"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144994682"
                        ],
                        "name": "A. Pentland",
                        "slug": "A.-Pentland",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Pentland",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Pentland"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 483975,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "74b312560b79929540734067e58de46966b96130",
            "isKey": false,
            "numCitedBy": 1684,
            "numCiting": 59,
            "paperAbstract": {
                "fragments": [],
                "text": "We present an unsupervised technique for visual learning, which is based on density estimation in high-dimensional spaces using an eigenspace decomposition. Two types of density estimates are derived for modeling the training data: a multivariate Gaussian (for unimodal distributions) and a mixture-of-Gaussians model (for multimodal distributions). Those probability densities are then used to formulate a maximum-likelihood estimation framework for visual search and target detection for automatic object recognition and coding. Our learning technique is applied to the probabilistic visual modeling, detection, recognition, and coding of human faces and nonrigid objects, such as hands."
            },
            "slug": "Probabilistic-Visual-Learning-for-Object-Moghaddam-Pentland",
            "title": {
                "fragments": [],
                "text": "Probabilistic Visual Learning for Object Representation"
            },
            "tldr": {
                "abstractSimilarityScore": 69,
                "text": "An unsupervised technique for visual learning is presented, which is based on density estimation in high-dimensional spaces using an eigenspace decomposition and is applied to the probabilistic visual modeling, detection, recognition, and coding of human faces and nonrigid objects."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145160149"
                        ],
                        "name": "W. Grosky",
                        "slug": "W.-Grosky",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Grosky",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Grosky"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 17402596,
            "fieldsOfStudy": [
                "Computer Science",
                "Art"
            ],
            "id": "6409474561709e6cc8167a96faa7e474fcc20d54",
            "isKey": false,
            "numCitedBy": 118,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "Presents a gentle introduction to multimedia information systems. The author explores the nature of multimedia data model and information system architecture, and reviews the evolution of multimedia information systems. He also discusses data model design, query processing, and browsing support, and takes a look at some state-of-the-art prototype systems.<<ETX>>"
            },
            "slug": "Multimedia-information-systems-Grosky",
            "title": {
                "fragments": [],
                "text": "Multimedia information systems"
            },
            "tldr": {
                "abstractSimilarityScore": 65,
                "text": "The author explores the nature of multimedia data model and information system architecture, and the evolution of multimedia information systems, and discusses data model design, query processing, and browsing support."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE MultiMedia"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "97129855"
                        ],
                        "name": "M. Hu",
                        "slug": "M.-Hu",
                        "structuredName": {
                            "firstName": "Ming-Kuei",
                            "lastName": "Hu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Hu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6431165,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ce1e3528047cd01937f6a8aa760640f6b3c8d531",
            "isKey": false,
            "numCitedBy": 8010,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper a theory of two-dimensional moment invariants for planar geometric figures is presented. A fundamental theorem is established to relate such moment invariants to the well-known algebraic invariants. Complete systems of moment invariants under translation, similitude and orthogonal transformations are derived. Some moment invariants under general two-dimensional linear transformations are also included. Both theoretical formulation and practical models of visual pattern recognition based upon these moment invariants are discussed. A simple simulation program together with its performance are also presented. It is shown that recognition of geometrical patterns and alphabetical characters independently of position, size and orientation can be accomplished. It is also indicated that generalization is possible to include invariance with parallel projection."
            },
            "slug": "Visual-pattern-recognition-by-moment-invariants-Hu",
            "title": {
                "fragments": [],
                "text": "Visual pattern recognition by moment invariants"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "It is shown that recognition of geometrical patterns and alphabetical characters independently of position, size and orientation can be accomplished and it is indicated that generalization is possible to include invariance with parallel projection."
            },
            "venue": {
                "fragments": [],
                "text": "IRE Trans. Inf. Theory"
            },
            "year": 1962
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1682773"
                        ],
                        "name": "A. Pentland",
                        "slug": "A.-Pentland",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Pentland",
                            "middleNames": [
                                "'Sandy'"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Pentland"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144075899"
                        ],
                        "name": "Tanzeem Choudhury",
                        "slug": "Tanzeem-Choudhury",
                        "structuredName": {
                            "firstName": "Tanzeem",
                            "lastName": "Choudhury",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tanzeem Choudhury"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14470115,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "13425bb41d326982ec6b3c6f3034aa978a1300ac",
            "isKey": false,
            "numCitedBy": 277,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "Smart environments, wearable computers, and ubiquitous computing in general are the coming \"fourth generation\" of computing and information technology. But that technology will be a stillbirth without new interfaces for interaction, minus a keyboard or mouse. To win wide consumer acceptance, these interactions must be friendly and personalized; the next generation interfaces must recognize people in their immediate environment and, at a minimum, know who they are. In this article, the authors discuss face recognition technology, how it works, problems to be overcome, current technologies, and future developments and possible applications. Twenty years ago, the problem of face recognition was considered among the most difficult in artificial intelligence and computer vision. Today, however, there are several companies that sell commercial face recognition software that is capable of high-accuracy recognition with databases of more than 1,000 people. The authors describe the face recognition technology used, explaining the algorithms for face recognition as well as novel applications, such as behavior monitoring that assesses emotions based on facial expressions."
            },
            "slug": "Face-Recognition-for-Smart-Environments-Pentland-Choudhury",
            "title": {
                "fragments": [],
                "text": "Face Recognition for Smart Environments"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "The authors describe the face recognition technology used, explaining the algorithms for face recognition as well as novel applications, such as behavior monitoring that assesses emotions based on facial expressions."
            },
            "venue": {
                "fragments": [],
                "text": "Computer"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1723124"
                        ],
                        "name": "R. E. Kent",
                        "slug": "R.-E.-Kent",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Kent",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. E. Kent"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14383150,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4351e54a492d71c60d4c02fcd8b5a12657bc1d40",
            "isKey": false,
            "numCitedBy": 15,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper, the first step to connect relational databases with systems consequence (Kent [5]), is concerned with the semantics of relational databases. It aims to to study system consequence in the logical/semantic system of relational databases. The paper, which was inspired by and which extends a recent set of papers on the theory of relational database systems (Spivak [6] [7]), is linked with work on the Information Flow Framework (IFF [9]) connected with the ontology standards effort (SUO), since relational databases naturally embed into first order logic. The database semantics discussed here is concerned with the conceptual level of database architecture. We offer both an intuitive and technical discussion. Corresponding to the notions of primary and foreign keys, relational database semantics takes two forms: a distinguished form where entities are distinguished from relations, and a unified form where relations and entities coincide. The distinguished form corresponds to the theory presented in (Spivak [6]). The unified form, a special case of the distinguished form, corresponds to the theory presented in (Spivak [7]). A later paper will discuss various formalisms of relational databases, such as relational algebra and first order logic, and will complete the description of the relational database logical environment."
            },
            "slug": "Database-Semantics-Kent",
            "title": {
                "fragments": [],
                "text": "Database Semantics"
            },
            "tldr": {
                "abstractSimilarityScore": 55,
                "text": "This paper aims to to study system consequence in the logical/semantic system of relational databases with work on the Information Flow Framework connected with the ontology standards effort (SUO), since relational databases naturally embed into first order logic."
            },
            "venue": {
                "fragments": [],
                "text": "IFIP \u2014 The International Federation for Information Processing"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2111010157"
                        ],
                        "name": "Richard C. Wilson",
                        "slug": "Richard-C.-Wilson",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Wilson",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Richard C. Wilson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1679753"
                        ],
                        "name": "E. Hancock",
                        "slug": "E.-Hancock",
                        "structuredName": {
                            "firstName": "Edwin",
                            "lastName": "Hancock",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Hancock"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5698143,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6382ab4fffd4322afb8cc5667fd54e8df3cf4c65",
            "isKey": false,
            "numCitedBy": 345,
            "numCiting": 42,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes a Bayesian framework for performing relational graph matching by discrete relaxation. Our basic aim is to draw on this framework to provide a comparative evaluation of a number of contrasting approaches to relational matching. Broadly speaking there are two main aspects to this study. Firstly we focus on the issue of how relational inexactness may be quantified. We illustrate that several popular relational distance measures can be recovered as specific limiting cases of the Bayesian consistency measure. The second aspect of our comparison concerns the way in which structural inexactness is controlled. We investigate three different realizations of the matching process which draw on contrasting control models. The main conclusion of our study is that the active process of graph-editing outperforms the alternatives in terms of its ability to effectively control a large population of contaminating clutter."
            },
            "slug": "Structural-Matching-by-Discrete-Relaxation-Wilson-Hancock",
            "title": {
                "fragments": [],
                "text": "Structural Matching by Discrete Relaxation"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "The main conclusion of the study is that the active process of graph-editing outperforms the alternatives in terms of its ability to effectively control a large population of contaminating clutter."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "27379268"
                        ],
                        "name": "M. Werman",
                        "slug": "M.-Werman",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Werman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Werman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1789171"
                        ],
                        "name": "D. Weinshall",
                        "slug": "D.-Weinshall",
                        "structuredName": {
                            "firstName": "Daphna",
                            "lastName": "Weinshall",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Weinshall"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15086346,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "id": "d2f6cf8be7aa86b41e4330336783e2b8ea0b0ea3",
            "isKey": false,
            "numCitedBy": 129,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "We develop expressions for measuring the distance between 2D point sets, which are invariant to either 2D affine transformations or 2D similarity transformations of the sets, and assuming a known correspondence between the point sets. We discuss the image normalization to be applied to the images before their comparison so that the computed distance is symmetric with respect to the two images. We then give a general (metric) definition of the distance between images, which leads to the same expressions for the similarity and affine cases. This definition avoids ad hoc decisions about normalization. Moreover, it makes it possible to compute the distance between images under different conditions, including cases where the images are treated asymmetrically. We demonstrate these results with real and simulated images. >"
            },
            "slug": "Similarity-and-Affine-Invariant-Distances-Between-Werman-Weinshall",
            "title": {
                "fragments": [],
                "text": "Similarity and Affine Invariant Distances Between 2D Point Sets"
            },
            "tldr": {
                "abstractSimilarityScore": 96,
                "text": "This work develops expressions for measuring the distance between 2D point sets, which are invariant to either 2D affine transformations or 2D similarity transformations of the sets, and assuming a known correspondence between the point sets."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1918501"
                        ],
                        "name": "Terence Wang",
                        "slug": "Terence-Wang",
                        "structuredName": {
                            "firstName": "Terence",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Terence Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2116625508"
                        ],
                        "name": "Chin-Liang Wang",
                        "slug": "Chin-Liang-Wang",
                        "structuredName": {
                            "firstName": "Chin-Liang",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chin-Liang Wang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7176697,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c5a7c332a0d8446d7ec36d18cbb589662e0b990f",
            "isKey": false,
            "numCitedBy": 40,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a new two-dimensional (2-D) optimum block stochastic gradient (TDOBSG) algorithm for 2-D adaptive finite impulse response (FIR) filtering. The TDOBSG algorithm employs a space-varying convergence factor for all the filter coefficients, where the convergence factor at each block iteration is optimized in a least squares sense that the squared norm of the a posteriori estimation error vector is minimized. It has the same order of computational complexity as another 2-D optimum block adaptive (TDOBA) algorithm. Computer simulations for image restoration show that the TDOBSG algorithm outperforms the TDOBA algorithm and other related algorithms in terms of objective and/or subjective measures."
            },
            "slug": "A-new-two-dimensional-block-adaptive-FIR-filtering-Wang-Wang",
            "title": {
                "fragments": [],
                "text": "A new two-dimensional block adaptive FIR filtering algorithm and its application to image restoration"
            },
            "tldr": {
                "abstractSimilarityScore": 72,
                "text": "A new two-dimensional (2-D) optimum block stochastic gradient (TDOBSG) algorithm for 2-D adaptive finite impulse response (FIR) filtering that outperforms the TDOBA algorithm and other related algorithms in terms of objective and/or subjective measures."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Image Process."
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2841968"
                        ],
                        "name": "J. Oakley",
                        "slug": "J.-Oakley",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Oakley",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Oakley"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "41195818"
                        ],
                        "name": "D. N. Davis",
                        "slug": "D.-N.-Davis",
                        "structuredName": {
                            "firstName": "Darryl",
                            "lastName": "Davis",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. N. Davis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2831051"
                        ],
                        "name": "R. T. Shann",
                        "slug": "R.-T.-Shann",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Shann",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. T. Shann"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 169,
                                "start": 164
                            }
                        ],
                        "text": "With respect to experimental practices that use human subjects, a distinction can be made between the evaluation of a complete system and that of parts of a system [145]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 58032734,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9c64b15d913b304825d147e772b66b042620ad03",
            "isKey": false,
            "numCitedBy": 837,
            "numCiting": 41,
            "paperAbstract": {
                "fragments": [],
                "text": "(1995). \" Image indexing and retrieval: some problems and proposed Solutions \" ."
            },
            "slug": "Storage-and-Retrieval-for-Image-and-Video-Databases-Oakley-Davis",
            "title": {
                "fragments": [],
                "text": "Storage and Retrieval for Image and Video Databases"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1803668"
                        ],
                        "name": "E. Angelopoulou",
                        "slug": "E.-Angelopoulou",
                        "structuredName": {
                            "firstName": "Elli",
                            "lastName": "Angelopoulou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Angelopoulou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34740030"
                        ],
                        "name": "L. B. Wolff",
                        "slug": "L.-B.-Wolff",
                        "structuredName": {
                            "firstName": "Lawrence",
                            "lastName": "Wolff",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. B. Wolff"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 31868366,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "589ab0cf71e0141b32d5861ca95a29a74530870f",
            "isKey": false,
            "numCitedBy": 32,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "We compute the sign of Gaussian curvature using a purely geometric definition. Consider a point p on a smooth surface S and a closed curve /spl gamma/ on S which encloses p. The image of /spl gamma/ on the unit normal Gaussian sphere is a new curve /spl beta/. The Gaussian curvature at p is defined as the ratio of the area enclosed by /spl gamma/ over the area enclosed by /spl beta/ as /spl gamma/ contracts to p. The sign of Gaussian curvature at p is determined by the relative orientations of the closed curves /spl gamma/ and /spl beta/. We directly compute the relative orientation of two such curves from intensity data. We employ three unknown illumination conditions to create a photometric scatter plot. This plot is in one-to-one correspondence with the subset of the unit Gaussian sphere containing the mutually illuminated surface normal. This permits direct computation of the sign of Gaussian curvature without the recovery of surface normals. Our method is albedo invariant. We assume diffuse reflectance, but the nature of the diffuse reflectance can be general and unknown. Error analysis on simulated images shows the accuracy of our technique. We also demonstrate the performance of this methodology on empirical data."
            },
            "slug": "Sign-of-Gaussian-Curvature-From-Curve-Orientation-Angelopoulou-Wolff",
            "title": {
                "fragments": [],
                "text": "Sign of Gaussian Curvature From Curve Orientation in Photometric Space"
            },
            "tldr": {
                "abstractSimilarityScore": 60,
                "text": "The sign of Gaussian curvature is computed using a purely geometric definition using the relative orientations of the closed curves /spl gamma/ and /spl beta/ from intensity data and the performance of this methodology on empirical data is demonstrated."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1756534"
                        ],
                        "name": "H. Wolfson",
                        "slug": "H.-Wolfson",
                        "structuredName": {
                            "firstName": "Haim",
                            "lastName": "Wolfson",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Wolfson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2598854"
                        ],
                        "name": "I. Rigoutsos",
                        "slug": "I.-Rigoutsos",
                        "structuredName": {
                            "firstName": "Isidore",
                            "lastName": "Rigoutsos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Rigoutsos"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 11915313,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3efe88739c2604d7fede2cf1da977670dd7968e6",
            "isKey": false,
            "numCitedBy": 625,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "Geometric hashing, a technique originally developed in computer vision for matching geometric features against a database of such features, finds use in a number of other areas. Matching is possible even when the recognizable database objects have undergone transformations or when only partial information is present. The technique is highly efficient and of low polynomial complexity."
            },
            "slug": "Geometric-hashing:-an-overview-Wolfson-Rigoutsos",
            "title": {
                "fragments": [],
                "text": "Geometric hashing: an overview"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "Geometric hashing, a technique originally developed in computer vision for matching geometric features against a database of such features, finds use in a number of other areas."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1932191"
                        ],
                        "name": "Greet Frederix",
                        "slug": "Greet-Frederix",
                        "structuredName": {
                            "firstName": "Greet",
                            "lastName": "Frederix",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Greet Frederix"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3266794"
                        ],
                        "name": "E. Pauwels",
                        "slug": "E.-Pauwels",
                        "structuredName": {
                            "firstName": "Eric",
                            "lastName": "Pauwels",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Pauwels"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 28023751,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cdafaa2e4941e9c690ac701b93fe782074ddf2d5",
            "isKey": false,
            "numCitedBy": 5,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "We report on preliminary but promising experiments that attempt to get automatic annotation of (parts of) real images by using non-parametric clustering to identify salient regions, followed by a limb-characterization algorithm applied to the contours of the regions."
            },
            "slug": "Automatic-Interpretation-Based-on-Robust-and-Frederix-Pauwels",
            "title": {
                "fragments": [],
                "text": "Automatic Interpretation Based on Robust Segmentation and Shape-Extraction"
            },
            "tldr": {
                "abstractSimilarityScore": 95,
                "text": "Preliminary but promising experiments that attempt to get automatic annotation of (parts of) real images by using non-parametric clustering to identify salient regions, followed by a limb-characterization algorithm applied to the contours of the regions."
            },
            "venue": {
                "fragments": [],
                "text": "VISUAL"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1776657"
                        ],
                        "name": "W. Qian",
                        "slug": "W.-Qian",
                        "structuredName": {
                            "firstName": "Wei",
                            "lastName": "Qian",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Qian"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2151633"
                        ],
                        "name": "M. Kallergi",
                        "slug": "M.-Kallergi",
                        "structuredName": {
                            "firstName": "Maria",
                            "lastName": "Kallergi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Kallergi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7159032"
                        ],
                        "name": "L. Clarke",
                        "slug": "L.-Clarke",
                        "structuredName": {
                            "firstName": "Laurence",
                            "lastName": "Clarke",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Clarke"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2137395"
                        ],
                        "name": "H. Li",
                        "slug": "H.-Li",
                        "structuredName": {
                            "firstName": "H",
                            "lastName": "Li",
                            "middleNames": [
                                "D"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50153120"
                        ],
                        "name": "P. Venugopal",
                        "slug": "P.-Venugopal",
                        "structuredName": {
                            "firstName": "Priya",
                            "lastName": "Venugopal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Venugopal"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1868866"
                        ],
                        "name": "D. Song",
                        "slug": "D.-Song",
                        "structuredName": {
                            "firstName": "Dansheng",
                            "lastName": "Song",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Song"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2107741597"
                        ],
                        "name": "R. Clark",
                        "slug": "R.-Clark",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Clark",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Clark"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 41335790,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0380f8231b7acb7179ffd342133ec045f7cdbf39",
            "isKey": false,
            "numCitedBy": 66,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "A novel multistage algorithm is proposed for the automatic segmentation of microcalcification clusters (MCCs) in digital mammography. First, a previously reported tree structured nonlinear filter is proposed for suppressing image noise, while preserving image details, to potentially reduce the false positive (FP) detection rate for MCCs. Second, a tree structured wavelet transform (TSWT) is applied to the images for microcalcification segmentation. The TSWT employs quadrature mirror filters as basic subunits for both multiresolution decomposition and reconstruction processes, where selective reconstruction of subimages is used to segment MCCs. Third, automatic linear scaling is then used to display the image of the segmented MCCs on a computer monitor for interpretation. The proposed algorithms were applied to an image database of 100 single view mammograms at a resolution of 105 microns and 12 bits deep (4096 gray levels). The database contained 50 cases of biopsy proven malignant MCCs, 8 benign cases, and 42 normal cases. The measured sensitivity (true positive detection rate) was 94% with a low FP detection rate of 1.6 MCCs/image. The image details of the segmented MCCs were reasonably well preserved, for microcalcification of less than 500 microns, with good delineation of the extent of the microcalcification clusters for each case based on visual criteria."
            },
            "slug": "Tree-structured-wavelet-transform-segmentation-of-Qian-Kallergi",
            "title": {
                "fragments": [],
                "text": "Tree structured wavelet transform segmentation of microcalcifications in digital mammography."
            },
            "tldr": {
                "abstractSimilarityScore": 71,
                "text": "A novel multistage algorithm is proposed for the automatic segmentation of microcalcification clusters (MCCs) in digital mammography by suppressing image noise, while preserving image details, to potentially reduce the false positive (FP) detection rate for MCCs."
            },
            "venue": {
                "fragments": [],
                "text": "Medical physics"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40179523"
                        ],
                        "name": "J. L. Hafner",
                        "slug": "J.-L.-Hafner",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Hafner",
                            "middleNames": [
                                "Lee"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. L. Hafner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733393"
                        ],
                        "name": "H. Sawhney",
                        "slug": "H.-Sawhney",
                        "structuredName": {
                            "firstName": "Harpreet",
                            "lastName": "Sawhney",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Sawhney"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712308"
                        ],
                        "name": "W. Equitz",
                        "slug": "W.-Equitz",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Equitz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Equitz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712991"
                        ],
                        "name": "M. Flickner",
                        "slug": "M.-Flickner",
                        "structuredName": {
                            "firstName": "Myron",
                            "lastName": "Flickner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Flickner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2141915"
                        ],
                        "name": "W. Niblack",
                        "slug": "W.-Niblack",
                        "structuredName": {
                            "firstName": "Wayne",
                            "lastName": "Niblack",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Niblack"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 33312054,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "e1dec5c4aaff8e79ebdcca5feec2640aebce323a",
            "isKey": false,
            "numCitedBy": 934,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "An improved shipping container having novel locking features in the end panel and corner flaps. The novel locking features improved bulge resistance at the end panels from sideward bulge of the product. The improved container comprises a pair of corner flaps being hinged from the side panels and folded inwardly against an end panel with the two corner flaps and end panel on each side of the container having a quadruple lock. The lock is formed by providing a locking tab on each corner flap as well as a pair of locking tabs on the end panel with the end panel and corner flaps locking tabs being designed to be swung and locked in the opening formed by the aligned mating locking tab."
            },
            "slug": "Efficient-Color-Histogram-Indexing-for-Quadratic-Hafner-Sawhney",
            "title": {
                "fragments": [],
                "text": "Efficient Color Histogram Indexing for Quadratic Form Distance Functions"
            },
            "tldr": {
                "abstractSimilarityScore": 85,
                "text": "An improved shipping container having novel locking features in the end panel and corner flaps and improved bulge resistance at the end panels from sideward bulge of the product."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144638781"
                        ],
                        "name": "A. Smeulders",
                        "slug": "A.-Smeulders",
                        "structuredName": {
                            "firstName": "Arnold",
                            "lastName": "Smeulders",
                            "middleNames": [
                                "W.",
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Smeulders"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8826771"
                        ],
                        "name": "M. Kersten",
                        "slug": "M.-Kersten",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "Kersten",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Kersten"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695527"
                        ],
                        "name": "T. Gevers",
                        "slug": "T.-Gevers",
                        "structuredName": {
                            "firstName": "Theo",
                            "lastName": "Gevers",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Gevers"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 18489010,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0dbfa403d009b83d83ea8a25625b13261c2f7049",
            "isKey": false,
            "numCitedBy": 27,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "Image databases call upon the combined effort of computing vision and database technology to advance beyond exemplary systems. In this paper we charter several areas for mutually beneficial research activities and provide an archi\u00ad tectural design to accommodate it."
            },
            "slug": "Crossing-the-Divide-Between-Computer-Vision-and-in-Smeulders-Kersten",
            "title": {
                "fragments": [],
                "text": "Crossing the Divide Between Computer Vision and Databases in Search of Image Databases"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This paper charter several areas for mutually beneficial research activities and provides an archi\u00ad tectural design to accommodate it."
            },
            "venue": {
                "fragments": [],
                "text": "VDB"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38011004"
                        ],
                        "name": "D. Judd",
                        "slug": "D.-Judd",
                        "structuredName": {
                            "firstName": "Dan",
                            "lastName": "Judd",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Judd"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1700396"
                        ],
                        "name": "P. McKinley",
                        "slug": "P.-McKinley",
                        "structuredName": {
                            "firstName": "Philip",
                            "lastName": "McKinley",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. McKinley"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145295484"
                        ],
                        "name": "Anil K. Jain",
                        "slug": "Anil-K.-Jain",
                        "structuredName": {
                            "firstName": "Anil",
                            "lastName": "Jain",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Anil K. Jain"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5944314,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "98af05675a3293e398b0eb12c1fe8632abdd223b",
            "isKey": false,
            "numCitedBy": 108,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "Algorithmic enhancements are described that allow large reduction (for some data sets, over 95 percent) in the number of floating point operations in mean square error data clustering. These improvements are incorporated into a parallel data clustering tool, P-CLUSTER, developed in an earlier study. Experiments on segmenting standard texture images show that the proposed enhancements enable clustering of an entire 512/spl times/512 image at approximately the same computational cost as that of previous methods applied to only 5 percent of the image pixels."
            },
            "slug": "Large-scale-parallel-data-clustering-Judd-McKinley",
            "title": {
                "fragments": [],
                "text": "Large-scale parallel data clustering"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "Experiments on segmenting standard texture images show that the proposed enhancements enable clustering of an entire 512/spl times/512 image at approximately the same computational cost as that of previous methods applied to only 5 percent of the image pixels."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of 13th International Conference on Pattern Recognition"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144564069"
                        ],
                        "name": "C. Chui",
                        "slug": "C.-Chui",
                        "structuredName": {
                            "firstName": "Charles",
                            "lastName": "Chui",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Chui"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3341994"
                        ],
                        "name": "L. Montefusco",
                        "slug": "L.-Montefusco",
                        "structuredName": {
                            "firstName": "Laura",
                            "lastName": "Montefusco",
                            "middleNames": [
                                "Bacchelli"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Montefusco"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "36784348"
                        ],
                        "name": "L. Puccio",
                        "slug": "L.-Puccio",
                        "structuredName": {
                            "firstName": "Luigia",
                            "lastName": "Puccio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Puccio"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 111,
                                "start": 107
                            }
                        ],
                        "text": "As long as the gap is there, use of contentbased retrieval for browsing will not be within the grasp of the general public as humans are accustomed to rely on the immediate semantic imprint the moment they see an image."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 118505072,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b85175c25d555192d52cb28999576937d45790e8",
            "isKey": false,
            "numCitedBy": 174,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Multiresolution and Multilevel Analyses: A. Cohen, Non-stationary Multiscale Analysis. P.N. Heller, and R.O. Wells, Jr., The Spectral Theory of Multiresolution Operators and Applications. S. Dahlke, Multiresolution Analysis, Haar Bases and Wavelets on Reimannian Manifolds. T.N.T. Goodman and C.A. Micchelli, Orthonormal Cardinal Functions. Wavelet Transforms: B. Torresani, Some Remarks on Wavelet Representations and Geometric Aspects. J. Kautsky and R. Turcajova, A Matrix Approach to Discrete Wavelets. G. Plonka and M. Tasche, A Unified Approach to Periodic Wavelets. Spline-Wavelets: G. Steidl, Spline Wavlets over R Z R/NZ and Z/NZ. S. Sakakibara, A Practice of Data Smoothing by B-Spline Wavelets. T. Lyche and L.L. Schumaker, L-Spline Wavelets. C.K. Chui, K. Jetter, and J. Stickler, Wavelets and Frames on the Four-Directional Mesh. Other Mathematical Tools for Time-Frequency Analysis: D.L. Donoho, On Minimum Entropy Segmentation. G. Davis, S. Mallat, and Z. Zhang, Adaptive Time-Frequency Approximations with Matching Pursuits. B.W. Suter and M.E. Oxley, Getting Around the Balian-Low Theorem Using Generalized Malvar Wavelets. G. Courbebaisse, B. Escudie, and T. Paul, Time Scale Energetic Distribution. Wavelets and Fractals: S. Jaffard, Some Mathematical Results about the Multifractal Formalism for Functions. M. Holschneider, Fractal Wavelet Dimensions and Time Evolution. Numerical Methods and Algorithms: W. Dahmen, S. Prissdorf, and R. Schneider Multiscale Methods for Pseudo-Differential Equations on Smooth Closed Manifolds. S. Bertoluzza, G. Naldi, and J.C. Ravel, Wavelet Methods for the Numerical Solution of Boundary Value Problems on the Interval. D. Karayannakis, On the Nodal Values of the Franklin Analyzing Wavelet. L.B. Montefusco, Parallel Numerical Algorithms with Orthonormal Wavelet Packet Bases. P. Fischer and M. Defranceschi, Representation of the Atomic Hartree-Fock Equations in a Wavelet Basis by Means of the BCR Algorithm. Applications: M.V. Wickerhauser, M. Farge, E. Goirand, E. Wesfreid, and E. Cubillo,Efficiency Comparison of Wavelet Packet and Adapted Local Cosine Bases for Compression of a Two-Dimensional Turbulent Flow. M.E. Mayer, L. Hudgins, and C.A. Friehe, Wavelet Spectra of Buoyant Atmospheric Turbulence. A. Druilhet, J.-L. Attiee, L.de Abreu Sa, P. Durand, and B. Benech, Experimental Study of Inhomogeneous Turbulence in the Lower Troposphere by Wavelet Analysis. G. Olmo and L.L. Presti, Applications of Wavelet Transform for Seismic Activity Monitoring. A. Denjean and F. Castanie, Mean Value Jump Detection: A Survey of Conventional and Wavelet Based Methods. M.V. Wickerhauser, Comparison of Picture Compression Methods: Wavelet, Wavelet Packet, and Local Cosine Transform Coding. Subject Index."
            },
            "slug": "Wavelets-:-theory,-algorithms,-and-applications-Chui-Montefusco",
            "title": {
                "fragments": [],
                "text": "Wavelets : theory, algorithms, and applications"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This paper presents the results of a large-scale study of Inhomogeneous Turbulence in the Lower Troposphere by Wavelet Analysis and a comparison of Picture Compression Methods: Wavelet, Wavelet Packet, and Local Cosine Transform Coding."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144969774"
                        ],
                        "name": "D. Dubois",
                        "slug": "D.-Dubois",
                        "structuredName": {
                            "firstName": "Didier",
                            "lastName": "Dubois",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Dubois"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1700697"
                        ],
                        "name": "H. Prade",
                        "slug": "H.-Prade",
                        "structuredName": {
                            "firstName": "Henri",
                            "lastName": "Prade",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Prade"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 23694083,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c3a53b722eef086ac54d6c2ac21ef04043a0c28c",
            "isKey": false,
            "numCitedBy": 938,
            "numCiting": 87,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-review-of-fuzzy-set-aggregation-connectives-Dubois-Prade",
            "title": {
                "fragments": [],
                "text": "A review of fuzzy set aggregation connectives"
            },
            "venue": {
                "fragments": [],
                "text": "Inf. Sci."
            },
            "year": 1985
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1724709"
                        ],
                        "name": "S. Arya",
                        "slug": "S.-Arya",
                        "structuredName": {
                            "firstName": "Sunil",
                            "lastName": "Arya",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Arya"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1709509"
                        ],
                        "name": "D. Mount",
                        "slug": "D.-Mount",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Mount",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Mount"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712586"
                        ],
                        "name": "N. Netanyahu",
                        "slug": "N.-Netanyahu",
                        "structuredName": {
                            "firstName": "Nathan",
                            "lastName": "Netanyahu",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Netanyahu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "37746341"
                        ],
                        "name": "R. Silverman",
                        "slug": "R.-Silverman",
                        "structuredName": {
                            "firstName": "Ruth",
                            "lastName": "Silverman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Silverman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1736712"
                        ],
                        "name": "A. Wu",
                        "slug": "A.-Wu",
                        "structuredName": {
                            "firstName": "Angela",
                            "lastName": "Wu",
                            "middleNames": [
                                "Y."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Wu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8193729,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "219101fe724232acc330ff0910152931538f85c7",
            "isKey": false,
            "numCitedBy": 2723,
            "numCiting": 94,
            "paperAbstract": {
                "fragments": [],
                "text": "Consider a set of <italic>S</italic> of <italic>n</italic> data points  in real <italic>d</italic>-dimensional space, R<supscrpt>d</supscrpt>, where distances are measured using any Minkowski metric. In nearest neighbor searching, we preprocess <italic>S</italic> into a data structure, so that given any query point <italic>q</italic><inline-equation> <f>\u2208</f></inline-equation> R<supscrpt>d</supscrpt>, is the closest point of S to <italic>q</italic> can be reported quickly. Given any positive real \u03b5, data point <italic>p</italic> is a (1 +\u03b5)-<italic>approximate nearest neighbor</italic> of <italic>q</italic> if its distance from <italic>q</italic> is within a factor of (1 + \u03b5) of the distance to the true nearest neighbor. We show that it is possible to preprocess a    set of <italic>n</italic> points in     R<supscrpt>d</supscrpt> in <italic>O(dn</italic> log <italic>n</italic>) time and <italic>O(dn)</italic> space, so that given a query point <italic> q</italic> <inline-equation> <f>\u2208</f></inline-equation> R<supscrpt>d</supscrpt>, and \u03b5 > 0, a (1 + \u03b5)-approximate nearest neighbor of <italic>q</italic> can be computed in <italic>O</italic>(<italic>c</italic><subscrpt><italic>d</italic>, \u03b5</subscrpt> log <italic>n</italic>) time, where <italic>c<subscrpt>d,\u03b5</subscrpt></italic>\u2264<italic>d</italic> <inline-equation> <f><fen lp=\"ceil\">1 + 6d/<g>e</g><rp post=\"ceil\"></fen></f></inline-equation>;<supscrpt>d</supscrpt> is a factor depending only on dimension and \u03b5. In general, we show that given an integer <italic>k</italic> \u2265 1, (1 + \u03b5)-approximations  to the  <italic>k</italic> nearest neighbors of <italic>q</italic> can  be computed in additional <italic>O(kd</italic> log <italic>n</italic>) time."
            },
            "slug": "An-optimal-algorithm-for-approximate-nearest-fixed-Arya-Mount",
            "title": {
                "fragments": [],
                "text": "An optimal algorithm for approximate nearest neighbor searching fixed dimensions"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "It is shown that it is possible to preprocess a set of data points in real D-dimensional space in O(kd) time and in additional space, so that given a query point q, the closest point of S to S to q can be reported quickly."
            },
            "venue": {
                "fragments": [],
                "text": "JACM"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2942047"
                        ],
                        "name": "Hyeokho Choi",
                        "slug": "Hyeokho-Choi",
                        "structuredName": {
                            "firstName": "Hyeokho",
                            "lastName": "Choi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hyeokho Choi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144908066"
                        ],
                        "name": "Richard Baraniuk",
                        "slug": "Richard-Baraniuk",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Baraniuk",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Richard Baraniuk"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14303538,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "ad430a75c2166b216366adda8e57eb7a76e20a3d",
            "isKey": false,
            "numCitedBy": 29,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "Wavelet-domain hidden Markov tree (HMT) models are powerful tools for modeling the statistical properties of wavelet transforms. By characterizing the joint statistics of the wavelet coefficients, HMTs efficiently capture the characteristics of a large class of real-world signals and images. In this paper, we apply this multiscale statistical description to the texture segmentation problem. Using the inherent tree structure of the HMT, we classify textures at various scales and then fuse these decisions into a reliable pixel-by-pixel segmentation."
            },
            "slug": "Multiscale-texture-segmentation-using-hidden-Markov-Choi-Baraniuk",
            "title": {
                "fragments": [],
                "text": "Multiscale texture segmentation using wavelet-domain hidden Markov models"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "This paper applies the inherent tree structure of the HMT to the texture segmentation problem, and classify textures at various scales and then fuse these decisions into a reliable pixel-by-pixel segmentation."
            },
            "venue": {
                "fragments": [],
                "text": "Conference Record of Thirty-Second Asilomar Conference on Signals, Systems and Computers (Cat. No.98CH36284)"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1808423"
                        ],
                        "name": "G. Csurka",
                        "slug": "G.-Csurka",
                        "structuredName": {
                            "firstName": "Gabriela",
                            "lastName": "Csurka",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Csurka"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "33726225"
                        ],
                        "name": "O. Faugeras",
                        "slug": "O.-Faugeras",
                        "structuredName": {
                            "firstName": "Olivier",
                            "lastName": "Faugeras",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Faugeras"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 5056356,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "8009b9cc532b3abd317e63e69cfbb349d17193b1",
            "isKey": false,
            "numCitedBy": 15,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "Studies the computation of projective invariants in pairs of images from uncalibrated cameras and presents a detailed study of the projective and permutation invariants for configurations of points and/or lines. Two basic computational approaches are given, one algebraic and one geometric. In each case, invariants are computed in projective space or directly from image measurements. Finally, we develop combinations of those projective invariants which are insensitive to permutations of the geometric primitives of each of the basic configurations."
            },
            "slug": "Algebraic-and-Geometric-Tools-to-Compute-Projective-Csurka-Faugeras",
            "title": {
                "fragments": [],
                "text": "Algebraic and Geometric Tools to Compute Projective and Permutation Invariants"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "Studies the computation of projective invariants in pairs of images from uncalibrated cameras and presents a detailed study of the projective and permutation invariants for configurations of points and/or lines."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2137198"
                        ],
                        "name": "R. Shepard",
                        "slug": "R.-Shepard",
                        "structuredName": {
                            "firstName": "Roger",
                            "lastName": "Shepard",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Shepard"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2536571,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "00779852a69a18653fc9df0fbe119e975213fe7c",
            "isKey": false,
            "numCitedBy": 2221,
            "numCiting": 64,
            "paperAbstract": {
                "fragments": [],
                "text": "A psychological space is established for any set of stimuli by determining metric distances between the stimuli such that the probability that a response learned to any stimulus will generalize to any other is an invariant monotonic function of the distance between them. To a good approximation, this probability of generalization (i) decays exponentially with this distance, and (ii) does so in accordance with one of two metrics, depending on the relation between the dimensions along which the stimuli vary. These empirical regularities are mathematically derivable from universal principles of natural kinds and probabilistic geometry that may, through evolutionary internalization, tend to govern the behaviors of all sentient organisms."
            },
            "slug": "Toward-a-universal-law-of-generalization-for-Shepard",
            "title": {
                "fragments": [],
                "text": "Toward a universal law of generalization for psychological science."
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "A psychological space is established for any set of stimuli by determining metric distances between the stimuli such that the probability that a response learned to any stimulus will generalize to any other is an invariant monotonic function of the distance between them."
            },
            "venue": {
                "fragments": [],
                "text": "Science"
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "100608313"
                        ],
                        "name": "B. Saravanos",
                        "slug": "B.-Saravanos",
                        "structuredName": {
                            "firstName": "B.",
                            "lastName": "Saravanos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Saravanos"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 137,
                                "start": 132
                            }
                        ],
                        "text": "Wellknown techniques from social sciences can be used for the experimental design [19] and for the statistical analysis of the data [104]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 18852961,
            "fieldsOfStudy": [
                "Geology"
            ],
            "id": "e67ff2d4b0bd0c08f1a1126c487a0eaccbd41a9c",
            "isKey": false,
            "numCitedBy": 422,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "WHILE the introduction of statistical methods into the analysis of aeronautical experimental data, whether for quality control in production, for the interpretation of the results of structural and aerodynamic laboratory experiments, or for airline operation, has been brought about only in recent years, it may by now be fair to assert that their advantages and even their indispensability are no longer in dispute. Hitherto, investigations on these lines have usually involved, explicitly or implicitly, only the \u2018normal curve of error\u2019 and allied considerations; owing, it may be thought, to the controllability of the various manufacturing or laboratory techniques, but also perhaps to the scarcity of data hitherto available. It may well be, however, that with the accumulation of information arising out of investigations planned with particular reference to the statistical analysis of their results the whole range of the apparatus for statistical analysis, usually confined to such fields as those of biology or economics, will be called into full play."
            },
            "slug": "The-Statistical-Analysis,-of-Experimental-Data-Saravanos",
            "title": {
                "fragments": [],
                "text": "The Statistical Analysis, of Experimental Data"
            },
            "tldr": {
                "abstractSimilarityScore": 96,
                "text": "The introduction of statistical methods into the analysis of aeronautical experimental data, whether for quality control in production, for the interpretation of the results of structural and aerodynamic laboratory experiments, or for airline operation, has been brought about only in recent years, it may by now be fair to assert that their advantages are no longer in dispute."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1949
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35043531"
                        ],
                        "name": "A. Dempster",
                        "slug": "A.-Dempster",
                        "structuredName": {
                            "firstName": "Arthur",
                            "lastName": "Dempster",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Dempster"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7890796"
                        ],
                        "name": "N. Laird",
                        "slug": "N.-Laird",
                        "structuredName": {
                            "firstName": "Nan",
                            "lastName": "Laird",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Laird"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2235217"
                        ],
                        "name": "D. Rubin",
                        "slug": "D.-Rubin",
                        "structuredName": {
                            "firstName": "Donald",
                            "lastName": "Rubin",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Rubin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 4193919,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "d36efb9ad91e00faa334b549ce989bfae7e2907a",
            "isKey": false,
            "numCitedBy": 48403,
            "numCiting": 134,
            "paperAbstract": {
                "fragments": [],
                "text": "Vibratory power unit for vibrating conveyers and screens comprising an asynchronous polyphase motor, at least one pair of associated unbalanced masses disposed on the shaft of said motor, with the first mass of a pair of said unbalanced masses being rigidly fastened to said shaft and with said second mass of said pair being movably arranged relative to said first mass, means for controlling and regulating the conveying rate during conveyer operation by varying the rotational speed of said motor between predetermined minimum and maximum values, said second mass being movably outwardly by centrifugal force against the pressure of spring means, said spring means being prestressed in such a manner that said second mass is, at rotational motor speeds lower than said minimum speed, held in its initial position, and at motor speeds between said lower and upper values in positions which are radially offset with respect to the axis of said motor to an extent depending on the value of said rotational motor speed."
            },
            "slug": "Maximum-likelihood-from-incomplete-data-via-the-EM-Dempster-Laird",
            "title": {
                "fragments": [],
                "text": "Maximum likelihood from incomplete data via the EM - algorithm plus discussions on the paper"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1977
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1737063"
                        ],
                        "name": "I. Daubechies",
                        "slug": "I.-Daubechies",
                        "structuredName": {
                            "firstName": "Ingrid",
                            "lastName": "Daubechies",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Daubechies"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 190,
                                "start": 186
                            }
                        ],
                        "text": "New challenges in content-based retrieval compared to the achievements of object recognition are the interactive manipulation of results, the usually very large number of object classes, and the absence of an explicit training phase for feature and classifier tuning."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 58524360,
            "fieldsOfStudy": [
                "Geology"
            ],
            "id": "7e63bf9af3f70abd5771c06d459a0d3fbfbb2909",
            "isKey": false,
            "numCitedBy": 15553,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Introduction Preliminaries and notation The what, why, and how of wavelets The continuous wavelet transform Discrete wavelet transforms: Frames Time-frequency density and orthonormal bases Orthonormal bases of wavelets and multiresolutional analysis Orthonormal bases of compactly supported wavelets More about the regularity of compactly supported wavelets Symmetry for compactly supported wavelet bases Characterization of functional spaces by means of wavelets Generalizations and tricks for orthonormal wavelet bases References Indexes."
            },
            "slug": "Ten-Lectures-on-Wavelets-Daubechies",
            "title": {
                "fragments": [],
                "text": "Ten Lectures on Wavelets"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This paper presents a meta-analyses of the wavelet transforms of Coxeter\u2019s inequality and its applications to multiresolutional analysis and orthonormal bases."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50560492"
                        ],
                        "name": "V. Vapnik",
                        "slug": "V.-Vapnik",
                        "structuredName": {
                            "firstName": "Vladimir",
                            "lastName": "Vapnik",
                            "middleNames": [
                                "Naumovich"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Vapnik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "principle of transduction [181]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 7138354,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8213dbed4db44e113af3ed17d6dad57471a0c048",
            "isKey": false,
            "numCitedBy": 38755,
            "numCiting": 72,
            "paperAbstract": {
                "fragments": [],
                "text": "Setting of the learning problem consistency of learning processes bounds on the rate of convergence of learning processes controlling the generalization ability of learning processes constructing learning algorithms what is important in learning theory?."
            },
            "slug": "The-Nature-of-Statistical-Learning-Theory-Vapnik",
            "title": {
                "fragments": [],
                "text": "The Nature of Statistical Learning Theory"
            },
            "venue": {
                "fragments": [],
                "text": "Statistics for Engineering and Information Science"
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 85,
                                "start": 81
                            }
                        ],
                        "text": "The similarity is then based on the group-wise presence of enough similar points [57]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 18,
                                "start": 14
                            }
                        ],
                        "text": "Similarly, in [57], [55], photometric invariance is"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 49,
                                "start": 45
                            }
                        ],
                        "text": "Many systems like Photobook [128], PictoSeek [57], and [116] are rooted in computer vision."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 19,
                                "start": 15
                            }
                        ],
                        "text": "feature class, [57] has the user indicate the requested"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 155,
                                "start": 151
                            }
                        ],
                        "text": "Query by image example is suited for applications where the target is an image of the same object or set of objects under different viewing conditions [57]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 94,
                                "start": 90
                            }
                        ],
                        "text": "A wide variety of tight photometric color invariants for object retrieval were derived in [57] from an analysis of the Schafer model of object reflection."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aPictoseek: Combining Color and Shape Invariant Features for Image Retrieval,o"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Image Processing,"
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 102,
                                "start": 98
                            }
                        ],
                        "text": "Low-level feature selectors use color pickers or selections from shape and texture examples [48], [61]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 60,
                                "start": 56
                            }
                        ],
                        "text": "Other joint histograms add local texture or local shape [61], directed edges [78], and local higher order structures [48]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 77,
                                "start": 73
                            }
                        ],
                        "text": "Most of the current systems have relied upon this form of querying [48], [61]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 182,
                                "start": 178
                            }
                        ],
                        "text": "It is regrettable that not too much work across the division between the disciplines of vision and databases has been done yet, with a few exceptions in commercial systems [48], [61] and research [46], [85], [171]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 53,
                                "start": 49
                            }
                        ],
                        "text": "Groundbreaking examples are QBIC [48] and Virage [61]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aVisual Information Retrieval,o"
            },
            "venue": {
                "fragments": [],
                "text": "Comm. ACM,"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 35,
                                "start": 30
                            }
                        ],
                        "text": "The El Nin\u00c4 o database system [146] proposes an architecture for the integration of several, possibly remote, engines through a mediator."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 80,
                                "start": 75
                            }
                        ],
                        "text": "This approach was extended to incorporate the metric of the color space in [146]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 8,
                                "start": 3
                            }
                        ],
                        "text": "In [146], [175], [68], the operator V maps the highdimensional feature space onto a display space with d \u0088 3."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 161,
                                "start": 156
                            }
                        ],
                        "text": "When d 2, the user can manipulate the projected distances between images, putting away nonrelevant images and bringing relevant images closer to each other [146]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 25,
                                "start": 20
                            }
                        ],
                        "text": "The feedback RFi in [146] leads to an update of the user-desired distances between pairs of images in IQ."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 132,
                                "start": 127
                            }
                        ],
                        "text": "In other cases, the use of one image cannot provide sufficient context for the query to select one of its many interpretations [146]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 171,
                                "start": 166
                            }
                        ],
                        "text": "When, for each group in the database, a small set of representative images can be found, they are stored in a visual dictionary from which the user creates the query [146]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 82,
                                "start": 77
                            }
                        ],
                        "text": "A linguistic description of an image is a daunting, probably impossible task [146]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "and R"
            },
            "venue": {
                "fragments": [],
                "text": "Jain, aUser Interfaces for Emergent Semantics in Image Databases,o Proc. Eighth IFIP Working Conf. Database Semantics (DS-8)"
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 160,
                                "start": 156
                            }
                        ],
                        "text": "One option is that the user selects m > 1 images from a palette of images presented to find images best matching the common characteristics of the m images [31]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 75,
                                "start": 71
                            }
                        ],
                        "text": "The simplest form of feedback is to indicate which images are relevant [31]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 177,
                                "start": 173
                            }
                        ],
                        "text": "Target search may also be applied when the user has a specific image in mind and the target is interactively specified as similar to a group of given examples, for instance [31]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 107,
                                "start": 103
                            }
                        ],
                        "text": "An alternative display model displays the image set minimizing the expected number of total iterations [31]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 7,
                                "start": 3
                            }
                        ],
                        "text": "In [31], we see three broad categories of user aims when"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 94,
                                "start": 90
                            }
                        ],
                        "text": "The generic pattern, which uses similarity in updating probabilities, is the form used in [31] for target search with ZQ = {target}."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aThe Bayesian Image Retrieval System"
            },
            "venue": {
                "fragments": [],
                "text": "PicHunter: Theory, Implementation, and Pychophysical Experiments,o IEEE Trans. Image Processing, vol. 9, no. 1, pp. 20-37"
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 26,
                                "start": 21
                            }
                        ],
                        "text": "The systems in [70], [163] study spatial relationships between regions, each characterized by locations, size, and features."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 72,
                                "start": 67
                            }
                        ],
                        "text": "Implicit spatial relations between regions sketched by the user in [163] yield a pictorial predicate."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 8,
                                "start": 3
                            }
                        ],
                        "text": "In [163], images are transformed into homogeneous"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 29,
                                "start": 24
                            }
                        ],
                        "text": "For example, both [20], [163] compare the similarity of regions using features."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 149,
                                "start": 144
                            }
                        ],
                        "text": "When weak segmentation of the query image and all images in IQ is performed, the user can specify the query by indicating example regions [20], [163]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 205,
                                "start": 200
                            }
                        ],
                        "text": "Computational parameters of g may include the size of the neighborhood around x to compute f\u0085x\u0086 or a homogeneity criterion when the size of the patch to compute f\u0085x\u0086 depends on the actual data, as in [163], [126], for example."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aIntegrated Sspatial and Feature Image Query,o"
            },
            "venue": {
                "fragments": [],
                "text": "Multimedia Systems,"
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 40,
                                "start": 36
                            }
                        ],
                        "text": "A discrete analogue can be found in [94], where points are removed from the digitized contour on the basis of perceptually motivated rules."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 54,
                                "start": 50
                            }
                        ],
                        "text": "Starting from a shape description, the authors in [94] decompose an object into its main components, making the matching between images of the same object easier."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 60,
                                "start": 56
                            }
                        ],
                        "text": "A different view on multiresolution shape is offered in [94], where the contour is sampled by a polygon and then simplified by removing points from the contour until a polygon survives selecting them on perceptual grounds."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Laka\u00c8mper, aConvexity Rule for Shape Decomposition Based on Discrete Contour Evolution,o"
            },
            "venue": {
                "fragments": [],
                "text": "Image Understanding,"
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 7,
                                "start": 3
                            }
                        ],
                        "text": "In [28], [142], SQ is parameterized by a weight vector on the distances between individual features."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 7,
                                "start": 3
                            }
                        ],
                        "text": "In [28], [110], the user in addition explicitly indicates nonrelevant images."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 128,
                                "start": 124
                            }
                        ],
                        "text": "In category search, the user may have available a group of images and the search is for additional images of the same class [28]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 19,
                                "start": 15
                            }
                        ],
                        "text": "The weights in [28] are updated by comparing the variance of a feature in the set of positive examples to the variance in the union of positive and negative examples."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aUsing a Relevance Feedback Mechanism to Improve Content-Based Image Retrieval,o"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. Visual '99: Information and Information Systems,"
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 19,
                                "start": 15
                            }
                        ],
                        "text": "The systems in [68], [184] have pursued integration furthest by using contentbased similarity, interaction, and visualization, as well as database techniques for retrieving relevant images."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 84,
                                "start": 80
                            }
                        ],
                        "text": "The result of the search can be manipulated interactively by relevance feedback [68], [51]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 21,
                                "start": 17
                            }
                        ],
                        "text": "In [146], [175], [68], the operator V maps the highdimensional feature space onto a display space with d \u0088 3."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 66,
                                "start": 62
                            }
                        ],
                        "text": "To improve the user's comprehension of the information space, [68] provides the user with a dynamic view on FQ through continuous variation of the active feature set."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "and Y"
            },
            "venue": {
                "fragments": [],
                "text": "Mori, aVisualization of Information Spaces to Retrieve and Browse Image Data,o Proc. Visual '99: Information and Information Systems, pp. 155-162"
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 142,
                                "start": 137
                            }
                        ],
                        "text": "Another possibility of partitioning is to divide the image in tiles of equal size and summarize the dominant feature values in each tile [130]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 21,
                                "start": 16
                            }
                        ],
                        "text": "For example, in [130], each tile in the partition of the image shows the semantic label, like sky, building, or grass, the tile received."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 169,
                                "start": 164
                            }
                        ],
                        "text": "o Learning from user annotations of a partitioning of the image allows for feature range queries like: aamount of sky > 50 percent and amount of sand > 30 percento [130]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aVision Texture for Annotation,o"
            },
            "venue": {
                "fragments": [],
                "text": "Multimedia Systems,"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2137198"
                        ],
                        "name": "R. Shepard",
                        "slug": "R.-Shepard",
                        "structuredName": {
                            "firstName": "Roger",
                            "lastName": "Shepard",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Shepard"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 121495715,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c09a7b374da46c71ee73329ee64f234b5f204922",
            "isKey": false,
            "numCitedBy": 72,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Toward-a-Universal-Law-of-Generalization-Shepard",
            "title": {
                "fragments": [],
                "text": "Toward a Universal Law of Generalization"
            },
            "venue": {
                "fragments": [],
                "text": "Science"
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2502152"
                        ],
                        "name": "A. Treisman",
                        "slug": "A.-Treisman",
                        "structuredName": {
                            "firstName": "Anne",
                            "lastName": "Treisman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Treisman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144403711"
                        ],
                        "name": "P. Cavanagh",
                        "slug": "P.-Cavanagh",
                        "structuredName": {
                            "firstName": "Patrick",
                            "lastName": "Cavanagh",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Cavanagh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48996942"
                        ],
                        "name": "B. Fischer",
                        "slug": "B.-Fischer",
                        "structuredName": {
                            "firstName": "Burkhart",
                            "lastName": "Fischer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Fischer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1888069"
                        ],
                        "name": "V. Ramachandran",
                        "slug": "V.-Ramachandran",
                        "structuredName": {
                            "firstName": "Vilayanur",
                            "lastName": "Ramachandran",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Ramachandran"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7751281"
                        ],
                        "name": "R. Heydt",
                        "slug": "R.-Heydt",
                        "structuredName": {
                            "firstName": "R\u00fcdiger",
                            "lastName": "Heydt",
                            "middleNames": [
                                "von",
                                "der"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Heydt"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 64275636,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "b3e98a68754dd6a137dadfcde58da1e4c1492cba",
            "isKey": false,
            "numCitedBy": 60,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "11-\u2013-FORM-PERCEPTION-AND-ATTENTION:-Striate-Cortex-Treisman-Cavanagh",
            "title": {
                "fragments": [],
                "text": "11 \u2013 FORM PERCEPTION AND ATTENTION: Striate Cortex and Beyond"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3134400"
                        ],
                        "name": "S. Hastings",
                        "slug": "S.-Hastings",
                        "structuredName": {
                            "firstName": "Samantha",
                            "lastName": "Hastings",
                            "middleNames": [
                                "Kelly"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Hastings"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 60782103,
            "fieldsOfStudy": [
                "Art"
            ],
            "id": "1f37ac722846096a15b5d2b6f7f4de06dc0e85df",
            "isKey": false,
            "numCitedBy": 77,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Query-Categories-in-a-Study-of-Intellectual-Access-Hastings",
            "title": {
                "fragments": [],
                "text": "Query Categories in a Study of Intellectual Access to Digitized Art Images."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2282976"
                        ],
                        "name": "Susanne Ornager",
                        "slug": "Susanne-Ornager",
                        "structuredName": {
                            "firstName": "Susanne",
                            "lastName": "Ornager",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Susanne Ornager"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 61051355,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "289a00d1dd218466716c4c82eb3e2ab741f1f07d",
            "isKey": false,
            "numCitedBy": 54,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Image-Retrieval:-Theoretical-Analysis-and-Empirical-Ornager",
            "title": {
                "fragments": [],
                "text": "Image Retrieval: Theoretical Analysis and Empirical User Studies on Accessing Information in Images."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1778093"
                        ],
                        "name": "M. Pao",
                        "slug": "M.-Pao",
                        "structuredName": {
                            "firstName": "Miranda",
                            "lastName": "Pao",
                            "middleNames": [
                                "Lee"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Pao"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "categorical information retrieval [123]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 60253153,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fa831c62b046fa26f8252f60f5b57e6b2adf4a72",
            "isKey": false,
            "numCitedBy": 104,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Concepts-of-Information-Retrieval-Pao",
            "title": {
                "fragments": [],
                "text": "Concepts of Information Retrieval"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2113475673"
                        ],
                        "name": "Derek White",
                        "slug": "Derek-White",
                        "structuredName": {
                            "firstName": "Derek",
                            "lastName": "White",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Derek White"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145889709"
                        ],
                        "name": "R. Jain",
                        "slug": "R.-Jain",
                        "structuredName": {
                            "firstName": "Raj",
                            "lastName": "Jain",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Jain"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 59888996,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "db92b14599d6230120c3cc54cf22ec1c3957d4cb",
            "isKey": false,
            "numCitedBy": 125,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Algorithms-and-strategies-for-similarity-retrieval-White-Jain",
            "title": {
                "fragments": [],
                "text": "Algorithms and strategies for similarity retrieval"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "52029549"
                        ],
                        "name": "G. Salton",
                        "slug": "G.-Salton",
                        "structuredName": {
                            "firstName": "Gerald",
                            "lastName": "Salton",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Salton"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 110,
                                "start": 105
                            }
                        ],
                        "text": "Comparing sparsely occupied histograms has long been used in text retrieval, where vector space modeling [143] implies the registration in a N-dimensional histogram F with as many dimensions as there are different words in the dictionary, typically 10,000."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 221,
                                "start": 216
                            }
                        ],
                        "text": "The initial impetus for the evaluation of image databases comes from the neighboring discipline of information retrieval, in which userbased evaluation techniques have reached a considerable degree of sophistication [143]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 54152601,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f44e0b5372a4fb1d8e1b15ca9e9cab7b4d65dd94",
            "isKey": false,
            "numCitedBy": 1972,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Automatic-text-processing-Salton",
            "title": {
                "fragments": [],
                "text": "Automatic text processing"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47138611"
                        ],
                        "name": "D. Ennis",
                        "slug": "D.-Ennis",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Ennis",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Ennis"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 1549730,
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "id": "43b4b7a416ea2d1af2dbea7c75723aef2967bdd6",
            "isKey": false,
            "numCitedBy": 106,
            "numCiting": 3,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Toward-a-Universal-Law-of-Generalization-Ennis",
            "title": {
                "fragments": [],
                "text": "Toward a universal law of generalization."
            },
            "venue": {
                "fragments": [],
                "text": "Science"
            },
            "year": 1988
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "corpusId": 35696139,
            "fieldsOfStudy": [],
            "id": "d68b95534860e2bddd17d17ef7f362d16c550bde",
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Locating text in complex color images"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit."
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "corpusId": 42756182,
            "fieldsOfStudy": [],
            "id": "9b688fd4be93dd8bd461dd7ab0b78427e4ba3a47",
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Large-Scale Parallel Data Clustering"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2792651"
                        ],
                        "name": "A. Blaser",
                        "slug": "A.-Blaser",
                        "structuredName": {
                            "firstName": "Albrecht",
                            "lastName": "Blaser",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Blaser"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "\u2026retrieval, semantic gap, sensory gap, narrow domain, broad domain, weak segmentation, accumulative features, salient features, signs, structural features, similarity, semantic interpretation, query space, display space, interactive session, indexing, architecture, evaluation, image databases.\n\u00e6"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 28217192,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "45faac770033f99cc0e60cd38c15444dff21e546",
            "isKey": false,
            "numCitedBy": 50,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Data-Base-Techniques-for-Pictorial-Applications-Blaser",
            "title": {
                "fragments": [],
                "text": "Data Base Techniques for Pictorial Applications"
            },
            "venue": {
                "fragments": [],
                "text": "Lecture Notes in Computer Science"
            },
            "year": 1980
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 8,
                                "start": 3
                            }
                        ],
                        "text": "In [186], preliminary work is reported towards automatic"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 78,
                                "start": 73
                            }
                        ],
                        "text": "Categories may be derived from labels or emerge from the database [170], [186]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 236503748,
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "and P"
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 63,
                                "start": 59
                            }
                        ],
                        "text": "The SS-tree [189] and its further improvement, the SR-tree [87], use the intersection of the minimum bounding hypersphere and minimum bounding hyperrectangle as the bounding region of a data element."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aThe SR-Tree: An Index Structure for High-Dimensional Nearest Neighbor Queries,o"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. SIGMOD, Int'l Conf. Management of Data,"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 70,
                                "start": 67
                            }
                        ],
                        "text": "Other models exploit statistical regularities in the texture field [9]."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aTexture Synthesis with Tandem Genetic Algorithms Using Nonparametric Partially Ordered Markov Models,o"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. Congress on Evolutionary Computation,"
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "In this section, we\ndiscuss patterns in applications, the repertoire of images,\nthe influence of the scene and the role of domain\nknowledge, and the semantic gap between image features\nand the user."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 27,
                                "start": 23
                            }
                        ],
                        "text": "In category search, the user may have available a group of images and the search is for additional images of the same class [28]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Information Retrieval,\u00ba J. Documentation"
            },
            "venue": {
                "fragments": [],
                "text": "Information Retrieval,\u00ba J. Documentation"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 61,
                                "start": 57
                            }
                        ],
                        "text": "From such topological relationships of image regions, in [71], a 2D-indexing is built in trees of symbol strings, each representing the projection of a region on the coordinate axis."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aSimilairty Retrieval by 2D C-Trees Matching in Image Databases,o"
            },
            "venue": {
                "fragments": [],
                "text": "J. Visual Comm. and Image Representation,"
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 84,
                                "start": 80
                            }
                        ],
                        "text": "In retrieval, the property is computed in a sliding mask for localization [99], [59]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Kreyszig, aTexture Descriptors Based on Co-Occurrences Matrices,o"
            },
            "venue": {
                "fragments": [],
                "text": "Computer Vision, Graphics, and Image Processing,"
            },
            "year": 1990
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 75,
                                "start": 71
                            }
                        ],
                        "text": "In exact queries based on accumulative features, backprojection [169], [41] can be used to give system feedback, indicating which parts of the image fulfill the criteria."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 94,
                                "start": 90
                            }
                        ],
                        "text": "As a histogram loses all information about the location of an object in the image, [169], [41] project the histogram back into the image to locate it by searching for best matches."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aFinding Waldo, or Focus of Attention Using Local Color Information,o"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Analysis and Machine Intelligence,"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 71,
                                "start": 66
                            }
                        ],
                        "text": "In the example of a wavelet histogram for texture-based retrieval [162], an image has a nine-dimensional vector for each pixel compressed to a 512-bin histogram to a total of 512(2) histograms of 512 bins per image."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 110,
                                "start": 105
                            }
                        ],
                        "text": "The lowest levels of the wavelet transforms [34], [26] have been applied to texture representation [92], [162] sometimes in conjunction with Markovian analysis [25]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aAutomated Binary Feature Sets for Image Retrieval,o"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. Int'l Conf. Acoustics, Speech, and Signal Processing,"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 55,
                                "start": 50
                            }
                        ],
                        "text": "retrieval, called latent semantic indexing [151], [199]."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aFrom Features to Semantics: Some Preliminary Results,o"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. Int'l Conf. Multimedia and Expo,"
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 30,
                                "start": 25
                            }
                        ],
                        "text": "Combining shape and color both in invariant fashion is a powerful combination, as described by [56], where the colors inside and outside affine curvature maximums in color edges are stored to identify objects."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 86,
                                "start": 81
                            }
                        ],
                        "text": "Therefore, in retrieval research, in [101], the Wold features of periodicity, directionality, and randomness are used, which agree reasonably well with linguistic descriptions of textures as implemented in [128]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "\u00aaComparing Images Using Joint Histograms ,\u00ba Multimedia Systems"
            },
            "venue": {
                "fragments": [],
                "text": "\u00aaComparing Images Using Joint Histograms ,\u00ba Multimedia Systems"
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 151,
                                "start": 147
                            }
                        ],
                        "text": "The area T may be the entire image or a conventional partitioning as the central part of the image against the upper, right, left, and lower parts [67]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aRough Sketch-Based Image Information Retrieval,o"
            },
            "venue": {
                "fragments": [],
                "text": "NEC Research and Development,"
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 227,
                                "start": 222
                            }
                        ],
                        "text": "If the appreciation of a human observer of an object is based on the perception of certain conspicuous items in the image [177], it is natural to direct the computation of broad domain features to these points and regions [157], [138]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aParts of Visual Form: Computational Aspects,o"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Analysis and Machine Intelligence,"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 21,
                                "start": 17
                            }
                        ],
                        "text": "Another class of users aims the search at a specific image."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 119,
                                "start": 115
                            }
                        ],
                        "text": "Also, the application of geometric description derived from scale space theory\nwill reveal viewpoint and scene independent salient point sets, thus opening the way to similarity of images on a few most informative regions or points."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Processing and Database System in the National Museum of Western Art,\u00ba INSPEL"
            },
            "venue": {
                "fragments": [],
                "text": "Processing and Database System in the National Museum of Western Art,\u00ba INSPEL"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 151,
                                "start": 147
                            }
                        ],
                        "text": "The sensory gap is the gap between the object in the world and the information in a (computational) description derived from a recording of that scene."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Content-based image retrieval systems may provide support in this disambiguation through elimination\namong several potential explanations, much the same as in natural language processing."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "\u00aaInvariant Features for Discriminating between Equivalence Classes,\u00ba Nonlinear Model-Based Image Video Processing and Analysis"
            },
            "venue": {
                "fragments": [],
                "text": "\u00aaInvariant Features for Discriminating between Equivalence Classes,\u00ba Nonlinear Model-Based Image Video Processing and Analysis"
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Smeulders has been in image processing since 1975 when he received the MSc degree in physics. He received the PhD degree in medical image analysis in"
            },
            "venue": {
                "fragments": [],
                "text": "Smeulders has been in image processing since 1975 when he received the MSc degree in physics. He received the PhD degree in medical image analysis in"
            },
            "year": 1982
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Combining shape and color both in invariant fashion is a powerful combination, as described by [56], where the colors inside and outside affine curvature maximums in color edges are stored to identify objects."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "\u00aaVision Texture for Annotation,\u00ba Multimedia Systems"
            },
            "venue": {
                "fragments": [],
                "text": "\u00aaVision Texture for Annotation,\u00ba Multimedia Systems"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 7,
                                "start": 3
                            }
                        ],
                        "text": "In [47], this is improved to include specular reflection, shape, and varying illumination."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aColor in Perspective,o"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Analysis and Machine Intelligence,"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 127,
                                "start": 123
                            }
                        ],
                        "text": "Basic texture properties include the Markovian analysis, dating back to Haralick in 1973, and generalized versions thereof [91], [58]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aMultiresolution Gauss- Markov Random Field Models for Texture Segmentation,o"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Image Processing,"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 67,
                                "start": 63
                            }
                        ],
                        "text": "Another example of geometric laws is the expression of spatial [22] or topological relationships [172] between objects."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 100,
                                "start": 96
                            }
                        ],
                        "text": "In the later system, matching is based on the 2D-string representation founded by Chang and Hau [22]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aImage-Information Systems\u00d0Where Do We Go from Here?a"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Knowledge and Data Eng.,"
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aEfficient Color Histogram Indexing for Quadratic Form Distance Functions,o"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Analysis and Machine Intelligence,"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "At one end of the spectrum, we have the narrow domain:"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Therefore, in retrieval research, in [101], the Wold features of periodicity, directionality, and randomness are used, which agree reasonably well with linguistic descriptions of textures as implemented in [128]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "\u00aaUser Interfaces for Emergent Semantics in Image Databases"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. Eighth IFIP Working Conf. Database Semantics (DS-8)"
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 154,
                                "start": 149
                            }
                        ],
                        "text": "We analyze characteristics of the image domain, the domain knowledge, and the types of use as the prime factors determining the functionality of a system."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A Framework of Boundary Detection and Image Segmentation"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. Computer Vision and Pattern Recognition"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[88] were the first to let users create a sketch of the global image composition which was then matched to the edges in IQ."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 62,
                                "start": 58
                            }
                        ],
                        "text": "The oldest realistic example of such a system is probably [88]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "and K"
            },
            "venue": {
                "fragments": [],
                "text": "Hirata, aA Sketch Retrieval Method for Full Color Image Database\u00d0Query by Visual Example,o Proc. ICPR, Computer Vision and Applications, pp. 530- 533"
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Relational Database of Images,\u00ba Computer"
            },
            "venue": {
                "fragments": [],
                "text": "Relational Database of Images,\u00ba Computer"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "5."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 175,
                                "start": 171
                            }
                        ],
                        "text": "To solve the problem, systems in [21], [142] use a program that explores the Internet, collecting images and inserting them in a predefined taxonomy on the basis of the text surrounding them."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Smeulders, \u00aaContent-Based Image Retrieval by Viewpoint-Invariant Image Indexing"
            },
            "venue": {
                "fragments": [],
                "text": "Image and Vision Computing"
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "\u00aaIconic Indexing by 2D Strings"
            },
            "venue": {
                "fragments": [],
                "text": "\u00aaIconic Indexing by 2D Strings"
            },
            "year": 1987
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 29,
                                "start": 25
                            }
                        ],
                        "text": "In general, a feature with a very wide class of invariance loses the power to discriminate among essential differences."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 148,
                                "start": 144
                            }
                        ],
                        "text": "A recent advancement in that direction is the fusion of illumination and scale invariant color and texture information into a consistent set of localized properties [66]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "\u00aaMeasurement of Color Invariants,\u00ba Proc. Computer Vision and Pattern Recognition"
            },
            "venue": {
                "fragments": [],
                "text": "\u00aaMeasurement of Color Invariants,\u00ba Proc. Computer Vision and Pattern Recognition"
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 138,
                                "start": 133
                            }
                        ],
                        "text": "What is needed in image search is a specification of the minimal invariant conditions in the specification of the query discussed in [159]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "and M"
            },
            "venue": {
                "fragments": [],
                "text": "Worring, aInvariance in Content-Based Retrieval,o Proc. Int'l Conf. Multimedia and Expo"
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 213,
                                "start": 208
                            }
                        ],
                        "text": "Another important texture analysis technique uses multiscale autoregressive MRSAR-models, which consider texture as the outcome of a deterministic dynamic system subject to state and observation noise [174], [106]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aTexture Classification and Segmentation Using Multiresolution Simultaneous Autoregressive Models,o"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognition,"
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 38,
                                "start": 34
                            }
                        ],
                        "text": "derive from the same distribution [35], [131]."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aTexture Recognition Using a Non- Parametric Multi-Scale Statistical Model,o"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. Computer Vision and Pattern Recognition,"
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 7,
                                "start": 3
                            }
                        ],
                        "text": "In [75], vector quantization was applied in the space of coefficients to reduce its dimensionality."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aImage Indexing Using Wavelet Vector Quantization,o"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. Digital Image Storage and Archiving Systems,"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 29,
                                "start": 25
                            }
                        ],
                        "text": "In general, a feature with a very wide class of invariance loses the power to discriminate among essential differences."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 148,
                                "start": 144
                            }
                        ],
                        "text": "A recent advancement in that direction is the fusion of illumination and scale invariant color and texture information into a consistent set of localized properties [66]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "\u00aaMeasurement of Color Invariants,\u00ba Proc. Computer Vision and Pattern Recognition"
            },
            "venue": {
                "fragments": [],
                "text": "\u00aaMeasurement of Color Invariants,\u00ba Proc. Computer Vision and Pattern Recognition"
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 213,
                                "start": 208
                            }
                        ],
                        "text": "Another important texture analysis technique uses multiscale autoregressive MRSAR-models, which consider texture as the outcome of a deterministic dynamic system subject to state and observation noise [174], [106]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aTexture Classification and Segmentation Using Multiresolution Simultaneous Autoregressive Models,o"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognition,"
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 38,
                                "start": 34
                            }
                        ],
                        "text": "derive from the same distribution [35], [131]."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aTexture Recognition Using a Non- Parametric Multi-Scale Statistical Model,o"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. Computer Vision and Pattern Recognition,"
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 138,
                                "start": 133
                            }
                        ],
                        "text": "What is needed in image search is a specification of the minimal invariant conditions in the specification of the query discussed in [159]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "and M"
            },
            "venue": {
                "fragments": [],
                "text": "Worring, aInvariance in Content-Based Retrieval,o Proc. Int'l Conf. Multimedia and Expo"
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 58,
                                "start": 53
                            }
                        ],
                        "text": "A good review of global shape invariants is given in [140]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aThe Method of Normalization of Determine Invariants,o"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Analysis and Machine Intelligence,"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 94,
                                "start": 89
                            }
                        ],
                        "text": "It is a balanced data structure with equal depth from the root, with O\u0085logN\u0086 performance [196]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "and G"
            },
            "venue": {
                "fragments": [],
                "text": "Ozsoyoglu, aA Framework for Feature-Based Indexing for Spatial Databases,o Proc. Seventh Int'l Working Conf. Scientific and Statistical Database Management, pp. 259- 269"
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 61,
                                "start": 56
                            }
                        ],
                        "text": "Conspicuous shape geometric invariants are presented in [136]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aLocal Invariants for Recognition,o"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Analysis and Machine Intelligence,"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Concepts of Information Retrieval. Libraries Unlimited"
            },
            "venue": {
                "fragments": [],
                "text": "Concepts of Information Retrieval. Libraries Unlimited"
            },
            "year": 1989
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Therefore, in retrieval research, in [101], the Wold features of periodicity, directionality, and randomness are used, which agree reasonably well with linguistic descriptions of textures as implemented in [128]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Information Retrieval,\u00ba Comm. ACM"
            },
            "venue": {
                "fragments": [],
                "text": "Information Retrieval,\u00ba Comm. ACM"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 60,
                                "start": 57
                            }
                        ],
                        "text": "We leave video retrieval for another place, for example, [1], [16]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "and D"
            },
            "venue": {
                "fragments": [],
                "text": "Petkovic, aContent-Based Representation and Retrieval of Visual Media: A State of the Art Review,o Multimedia Tools and Applications, vol. 3, pp. 179-202"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Therefore, in retrieval research, in [101], the Wold features of periodicity, directionality, and randomness are used, which agree reasonably well with linguistic descriptions of textures as implemented in [128]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Information Retrieval,\u00ba Comm. ACM"
            },
            "venue": {
                "fragments": [],
                "text": "Information Retrieval,\u00ba Comm. ACM"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 213,
                                "start": 208
                            }
                        ],
                        "text": "It is regrettable that not too much work across the division between the disciplines of vision and databases has been done yet, with a few exceptions in commercial systems [48], [61] and research [46], [85], [171]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aLocation Hashing: An Efficient Method for Locating Object Queries in Image Databases,o"
            },
            "venue": {
                "fragments": [],
                "text": "Storage and Retrieval in Image and Video Databases,"
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "a Similarity and Affine Invariant Distances between 2 D Point Sets , o IEEE Trans"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Analysis and Machine Intelligence Pattern Analysis and Machine Intelligence o IEEE Trans . Computational Science Eng ."
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 60,
                                "start": 57
                            }
                        ],
                        "text": "We leave video retrieval for another place, for example, [1], [16]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "and D"
            },
            "venue": {
                "fragments": [],
                "text": "Petkovic, aContent-Based Representation and Retrieval of Visual Media: A State of the Art Review,o Multimedia Tools and Applications, vol. 3, pp. 179-202"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 64,
                                "start": 59
                            }
                        ],
                        "text": "This reduces content-based access to information retrieval [135]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aText Databases and Information Retrieval,o"
            },
            "venue": {
                "fragments": [],
                "text": "ACM Computing Surveys,"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 82,
                                "start": 77
                            }
                        ],
                        "text": "Textures also served as a support feature for segmentation-based recognition [102], but the texture properties discussed so far offer little semantic referent."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aEdge Flow: A Framework of Boundary Detection and Image Segmentation,o"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. Computer Vision and Pattern Recognition,"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 153,
                                "start": 149
                            }
                        ],
                        "text": "A Web search system in which the user places icons representing categories like human, sky, and water in the requested spatial order is presented in [97]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aVisual Websearching Using Iconic Queries,o"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. Computer Vision and Pattern Recognition,"
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "\u00aaFilter Image Browsing: Exploiting Interaction in Retrieval,\u00ba Proc. Visual '99: Information and Information Systems"
            },
            "venue": {
                "fragments": [],
                "text": "\u00aaFilter Image Browsing: Exploiting Interaction in Retrieval,\u00ba Proc. Visual '99: Information and Information Systems"
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Image Retrieval Based on Hidden Markov Models IEEE Trans. Image Processing"
            },
            "venue": {
                "fragments": [],
                "text": "Image Retrieval Based on Hidden Markov Models IEEE Trans. Image Processing"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 53,
                                "start": 49
                            }
                        ],
                        "text": "Texture search proved useful in satellite images [98] and images of documents [33]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aDeriving Texture Feature Set for Content- Based Retrieval of Satellite Image Database,o"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. Int'l Conf. Image Processing,"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "At one end of the spectrum, we have the narrow domain:"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "\u00aaForm Perception and Attention-Striate Cortex and Beyond,\u00ba Visual Perception: The Neurophysiological Foundation"
            },
            "venue": {
                "fragments": [],
                "text": "\u00aaForm Perception and Attention-Striate Cortex and Beyond,\u00ba Visual Perception: The Neurophysiological Foundation"
            },
            "year": 1990
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 7,
                                "start": 3
                            }
                        ],
                        "text": "In [53], a graph is formed of topological relationships of homogenous RGB-regions."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 7,
                                "start": 3
                            }
                        ],
                        "text": "In [53], hierarchically ordered trees are compared for the"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "and K"
            },
            "venue": {
                "fragments": [],
                "text": "Essig, aHierarchical Color Image Region Segmentation for Content-Based Image Retrieval System,o IEEE Trans. Image Processing, vol. 9, no. 1 pp. 156-163"
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "\u00aaCORE: A Content Based Retrieval System for Multimedia Information Systems,\u00ba Multimedia Systems"
            },
            "venue": {
                "fragments": [],
                "text": "\u00aaCORE: A Content Based Retrieval System for Multimedia Information Systems,\u00ba Multimedia Systems"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 14,
                                "start": 9
                            }
                        ],
                        "text": "In [20], [112], the homogeneity criterion is based on"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aSegmentation of Color Texture,o"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Analysis and Machine Intelligence,"
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 21,
                                "start": 18
                            }
                        ],
                        "text": "In a recent paper [3], a 1358 IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE, VOL."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aGeometric and Illumination Invariants for Object Recognition,o"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Analysis and Machine Intelligence,"
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "\u00aaImage Retrieval Evaluation,\u00ba Proc. Workshop Content-Based Access of Image and Video Libraries"
            },
            "venue": {
                "fragments": [],
                "text": "\u00aaImage Retrieval Evaluation,\u00ba Proc. Workshop Content-Based Access of Image and Video Libraries"
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aImage Retrieval Evaluation,o"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. Workshop Content-Based Access of Image and Video Libraries,"
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Therefore, in retrieval research, in [101], the Wold features of periodicity, directionality, and randomness are used, which agree reasonably well with linguistic descriptions of textures as implemented in [128]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "\u00aaPattern Recognition by Moment Invariants"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. IRE Trans. Information Theory"
            },
            "year": 1962
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 24,
                                "start": 20
                            }
                        ],
                        "text": ", for art paintings [64], the color composition of photographs [48], and trademarks [79], [39], where two-dimensional images are recorded in frontal view under standard conditions."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 193,
                                "start": 189
                            }
                        ],
                        "text": "On the coverage side, labeling is seldom complete, context sensitive, and, in any case, there is a significant fraction of requests whose semantics can't be captured by labeling alone [6], [64]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aQuery Categories in a Study of Intellectual Access to Digitized Art Images,o"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. 58th Ann. Meeting Am. Soc. Information Science,"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 20,
                                "start": 15
                            }
                        ],
                        "text": "For faces, many geometric models have been\nsuggested, as well as statistical models [127]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "\u00aaIntegrated Sspatial and Feature Image Query,\u00ba Multimedia Systems"
            },
            "venue": {
                "fragments": [],
                "text": "\u00aaIntegrated Sspatial and Feature Image Query,\u00ba Multimedia Systems"
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Therefore, in retrieval research, in [101], the Wold features of periodicity, directionality, and randomness are used, which agree reasonably well with linguistic descriptions of textures as implemented in [128]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "\u00aaPattern Recognition by Moment Invariants"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. IRE Trans. Information Theory"
            },
            "year": 1962
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 127,
                                "start": 122
                            }
                        ],
                        "text": "If the appreciation of a human observer of an object is based on the perception of certain conspicuous items in the image [177], it is natural to direct the computation of broad domain features to these points and regions [157], [138]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "and R"
            },
            "venue": {
                "fragments": [],
                "text": "von der Heydt, aForm Perception and Attention-Striate Cortex and Beyond,o Visual Perception: The Neurophysiological Foundation, pp. 273-316"
            },
            "year": 1990
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 34,
                                "start": 29
                            }
                        ],
                        "text": "can be done in feature space [118] or at the level of the entire"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aVisual Learning and Recognition of 3D Objects from Appearance,o"
            },
            "venue": {
                "fragments": [],
                "text": "Int'l J. Computer Vision, vol. 14,"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "5."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Analysis and Machine Intelligence"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Analysis and Machine Intelligence"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 220,
                                "start": 218
                            }
                        ],
                        "text": "New challenges in content-based retrieval are the huge amount of objects to search among, the incomplete query specification, the\nincomplete image description, and the variability of sensing conditions and object states."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "\u00aaTexture Descriptors Based on Co-Occurrences Matrices,\u00ba Computer Vision, Graphics, and Image Processing"
            },
            "venue": {
                "fragments": [],
                "text": "\u00aaTexture Descriptors Based on Co-Occurrences Matrices,\u00ba Computer Vision, Graphics, and Image Processing"
            },
            "year": 1990
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Pattern Recognition: A Review IEEE Trans. Pattern Analysis and Machine Intelligence"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognition: A Review IEEE Trans. Pattern Analysis and Machine Intelligence"
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 48,
                                "start": 44
                            }
                        ],
                        "text": "Color constancy was applied to retrieval in [54] by using an illumination invariant color representation."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aColor Constant Color Indexing,o"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Analysis and Machine Intelligence,"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "\u00aaInfoScopes: Multimedia Information Systems,\u00ba Multimedia Systems and Techniques"
            },
            "venue": {
                "fragments": [],
                "text": "\u00aaInfoScopes: Multimedia Information Systems,\u00ba Multimedia Systems and Techniques"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "a Visual Image Retrieval by Elastic Matching of User Sketches , o IEEE Trans"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Analysis and Machine Intelligence"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "At one end of the spectrum, we have the narrow domain:"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A Power Tool for Interactive Content-Based Image Retrieval"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Circuits and Systems for Video Technology"
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 29,
                                "start": 24
                            }
                        ],
                        "text": "That is why saliency in [100] is defined as the"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aScale Space Primal Sketch Construction and Experiments,o"
            },
            "venue": {
                "fragments": [],
                "text": "Image Vision Computing,"
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 111,
                                "start": 108
                            }
                        ],
                        "text": "An attempts to formulate a general categorization of user requests for still and moving images are found in [6]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 187,
                                "start": 184
                            }
                        ],
                        "text": "On the coverage side, labeling is seldom complete, context sensitive, and, in any case, there is a significant fraction of requests whose semantics can't be captured by labeling alone [6], [64]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aAnalysis of User Need in Image Archives,o"
            },
            "venue": {
                "fragments": [],
                "text": "J. Information Science,"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 28,
                                "start": 24
                            }
                        ],
                        "text": "This is the correlogram [73], defined as a threedimensional histogram where the colors of any pair are along the first and second dimension and the spatial distance between them along the third."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "and R"
            },
            "venue": {
                "fragments": [],
                "text": "Zabih, aSpatial Color Indexing and Applications,o Int'l J. Computer Vision, vol. 35, no. 3, pp. 245-268"
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 68,
                                "start": 64
                            }
                        ],
                        "text": "Other transforms have also been explored, most notably fractals [44]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aFast Texture Database Retrieval Using Extended Fractal Features,o Storage and Retrieval for Image and Video"
            },
            "venue": {
                "fragments": [],
                "text": "Databases, VI,"
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 139,
                                "start": 135
                            }
                        ],
                        "text": "Matching a query and an object in the data file can be done along the ordered set of eigen shapes [150] or with elastic matching [36], [11]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "and D"
            },
            "venue": {
                "fragments": [],
                "text": "Jacobs, aDetermining the Similarity of Deformable Shapes,o Vision Research, vol. 38, nos. 15- 16, pp. 2,365-2,385"
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "This and similar studies reveal that the range of queries is wider than just retrieving images based on the presence or absence of objects of simple visual characteristics."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Combining shape and color both in invariant fashion is a powerful combination, as described by [56], where the colors inside and outside affine curvature maximums in color edges are stored to identify objects."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "\u00aaUser Interfaces for Emergent Semantics in Image Databases,\u00ba Proc. Eighth IFIP Working Conf"
            },
            "venue": {
                "fragments": [],
                "text": "\u00aaUser Interfaces for Emergent Semantics in Image Databases,\u00ba Proc. Eighth IFIP Working Conf"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 71,
                                "start": 66
                            }
                        ],
                        "text": "Categories may be derived from labels or emerge from the database [170], [186]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 50,
                                "start": 45
                            }
                        ],
                        "text": "Recent work from the vision side is found in [170], where the database organizes itself for narrow domains in clustering hierarchies of the most expressive features, and in [2], where clusters of feature values are sought in a graph-theoretical representation."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aHierarchical Discriminant Analysis for Image Retrieval,o"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Analysis and Machine Intelligence,"
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 126,
                                "start": 122
                            }
                        ],
                        "text": "Invariant description in image retrieval is relatively new, but quickly gaining ground for a good introduction, see [18], [32]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aAlgebraic and Geometrical Tools to Compute Projective and Permutation Invariants,o"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Analysis and Machine Intelligence,"
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 8,
                                "start": 3
                            }
                        ],
                        "text": "In [183], a good review is given of methods to compare shapes directly after segmentation into a set of object points t\u0085x\u0086: Sq;d \u0088 s\u0085tq\u0085x\u0086; td\u0085x\u0086\u0086; \u008515\u0086"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 8,
                                "start": 3
                            }
                        ],
                        "text": "In [183], an analysis is given for the Hausdorff and related metrics between two shapes on robustness and computational complexity."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Hagendoorn, aState-of-the-Art in Shape Matching,o Multimedia Search: State of the Art"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Therefore, in retrieval research, in [101], the Wold features of periodicity, directionality, and randomness are used, which agree reasonably well with linguistic descriptions of textures as implemented in [128]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "\u00aaImage and Video Indexing in the Compressed Domain: A Critical Review,\u00ba Image and Vision Computing"
            },
            "venue": {
                "fragments": [],
                "text": "\u00aaImage and Video Indexing in the Compressed Domain: A Critical Review,\u00ba Image and Vision Computing"
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Grosky, \u00aaMulti-Media Information Systems"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Multimedia"
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 7,
                                "start": 3
                            }
                        ],
                        "text": "In [23], 2D-strings describing spatial relationships between objects are discussed and, much later, reviewed in [198]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aIconic Indexing by 2D Strings,o"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Analysis and Machine Intelligence,"
            },
            "year": 1987
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 94,
                                "start": 90
                            }
                        ],
                        "text": ", for art paintings [64], the color composition of photographs [48], and trademarks [79], [39], where two-dimensional images are recorded in frontal view under standard conditions."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aSimilarity Retrieval of Trademark Images,o"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Multimedia,"
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 36,
                                "start": 32
                            }
                        ],
                        "text": "Sketched outlines of objects in [93] are first normalized to remove irrelevant detail from the query object before matching it to objects segmented from the image."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Laka\u00c8mper, aContour-Based Shape Similarity,o"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. Visual '99: Information and Information Systems,"
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 90,
                                "start": 86
                            }
                        ],
                        "text": "The result of the search can be manipulated interactively by relevance feedback [68], [51]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aPARISS: Panoramic"
            },
            "venue": {
                "fragments": [],
                "text": "Adaptive and Reconfigurable Interface for Similarity Search,o Proc. Int'l Conf. Image Processing"
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aSimilarity of Color Images,o Storage and Retrieval of Image and Video"
            },
            "venue": {
                "fragments": [],
                "text": "Databases III,"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "\u00aaVisual Websearching Using Iconic Queries,\u00ba Proc. Computer Vision and Pattern Recognition"
            },
            "venue": {
                "fragments": [],
                "text": "\u00aaVisual Websearching Using Iconic Queries,\u00ba Proc. Computer Vision and Pattern Recognition"
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 55,
                                "start": 50
                            }
                        ],
                        "text": "A more general version is the geometric histogram [134], with the normal histogram, the correlogram, and several alternatives as special cases."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "and Z"
            },
            "venue": {
                "fragments": [],
                "text": "Zhang, aGeometric Histogram: A Distribution of Geometric Configurations of Color Subsets,o Internet Imaging, vol. 3,964, pp. 91-101"
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 35,
                                "start": 31
                            }
                        ],
                        "text": "suitable composition operators [45], [38]."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aCombining Fuzzy Information from Multiple Systems,o"
            },
            "venue": {
                "fragments": [],
                "text": "J. Computer Systems Science,"
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 171,
                                "start": 166
                            }
                        ],
                        "text": "Also, in [20], homogeneous regions are represented as collections of ellipsoids of uniform color or texture, but invariant texture properties deserve more attention, [173] and [185]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aRotation Invariant Texture Features and Their Use in Automatic Script Identification,o"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Analysis and Machine Intelligence,"
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 171,
                                "start": 166
                            }
                        ],
                        "text": "Also, in [20], homogeneous regions are represented as collections of ellipsoids of uniform color or texture, but invariant texture properties deserve more attention, [173] and [185]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aRotation Invariant Texture Features and Their Use in Automatic Script Identification,o"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Analysis and Machine Intelligence,"
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 9,
                                "start": 4
                            }
                        ],
                        "text": "They have often been considered for their locality and their compression efficiency."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 101,
                                "start": 99
                            }
                        ],
                        "text": "The physics of illumination, surface reflection, and image formation have a general effect on images."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "J. Computer Vision"
            },
            "venue": {
                "fragments": [],
                "text": "J. Computer Vision"
            },
            "year": 1991
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 145,
                                "start": 140
                            }
                        ],
                        "text": "For a 64-bin histogram, experiments show that, for reasonable conditions, the discriminating power among images is limited to 25,000 images [167]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aThe Capacity of Color Histogram Indexing,o"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. Computer Vision and Pattern Recognition,"
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 99,
                                "start": 95
                            }
                        ],
                        "text": "Combining shape and color both in invariant fashion is a powerful combination, as described by [56], where the colors inside and outside affine curvature maximums in color edges are stored to identify objects."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aContent-Based Image Retrieval by Viewpoint-Invariant Image Indexing,o"
            },
            "venue": {
                "fragments": [],
                "text": "Image and Vision Computing,"
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 25,
                                "start": 21
                            }
                        ],
                        "text": "In the MAVIS2-system [84], data are considered at four semantic levels, embodied in four layers called the raw media, the selection, the selection expression, and conceptual layers."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "and W"
            },
            "venue": {
                "fragments": [],
                "text": "Hall, aSemiotics and Agents for Integrating and Navigating through Multimedia Representations,o Proc. Storage and Retrieval for Media Databases, vol. 3972, pp. 120-131"
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 8,
                                "start": 3
                            }
                        ],
                        "text": "In [176], over 10,000 features are computed from the image each SMEULDERS ET AL."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 8,
                                "start": 3
                            }
                        ],
                        "text": "In [176], a very large number of precomputed features is considered, of which a small subset is selected by boosting [80] to learn the image class."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aBoosting Image Retrieval,o"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. Computer Vision and Pattern Recognition,"
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "a Invariant Image Recognition by Zernike Moments , o IEEE Trans"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Analysis and Machine Intelligence"
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aProbabilistic Visual Learning for Object Representation,o"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Analysis and Machine Intelligence,"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "\u2026retrieval, semantic gap, sensory gap, narrow domain, broad domain, weak segmentation, accumulative features, salient features, signs, structural features, similarity, semantic interpretation, query space, display space, interactive session, indexing, architecture, evaluation, image databases.\n\u00e6"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Current Techniques, Promising Directions, and Open Issues,\u00ba J. Visual Comm. and Image Representation"
            },
            "venue": {
                "fragments": [],
                "text": "Current Techniques, Promising Directions, and Open Issues,\u00ba J. Visual Comm. and Image Representation"
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Venetsanopoulos, \u00aaA Novel Vector-Based Approach to Color Image Retrieval Using a Vector Angular-Based Distance Measure,\u00ba Image Understanding"
            },
            "venue": {
                "fragments": [],
                "text": "Venetsanopoulos, \u00aaA Novel Vector-Based Approach to Color Image Retrieval Using a Vector Angular-Based Distance Measure,\u00ba Image Understanding"
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Venetsanopoulos, \u00aaA Novel Vector-Based Approach to Color Image Retrieval Using a Vector Angular-Based Distance Measure,\u00ba Image Understanding"
            },
            "venue": {
                "fragments": [],
                "text": "Venetsanopoulos, \u00aaA Novel Vector-Based Approach to Color Image Retrieval Using a Vector Angular-Based Distance Measure,\u00ba Image Understanding"
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 76,
                                "start": 71
                            }
                        ],
                        "text": "A wide, rather unstructured variety of image detectors can be found in [165]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aSUSAN\u00d0A New Approach to Low Level Image Processing,o"
            },
            "venue": {
                "fragments": [],
                "text": "Int'l J. Computer Vision, vol. 23,"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "In this section, we\ndiscuss patterns in applications, the repertoire of images,\nthe influence of the scene and the role of domain\nknowledge, and the semantic gap between image features\nand the user."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 7,
                                "start": 3
                            }
                        ],
                        "text": "In the literature, a wide variety of content-based retrieval\nmethods and systems may be found."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "PicHunter: Theory, Implementation , and Pychophysical Experiments"
            },
            "venue": {
                "fragments": [],
                "text": "\u00aaThe Bayesian Image Retrieval System IEEE Trans. Image Processing"
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 35,
                                "start": 31
                            }
                        ],
                        "text": "Then, expectation-maximization [37] is used to determine"
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "and D"
            },
            "venue": {
                "fragments": [],
                "text": "Rubin, aMaximum Likelihood from Incomplete Data via the EM Algorithm,o J. Royal Statistical Soc., vol. 39, no. 1, pp. 1-38"
            },
            "year": 1977
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "\u00aaUsing Textual and Visual Cues for Content-Based Image Retrieval from the World Wide Web,\u00ba Image Understanding"
            },
            "venue": {
                "fragments": [],
                "text": "\u00aaUsing Textual and Visual Cues for Content-Based Image Retrieval from the World Wide Web,\u00ba Image Understanding"
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 81,
                                "start": 77
                            }
                        ],
                        "text": "Other joint histograms add local texture or local shape [61], directed edges [78], and local higher order structures [48]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aImage Retrieval Using Color and Shape,o"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognition,"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 105,
                                "start": 101
                            }
                        ],
                        "text": "By the same token, the RGB color space is effective in literal similarity (as it is effective in art [65]) while it does not represent the process of physical color formation or the process of color perception."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 202,
                                "start": 198
                            }
                        ],
                        "text": "Other systems based on signs are designed with specific application domains in mind, like OCR from an image [200], faces to detect from the image [197], medical images [90], [17], textile [95], art [65], or detecting the constituent components of silhouettes of plants based on a visual lexicon in [180]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aImage Processing and Database System in the National Museum of Western Art,o"
            },
            "venue": {
                "fragments": [],
                "text": "Int'l J. Special Libraries,"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 169,
                                "start": 165
                            }
                        ],
                        "text": "Automatic identification of salient regions in the image, based on nonparametric clustering followed by decomposition of the shapes found into limbs, is explored in [52]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aAutomatic Interpretation Based on Robust Segmentation and Shape Extraction,o"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. Visual '99: Information and Information Systems,"
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 27,
                                "start": 23
                            }
                        ],
                        "text": "To that end, in [107], [50], lay-out descriptions of an object are discussed in the form of a graph of relations between blobs."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aAutomatic Detection of Human Nudes,o"
            },
            "venue": {
                "fragments": [],
                "text": "Int'l J. Computer Vision,"
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 29,
                                "start": 24
                            }
                        ],
                        "text": "For a narrow domain, in [129], [132], the relevant elements of a medical X-ray image are characterized separately and joined together in a graph that encodes their spatial relations."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 146,
                                "start": 141
                            }
                        ],
                        "text": "A similar lay-out description of an image in terms of a graph representing the spatial relations between the objects of interest was used in [129] for the description of medical images."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aSimilarity Searching in Medical Image Databases,o"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Knowledge and Data Eng.,"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "a Filtering for Texture Classification : A Comparative Study , o IEEE Trans"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Analysis and Machine Intelligence"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 89,
                                "start": 85
                            }
                        ],
                        "text": "In point-by-point-based methods for shape comparison, shape similarity is studied in [83], where maximum curvature points on the contour and the length between them are used to characterize the object."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aObject-Based Image Similarity Computation Using Inductive Learning of Contour-Segment Relations,o"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Iamge Processing,"
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 27,
                                "start": 23
                            }
                        ],
                        "text": "To that end, in [107], [50], lay-out descriptions of an object are discussed in the form of a graph of relations between blobs."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aAutomatic Detection of Human Nudes,o"
            },
            "venue": {
                "fragments": [],
                "text": "Int'l J. Computer Vision,"
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 68,
                                "start": 63
                            }
                        ],
                        "text": "Such sets of selected and ordered contour points are stored in [108] relative to the basis spanned by an arbitrary pair of the points."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aSimilar-Shape Retrieval in Shape Data Management,o"
            },
            "venue": {
                "fragments": [],
                "text": "Computer, vol. 28,"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "\u00aaImage Retrieval by Color Semantics,\u00ba Multimedia Systems"
            },
            "venue": {
                "fragments": [],
                "text": "\u00aaImage Retrieval by Color Semantics,\u00ba Multimedia Systems"
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Content-based image retrieval systems may provide support in this disambiguation through elimination\namong several potential explanations, much the same as in natural language processing."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Lecture Notes in Computer Science"
            },
            "venue": {
                "fragments": [],
                "text": "Lecture Notes in Computer Science"
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 78,
                                "start": 74
                            }
                        ],
                        "text": "In retrieval, the property is computed in a sliding mask for localization [99], [59]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aColor Image Retrieval Based on Hidden Markov Models,o"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Image Processing,"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 8,
                                "start": 3
                            }
                        ],
                        "text": "In [144], users pose spatial-predicate queries on geographical signs located in maps based on their absolute or relative positions."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 134,
                                "start": 129
                            }
                        ],
                        "text": "In the case of maps, the interpretation of map symbols and their spatial relationships provides access to the content of the map [144]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aMARCO: MAp Retrieval by Content,o"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Analysis and Machine Intelligence,"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 37,
                                "start": 33
                            }
                        ],
                        "text": "combinations of moments [72] and [89] have been success-"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 95,
                                "start": 91
                            }
                        ],
                        "text": "Moments, specifically their invariant combinations, have been frequently used in retrieval [89]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aInvariant Image Recognition by Zernike Moments,o"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Analysis and Machine Intelligence,"
            },
            "year": 1990
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 119,
                                "start": 115
                            }
                        ],
                        "text": "In the MPEG-standard, the possibility of including semantic descriptors in the compression transform is introduced [29]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aThe Role of Analysis in Content-Based Video Coding and Indexing,o"
            },
            "venue": {
                "fragments": [],
                "text": "Signal Processing,"
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "\u00aaMultiscale Autoregressive Image Respresentation for Texture Segmentation,\u00ba Image Processing VIII"
            },
            "venue": {
                "fragments": [],
                "text": "\u00aaMultiscale Autoregressive Image Respresentation for Texture Segmentation,\u00ba Image Processing VIII"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "a Algebraic and Geometrical Tools to Compute Projective and Permutation Invariants , o IEEE Trans"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Analysis and Machine Intelligence Ten Lectures on Wavelets"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 119,
                                "start": 115
                            }
                        ],
                        "text": "In the MPEG-standard, the possibility of including semantic descriptors in the compression transform is introduced [29]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aThe Role of Analysis in Content-Based Video Coding and Indexing,o"
            },
            "venue": {
                "fragments": [],
                "text": "Signal Processing,"
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 89,
                                "start": 85
                            }
                        ],
                        "text": "Also, the application of geometric description derived from scale space theory\nwill reveal viewpoint and scene independent salient point sets, thus opening the way to similarity of images on a few most informative regions or points."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Protopapas, \u00aaEfficient and Effective Nearest Neighbor Search in a Medical Image Database of Tumor Shapes,\u00ba Image Description and Retrieval"
            },
            "venue": {
                "fragments": [],
                "text": "Protopapas, \u00aaEfficient and Effective Nearest Neighbor Search in a Medical Image Database of Tumor Shapes,\u00ba Image Description and Retrieval"
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Thong, \u00aaIndexing Multimedia for the Internet,\u00ba Proc. Visual '99: Information and Information Systems"
            },
            "venue": {
                "fragments": [],
                "text": "Thong, \u00aaIndexing Multimedia for the Internet,\u00ba Proc. Visual '99: Information and Information Systems"
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 13,
                                "start": 9
                            }
                        ],
                        "text": "In [74], [79], systems are designed for classifying trademarks."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 88,
                                "start": 84
                            }
                        ],
                        "text": ", for art paintings [64], the color composition of photographs [48], and trademarks [79], [39], where two-dimensional images are recorded in frontal view under standard conditions."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aShape-Based Retrieval: A Case Study with Trademark Image Databases,o"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognition,"
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 126,
                                "start": 121
                            }
                        ],
                        "text": "All point pairs are used as a basis to make the redundant representation geometrically invariant, a technique similar to [192] for unordered point sets."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 35,
                                "start": 30
                            }
                        ],
                        "text": "is found in geometric hashing [192], where each triplet spans a base for the remaining points of the object."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aGeometric Hashing: An Overview,o"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Computational Science Eng.,"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 164,
                                "start": 160
                            }
                        ],
                        "text": "The lowest levels of the wavelet transforms [34], [26] have been applied to texture representation [92], [162] sometimes in conjunction with Markovian analysis [25]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aMultiscale Texture Segmentation Using Wavelet-Domain Hidden Markov Models,o"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. 32nd Asilomar Conf. Signals, Systems, and Computers,"
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 172,
                                "start": 168
                            }
                        ],
                        "text": "Other systems based on signs are designed with specific application domains in mind, like OCR from an image [200], faces to detect from the image [197], medical images [90], [17], textile [95], art [65], or detecting the constituent components of silhouettes of plants based on a visual lexicon in [180]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "and Z"
            },
            "venue": {
                "fragments": [],
                "text": "Protopapas, aEfficient and Effective Nearest Neighbor Search in a Medical Image Database of Tumor Shapes,o Image Description and Retrieval, pp. 17-54"
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "\u00aaAn Optimal Algorithm for Approximate Nearest Neighborhood Searching,\u00ba Proc. Symp. Discrete Algorithms"
            },
            "venue": {
                "fragments": [],
                "text": "\u00aaAn Optimal Algorithm for Approximate Nearest Neighborhood Searching,\u00ba Proc. Symp. Discrete Algorithms"
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 206,
                                "start": 202
                            }
                        ],
                        "text": "It is regrettable that not too much work across the division between the disciplines of vision and databases has been done yet, with a few exceptions in commercial systems [48], [61] and research [46], [85], [171]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aLarge-Scale Parallel Data Clustering,o"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Analysis and Machine Intelligence,"
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 59,
                                "start": 54
                            }
                        ],
                        "text": "When specification is by parameterized template [36], [150], each image in IQ is processed to find the best match with edges of the images."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 87,
                                "start": 82
                            }
                        ],
                        "text": "In elastic deformation of image portions [36], [122] or modal matching techniques [150], image patches are deformed to minimize a cost functional that depends on a weighed sum of the mismatch of the two patches and on the deformation energy."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 103,
                                "start": 98
                            }
                        ],
                        "text": "Matching a query and an object in the data file can be done along the ordered set of eigen shapes [150] or with elastic matching [36], [11]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aDeformable Prototypes for Encoding Shape Categories in Image Databases,o"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognition,"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 135,
                                "start": 130
                            }
                        ],
                        "text": "Since this problem is yet unsolved, research is focused on different methods to associate higher level semantics to data-driven observables."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Fdez-Vidal, \u00aaThe RGFF Representational Model: A System for the Automatically Learned Partitioning ofof`Visual Pattern' in Digital Images"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Analysis and Machine Intelligence"
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 19,
                                "start": 15
                            }
                        ],
                        "text": "The systems in [70], [163] study spatial relationships between regions, each characterized by locations, size, and features."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 7,
                                "start": 3
                            }
                        ],
                        "text": "In [70], knowledge-based type abstraction hierarchies are"
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aA Knowledge-Based Approach for Retrieving Images by Content,o"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Knowledge and Data Eng.,"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 28,
                                "start": 24
                            }
                        ],
                        "text": "combinations of moments [72] and [89] have been success-"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aPattern Recognition by Moment Invariants,o"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. IRE Trans. Information Theory,"
            },
            "year": 1962
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 19,
                                "start": 15
                            }
                        ],
                        "text": "The display in [86] combines exact and SMEULDERS ET AL."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aBrowsing Functions in Three- Dimensional Space for Digital Libraries,o"
            },
            "venue": {
                "fragments": [],
                "text": "Int'l J. Digital Libraries,"
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 151,
                                "start": 146
                            }
                        ],
                        "text": "Other systems based on signs are designed with specific application domains in mind, like OCR from an image [200], faces to detect from the image [197], medical images [90], [17], textile [95], art [65], or detecting the constituent components of silhouettes of plants based on a visual lexicon in [180]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aHuman Face Image Retrieval System for Large Database,o"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. 14th Int'l Conf. Pattern Recognition,"
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 13,
                                "start": 9
                            }
                        ],
                        "text": "See also [69] for a comparison with correlograms."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aIntegrating Color"
            },
            "venue": {
                "fragments": [],
                "text": "Texture, and Geometry for Image Retrieval,o Proc. Computer Vision and Pattern Recognition, pp. 239-247"
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Therefore, in retrieval research, in [101], the Wold features of periodicity, directionality, and randomness are used, which agree reasonably well with linguistic descriptions of textures as implemented in [128]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "\u00aaImage Retrieval Using Color and Shape,\u00ba Pattern Recognition"
            },
            "venue": {
                "fragments": [],
                "text": "\u00aaImage Retrieval Using Color and Shape,\u00ba Pattern Recognition"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "\u00aaBenchmarking Multimedia Databases,\u00ba Multimedia Tools and Applications"
            },
            "venue": {
                "fragments": [],
                "text": "\u00aaBenchmarking Multimedia Databases,\u00ba Multimedia Tools and Applications"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 69,
                                "start": 64
                            }
                        ],
                        "text": "The large number of elements is clearly an issue in [21], [40], [168] and any other of the numerous Web search engines, where the emphasis is on filling the database using the World Wide Web as a logical repository."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 64,
                                "start": 59
                            }
                        ],
                        "text": "A broad class of images can be found in large photo stocks [168] or other photo archives [42]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 110,
                                "start": 105
                            }
                        ],
                        "text": "To support the quest for relevant results, other sources than images are also employed, see for example, [168], [21]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aSearching for Multimedia on the World Wide Web,o"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. Int'l Conf. Multimedia Computing and Systems,"
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 67,
                                "start": 62
                            }
                        ],
                        "text": "An abundant comparison of shape for retrieval can be found in [109], evaluating many features on a 500-element trademark data set."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aShape Measures for Content Based Image Retrieval: A Comparison,o"
            },
            "venue": {
                "fragments": [],
                "text": "Information Procesing Management,"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "\u00aaToward a Unified Theory of Similarity and Recognition,\u00ba Psychological Rev"
            },
            "venue": {
                "fragments": [],
                "text": "\u00aaToward a Unified Theory of Similarity and Recognition,\u00ba Psychological Rev"
            },
            "year": 1988
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 54,
                                "start": 50
                            }
                        ],
                        "text": "The lowest levels of the wavelet transforms [34], [26] have been applied to texture representation [92], [162] sometimes in conjunction with Markovian analysis [25]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Wavelets: Theory"
            },
            "venue": {
                "fragments": [],
                "text": "Algorithms, and Applications. Academic Press"
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 112,
                                "start": 107
                            }
                        ],
                        "text": "A solid comparative study on texture classification from mostly transform-based properties can be found in [133]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Husoy, aFiltering for Texture Classification: A Comparative Study,o"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Analysis and Machine Intelligence,"
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 181,
                                "start": 176
                            }
                        ],
                        "text": "Also, in [20], homogeneous regions are represented as collections of ellipsoids of uniform color or texture, but invariant texture properties deserve more attention, [173] and [185]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aUsing Zernike Moments for the Illumination and Geometry Invariant Classification of Multi- Spectral Texture,o"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Image Processing,"
            },
            "year": 1991
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 126,
                                "start": 122
                            }
                        ],
                        "text": "In content-based image retrieval, the first steps are taken to establish the discriminating power of invariant properties [55]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 24,
                                "start": 20
                            }
                        ],
                        "text": "Similarly, in [57], [55], photometric invariance is"
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "and R"
            },
            "venue": {
                "fragments": [],
                "text": "van den Boomgaard, aMeasurement of Color Invariants,o Proc. Computer Vision and Pattern Recognition"
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 164,
                                "start": 160
                            }
                        ],
                        "text": "It also has the advantage of dealing directly with features that can be represented in a metric space but not in a vector space, unlike techniques like FastMap [46] or multidimensional scaling which approximate the feature space with a vector space that maintains approximately the same metric."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 200,
                                "start": 196
                            }
                        ],
                        "text": "It is regrettable that not too much work across the division between the disciplines of vision and databases has been done yet, with a few exceptions in commercial systems [48], [61] and research [46], [85], [171]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aFastmap: A Fast Algorithm for Indexing"
            },
            "venue": {
                "fragments": [],
                "text": "Data-Mining and Visualization of Traditional and Multimedia Datasets,o Proc. SIGMOD, Int'l Conf. Management of Data, pp. 163-174"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 52,
                                "start": 48
                            }
                        ],
                        "text": "When specification is by parameterized template [36], [150], each image in IQ is processed to find the best match with edges of the images."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 45,
                                "start": 41
                            }
                        ],
                        "text": "In elastic deformation of image portions [36], [122] or modal matching techniques [150], image patches are deformed to minimize a cost functional that depends on a weighed sum of the mismatch of the two patches and on the deformation energy."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 133,
                                "start": 129
                            }
                        ],
                        "text": "Matching a query and an object in the data file can be done along the ordered set of eigen shapes [150] or with elastic matching [36], [11]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aVisual Image Retrieval by Elastic Matching of User Sketches,o"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Analysis and Machine Intelligence,"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 77,
                                "start": 72
                            }
                        ],
                        "text": "One of the early contributions to do so can be found in the CORE-system [193], which has been the basis for many different applications."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aCORE: A Content Based Retrieval System for Multimedia Information Systems,o"
            },
            "venue": {
                "fragments": [],
                "text": "Multimedia Systems,"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 41,
                                "start": 37
                            }
                        ],
                        "text": "Further research is needed in the design of complete sets of image properties with well-described variant conditions which they are capable of handling."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 188,
                                "start": 184
                            }
                        ],
                        "text": "Combining shape and color both in invariant fashion is a powerful combination, as described by [56], where the colors inside and outside affine curvature maximums in color edges are stored to identify objects."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 100,
                                "start": 96
                            }
                        ],
                        "text": "The aim of invariant descriptions is to identify objects, no matter from how and where they are observed, at the loss of some of the information content."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Based Image Querying,\u00ba Proc. Int'l Workshop Content-Based Access of Image and Video libraries"
            },
            "venue": {
                "fragments": [],
                "text": "Based Image Querying,\u00ba Proc. Int'l Workshop Content-Based Access of Image and Video libraries"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 82,
                                "start": 78
                            }
                        ],
                        "text": "Texture search proved useful in satellite images [98] and images of documents [33]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aDocument Image Database Retrieval and Browsing Using Texture Analysis,o"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. Fourth Int'l Conf. Document Analysis and Recognition,"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 40,
                                "start": 35
                            }
                        ],
                        "text": "recently been introduced in [194], [139], both using the"
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "and N"
            },
            "venue": {
                "fragments": [],
                "text": "Ahuja, aLearning to Recognize Objects,o Proc. Computer Vision and Pattern Recognition, pp. 724- 731"
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 195,
                                "start": 190
                            }
                        ],
                        "text": "Combining shape and color both in invariant fashion is a powerful combination, as described by [56], where the colors inside and outside affine curvature maximums in color edges are stored to identify objects."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Analysis and Machine Intelligence"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Analysis and Machine Intelligence"
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 103,
                                "start": 98
                            }
                        ],
                        "text": "This assumption is consistent with a class of psychological models of human similarity perception [154], [147] and requires that the feature space be metric."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aToward a Universal Law of Generalization for"
            },
            "venue": {
                "fragments": [],
                "text": "Physical Science,o Science,"
            },
            "year": 1987
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 53,
                                "start": 49
                            }
                        ],
                        "text": "These three types of use are not the whole story [42]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 93,
                                "start": 89
                            }
                        ],
                        "text": "A broad class of images can be found in large photo stocks [168] or other photo archives [42]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aPictorial Information Retrieval,o"
            },
            "venue": {
                "fragments": [],
                "text": "J. Documentation,"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 52,
                                "start": 47
                            }
                        ],
                        "text": "Content-based image retrieval systems may provide support in this disambiguation through elimination\namong several potential explanations, much the same as in natural language processing."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "\u00aaInvariance in Content-Based Retrieval,\u00ba Proc. Int'l Conf. Multimedia and Expo"
            },
            "venue": {
                "fragments": [],
                "text": "\u00aaInvariance in Content-Based Retrieval,\u00ba Proc. Int'l Conf. Multimedia and Expo"
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 46,
                                "start": 41
                            }
                        ],
                        "text": "suggested, as well as statistical models [127]."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aFace Recognition for Smart Environments,o"
            },
            "venue": {
                "fragments": [],
                "text": "Computer, vol. 33,"
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 32,
                                "start": 27
                            }
                        ],
                        "text": "To keep up performance, in [125], a joint histogram is used, providing discrimination among 250,000 images in their database, rendering 80 percent recall among the best 10 for two shots from the same scene using simple features."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Zabith, aComparing Images Using Joint Histograms,o"
            },
            "venue": {
                "fragments": [],
                "text": "Multimedia Systems,"
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 140,
                                "start": 135
                            }
                        ],
                        "text": "The user can also explicitly bring in semantic information by annotating individual images, groups of images, or regions inside images [111] with a semantic label."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 19,
                                "start": 14
                            }
                        ],
                        "text": "The system in [111] precomputes a hierarchical grouping of partitionings (or images for that matter) based on the similarity for each individual feature."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aInteractive Learning with a `Society of Models,'o"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognition,"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 140,
                                "start": 135
                            }
                        ],
                        "text": "The user can also explicitly bring in semantic information by annotating individual images, groups of images, or regions inside images [111] with a semantic label."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 19,
                                "start": 14
                            }
                        ],
                        "text": "The system in [111] precomputes a hierarchical grouping of partitionings (or images for that matter) based on the similarity for each individual feature."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aInteractive Learning with a `Society of Models,'o"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognition,"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 17,
                                "start": 12
                            }
                        ],
                        "text": "The SS-tree [189] and its further improvement, the SR-tree [87], use the intersection of the minimum bounding hypersphere and minimum bounding hyperrectangle as the bounding region of a data element."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aSimilarity Indexing with the SS-Tree,o"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. 12th Int'l Conf. Data Eng.,"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 40,
                                "start": 35
                            }
                        ],
                        "text": "recently been introduced in [194], [139], both using the"
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "and N"
            },
            "venue": {
                "fragments": [],
                "text": "Ahuja, aLearning to Recognize Objects,o Proc. Computer Vision and Pattern Recognition, pp. 724- 731"
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 195,
                                "start": 190
                            }
                        ],
                        "text": "Combining shape and color both in invariant fashion is a powerful combination, as described by [56], where the colors inside and outside affine curvature maximums in color edges are stored to identify objects."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Analysis and Machine Intelligence"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Analysis and Machine Intelligence"
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 103,
                                "start": 98
                            }
                        ],
                        "text": "This assumption is consistent with a class of psychological models of human similarity perception [154], [147] and requires that the feature space be metric."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aToward a Universal Law of Generalization for"
            },
            "venue": {
                "fragments": [],
                "text": "Physical Science,o Science,"
            },
            "year": 1987
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 192,
                                "start": 188
                            }
                        ],
                        "text": "Other systems based on signs are designed with specific application domains in mind, like OCR from an image [200], faces to detect from the image [197], medical images [90], [17], textile [95], art [65], or detecting the constituent components of silhouettes of plants based on a visual lexicon in [180]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aMontage: An Image Database for the Fashion"
            },
            "venue": {
                "fragments": [],
                "text": "Textile, and Clothing Industry in Hong Kong,o Proc. Asian Conf. Computer Vision, pp. 575-582"
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "\u00aaBoosting Image Retrieval,\u00ba Proc. Computer Vision and Pattern Recognition"
            },
            "venue": {
                "fragments": [],
                "text": "\u00aaBoosting Image Retrieval,\u00ba Proc. Computer Vision and Pattern Recognition"
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "An Efficient Method for Locating Object Queries in Image Databases,\u00ba Storage and Retrieval in Image and Video Databases"
            },
            "venue": {
                "fragments": [],
                "text": "An Efficient Method for Locating Object Queries in Image Databases,\u00ba Storage and Retrieval in Image and Video Databases"
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 87,
                                "start": 82
                            }
                        ],
                        "text": "Similarity of two points sets Pq and Pd given in a rowwise matrix is discussed in [188]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aSimilarity and Affine Invariant Distances between 2D Point Sets,o"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Analysis and Machine Intelligence,"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 71,
                                "start": 66
                            }
                        ],
                        "text": "A simulated fisheye lens is used to induce perception of depth in [175]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 15,
                                "start": 10
                            }
                        ],
                        "text": "In [146], [175], [68], the operator V maps the highdimensional feature space onto a display space with d \u0088 3."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aBrowsing Images Based on Social and Content Similarity,o"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. Int'l Conf. Multimedia and Expo,"
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 24,
                                "start": 19
                            }
                        ],
                        "text": "The Piction system [155] proposes an architecture for collaborative use of image information and related textual information, while making knowledge explicit."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aAutomatic Indexing and Content-Based Retrieval of Captioned Images,o"
            },
            "venue": {
                "fragments": [],
                "text": "Computer, vol. 28,"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 176,
                                "start": 173
                            }
                        ],
                        "text": "Recent work from the vision side is found in [170], where the database organizes itself for narrow domains in clustering hierarchies of the most expressive features, and in [2], where clusters of feature values are sought in a graph-theoretical representation."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aGraph-Theoretic Clustering for Image Grouping and Retrieval,o"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. Computer Vision and Pattern Recognition,"
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 7,
                                "start": 3
                            }
                        ],
                        "text": "In [14], the VP-tree was generalized for high dimensional feature vectors."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aDistance-Based Indexing for High-Dimensional Metric Spaces,o"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. SIGMOD Int'l Conf. Management of Data,"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "At one end of the spectrum, we have the narrow domain:"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 91,
                                "start": 86
                            }
                        ],
                        "text": "Wavelets say something about the local shape as well as the texture and so do many scale space and local filter strategies."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Rosin, \u00aaEdges: Saliency Measures and Automatic Thresholding ,\u00ba Machine Vision Applications"
            },
            "venue": {
                "fragments": [],
                "text": "Rosin, \u00aaEdges: Saliency Measures and Automatic Thresholding ,\u00ba Machine Vision Applications"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "\u00aaSimilarity of Color Images,\u00ba Storage and Retrieval of Image and Video Databases III"
            },
            "venue": {
                "fragments": [],
                "text": "\u00aaSimilarity of Color Images,\u00ba Storage and Retrieval of Image and Video Databases III"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "An Efficient Method for Locating Object Queries in Image Databases,\u00ba Storage and Retrieval in Image and Video Databases"
            },
            "venue": {
                "fragments": [],
                "text": "An Efficient Method for Locating Object Queries in Image Databases,\u00ba Storage and Retrieval in Image and Video Databases"
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 42,
                                "start": 38
                            }
                        ],
                        "text": "The generic architecture described in [60] is based on a detailed model of the various information types."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aMulti-Media Information Systems.o"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Multimedia,"
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Veltkamp, \u00aaReliable and Efficient Pattern Matching Using an Affine Invariant Metric,\u00ba Int"
            },
            "venue": {
                "fragments": [],
                "text": "J. Computer Vision"
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 57,
                                "start": 53
                            }
                        ],
                        "text": "For a review on statistical pattern recognition, see [80]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 121,
                                "start": 117
                            }
                        ],
                        "text": "In [176], a very large number of precomputed features is considered, of which a small subset is selected by boosting [80] to learn the image class."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aStatistical Pattern Recognition: A Review,o"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Analysis and Machine Intelligence,"
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 111,
                                "start": 106
                            }
                        ],
                        "text": "The performance of R -trees degrades by a factor of 12 as the number of dimensions increases from 5 to 10 [190]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 73,
                                "start": 68
                            }
                        ],
                        "text": "The VAM-split R-tree splits along the dimension of maximum variance [190], hence the name, and was shown to have a better performance than standard R -tree."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aAlgorithms and Strategies for Similarity Retrieval,o"
            },
            "venue": {
                "fragments": [],
                "text": "Storage and Retrieval in Image, and Video Databases,"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 303,
                                "start": 298
                            }
                        ],
                        "text": "Other systems based on signs are designed with specific application domains in mind, like OCR from an image [200], faces to detect from the image [197], medical images [90], [17], textile [95], art [65], or detecting the constituent components of silhouettes of plants based on a visual lexicon in [180]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aDomain Concept to Feature Mapping for a Plant Variety Image Database,o"
            },
            "venue": {
                "fragments": [],
                "text": "Image Databases and Multimedia Search,"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 147,
                                "start": 143
                            }
                        ],
                        "text": "If two objects ti (or two appearances of the same object) are equivalent under a group of transformations W , they are in an equivalence class [18]:"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 120,
                                "start": 116
                            }
                        ],
                        "text": "Invariant description in image retrieval is relatively new, but quickly gaining ground for a good introduction, see [18], [32]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aInvariant Features for Discriminating between Equivalence Classes,o Nonlinear Model-Based Image Video Processing and Analysis"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 64,
                                "start": 60
                            }
                        ],
                        "text": "In computer vision, color constancy was first considered in [49]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Novel Algorithm for Color Constancy,o"
            },
            "venue": {
                "fragments": [],
                "text": "Int'l J. Computer Vision,"
            },
            "year": 1990
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 55,
                                "start": 52
                            }
                        ],
                        "text": "This view is rooted in the psychological literature [8] and, in the context of content-based retrieval, it has been proposed, for example, in [114]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aToward a Unified Theory of Similarity and Recognition,o"
            },
            "venue": {
                "fragments": [],
                "text": "Psychological Rev., vol. 95,"
            },
            "year": 1988
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 129,
                                "start": 124
                            }
                        ],
                        "text": "A method employing local shape and intensity information for viewpoint and occlusion invariant object retrieval is given in [148]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 8,
                                "start": 3
                            }
                        ],
                        "text": "In [148], salient and invariant transitions in gray value images"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aLocal Grayvalue Invariants for Image Retrieval,o"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Analysis and Machine Intelligence,"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "\u00aaASSERT: A Physician in the Loop Content-Based Retrieval System for HCRT Image Databases,\u00ba Image Understanding"
            },
            "venue": {
                "fragments": [],
                "text": "\u00aaASSERT: A Physician in the Loop Content-Based Retrieval System for HCRT Image Databases,\u00ba Image Understanding"
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 136,
                                "start": 131
                            }
                        ],
                        "text": "In the repertoire of images under consideration\u00d0the image domain I\u00d0there is a gradual distinction between narrow and broad domains [160]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "and T"
            },
            "venue": {
                "fragments": [],
                "text": "Gevers, aCrossing the Divide between Computer Vision and Data Bases in Search of Image Databases,o Proc. Fourth Working Conf. Visual Database Systems, pp. 223-239"
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "5."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 179,
                                "start": 174
                            }
                        ],
                        "text": "Combining shape and color both in invariant fashion is a powerful combination, as described by [56], where the colors inside and outside affine curvature maximums in color edges are stored to identify objects."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 27,
                                "start": 22
                            }
                        ],
                        "text": "For faces, many geometric models have been\nsuggested, as well as statistical models [127]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "\u00aaNonparametric Clustering for Image Segmentation and Grouping,\u00ba Image Understanding"
            },
            "venue": {
                "fragments": [],
                "text": "\u00aaNonparametric Clustering for Image Segmentation and Grouping,\u00ba Image Understanding"
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 52,
                                "start": 47
                            }
                        ],
                        "text": "In elastic deformation of image portions [36], [122] or modal matching techniques [150], image patches are deformed to minimize a cost functional that depends on a weighed sum of the mismatch of the two patches and on the deformation energy."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aImage Retrieval by Shape and Texture,o"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognition,"
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 103,
                                "start": 99
                            }
                        ],
                        "text": "In space-partitioning index techniques, the feature space is organized like a tree as discussed in [15]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aTree-Based Indexes for Image Data,o"
            },
            "venue": {
                "fragments": [],
                "text": "J. Visual Comm. and Image Representation,"
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 8,
                                "start": 3
                            }
                        ],
                        "text": "In [152], a 15-fold decrease in response time is reported using the k\u00ff d tree for a 20-nearest neighbors query over N \u0088 500,000 images with M \u0088 78 dimensions in feature space and \u0088 0:1."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "and M"
            },
            "venue": {
                "fragments": [],
                "text": "La Cascia, aImagerover: A Content- Base Image Browser for the World Wide Web,o Proc. Workshop Content-Based Access to Image and Video Libraries, pp. 1,000-1,006"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 8,
                                "start": 3
                            }
                        ],
                        "text": "In [191], [74], a Bayesian framework is developed for the matching of relational attributed graphs by discrete relaxation."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aStructural Matching by Discrete Relaxation,o"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Analysis and Machine Intelligence,"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 103,
                                "start": 99
                            }
                        ],
                        "text": "In space-partitioning index techniques, the feature space is organized like a tree as discussed in [15]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aTree-Based Indexes for Image Data,o"
            },
            "venue": {
                "fragments": [],
                "text": "J. Visual Comm. and Image Representation,"
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "\u2026retrieval, semantic gap, sensory gap, narrow domain, broad domain, weak segmentation, accumulative features, salient features, signs, structural features, similarity, semantic interpretation, query space, display space, interactive session, indexing, architecture, evaluation, image databases.\n\u00e6"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Petkovic, \u00aaContent-Based Representation and Retrieval of Visual Media: A State of the Art Review"
            },
            "venue": {
                "fragments": [],
                "text": "Multimedia Tools and Applications"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 13,
                                "start": 8
                            }
                        ],
                        "text": "A study [121] of journalists identified five typical patterns of use: searches for one specific image, general browsing to make an interactive choice, searches for a picture to go with a broad story, searches to illustrate a document, and searches for fill-ins only on the esthetic value of the picture."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aImage Retrieval: Theoretical and Empirical User Studies on Accessing Information in Images,o"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. 60th Am. Soc. Information Science Ann. Meeting,"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 8,
                                "start": 3
                            }
                        ],
                        "text": "In [105], a series of Gabor filters of different directions and scale have been used to enhance image properties [137]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aTexture Features for Browsing and Retrieval of Image Data,o"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Analysis and Machine Intelligence,"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "5."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 179,
                                "start": 174
                            }
                        ],
                        "text": "Combining shape and color both in invariant fashion is a powerful combination, as described by [56], where the colors inside and outside affine curvature maximums in color edges are stored to identify objects."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 27,
                                "start": 22
                            }
                        ],
                        "text": "For faces, many geometric models have been\nsuggested, as well as statistical models [127]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "\u00aaNonparametric Clustering for Image Segmentation and Grouping,\u00ba Image Understanding"
            },
            "venue": {
                "fragments": [],
                "text": "\u00aaNonparametric Clustering for Image Segmentation and Grouping,\u00ba Image Understanding"
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 52,
                                "start": 47
                            }
                        ],
                        "text": "In elastic deformation of image portions [36], [122] or modal matching techniques [150], image patches are deformed to minimize a cost functional that depends on a weighed sum of the mismatch of the two patches and on the deformation energy."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aImage Retrieval by Shape and Texture,o"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognition,"
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "\u00aaLearning to Recognize Objects,\u00ba Proc. Computer Vision and Pattern Recognition"
            },
            "venue": {
                "fragments": [],
                "text": "\u00aaLearning to Recognize Objects,\u00ba Proc. Computer Vision and Pattern Recognition"
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 172,
                                "start": 168
                            }
                        ],
                        "text": "Combining shape and color both in invariant fashion is a powerful combination, as described by [56], where the colors inside and outside affine curvature maximums in color edges are stored to identify objects."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "\u00aaAutomatic Detection of Human Nudes,\u00ba Int'l"
            },
            "venue": {
                "fragments": [],
                "text": "J. Computer Vision"
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "a The Method of Normalization of Determine Invariants , o IEEE Trans"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Analysis and Machine Intelligence a Image Retrieval : Current Techniques , Promising Directions , and Open Issues , o J . Visual Comm . and Image Representation"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "\u00aaImagerover: A Content- Base Image Browser for the World Wide Web"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. Workshop Content-Based Access to Image and Video Libraries"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 38,
                                "start": 33
                            }
                        ],
                        "text": "In contrast, systems reviewed in [141] and, particularly, the MARSsystem [142], are based on the information retrieval paradigm."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aImage Retrieval: Current Techniques"
            },
            "venue": {
                "fragments": [],
                "text": "Promising Directions, and Open Issues,o J. Visual Comm. and Image Representation, vol. 10, no. 1, pp. 39-62"
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 57,
                                "start": 53
                            }
                        ],
                        "text": "A similar approach for digital libraries is taken by [24]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 12,
                                "start": 8
                            }
                        ],
                        "text": "Also in [24], the aim is to create a very large"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aA Parallel Computing Approach to Creating Engineering Concept Spaces for Semantic Retrieval: The Illinois Digital Library Initiative Project,o"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Analysis and Machine Intelligence,"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Pictorial information retrieval"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "In this section, we\ndiscuss patterns in applications, the repertoire of images,\nthe influence of the scene and the role of domain\nknowledge, and the semantic gap between image features\nand the user."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Proc. Computer Vision and Pattern Recognition"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. Computer Vision and Pattern Recognition"
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "In this section, we\ndiscuss patterns in applications, the repertoire of images,\nthe influence of the scene and the role of domain\nknowledge, and the semantic gap between image features\nand the user."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Theoretical and Empirical User Studies on Accessing Information in Images"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. 60th Am. Soc. Information Science Ann. Meeting"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "At one end of the spectrum, we have the narrow domain:"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "\u00aaImage Processing and Database System in the National Museum of Western Art,\u00ba Int'l"
            },
            "venue": {
                "fragments": [],
                "text": "J. Special Libraries"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 178,
                                "start": 174
                            }
                        ],
                        "text": "Other systems based on signs are designed with specific application domains in mind, like OCR from an image [200], faces to detect from the image [197], medical images [90], [17], textile [95], art [65], or detecting the constituent components of silhouettes of plants based on a visual lexicon in [180]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "and R"
            },
            "venue": {
                "fragments": [],
                "text": "De Dominicis, a Integrating Content- Based Retrieval in a Medical Image Reference Database,o Computerized Medical Imaging and Graphics, vol. 20, no. 4, pp. 231- 241"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 8,
                                "start": 3
                            }
                        ],
                        "text": "In [120], ranges on color values are predefined in predicates like aMostlyBlueo and aSomeYellow."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 8,
                                "start": 3
                            }
                        ],
                        "text": "In [120], an extended relational database system was used."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aCHABOT\u00d0Retrieval from a Relational Database of Images,o"
            },
            "venue": {
                "fragments": [],
                "text": "Computer, vol. 28,"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "\u00aaImagerover: A Content- Base Image Browser for the World Wide Web"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. Workshop Content-Based Access to Image and Video Libraries"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 178,
                                "start": 174
                            }
                        ],
                        "text": "Other systems based on signs are designed with specific application domains in mind, like OCR from an image [200], faces to detect from the image [197], medical images [90], [17], textile [95], art [65], or detecting the constituent components of silhouettes of plants based on a visual lexicon in [180]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "and R"
            },
            "venue": {
                "fragments": [],
                "text": "De Dominicis, a Integrating Content- Based Retrieval in a Medical Image Reference Database,o Computerized Medical Imaging and Graphics, vol. 20, no. 4, pp. 231- 241"
            },
            "year": 1996
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 142,
            "methodology": 57,
            "result": 1
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 412,
        "totalPages": 42
    },
    "page_url": "https://www.semanticscholar.org/paper/Content-Based-Image-Retrieval-at-the-End-of-the-Smeulders-Worring/0b7c4096ed697696a5f4fc8f3a6a750dc0cdecfe?sort=total-citations"
}