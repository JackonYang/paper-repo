{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2083209039"
                        ],
                        "name": "Edgar Seemann",
                        "slug": "Edgar-Seemann",
                        "structuredName": {
                            "firstName": "Edgar",
                            "lastName": "Seemann",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Edgar Seemann"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1739548"
                        ],
                        "name": "Mario Fritz",
                        "slug": "Mario-Fritz",
                        "structuredName": {
                            "firstName": "Mario",
                            "lastName": "Fritz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mario Fritz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48920094"
                        ],
                        "name": "B. Schiele",
                        "slug": "B.-Schiele",
                        "structuredName": {
                            "firstName": "Bernt",
                            "lastName": "Schiele",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Schiele"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 82,
                                "start": 78
                            }
                        ],
                        "text": "In rare cases this assignment may be suboptimal, especially in crowded scenes [32], but in practice the effect should be negligible."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 224,
                                "start": 174
                            }
                        ],
                        "text": "Detecting people in images is a problem with a long history [37, 13, 35, 27, 16, 41, 23, 5]; in the past two years there has been a surge of interest in pedestrian detection [6, 9, 11, 18, 20, 21, 25, 30, 32, 33, 36, 38, 42]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6240352,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4736c2b507a05aa3848dc049003a6b1bd62da221",
            "isKey": false,
            "numCitedBy": 74,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "Object class detection in scenes of realistic complexity remains a challenging task in computer vision. Most recent approaches focus on a single and general model for object class detection. However, in particular in the context of image sequences, it may be advantageous to adapt the general model to a more object-instance specific model in order to detect this particular object reliably within the image sequence. In this work we present a generative object model that is capable to scale from a general object class model to a more specific object-instance model. This allows to detect class instances as well as to distinguish between individual object instances reliably. We experimentally evaluate the performance of the proposed system on both still images and image sequences."
            },
            "slug": "Towards-Robust-Pedestrian-Detection-in-Crowded-Seemann-Fritz",
            "title": {
                "fragments": [],
                "text": "Towards Robust Pedestrian Detection in Crowded Image Sequences"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This work presents a generative object model that is capable to scale from a general object class model to a more specific object-instance model that allows to detect class instances as well as to distinguish between individual object instances reliably."
            },
            "venue": {
                "fragments": [],
                "text": "2007 IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144404428"
                        ],
                        "name": "Yang Song",
                        "slug": "Yang-Song",
                        "structuredName": {
                            "firstName": "Yang",
                            "lastName": "Song",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yang Song"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7285418"
                        ],
                        "name": "X. Feng",
                        "slug": "X.-Feng",
                        "structuredName": {
                            "firstName": "Xiaolin",
                            "lastName": "Feng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "X. Feng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1690922"
                        ],
                        "name": "P. Perona",
                        "slug": "P.-Perona",
                        "structuredName": {
                            "firstName": "Pietro",
                            "lastName": "Perona",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Perona"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 91,
                                "start": 60
                            }
                        ],
                        "text": "Detecting people in images is a problem with a long history [37, 13, 35, 27, 16, 41, 23, 5]; in the past two years there has been a surge of interest in pedestrian detection [6, 9, 11, 18, 20, 21, 25, 30, 32, 33, 36, 38, 42]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 16347620,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "dcbf88922b6c87a27b4f045decd020fb71a97985",
            "isKey": false,
            "numCitedBy": 149,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "Detecting humans in images is a useful application of computer vision. Loose and textured clothing, occlusion and scene clutter make it a difficult problem because bottom-up segmentation and grouping do not always work. We address the problem of detecting humans from their motion pattern in monocular image sequences; extraneous motions and occlusion may be present. We assume that we may not rely on segmentation or grouping and that the vision front-end is limited to observing the motion of key points and textured patches in between pairs of frames. We do not assume that we are able to track features for more than two frames. Our method is based on learning an approximate probabilistic model of the joint position and velocity of different body features. Detection is performed by hypothesis testing on the maximum a posteriori estimate of the pose and motion of the body. Our experiments on a dozen of walking sequences indicate that our algorithm is accurate and efficient."
            },
            "slug": "Towards-detection-of-human-motion-Song-Feng",
            "title": {
                "fragments": [],
                "text": "Towards detection of human motion"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This work addresses the problem of detecting humans from their motion pattern in monocular image sequences; extraneous motions and occlusion may be present."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings IEEE Conference on Computer Vision and Pattern Recognition. CVPR 2000 (Cat. No.PR00662)"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712041"
                        ],
                        "name": "K. Mikolajczyk",
                        "slug": "K.-Mikolajczyk",
                        "structuredName": {
                            "firstName": "Krystian",
                            "lastName": "Mikolajczyk",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Mikolajczyk"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2462253"
                        ],
                        "name": "C. Schmid",
                        "slug": "C.-Schmid",
                        "structuredName": {
                            "firstName": "Cordelia",
                            "lastName": "Schmid",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Schmid"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688869"
                        ],
                        "name": "Andrew Zisserman",
                        "slug": "Andrew-Zisserman",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Zisserman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Zisserman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 91,
                                "start": 60
                            }
                        ],
                        "text": "Detecting people in images is a problem with a long history [37, 13, 35, 27, 16, 41, 23, 5]; in the past two years there has been a surge of interest in pedestrian detection [6, 9, 11, 18, 20, 21, 25, 30, 32, 33, 36, 38, 42]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 3870070,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f9cc6155cd69023a736a7b8f8680bcd6232c840e",
            "isKey": false,
            "numCitedBy": 764,
            "numCiting": 47,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a novel method for human detection in single images which can detect full bodies as well as close-up views in the presence of clutter and occlusion. Humans are modeled as flexible assemblies of parts, and robust part detection is the key to the approach. The parts are represented by co-occurrences of local features which captures the spatial layout of the partrsquos appearance. Feature selection and the part detectors are learnt from training images using AdaBoost. The detection algorithm is very efficient as (i) all part detectors use the same initial features, (ii) a coarse-to-fine cascade approach is used for part detection, (iii) a part assembly strategy reduces the number of spurious detections and the search space. The results outperform existing human detectors."
            },
            "slug": "Human-Detection-Based-on-a-Probabilistic-Assembly-Mikolajczyk-Schmid",
            "title": {
                "fragments": [],
                "text": "Human Detection Based on a Probabilistic Assembly of Robust Part Detectors"
            },
            "tldr": {
                "abstractSimilarityScore": 92,
                "text": "A novel method for human detection in single images which can detect full bodies as well as close-up views in the presence of clutter and occlusion is described."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "51323684"
                        ],
                        "name": "David Ger\u00f3nimo",
                        "slug": "David-Ger\u00f3nimo",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Ger\u00f3nimo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David Ger\u00f3nimo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1782314"
                        ],
                        "name": "A. Sappa",
                        "slug": "A.-Sappa",
                        "structuredName": {
                            "firstName": "Angel",
                            "lastName": "Sappa",
                            "middleNames": [
                                "Domingo"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Sappa"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144187725"
                        ],
                        "name": "Antonio M. L\u00f3pez",
                        "slug": "Antonio-M.-L\u00f3pez",
                        "structuredName": {
                            "firstName": "Antonio",
                            "lastName": "L\u00f3pez",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Antonio M. L\u00f3pez"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1786419"
                        ],
                        "name": "D. Ponsa",
                        "slug": "D.-Ponsa",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Ponsa",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Ponsa"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 159,
                                "start": 155
                            }
                        ],
                        "text": "MIT[27] 924 \u2013 \u2013 \u2013 \u2013 \u2013 128 128 128 3 USC-A[43] \u2013 \u2013 \u2013 313 \u2013 205 70 98 133 3 USC-B[43] \u2013 \u2013 \u2013 271 \u2013 54 63 90 126 3 USC-C[44] \u2013 \u2013 \u2013 232 \u2013 100 74 108 145 3 3 CVC[14] 1000 6175\u2020 \u2013 \u2013 \u2013 \u2013 46 83 164 3 3 TUD-det[1] 400 \u2013 400 311 \u2013 250 133 218 278 3 3 INRIA[5] 1208 1218 614 566 453 288 139 279 456 3 DC[24] 2."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 36,
                                "start": 24
                            }
                        ],
                        "text": "Automotive applications [12, 14, 34] are particularly compelling as they have the potential to save numerous lives [39]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6925699,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "57fe081950f21ca03b5b375ae3e84b399c015861",
            "isKey": false,
            "numCitedBy": 86,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "On-board pedestrian detection is in the frontier of the state- of-the-art since it implies processing outdoor scenarios from a mobile platform and searching for aspect-changing objects in cluttered urban environments. Most promising approaches include the development of classifiers based on feature selection and machine learning. However, they use a large number of features which compromises real-time. Thus, methods for running the classifiers in only a few image windows must be provided. In this paper we contribute in both aspects, proposing a cam- era pose estimation method for adaptive sparse image sampling, as well as a classifier for pedestrian detection based on Haar wavelets and edge orientation histograms as features and AdaBoost as learning machine. Both proposals are compared with relevant approaches in the literature, showing comparable results but reducing processing time by four for the sampling tasks and by ten for the classification one."
            },
            "slug": "Adaptive-Image-Sampling-and-Windows-Classification-Ger\u00f3nimo-Sappa",
            "title": {
                "fragments": [],
                "text": "Adaptive Image Sampling and Windows Classification for On-board Pedestrian Detection"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A cam- era pose estimation method for adaptive sparse image sampling, as well as a classifier for pedestrian detection based on Haar wavelets and edge orientation histograms as features and AdaBoost as learning machine are proposed."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1731948"
                        ],
                        "name": "Paul A. Viola",
                        "slug": "Paul-A.-Viola",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Viola",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Paul A. Viola"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145319478"
                        ],
                        "name": "Michael J. Jones",
                        "slug": "Michael-J.-Jones",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Jones",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael J. Jones"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144626092"
                        ],
                        "name": "D. Snow",
                        "slug": "D.-Snow",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Snow",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Snow"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 101,
                                "start": 94
                            }
                        ],
                        "text": "We are also interested in evaluating detectors that utilize features computed over 2-4 frames [41, 4] and also algorithms that integrate information over longer time scales."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 91,
                                "start": 60
                            }
                        ],
                        "text": "Detecting people in images is a problem with a long history [37, 13, 35, 27, 16, 41, 23, 5]; in the past two years there has been a surge of interest in pedestrian detection [6, 9, 11, 18, 20, 21, 25, 30, 32, 33, 36, 38, 42]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 47726,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3702c79b8d118f8f363d685905bd285ab8e33979",
            "isKey": false,
            "numCitedBy": 1524,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes a pedestrian detection system that integrates image intensity information with motion information. We use a detection style algorithm that scans a detector over two consecutive frames of a video sequence. The detector is trained (using AdaBoost) to take advantage of both motion and appearance information to detect a walking person. Past approaches have built detectors based on motion information or detectors based on appearance information, but ours is the first to combine both sources of information in a single detector. The implementation described runs at about 4 frames/second, detects pedestrians at very small scales (as small as 20 \u00d7 15 pixels), and has a very low false positive rate.Our approach builds on the detection work of Viola and Jones. Novel contributions of this paper include: (i) development of a representation of image motion which is extremely efficient, and (ii) implementation of a state of the art pedestrian detection system which operates on low resolution images under difficult conditions (such as rain and snow)."
            },
            "slug": "Detecting-Pedestrians-Using-Patterns-of-Motion-and-Viola-Jones",
            "title": {
                "fragments": [],
                "text": "Detecting Pedestrians Using Patterns of Motion and Appearance"
            },
            "tldr": {
                "abstractSimilarityScore": 52,
                "text": "This pedestrian detection system is the first to combine both sources of information in a single detector, and operates on low resolution images under difficult conditions (such as rain and snow)."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1906895"
                        ],
                        "name": "M. Andriluka",
                        "slug": "M.-Andriluka",
                        "structuredName": {
                            "firstName": "Mykhaylo",
                            "lastName": "Andriluka",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Andriluka"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145920814"
                        ],
                        "name": "S. Roth",
                        "slug": "S.-Roth",
                        "structuredName": {
                            "firstName": "Stefan",
                            "lastName": "Roth",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Roth"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48920094"
                        ],
                        "name": "B. Schiele",
                        "slug": "B.-Schiele",
                        "structuredName": {
                            "firstName": "Bernt",
                            "lastName": "Schiele",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Schiele"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 203,
                                "start": 200
                            }
                        ],
                        "text": "MIT[27] 924 \u2013 \u2013 \u2013 \u2013 \u2013 128 128 128 3 USC-A[43] \u2013 \u2013 \u2013 313 \u2013 205 70 98 133 3 USC-B[43] \u2013 \u2013 \u2013 271 \u2013 54 63 90 126 3 USC-C[44] \u2013 \u2013 \u2013 232 \u2013 100 74 108 145 3 3 CVC[14] 1000 6175\u2020 \u2013 \u2013 \u2013 \u2013 46 83 164 3 3 TUD-det[1] 400 \u2013 400 311 \u2013 250 133 218 278 3 3 INRIA[5] 1208 1218 614 566 453 288 139 279 456 3 DC[24] 2."
                    },
                    "intents": []
                }
            ],
            "corpusId": 206590983,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ccbc65d05e753b097a6c6b1ece25624e2ee39d5d",
            "isKey": false,
            "numCitedBy": 924,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "Both detection and tracking people are challenging problems, especially in complex real world scenes that commonly involve multiple people, complicated occlusions, and cluttered or even moving backgrounds. People detectors have been shown to be able to locate pedestrians even in complex street scenes, but false positives have remained frequent. The identification of particular individuals has remained challenging as well. Tracking methods are able to find a particular individual in image sequences, but are severely challenged by real-world scenarios such as crowded street scenes. In this paper, we combine the advantages of both detection and tracking in a single framework. The approximate articulation of each person is detected in every frame based on local features that model the appearance of individual body parts. Prior knowledge on possible articulations and temporal coherency within a walking cycle are modeled using a hierarchical Gaussian process latent variable model (hGPLVM). We show how the combination of these results improves hypotheses for position and articulation of each person in several subsequent frames. We present experimental results that demonstrate how this allows to detect and track multiple people in cluttered scenes with reoccurring occlusions."
            },
            "slug": "People-tracking-by-detection-and-Andriluka-Roth",
            "title": {
                "fragments": [],
                "text": "People-tracking-by-detection and people-detection-by-tracking"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This paper combines the advantages of both detection and tracking in a single framework using a hierarchical Gaussian process latent variable model (hGPLVM) and presents experimental results that demonstrate how this allows to detect and track multiple people in cluttered scenes with reoccurring occlusions."
            },
            "venue": {
                "fragments": [],
                "text": "2008 IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144854796"
                        ],
                        "name": "D. Gavrila",
                        "slug": "D.-Gavrila",
                        "structuredName": {
                            "firstName": "Dariu",
                            "lastName": "Gavrila",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Gavrila"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2919518"
                        ],
                        "name": "S. Munder",
                        "slug": "S.-Munder",
                        "structuredName": {
                            "firstName": "Stefan",
                            "lastName": "Munder",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Munder"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 36,
                                "start": 24
                            }
                        ],
                        "text": "Automotive applications [12, 14, 34] are particularly compelling as they have the potential to save numerous lives [39]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 59459,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "91335d9335e4fd06de48d769d1b79eaded4e431b",
            "isKey": false,
            "numCitedBy": 595,
            "numCiting": 42,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a multi-cue vision system for the real-time detection and tracking of pedestrians from a moving vehicle. The detection component involves a cascade of modules, each utilizing complementary visual criteria to successively narrow down the image search space, balancing robustness and efficiency considerations. Novel is the tight integration of the consecutive modules: (sparse) stereo-based ROI generation, shape-based detection, texture-based classification and (dense) stereo-based verification. For example, shape-based detection activates a weighted combination of texture-based classifiers, each attuned to a particular body pose.Performance of individual modules and their interaction is analyzed by means of Receiver Operator Characteristics (ROCs). A sequential optimization technique allows the successive combination of individual ROCs, providing optimized system parameter settings in a systematic fashion, avoiding ad-hoc parameter tuning. Application-dependent processing constraints can be incorporated in the optimization procedure.Results from extensive field tests in difficult urban traffic conditions suggest system performance is at the leading edge."
            },
            "slug": "Multi-cue-Pedestrian-Detection-and-Tracking-from-a-Gavrila-Munder",
            "title": {
                "fragments": [],
                "text": "Multi-cue Pedestrian Detection and Tracking from a Moving Vehicle"
            },
            "tldr": {
                "abstractSimilarityScore": 67,
                "text": "This paper presents a multi-cue vision system for the real-time detection and tracking of pedestrians from a moving vehicle, with results from extensive field tests in difficult urban traffic conditions suggest system performance is at the leading edge."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48950628"
                        ],
                        "name": "N. Dalal",
                        "slug": "N.-Dalal",
                        "structuredName": {
                            "firstName": "Navneet",
                            "lastName": "Dalal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Dalal"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 119,
                                "start": 116
                            }
                        ],
                        "text": "All approaches use sliding windows and NMS (all except LatSvm use kernel density estimation for NMS, as proposed in [4])."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 101,
                                "start": 94
                            }
                        ],
                        "text": "We are also interested in evaluating detectors that utilize features computed over 2-4 frames [41, 4] and also algorithms that integrate information over longer time scales."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 68,
                                "start": 65
                            }
                        ],
                        "text": "The first of these is context, both spatial [9, 15] and temporal [4]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 37581938,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "47980c6e42f1a3381e6c5f3db7230e6a64c40218",
            "isKey": false,
            "numCitedBy": 369,
            "numCiting": 218,
            "paperAbstract": {
                "fragments": [],
                "text": "This thesis targets the detection of humans and other object classes in images and videos. Our focus is on developing robust feature extraction algorithms that encode image regions as highdimensional feature vectors that support high accuracy object/non-object decisions. To test our feature sets we adopt a relatively simple learning framework that uses linear Support Vector Machines to classify each possible image region as an object or as a non-object. The approach is data-driven and purely bottom-up using low-level appearance and motion vectors to detect objects. As a test case we focus on person detection as people are one of the most challenging object classes with many applications, for example in film and video analysis, pedestrian detection for smart cars and video surveillance. Nevertheless we do not make any strong class specific assumptions and the resulting object detection framework also gives state-of-the-art performance for many other classes including cars, motorbikes, cows and sheep. This thesis makes four main contributions. Firstly, we introduce grids of locally normalised Histograms of Oriented Gradients (HOG) as descriptors for object detection in static images. The HOG descriptors are computed over dense and overlapping grids of spatial blocks, with image gradient orientation features extracted at fixed resolution and gathered into a highdimensional feature vector. They are designed to be robust to small changes in image contour locations and directions, and significant changes in image illumination and colour, while remaining highly discriminative for overall visual form. We show that unsmoothed gradients, fine orientation voting, moderately coarse spatial binning, strong normalisation and overlapping blocks are all needed for good performance. Secondly, to detect moving humans in videos, we propose descriptors based on oriented histograms of differential optical flow. These are similar to static HOG descriptors, but instead of image gradients, they are based on local differentials of dense optical flow. They encode the noisy optical flow estimates into robust feature vectors in a manner that is robust to the overall camera motion. Several variants are proposed, some capturing motion boundaries while others encode the relative motions of adjacent image regions. Thirdly, we propose a general method based on kernel density estimation for fusing multiple overlapping detections, that takes into account the number of detections, their confidence scores and the scales of the detections. Lastly, we present work in progress on a parts based approach to person detection that first detects local body parts like heads, torso, and legs and then fuses them to create a global overall person detector."
            },
            "slug": "Finding-People-in-Images-and-Videos-Dalal",
            "title": {
                "fragments": [],
                "text": "Finding People in Images and Videos"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This thesis introduces grids of locally normalised Histograms of Oriented Gradients (HOG) as descriptors for object detection in static images and proposes descriptors based on oriented histograms of differential optical flow to detect moving humans in videos."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2570029"
                        ],
                        "name": "P. Sabzmeydani",
                        "slug": "P.-Sabzmeydani",
                        "structuredName": {
                            "firstName": "Payam",
                            "lastName": "Sabzmeydani",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Sabzmeydani"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "10771328"
                        ],
                        "name": "Greg Mori",
                        "slug": "Greg-Mori",
                        "structuredName": {
                            "firstName": "Greg",
                            "lastName": "Mori",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Greg Mori"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 60,
                                "start": 34
                            }
                        ],
                        "text": "(3) We benchmark seven algorithms [40, 5, 7, 30, 11, 42, 21], either obtained directly from the original authors or reimplemented in-house."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 19,
                                "start": 15
                            }
                        ],
                        "text": "20 \u201907 Shapelet[30] gradients AdaBoost 3 60."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 224,
                                "start": 174
                            }
                        ],
                        "text": "Detecting people in images is a problem with a long history [37, 13, 35, 27, 16, 41, 23, 5]; in the past two years there has been a surge of interest in pedestrian detection [6, 9, 11, 18, 20, 21, 25, 30, 32, 33, 36, 38, 42]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 99,
                                "start": 91
                            }
                        ],
                        "text": "We obtained the detectors directly from their authors, the only exceptions were the VJ and Shapelet detectors which were reimplemented in [42] (these outperform the OpenCV VJ code and the original Shapelet code, respectively, see Fig."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 15,
                                "start": 7
                            }
                        ],
                        "text": "VJ and Shapelet perform poorly."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 60,
                                "start": 52
                            }
                        ],
                        "text": "We observed this in two of the algorithms evaluated [30, 21] 2."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 13420116,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b09d132046f3b21f98206eb514ebfcbd73f32513",
            "isKey": true,
            "numCitedBy": 356,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we address the problem of detecting pedestrians in still images. We introduce an algorithm for learning shapelet features, a set of mid-level features. These features are focused on local regions of the image and are built from low-level gradient information that discriminates between pedestrian and non-pedestrian classes. Using Ad-aBoost, these shapelet features are created as a combination of oriented gradient responses. To train the final classifier, we use AdaBoost for a second time to select a subset of our learned shapelets. By first focusing locally on smaller feature sets, our algorithm attempts to harvest more useful information than by examining all the low-level features together. We present quantitative results demonstrating the effectiveness of our algorithm. In particular, we obtain an error rate 14 percentage points lower (at 10-6 FPPW) than the previous state of the art detector of Dalal and Triggs on the INRIA dataset."
            },
            "slug": "Detecting-Pedestrians-by-Learning-Shapelet-Features-Sabzmeydani-Mori",
            "title": {
                "fragments": [],
                "text": "Detecting Pedestrians by Learning Shapelet Features"
            },
            "tldr": {
                "abstractSimilarityScore": 56,
                "text": "This paper introduces an algorithm for learning shapelet features, a set of mid-level features that are built from low-level gradient information that discriminates between pedestrian and non-pedestrian classes on the INRIA dataset."
            },
            "venue": {
                "fragments": [],
                "text": "2007 IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2433494"
                        ],
                        "name": "Andreas Ess",
                        "slug": "Andreas-Ess",
                        "structuredName": {
                            "firstName": "Andreas",
                            "lastName": "Ess",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andreas Ess"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1789756"
                        ],
                        "name": "B. Leibe",
                        "slug": "B.-Leibe",
                        "structuredName": {
                            "firstName": "B.",
                            "lastName": "Leibe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Leibe"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144810819"
                        ],
                        "name": "K. Schindler",
                        "slug": "K.-Schindler",
                        "structuredName": {
                            "firstName": "Konrad",
                            "lastName": "Schindler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Schindler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1681236"
                        ],
                        "name": "L. Gool",
                        "slug": "L.-Gool",
                        "structuredName": {
                            "firstName": "Luc",
                            "lastName": "Gool",
                            "middleNames": [
                                "Van"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Gool"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 51,
                                "start": 44
                            }
                        ],
                        "text": "The first of these is context, both spatial [9, 15] and temporal [4]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 224,
                                "start": 174
                            }
                        ],
                        "text": "Detecting people in images is a problem with a long history [37, 13, 35, 27, 16, 41, 23, 5]; in the past two years there has been a surge of interest in pedestrian detection [6, 9, 11, 18, 20, 21, 25, 30, 32, 33, 36, 38, 42]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 10044277,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7047496e6159cdac94b2871516b593bf1c6bf0c5",
            "isKey": false,
            "numCitedBy": 623,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a mobile vision system for multi-person tracking in busy environments. Specifically, the system integrates continuous visual odometry computation with tracking-by-detection in order to track pedestrians in spite of frequent occlusions and egomotion of the camera rig. To achieve reliable performance under real-world conditions, it has long been advocated to extract and combine as much visual information as possible. We propose a way to closely integrate the vision modules for visual odometry, pedestrian detection, depth estimation, and tracking. The integration naturally leads to several cognitive feedback loops between the modules. Among others, we propose a novel feedback connection from the object detector to visual odometry which utilizes the semantic knowledge of detection to stabilize localization. Feedback loops always carry the danger that erroneous feedback from one module is amplified and causes the entire system to become instable. We therefore incorporate automatic failure detection and recovery, allowing the system to continue when a module becomes unreliable. The approach is experimentally evaluated on several long and difficult video sequences from busy inner-city locations. Our results show that the proposed integration makes it possible to deliver stable tracking performance in scenes of previously infeasible complexity."
            },
            "slug": "A-mobile-vision-system-for-robust-multi-person-Ess-Leibe",
            "title": {
                "fragments": [],
                "text": "A mobile vision system for robust multi-person tracking"
            },
            "tldr": {
                "abstractSimilarityScore": 88,
                "text": "A mobile vision system for multi-person tracking in busy environments that integrates continuous visual odometry computation with tracking-by-detection in order to track pedestrians in spite of frequent occlusions and egomotion of the camera rig is presented."
            },
            "venue": {
                "fragments": [],
                "text": "2008 IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2919518"
                        ],
                        "name": "S. Munder",
                        "slug": "S.-Munder",
                        "structuredName": {
                            "firstName": "Stefan",
                            "lastName": "Munder",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Munder"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144854796"
                        ],
                        "name": "D. Gavrila",
                        "slug": "D.-Gavrila",
                        "structuredName": {
                            "firstName": "Dariu",
                            "lastName": "Gavrila",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Gavrila"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 295,
                                "start": 291
                            }
                        ],
                        "text": "MIT[27] 924 \u2013 \u2013 \u2013 \u2013 \u2013 128 128 128 3 USC-A[43] \u2013 \u2013 \u2013 313 \u2013 205 70 98 133 3 USC-B[43] \u2013 \u2013 \u2013 271 \u2013 54 63 90 126 3 USC-C[44] \u2013 \u2013 \u2013 232 \u2013 100 74 108 145 3 3 CVC[14] 1000 6175\u2020 \u2013 \u2013 \u2013 \u2013 46 83 164 3 3 TUD-det[1] 400 \u2013 400 311 \u2013 250 133 218 278 3 3 INRIA[5] 1208 1218 614 566 453 288 139 279 456 3 DC[24] 2."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 66,
                                "start": 62
                            }
                        ],
                        "text": "The other most relevant datasets are the DaimlerChrysler (DC) [24] and ETH [8] datasets."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 10769792,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4ebbf3ec461f9b347937e4a5b993f12940558934",
            "isKey": false,
            "numCitedBy": 636,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "Detecting people in images is key for several important application domains in computer vision. This paper presents an in-depth experimental study on pedestrian classification; multiple feature-classifier combinations are examined with respect to their ROC performance and efficiency. We investigate global versus local and adaptive versus nonadaptive features, as exemplified by PCA coefficients, Haar wavelets, and local receptive fields (LRFs). In terms of classifiers, we consider the popular support vector machines (SVMs), feedforward neural networks, and k-nearest neighbor classifier. Experiments are performed on a large data set consisting of 4,000 pedestrian and more than 25,000 nonpedestrian (labeled) images captured in outdoor urban environments. Statistically meaningful results are obtained by analyzing performance variances caused by varying training and test sets. Furthermore, we investigate how classification performance and training sample size are correlated. Sample size is adjusted by increasing the number of manually labeled training data or by employing automatic bootstrapping or cascade techniques. Our experiments show that the novel combination of SVMs with LRF features performs best. A boosted cascade of Haar wavelets can, however, reach quite competitive results, at a fraction of computational cost. The data set used in this paper is made public, establishing a benchmark for this important problem"
            },
            "slug": "An-Experimental-Study-on-Pedestrian-Classification-Munder-Gavrila",
            "title": {
                "fragments": [],
                "text": "An Experimental Study on Pedestrian Classification"
            },
            "tldr": {
                "abstractSimilarityScore": 53,
                "text": "An in-depth experimental study on pedestrian classification; multiple feature-classifier combinations are examined with respect to their ROC performance and efficiency and show that the novel combination of SVMs with LRF features performs best."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143847264"
                        ],
                        "name": "Bo Wu",
                        "slug": "Bo-Wu",
                        "structuredName": {
                            "firstName": "Bo",
                            "lastName": "Wu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bo Wu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144862593"
                        ],
                        "name": "R. Nevatia",
                        "slug": "R.-Nevatia",
                        "structuredName": {
                            "firstName": "Ramakant",
                            "lastName": "Nevatia",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Nevatia"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 45,
                                "start": 41
                            }
                        ],
                        "text": "MIT[27] 924 \u2013 \u2013 \u2013 \u2013 \u2013 128 128 128 3 USC-A[43] \u2013 \u2013 \u2013 313 \u2013 205 70 98 133 3 USC-B[43] \u2013 \u2013 \u2013 271 \u2013 54 63 90 126 3 USC-C[44] \u2013 \u2013 \u2013 232 \u2013 100 74 108 145 3 3 CVC[14] 1000 6175\u2020 \u2013 \u2013 \u2013 \u2013 46 83 164 3 3 TUD-det[1] 400 \u2013 400 311 \u2013 250 133 218 278 3 3 INRIA[5] 1208 1218 614 566 453 288 139 279 456 3 DC[24] 2."
                    },
                    "intents": []
                }
            ],
            "corpusId": 206769463,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "de1ac0baea1f907388ff5fe9fa22f25f406e2ca6",
            "isKey": false,
            "numCitedBy": 881,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper proposes a method for human detection in crowded scene from static images. An individual human is modeled as an assembly of natural body parts. We introduce edgelet features, which are a new type of silhouette oriented features. Part detectors, based on these features, are learned by a boosting method. Responses of part detectors are combined to form a joint likelihood model that includes cases of multiple, possibly inter-occluded humans. The human detection problem is formulated as maximum a posteriori (MAP) estimation. We show results on a commonly used previous dataset as well as new data sets that could not be processed by earlier methods."
            },
            "slug": "Detection-of-multiple,-partially-occluded-humans-in-Wu-Nevatia",
            "title": {
                "fragments": [],
                "text": "Detection of multiple, partially occluded humans in a single image by Bayesian combination of edgelet part detectors"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "The human detection problem is formulated as maximum a posteriori (MAP) estimation, and edgelet features are introduced, which are a new type of silhouette oriented features that are learned by a boosting method."
            },
            "venue": {
                "fragments": [],
                "text": "Tenth IEEE International Conference on Computer Vision (ICCV'05) Volume 1"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2919518"
                        ],
                        "name": "S. Munder",
                        "slug": "S.-Munder",
                        "structuredName": {
                            "firstName": "Stefan",
                            "lastName": "Munder",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Munder"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1679944"
                        ],
                        "name": "C. Schn\u00f6rr",
                        "slug": "C.-Schn\u00f6rr",
                        "structuredName": {
                            "firstName": "Christoph",
                            "lastName": "Schn\u00f6rr",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Schn\u00f6rr"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144854796"
                        ],
                        "name": "D. Gavrila",
                        "slug": "D.-Gavrila",
                        "structuredName": {
                            "firstName": "Dariu",
                            "lastName": "Gavrila",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Gavrila"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 224,
                                "start": 174
                            }
                        ],
                        "text": "Detecting people in images is a problem with a long history [37, 13, 35, 27, 16, 41, 23, 5]; in the past two years there has been a surge of interest in pedestrian detection [6, 9, 11, 18, 20, 21, 25, 30, 32, 33, 36, 38, 42]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 12797124,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "896a2ad6b91c74aa78ea0111b4e566f57d2dbb75",
            "isKey": false,
            "numCitedBy": 115,
            "numCiting": 48,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a robust multicue approach to the integrated detection and tracking of pedestrians in a cluttered urban environment. A novel spatiotemporal object representation is proposed, which combines a generative shape model and a discriminative texture classifier, both of which are composed of a mixture of pose-specific submodels. Shape is represented by a set of linear subspace models, which is an extension of point distribution models, with shape transitions being modeled by a first-order Markov process. Texture, i.e., the shape-normalized intensity pattern, is represented by a manifold that is implicitly delimited by a set of pattern classifiers, whereas texture transition is modeled by a random walk. Direct 3-D measurements that are provided by a stereo system are further incorporated into the observation density function. We employ a Bayesian framework based on particle filtering to achieve integrated object detection and tracking. Large-scale experiments that involve pedestrian detection and tracking from a moving vehicle demonstrate the benefit of the proposed approach."
            },
            "slug": "Pedestrian-Detection-and-Tracking-Using-a-Mixture-Munder-Schn\u00f6rr",
            "title": {
                "fragments": [],
                "text": "Pedestrian Detection and Tracking Using a Mixture of View-Based Shape\u2013Texture Models"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A novel spatiotemporal object representation is proposed, which combines a generative shape model and a discriminative texture classifier, both of which are composed of a mixture of pose-specific submodels."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Intelligent Transportation Systems"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145696606"
                        ],
                        "name": "Vinay Sharma",
                        "slug": "Vinay-Sharma",
                        "structuredName": {
                            "firstName": "Vinay",
                            "lastName": "Sharma",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Vinay Sharma"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144429686"
                        ],
                        "name": "James W. Davis",
                        "slug": "James-W.-Davis",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Davis",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "James W. Davis"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 224,
                                "start": 174
                            }
                        ],
                        "text": "Detecting people in images is a problem with a long history [37, 13, 35, 27, 16, 41, 23, 5]; in the past two years there has been a surge of interest in pedestrian detection [6, 9, 11, 18, 20, 21, 25, 30, 32, 33, 36, 38, 42]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 10755594,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "47b84e0b1d572b0b3dd6e050dc9f72765b8f4eb8",
            "isKey": false,
            "numCitedBy": 44,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a unified method for simultaneously acquiring both the location and the silhouette shape of people in outdoor scenes. The proposed algorithm integrates top-down and bottom-up processes in a balanced manner, employing both appearance and motion cues at different perceptual levels. Without requiring manually segmented training data, the algorithm employs a simple top-down procedure to capture the high-level cue of object familiarity. Motivated by regularities in the shape and motion characteristics of humans, interactions among low-level contour features are exploited to extract mid-level perceptual cues such as smooth continuation, common fate, and closure. A Markov random field formulation is presented that effectively combines the various cues from the top-down and bottom-up processes. The algorithm is extensively evaluated on static and moving pedestrian datasets for both detection and segmentation."
            },
            "slug": "Integrating-Appearance-and-Motion-Cues-for-and-of-Sharma-Davis",
            "title": {
                "fragments": [],
                "text": "Integrating Appearance and Motion Cues for Simultaneous Detection and Segmentation of Pedestrians"
            },
            "tldr": {
                "abstractSimilarityScore": 87,
                "text": "A unified method for simultaneously acquiring both the location and the silhouette shape of people in outdoor scenes by integrating top-down and bottom-up processes in a balanced manner, employing both appearance and motion cues at different perceptual levels is presented."
            },
            "venue": {
                "fragments": [],
                "text": "2007 IEEE 11th International Conference on Computer Vision"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2433494"
                        ],
                        "name": "Andreas Ess",
                        "slug": "Andreas-Ess",
                        "structuredName": {
                            "firstName": "Andreas",
                            "lastName": "Ess",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andreas Ess"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1789756"
                        ],
                        "name": "B. Leibe",
                        "slug": "B.-Leibe",
                        "structuredName": {
                            "firstName": "B.",
                            "lastName": "Leibe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Leibe"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1681236"
                        ],
                        "name": "L. Gool",
                        "slug": "L.-Gool",
                        "structuredName": {
                            "firstName": "Luc",
                            "lastName": "Gool",
                            "middleNames": [
                                "Van"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Gool"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 78,
                                "start": 75
                            }
                        ],
                        "text": "The other most relevant datasets are the DaimlerChrysler (DC) [24] and ETH [8] datasets."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 27,
                                "start": 24
                            }
                        ],
                        "text": "6k 10k\u2020 \u2013 36 36 36 3 ETH[8] 2388 \u2013 499 12k \u2013 1804 50 90 189 3 3 3 3 Caltech 192k 61k 67k 155k 56k 65k 27 48 97 3 3 3 3 3 3"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 150,
                                "start": 147
                            }
                        ],
                        "text": "Pedestrians can be labeled in photographs [5], surveillance video [26], and images taken from a mobile recording setup, such as a robot or vehicle [8]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 7,
                                "start": 4
                            }
                        ],
                        "text": "The ETH data, captured using a pair of cameras attached to a stroller, has reasonable scale variation and a significant amount of labeled data; however, occlusions are not annotated and each frame is labeled independently."
                    },
                    "intents": []
                }
            ],
            "corpusId": 16824129,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "590941c26d057f917c7f5275824d350e9aac7ba3",
            "isKey": true,
            "numCitedBy": 545,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we address the challenging problem of simultaneous pedestrian detection and ground-plane estimation from video while walking through a busy pedestrian zone. Our proposed system integrates robust stereo depth cues, ground-plane estimation, and appearance-based object detection in a principled fashion using a graphical model. Object-object occlusions lead to complex interactions in this model that make an exact solution computationally intractable. We therefore propose a novel iterative approach that first infers scene geometry using belief propagation and then resolves interactions between objects using a global optimization procedure. This approach leads to a robust solution in few iterations, while allowing object detection to benefit from geometry estimation and vice versa. We quantitatively evaluate the performance of our proposed approach on several challenging test sequences showing strolls through busy shopping streets. Comparisons to various baseline systems show that it outperforms both a system using no scene geometry and one just relying on structure-from-motion without dense stereo."
            },
            "slug": "Depth-and-Appearance-for-Mobile-Scene-Analysis-Ess-Leibe",
            "title": {
                "fragments": [],
                "text": "Depth and Appearance for Mobile Scene Analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This work proposes a novel iterative approach that first infers scene geometry using belief propagation and then resolves interactions between objects using a global optimization procedure, which leads to a robust solution in few iterations, while allowing object detection to benefit from geometry estimation and vice versa."
            },
            "venue": {
                "fragments": [],
                "text": "2007 IEEE 11th International Conference on Computer Vision"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2828154"
                        ],
                        "name": "Duan Tran",
                        "slug": "Duan-Tran",
                        "structuredName": {
                            "firstName": "Duan",
                            "lastName": "Tran",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Duan Tran"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144016256"
                        ],
                        "name": "D. Forsyth",
                        "slug": "D.-Forsyth",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Forsyth",
                            "middleNames": [
                                "Alexander"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Forsyth"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 53,
                                "start": 49
                            }
                        ],
                        "text": "Detectors may require different sampling schemes [36], particularly those that are somewhat invariant to changes in position and scale; furthermore, there can be complex interactions between sampling density and NMS."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 224,
                                "start": 174
                            }
                        ],
                        "text": "Detecting people in images is a problem with a long history [37, 13, 35, 27, 16, 41, 23, 5]; in the past two years there has been a surge of interest in pedestrian detection [6, 9, 11, 18, 20, 21, 25, 30, 32, 33, 36, 38, 42]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 13902758,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "35570297681daa3973498eabead361d0be961672",
            "isKey": false,
            "numCitedBy": 63,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "Fair discriminative pedestrian finders are now available. In fact, these pedestrian finders make most errors on pedestrians in configurations that are uncommon in the training data, for example, mounting a bicycle. This is undesirable. However, the human configuration can itself be estimated discriminatively using structure learning. We demonstrate a pedestrian finder which first finds the most likely human pose in the window using a discriminative procedure trained with structure learning on a small dataset. We then present features (local histogram of oriented gradient and local PCA of gradient) based on that configuration to an SVM classifier. We show, using the INRIA Person dataset, that estimates of configuration significantly improve the accuracy of a discriminative pedestrian finder."
            },
            "slug": "Configuration-Estimates-Improve-Pedestrian-Finding-Tran-Forsyth",
            "title": {
                "fragments": [],
                "text": "Configuration Estimates Improve Pedestrian Finding"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "It is shown, using the INRIA Person dataset, that estimates of configuration significantly improve the accuracy of a discriminative pedestrian finder."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1731948"
                        ],
                        "name": "Paul A. Viola",
                        "slug": "Paul-A.-Viola",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Viola",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Paul A. Viola"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2111328101"
                        ],
                        "name": "Michael Jones",
                        "slug": "Michael-Jones",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Jones",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael Jones"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 60,
                                "start": 34
                            }
                        ],
                        "text": "(3) We benchmark seven algorithms [40, 5, 7, 30, 11, 42, 21], either obtained directly from the original authors or reimplemented in-house."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 235084,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4cb4d685b47001652b29dc41c1b3e786277e7647",
            "isKey": false,
            "numCitedBy": 4016,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes a visual object detection framework that is capable of processing images extremely rapidly while achieving high detection rates. There are three key contributions. The first is the introduction of a new image representation called the \u201cIntegral Image\u201d which allows the features used by our detector to be computed very quickly. The second is a learning algorithm, based on AdaBoost, which selects a small number of critical visual features and yields extremely efficient classifiers [4]. The third contribution is a method for combining classifiers in a \u201ccascade\u201d which allows background regions of the image to be quickly discarded while spending more computation on promising object-like regions. A set of experiments in the domain of face detection are presented. The system yields face detection performance comparable to the best previous systems [16, 11, 14, 10, 1]. Implemented on a conventional desktop, face detection proceeds at 15 frames per second. Author email: fPaul.Viola,Mike.J.Jonesg@compaq.com c Compaq Computer Corporation, 2001 This work may not be copied or reproduced in whole or in part for any commercial purpose. Permission to copy in whole or in part without payment of fee is granted for nonprofit educational and research purposes provided that all such whole or partial copies include the following: a notice that such copying is by permission of the Cambridge Research Laboratory of Compaq Computer Corporation in Cambridge, Massachusetts; an acknowledgment of the authors and individual contributors to the work; and all applicable portions of the copyright notice. Copying, reproducing, or republishing for any other purpose shall require a license with payment of fee to the Cambridge Research Laboratory. All rights reserved. CRL Technical reports are available on the CRL\u2019s web page at http://crl.research.compaq.com. Compaq Computer Corporation Cambridge Research Laboratory One Cambridge Center Cambridge, Massachusetts 02142 USA"
            },
            "slug": "Robust-Real-time-Object-Detection-Viola-Jones",
            "title": {
                "fragments": [],
                "text": "Robust Real-time Object Detection"
            },
            "tldr": {
                "abstractSimilarityScore": 80,
                "text": "A visual object detection framework that is capable of processing images extremely rapidly while achieving high detection rates is described, with the introduction of a new image representation called the \u201cIntegral Image\u201d which allows the features used by the detector to be computed very quickly."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1789756"
                        ],
                        "name": "B. Leibe",
                        "slug": "B.-Leibe",
                        "structuredName": {
                            "firstName": "B.",
                            "lastName": "Leibe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Leibe"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2590936"
                        ],
                        "name": "Nico Cornelis",
                        "slug": "Nico-Cornelis",
                        "structuredName": {
                            "firstName": "Nico",
                            "lastName": "Cornelis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nico Cornelis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1804147"
                        ],
                        "name": "K. Cornelis",
                        "slug": "K.-Cornelis",
                        "structuredName": {
                            "firstName": "Kurt",
                            "lastName": "Cornelis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Cornelis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1681236"
                        ],
                        "name": "L. Gool",
                        "slug": "L.-Gool",
                        "structuredName": {
                            "firstName": "Luc",
                            "lastName": "Gool",
                            "middleNames": [
                                "Van"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Gool"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 224,
                                "start": 174
                            }
                        ],
                        "text": "Detecting people in images is a problem with a long history [37, 13, 35, 27, 16, 41, 23, 5]; in the past two years there has been a surge of interest in pedestrian detection [6, 9, 11, 18, 20, 21, 25, 30, 32, 33, 36, 38, 42]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 12056046,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "82fa8d73891ce6476d58f11d6e3b563af21d0a3a",
            "isKey": false,
            "numCitedBy": 347,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we present a system that integrates fully automatic scene geometry estimation, 2D object detection, 3D localization, trajectory estimation, and tracking for dynamic scene interpretation from a moving vehicle. Our sole input are two video streams from a calibrated stereo rig on top of a car. From these streams, we estimate structure-from-motion (SfM) and scene geometry in real-time. In parallel, we perform multi-view/multi-category object recognition to detect cars and pedestrians in both camera images. Using the SfM self-localization, 2D object detections are converted to 3D observations, which are accumulated in a world coordinate frame. A subsequent tracking module analyzes the resulting 3D observations to find physically plausible spacetime trajectories. Finally, a global optimization criterion takes object-object interactions into account to arrive at accurate 3D localization and trajectory estimates for both cars and pedestrians. We demonstrate the performance of our integrated system on challenging real-world data showing car passages through crowded city areas."
            },
            "slug": "Dynamic-3D-Scene-Analysis-from-a-Moving-Vehicle-Leibe-Cornelis",
            "title": {
                "fragments": [],
                "text": "Dynamic 3D Scene Analysis from a Moving Vehicle"
            },
            "tldr": {
                "abstractSimilarityScore": 74,
                "text": "A system that integrates fully automatic scene geometry estimation, 2D object detection, 3D localization, trajectory estimation, and tracking for dynamic scene interpretation from a moving vehicle and demonstrates the performance of this integrated system on challenging real-world data showing car passages through crowded city areas."
            },
            "venue": {
                "fragments": [],
                "text": "2007 IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145030811"
                        ],
                        "name": "C. Papageorgiou",
                        "slug": "C.-Papageorgiou",
                        "structuredName": {
                            "firstName": "Constantine",
                            "lastName": "Papageorgiou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Papageorgiou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685292"
                        ],
                        "name": "T. Poggio",
                        "slug": "T.-Poggio",
                        "structuredName": {
                            "firstName": "Tomaso",
                            "lastName": "Poggio",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Poggio"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 7,
                                "start": 3
                            }
                        ],
                        "text": "MIT[27] 924 \u2013 \u2013 \u2013 \u2013 \u2013 128 128 128 3 USC-A[43] \u2013 \u2013 \u2013 313 \u2013 205 70 98 133 3 USC-B[43] \u2013 \u2013 \u2013 271 \u2013 54 63 90 126 3 USC-C[44] \u2013 \u2013 \u2013 232 \u2013 100 74 108 145 3 3 CVC[14] 1000 6175\u2020 \u2013 \u2013 \u2013 \u2013 46 83 164 3 3 TUD-det[1] 400 \u2013 400 311 \u2013 250 133 218 278 3 3 INRIA[5] 1208 1218 614 566 453 288 139 279 456 3 DC[24] 2."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 63,
                                "start": 60
                            }
                        ],
                        "text": "The most widely used \u2018person\u2019 datasets include subsets of the MIT LabelMe data [29] and the PASCAL VOC datasets [28]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 91,
                                "start": 60
                            }
                        ],
                        "text": "Detecting people in images is a problem with a long history [37, 13, 35, 27, 16, 41, 23, 5]; in the past two years there has been a surge of interest in pedestrian detection [6, 9, 11, 18, 20, 21, 25, 30, 32, 33, 36, 38, 42]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 13308232,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e6c20ed0c3f375f403ab5d750a6e9699d5c3af6a",
            "isKey": false,
            "numCitedBy": 1404,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a general, trainable system for object detection in unconstrained, cluttered scenes. The system derives much of its power from a representation that describes an object class in terms of an overcomplete dictionary of local, oriented, multiscale intensity differences between adjacent regions, efficiently computable as a Haar wavelet transform. This example-based learning approach implicitly derives a model of an object class by training a support vector machine classifier using a large set of positive and negative examples. We present results on face, people, and car detection tasks using the same architecture. In addition, we quantify how the representation affects detection performance by considering several alternate representations including pixels and principal components. We also describe a real-time application of our person detection system as part of a driver assistance system."
            },
            "slug": "A-Trainable-System-for-Object-Detection-Papageorgiou-Poggio",
            "title": {
                "fragments": [],
                "text": "A Trainable System for Object Detection"
            },
            "tldr": {
                "abstractSimilarityScore": 92,
                "text": "A general, trainable system for object detection in unconstrained, cluttered scenes that derives much of its power from a representation that describes an object class in terms of an overcomplete dictionary of local, oriented, multiscale intensity differences between adjacent regions, efficiently computable as a Haar wavelet transform."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144854796"
                        ],
                        "name": "D. Gavrila",
                        "slug": "D.-Gavrila",
                        "structuredName": {
                            "firstName": "Dariu",
                            "lastName": "Gavrila",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Gavrila"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1762260"
                        ],
                        "name": "V. Philomin",
                        "slug": "V.-Philomin",
                        "structuredName": {
                            "firstName": "Vasanth",
                            "lastName": "Philomin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Philomin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 91,
                                "start": 60
                            }
                        ],
                        "text": "Detecting people in images is a problem with a long history [37, 13, 35, 27, 16, 41, 23, 5]; in the past two years there has been a surge of interest in pedestrian detection [6, 9, 11, 18, 20, 21, 25, 30, 32, 33, 36, 38, 42]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 766556,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bb490d879512b3d43b267e3ac8931c099a5a2fd3",
            "isKey": false,
            "numCitedBy": 760,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents an efficient shape-based object detection method based on Distance Transforms and describes its use for real-time vision on-board vehicles. The method uses a template hierarchy to capture the variety of object shapes; efficient hierarchies can be generated offline for given shape distributions using stochastic optimization techniques (i.e. simulated annealing). Online, matching involves a simultaneous coarse-to-fine approach over the shape hierarchy and over the transformation parameters. Very large speed-up factors are typically obtained when comparing this approach with the equivalent brute-force formulation; we have measured gains of several orders of magnitudes. We present experimental results on the real-time detection of traffic signs and pedestrians from a moving vehicle. Because of the highly time sensitive nature of these vision tasks, we also discuss some hardware-specific implementations of the proposed method as far as SIMD parallelism is concerned."
            },
            "slug": "Real-time-object-detection-for-\"smart\"-vehicles-Gavrila-Philomin",
            "title": {
                "fragments": [],
                "text": "Real-time object detection for \"smart\" vehicles"
            },
            "tldr": {
                "abstractSimilarityScore": 67,
                "text": "An efficient shape-based object detection method based on Distance Transforms is presented and its use for real-time vision on-board vehicles and some hardware-specific implementations of the proposed method as far as SIMD parallelism is concerned are discussed."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Seventh IEEE International Conference on Computer Vision"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3127283"
                        ],
                        "name": "Piotr Doll\u00e1r",
                        "slug": "Piotr-Doll\u00e1r",
                        "structuredName": {
                            "firstName": "Piotr",
                            "lastName": "Doll\u00e1r",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Piotr Doll\u00e1r"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2490700"
                        ],
                        "name": "Boris Babenko",
                        "slug": "Boris-Babenko",
                        "structuredName": {
                            "firstName": "Boris",
                            "lastName": "Babenko",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Boris Babenko"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50172592"
                        ],
                        "name": "Serge J. Belongie",
                        "slug": "Serge-J.-Belongie",
                        "structuredName": {
                            "firstName": "Serge",
                            "lastName": "Belongie",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Serge J. Belongie"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1690922"
                        ],
                        "name": "P. Perona",
                        "slug": "P.-Perona",
                        "structuredName": {
                            "firstName": "Pietro",
                            "lastName": "Perona",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Perona"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144035504"
                        ],
                        "name": "Z. Tu",
                        "slug": "Z.-Tu",
                        "structuredName": {
                            "firstName": "Zhuowen",
                            "lastName": "Tu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Z. Tu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 44,
                                "start": 37
                            }
                        ],
                        "text": "Discriminative part-based approaches [6, 11] may also provide more robustness to occlusion, although those may be ill-suited for low resolution pedestrians."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 224,
                                "start": 174
                            }
                        ],
                        "text": "Detecting people in images is a problem with a long history [37, 13, 35, 27, 16, 41, 23, 5]; in the past two years there has been a surge of interest in pedestrian detection [6, 9, 11, 18, 20, 21, 25, 30, 32, 33, 36, 38, 42]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 341776,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6b1a05759f570f13ebdc5ea7f7a957e41f43203d",
            "isKey": false,
            "numCitedBy": 154,
            "numCiting": 47,
            "paperAbstract": {
                "fragments": [],
                "text": "Object detection is one of the key problems in computer vision. In the last decade, discriminative learning approaches have proven effective in detecting rigid objects, achieving very low false positives rates. The field has also seen a resurgence of part-based recognition methods, with impressive results on highly articulated, diverse object categories. In this paper we propose a discriminative learning approach for detection that is inspired by part-based recognition approaches. Our method, Multiple Component Learning (mcl), automatically learns individual component classifiers and combines these into an overall classifier. Unlike previous methods, which rely on either fairly restricted part models or labeled part data, mcl learns powerful component classifiers in a weakly supervised manner, where object labels are provided but part labels are not. The basis of mcl lies in learning a set classifier; we achieve this by combining boosting with weakly supervised learning, specifically the Multiple Instance Learning framework (mil). mcl is general, and we demonstrate results on a range of data from computer audition and computer vision. In particular, mcl outperforms all existing methods on the challenging INRIA pedestrian detection dataset, and unlike methods that are not part-based, mcl is quite robust to occlusions."
            },
            "slug": "Multiple-Component-Learning-for-Object-Detection-Doll\u00e1r-Babenko",
            "title": {
                "fragments": [],
                "text": "Multiple Component Learning for Object Detection"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "The method, Multiple Component Learning (mcl), automatically learns individual component classifiers and combines these into an overall classifier, and unlike methods that are not part-based, mcl is quite robust to occlusions."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145527707"
                        ],
                        "name": "Zhe L. Lin",
                        "slug": "Zhe-L.-Lin",
                        "structuredName": {
                            "firstName": "Zhe",
                            "lastName": "Lin",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zhe L. Lin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1693428"
                        ],
                        "name": "L. Davis",
                        "slug": "L.-Davis",
                        "structuredName": {
                            "firstName": "Larry",
                            "lastName": "Davis",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Davis"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 224,
                                "start": 174
                            }
                        ],
                        "text": "Detecting people in images is a problem with a long history [37, 13, 35, 27, 16, 41, 23, 5]; in the past two years there has been a surge of interest in pedestrian detection [6, 9, 11, 18, 20, 21, 25, 30, 32, 33, 36, 38, 42]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14506749,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "40a4e30c2eca4de538d6ac39db48b2f04027ba6c",
            "isKey": false,
            "numCitedBy": 170,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a learning-based, sliding window-style approach for the problem of detecting humans in still images. Instead of traditional concatenation-style image location-based feature encoding, a global descriptor more invariant to pose variation is introduced. Specifically, we propose a principled approach to learning and classifying human/non-human image patterns by simultaneously segmenting human shapes and poses, and extracting articulation-insensitive features. The shapes and poses are segmented by an efficient, probabilistic hierarchical part-template matching algorithm, and the features are collected in the context of poses by tracing around the estimated shape boundaries. Histograms of oriented gradients are used as a source of low-level features from which our pose-invariant descriptors are computed, and kernel SVMs are adopted as the test classifiers. We evaluate our detection and segmentation approach on two public pedestrian datasets."
            },
            "slug": "A-Pose-Invariant-Descriptor-for-Human-Detection-and-Lin-Davis",
            "title": {
                "fragments": [],
                "text": "A Pose-Invariant Descriptor for Human Detection and Segmentation"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "This work proposes a principled approach to learning and classifying human/non-human image patterns by simultaneously segmenting human shapes and poses, and extracting articulation-insensitive features."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3140335"
                        ],
                        "name": "A. Shashua",
                        "slug": "A.-Shashua",
                        "structuredName": {
                            "firstName": "Amnon",
                            "lastName": "Shashua",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Shashua"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1915667"
                        ],
                        "name": "Y. Gdalyahu",
                        "slug": "Y.-Gdalyahu",
                        "structuredName": {
                            "firstName": "Yoram",
                            "lastName": "Gdalyahu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Gdalyahu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2079194"
                        ],
                        "name": "G. Hayun",
                        "slug": "G.-Hayun",
                        "structuredName": {
                            "firstName": "Gaby",
                            "lastName": "Hayun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Hayun"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 36,
                                "start": 24
                            }
                        ],
                        "text": "Automotive applications [12, 14, 34] are particularly compelling as they have the potential to save numerous lives [39]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14981509,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "37a15ce03c26ec83d95bf4aaf756a41370d50353",
            "isKey": false,
            "numCitedBy": 404,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe the functional and architectural breakdown of a monocular pedestrian detection system. We describe in detail our approach for single-frame classification based on a novel scheme of breaking down the class variability by repeatedly training a set of relatively simple classifiers on clusters of the training set. Single-frame classification performance results and system level performance figures for daytime conditions are presented with a discussion about the remaining gap to meet a daytime normal weather condition production system."
            },
            "slug": "Pedestrian-detection-for-driving-assistance-and-Shashua-Gdalyahu",
            "title": {
                "fragments": [],
                "text": "Pedestrian detection for driving assistance systems: single-frame classification and system level performance"
            },
            "tldr": {
                "abstractSimilarityScore": 93,
                "text": "The functional and architectural breakdown of a monocular pedestrian detection system is described and the approach for single-frame classification based on a novel scheme of breaking down the class variability by repeatedly training a set of relatively simple classifiers on clusters of the training set is described."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Intelligent Vehicles Symposium, 2004"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1789756"
                        ],
                        "name": "B. Leibe",
                        "slug": "B.-Leibe",
                        "structuredName": {
                            "firstName": "B.",
                            "lastName": "Leibe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Leibe"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1732672"
                        ],
                        "name": "A. Leonardis",
                        "slug": "A.-Leonardis",
                        "structuredName": {
                            "firstName": "Ale\u0161",
                            "lastName": "Leonardis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Leonardis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48920094"
                        ],
                        "name": "B. Schiele",
                        "slug": "B.-Schiele",
                        "structuredName": {
                            "firstName": "Bernt",
                            "lastName": "Schiele",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Schiele"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 74,
                                "start": 66
                            }
                        ],
                        "text": "Of course, not all detection systems are based on sliding windows [19, 17], and per-window evaluation of such systems is impossible."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14144539,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1c41c1f86b92a8c011e0324d90624d539a849b8b",
            "isKey": false,
            "numCitedBy": 1060,
            "numCiting": 95,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract\nThis paper presents a novel method for detecting and localizing objects of a visual category in cluttered real-world scenes. Our approach considers object categorization and figure-ground segmentation as two interleaved processes that closely collaborate towards a common goal. As shown in our work, the tight coupling between those two processes allows them to benefit from each other and improve the combined performance.\n\nThe core part of our approach is a highly flexible learned representation for object shape that can combine the information observed on different training examples in a probabilistic extension of the Generalized Hough Transform. The resulting approach can detect categorical objects in novel images and automatically infer a probabilistic segmentation from the recognition result. This segmentation is then in turn used to again improve recognition by allowing the system to focus its efforts on object pixels and to discard misleading influences from the background. Moreover, the information from where in the image a hypothesis draws its support is employed in an MDL based hypothesis verification stage to resolve ambiguities between overlapping hypotheses and factor out the effects of partial occlusion.\n\nAn extensive evaluation on several large data sets shows that the proposed system is applicable to a range of different object categories, including both rigid and articulated objects. In addition, its flexible representation allows it to achieve competitive object detection performance already from training sets that are between one and two orders of magnitude smaller than those used in comparable systems.\n"
            },
            "slug": "Robust-Object-Detection-with-Interleaved-and-Leibe-Leonardis",
            "title": {
                "fragments": [],
                "text": "Robust Object Detection with Interleaved Categorization and Segmentation"
            },
            "tldr": {
                "abstractSimilarityScore": 57,
                "text": "A novel method for detecting and localizing objects of a visual category in cluttered real-world scenes that is applicable to a range of different object categories, including both rigid and articulated objects and able to achieve competitive object detection performance from training sets that are between one and two orders of magnitude smaller than those used in comparable systems."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2340109"
                        ],
                        "name": "C. Wojek",
                        "slug": "C.-Wojek",
                        "structuredName": {
                            "firstName": "Christian",
                            "lastName": "Wojek",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Wojek"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48920094"
                        ],
                        "name": "B. Schiele",
                        "slug": "B.-Schiele",
                        "structuredName": {
                            "firstName": "Bernt",
                            "lastName": "Schiele",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Schiele"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 60,
                                "start": 34
                            }
                        ],
                        "text": "(3) We benchmark seven algorithms [40, 5, 7, 30, 11, 42, 21], either obtained directly from the original authors or reimplemented in-house."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 8,
                                "start": 0
                            }
                        ],
                        "text": "MultiFtr ties or outperforms HOG on more difficult cases (smaller scales, occlusion, atypical aspect ratios), and as these comprise the bulk of the dataset MultiFtr achieves a slightly higher overall performance."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 19,
                                "start": 15
                            }
                        ],
                        "text": "05 \u201907 MultiFtr[42] HOG+Haar AdaBoost 3 3 3 18."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 142,
                                "start": 134
                            }
                        ],
                        "text": "Performance drops significantly even under partial occlusion, leading to a maximum recall of slightly under 30% at 1 FPPI achieved by MultiFtr."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 22,
                                "start": 14
                            }
                        ],
                        "text": "Summary: HOG, MultiFtr and FtrMine tend to outperform the other methods surveyed."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 195,
                                "start": 187
                            }
                        ],
                        "text": "Performs clearly degrades for atypical aspect ratios, from a maximum recall of about 56% at 1 FPPI on typical aspect ratios, achieved by HOG, to about 40% recall achieved by both HOG and MultiFtr."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 8,
                                "start": 0
                            }
                        ],
                        "text": "MultiFtr outperforms the remaining methods, with HOG as a close second."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 224,
                                "start": 174
                            }
                        ],
                        "text": "Detecting people in images is a problem with a long history [37, 13, 35, 27, 16, 41, 23, 5]; in the past two years there has been a surge of interest in pedestrian detection [6, 9, 11, 18, 20, 21, 25, 30, 32, 33, 36, 38, 42]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 142,
                                "start": 138
                            }
                        ],
                        "text": "We obtained the detectors directly from their authors, the only exceptions were the VJ and Shapelet detectors which were reimplemented in [42] (these outperform the OpenCV VJ code and the original Shapelet code, respectively, see Fig."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 83,
                                "start": 75
                            }
                        ],
                        "text": "At the medium scale, which contains over 68% of the annotated pedestrians, MultiFtr achieves the best relative performance but absolute performance is quite poor with 72% miss rate at 1 FPPI."
                    },
                    "intents": []
                }
            ],
            "corpusId": 39046756,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3e6fa6cf1fe2e23fdf7716f89b160333c7a93b26",
            "isKey": false,
            "numCitedBy": 266,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "Over the years a number of powerful people detectors have been proposed. While it is standard to test complete detectors on publicly available datasets, it is often unclear how the different components (e.g. features and classifiers) of the respective detectors compare. Therefore, this paper contributes a systematic comparison of the most prominent and successful people detectors. Based on this evaluation we also propose a new detector that outperforms the state-of-art on the INRIA person dataset by combining multiple features."
            },
            "slug": "A-Performance-Evaluation-of-Single-and-People-Wojek-Schiele",
            "title": {
                "fragments": [],
                "text": "A Performance Evaluation of Single and Multi-feature People Detection"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "A systematic comparison of the most prominent and successful people detectors is contributed and a new detector is proposed that outperforms the state-of-art on the INRIA person dataset by combining multiple features."
            },
            "venue": {
                "fragments": [],
                "text": "DAGM-Symposium"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2054165706"
                        ],
                        "name": "S. Ioffe",
                        "slug": "S.-Ioffe",
                        "structuredName": {
                            "firstName": "Sergey",
                            "lastName": "Ioffe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Ioffe"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144016256"
                        ],
                        "name": "D. Forsyth",
                        "slug": "D.-Forsyth",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Forsyth",
                            "middleNames": [
                                "Alexander"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Forsyth"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 91,
                                "start": 60
                            }
                        ],
                        "text": "Detecting people in images is a problem with a long history [37, 13, 35, 27, 16, 41, 23, 5]; in the past two years there has been a surge of interest in pedestrian detection [6, 9, 11, 18, 20, 21, 25, 30, 32, 33, 36, 38, 42]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14097182,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "31635ba161c6cea677f87a88d9874e5506819207",
            "isKey": false,
            "numCitedBy": 257,
            "numCiting": 57,
            "paperAbstract": {
                "fragments": [],
                "text": "Finding people in pictures presents a particularly difficult object recognition problem. We show how to find people by finding candidate body segments, and then constructing assemblies of segments that are consistent with the constraints on the appearance of a person that result from kinematic properties. Since a reasonable model of a person requires at least nine segments, it is not possible to inspect every group, due to the huge combinatorial complexity.We propose two approaches to this problem. In one, the search can be pruned by using projected versions of a classifier that accepts groups corresponding to people. We describe an efficient projection algorithm for one popular classifier, and demonstrate that our approach can be used to determine whether images of real scenes contain people.The second approach employs a probabilistic framework, so that we can draw samples of assemblies, with probabilities proportional to their likelihood, which allows to draw human-like assemblies more often than the non-person ones. The main performance problem is in segmentation of images, but the overall results of both approaches on real images of people are encouraging."
            },
            "slug": "Probabilistic-Methods-for-Finding-People-Ioffe-Forsyth",
            "title": {
                "fragments": [],
                "text": "Probabilistic Methods for Finding People"
            },
            "tldr": {
                "abstractSimilarityScore": 70,
                "text": "This work shows how to find people by finding candidate body segments, and then constructing assemblies of segments that are consistent with the constraints on the appearance of a person that result from kinematic properties, using an efficient projection algorithm for one popular classifier."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143847264"
                        ],
                        "name": "Bo Wu",
                        "slug": "Bo-Wu",
                        "structuredName": {
                            "firstName": "Bo",
                            "lastName": "Wu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bo Wu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144862593"
                        ],
                        "name": "R. Nevatia",
                        "slug": "R.-Nevatia",
                        "structuredName": {
                            "firstName": "Ramakant",
                            "lastName": "Nevatia",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Nevatia"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 120,
                                "start": 116
                            }
                        ],
                        "text": "MIT[27] 924 \u2013 \u2013 \u2013 \u2013 \u2013 128 128 128 3 USC-A[43] \u2013 \u2013 \u2013 313 \u2013 205 70 98 133 3 USC-B[43] \u2013 \u2013 \u2013 271 \u2013 54 63 90 126 3 USC-C[44] \u2013 \u2013 \u2013 232 \u2013 100 74 108 145 3 3 CVC[14] 1000 6175\u2020 \u2013 \u2013 \u2013 \u2013 46 83 164 3 3 TUD-det[1] 400 \u2013 400 311 \u2013 250 133 218 278 3 3 INRIA[5] 1208 1218 614 566 453 288 139 279 456 3 DC[24] 2."
                    },
                    "intents": []
                }
            ],
            "corpusId": 6687662,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "44be974c7f765155980312d8bad4383a67417f89",
            "isKey": false,
            "numCitedBy": 214,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "Detection of object of a known class is a fundamental problem of computer vision. The appearance of objects can change greatly due to illumination, view point, and articulation. For object classes with large intra-class variation, some divide-and-conquer strategy is necessary. Tree structured classifier models have been used for multi-view multi- pose object detection in previous work. This paper proposes a boosting based learning method, called Cluster Boosted Tree (CBT), to automatically construct tree structured object detectors. Instead of using predefined intra-class sub- categorization based on domain knowledge, we divide the sample space by unsupervised clustering based on discriminative image features selected by boosting algorithm. The sub-categorization information of the leaf nodes is sent back to refine their ancestors' classification functions. We compare our approach with previous related methods on several public data sets. The results show that our approach outperforms the state-of-the-art methods."
            },
            "slug": "Cluster-Boosted-Tree-Classifier-for-Multi-View,-Wu-Nevatia",
            "title": {
                "fragments": [],
                "text": "Cluster Boosted Tree Classifier for Multi-View, Multi-Pose Object Detection"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "This paper proposes a boosting based learning method, called Cluster Boosted Tree (CBT), to automatically construct tree structured object detectors, and shows that this approach outperforms the state-of-the-art methods."
            },
            "venue": {
                "fragments": [],
                "text": "2007 IEEE 11th International Conference on Computer Vision"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1787591"
                        ],
                        "name": "Christoph H. Lampert",
                        "slug": "Christoph-H.-Lampert",
                        "structuredName": {
                            "firstName": "Christoph",
                            "lastName": "Lampert",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christoph H. Lampert"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1758219"
                        ],
                        "name": "Matthew B. Blaschko",
                        "slug": "Matthew-B.-Blaschko",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Blaschko",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Matthew B. Blaschko"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143936663"
                        ],
                        "name": "Thomas Hofmann",
                        "slug": "Thomas-Hofmann",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Hofmann",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thomas Hofmann"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 74,
                                "start": 66
                            }
                        ],
                        "text": "Of course, not all detection systems are based on sliding windows [19, 17], and per-window evaluation of such systems is impossible."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6131848,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "54b224478a63e33441c651175c522f3702062fc4",
            "isKey": false,
            "numCitedBy": 800,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "Most successful object recognition systems rely on binary classification, deciding only if an object is present or not, but not providing information on the actual object location. To perform localization, one can take a sliding window approach, but this strongly increases the computational cost, because the classifier function has to be evaluated over a large set of candidate subwindows. In this paper, we propose a simple yet powerful branch-and-bound scheme that allows efficient maximization of a large class of classifier functions over all possible subimages. It converges to a globally optimal solution typically in sublinear time. We show how our method is applicable to different object detection and retrieval scenarios. The achieved speedup allows the use of classifiers for localization that formerly were considered too slow for this task, such as SVMs with a spatial pyramid kernel or nearest neighbor classifiers based on the chi2-distance. We demonstrate state-of-the-art performance of the resulting systems on the UIUC Cars dataset, the PASCAL VOC 2006 dataset and in the PASCAL VOC 2007 competition."
            },
            "slug": "Beyond-sliding-windows:-Object-localization-by-Lampert-Blaschko",
            "title": {
                "fragments": [],
                "text": "Beyond sliding windows: Object localization by efficient subwindow search"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "A simple yet powerful branch-and-bound scheme that allows efficient maximization of a large class of classifier functions over all possible subimages and converges to a globally optimal solution typically in sublinear time is proposed."
            },
            "venue": {
                "fragments": [],
                "text": "2008 IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145160921"
                        ],
                        "name": "Bryan C. Russell",
                        "slug": "Bryan-C.-Russell",
                        "structuredName": {
                            "firstName": "Bryan",
                            "lastName": "Russell",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bryan C. Russell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143805211"
                        ],
                        "name": "A. Torralba",
                        "slug": "A.-Torralba",
                        "structuredName": {
                            "firstName": "Antonio",
                            "lastName": "Torralba",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Torralba"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2056417995"
                        ],
                        "name": "K. Murphy",
                        "slug": "K.-Murphy",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Murphy",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Murphy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1768236"
                        ],
                        "name": "W. Freeman",
                        "slug": "W.-Freeman",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Freeman",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Freeman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 83,
                                "start": 79
                            }
                        ],
                        "text": "The most widely used \u2018person\u2019 datasets include subsets of the MIT LabelMe data [29] and the PASCAL VOC datasets [28]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1900911,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "092c275005ae49dc1303214f6d02d134457c7053",
            "isKey": false,
            "numCitedBy": 3076,
            "numCiting": 82,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract\nWe seek to build a large collection of images with ground truth labels to be used for object detection and recognition research. Such data is useful for supervised learning and quantitative evaluation. To achieve this, we developed a web-based tool that allows easy image annotation and instant sharing of such annotations. Using this annotation tool, we have collected a large dataset that spans many object categories, often containing multiple instances over a wide variety of images. We quantify the contents of the dataset and compare against existing state of the art datasets used for object recognition and detection. Also, we show how to extend the dataset to automatically enhance object labels with WordNet, discover object parts, recover a depth ordering of objects in a scene, and increase the number of labels using minimal user supervision and images from the web.\n"
            },
            "slug": "LabelMe:-A-Database-and-Web-Based-Tool-for-Image-Russell-Torralba",
            "title": {
                "fragments": [],
                "text": "LabelMe: A Database and Web-Based Tool for Image Annotation"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A web-based tool that allows easy image annotation and instant sharing of such annotations is developed and a large dataset that spans many object categories, often containing multiple instances over a wide variety of images is collected."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2156107703"
                        ],
                        "name": "Hua Yang",
                        "slug": "Hua-Yang",
                        "structuredName": {
                            "firstName": "Hua",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hua Yang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1742208"
                        ],
                        "name": "M. Pollefeys",
                        "slug": "M.-Pollefeys",
                        "structuredName": {
                            "firstName": "Marc",
                            "lastName": "Pollefeys",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Pollefeys"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145715427"
                        ],
                        "name": "G. Welch",
                        "slug": "G.-Welch",
                        "structuredName": {
                            "firstName": "Greg",
                            "lastName": "Welch",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Welch"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40454588"
                        ],
                        "name": "Jan-Michael Frahm",
                        "slug": "Jan-Michael-Frahm",
                        "structuredName": {
                            "firstName": "Jan-Michael",
                            "lastName": "Frahm",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jan-Michael Frahm"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2044671"
                        ],
                        "name": "A. Ilie",
                        "slug": "A.-Ilie",
                        "structuredName": {
                            "firstName": "Adrian",
                            "lastName": "Ilie",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Ilie"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 112,
                                "start": 108
                            }
                        ],
                        "text": "To perform the stabilization, we implemented a differential camera tracker based on the system described in [45]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 12506269,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "5875ddf4b65534b26cb3b5e564d9183567672f6e",
            "isKey": false,
            "numCitedBy": 15,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "The appearance of a scene is a function of the scene contents, the lighting, and the camera pose. A set of n-pixel images of a non-degenerate scene captured from different perspectives lie on a 6D nonlinear manifold in Rn. In general, this nonlinear manifold is complicated and numerous samples are required to learn it globally. In this paper, we present a novel method and some preliminary results for incrementally tracking camera motion through sampling and linearizing the local appearance manifold. At each frame time, we use a cluster of calibrated and synchronized small baseline cameras to capture scene appearance samples at different camera poses. We compute a first-order approximation of the appearance manifold around the current camera pose. Then, as new cluster samples are captured at the next frame time, we estimate the incremental camera motion using a linear solver. By using intensity measurements and directly sampling the appearance manifold, our method avoids the commonly-used feature extraction and matching processes, and does not require 3D correspondences across frames. Thus it can be used for scenes with complicated surface materials, geometries, and view-dependent appearance properties, situations where many other camera tracking methods would fail."
            },
            "slug": "Differential-Camera-Tracking-through-Linearizing-Yang-Pollefeys",
            "title": {
                "fragments": [],
                "text": "Differential Camera Tracking through Linearizing the Local Appearance Manifold"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A novel method that avoids the commonly-used feature extraction and matching processes, and does not require 3D correspondences across frames, can be used for scenes with complicated surface materials, geometries, and view-dependent appearance properties, situations where many other camera tracking methods would fail."
            },
            "venue": {
                "fragments": [],
                "text": "2007 IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144891282"
                        ],
                        "name": "David R. Martin",
                        "slug": "David-R.-Martin",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Martin",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David R. Martin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143800213"
                        ],
                        "name": "Charless C. Fowlkes",
                        "slug": "Charless-C.-Fowlkes",
                        "structuredName": {
                            "firstName": "Charless",
                            "lastName": "Fowlkes",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Charless C. Fowlkes"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143751119"
                        ],
                        "name": "Jitendra Malik",
                        "slug": "Jitendra-Malik",
                        "structuredName": {
                            "firstName": "Jitendra",
                            "lastName": "Malik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jitendra Malik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 33,
                                "start": 4
                            }
                        ],
                        "text": "The Berkeley Segmentation Dataset [22], the Barron et al. [3] and Middlebury [2] optical flow datasets, the Middlebury Stereo Dataset [31] and the Caltech 101 object categorization dataset [10] all improved performance evaluation and helped drive innovation in their respective fields."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 38,
                                "start": 34
                            }
                        ],
                        "text": "The Berkeley Segmentation Dataset [22], the Barron et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 8165754,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "33a7a59f785ef46091c30c4c85ef88c6bdabab51",
            "isKey": false,
            "numCitedBy": 2381,
            "numCiting": 50,
            "paperAbstract": {
                "fragments": [],
                "text": "The goal of this work is to accurately detect and localize boundaries in natural scenes using local image measurements. We formulate features that respond to characteristic changes in brightness, color, and texture associated with natural boundaries. In order to combine the information from these features in an optimal way, we train a classifier using human labeled images as ground truth. The output of this classifier provides the posterior probability of a boundary at each image location and orientation. We present precision-recall curves showing that the resulting detector significantly outperforms existing approaches. Our two main results are 1) that cue combination can be performed adequately with a simple linear model and 2) that a proper, explicit treatment of texture is required to detect boundaries in natural images."
            },
            "slug": "Learning-to-detect-natural-image-boundaries-using-Martin-Fowlkes",
            "title": {
                "fragments": [],
                "text": "Learning to detect natural image boundaries using local brightness, color, and texture cues"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The two main results are that cue combination can be performed adequately with a simple linear model and that a proper, explicit treatment of texture is required to detect boundaries in natural images."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3127283"
                        ],
                        "name": "Piotr Doll\u00e1r",
                        "slug": "Piotr-Doll\u00e1r",
                        "structuredName": {
                            "firstName": "Piotr",
                            "lastName": "Doll\u00e1r",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Piotr Doll\u00e1r"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144035504"
                        ],
                        "name": "Z. Tu",
                        "slug": "Z.-Tu",
                        "structuredName": {
                            "firstName": "Zhuowen",
                            "lastName": "Tu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Z. Tu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145492205"
                        ],
                        "name": "Hai Tao",
                        "slug": "Hai-Tao",
                        "structuredName": {
                            "firstName": "Hai",
                            "lastName": "Tao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hai Tao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50172592"
                        ],
                        "name": "Serge J. Belongie",
                        "slug": "Serge-J.-Belongie",
                        "structuredName": {
                            "firstName": "Serge",
                            "lastName": "Belongie",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Serge J. Belongie"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 60,
                                "start": 34
                            }
                        ],
                        "text": "(3) We benchmark seven algorithms [40, 5, 7, 30, 11, 42, 21], either obtained directly from the original authors or reimplemented in-house."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 8961509,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "69deed411eeff65cc0cba9e7db94ac337322089b",
            "isKey": false,
            "numCitedBy": 226,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "The efficiency and robustness of a vision system is often largely determined by the quality of the image features available to it. In data mining, one typically works with immense volumes of raw data, which demands effective algorithms to explore the data space. In analogy to data mining, the space of meaningful features for image analysis is also quite vast. Recently, the challenges associated with these problem areas have become more tractable through progress made in machine learning and concerted research effort in manual feature design by domain experts. In this paper, we propose a feature mining paradigm for image classification and examine several feature mining strategies. We also derive a principled approach for dealing with features with varying computational demands. Our goal is to alleviate the burden of manual feature design, which is a key problem in computer vision and machine learning. We include an in-depth empirical study on three typical data sets and offer theoretical explanations for the performance of various feature mining strategies. As a final confirmation of our ideas, we show results of a system, that utilizing feature mining strategies matches or outperforms the best reported results on pedestrian classification (where considerable effort has been devoted to expert feature design)."
            },
            "slug": "Feature-Mining-for-Image-Classification-Doll\u00e1r-Tu",
            "title": {
                "fragments": [],
                "text": "Feature Mining for Image Classification"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A feature mining paradigm for image classification is proposed and several feature mining strategies are examined to alleviate the burden of manual feature design, which is a key problem in computer vision and machine learning."
            },
            "venue": {
                "fragments": [],
                "text": "2007 IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685089"
                        ],
                        "name": "Pedro F. Felzenszwalb",
                        "slug": "Pedro-F.-Felzenszwalb",
                        "structuredName": {
                            "firstName": "Pedro",
                            "lastName": "Felzenszwalb",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Pedro F. Felzenszwalb"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145689002"
                        ],
                        "name": "David A. McAllester",
                        "slug": "David-A.-McAllester",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "McAllester",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David A. McAllester"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1770537"
                        ],
                        "name": "D. Ramanan",
                        "slug": "D.-Ramanan",
                        "structuredName": {
                            "firstName": "Deva",
                            "lastName": "Ramanan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Ramanan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 60,
                                "start": 34
                            }
                        ],
                        "text": "(3) We benchmark seven algorithms [40, 5, 7, 30, 11, 42, 21], either obtained directly from the original authors or reimplemented in-house."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 6,
                                "start": 0
                            }
                        ],
                        "text": "LatSvm likely suffers from being trained on the Pascal dataset, while results for HikSvm are artificially depressed since small people are not detected."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 44,
                                "start": 37
                            }
                        ],
                        "text": "Discriminative part-based approaches [6, 11] may also provide more robustness to occlusion, although those may be ill-suited for low resolution pedestrians."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 17,
                                "start": 13
                            }
                        ],
                        "text": "05 \u201908 LatSvm[11] HOG latent SVM 3 3 6."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 16,
                                "start": 10
                            }
                        ],
                        "text": "Note that LatSvm, which is part-based, degrades least."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 87,
                                "start": 81
                            }
                        ],
                        "text": "For unoccluded\nnear pedestrians, purely gradient based detectors such as HikSvm, LatSvm and especially HOG perform best, with a miss rate under 40% at 1 FPPI."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 224,
                                "start": 174
                            }
                        ],
                        "text": "Detecting people in images is a problem with a long history [37, 13, 35, 27, 16, 41, 23, 5]; in the past two years there has been a surge of interest in pedestrian detection [6, 9, 11, 18, 20, 21, 25, 30, 32, 33, 36, 38, 42]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14327585,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "860a9d55d87663ca88e74b3ca357396cd51733d0",
            "isKey": true,
            "numCitedBy": 2616,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes a discriminatively trained, multiscale, deformable part model for object detection. Our system achieves a two-fold improvement in average precision over the best performance in the 2006 PASCAL person detection challenge. It also outperforms the best results in the 2007 challenge in ten out of twenty categories. The system relies heavily on deformable parts. While deformable part models have become quite popular, their value had not been demonstrated on difficult benchmarks such as the PASCAL challenge. Our system also relies heavily on new methods for discriminative training. We combine a margin-sensitive approach for data mining hard negative examples with a formalism we call latent SVM. A latent SVM, like a hidden CRF, leads to a non-convex training problem. However, a latent SVM is semi-convex and the training problem becomes convex once latent information is specified for the positive examples. We believe that our training methods will eventually make possible the effective use of more latent information such as hierarchical (grammar) models and models involving latent three dimensional pose."
            },
            "slug": "A-discriminatively-trained,-multiscale,-deformable-Felzenszwalb-McAllester",
            "title": {
                "fragments": [],
                "text": "A discriminatively trained, multiscale, deformable part model"
            },
            "tldr": {
                "abstractSimilarityScore": 87,
                "text": "A discriminatively trained, multiscale, deformable part model for object detection, which achieves a two-fold improvement in average precision over the best performance in the 2006 PASCAL person detection challenge and outperforms the best results in the 2007 challenge in ten out of twenty categories."
            },
            "venue": {
                "fragments": [],
                "text": "2008 IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2433269"
                        ],
                        "name": "Derek Hoiem",
                        "slug": "Derek-Hoiem",
                        "structuredName": {
                            "firstName": "Derek",
                            "lastName": "Hoiem",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Derek Hoiem"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1763086"
                        ],
                        "name": "Alexei A. Efros",
                        "slug": "Alexei-A.-Efros",
                        "structuredName": {
                            "firstName": "Alexei",
                            "lastName": "Efros",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alexei A. Efros"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145670946"
                        ],
                        "name": "M. Hebert",
                        "slug": "M.-Hebert",
                        "structuredName": {
                            "firstName": "Martial",
                            "lastName": "Hebert",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Hebert"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 51,
                                "start": 44
                            }
                        ],
                        "text": "The first of these is context, both spatial [9, 15] and temporal [4]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6152006,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4081e007d7eced95cc618164e976a80d44ff5f4e",
            "isKey": false,
            "numCitedBy": 656,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "Image understanding requires not only individually estimating elements of the visual world but also capturing the interplay among them. In this paper, we provide a framework for placing local object detection in the context of the overall 3D scene by modeling the interdependence of objects, surface orientations, and camera viewpoint. Most object detection methods consider all scales and locations in the image as equally likely. We show that with probabilistic estimates of 3D geometry, both in terms of surfaces and world coordinates, we can put objects into perspective and model the scale and location variance in the image. Our approach reflects the cyclical nature of the problem by allowing probabilistic object hypotheses to refine geometry and vice-versa. Our framework allows painless substitution of almost any object detector and is easily extended to include other aspects of image understanding. Our results confirm the benefits of our integrated approach."
            },
            "slug": "Putting-Objects-in-Perspective-Hoiem-Efros",
            "title": {
                "fragments": [],
                "text": "Putting Objects in Perspective"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "This paper provides a framework for placing local object detection in the context of the overall 3D scene by modeling the interdependence of objects, surface orientations, and camera viewpoint by allowing probabilistic object hypotheses to refine geometry and vice-versa."
            },
            "venue": {
                "fragments": [],
                "text": "2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'06)"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1709053"
                        ],
                        "name": "Daniel Scharstein",
                        "slug": "Daniel-Scharstein",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Scharstein",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Daniel Scharstein"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1717841"
                        ],
                        "name": "R. Szeliski",
                        "slug": "R.-Szeliski",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Szeliski",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Szeliski"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 133,
                                "start": 108
                            }
                        ],
                        "text": "The Berkeley Segmentation Dataset [22], the Barron et al. [3] and Middlebury [2] optical flow datasets, the Middlebury Stereo Dataset [31] and the Caltech 101 object categorization dataset [10] all improved performance evaluation and helped drive innovation in their respective fields."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 80,
                                "start": 76
                            }
                        ],
                        "text": "[3] and Middlebury [2] optical flow datasets, the Middlebury Stereo Dataset [31] and the Caltech 101 object categorization dataset [10] all improved performance evaluation and helped drive innovation in their respective fields."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 195859047,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d2f78c2b2b325d72f359d4c797c9aab6a8e60942",
            "isKey": false,
            "numCitedBy": 3002,
            "numCiting": 65,
            "paperAbstract": {
                "fragments": [],
                "text": "Stereo matching is one of the most active research areas in computer vision. While a large number of algorithms for stereo correspondence have been developed, relatively little work has been done on characterizing their performance. In this paper, we present a taxonomy of dense, two-frame stereo methods. Our taxonomy is designed to assess the different components and design decisions made in individual stereo algorithms. Using this taxonomy, we compare existing stereo methods and present experiments evaluating the performance of many different variants. In order to establish a common software platform and a collection of data sets for easy evaluation, we have designed a stand-alone, flexible C++ implementation that enables the evaluation of individual components and that can easily be extended to include new algorithms. We have also produced several new multi-frame stereo data sets with ground truth and are making both the code and data sets available on the Web. Finally, we include a comparative evaluation of a large set of today's best-performing stereo algorithms."
            },
            "slug": "A-Taxonomy-and-Evaluation-of-Dense-Two-Frame-Stereo-Scharstein-Szeliski",
            "title": {
                "fragments": [],
                "text": "A taxonomy and evaluation of dense two-frame stereo correspondence algorithms"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "This paper has designed a stand-alone, flexible C++ implementation that enables the evaluation of individual components and that can easily be extended to include new algorithms."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings IEEE Workshop on Stereo and Multi-Baseline Vision (SMBV 2001)"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48004138"
                        ],
                        "name": "Li Fei-Fei",
                        "slug": "Li-Fei-Fei",
                        "structuredName": {
                            "firstName": "Li",
                            "lastName": "Fei-Fei",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Li Fei-Fei"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2276554"
                        ],
                        "name": "R. Fergus",
                        "slug": "R.-Fergus",
                        "structuredName": {
                            "firstName": "Rob",
                            "lastName": "Fergus",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Fergus"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1690922"
                        ],
                        "name": "P. Perona",
                        "slug": "P.-Perona",
                        "structuredName": {
                            "firstName": "Pietro",
                            "lastName": "Perona",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Perona"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 135,
                                "start": 131
                            }
                        ],
                        "text": "[3] and Middlebury [2] optical flow datasets, the Middlebury Stereo Dataset [31] and the Caltech 101 object categorization dataset [10] all improved performance evaluation and helped drive innovation in their respective fields."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6953475,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "812355cec91fa30bb50e9e992a3549af39e4f6eb",
            "isKey": false,
            "numCitedBy": 2365,
            "numCiting": 46,
            "paperAbstract": {
                "fragments": [],
                "text": "Learning visual models of object categories notoriously requires hundreds or thousands of training examples. We show that it is possible to learn much information about a category from just one, or a handful, of images. The key insight is that, rather than learning from scratch, one can take advantage of knowledge coming from previously learned categories, no matter how different these categories might be. We explore a Bayesian implementation of this idea. Object categories are represented by probabilistic models. Prior knowledge is represented as a probability density function on the parameters of these models. The posterior model for an object category is obtained by updating the prior in the light of one or more observations. We test a simple implementation of our algorithm on a database of 101 diverse object categories. We compare category models learned by an implementation of our Bayesian approach to models learned from by maximum likelihood (ML) and maximum a posteriori (MAP) methods. We find that on a database of more than 100 categories, the Bayesian approach produces informative models when the number of training examples is too small for other methods to operate successfully."
            },
            "slug": "One-shot-learning-of-object-categories-Fei-Fei-Fergus",
            "title": {
                "fragments": [],
                "text": "One-shot learning of object categories"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "It is found that on a database of more than 100 categories, the Bayesian approach produces informative models when the number of training examples is too small for other methods to operate successfully."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9394419"
                        ],
                        "name": "T. Tsukiyama",
                        "slug": "T.-Tsukiyama",
                        "structuredName": {
                            "firstName": "Toshifumi",
                            "lastName": "Tsukiyama",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Tsukiyama"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1700379"
                        ],
                        "name": "Y. Shirai",
                        "slug": "Y.-Shirai",
                        "structuredName": {
                            "firstName": "Yoshiaki",
                            "lastName": "Shirai",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Shirai"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 41410208,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "34cc9ec982f052302b9ee32160b2bf30a88010b7",
            "isKey": false,
            "numCitedBy": 43,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Detection-of-the-movements-of-persons-from-a-sparse-Tsukiyama-Shirai",
            "title": {
                "fragments": [],
                "text": "Detection of the movements of persons from a sparse sequence of TV images"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit."
            },
            "year": 1985
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "15808204"
                        ],
                        "name": "J. Barron",
                        "slug": "J.-Barron",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Barron",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Barron"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1793739"
                        ],
                        "name": "David J. Fleet",
                        "slug": "David-J.-Fleet",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Fleet",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David J. Fleet"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46818737"
                        ],
                        "name": "S. Beauchemin",
                        "slug": "S.-Beauchemin",
                        "structuredName": {
                            "firstName": "Steven",
                            "lastName": "Beauchemin",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Beauchemin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 3,
                                "start": 0
                            }
                        ],
                        "text": "[3] and Middlebury [2] optical flow datasets, the Middlebury Stereo Dataset [31] and the Caltech 101 object categorization dataset [10] all improved performance evaluation and helped drive innovation in their respective fields."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1290100,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "400f4afb2a055d95483d83c4bedab10281a8639d",
            "isKey": false,
            "numCitedBy": 4068,
            "numCiting": 125,
            "paperAbstract": {
                "fragments": [],
                "text": "While different optical flow techniques continue to appear, there has been a lack of quantitative evaluation of existing methods. For a common set of real and synthetic image sequences, we report the results of a number of regularly cited optical flow techniques, including instances of differential, matching, energy-based, and phase-based methods. Our comparisons are primarily empirical, and concentrate on the accuracy, reliability, and density of the velocity measurements; they show that performance can differ significantly among the techniques we implemented."
            },
            "slug": "Performance-of-optical-flow-techniques-Barron-Fleet",
            "title": {
                "fragments": [],
                "text": "Performance of optical flow techniques"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "These comparisons are primarily empirical, and concentrate on the accuracy, reliability, and density of the velocity measurements; they show that performance can differ significantly among the techniques the authors implemented."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2005
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 123,
                                "start": 119
                            }
                        ],
                        "text": "3, we discuss the pitfalls of per-window metrics and describe our evaluation methodology, based on the PASCAL criteria [28]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 50,
                                "start": 46
                            }
                        ],
                        "text": "For comparison, in the PASCAL labeling scheme [28] only the visible BB is labeled and occluded pedestrians are marked as \u2018truncated\u2019."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 137,
                                "start": 133
                            }
                        ],
                        "text": "this is the accepted methodology for the INRIA dataset [5], as opposed to the per-image measures frequently used in object detection [28]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 116,
                                "start": 112
                            }
                        ],
                        "text": "The most widely used \u2018person\u2019 datasets include subsets of the MIT LabelMe data [29] and the PASCAL VOC datasets [28]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 129,
                                "start": 125
                            }
                        ],
                        "text": "We perform single frame evaluation using a modified version of the scheme laid out in the PASCAL object detection challenges [28]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Dataset issues in object rec"
            },
            "venue": {
                "fragments": [],
                "text": "Towards Category-Level Object Rec., pages 29\u201348. Springer,"
            },
            "year": 2006
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 121,
                                "start": 118
                            }
                        ],
                        "text": "The per-window results, when available, are reproduced from the original publications (the VJ curve is extracted from [5])."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 58,
                                "start": 55
                            }
                        ],
                        "text": "this is the accepted methodology for the INRIA dataset [5], as opposed to the per-image measures frequently used in object detection [28]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 60,
                                "start": 34
                            }
                        ],
                        "text": "(3) We benchmark seven algorithms [40, 5, 7, 30, 11, 42, 21], either obtained directly from the original authors or reimplemented in-house."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 248,
                                "start": 245
                            }
                        ],
                        "text": "MIT[27] 924 \u2013 \u2013 \u2013 \u2013 \u2013 128 128 128 3 USC-A[43] \u2013 \u2013 \u2013 313 \u2013 205 70 98 133 3 USC-B[43] \u2013 \u2013 \u2013 271 \u2013 54 63 90 126 3 USC-C[44] \u2013 \u2013 \u2013 232 \u2013 100 74 108 145 3 3 CVC[14] 1000 6175\u2020 \u2013 \u2013 \u2013 \u2013 46 83 164 3 3 TUD-det[1] 400 \u2013 400 311 \u2013 250 133 218 278 3 3 INRIA[5] 1208 1218 614 566 453 288 139 279 456 3 DC[24] 2."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 45,
                                "start": 42
                            }
                        ],
                        "text": "Pedestrians can be labeled in photographs [5], surveillance video [26], and images taken from a mobile recording setup, such as a robot or vehicle [8]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 81,
                                "start": 78
                            }
                        ],
                        "text": "Publicly available benchmarks, the most popular of which is the INRIA dataset [5], have contributed to spurring interest and progress in this area of machine vision."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 21,
                                "start": 18
                            }
                        ],
                        "text": "The INRIA dataset [5] has helped drive recent advances in pedestrian detection and remains the most widely used."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 91,
                                "start": 60
                            }
                        ],
                        "text": "Detecting people in images is a problem with a long history [37, 13, 35, 27, 16, 41, 23, 5]; in the past two years there has been a surge of interest in pedestrian detection [6, 9, 11, 18, 20, 21, 25, 30, 32, 33, 36, 38, 42]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 70,
                                "start": 67
                            }
                        ],
                        "text": "7(b) we show a heat map obtained by using BBs generated by the HOG [5] pedestrian detector with a low threshold."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Histogram of oriented gradient for human detection"
            },
            "venue": {
                "fragments": [],
                "text": "CVPR,"
            },
            "year": 2005
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 60,
                                "start": 34
                            }
                        ],
                        "text": "(3) We benchmark seven algorithms [40, 5, 7, 30, 11, 42, 21], either obtained directly from the original authors or reimplemented in-house."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 88,
                                "start": 82
                            }
                        ],
                        "text": "LatSvm likely suffers from being trained on the Pascal dataset, while results for HikSvm are artificially depressed since small people are not detected."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 18,
                                "start": 12
                            }
                        ],
                        "text": "Results for HikSvm at the medium/far scales are not shown (see Table 2 for details)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 79,
                                "start": 73
                            }
                        ],
                        "text": "For unoccluded\nnear pedestrians, purely gradient based detectors such as HikSvm, LatSvm and especially HOG perform best, with a miss rate under 40% at 1 FPPI."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 17,
                                "start": 13
                            }
                        ],
                        "text": "05 \u201908 HikSvm[21] HOG-like HIK SVM 3 3 140 96 1."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 224,
                                "start": 174
                            }
                        ],
                        "text": "Detecting people in images is a problem with a long history [37, 13, 35, 27, 16, 41, 23, 5]; in the past two years there has been a surge of interest in pedestrian detection [6, 9, 11, 18, 20, 21, 25, 30, 32, 33, 36, 38, 42]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 60,
                                "start": 52
                            }
                        ],
                        "text": "We observed this in two of the algorithms evaluated [30, 21] 2."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Classification using intersection kernel SVMs is efficient"
            },
            "venue": {
                "fragments": [],
                "text": "CVPR,"
            },
            "year": 2008
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Pedestrian det . via classification on riemannian manifolds"
            },
            "venue": {
                "fragments": [],
                "text": "PAMI"
            },
            "year": 1985
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Pedestrian det . via classification on riemannian manifolds"
            },
            "venue": {
                "fragments": [],
                "text": "PAMI"
            },
            "year": 2008
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "ETISEO , performance eval . for video surveillance systems"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2007
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 224,
                                "start": 174
                            }
                        ],
                        "text": "Detecting people in images is a problem with a long history [37, 13, 35, 27, 16, 41, 23, 5]; in the past two years there has been a surge of interest in pedestrian detection [6, 9, 11, 18, 20, 21, 25, 30, 32, 33, 36, 38, 42]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Pedestrian det"
            },
            "venue": {
                "fragments": [],
                "text": "via classification on riemannian manifolds. PAMI, 30(10):1713\u20131727,"
            },
            "year": 2008
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A database and eval . methodology for optical flow"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2007
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 76,
                                "start": 66
                            }
                        ],
                        "text": "The Berkeley Segmentation Dataset [22], the Barron et al. [3] and Middlebury [2] optical flow datasets, the Middlebury Stereo Dataset [31] and the Caltech 101 object categorization dataset [10] all improved performance evaluation and helped drive innovation in their respective fields."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 22,
                                "start": 19
                            }
                        ],
                        "text": "[3] and Middlebury [2] optical flow datasets, the Middlebury Stereo Dataset [31] and the Caltech 101 object categorization dataset [10] all improved performance evaluation and helped drive innovation in their respective fields."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A database and eval"
            },
            "venue": {
                "fragments": [],
                "text": "methodology for optical flow. In ICCV,"
            },
            "year": 2007
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Human detection based on a prob . assembly of robust part det"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2004
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "performance eval . for video surveillance systems"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2008
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "ETISEO , performance eval . for video surveillance systems"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2008
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A database and eval . methodology for optical flow"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2007
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 70,
                                "start": 66
                            }
                        ],
                        "text": "Pedestrians can be labeled in photographs [5], surveillance video [26], and images taken from a mobile recording setup, such as a robot or vehicle [8]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "ETISEO, performance eval"
            },
            "venue": {
                "fragments": [],
                "text": "for video surveillance systems. In AVSS,"
            },
            "year": 2007
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Human detection based on a prob . assembly of robust part det"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2004
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 34,
            "methodology": 12
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 53,
        "totalPages": 6
    },
    "page_url": "https://www.semanticscholar.org/paper/Pedestrian-detection:-A-benchmark-Doll\u00e1r-Wojek/3e083dc8aeb7983a5cdff146985363d38caf0886?sort=total-citations"
}