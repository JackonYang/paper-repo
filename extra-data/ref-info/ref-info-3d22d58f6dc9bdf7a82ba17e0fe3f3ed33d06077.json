{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2105795"
                        ],
                        "name": "Michael J. Black",
                        "slug": "Michael-J.-Black",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Black",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael J. Black"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145981906"
                        ],
                        "name": "P. Anandan",
                        "slug": "P.-Anandan",
                        "structuredName": {
                            "firstName": "P.",
                            "lastName": "Anandan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Anandan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 206768565,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "e7c49a201daf302b8a7fd70729f1b08fcf4c1b90",
            "isKey": false,
            "numCitedBy": 61,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "A model is proposed for the incremental estimation of visual motion fields from image sequences. The authors' model exploits three standard constraints on image motion within an optimization framework: (1) data conservation-the intensity structure of a surface patch changes gradually over time; (2) spatial coherence-neighboring points have similar motions; and (3) temporal coherence-the image velocity of a surface patch changes gradually. The authors' formulation takes into account the possibility of multiple motions at a particular location. They present an incremental scheme for the minimization of the objective function, based on simulated annealing. All computations are parallel, local, and incremental, and occlusion and disocclusion boundaries are estimated.<<ETX>>"
            },
            "slug": "A-model-for-the-detection-of-motion-over-time-Black-Anandan",
            "title": {
                "fragments": [],
                "text": "A model for the detection of motion over time"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "An incremental scheme for the minimization of the objective function is presented, based on simulated annealing, and all computations are parallel, local, and incremental, and occlusion and disocclusion boundaries are estimated."
            },
            "venue": {
                "fragments": [],
                "text": "[1990] Proceedings Third International Conference on Computer Vision"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1753210"
                        ],
                        "name": "Trevor Darrell",
                        "slug": "Trevor-Darrell",
                        "structuredName": {
                            "firstName": "Trevor",
                            "lastName": "Darrell",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Trevor Darrell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1749590"
                        ],
                        "name": "S. Sclaroff",
                        "slug": "S.-Sclaroff",
                        "structuredName": {
                            "firstName": "Stan",
                            "lastName": "Sclaroff",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Sclaroff"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144994682"
                        ],
                        "name": "A. Pentland",
                        "slug": "A.-Pentland",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Pentland",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Pentland"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 11714789,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f1bc36997be7b59641052332b08218e2f8ce86c3",
            "isKey": false,
            "numCitedBy": 74,
            "numCiting": 2,
            "paperAbstract": {
                "fragments": [],
                "text": "The authors formulate the segmentation task as a search for a set of descriptions which minimally encodes a scene. A novel framework for cooperative robust estimation is used to estimate descriptions that locally provide the most savings in encoding an image. A modified Hopfield-Tank networks finds the subset of these descriptions which best describes an entire scene, accounting for occlusion and transparent overlap among individual descriptions. Using a part-based 3-D shape model the authors have implemented a system that is able to successfully segment images into their constituent structure.<<ETX>>"
            },
            "slug": "Segmentation-by-minimal-description-Darrell-Sclaroff",
            "title": {
                "fragments": [],
                "text": "Segmentation by minimal description"
            },
            "tldr": {
                "abstractSimilarityScore": 56,
                "text": "A novel framework for cooperative robust estimation is used to estimate descriptions that locally provide the most savings in encoding an image and a modified Hopfield-Tank networks finds the subset of these descriptions which best describes an entire scene."
            },
            "venue": {
                "fragments": [],
                "text": "[1990] Proceedings Third International Conference on Computer Vision"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2074144179"
                        ],
                        "name": "M. Husain",
                        "slug": "M.-Husain",
                        "structuredName": {
                            "firstName": "Masud",
                            "lastName": "Husain",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Husain"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3247077"
                        ],
                        "name": "S. Treue",
                        "slug": "S.-Treue",
                        "structuredName": {
                            "firstName": "Stefan",
                            "lastName": "Treue",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Treue"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2189155"
                        ],
                        "name": "R. Andersen",
                        "slug": "R.-Andersen",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Andersen",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Andersen"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 27376389,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c7cf4e26a6b6fd0b62a452781abdd424fb7749b3",
            "isKey": false,
            "numCitedBy": 47,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "Although it is appreciated that humans can use a number of visual cues to perceive the three-dimensional (3-D) shape of an object, for example, luminance, orientation, binocular disparity, and motion, the exact mechanisms employed are not known (De Yoe and Van Essen 1988). An important approach to understanding the computations performed by the visual system is to develop algorithms (Marr 1982) or neural network models (Lehky and Sejnowski 1988; Siegel 1987) that are capable of computing shape from specific cues in the visual image. In this study we investigated the ability of observers to see the 3-D shape of an object using motion cues, so called structure-from-motion (SFM). We measured human performance in a two-alternative forced choice task using novel dynamic random-dot stimuli with limited point lifetimes. We show that the human visual system integrates motion information spatially and temporally (across several point lifetimes) as part of the process for computing SFM. We conclude that SFM algorithms must include surface interpolation to account for human performance. Our experiments also provide evidence that local velocity information, and not position information derived from discrete views of the image (as proposed by some algorithms), is used to solve the SFM problem by the human visual system."
            },
            "slug": "Surface-Interpolation-in-Three-Dimensional-Husain-Treue",
            "title": {
                "fragments": [],
                "text": "Surface Interpolation in Three-Dimensional Structure-from-Motion Perception"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This study investigates the ability of observers to see the 3-D shape of an object using motion cues, so called structure-from-motion (SFM), and shows that the human visual system integrates motion information spatially and temporally as part of the process for computing SFM."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1710238"
                        ],
                        "name": "R. Haralick",
                        "slug": "R.-Haralick",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Haralick",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Haralick"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3159307"
                        ],
                        "name": "H. Joo",
                        "slug": "H.-Joo",
                        "structuredName": {
                            "firstName": "Hyonam",
                            "lastName": "Joo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Joo"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 13371212,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "f349b9dfa765fef54ac2308fd703082683bed32c",
            "isKey": false,
            "numCitedBy": 50,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": "A robust technique is described for solving the 3D-to-2D perspective projection pose estimation problem, given corresponding point sets. The technique has a considerable advantage over the least-squares (LS) technique in that with as many as 30% of the corresponding point pair matches completely incorrect the robust technique can determine the correct pose almost as accurately as the LS technique would if the LS technique were given only the correctly matched point pairs. The results of several hundred thousand experiments are reported that support the above conclusion.<<ETX>>"
            },
            "slug": "2D-3D-pose-estimation-Haralick-Joo",
            "title": {
                "fragments": [],
                "text": "2D-3D pose estimation"
            },
            "tldr": {
                "abstractSimilarityScore": 96,
                "text": "A robust technique is described for solving the 3D-to-2D perspective projection pose estimation problem, given corresponding point sets, which has a considerable advantage over the least-squares technique in that with as many as 30% of the corresponding point pair matches completely incorrect the robust technique can determine the correct pose almost as accurately."
            },
            "venue": {
                "fragments": [],
                "text": "[1988 Proceedings] 9th International Conference on Pattern Recognition"
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3194361"
                        ],
                        "name": "S. Geman",
                        "slug": "S.-Geman",
                        "structuredName": {
                            "firstName": "Stuart",
                            "lastName": "Geman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Geman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1707642"
                        ],
                        "name": "D. Geman",
                        "slug": "D.-Geman",
                        "structuredName": {
                            "firstName": "Donald",
                            "lastName": "Geman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Geman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5837272,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "459b30a9a960080f3b313e41886b1aa0e51e882c",
            "isKey": false,
            "numCitedBy": 18711,
            "numCiting": 60,
            "paperAbstract": {
                "fragments": [],
                "text": "We make an analogy between images and statistical mechanics systems. Pixel gray levels and the presence and orientation of edges are viewed as states of atoms or molecules in a lattice-like physical system. The assignment of an energy function in the physical system determines its Gibbs distribution. Because of the Gibbs distribution, Markov random field (MRF) equivalence, this assignment also determines an MRF image model. The energy function is a more convenient and natural mechanism for embodying picture attributes than are the local characteristics of the MRF. For a range of degradation mechanisms, including blurring, nonlinear deformations, and multiplicative or additive noise, the posterior distribution is an MRF with a structure akin to the image model. By the analogy, the posterior distribution defines another (imaginary) physical system. Gradual temperature reduction in the physical system isolates low energy states (``annealing''), or what is the same thing, the most probable states under the Gibbs distribution. The analogous operation under the posterior distribution yields the maximum a posteriori (MAP) estimate of the image given the degraded observations. The result is a highly parallel ``relaxation'' algorithm for MAP estimation. We establish convergence properties of the algorithm and we experiment with some simple pictures, for which good restorations are obtained at low signal-to-noise ratios."
            },
            "slug": "Stochastic-Relaxation,-Gibbs-Distributions,-and-the-Geman-Geman",
            "title": {
                "fragments": [],
                "text": "Stochastic Relaxation, Gibbs Distributions, and the Bayesian Restoration of Images"
            },
            "tldr": {
                "abstractSimilarityScore": 52,
                "text": "The analogy between images and statistical mechanics systems is made and the analogous operation under the posterior distribution yields the maximum a posteriori (MAP) estimate of the image given the degraded observations, creating a highly parallel ``relaxation'' algorithm for MAP estimation."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 1984
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144745619"
                        ],
                        "name": "S. German",
                        "slug": "S.-German",
                        "structuredName": {
                            "firstName": "Stuart",
                            "lastName": "German",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. German"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "121982077"
                        ],
                        "name": "D. German",
                        "slug": "D.-German",
                        "structuredName": {
                            "firstName": "Donald",
                            "lastName": "German",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. German"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 59916588,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a1f9fcf2ccc313a5018e536e76e75d1f7992937b",
            "isKey": false,
            "numCitedBy": 2214,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Stochastic-relaxation,-Gibbs-distributions,-and-the-German-German",
            "title": {
                "fragments": [],
                "text": "Stochastic relaxation, Gibbs distributions, and the Bayesian restoration of images"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1988
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {},
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 6,
        "totalPages": 1
    },
    "page_url": "https://www.semanticscholar.org/paper/Robust-estimation-of-a-multi-layered-motion-Darrell-Pentland/3d22d58f6dc9bdf7a82ba17e0fe3f3ed33d06077?sort=total-citations"
}